text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Simulation Tools for 3D and 4D CT and Dosimetry Abstract Photon-counting CT (PCCT) is a major technological advance in CT imaging. Using photon-counting instead of current energy-integrating detectors, PCCT can offer superior performance in terms of spatial resolution, artifact reduction, and most notably, material decomposition. PCCT’s energy differentiation utility offers an ability to more precisely distinguish different materials and optimize and expand the use of contrast agents in CT. With these abilities, PCCT can significantly facilitate quantitative imaging, reduce radiation exposure, and enable revolutionary new applications in functional and physiological imaging beyond existing CT techniques. To realize the full potential of PCCT in clinical practice, the technology needs comprehensive assessments and application-based optimizations. Effective design and deployment of PCCT depends on many design and use choices that should be made in view of the eventual clinical utility. Making these choices requires large scale trials on actual patients. However, such trials are challenging, considering the need to make many decisions prior to prototyping, the limited numbers of prototype PCCT scanners available today, and the often-unknown ground-truth in the patient images. Even for existing prototype systems, many decisions require repetitive trials with multiple acquisitions. This is both unethical and impractical considering radiation safety concerns and costs. These challenges can be overcome by utilizing virtual imaging trials (VITs) using computerized patients and imaging models. VITs provide an efficient means with which to determine the most effective and optimized design and use of imaging technologies with complete control over the study design. In our prior funded project, we developed a VIT framework to evaluate standard energy-integrating detector CT technologies. In this project, we expand the applicability of this framework to photon-counting detector CT. Specifically, we enhance our computational XCAT phantoms to model the necessary higher-resolution detail including normal and abnormal tissue heterogeneities and intra-organ contrast perfusion diversity across populations (Aim 1). To image the phantoms, we develop the first PCCT simulator capable of mimicking existing and emerging prototypes (Aim 2). The enhanced VIT framework will provide the essential foundation with which to comprehensively evaluate and optimize PCCT technologies and applications. In Aim 3, we assess and optimize the use of PCCT for morphological, textural, and compositional quantification in select oncologic and cardiac applications, two leading health detriments in the US where PCCT can offer a notable impact. The results will be the first of their kind in comprehensively evaluating the task-based merits and capabilities of PCCT, determining optimum dose per patient size for PCCT imaging of patients for cancerous lesions and cardiac plaque/stenoses, and helping to establish the effective utility of PCCT in clinical care. The purpose of this project is to develop and utilize a virtual framework to comprehensively evaluate and optimize emerging photon-counting devices and applications in CT imaging. The results will be the first of their kind evaluating the task-based merits and capabilities of photon-counting CT and will help establish its effectual utility in oncologic and cardiac care.",Simulation Tools for 3D and 4D CT and Dosimetry,10189580,R01EB001838,"['3-Dimensional', 'Abdomen', 'Anatomy', 'Cancerous', 'Cardiac', 'Caring', 'Clinic', 'Clinical', 'Computer software', 'Contrast Media', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Dose', 'Ensure', 'Ethics', 'Evaluation', 'Foundations', 'Functional Imaging', 'Funding', 'Health', 'Heterogeneity', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Industry', 'Lesion', 'Manufacturer Name', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Noise', 'Organ', 'Pathologic', 'Patient imaging', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Population', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Research Design', 'Resolution', 'Resources', 'Role', 'Safety', 'Scientist', 'Series', 'Specimen', 'Stenosis', 'System', 'Task Performances', 'Techniques', 'Technology', 'Texture', 'Tissue Model', 'Tissues', 'Work', 'X-Ray Computed Tomography', 'analytical method', 'base', 'cardiac plaque', 'clinical application', 'clinical care', 'clinical practice', 'computerized', 'computerized tools', 'cost', 'cost efficient', 'deep learning', 'design', 'detector', 'dosimetry', 'experimental study', 'human imaging', 'human subject', 'improved', 'insight', 'learning strategy', 'photon-counting detector', 'prototype', 'quantitative imaging', 'simulation', 'soft tissue', 'tool', 'unethical', 'virtual', 'virtual imaging']",NIBIB,DUKE UNIVERSITY,R01,2021,534495
"Biomechanical Analysis in Strabismus Surgery We propose 3 interrelated aims to define the biomechanics of the eye rotating (extraocular) muscles (EOMs) & optic nerve (ON) in health & visual disease, understand novel EOM actions, & characterize mechanical effects that may contribute to severe myopia. We aim to improve treatment of strabismus, misalignment of visual directions of the eyes; glaucoma & non-arteritic anterior ischemic optic neuropathy (NA-AION), both common blinding ON diseases; & high axial myopia, an ocular elongation & distortion that has become a worldwide epidemic & major cause of blindness. We propose a novel & critical nexus linking the EOMs, ON, & structure of the eye's scleral wall that we will explore using modern imaging & artificial intelligence techniques. Aim I will clarify the kinematic (motion) properties of the human eye, testing by multipositional magnetic resonance imaging (MRI) of the eyeball & EOMs the hypothesis that translational (linear) movement contributes importantly to ocular alignment. MRI will be performed during horizontal convergence & vertical eye rotation in normal people, & in patients who have common forms of strabismus including convergence insufficiency, eye crossing (esotropia), & outward ocular deviation (exotropia), both before & after corrective EOM surgery. Clarification of ocular translation is necessary to understand normal ocular motility and treat its disorders. Aim II will characterize the mechanical loading on the ON caused by eye movements. We will characterize the mechanical effects of ON tractional loading on the eyeball during horizontal & vertical eye rotations at 2 scales in living people, to test the hypothesis that such ON loading deforms it & adjacent retina & blood vessels as loading translates the eye. We propose that the resulting deformation during eye movements may create repetitive strain injury contributing to glaucoma, NA-AION, & axial myopia. In groups of subjects with the foregoing diseases, & in an equal group of matched healthy subjects, we will study mechanical effects of eye movement within the living eye by imaging its internal micro structure & blood vessels with optical coherence tomography, & outside the eyeball in the eye socket using MRI. Effects of tethering during eye movement will be studied ex vivo by precision 3D optical imaging of fresh human eye bank specimens subjected to mechanical tension on the ON that mimic effects of the eye movements imaged in the living subjects. Aim III will model the biomechanics of ocular kinematics. The constitutive mechanical properties of the non-muscular ocular & eye socket tissues will be described by finite element models (FEMs) using modern engineering methods for computational simulation to predict ocular kinematics, as well as local mechanical strains in the ON & sclera that may cause glaucoma, NA-AION, & the ocular deformities underlying extreme nearsightedness. We will determine if FEMs employing normal tissue properties can simulate normal ocular translation during horizontal & vertical rotations & convergence. By FEM simulation, we will also test the hypothesis that ocular loading by eye movement might contribute to: normal vergence, strabismus, & the effects of strabismus surgery. Relevance. Strabismus is a common clinical disorder that can cause double vision in adults and vision loss in children. Strabismus is often treated by surgical manipulation of the eye muscles, although current knowledge of their structure and function is incomplete. Proposed functional imaging and biomechanical studies of the properties of the eye muscles, eyeball, and optic nerve will improve understanding of the causes and treatment of strabismus, optic nerve diseases, and nearsightedness.",Biomechanical Analysis in Strabismus Surgery,10134346,R01EY008313,"['3-Dimensional', 'Accounting', 'Adult', 'Agreement', 'Algorithms', 'Anatomy', 'Anterior Ischemic Optic Neuropathy', 'Artificial Intelligence', 'Behavior', 'Biological Specimen Banks', 'Biomechanics', 'Blindness', 'Blood Vessels', 'Child', 'Choroid', 'Clinical', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Connective Tissue', 'Convergence Insufficiency', 'Cumulative Trauma Disorders', 'Deformity', 'Degenerative Myopia', 'Diplopia', 'Disease', 'Duct (organ) structure', 'Elements', 'Engineering', 'Epidemic', 'Equilibrium', 'Esotropia', 'Etiology', 'Exotropia', 'Eye', 'Eye Banks', 'Eye Movements', 'Failure', 'Functional Imaging', 'Gap Junctions', 'Glaucoma', 'Health', 'Human', 'Image', 'Individual', 'Knowledge', 'Lasers', 'Link', 'Magnetic Resonance Imaging', 'Matched Group', 'Measurement', 'Measures', 'Mechanics', 'Modeling', 'Modernization', 'Motion', 'Movement', 'Muscle', 'Muscle Contraction', 'Myopia', 'Normal tissue morphology', 'Ocular orbit', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Physiologic Intraocular Pressure', 'Play', 'Primary Open Angle Glaucoma', 'Property', 'Retina', 'Role', 'Rotation', 'Scanning', 'Sclera', 'Strabismus', 'Stress', 'Structure', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Traction', 'Translating', 'Translations', 'Validation', 'Variant', 'Visual', 'anatomic imaging', 'biomechanical model', 'cell motility', 'crosslink', 'digital imaging', 'ex vivo imaging', 'human tissue', 'improved', 'in vivo imaging', 'in vivo optical imaging', 'kinematics', 'mechanical load', 'mechanical properties', 'model development', 'models and simulation', 'monocular', 'neglect', 'novel', 'ocular imaging', 'optic nerve disorder', 'optical imaging', 'orbit muscle', 'predictive modeling', 'quantitative imaging', 'retina blood vessel structure', 'simulation']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,584907
"Stanford Tissue Mapping Center HuBMAP Supplemental Research Proposal Overview We are requesting supplemental funds for two items:  1. Development of a new computational tool based on a recently developed deep-learning network called  ORCA to use spatial features with single-cell expression data from CODEX to more accurately transfer  cell type annotations to unlabeled CODEX datasets (50% funds are requested to fund a member from  Prof. Jure Leskovec from Computer Science at Stanford University to join our efforts at the Stanford  TMC). This tool has already been used to transfer cell type annotations to unlabeled HuBMAP donor  small intestine and large intestine single cell CODEX data, already saving nearly 100 hours of  annotations required for annotating 2 donors datasets, yet does not incorporate spatial annotations to  help with cell type annotations.  2. An EvoSep Liquid Chromatography system (50% funds are requested) for scProteomics. It is one of the  few systems which can run a true low nano flow rate gradient ( <100 nl/min). Low nano flow can  dramatically improve sensitivity which is the key for the success of scProteomics using mass spectrometry. We will develop a new deep-learning network called ORCA to use spatial features within CODEX data to accurately assign cell type labels to unannotated CODEX datasets saving hundreds of hours of manual annotation. We will also use an EvoSep Liquid Chromatography system to improve our sensitivity for scProteomics for our future small intestine and colon samples.",Stanford Tissue Mapping Center,10414673,U54HG010426,"['Cells', 'Colon', 'Data', 'Data Set', 'Development', 'Funding', 'Future', 'Hour', 'Human BioMolecular Atlas Program', 'Label', 'Large Intestine', 'Liquid Chromatography', 'Manuals', 'Mass Spectrum Analysis', 'Research Proposals', 'Running', 'Sampling', 'Savings', 'Small Intestines', 'System', 'Tissues', 'Universities', 'base', 'cell type', 'computer science', 'computerized tools', 'deep learning', 'improved', 'learning network', 'member', 'nano', 'success', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2021,100000
"Center for Genome Imaging Project Summary/Abstract Center for genome imaging (CGI) Objectives: Three-dimensional (3D) genome organization is a major contributor to genome func- tion, and yet, we are only at the very dawn of discovering the structural signatures that underlie that organization. Thus, the goal of the proposed studies is to develop and apply tools that will enable se- quence-specific imaging of human genomes, in their entirety, with high genomic resolution. In particu- lar, the proposed work will innovate methods for fixed and live cell imaging using diffraction-limited light microscopy and super-resolution microscopy as well as develop new tools for image analysis and ge- nome modeling. To this end, it will involve the continued collaboration of four laboratories, whose col- lective breadth of expertise covers the fields of classical and molecular genetics, chromosome dynam- ics, imaging, Hi-C analysis, convolutional neural networks, and polymer physics-based and restraint- based modeling. An equally important objective of the proposed studies is to ensure a generation of re- searchers whose personal breadth of expertise will come to match that of the entire current team.  Health relatedness: Will a solid grasp of 3D genome organization have implications for under- standing human development? Will it contribute to the protection of human health? Will it contribute to strategies for early diagnostics and perhaps even the development of new therapies? The answer to all these questions is almost certainly a resounding Yes, as knowledge of 3D genome organization will en- hance our capacity to address both fundamental biological processes as well as disease.  Innovation: An abundance of studies argue that genomes function as integrated units and, yet, no extant technologies enable sequence-specific imaging of entire genomes at high genomic resolution. Thus, the capacity of researchers to fathom the interplay between 3D genome organization and ge- nome function has been limited to disjointed snapshots of localized events. Accordingly, first three aims will develop the next tier of tools to put entire genomes within reach. They will advance a new method, OligoFISSEQ, and then integrate it with OligoSTORM and OligoDNA-PAINT to finally achieve high- throughput imaging at both conventional and super-resolution. They will also tackle two genomic fea- tures that have been prohibitively difficult to capture – presence of homologs in diploid cells and highly repeated sequences – as well as innovate strategies for high volume data storage, image processing and analysis, and modeling. Finally, a fourth aim will implement methods for disseminating our tools.  1. Scaling technologies toward whole genome imaging  2. Filling in gaps to visualize chromosomes end-to-end – tackling homologs and repeats  3. Probe design, image analysis, modeling, and integration of epigenetic data  4. Training, resources, and opportunities for engaging colleagues in whole genome imaging Project Narrative/Relevance Center for genome imaging (CGI)  A full understanding of the genome will require the highest resolution knowledge of how genes and chromosomes are organized in 3D space in both healthy and diseased cells. Without such knowledge, efforts to advance disease diagnosis and medical intervention will be compromised. As such, the overarching goal of the proposed studies is to develop and implement imaging and analysis strategies that can encompass entire genomes, including the distinction of homologs and the identification of highly repetitive sequences, and, thus, comprehensively elucidate how spatial organiza- tion influences genome function, stability, and inheritance.",Center for Genome Imaging,10177498,RM1HG011016,"['3-Dimensional', 'Address', 'Aneuploidy', 'Biological', 'Biological Process', 'Cells', 'Chromosomes', 'Collaborations', 'Complement', 'Cues', 'Data', 'Data Storage and Retrieval', 'Development', 'Diagnostic', 'Diploid Cells', 'Disease', 'Ensure', 'Epigenetic Process', 'Etiology', 'Event', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Health', 'Hi-C', 'Human', 'Human Development', 'Human Genome', 'Image', 'Image Analysis', 'Imaging Device', 'Individual', 'Infection', 'Intervention', 'Knowledge', 'Laboratories', 'Malignant Neoplasms', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Molecular Genetics', 'Physics', 'Polymers', 'Predisposition', 'Repetitive Sequence', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Resources', 'Solid', 'Sports', 'Structure', 'Technology', 'Training', 'Visualization', 'Work', 'advanced disease', 'base', 'convolutional neural network', 'cost', 'design', 'disease diagnosis', 'epigenome', 'falls', 'genome-wide', 'grasp', 'human imaging', 'image processing', 'imaging study', 'innovation', 'light microscopy', 'live cell imaging', 'novel therapeutics', 'restraint', 'senescence', 'tool', 'transcriptome', 'whole genome']",NHGRI,HARVARD MEDICAL SCHOOL,RM1,2021,3248226
"Developing new computational tools for spatial transcriptomics data Project Summary  Spatial transcriptomics is a groundbreaking new technology that allows measurement of gene ac- tivity in a tissue sample while mapping where the activity is occurring. It holds the promise to facilitate our understanding of spatial heterogeneity underlying essential phenotypes and diseases, such as neurodegenerative diseases and cancer. However, the development of bioinformatics infrastructures and computational tools has fallen seriously behind the technological advances. The lack of proper computational approaches presents current data analysis barriers that signiﬁcantly hinder biological investigations. The overarching goal of this proposal is to address some of the most pressing ana- lytic challenges facing proﬁling and interpreting spatial transcriptomics data, including 1) lack of robust identiﬁcation of genes with spatial expression patterns across a variety of technical platforms, 2) lack of tools to identify structures, microenvironments as well as developmental trajectory on the tissue, and 3) lack of tools that can jointly analyze spatial transcriptomic data across multiple samples and multiple data sources. In the proposal, we will work on the following aims: Aim 1. Develop nonpara- metric tools for identifying genes with spatial expression patterns. Aim 2. Develop spatially aware dimension reduction tools for detecting structures and developmental trajectories on the tissue. Aim 3. Develop integrative association tools for spatial transcriptomic analysis across multiple samples and datasets. All the methods will be implemented in user-friendly software and disseminated to the sci- entiﬁc community. Successful achievement of all aims will dramatically increase the power of spatial transcriptomics analysis, and facilitate the application of these cutting-edge technologies to transla- tional and clinical studies. Project Narrative  Spatial transcriptomics is a groundbreaking new technology that allows measurement of gene ac- tivity in a tissue sample while mapping where the activity is occurring. Successful proﬁling of spatial gene expression can signiﬁcantly advance the frontier of transcriptomics research and associate these variations with human health and diseases. The aim of this proposal is to develop bioinformatics in- frastructures and computational tools for spatial transcriptomics studies.",Developing new computational tools for spatial transcriptomics data,10278763,R01HG011883,"['Achievement', 'Address', 'Algebra', 'Architecture', 'Awareness', 'Bioinformatics', 'Biological', 'Breast Cancer Patient', 'Case-Control Studies', 'Cell Culture Techniques', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Event', 'Foundations', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Heterogeneity', 'Human', 'Image', 'Immune response', 'Investigation', 'Joints', 'Link', 'Location', 'Malignant Neoplasms', 'Measurement', 'Methodology', 'Methods', 'Neurodegenerative Disorders', 'Pattern', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Property', 'Psychological Transfer', 'Resolution', 'Sample Size', 'Sampling', 'Slide', 'Software Tools', 'Structure', 'Technology', 'Tissue Sample', 'Tissues', 'Training', 'Treatment outcome', 'Validation', 'Variant', 'Work', 'base', 'bioinformatics infrastructure', 'cohort', 'computerized data processing', 'computerized tools', 'deep learning', 'deep neural network', 'digital', 'frontier', 'genomic data', 'histological image', 'innovation', 'learning strategy', 'multiple data sources', 'new technology', 'novel', 'open source', 'phase II trial', 'rapid detection', 'simulation', 'single-cell RNA sequencing', 'tissue culture', 'tool', 'transcriptomics', 'translational study', 'user friendly software', 'user-friendly']",NHGRI,UNIVERSITY OF CHICAGO,R01,2021,397266
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T Project Summary The goal of this project is to develop a framework for high-performance parallel transmission (pTx) that is trans- ferable to a wide range of MRI scanners, and apply it to push the spatial encoding limits of echo planar imaging (EPI) at 7 Tesla. EPI is by far the most widely used pulse sequence for rapid functional, diffusion, and perfusion imaging, and has been the focus of considerable development in recent years to increase its speed and spatial resolution. Now there is a strong desire to push EPI's spatial resolution down to the micro scale. For functional MRI (fMRI), this would enable imaging of ﬁne structures (layers, columns, and nuclei) of cortical and subcortical architecture while better resolving the hemodynamic response. For diffusion MRI (dMRI), micro scale EPI would improve surface and laminar analysis of ﬁbers in the cortex, as well as brain parcelation using fractional anisotropy differences between gray matter regions, while broadly reducing partial volume effects. It would further enable EPI to be broadly applied to accelerate anatomic scans that are geometrically matched to fMRI and dMRI scans. However, increasing the resolution of single-shot EPI requires longer readouts which extend echo times and re- duce functional contrast in fMRI and signal-to-noise in dMRI at 7 Tesla, while increasing geometric distortions and blurring. Segmented or multishot EPI is a classic method to increase spatial resolution without increasing readout durations, but is underutilized, primarily due to its high sensitivity to motion and dynamic phase changes between shots which cause large image artifacts.  We propose to develop a new multishot EPI technique called shuttered EPI, which addresses the lim- itations of conventional multishot EPI by imaging a set of spatially disjoint shutters in each shot. The shutters are produced by a multidimensional excitation pulse and are spatially shifted between shots to cover an entire slice. However, with thin slices the length of the excitation pulses are impractical (20-100 ms). Many-coil pTx (> 8 coils) can shorten the length of these pulses to feasible durations, but current 7 Tesla scanners have only 8 transmit channels due to cost, footprint, cabling, and other constraints. In the ﬁrst project period we pioneered a technique called array-compressed pTx (acpTx) which overcomes this limitation. Using acpTx, 8 transmit chan- nels can control an arbitrarily large number of coils, where the channels and coils are connected via an array compression network that is optimized with RF pulses for speciﬁc excitations. In this project, we will develop and apply acpTx methods and hardware (a many-coil head transmit array and an 8 channel-to-many coil array com- pression network) to achieve feasible RF pulse durations when exciting the shutter patterns required for shuttered EPI. These developments will be implemented on two major 7T scanner platforms and evaluated in submillimeter (600 micron) fMRI and dMRI acquisitions. Overall, the project encompasses the synergistic design of RF pulses, hardware, acquisitions and reconstructions to achieve a major advance in spatial encoding. Project Narrative Diffusion and functional magnetic resonance imaging (MRI) at 7 Tesla ﬁeld strength using echo planar imaging (EPI) has the potential to deliver clear images of brain structure and function at the level of layers, columns, and nuclei. However, when existing EPI scans are pushed to the spatial resolutions required to resolve these structures, they become highly sensitive to off resonance-induced geometric distortions, relaxation-induced blur- ring, physiological noise and motion. To address this problem, in this project we will develop many-coil array- compressed parallel transmission and apply it to enable shuttered multishot EPI scans that are robust to these effects.",Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T,10093035,R01EB016695,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Anisotropy', 'Architecture', 'Biological', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Data', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Echo-Planar Imaging', 'Elements', 'Fiber', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Head', 'Homebound Persons', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Length', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Morphologic artifacts', 'Motion', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Physiological', 'Problem Formulations', 'Relaxation', 'Research Project Grants', 'Resolution', 'Scanning', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Thinness', 'Time', 'base', 'blood oxygen level dependent', 'cost', 'design', 'gray matter', 'hemodynamics', 'image reconstruction', 'improved', 'magnetic field', 'motion sensitivity', 'neuroimaging', 'perfusion imaging', 'phase change', 'reconstruction', 'response', 'simulation', 'spectroscopic imaging', 'time use', 'transmission process', 'virtual']",NIBIB,VANDERBILT UNIVERSITY,R01,2021,558172
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,10225587,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2021,540280
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),10246945,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'data streams', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'open source tool', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2021,1174855
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10115690,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2021,66390
"Muscle Control Mechanism of Voice Production in Vocal Fold Paralysis Project Summary After nearly five decades of human voice research, much remains unknown regarding muscle control mechanism of voice production. Studies confirmed that vocal fold pre-phonatory posture (geometry, position, tension and stiffness) is among the primary factors controlling vocal fold vibratory dynamics and voice type. However, very limited data is available on muscle control of these properties, primarily due to experimental difficulties. Muscle control of glottic geometry and dynamics has been studied in in vivo human and animal models, but these studies were limited to an endoscopic superior view, thus cannot to provide 3D deformation/movement of the vocal folds. Moreover, tension and stiffness of the vocal fold tissues are very difficult to obtain in vivo due to a lack of reliable techniques. A significant knowledge gap remains regarding how intrinsic laryngeal muscles (ILMs) control voice production through vocal fold posturing as well as how ILM dysfunctions, such as vocal fold paralysis/paresis (VFP), affect voice production by altering vocal fold posturing. In this project, we propose to use an innovative approach that integrates experimental data and state-of-the-art computer modeling techniques to produce a complete dataset of 3D vocal fold postures (geometry, position, tension, stiffness), 3D vocal fold vibratory dynamics, and voice outcomes in the full muscle control space including symmetric, asymmetric and compensative muscle activations. The PI’s group recently developed a state-of-the-art, physics based, 3D computer model that integrates realistic laryngeal anatomy, physiologically quantifiable inputs, inverse material parameterization and machine learning for simulating vocal fold posturing and flow-structure-acoustics interaction (FSAI) during voice production. For this project, we propose to combine this embodied model with experimental data to generate a holistic view of vocal fold posturing and FSAI with great temporal and spatial details in the full muscle control space. In particular, the model will reveal the 3D complexity of vocal fold postures and vibrations and provide measures of tension and stiffness with muscle activations, which have not been available. We propose to use the dataset to elucidate causal links among muscle activity, vocal fold posturing, vocal fold vibration and voice outcome. Muscle combinations with distinct posturing, vibration and acoustic patterns will be identified. The new knowledge is expected to elucidate the muscle control mechanism of voice production through vocal fold posturing. The proposed work has the potential to improve insight into the function and dysfunction of the ILMs and to serve as a foundation for novel, targeted therapeutic approaches. We hope to develop possible biomechanical metrics for the diagnosis and optimal methodology for treatment of VFP. Project Narrative Vocal fold paralysis/paresis (VFP) is the most common etiology of voice disorders which affects 9% of the U.S. population. Diagnosis and optimal treatment of VFP remain challenging because of incomplete understanding of muscle control mechanism of vocal fold posturing and vibration. This project will build causal links among muscle activation, vocal fold posturing, vocal fold vibration and voice acoustics, allowing for the development of possible biomechanical metrics for diagnosis and optimal treatment of VFP.",Muscle Control Mechanism of Voice Production in Vocal Fold Paralysis,10299679,R15DC019229,"['3-Dimensional', 'Acoustics', 'Affect', 'Anatomy', 'Animal Model', 'Biomechanics', 'Canis familiaris', 'Computer Models', 'Consultations', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Doctor of Medicine', 'Etiology', 'Financial compensation', 'Foundations', 'Functional disorder', 'Geometry', 'Human', 'Knowledge', 'Laryngeal muscle structure', 'Larynx', 'Link', 'MRI Scans', 'Machine Learning', 'Measures', 'Methodology', 'Modeling', 'Movement', 'Muscle', 'Otolaryngology', 'Outcome', 'Paralysed', 'Paresis', 'Pattern', 'Physics', 'Physiological', 'Population', 'Positioning Attribute', 'Posture', 'Production', 'Property', 'Research', 'Structure', 'Students', 'Techniques', 'Testing', 'Tissues', 'Universities', 'Voice', 'Voice Disorders', 'Work', 'base', 'clinically relevant', 'experimental study', 'human model', 'improved', 'in vivo', 'innovation', 'insight', 'novel', 'optimal treatments', 'professor', 'simulation', 'targeted treatment', 'vibration', 'vocal cord']",NIDCD,UNIVERSITY OF MAINE ORONO,R15,2021,431951
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness in the US. The management of glaucoma is based on early detection, followed by careful evaluation and monitoring to identify those with rapid disease progression and high risk for vision loss. This allows for the rational use of medical, laser, and surgical treatments. Current methods of assessing glaucoma have significant limitations. Visual field (VF) testing has a low sensitivity for detecting early disease, and its reproducibility worsens in advanced stages, reducing its reliability for monitoring disease progression. Optical coherence tomography (OCT) precisely measure the peripapillary nerve fiber layer (NFL) thickness and is the most commonly used technology for objective glaucoma evaluation. However, NFL thickness has limited sensitivity in detecting early glaucoma, and reaches a floor value in moderate glaucoma, which prevents it from tracking glaucoma progress into later stages. The goal of the proposed research is to develop advanced OCT technology that will enhance detection of early glaucoma, improve the sensitivity of detecting significant disease progression, and increase the accuracy of measuring progression speed. The Specific Aims are: 1. Develop a directional high-resolution OCT and OCT angiography prototype to improve imaging of  structure and perfusion. The prototype will have real-time control of beam direction to maintain  perpendicular incidence on the NFL for accurate reflectance analysis, which has shown promise for very  sensitive detection of early glaucoma. Sensorless adaptive-optics aberration correction will enable high  transverse resolution to enhance the detection of nerve fiber bundle and capillary defects. Ultrahigh axial  resolution will enable assessment of the pentalaminar structure of the inner plexiform layer. 2. Wide-field OCT and OCT angiography analyses and visual field simulation. Wide peripapillary and  macular scans, using a next-generation commercial spectral-domain OCT system, will allow visualization of  nerve fiber and perfusion defects from the disc margin to temporal raphe, thus improving early glaucoma  detection. VF simulation will be performed to convert OCTA perfusion measurement to a VF-equivlaent dB-  scale familiar to clinicians for monitoring progression. The simulation has higher reproducibility than actual  VF, which improves detection of disease progression and measurement of progression speed. 3. Clinical studies in glaucoma diagnosis and monitoring. The clinical study will test whether the  proposed new technologies can improve the detection of pre-perimetric glaucoma, detection of disease  progression, and the accuracy of measuring the speed of progression. This research is likely to transform the clinical practice of glaucoma by developing novel objective functional and structural tests that can be practically implemented on the next generation of clinical OCT systems. This will save vision by achieving accurate diagnosis in early glacuoma and timely intervention in rapid progressors. PROJECT NARRATIVE Optical coherence tomography (OCT) is a high-resolution imaging technology that is already commonly used to diagnose and monitor glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, and provide more accurate monitoring of disease progression. Directional OCT technology will be developed to accurately measure nerve fiber layer reflectance; sensorless adaptive-optics OCT technology will be used to improve imaging of nerve fiber bundles and capillaries; ultrahigh axial resolution will enable imaging of detailed internal retinal structures such as the lamellae of the inner plexiform layer; and capillary perfusion measurements will be used to simulate visual field function.",Functional and Structural Optical Coherence Tomography for Glaucoma,10211838,R01EY023285,"['3-Dimensional', 'Angiography', 'Blindness', 'Blood capillaries', 'Clinical', 'Clinical Research', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Floor', 'Future', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging technology', 'Incidence', 'Inner Plexiform Layer', 'Intervention', 'Lasers', 'Location', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Nerve Fibers', 'Nose', 'Open-Angle Glaucoma', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Questionnaires', 'Real-Time Systems', 'Reproducibility', 'Research', 'Resolution', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Visualization', 'accurate diagnosis', 'adaptive optics', 'base', 'clinical practice', 'deep neural network', 'field study', 'high resolution imaging', 'high risk', 'improved', 'macula', 'new technology', 'next generation', 'novel', 'novel strategies', 'optic nerve disorder', 'prevent', 'prototype', 'quantitative imaging', 'simulation', 'tool']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,624917
"Human and Machine Learning for Customized Control of Assistive Robots PROJECT SUMMARY This application will result in a technological platform that re-empowers persons with severe paralysis, by allowing them to independently control a wide spectrum of robotic actions. Severe paralysis is devastating, and chronic—and reliance on caregivers is persistent. Assistive machines such as wheelchairs and robotic arms offer a groundbreaking path to independence: where control over their environment and interactions is returned to the person.  However, to operate complex machines like robotic arms and hands typically poses a difﬁcult learning challenge and requires complex control signals—and the commercial control interfaces accessible to persons with severe paralysis (e.g. sip-and-puff, switch-based head arrays) are not adequate. As a result, assistive robotic arms remain largely inaccessible to those with severe paralysis—arguably the population who would beneﬁt from them most.  The purpose of the proposed study is to provide people with tetraplegia with the means to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. Control interfaces that generate a unique map from a user's body motions to control signals for a machine offer a customized interaction, however these interfaces have only been used to issue low-dimensional (2-D) control signals whereas more complex machines require higher-dimensional (e.g. 6-D) signals. We propose an approach that leverages robotics autonomy and machine learning in order to aid the end-user in learning how to issue effective higher-dimensional control signals through body motions. Speciﬁcally, initially the human issues a lower- dimensional control signal and robotics autonomy is used to bridge the gap by taking over whatever is not covered by the human's control signal. Help from the robotics autonomy is then progressively scaled back, automatically, to cover fewer and fewer control dimensions as the user becomes more skilled.  The ﬁrst piece to our approach deals with how to extract control signals from the human, using the body-machine interface. The development and optimization of decoding procedures for controlling a robotic arm using residual body motions will be addressed under Speciﬁc Aim 1. The second piece to our approach deals with how to interpret control signals from a human within a paradigm that shares control between the human and robotics autonomy. To identify which shared-control formulations most effectively utilize the human's control signals will be the topic of Speciﬁc Aim 2. The ﬁnal piece to our approach deals with how to adapt the shared-control paradigm so that more control is transferred to the human over time. This adaptation is necessary for the human's learning process, since the goal in the end is for the human to be able to fully control the robotic arm him/herself, and will be assessed under Speciﬁc Aim 3.  At the completion of this project, tetraplegic end-users will be able to operate a robotic arm using their residual body motions, through an interface that both promotes the use of residual body motions (and thus also recovery of motor skill) and adapts with the human as their abilities change over time. By leveraging adaptive robotics autonomy, our application moreover provides a safe mechanism to facilitate learning how to operate the robotic platform. Frequently the more severe a person's motor impairment, the less able they are to operate the very assistive machines, like powered wheelchairs and robotic arms, which might enhance their quality of life. The purpose of the proposed study is to provide people with tetraplegia with the means, through non-invasive technologies, to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. We propose and study an approach that leverages robot machine learning and autonomy in order to facilitate human motor learning of how to operate a robotic arm using a customized interface, in order to make powered assisted manipulation more accessible to people with severe paralysis. 1",Human and Machine Learning for Customized Control of Assistive Robots,10005323,R01EB024058,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Affect', 'Algorithms', 'Back', 'Caregivers', 'Cerebral Palsy', 'Chronic', 'Complex', 'Computers', 'Custom', 'Data', 'Development', 'Devices', 'Dimensions', 'Eating', 'Effectiveness', 'Environment', 'Exercise', 'Formulation', 'Fostering', 'Freedom', 'Future', 'Goals', 'Hand', 'Head', 'Health Benefit', 'Human', 'Learning', 'Left', 'Limb structure', 'Machine Learning', 'Maintenance', 'Maps', 'Mental Depression', 'Mental Health', 'Motion', 'Motivation', 'Motor', 'Motor Skills', 'Movement', 'Multiple Sclerosis', 'Neurologic', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Population', 'Posture', 'Powered wheelchair', 'Procedures', 'Process', 'Quadriplegia', 'Quality of life', 'Rehabilitation therapy', 'Residual state', 'Robot', 'Robotics', 'Self-Help Devices', 'Shoulder', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Spinal cord injured survivor', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Wheelchairs', 'Work', 'arm', 'assistive robot', 'base', 'body-machine interface', 'brain machine interface', 'efficacy evaluation', 'empowerment', 'feeding', 'high dimensionality', 'improved', 'machine learning algorithm', 'motor impairment', 'motor learning', 'motor recovery', 'n-dimensional', 'novel strategies', 'physical conditioning', 'psychologic', 'robot control', 'sensor', 'two-dimensional']",NIBIB,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R01,2021,375190
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10220967,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2021,821583
"Individualized spatial topology in functional neuroimaging Project Summary. Neuroimaging is poised to take a substantial leap forward in understanding the neurophysiological underpinnings of human behavior, due to a combination of improved analytic techniques and the quality of imaging data. These advances are allowing researchers to develop population-level multivariate models of the functional brain representations underlying behavior, performance, clinical status and prognosis, and other outcomes. Population-based models can identify patterns of brain activity, or `signatures', that can predict behavior and decode mental states in new individuals, producing generalizable knowledge and highly reproducible maps. These signatures can capture behavior with large effect sizes, and can be used and tested across research groups. However, the potential of such signatures is limited by neuroanatomical constraints, in particular individual variation in functional brain anatomy. To circumvent this problem, current models are either applied only to individual participants, severely limiting generalizability, or force participants' data into anatomical reference spaces (atlases) that do not respect individual functional topology and boundaries. Here we seek to overcome this shortcoming by developing new topological models for inter-subject alignment, which register participants' functional brain maps to one another. This will increase effective spatial resolution, and more importantly allow us to explicitly analyze the spatial topology of functional maps make inferences on differences in activation location and shape across persons and psychological states. We will test and validate the methods using a purpose-designed experiment (n = 120) that includes two types of naturalistic narrative experiences (movies and audio stories) and tasks from three functional domains (pain, emotion, and cognition). The tasks are designed with several constraints in mind, including: (1) systematic coverage of cognitive, emotional, and sensory tasks matched in stimulus properties (e.g., stimulus duration); and (2) multiple levels of task demand within each task, to permit parametric modeling and prediction of demand levels. We will compare our new methods to existing methods based on out-of-sample effect sizes in predicting behavior and test-retest reliability. We will make the analytic methods, software, and dataset available to other researchers, along with a library of functional reference spaces for multiple psychological states. Project Narrative. We develop new methods for enhancing the development of models that can predict behavior, clinical status, and other outcomes using neuroimaging data. Successful development will help improve the translational impact of neuroimaging. It will also contribute to developing multidisciplinary neuroscience, by promoting the development of neural signatures for specific mental processes in humans with increased precision and specificity.",Individualized spatial topology in functional neuroimaging,10150848,R01EB026549,"['Affective', 'Anatomy', 'Atlases', 'Behavior', 'Brain', 'Charon', 'Clinical', 'Cognition', 'Cognitive', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Emotional', 'Emotions', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Human', 'Image', 'Individual', 'Individual Differences', 'Knowledge', 'Libraries', 'Location', 'Machine Learning', 'Maps', 'Mental Processes', 'Methods', 'Mind', 'Modeling', 'Neurosciences', 'Outcome', 'Pain', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Process', 'Prognosis', 'Property', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Sensory', 'Shapes', 'Specificity', 'Stimulus', 'Sum', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'Wages', 'Work', 'affective neuroscience', 'analytical method', 'base', 'behavior prediction', 'behavior test', 'cognitive neuroscience', 'design', 'experience', 'experimental study', 'flexibility', 'improved', 'individual variation', 'mental state', 'model development', 'movie', 'multidisciplinary', 'neurodevelopment', 'neuroimaging', 'neurophysiology', 'population based', 'predictive modeling', 'psychologic', 'statistics', 'translational impact']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,653664
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of differenttypes of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",10397321,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2021,1500000
"Random Matrix Theory-Based Noise Removal in MRI PROJECT SUMMARY MRI is a widely-used imaging modality which offers unique soft-tissue contrast and provides a wealth of anatomical and functional information. However, MRI is inherently slow and signal-to-noise ratio (SNR)-limited, resulting in variable diagnostic image quality and limiting statistical power for research studies. Particularly clinically relevant SNR-starved applications are diffusion MRI (dMRI) and functional (fMRI) for surgical planning (e.g., in functional neurosurgery and in brain tumors). dMRI suffers from long scan times, low resolution and subject motion; BOLD fMRI response signal changes are only about 3% using 3T MRI. State-of-the-art denoising methods, based on image models or smoothing, result in partial-volume effects and loss of fine anatomical detail. We have identified an untapped reserve for significant noise reduction in clinically feasible MRI protocols resulting in SNR increase and Rician MRI noise floor decrease by factors of up to 5-fold, using a model-free noise reduction (denoising) and image reconstruction technique, based on random matrix theory. It does not rely on user-specific input, and outperforms state-of-the-art denoising methods. Our method allows us to identify and remove a pure thermal noise contribution in the principal component analysis (PCA) representation of an MRI data matrix. Remarkably, while noise enters randomly in each voxel's signal, its contribution to the principal components becomes deterministic, when signals from large number of voxels and inequivalent acquisitions (e.g., q-space, time-domain, coils) are combined, which allows us to identify and remove pure- noise components. The key to our MP-PCA method is acquisition redundancy, such that the bulk of the PCA spectrum is dominated by the noise, whose contribution can then be identified and removed. While we initially exploited redundancy in the dMRI q-space, our preliminary findings show it is also present in multi-coil arrays, and in the temporal domain of fMRI. The main goals of this study are: To develop and optimize the MP-PCA denoising framework at the level of multi-coil image reconstruction and to evaluate its accuracy and precision in dMRI (Aim 1); to evaluate its clinical utility for increasing dMRI resolution in functional neurosurgery, based on the ground-truth derived from MR-guided ultrasound intra-operative feedback (Aim 2); and to evaluate its clinical utility for decreasing fMRI scan time in preoperative planning of brain tumor resections (Aim 3). Fundamentally, this project will establish an objective framework to quantify the information content of different MRI modalities, by separating between the signal and the noise. Its applications to dMRI and fMRI, together with using multi-coil redundancy, will lead to maximal possible SNR, thereby reducing scan time, and improving resolution, precision, sensitivity and diagnostic utility of clinically relevant MRI protocols. PROJECT NARRATIVE MRI, while offering unique soft-tissue contrast, anatomical and functional information, remains inherently slow and signal-to-noise ratio (SNR)-starved, which limits its spatial resolution, lengthens scans, and makes them prone to motion artifacts, thus reducing diagnostic quality. We have identified an untapped reserve for significant noise reduction in clinically feasible MRI acquisitions resulting in SNR increase by up to 5-fold, using a model-free post-processing noise reduction technique, based on random matrix theory. The main goals of this study are to evaluate the robustness and utility of our noise-reduction and reconstruction framework in terms of increasing resolution and shortening scan time, as well as to translate it into functional neurosurgery and preoperative planning for brain tumors.",Random Matrix Theory-Based Noise Removal in MRI,10229483,R01EB027075,"['Address', 'Algorithms', 'Anatomy', 'Body Surface', 'Body Temperature', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Cell Nucleus', 'Clinical', 'Data', 'Deep Brain Stimulation', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diffusion Magnetic Resonance Imaging', 'Essential Tremor', 'Excision', 'Feedback', 'Floor', 'Focused Ultrasound', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Image', 'Joints', 'Language', 'Length', 'Lesion', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Medial', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Nuclear', 'Operative Surgical Procedures', 'Outcome', 'Parkinson Disease', 'Patients', 'Plant Roots', 'Principal Component Analysis', 'Protocols documentation', 'Pyramidal Tracts', 'RF coil', 'Residual state', 'Resolution', 'Retrospective Studies', 'Sampling', 'Scanning', 'Signal Transduction', 'Spectrum Analysis', 'Techniques', 'Testing', 'Thalamic Nuclei', 'Therapeutic', 'Time', 'Translating', 'Ultrasonography', 'Variant', 'base', 'brain tumor resection', 'clinically relevant', 'denoising', 'functional MRI scan', 'healthy volunteer', 'image reconstruction', 'imaging modality', 'improved', 'nervous system disorder', 'neurosurgery', 'reconstruction', 'research study', 'response', 'soft tissue', 'theories']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,678113
"Generation of parametric images for FDG PET using dual-time-point scans Project Summary/Abstract Positron emission tomography combined with computed tomography (PET/CT) using the radiolabeled tracer 2- deoxy-2-(18F)fluoro-D-glucose (FDG) has become a standard imaging tool for cancer patient management. The semi-quantitative parameter standardized uptake value (SUV) is routinely used in clinical for tumor uptake quantification, which is computed on the static PET image acquired at a certain time (typically 60 min) post tracer injection for a short interval (typically 5-15 min). However, the quantification accuracy of SUV from a single PET scan suffers from the variabilities of tracer plasma clearance and acquisition start time. The dual- time-point FDG PET imaging has been intensively investigated and used in both clinical and research studies, typically one scan at 60 min and the other at 120 min, showing the potential to enhance the diagnostic accuracy of FDG PET by differentiating malignancy from inflammation and normal tissue. However, the current clinical dual-time-point FDG PET studies use the relative SUV change between two scans as the quantification index, which cannot eliminate the variations in tracer plasma clearance. Meanwhile, the dual-time-point protocol has not been optimized and standardized currently, leading to conflicting results. The fully-quantitative parameter, tracer net uptake rate constant Ki, is the most accurate parameter to quantify FDG PET, which is calculated using dynamic imaging with compartmental modeling. Ki is independent on the plasma clearance or acquisition start time. However, the long and complex acquisition protocol (typically at least 60 min), which requires dynamic scanning and sequential arterial blood sampling (or image-derived blood activity) used as input function from the time of injection, limits its application in clinical practice. Meanwhile, generation of the parametric Ki image, which can provide additional heterogeneity information for FDG PET, is challenging clinically using voxel-by-voxel compartmental modeling due to the computational cost and being sensitive to noise using non-linear least squares. The graphical Patlak plot, can be used for simplified Ki calculation and Ki image generation by voxel-by-voxel fitting. However, it still needs dynamic scanning starting from 15-30 min after injection and input function from the time of injection. The aims of this proposal are 1) to optimize the dual-time-point protocol for accurate Ki quantification using Patlak plot without the need for individual patient's input function, and 2) to generate high-quality low-noise dual-time-point Ki images using novel techniques based on deep learning. Upon the success of this project, our proposed approach can obtain reliable tumor Ki quantification and parametric Ki image ""for free"" without adding any additional complexity on the existing dual- time-point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology. We expect the translation of this approach to clinical investigation to be fast, as this is a post-processing approach and is based on data already acquired using clinically used protocol without imposing additional burden to technologists. Project Narrative For FDG PET imaging, we propose to develop a novel and simple approach of quantifying tumor Ki and generating parametric Ki image ""for free"" without adding any additional complexity on the existing dual-time- point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology.",Generation of parametric images for FDG PET using dual-time-point scans,10117077,R03EB027864,"['Blood', 'Blood specimen', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Generations', 'Glucose', 'Heterogeneity', 'Image', 'Imaging Device', 'Inflammation', 'Injections', 'Label', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Noise', 'Normal tissue morphology', 'Oncology', 'Patients', 'Plasma', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation exposure', 'Radiolabeled', 'Scanning', 'Standardization', 'Techniques', 'Time', 'Tracer', 'Training', 'Translations', 'Variant', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical investigation', 'clinical practice', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'diagnostic accuracy', 'image reconstruction', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'parametric imaging', 'population based', 'research study', 'simulation', 'success', 'tumor', 'uptake']",NIBIB,YALE UNIVERSITY,R03,2021,83750
"Multiband ASL for Neurodevelopment Study Project Summary/Abstract The developmental period between childhood to adolescence and young adulthood is marked by a mix of potential and vulnerability. A number of potentially life-long behavioral and emotional problems emerge during this critical period, including alcohol and illicit drug use, risky behaviors, and the first signs of emotional disorders. It is important to understand detailed patterns of typical development, so alterations can be identified and rectified as early as possible. As an entirely noninvasive and quantitative imaging method, arterial spin labeled (ASL) perfusion MRI is increasingly being recognized as an important biomarker for functional brain development in both healthy populations and neurodevelopmental disorders. However, there remain significant challenges for making ASL an impactful tool in studying neurodevelopment, including: 1) a coarse spatial resolution of ~4x4x4mm3, 2) susceptibility to head motion with segmented 3D acquisitions, and 3) potential confounding effects of age dependent variations in arterial transit time using a single post-labeling delay (PLD) scan. Simultaneous multi-slice (SMS) or multiband (MB) is a new accelerated imaging technology that simultaneously excites multiple slices and recovers each slice with parallel imaging techniques. Preliminary studies combining MB with ASL showed that MB can reduce T1 relaxation of the label, improve spatial coverage and/or resolution compared to those of standard 2D ASL. MB imaging may also overcome the limitation of 3D ASL acquisitions in terms of head motion and spatial blurring. However, the signal-to-noise ratio (SNR) of existing MB ASL is inferior to that of 3D ASL. This project builds on two recent innovations from our lab: 1) a constrained slice-dependent (CSD) background suppression (BS) technique that improves the SNR of 2D MB pCASL to be comparable to that of 3D pCASL; and 2) a single-shot 3D GRASE pCASL method with 2D CAIPIRINHA accelerations that improves the imaging speed of 3D pCASL. The goal of this R01 project is to develop and evaluate cutting-edge MB pCASL protocols that are able to offer a high spatial resolution of isotropic 2mm or higher, resistance to head motion and multi-delay capability for accurate perfusion quantification in pediatric populations. A convolutional neural network (CNN) based denoising algorithm for multi-delay MB pCASL will be further developed. The developed suite of MB pCASL protocol and post- processing algorithms will be evaluated in 40 typically developing children and adolescents. The successful completion of this R01 project will lead to a robust multi-delay MB pCASL protocol that is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care. To maximize the scientific and clinical impact, we will continue disseminating the pulse sequence and associated post-processing software as we have been doing in the past decade. Relevance to Public Health A number of potentially life-long behavioral and emotional problems emerge during the developmental period between childhood to adolescence and young adulthood, including alcohol and illicit drug use, risky behaviors, and emotional disorders. This project will develop a robust noninvasive imaging technique using magnetic resonance imaging (MRI) that offers high spatial resolution, resistance to head motion and accurate quantification of cerebral blood flow in children and adolescents. The developed technology is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care.",Multiband ASL for Neurodevelopment Study,10124390,R01EB028297,"['3-Dimensional', 'Acceleration', 'Adolescence', 'Adolescent', 'Affect', 'Age', 'Alcohols', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Behavior Disorders', 'Behavioral', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Child', 'Childhood', 'Clinical', 'Computer software', 'Data', 'Databases', 'Development', 'Emotional', 'Emotional disorder', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Imaging technology', 'Inferior', 'Joint repair', 'Label', 'Life', 'Magnetic Resonance Imaging', 'Methods', 'Motion', 'Network-based', 'Neurodevelopmental Disorder', 'Noise', 'Pattern', 'Performance', 'Perfusion', 'Perfusion Weighted MRI', 'Phase', 'Physiologic pulse', 'Population', 'Predisposition', 'Principal Component Analysis', 'Protocols documentation', 'Public Health', 'Publishing', 'Relaxation', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Risk Behaviors', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Speed', 'Spin Labels', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'age effect', 'age related', 'autism spectrum disorder', 'base', 'child depression', 'clinical care', 'convolutional neural network', 'critical period', 'denoising', 'developmental disease', 'illicit drug use', 'imaging modality', 'improved', 'innovation', 'neurodevelopment', 'non-invasive imaging', 'novel', 'perfusion imaging', 'potential biomarker', 'quantitative imaging', 'socioeconomics', 'substance use', 'time use', 'tool', 'young adult']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,436591
"High performance PET Detector Module for Human Brain Imaging Project Summary / Abstract This proposal is in response to PA 18-484. In the BRAIN 2025 Report, PET (positron emission tomography) is identified as “the best means to translate studies of neurotransmitters, receptors, and neuromodulators to humans.” However dynamic assessment of receptor occupancy and metabolism is hindered by the spatial resolution and sensitivity of even the most modern of clinically available PET scanners. To address this challenge, we propose a next generation PET detector with a highly innovative design: a detector module with a layered scintillator structure and a side readout configuration. The crystal slabs in the module are stacked along the depth direction and are optically separated by reflective films. The scintillation light created in each layer is measured by photodetectors located on the four sides of the crystal. Compared with traditional PET detectors, which contain pixelated crystal arrays, the new design has the following advantages: (1) The layered structure provides depth of interaction (DOI) information such that a smaller diameter detector ring can be used without increasing parallax error, increasing sensitivity while lowering costs. (2) The four-sided readout method improves the energy resolution of the system with increased scintillation light collection efficiency by reducing light loss due to total internal reflection. (3) Sub millimeter spatial resolution is achievable without using very small pitch crystal arrays, since the interaction location in each crystal layer is determined via machine learning- based decoding of the light distribution collected on the four crystal sides. Therefore the production cost of the crystals is reduced. (4) Since the interaction location and energy resolution for each layer are determined independently, the system sensitivity can be increased by stacking more layers in the module without affecting the spatial and energy resolution of the system. (5) For side readout setup, a larger ratio of cross-sectional area to length requires fewer photodetectors to cover all four sides of the module; this reduces photodetector cost. The first four points above have been demonstrated in preliminary studies using a small, prototype module. We propose to build a large scale detector module with this new design to verify the fifth advantage, and to study the effect of detector size on the first four. The outcome of this proposal will be two DOI enabled detector modules with excellent spatial resolution (~1 mm) and energy resolution (~10%), as well as good timing resolution (~400 ps), and DOI resolution (~ 3 mm) and high system sensitivity. A full characterization study for the two modules and imaging studies for both the Derenzo and Hoffman brain phantoms will address the current limitations of human brain PET scanners, and will serve as the foundation for a new dynamic PET scanner for neuroimaging. Project Narrative The goal of this project is to develop a novel design for detector modules used in brain-dedicated PET system with good spatial resolution, energy resolution, timing resolution, and DOI resolution, as well as high sensitivity. If successful, the study will pave the way for building a novel PET system for greatly improved dynamic PET imaging of the human brain.",High performance PET Detector Module for Human Brain Imaging,10254284,R01EB028337,"['Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Area', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Caliber', 'Calibration', 'Clinical', 'Collection', 'Crystallization', 'Development', 'Diagnosis', 'Evaluation', 'Event', 'Film', 'Foundations', 'Gamma Rays', 'Geometry', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Individual', 'Length', 'Light', 'Location', 'Machine Learning', 'Measures', 'Metabolism', 'Methods', 'Modernization', 'Neuromodulator', 'Neurotransmitter Receptor', 'Optics', 'Outcome', 'Parkinson Disease', 'Pattern', 'Performance', 'Portugal', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Production', 'Reporting', 'Resolution', 'Rod', 'Side', 'Signal Transduction', 'Silicon', 'Source', 'Staging', 'Structure', 'Surface', 'System', 'Thinness', 'Translating', 'Variant', 'base', 'brain size', 'cost', 'design', 'detector', 'human imaging', 'imaging study', 'improved', 'innovation', 'machine learning method', 'meetings', 'millimeter', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'photomultiplier', 'prototype', 'receptor', 'response']",NIBIB,"CANON MEDICAL RESEARCH USA, INC.",R01,2021,237471
"Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) remains the main cause of morbidity and mortality in the United States. Cardiac CT provides fast non-invasive assessment of CAD with a high sensitivity and negative predictive value – provided that the lumen can be visualized. However, heavily calcified or stented coronary segments are non- assessable, precluding non-invasive diagnosis of flow-limiting coronary plaques in an estimated 2 million U.S. adults. In addition, the spatial resolution of state-of-the-art CT systems is insufficient for robust visualization of features associated with high risk plaques. Further, while CT can quantitatively evaluate the impact of obstructive CAD on myocardial function using dynamic perfusion imaging, this requires relatively high patient radiation doses, which has limited widespread adoption. Considering the high personal and societal cost of CAD, robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam is critically needed. Built by Siemens Healthcare, a first-of-its-kind, whole-body, photon-counting-detector (PCD) CT system was installed in 2014 at the Mayo Clinic. With support from NIH award EB016966, we showed that the increased iodine contrast-to-noise ratio, decreased electronic noise, spectral imaging capabilities, and improved spatial resolution of PCD-CT relative to commercial CT enabled us to accurately measure increased vasa vasorum density in injured swine carotid arterial walls, demonstrating the exceptional potential of PCD-CT in vascular imaging. Because this system lacks cardiac imaging capabilities, our objective is to develop and validate a PCD dual-source (DS) CT system and novel imaging algorithms to accurately assess CAD in humans, especially in patients with heavily calcified, stented, or high-risk plaques, and to identify patients with myocardial perfusion defects. Our premise is that the established benefits of PCD-CT, used with a DS geometry and advanced noise reduction and material decomposition algorithms, can meet these objectives. Our proposal is significant in many ways: the technology developments will benefit all of CT imaging; robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam will obviate the need for additional imaging, reducing the overall time and cost to comprehensively evaluate CAD and its clinical significance. To extend the demonstrated benefits of PCDs to cardiac CT will require numerous physics, engineering, and algorithm innovations, including novel noise reduction and material decomposition algorithms using energy, spatial and temporal domain redundancies, as well as deep learning. These advances will culminate in a large clinical study to demonstrate not merely that the images are “better,” as is so often done, but that PCD-DSCT provides clinically-significant improvements in the diagnosis and management of patients with suspected CAD. PROJECT NARRATIVE This project will develop a new type of cardiac computed tomography (CT) scanner that is able to comprehensively assess coronary artery disease in humans. This technology, known as photon-counting- detector dual-source CT, is capable of exceptional spatial and temporal resolution, multi-energy spectral imaging and reduced radiation doses, allowing it to image the coronary artery and myocardium with unparalleled quality. This will enable comprehensive assessment of coronary artery anatomy and myocardial function from a single imaging exam, reducing time to diagnosis and cost, while also improving patient diagnosis and management.",Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management,10150846,R01EB028590,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Award', 'Blood Vessels', 'Cardiac', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computed Tomography Scanners', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Defect', 'Diagnosis', 'Diagnostic', 'Dose', 'Engineering', 'Equipment', 'Family suidae', 'Geometry', 'Goals', 'Healthcare', 'Heart failure', 'Human', 'Image', 'Individual', 'Iodine', 'Lesion', 'Low Dose Radiation', 'Magnetic Resonance Imaging', 'Measures', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Noise', 'Patients', 'Perfusion', 'Physics', 'Physiological', 'Predictive Value', 'Radiation', 'Radiation Dose Unit', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Societies', 'Source', 'Specimen', 'Stents', 'Sudden Death', 'System', 'Techniques', 'Technology', 'Time', 'Translating', 'United States', 'United States National Institutes of Health', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'algorithm development', 'calcification', 'clinically significant', 'coronary plaque', 'cost', 'deep learning', 'density', 'design', 'detector', 'heart imaging', 'heart motion', 'high risk', 'human subject', 'imaging capabilities', 'improved', 'industry partner', 'injured', 'innovation', 'mortality', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'perfusion imaging', 'photon-counting detector', 'porcine model', 'routine practice', 'single photon emission computed tomography', 'societal costs', 'spectral energy', 'spectrograph', 'technology development', 'temporal measurement', 'vasa vasorum']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,657862
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10187567,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2021,310796
"Data-driven Head Motion Correction in PET Imaging Using Deep Learning Project Summary Positron-emission tomography (PET) is an imaging modality that allows clinicians and researchers to study the physiological or pathological processes of the human body, and in particular the brain via the use of specific tracers. For brain PET imaging, patient head movement during scanning presents a challenge for accurate PET image reconstruction and subsequent quantitative analysis. Problems due to head motion are exacerbated by the long duration of the scans, with scan times commonly over one hour. Furthermore, some PET studies specifically involve subjects that either have trouble staying still due to psychological variations, e.g. patients with neurodegenerative disorders such as Alzheimer's disease and Parkinson's disease, or psychological variations, e.g. subjects with anxiety disorders, or are required to participate in tasks that involve movement, e.g. smoking cigarettes while scanning. In brain scans, the average head motion can vary from 7 mm in clinical scans to triple this amount for longer research scans. Quantitatively, a 5 mm head motion can produce biases of up to ~35% in regional intensities and ∼15% in volume of distribution estimates, which could much larger than the difference observed in regional intensities or binding potential that distinguish different demographic groups being studied. The ability to track and correct head motion, therefore, would be of high utility in both clinical and research PET studies. In the past, many motion correction methods have been proposed. However, except for hardware-based approaches, there has been no method that can track frequent head motion on-the-fly during the PET acquisition. Hardware-based approaches are not readily available for clinical translation or used by other research facilities due to highly-customized software/hardware setup. To address this challenge, we propose to develop a data-driven methodology using deep learning to track and estimate rigid head motion using PET raw data, and incorporate both tracer type and time as conditional variables into this deep neural network design in order to handle diverse PET tracer types and their dynamic behavior. Overall, these solutions will provide for a data-driven motion estimation methodology to improve the quality of PET imaging. Specifically, we will start with the development and testing of our methodology for rigid head motion estimation using single-tracer PET raw data. Then we will perform evaluation of our multi-tracer motion estimation methodology applied to real PET data with a diverse range of tracers. Finally, in the exploratory phase, we will integrate time-of-flight information into deep learning-based motion prediction. The significance of this proposal is that it will allow for improved quality of PET imaging in real time and potentially allow for its use in clinical PET systems that do not have special motion tracking hardware. This work will serve as a first step towards developing data-driven motion estimation algorithms for full body PET imaging. The innovation lies in the development of what is a data-driven solution to the problem of real time motion estimation. Project Narrative Positron-emission tomography (PET) imaging of the brain is a highly useful tool for biomedical research and clinical practice. Head motion during scanning degrades PET image quality and introduces image artifacts. We propose to develop new data-driven methods, based on PET raw data, to estimate head motion using deep learning, which can be used for real time motion estimation in PET imaging.",Data-driven Head Motion Correction in PET Imaging Using Deep Learning,10144432,R21EB028954,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anxiety Disorders', 'Behavior', 'Binding', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain scan', 'Cigarette', 'Clinical', 'Clinical Research', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Development', 'Devices', 'Effect Modifiers (Epidemiology)', 'Evaluation', 'Event', 'Funding', 'Gold', 'Head', 'Head Movements', 'Hour', 'Human', 'Human body', 'Image', 'Individual', 'Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Movement', 'Neurodegenerative Disorders', 'Parkinson Disease', 'Pathologic Processes', 'Patients', 'Performance', 'Phase', 'Physiological Processes', 'Positron-Emission Tomography', 'Research', 'Research Personnel', 'Scanning', 'Smoking', 'Synapses', 'System', 'Testing', 'Time', 'Tracer', 'Training', 'Variant', 'Work', 'base', 'clinical practice', 'clinical translation', 'deep learning', 'deep neural network', 'density', 'design', 'effectiveness evaluation', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'interest', 'neural network', 'novel', 'psychologic', 'reconstruction', 'research facility', 'simulation', 'statistics', 'tool']",NIBIB,YALE UNIVERSITY,R21,2021,209375
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10186744,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,377473
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10173765,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'efficacy evaluation', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'open source tool', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2021,256578
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of target and OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and automated multi-organ segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop and validate a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will develop an MT-MR simulation based multi-organ auto- segmentation tool. In Aim 3, we will optimize a deep learning-based dose prediction model and assess the effectiveness of the MT-MR based RTP workflow in adaptive stereotactic body radiotherapy planning of pancreatic cancer patients. Successful completion of the project will significantly promote the clinical adoption of MR simulation for abdominal RTP, which will improve treatment precision and outcomes. Moreover, the developed techniques will open the door to future studies aiming at optimizations in both cancer diagnosis and radiotherapy. Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and automated multi- organ segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10331615,R01EB029088,"['3-Dimensional', 'Abdomen', 'Address', 'Adoption', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Detection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pancreas', 'Patients', 'Phase', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protocols documentation', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Spatial Distribution', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Variant', 'Water', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer radiation therapy', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'effectiveness evaluation', 'experience', 'image processing', 'image reconstruction', 'improved', 'interest', 'learning strategy', 'multimodality', 'multitask', 'novel', 'pancreatic cancer patients', 'predictive modeling', 'prevent', 'respiratory', 'simulation', 'soft tissue', 'standard of care', 'success', 'tool', 'treatment planning', 'tumor']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,507076
"CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience The field of network neuroscience has developed powerful analysis tools for studying brain networks and holds promise for deepening our understanding of the role played by brain networks in health, disease, development, and cognition. Despite widespread interest, barriers exist that prevent these tools from having broader impact. These include (1) unstandardized practices for sharing and documenting software, (2) long delays from when a method is first introduced to when it becomes publicly available, and (3) gaps in theoretic knowledge and understanding leading to incorrect, delays due to mistakes, and errors in reported results. These barriers ultimately slow the rate of neuroscientific discovery and stall progress in applied domains. To overcome these challenges, we will use open science methods and cloud-computing, to increase the availability of network neuroscience tools. We will use the platform ""brainlife.io"" for sharing these tools, which will be packaged into self-contained, standardized, reproducible Apps, shared with and modified by a community of users, and integrated into existing brainlife.io analysis pipelines. Apps will also be accompanied by links to primary sources, in-depth tutorials, and documentation, and worked-through examples, highlighting their correct usage and offering solutions for mitigating possible pitfalls. In standardizing and packaging network neuroscience tools as Apps, this proposed research will engage a new generation of neuroscientists, providing them powerful new and leading to new discoveries. Second, the proposed research will contribute growing suite of modeling analysis that can be modified to suit specialized purposes. Finally, the Brainlife.io platform will serve as part of the infrastructure supporting neuroscience research. Altogether, these advances will lead to new opportunities in network neuroscience research and further stimulate its growth while increasing synergies with other domains in neuroscience. Structural and functional networks support cognitive processes. Miswiring networks lead to maladaptive behavior and neuropsychicatric disorders. Network neuroscience is a young field that provides a quantitative framework for modeling brain networks. This project will make network neuroscientific tools available to new users via open science and cloud-computing. New applications of these tools this will lead deeper insight into the role of networks in health as well as in clinical disorders.",CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience,10262925,R01EB029272,"['Address', 'Aging', 'Behavior', 'Biophysics', 'Brain', 'Clinical', 'Cloud Computing', 'Cognition', 'Communities', 'Complex Analysis', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Elements', 'France', 'Funding', 'Generations', 'Graph', 'Growth', 'Health', 'Infrastructure', 'Instruction', 'Knowledge', 'Language', 'Lead', 'Libraries', 'Link', 'Literature', 'Mathematics', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Pathway Analysis', 'Play', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Science', 'Sociology', 'Source', 'Standardization', 'Structure', 'Study models', 'System', 'Techniques', 'Time', 'Training', 'Work', 'analysis pipeline', 'brain computer interface', 'cloud based', 'cognitive process', 'cyber infrastructure', 'data sharing', 'experience', 'innovation', 'insight', 'interest', 'machine learning method', 'network architecture', 'network models', 'neuroimaging', 'open data', 'prevent', 'relating to nervous system', 'statistics', 'support network', 'synergism', 'tool']",NIBIB,INDIANA UNIVERSITY BLOOMINGTON,R01,2021,112726
"Reconstruction of robust, high SNR functional brain images using machine learning and oscillatory steady state MRI Project Summary/Abstract: Functional magnetic resonance imaging (fMRI) is an important tool both clinically and in scientific research, with broad applications ranging from cognitive neuroscience to presurgical planning. FMRI can generate whole brain neuronal activation maps, yet it is an inherently low signal to noise ratio (SNR) method due to the relatively small changes in activation signal relative to the baseline signal. The overarching goal of this project is to develop and validate robust, high SNR fMRI by using a novel acquisition method, oscillating steady state (OSS) fMRI, along with machine learning (ML) techniques, to reconstruct high-quality images of the OSS fMRI data. OSS fMRI can increase SNR by >2x compared to the current state-of-the-art in fMRI acquisition methods, and this boost is roughly equivalent to the SNR gain going from a 3T MRI scanner to a 7T MRI scanner. The SNR increase is a direct result of the steady state approach. However, with a more complex, oscillating acquisition, OSS fMRI can be more susceptible to common MRI artifacts than traditional methods if left uncorrected. Two of the most common sources of MRI artifacts are changes in the main magnetic field (B0) due to physiological noise (such as respiration) and patient motion. This project will develop robust, high SNR fMRI at 3T by incorporating the effects of (1) B0 changes and (2) patient motion into the OSS signal model and image reconstruction algorithms. A new image reconstruction that incorporates neural networks will correct for B0 fluctuations and remove B0 induced artifacts. We will train a neural network to generate B0 field maps using data from a conventional, physics-based two echo field mapping technique to implicitly incorporate prior information of the physics into the reconstruction, while also providing a fast, ML-based field mapping method. To correct for subject motion, we will develop a neural network that estimates rigid-body motion parameters from sequential image frames in the fMRI scan. These motion parameters will be used in an iterative image reconstruction to produce high-quality resting-state and task-based fMRI, even in the presence of subject motion. The technology developed in this proposal will result in improved functional MRI that has the potential to significantly advance both the study of the human brain and the treatment of neurological disorders. The University of Michigan is one of the top research universities in the US, and provides an ideal environment and infrastructure to complete the proposed research strategy. The Functional Magnetic Resonance Laboratory and the Electrical Engineering and Computer Science Department at UM have all the necessary hardware and computational resources needed for this project, including two state-of-the-art GE 3T MRI scanners and extensive GPU hardware for the machine learning components of the project. Furthermore, Drs. Jeffrey Fessler and Douglas Noll have proven expertise in fMRI image acquisition and reconstruction, as well as extensive mentorship experience, that will help guide this project and my training. Project Narrative Functional magnetic resonance imaging (fMRI) is used to measure brain function, and it has revolutionized our understanding of cognitive processes during the last 25 years and has also been used as a tool for presurgical mapping of language and other sensitive brain regions. More recently, fMRI is being used as a biomarker for the progression of neurologic and psychiatric diseases, for example, in Alzheimer’s disease, multiple sclerosis, and major depression. In this project we will improve fMRI techniques by developing new methods that are more robust to common sources of MRI image degradation, which will improve the sharpness of the fMRI images without increasing instrumentation costs.","Reconstruction of robust, high SNR functional brain images using machine learning and oscillatory steady state MRI",10196983,F32EB029289,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Dictionary', 'Echo-Planar Imaging', 'Electrical Engineering', 'Elements', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Head Movements', 'Human', 'Hybrids', 'Image', 'Imaging Phantoms', 'Imaging Techniques', 'Infrastructure', 'Laboratories', 'Language', 'Left', 'Length', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Maps', 'Measures', 'Mental disorders', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Morphologic artifacts', 'Motion', 'Multiple Sclerosis', 'Neurologic Process', 'Neurons', 'Noise', 'Patients', 'Physics', 'Physiological', 'Research', 'Resolution', 'Respiration', 'Rest', 'Scanning', 'Signal Transduction', 'Site', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Universities', 'base', 'blood oxygen level dependent', 'cognitive neuroscience', 'cognitive process', 'computer science', 'computing resources', 'cost', 'experience', 'functional MRI scan', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'instrumentation', 'magnetic field', 'nervous system disorder', 'neural network', 'novel', 'open source', 'progression marker', 'reconstruction', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F32,2021,66390
"A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging PROJECT SUMMARY  Obesity is a significant and growing problem in the United States. Currently, 68.5% of the U.S. population is overweight, with approximately 37.7% of the overweight population being obese. The significant health problems associated with overweightedness and obesity, the “body habitus” of this population combined with the significant challenges in medical imaging of these individuals reduces the effectiveness of healthcare for this population. In ultrasound imaging, the quality of abdominal ultrasound exams are significantly affected by obesity.  Fundamentally, an ultrasound image relies on acoustic propagation to a target, reflection, and then propagation back to the surface. The process of beamforming, which converts the surface measurement to an image, is sensitive to the low amplitude reflections from different tissue layers and tissue properties. Typically, the additional fat and connective tissue layers in obese patients can significantly degrade ultrasound image quality by introducing multi-path reverberation and phase aberration that obscure or distort these low amplitude reflections.  However, due to the computational complexity of describing ultrasound propagation and reflection in heterogeneous media, beamformers currently rely on simplified models that do not describe the propagation physics directly. We propose a generational leap in how we approach ultrasound beamforming by using physically and anatomically realistic wave propagation models and measurements that can effectively harness the power of data-driven and rapidly evolving machine learning beamformers. A custom highly realistic simulation tool that we have developed will use acoustical maps of the fine structures in the human body based on photographic cryosections. This physics-based approach will allow us to develop high quality training data and to understand the physical mechanisms for image quality improvement. These simulations will be calibrated to ex vivo and in vivo human data to subsequently generate a large data set that can be used to train a machine- learning-based real-time beamformer. We will focus on two sources of image degradation which we have identified to be particularly deleterious: multipath reverberation and aberration of the focusing profile. The proposed neural network beamformer filters incoherent noise, such as multi-path reverberation, and corrects aberration in the radiofrequency channel signals.  After training the beamformer and implementing it in real-time, a pilot human study in liver ultrasound imaging will be conducted to determine the improvement in image quality in high-body-mass index individuals, where diagnostic imaging is problematic due to image degradation. This technique is highly translatable to other clinical scenarios, varying from cardiac to transcranial to obstetric imaging, by changing the anatomical model. Furthermore, the physical concepts that will be extracted from the learned representation, can be used to improve the design process for ultrasound equipment, including transmit sequences, and transducers. RELEVANCE TO PUBLIC HEALTH Ultrasound beamforming, the process of transforming ultrasound into an image, is based on the principles of wave propagation which are complex due to the soft tissue structure in the human anatomy. Currently, ultrasound imaging uses simplified models of wave propagation. Here we address these limitations with physically and anatomically realistic propagation models based on the human anatomy that can effectively train and harness the power of machine learning beamformers. This technique directly addresses the principal challenge and objective of ultrasound beamforming, which is to limit unwanted acoustical effects from superficial tissue while maximizing signal from deep targets. The advancement of the proposed technology addresses the clear clinical need to provide diagnostic imaging to the growing population of body-limited imaging cases.",A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging,10130064,R01EB029419,"['3-Dimensional', 'Abdomen', 'Acoustics', 'Address', 'Affect', 'Anatomic Models', 'Anatomy', 'Back', 'Cardiac', 'Carotid Arteries', 'Characteristics', 'Clinical', 'Complex', 'Connective Tissue', 'Custom', 'Data', 'Data Set', 'Databases', 'Dependence', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of obstetrics', 'Effectiveness', 'Equipment', 'Fatty acid glycerol esters', 'Generations', 'Health', 'Healthcare', 'Human', 'Human body', 'Image', 'Individual', 'Left', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Measurement', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Noise', 'Obesity', 'Overweight', 'Patients', 'Phase', 'Physics', 'Population', 'Process', 'Property', 'Public Health', 'Resolution', 'Signal Transduction', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Transducers', 'Ultrasonic wave', 'Ultrasonography', 'United States', 'Weight', 'base', 'deep learning', 'design', 'health care quality', 'high body mass index', 'human data', 'human study', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo imaging', 'large datasets', 'learning strategy', 'liver imaging', 'neural network', 'obese patients', 'prototype', 'radio frequency', 'relating to nervous system', 'simulation', 'soft tissue', 'sound', 'tissue phantom', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,521287
"NeuroExplorer: Ultra-high Performance Human Brain PET Imager for Highly-resolved In Vivo Imaging of Neurochemistry Research applications of brain Positron Emission Tomography (PET) have been in place for over 40 years. The combination of quantitative PET systems with novel radiotracers has led to a numerous imaging para- digms to understand normal brain physiology including neurotransmitter dynamics and receptor pharmacology at rest and during activation. Brain-dedicated PET systems offer important advantages over currently available PET systems in terms of sensitivity and resolution. However, the state-of-the-art for brain PET has not progressed beyond the 20-year-old HRRT. Therefore, there is a compelling need to build the next generation of brain PET systems for human studies. This proposal brings together a highly experienced collaborative team from Yale, UC Davis, and United Imaging Healthcare America (UIHA). to develop the next generation NeuroEXPLORER (NX) PET system with the following Aims. Specific Aim 1: Design and Build the NeuroEXPLORER: In 2 years, we will complete the design and build the NX system. The design includes high performance LYSO-SiPM blocks with small detectors, 4-mm depth-of-interaction, 250 ps time-of-flight resolution, and axial length of ~50 cm, paired with CT for attenuation correction. This design will produce a factor of 10 greater effective sensitivity than the HRRT and practical resolution of 1.5-2 mm in the human brain. The system will include built-in real-time state-of-art motion tracking cameras and will be tested using novel phantom experiments to assess the full-range of operation to validate the dramatic improvement in small- region precision and accuracy. Specific Aim 2: Algorithm Development for Fully-Quantitative Brain PET. We will develop the novel algorithms for this system. Using EXPLORER experience. we will implement reconstruction algorithms to produce dynamic images with uniform ultra-high resolution in space and time, Extending Yale’s HRRT motion correction experience, we will develop camera-based motion detection and correction algorithms to deliver ultra-high resolution human brain images. Using the carotid artery shape and geometry, we will develop methods to accurately measure blood activity to be compared to human arterial data with the goal to permit kinetic modeling without arterial sampling. We will develop noise reduction methods with machine learning to reduce dose for studying health brains and to eliminate the need for the CT scan for attenuation correction. Specific Aim 3: Human Paradigm Demonstration. With human subjects, we will evaluate specific imaging paradigms to demonstrate the effectiveness of the NX system: 1) demonstration of the dramatic sensitivity increase (with a direct comparison to the HRRT) and its impact on detection of pharmacologic effects, 2) leveraging high sensitivity to reliably measure uptake in small nuclei; and 3) opening new frontiers of imaging neurotransmitter dynamics, including dopamine and opioid release. The ultimate goal is a fully functioning and characterized system that dramatically expands the scope of brain PET protocols and applications. Human research applications of brain Positron Emission Tomography (PET) imaging have been in place for over 40 years and have led to a detailed understand of normal brain physiology including neurotransmitter dynamics and receptor pharmacology at rest and during activation. Brain-dedicated PET systems offer important advantages over currently available PET systems, but the state-of-the-art for brain PET imaging systems has not progressed beyond the 20-year-old HRRT. The proposed next generation NeuroEXPLORER (NX) PET system will have a factor of 10 greater sensitivity and will dramatically expand the scope of human brain PET protocols and applications.",NeuroExplorer: Ultra-high Performance Human Brain PET Imager for Highly-resolved In Vivo Imaging of Neurochemistry,10261504,U01EB029811,"['20 year old', 'Adolescent', 'Algorithms', 'Americas', 'Area', 'Blood', 'Brain', 'Brain imaging', 'Brain scan', 'Carotid Arteries', 'Cell Nucleus', 'Child', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Disease', 'Dopamine', 'Dose', 'Effectiveness', 'Enzymes', 'Evaluation', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Healthcare', 'Hippocampus (Brain)', 'Human', 'Image', 'Inferior', 'Length', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Metabolism', 'Methods', 'Midbrain structure', 'Modeling', 'Motion', 'Nerve Degeneration', 'Neurotransmitters', 'Noise', 'Opioid', 'Performance', 'Pharmacology', 'Physics', 'Physiology', 'Positron-Emission Tomography', 'Proteins', 'Protocols documentation', 'Radioactive', 'Research', 'Resolution', 'Rest', 'Sampling', 'Sensory Receptors', 'Shapes', 'Structure', 'Substantia nigra structure', 'Synapses', 'System', 'Technology', 'Testing', 'Thalamic structure', 'Time', 'Tracer', 'X-Ray Computed Tomography', 'algorithm development', 'attenuation', 'base', 'body system', 'brain health', 'data quality', 'density', 'design', 'detector', 'experience', 'experimental study', 'frontier', 'human subject', 'imager', 'imaging system', 'improved', 'in vivo imaging', 'kinetic model', 'locus ceruleus structure', 'neurochemistry', 'neurotransmitter release', 'next generation', 'novel', 'operation', 'pre-clinical', 'radiotracer', 'raphe nuclei', 'receptor', 'reconstruction', 'solid state', 'statistics', 'ultra high resolution', 'uptake']",NIBIB,YALE UNIVERSITY,U01,2021,1700000
"Crossing space and time: uncovering the nonlinear dynamics of multimodal and multiscale brain activity The brain is a complex dynamical system, with a hierarchy of spatial and temporal scales ranging from microns and milliseconds to centimeters and years. Activity at any given scale contributes to activity at the scales above it and can influence activity at smaller scales. Thus a true understanding of the brain requires the ability to understand how each level contributes to the system as a whole. Most brain research focuses on a single scale (single unit firing, activity in a circuit), which cannot account for the constraints imposed by activities at other scales. The goal of this proposal is to develop a framework for the integration of multiscalar, multimodal measurements of brain activity. One of the challenges in understanding how activity translates across scales is that features that are relevant at one scale (e.g., firing rate) do not have clear analogues at other scales. We address this issue by defining trajectories in “state space” at each scale, where the state space is defined by parameters and time scales appropriate to each type of data. The trajectory of brain activity through state space can uncover features like attractor dynamics and limit cycles that characterize the evolution of activity. Using machine learning along with new and existing multimodal measurements of brain activity (MRI, optical, and electrophysiological), we propose to establish methods that relate trajectories across scales while handling the mismatch in temporal sampling rates inherent in multi-scale data. Specific aims are 1. Create and test a tool for learning how trajectories at fast scales influence activity at slower scales. Different modalities have different inherent temporal resolutions in addition to different types of contrast. Current methods generally downsample the faster modality in some way, losing much information in the process. We will leverage variants on long short-term memory (LSTM) network architectures to learn the relationship between state space trajectories acquired simultaneously with population recording and optical imaging, and with optical imaging and fMRI. 2. Create and test a tool for learning how trajectories at slow scales influence activity at faster scales. Leveraging the same LSTM-based approach, we will learn how slower, larger scale activity affects activity at smaller scales, using whisker stimulation as a test case. We anticipate inclusion of the large scale activity (measured with fMRI or optical imaging) will improve prediction of the response at smaller scales (measured with optical imaging or population recording). Our work will allow us to begin to answer a wide range of questions about how the brain functions (e.g., what type of localized stimulation that will drive the brain to a desired global state? How does modulation of the global brain state affect local information processing?) and provide guidance for future experiments by identifying key features that influence activity across scales. By approaching the whole brain as a complex dynamical system, we will break free from the limitations of previous studies that focus on individual cells or circuits. We also expect our work to stimulate new theories that incorporate multiple scales of activity. The brain is a complex, dynamical system that exhibits structured activity at many different space and time scales. Most existing studies focus on a single scale (for example, spiking of individual neurons or activity in a particular circuit). However, interactions occur across scales and may account for much of the variability observed in the brain. This proposal will develop a framework for integrating data from different scales using machine learning tools. The results will improve our understanding of how the brain functions and serve as a foundation for modeling neuromodulatory treatments for brain disorders.",Crossing space and time: uncovering the nonlinear dynamics of multimodal and multiscale brain activity,10353118,R01EB029857,"['Address', 'Affect', 'Brain', 'Brain Diseases', 'Cells', 'Complex', 'Data', 'Electrophysiology (science)', 'Evolution', 'Exhibits', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Individual', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Neurons', 'Nonlinear Dynamics', 'Optics', 'Population', 'Process', 'Sampling', 'Structure', 'System', 'Testing', 'Time', 'Translating', 'Variant', 'Vibrissae', 'Work', 'analog', 'base', 'brain research', 'dynamic system', 'experimental study', 'improved', 'information processing', 'long short term memory', 'long short term memory network', 'millisecond', 'multimodality', 'multiscale data', 'network architecture', 'neuroregulation', 'optical imaging', 'predicting response', 'temporal measurement', 'theories', 'tool']",NIBIB,EMORY UNIVERSITY,R01,2021,131945
"A comprehensive deep learning framework for MRI reconstruction PROJECT SUMMARY/ABSTRACT The primary goal of this investigation is to develop and validate a comprehensive, robust deep learning (DL) framework that improves MRI reconstruction beyond the limits of existing technology. The proposed framework uses “plug-and-play” algorithms to combine physics-driven MR acquisition models with state-of-the-art learned image models, which are instantiated by image denoising subroutines. To fully exploit the rich structure of MR images, we propose to use DL-based denoisers that are trained in an application-speciﬁc manner. The proposed framework, termed PnP-DL, offers advantages over other existing DL methods, as well as compressed sensing (CS). Compared to existing DL methods for MRI reconstruction, PnP-DL is more immune to inevitable variations in the forward model, such as changes in the coil sensitivities or undersampling pattern, allowing it to generalize across applications and acquisition settings. Compared to CS, PnP-DL recovers images faster, with higher quality, and with potentially superior diagnostic value. Our preliminary results highlight the potential of PnP-DL to advance MRI technology. In this work, we will fur- ther develop PnP-DL and validate it in these major applications: cardiac cine, 2D brain, and 3D brain imaging. In Aim 1, we will train and optimize convolutional neural network-based application-speciﬁc denoisers for the above-mentioned applications. The denoiser with the best denoising performance will be selected for further investigation. In Aim 2, we will develop and compare different PnP algorithms. The algorithm yielding the best combination of reconstruction accuracy and computational speed will be implemented in Gadgetron for inline processing. In Aim 3, we will compare the performance of PnP-DL to other state-of-the-art methods using retro- spectively undersampled data. This study will demonstrate that, in terms of image quality, PnP-DL is superior to CS and existing DL methods and, despite higher acceleration, is non-inferior to parallel MRI with rate-2 acceler- ation. In Aim 4, we will evaluate the performance of PnP-DL using prospectively undersampled data from adult and pediatric patients. Successful completion of this project will demonstrate that PnP-DL outperforms state- of-the-art methods in terms of image quality while exhibiting a level of robustness and broad applicability that has eluded other DL-based MRI reconstruction methods. The acceleration and image quality improvement afforded by these developments will beneﬁt almost all MRI applications, including pediatric imaging, where reducing sedation is a pressing need, and high-dimensional imaging applications (e.g., whole-heart 4D ﬂow imaging), which are too slow for routine clinical use. PROJECT NARRATIVE Magnetic Resonance Imaging (MRI) has many advantages over other imaging methods, but MRI is slow. Addi- tional developments are required to shorten the scan time, improve patient comfort, reduce the use of sedation for imaging children, and improve image quality. In this project, we will develop faster and more accurate methods for MRI. These efforts should lead to signiﬁcant improvements in the diagnosis of different diseases, so that patients may beneﬁt from appropriate treatment.",A comprehensive deep learning framework for MRI reconstruction,10211757,R01EB029957,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adoption', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Architecture', 'Awareness', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Breathing', 'Cardiac', 'Child', 'Childhood', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Exhibits', 'Formulation', 'Goals', 'Headache', 'Heart', 'Heart Diseases', 'Image', 'Imaging Device', 'Imaging technology', 'Immune', 'Investigation', 'Lead', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Motion', 'Network-based', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physics', 'Play', 'Predisposition', 'Process', 'Pythons', 'Recovery', 'Rest', 'Sampling', 'Scanning', 'Sedation procedure', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'computer framework', 'convolutional neural network', 'cost', 'data acquisition', 'data space', 'deep learning', 'denoising', 'design', 'heart imaging', 'high dimensionality', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'musculoskeletal imaging', 'neural network architecture', 'novel', 'pediatric patients', 'prospective', 'real-time images', 'reconstruction', 'repository']",NIBIB,OHIO STATE UNIVERSITY,R01,2021,613825
"Center for Mesoscale Mapping Overview of the Proposed Resource – Abstract The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings. While there is still no formal consensus on the definition of mesoscopic within the neuroscience community, we take as our guide the spatial and temporal scales at which local groups of neurons act in coherent fashion – in the cortex, this includes the spatial scale of columns and laminar structures (between ~0.1-1 mm), while in deeper structures includes the myriad of deep brain and brainstem nuclei. Preliminary data from our own center, and of course others throughout the world, now support the notion that we are on the threshold of being able to map, measure and perturb the human brain at these scales, and do so comprehensively across wide swaths of the human brain. Temporally too, recent advances suggest a convergence between temporal scales addressable with tools like fMRI, which can now investigate delta frequency coherent phenomena, and advanced electromagnetic tools to measure and perturb coherent electrophysiological activity at higher frequencies still. With this convergence in mind, the tools we proposed to develop within the TRDs of the CMM will provide our Collaborative and Service User community with the important “missing links” between the advances in human cognitive neuroscience at the “system level,” and the enormous strides in cellular level circuit functional characterization. Our Collaborators will bring their own unique challenges to help us define and further refine these tools, offering problems requiring distinct measures of human brain structural and functional properties in a variety of normal and disease settings. Our Service Users will utilize our tools to better understand human neural systems, and particularly human disease states from multiple sclerosis to Alzheimer’s, to depression and epilepsy. Finally, our Center will seek to disseminate these tools, through open-source software and hardware designs, industrial partnerships and “hands-on” teaching courses for hardware, and to train a new generation of human neuroscientists in the use of our advanced tools to explore the human brain at this next frontier. Overview of the Proposed Resource – Narrative The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings.",Center for Mesoscale Mapping,10224848,P41EB030006,"['3-Dimensional', 'Acceleration', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Basic Science', 'Biological', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cerebral Palsy', 'Communities', 'Computer Models', 'Computer software', 'Consensus', 'Data', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electrophysiology (science)', 'Epilepsy', 'Evaluation', 'Event', 'Fiber', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Histologic', 'Human', 'Image', 'Investigation', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Mental Depression', 'Mental disorders', 'Microscopic', 'Mind', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Motion', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Online Systems', 'Performance', 'Peripheral Nerve Stimulation', 'Property', 'Publications', 'Research Personnel', 'Resolution', 'Resources', 'Respiration', 'Scanning', 'Services', 'Signal Transduction', 'Sleep Disorders', 'Slice', 'Space Models', 'Spatial Distribution', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training Programs', 'Transcranial magnetic stimulation', 'Visualization', 'Work', 'base', 'cognitive neuroscience', 'data space', 'deep learning', 'design', 'electric field', 'frontier', 'human disease', 'human imaging', 'improved', 'in vivo', 'industry partner', 'instrumentation', 'machine learning algorithm', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'post-doctoral training', 'pre-doctoral', 'reconstruction', 'relating to nervous system', 'response', 'spatiotemporal', 'tool', 'tool development', 'translational neuroscience', 'usability', 'white matter']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,P41,2021,1234408
"Advanced Image Analysis Tools for Super-Resolved MRI in Small Animals SUMMARY Imaging in animal models plays a key role in biomedical research, enabling both foundational studies for understanding disease processes, as well as translational studies evaluating novel therapies. In vivo imaging, in particular, offers the benefits of minimal harm to the animal and opportunities for measuring developmental, longitudinal changes. Magnetic resonance imaging (MRI) is one of the most extensively used in vivo imaging modalities because of its excellent sensitivity to a multitude of biological parameters and flexibility with different animal models, such as rodents, ferrets, and non-human primates. MRI has been used not only to advance understanding of neurodegenerative diseases, but also aging, cancer, addiction, and cardiovascular disorders. However, despite the research community’s desire for emulating clinical trials and performing high-throughput studies, automated analysis of MRI in animal models has significantly lagged state-of-the-art tools that are available in the analysis of human imaging. A major reason is that most animal MRI acquisitions are two- dimensional with high in-plane resolution but thick slices, whereas the most powerful image analysis tools work best on isotropic acquisitions. As a result, many researchers have been resigned to performing analyses involving laborious, manual delineations. Our team has recently developed a novel algorithm that uses deep learning to extract isotropic spatial resolution from a standard anisotropic MRI acquisition possessing without the need for external high-resolution training data, which is typically unavailable and difficult to procure. The ability to retrospectively recover isotropic spatial resolution from these two-dimensional MRI acquisitions allows for significantly reduced costs compared to high- resolution isotropic acquisitions. Moreover, it opens up the possibilities for more advanced analyses by enabling key image processing algorithms, such as registration and segmentation, to be more accurately performed and with greater automation. We therefore propose to perform the following Specific Aims in this R21 application: 1) Optimize and evaluate our deep learning-based unsupervised super-resolution approach for animal MRI; 2) Develop and evaluate a super-resolution algorithm for higher-dimensional data; 3) Publicly release the developed tools. Our overarching hypothesis is that the provided tools will enable significantly more sensitive imaging biomarkers, thereby increasing statistical power and reducing the size and cost of animal studies. The combination of the proposed resolution enhancement with state-of-the-art techniques for image analysis will also increase reproducibility by obviating the need for laborious, and potentially inconsistent manual delineations. Furthermore, these efforts will enable both pre-clinical and clinical trials to be implemented with nearly identical analysis pipelines. This application is being submitted in response to PAR 19-369, “Development of Animal Models and Related Biological Materials for Research.” NARRATIVE Animal models are critical for developing new therapies and improving the understanding of a wide variety of diseases such as cancer, traumatic brain injury, and Alzheimer’s disease. Although magnetic resonance imaging enables monitoring of disease progression in animals, computational tools for extracting imaging biomarkers have lagged behind state-of-the-art tools available for clinical data, often because of limitations in spatial resolution. This project will develop and publicly release novel tools for improving the spatial resolution in animal images, leading to more robust, automated image analyses that will improve translation of animal studies to humans.",Advanced Image Analysis Tools for Super-Resolved MRI in Small Animals,10303505,R21OD030163,"['4D MRI', 'Adoption', 'Aging', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Automation', 'Biocompatible Materials', 'Biological', 'Biomedical Research', 'Brain scan', 'Cardiovascular Diseases', 'Clinical Data', 'Clinical Trials', 'Communities', 'Data', 'Development', 'Disease', 'Disease Progression', 'Ensure', 'Feedback', 'Ferrets', 'Foundations', 'Four-dimensional', 'Future', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Masks', 'Measures', 'Modeling', 'Monitor', 'Mus', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Play', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'Scanning', 'Slice', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Translations', 'Traumatic Brain Injury', 'Work', 'analysis pipeline', 'animal imaging', 'animal model development', 'automated analysis', 'automated image analysis', 'base', 'cancer addiction', 'computerized tools', 'cost', 'deep learning', 'design', 'diffusion weighted', 'flexibility', 'heart imaging', 'human data', 'human imaging', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'in vivo imaging', 'interest', 'machine learning algorithm', 'multidimensional data', 'nonhuman primate', 'novel', 'novel therapeutics', 'preclinical trial', 'response', 'tool', 'translational study', 'two-dimensional', 'usability', 'validation studies', 'web site']",OD,HENRY M. JACKSON FDN FOR THE ADV MIL/MED,R21,2021,218013
"Machine learning approach to non-invasive MRI-based blood oximetry PROJECT SUMMARY Measurement of blood oxygen (O2) saturation, the fraction of oxygen-saturated hemoglobin in blood, provides information on whole-body and organ-specific O2 delivery and consumption and is used to guide therapy and intervention. Blood sampling and analysis by invasive catheterization performed under X-ray fluoroscopic guidance is the standard method used to measure O2 saturation in multiple anatomical locations in the cardiac chambers and major blood vessels. Non-invasive measurement of O2 saturation using magnetic resonance (MR) imaging was first proposed nearly 30 years ago; however, previous techniques have relied on fitting the Luz- Meiboom model and other model variants using traditional linear and non-linear regression model approaches. Although the model captures the basic underlying biophysical principles, it does not fully characterize the complex relationship between blood O2 saturation and the MR signal. Despite being a non-invasive, non- radiating alternative to invasive catheterization, the low accuracy of MR oximetry, due to inadequacy of the model as well as estimation methods, have prevented the technique from gaining clinical acceptance. We propose to overcome this critical limitation by meeting our overall objective; to deploy a model-free approach based on machine learning (ML) to develop and implement an accurate, clinically feasible, MR oximetry technique. We hypothesize that ML algorithms provide greater flexibility in parameter estimation than traditional methods, and can be trained to learn and map the true in vivo relationship that describes the sensitivity of MR blood signal to O2 saturation. We intend to achieve our objective through the following specific aims. In Aim 1, we will develop a supervised ML algorithm for MR oximetry. Pre-training will occur with training data simulated using the L-M model and then augmented with in vivo data via transfer learning. Simultaneously, in Aim 2, we will design and implement a 3D MR oximetry method for volumetric data acquisition. A volumetric map will facilitate O2 saturation measurement throughout the vascular system, and will support the combination with 4D flow to evaluate O2 delivery and consumption. In Aim 3, we will validate the proposed ML-based 3D MR oximetry technique in a small cohort of patients referred for catheter-based O2 saturation measurement. For the first time, our proposed work will apply machine learning to accurately characterize the in vivo sensitivity of the transverse relaxation time (T2) weighted MR blood signal to O2 saturation, using a unique combination of simulated and in vivo training data. ML-based MR oximetry will provide the accuracy of measurement required for clinical use, and therefore will be able to replace or reduce the frequency and duration of an invasive, radiation-based method with a safe, non-invasive alternative. ML-based MR oximetry as an imaging tool is expected to significantly improve the diagnostic value of an MR exam, and will be especially valuable in the management of patients with congenital heart disease. Our work thus aligns with the mission of NIBIB to have a positive impact on human health with the development of novel technology. PROJECT NARRATIVE The proposed work is relevant to public health because it will lead to a non-invasive, non-radiating biomedical technology to measure blood oxygen saturation at multiple locations within the heart and other blood vessels as an alternative to invasive catheterization. The project aligns with NIBIB’s goal to improve disease detection and management as this is the first application of machine learning to refine a novel 3D volumetric magnetic resonance technique to accurately determine oxygen saturation in the blood. This will significantly enhance the capabilities of MRI to provide comprehensive disease diagnosis and assessment.",Machine learning approach to non-invasive MRI-based blood oximetry,10217710,R21EB030294,"['3-Dimensional', 'Adult', 'Age', 'Anatomy', 'Biomedical Technology', 'Biophysics', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood flow', 'Blood specimen', 'Cardiac', 'Catheterization', 'Catheters', 'Cerebrum', 'Clinical', 'Clinical Management', 'Collaborations', 'Complex', 'Congenital Cardiovascular Abnormality', 'Consumption', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Fetus', 'Fingers', 'Frequencies', 'Funding', 'Goals', 'Health', 'Heart', 'Heart Abnormalities', 'Heart failure', 'Hemoglobin', 'Human', 'Image', 'Imaging Device', 'Institution', 'Intervention', 'Kidney', 'Learning', 'Limb structure', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Morphology', 'National Institute of Biomedical Imaging and Bioengineering', 'Nature', 'Network-based', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Oxygen', 'Oxygen saturation measurement', 'Patients', 'Pediatric Hospitals', 'Peripheral', 'Physiologic pulse', 'Physiology', 'Procedures', 'Process', 'Property', 'Psychological Transfer', 'Public Health', 'Pulmonary Hypertension', 'Pulmonary vessels', 'Radiation', 'Radiation exposure', 'Relaxation', 'Risk', 'Roentgen Rays', 'Salvelinus', 'Scanning', 'Signal Transduction', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Vascular System', 'Venous', 'Work', 'base', 'cerebrovascular', 'clinical application', 'clinical practice', 'cohort', 'congenital heart disorder', 'data acquisition', 'design', 'diagnostic catheterization', 'disease diagnosis', 'feedforward neural network', 'flexibility', 'imaging capabilities', 'improved', 'in vivo', 'individual patient', 'interest', 'limb ischemia', 'machine learning algorithm', 'machine learning method', 'meetings', 'neonate', 'neural network', 'new technology', 'nonlinear regression', 'novel', 'post-transplant', 'prevent', 'supervised learning', 'tool']",NIBIB,OHIO STATE UNIVERSITY,R21,2021,587783
"Prism-PET: A TOF-DOI-Compton PET detector technology for total-body PET imaging Abstract  The relatively small axial field-of-view (FOV) in almost all PET scanners has severely limited their sensitivity and resulted in significant tradeoffs between image signal-to-noise ratio (SNR), acquisition time, and delivered dose. The solution is to improve geometric coverage using large axial FOV for total-body imaging which has the potential to improve sensitivity by about 40 times compared to existing commercial whole-body PET scanners. The construction of the world's first total-body PET/CT scan-ner, called EXPLORER, with 194-cm axial FOV has recently been completed. However, it has a poor time-of-flight (TOF) resolution of 430 ps, compared to the state-of-the-art whole-body PET scanner with 200 ps timing resolution (Siemens Biograph Vision). In addition, axial detector penetration of obliquely incident gamma photons detected within this wide acceptance angle will introduce significant depth-of-interaction (DOI) parallax error, leading to degraded spatial resolution. These two major defi-ciencies of the EXPLORER scanner offset its effective sensitivity gain, specially for imaging single organs such as the human brain when compared to the Biograph Vision PET scanner. For this research, we propose to build cost-effective block detectors with combined highest spatial resolution (2 mm), highest TOF resolution (<120 ps and potentially 100 ps), best DOI localization (1.85 mm), and highest inter- crystal Compton scatter recovery capabilities (88%) using single-ended readout and machine learning post-processing engines. Our novel detector module, called Prism-PET, enables these capabilities by mimicking very closely the behavior of dual-ended readout with enhanced and controlled light sharing using a segmented array of right angle prism-mirror light guides. Given our promising preliminary ex-perimental results, we aim to accomplish the following tasks: (1) model a prototype TOF-DOI PET scanner using GATE Monte Carlo simulations and use its list-mode data to develop our TOF-DOI image recontruction; (2) build Prism-PET detector modules and characterize coincidence detector blocks for DOI-corrected spatial resolution, energy resolution, and timing resolution and use machine learning to recover inter-crystal Compton scattered events to reach the 2-mm intrinsic spatial resolution without sacrificing sensitivity; (3) Build a one-ring prototype Prism-PET scanner; (4) perform normalization scan, optimize our image reconstruction using experimental coincidence events and validate the optimal imaging performance using Hot Spot phantoms. Our proposed TOF-DOI-Compton detector and system technologies maximize the sensitivity benefits of improved geometric coverage in total-body PET scanners across the entire FOV. Narratives/Relevance  The EXPLORER total-body PET scanner has limitations due to its poor timing resolution and lack of DOI-encoding, both of which offset its effective sensitivity gain, specially for imaging single organs, despite the very costly improvement of its geometric coverage. In the proposed work we will develop cost-effective and practical single-ended TOF-DOI-Compton PET detector modules, where these capabilities are enabled by using our novel right an-gle prism mirror light guides which enhance (1) light sharing by efficient 180-degree bending of photon paths and (2) crystal identification by localiz-ing the shared photons to only those immediate neighboring pixels that help with the correct identification. Our Prism-PET scanner with < 120 ps timing resolution, 1.85 mm DOI-encoding, and 88% Compton-scatter recovery miti-gates the limitations with the EXPLORER total-body scanner and achieves unparalleled spatial resolution and sensitivity.",Prism-PET: A TOF-DOI-Compton PET detector technology for total-body PET imaging,10233306,R01EB030413,"['Architecture', 'Behavior', 'Brain', 'Caliber', 'Calibration', 'Collaborations', 'Compton radiation', 'Computer software', 'Coupled', 'Coupling', 'Crystallization', 'Custom', 'Data', 'Detection', 'Dose', 'Electronics', 'Elements', 'Event', 'Floods', 'Geometry', 'Goals', 'Hot Spot', 'Human', 'Image', 'Imaging Phantoms', 'Industrialization', 'Length', 'Light', 'Location', 'Machine Learning', 'Modeling', 'Monte Carlo Method', 'Noise', 'Optics', 'Organ', 'PET/CT scan', 'Pattern', 'Penetration', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Radiation Tolerance', 'Recovery', 'Research', 'Resolution', 'Rotation', 'Scanning', 'Signal Transduction', 'Silicon', 'Source', 'Supervision', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Vision', 'Work', 'convolutional neural network', 'cost', 'cost effective', 'detector', 'image reconstruction', 'improved', 'novel', 'performance tests', 'photomultiplier', 'prototype', 'reconstruction', 'response', 'risk mitigation', 'simulation']",NIBIB,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2021,647165
"Ultrasound-based sensors for the fusion and motion correction of MRI and PET/CT data Project summary Radiology departments are equipped with many different types of medical imaging scanners, such as Magnetic Resonance Imaging (MRI), Positron Emission Tomography (PET), Computed Tomography (CT), X-ray, ultrasound imaging (USI) and Single-Photon Emission Computed Tomography (SPECT), among others. Clearly, none of these modalities is ideal; otherwise, there would be no rationale for anybody to purchase any others. Each modality is characterized by its own contrast mechanism and provides its own type of information.  An ideal scanner might be defined here as one that could provide any of these contrasts, whose hardware would include that required for all of the main scanning techniques, whereby one could simply select the desired scan type, e.g., MRI+CT+USI, and proceed. Clearly, in practice, such an ideal scanner would be quite impractical. Hardware components associated with each modality would compete for the small amount of space available around the patient and these components would interfere in ways that might seriously impede their functioning. Even if such technical problems could be solved, complexity would likely drive cost to prohibitive heights. A more realistic multi-modality strategy is to perform scans sequentially, on different physical scanners, and to fuse images afterward, mostly through software. Exceptions include hybrid scanners such as PET/CT, which are widespread, and PET/MRI, which are available but uncommon. The fact that both involve PET is not a coincidence, but rather a testimony to the fact that PET may well currently be the best available tool for diagnosing/staging cancer, and that it further requires good anatomical images such as those provided by CT or MRI for proper attenuation correction maps to be calculated.  In particular, PET/MRI scanners are true masterpieces of engineering. The two combined modalities prove especially useful in the fields of cancer detection/staging and neuroscience. Arguably, the main problem with these scanners may be that they are rare and very expensive, two problems that are not unrelated of course. Masterpieces of engineering may demand respect but they also tend to demand a high price; in contrast, the present project represents a practical and low-cost approach to multi-modality imaging. For the same reasons that drove vendors to develop PET/MRI scanners, because both modalities are so powerful in their own rights yet so complementary as well, we focus here on combining PET and MRI acquisitions. But the proposed work is not limited to these two scan types, and in the future it might well prove generalizable to any combination of sequential scans from any imaging modalities and/or radiation therapy devices. It is based on the developments of ultrasound-based sensors that can be attached to the patient's skin and accompany him/her through sequential scans, acting as a common thread across modalities. Fifty-four patients scheduled for a clinical PET/CT scan will be recruited to validate the proposed technology, and half of them will be scanned by MRI as well. Project narrative Positron Emission Tomography (PET) and Magnetic Resonance Imaging (MRI) scanners provide different and complementary diagnostic information; while PET/MRI systems combine both technologies into a same physical scanner, such multi-modality scanners tend to be very expensive and not widely available. A small, low-cost ultrasound-based sensor that attaches to the skin is proposed here that can act as a common thread between sequentially-performed PET and MRI scans, allowing data from separate scanners to be combined and fused in effect as if they had come from a single multi-modality scanner.",Ultrasound-based sensors for the fusion and motion correction of MRI and PET/CT data,10092861,R01EB030470,"['Address', 'Adoption', 'Anatomy', 'Attenuated', 'Award', 'Breathing', 'Cancer Detection', 'Clinical', 'Code', 'Complex', 'Computer software', 'Curved Tube', 'Data', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Discipline of Nuclear Medicine', 'Disease', 'Electrons', 'Emission-Computed Tomography', 'Engineering', 'Feedback', 'Future', 'Gamma Rays', 'Health', 'Hybrids', 'Image', 'Link', 'Localized Disease', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Medical Imaging', 'Metals', 'Methods', 'Modality', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Organ', 'Patient Schedules', 'Patients', 'Positron-Emission Tomography', 'Price', 'Publishing', 'Radiation therapy', 'Radiology Specialty', 'Research Personnel', 'Rights', 'Roentgen Rays', 'Scanning', 'Signal Transduction', 'Skin', 'Source', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Ultrasonography', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'attenuation', 'base', 'contrast imaging', 'cost', 'data streams', 'design', 'image registration', 'imaging modality', 'imaging system', 'improved', 'machine learning algorithm', 'magnetic field', 'man', 'motion sensor', 'multimodality', 'prototype', 'recruit', 'respiratory', 'sensor', 'sensor technology', 'single photon emission computed tomography', 'sound', 'tool']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,1342160
"Real-time spectroscopic photoacoustic/ultrasound (PAUS) scanner withsimultaneous fluence and motion compensation to guide and validateinterventions: system development and preclinical testing. Abstract The goal of this project is to develop a clinical real-time spectroscopic photoacoustic/ultrasound (PAUS) system for molecular guidance of interventional procedures through a partnership between UW and GE Research. Recently, we proposed a new, fast-sweep concept for PA imaging. To put this concept into practice, we first developed a unique, compact, diode-pumped, tunable (700 -900 nm) laser operating at very high (up to 1000 Hz) repetition rates and relatively low (~ 1 mJ) pulse energies, and a fiber-optic delivery system to sequentially couple laser pulses into the imaging probe. In addition to US B-mode, and all other US modes, the system simultaneously produces real-time (50 Hz) spectroscopic PA images, which were combined for the first time for real-time PAUS imaging. A unique feature is automatic on-line laser-fluence compensation and motion correction, enabling quantitative optical absorption spectroscopy at every image pixel. Spectroscopy can identify substances opaque to US based on their molecular constituents (drugs/contrast agents), and quantify tissue functional changes (e.g., blood oxygenation and its concentration) within the image; in addition, manipulation with a needle is better visualized with PA. UW will work with GE Research to integrate spectroscopic PAUS into a high-end US scanner to create a clinical-grade PAUS system, and test whether it can improve interventional procedure guidance in general and, particularly, in ethanol (EA) ablation therapies of recurrent thyroid tumors. The prognosis for most people with thyroid cancer after primary treatment is very good, but the recurrence rate or persistence can be up to 30%. If recurrent cancer is confirmed, image-guided nonsurgical procedures such as EA or radio frequency ablation (RFA) are commonly used alternatives to more invasive procedures. Although US helps position EA and RFA needles, on-line imaging of the ablative area and confirmation of ablation remain difficult for US. When the recurrent nodule (especially the capillary network in it) is not entirely treated, the cancer will return with possible metastasis. We hypothesize here that real-time spectroscopic PAUS will improve the efficacy of ablation procedures and dramatically reduce procedure repetitions. If successful in this initial stage, the project will move to a clinical trial to both guide and validate ablative therapies and explore real-time spectroscopic PAUS for other interventional procedures. SA1 will integrate our unique laser and scanning fiber-optic delivery system with a clinical GE US scanner for real-time spectroscopic PAUS. Then, SA2 will develop real-time signal processing tools for motion correction and fluence compensation and imaging protocols for spectroscopic PAUS. SA3 will focus on optimizing the PAUS system using phantom and ex vivo studies. Finally, in SA4 the developed PAUS system will be used to test the clinical applicability of PAUS guidance with three in vivo models, including small animal studies of thyroid cancer, an animal model approximating human anatomy, and pilot measurements on human subjects. Real-time spectroscopic photoacoustic/ultrasound (PAUS) scanner with simultaneous fluence and motion compensation to guide and validate interventions: system development and preclinical testing Narrative Real-time ultrasound (US) is commonly used to guide interventional procedures, but for injections of therapeutic agents such as ethanol, the drug itself cannot be directly visualized. Photoacoustics (PA), combining pulsed light delivery to the body with US detection of light absorbing structures within the body, has been proposed to bring a molecular dimension to US to help view molecular substances such as drugs, but its clinical translation has been greatly limited by both fundamental issues related to tissue motion and wavelength-dependent light intensity variations within the body and practical issues related to the size, speed, and expense of the laser systems typically used for imaging. Here we present a completely new approach integrating PA and US (PAUS) imaging to directly address both fundamental and practical issues limiting clinical translation, and will test it by developing and evaluating a clinical real-time PAUS system as a robust molecular guidance tool for interventional procedures.",Real-time spectroscopic photoacoustic/ultrasound (PAUS) scanner withsimultaneous fluence and motion compensation to guide and validateinterventions: system development and preclinical testing.,10295522,R01EB030484,"['Ablation', 'Address', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Area', 'Blood', 'Blood capillaries', 'Canis familiaris', 'Characteristics', 'Clinical', 'Clinical Trials', 'Coagulative necrosis', 'Color', 'Contrast Media', 'Coupling', 'Detection', 'Devices', 'Dimensions', 'Ethanol', 'External Beam Radiation Therapy', 'Fiber', 'Fiber Optics', 'Financial compensation', 'Goals', 'Human', 'Image', 'Image Enhancement', 'Injection of therapeutic agent', 'Injections', 'Intervention', 'Lasers', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Methods', 'Microbubbles', 'Modality', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Needles', 'Neoplasm Metastasis', 'Nodule', 'Operative Surgical Procedures', 'Optics', 'Papillary thyroid carcinoma', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Pilot Projects', 'Positioning Attribute', 'Preclinical Testing', 'Procedures', 'Prognosis', 'Protocols documentation', 'Pump', 'Radiofrequency Interstitial Ablation', 'Recurrence', 'Recurrent Malignant Neoplasm', 'Reporting', 'Research', 'Scanning', 'Spectrum Analysis', 'Speed', 'Structure', 'System', 'Systems Development', 'Testing', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'Universities', 'Variant', 'Washington', 'Work', 'absorption', 'base', 'clinical application', 'clinical translation', 'drug distribution', 'efficacy validation', 'experimental study', 'flexibility', 'high risk', 'histological studies', 'human subject', 'image guided', 'imaging capabilities', 'imaging probe', 'improved', 'in vivo Model', 'industry partner', 'light intensity', 'molecular decomposition', 'novel strategies', 'photoacoustic imaging', 'reconstruction', 'signal processing', 'skills', 'soft tissue', 'spectroscopic imaging', 'surgical risk', 'thyroid neoplasm', 'tool', 'tumor']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2021,747636
"Patient-specific, high-sensitivity spectral CT for assessment of pancreatic cancer Abstract. The proposed project concentrates on technology developments to enable high sensitivity, bias-tolerant spectral CT for accurate quantitation of iodine concentration. Spectral CT has the potential of providing true quantitative information of tissue composition and provides an avenue for combined functional and structural imaging. High- sensitivity spectral CT accommodates anatomical sites that are traditionally hard to image, and reliable meas- urements of iodine perfusion allow additional quantitative measures such as tissue texture to aid diagnosis and clinical decision making. In the case of pancreatic cancer, the complex tumor microenvironment and the conse- quential poor perfusion characteristics lead to difficulty in diagnosis, staging, and treatment assessment. The need for visualizing low-enhancing lesions and the benefit of extracting quantitative information directly from image data strongly motivate a high-sensitivity imaging modality for reproducible iodine measurements. The need for visualizing low-enhancing lesions and the benefit of extracting quantitative information directly from image data strongly motivate a high-sensitivity imaging modality for reproducible iodine measurements. How- ever, state-of-the-art spectral CT presents large quantitation bias, i.e., inaccuracies in measured iodine concen- tration compared to the truth. We identify three major sources that contribute to quantitation bias: imaging system (e.g., spectrum mismatch), post-processing (e.g., biased estimator), and patient (scatter, beam hardening). The bias effect in current spectral CT cannot be fully eliminated by increasing radiation exposure, and has complex dependencies on the imaging system, imaging techniques, patient habitus, and processing algorithms. This in- accuracy is a major impediment to pancreatic cancer management and quantitative applications in general. The overall goal of this proposal is to develop robust, high-sensitivity spectral CT solutions that will enhance sensi- tivity and reduce variability in iodine quantitation, which in turn enables accurate, high-performance spectral biomarkers for disease management. The following specific aims will be pursued: (1) to develop an end-to-end, modular theoretical model for robust spectral CT design and optimization, (2) to develop bias-tolerant processing pipeline, and (3) to implement and evaluate high performance, hybrid spectral CT solutions on an experimental CT bench. Completion of the proposed efforts enables robust, high sensitivity spectral CT for improved tumor detection and characterization through accurate, high performance spectral biomarkers. Vendor- and spectral technology-independent outcomes of the proposal include: optimized, patient-specific protocols; post-processing pipelines that are robust against quantitative bias and variability; and the next generation spectral CT system designs for enhanced iodine quantitation. Achievements from the proposed project will improve sensitivity and quantitation accuracy of iodinated contrast media in spectral CT which enables quantitative diagnostics and treatment assessment using robust iodine biomarkers across a broad range of clinical applications. Public Health Relevance. Diagnosis, staging, and treatment assessment of pancreatic cancer is severely challenged by the difficulty to delineate and reproducibly measure pancreatic lesions as a result of low-enhancement from contrast agents. We propose to develop high-sensitivity, low-bias spectral CT technology to enhance low concentration iodine visualization and mitigate system-dependent variability to allow quantitative image biomarkers as additional in- dicators for diagnosis and treatment efficacy. The technology developed in this work can be widely applied to improve quantitative accuracy of spectral CT applications, and facilitate robust clinical translation of novel spec- tral biomarkers for general disease management.","Patient-specific, high-sensitivity spectral CT for assessment of pancreatic cancer",10296757,R01EB030494,"['3D Print', 'Achievement', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Biological Products', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Complement', 'Complex', 'Computed Tomography Scanners', 'Computer software', 'Contrast Media', 'Data', 'Dependence', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Enhancing Lesion', 'Evaluation', 'Functional Imaging', 'Goals', 'Hybrids', 'Image', 'Imaging Techniques', 'Iodine', 'Joints', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Malignant neoplasm of pancreas', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Noise', 'Organ', 'Outcome', 'Pancreas', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Physics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility', 'Roentgen Rays', 'Selection Bias', 'Shapes', 'Source', 'Staging', 'Structure', 'System', 'Technology', 'Texture', 'Theoretical model', 'Tissues', 'Treatment Efficacy', 'Tweens', 'Vendor', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical application', 'clinical decision-making', 'clinical translation', 'contrast enhanced', 'denoising', 'design', 'detector', 'fluorodeoxyglucose positron emission tomography', 'imaging approach', 'imaging biomarker', 'imaging modality', 'imaging system', 'improved', 'intelligent algorithm', 'next generation', 'novel', 'novel therapeutics', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'response', 'spectrograph', 'technology development', 'tumor', 'tumor microenvironment']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2021,643028
"Deformable motion compensation for 3D image-guided interventional radiology PROJECT SUMMARY / ABSTRACT C-arm cone-beam CT (CBCT) plays an increasing role in guidance of interventional radiology (IR) procedures in the abdo- men, with special emphasis in embolization procedures, such as transarterial chemoembolization (TACE) for treatment of hepatocellular carcinoma (HCC) or transarterial embolization (TAE) for control of internal hemorrhage. However, relatively long scan time of CBCT results in artifacts arising from organ motion (respiratory and cardiac motion and peristalsis). This poses a significant challenge to guidance in interventional radiology: for example, motion artifacts were found to render up to 25% of CBCT images un-interpretable in image-guided TACE, and 18% in CBCT-guided emergency TAE. The impact of motion is most significant in cases of single or isolated lesions treated with selective embolization that requires visual- ization of very small vascular structures. Existing motion correction methods often invoke assumption of periodicity, lim- iting their applicability outside of cardiac and respiratory motions, or rely on fiducial tracking or gated acquisition that disrupt IR workflow and/or increase radiation dose. Therefore, the application of CBCT in image-guided interventional procedures in the abdomen would significantly benefit from new methods that estimate complex deformable motion directly from image data. “Autofocus” techniques based on maximization of a regularized image sharpness criterion were shown to yield effective patient motion compensation in extremity, head and cardiac CBCT. However, current applications of such methods are limited to rigid motions. We hypothesize that deformable organ motion compensation in interven- tional soft-tissue CBCT can be achieved with advanced autofocus techniques using multiple locally rigid regions of in- terest, preconditioned with basic motion characteristics obtained through a machine learning decision framework. The following aims will be pursued: 1) Develop a joint multi-region autofocus optimization method to compensate deforma- ble organ motion. This includes incorporation into a comprehensive artifacts correction and image reconstruction pipe- line, design of multi-stage optimization schedules for convergence acceleration, and performance evaluation in deforma- ble phantoms, and cadaver and animal experiments. 2) Develop a decision framework for preconditioning of the motion compensation method through a combination of projection-based approaches for physiological signal estimations (res- piratory cycle) and a multi-input, multi-branch, deep learning architecture trained on extremely realistic simulated data that will estimate basic properties of motion (spatial distribution of amplitude, direction, and frequency) from an initial motion-contaminated image and its associated raw projection data. 3) Evaluate deformable motion compensation in animal experiments and in a clinical study in 50 cases of CBCT-guided TACE and assess image quality via expert observer evaluation of satisfaction and utility. The proposed work will yield a robust, practical method for compensation of deform- able soft-tissue motion in CBCT, removing a critical impediment to 3D guidance in IR. The deformable autofocus frame- work will be applicable to other interventions in which soft-tissue motion diminishes CBCT guidance, such as image-guided radiation therapy. PROJECT NARRATIVE Interventional Cone Beam CT (CBCT) provides critical 3D information to guide minimally-invasive procedures in the abdomen, but CBCT image quality is often compromised by organ deformation due to breathing, cardiac, and peristaltic motions. We propose a novel framework to mitigate the effects of this complex deformable motion using only the CBCT image data, without a need for gating, external trackers, or fiducial markers. This algorithm will remove a major impediment to 3D guidance in procedures such as transcatheter embolization procedures in the abdomen.",Deformable motion compensation for 3D image-guided interventional radiology,10100337,R01EB030547,"['3-Dimensional', 'Abdomen', 'Acceleration', 'Affect', 'Algorithms', 'Angiography', 'Animal Experiments', 'Animals', 'Architecture', 'Arterial Embolization', 'Arteries', 'Blood Vessels', 'Breathing', 'Cadaver', 'Cardiac', 'Characteristics', 'Chemoembolization', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Emergency Situation', 'Evaluation', 'Exhibits', 'Financial compensation', 'Fluoroscopy', 'Frequencies', 'Head', 'Hemorrhage', 'Image', 'Intervention', 'Interventional radiology', 'Joints', 'Learning', 'Lesion', 'Limb structure', 'Liver', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Motion', 'Organ', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Periodicity', 'Peristalsis', 'Physiological', 'Play', 'Primary carcinoma of the liver cells', 'Procedures', 'Property', 'Prostate Ablation', 'Radiation Dose Unit', 'Recurrence', 'Reporting', 'Residual state', 'Role', 'Scanning', 'Schedule', 'Signal Transduction', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Therapeutic Embolization', 'Three-Dimensional Image', 'Time', 'Training', 'Validation', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'arm', 'base', 'clinical application', 'cone-beam computed tomography', 'convolutional neural network', 'deep learning', 'design', 'experimental study', 'feeding', 'heart motion', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging modality', 'improved', 'internal control', 'minimally invasive', 'novel', 'porcine model', 'preconditioning', 'radiologist', 'respiratory', 'satisfaction', 'simulation', 'soft tissue', 'standard care', 'tumor']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,368438
"Brain phantom generation by generative adversarial net (GAN) for AI-based emission tomography Project Summary  Positron emission tomography (PET) and single photon emission computed tomography (SPECT) are useful functional medical imaging techniques that can be performed to evaluate brain functions such as regional cerebral perfusion and neurotransmission. The spatial resolution of reconstruction for PET is usually 3-6 mm, and for SPECT is only 1-2 cm. Motivated by the latest advances in artificial intelligence (AI)/machine learning (ML) and its successful application to MRI and CT, it is highly desirable to develop an ML-based system for PET/SPECT cerebral image reconstruction (one of our specific interests is Parkinson disease) to achieve higher resolution and lower noise than using conventional approaches. However, to develop such a learning system, ground-truth data (accurate images, used as the labels) that guide the training are unavailable from the the real world. Published ML systems for PET imaging have used reconstructed images from conventional methods as the label to guide the training. As a result, the goal was only targeted to improve reconstruction speed, rather than improving the image quality. Since the quality of reconstructed image by ML system cannot exceed the guiding images, the performance of ML system cannot surpass conventional methods. Therefore, in this project, we propose a two-year project that will use conditional generative adversarial networks (GAN) to generate digital 2-D human brain phantoms, which will be highly similar to real human brains. The generated phantoms will serve as the (precise) ground-truth data to develop ML-based PET/SPECT reconstruction systems (our future research). The generated phantoms will contain an activity image and an attenuation map. Hence, results from this work can be used for simulating brain PET or SPECT examinations for various neurological disorders, and neural network can be trained with known ground truth. In addition, designing ML systems often relies on large amounts of data, but it is not easy to access data from a large number of patients in the US for specific medical research (mature ML systems developed for computer vision and image classification often involve images on the million level for training). Existing ML systems developed for MRI, CT, and PET imaging often merely uses a few tens of patient data for training and even less data to validate. Therefore, those systems are high-likely overfitted to the data used in training. With the generation system proposed from this project, we can produce a large phantom population to avoid the overfitting problem when design the AI image-reconstruction system. Once the GAN system is successfully developed, it can be easily transplanted to phantom generation for the AI-based CT and AI-based MRI. The method is also potentially extendable to generate phantom populations of torso, abdomen, and extremities for simulating cardiac imaging, tumor imaging, etc. Project Narrative  A two-year small project for generating 2-D digital brain phantoms by generative adversarial net (GAN). The generator can generate artificial digital phantoms very similar to realistic phantoms, so a large number of ground-truth images become available for developing machine-learning-based emission tomography.",Brain phantom generation by generative adversarial net (GAN) for AI-based emission tomography,10293006,R03EB030653,"['Abdomen', 'Address', 'Affect', 'Artificial Intelligence', 'Biological Markers', 'Brain', 'Cancer Biology', 'Cardiac', 'Cerebrum', 'Classification', 'Collimator', 'Computer Analysis', 'Computer Vision Systems', 'Corpus striatum structure', 'Data', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Educational Status', 'Effectiveness', 'Future', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Investigation', 'Label', 'Learning', 'Limb structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Monitor', 'Morphologic artifacts', 'Nerve Degeneration', 'Noise', 'Organ', 'Output', 'Parkinson Disease', 'Patients', 'Performance', 'Perfusion', 'Physics', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Publishing', 'Research', 'Resolution', 'Scheme', 'Speed', 'System', 'Time', 'Training', 'Training Support', 'Transplantation', 'United States', 'Vascular Diseases', 'Water', 'Width', 'Work', 'attenuation', 'base', 'bone', 'cancer imaging', 'data access', 'design', 'digital', 'digital imaging', 'dopaminergic neuron', 'heart imaging', 'image guided', 'image reconstruction', 'improved', 'interest', 'nervous system disorder', 'neural network', 'neurotransmission', 'putamen', 'radiotracer', 'reconstruction', 'reduce symptoms', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'uptake', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R03,2021,81875
"Next-Generation Cardiovascular MRI powered by Artificial Intelligence Project Summary/Abstract: Despite the accuracy and versatility of cardiovascular MRI, its footprint is only 1% among cardiac imaging tests (SPECT, echocardiography, CT, MRI) in the US. While there are several factors such as referral patterns favoring SPECT and echocardiography among cardiologists that account for low utilization, the two addressable obstacles that preclude widespread adoption are lengthy scan time (imaging facility operational cost) and reading (physician cost). These obstacles must be addressed for community hospitals with limited resources to adopt cardiovascular MRI into clinical routine practice. While compressed sensing (CS), since its introduction into the MRI world in 2007, has led to highly-accelerated cardiovascular MRI acquisitions, the subsequent image reconstruction remains too slow (> 5 min for 2D time series, > 1 hour for 3D time series) for clinical translation (unmet need 1). Downstream, image analysis for cardiovascular MRI is notoriously labor intensive (e.g. 30- to 60-min) and limited (“circles” at two cardiac phases for cine MRI, whereas perfusion and late gadolinium-enhanced (LGE) images are evaluated visually), for what is essentially a basic computer vision task (unmet need 2). In direct response, we will address these two unmet needs and unlock the enormous potential of CMR using deep learning (DL). DL applications have exploded since advancements in optimization and GPU hardware. While several recent studies have applied neural networks such as convolutional neural networks (CNNs), U-Nets, and Generative Adversarial Nets (GANs) for reconstruction and segmentation, no study has implemented an inline end-to-end pipeline that receives raw k-space from the MRI scanner and delivers both reconstructed images and fully processed images automatically with high speed (< 1 min). The objectives of this study are: a) developing a network for image reconstruction with maximal acceleration (aim 1), (b) developing a network for image processing tasks (aim 2), and c) developing an integrated, end-to-end network that does both (aim 3). By developing an architecture that can simultaneously learn maximal acceleration, fine tune end-to-end performance, and perform reconstruction/inference using feed-forward networks, we anticipate a disruptive technology that will lead to a paradigm shift in cardiovascular MRI and increase its footprint in community hospitals. This 2-year study is doable because of the requisite database of raw k-space (not derived from DICOM) data (N = 617) and annotated cardiac MR images (N=3,021) from over 3,000 patients existing at our institution. Success of this proposal will deliver a disruptive technology that has potential to cause a paradigm shift in cardiovascular MRI and enable widespread adoption of cardiovascular MRI into clinical routine practice. PROJECT NARRATIVE: The goal of this proposal is to develop a new-generation cardiovascular MRI technology empowered by artificial intelligence, more specifically deep learning. The proposed technology accurately reconstructs cardiovascular images and segments cardiac regions of interest within 1 min without any human intervention. This disruptive technology addresses the two major bottlenecks – lengthy scan time and reading – that preclude widespread adoption of cardiovascular MRI by community hospitals.",Next-Generation Cardiovascular MRI powered by Artificial Intelligence,10226541,R21EB030806,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adopted', 'Adoption', 'Adult', 'Agreement', 'Architecture', 'Artificial Intelligence', 'Cardiac', 'Cardiovascular system', 'Childhood', 'Cine Magnetic Resonance Imaging', 'Classification', 'Clinical', 'Community Hospitals', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Digital Imaging and Communications in Medicine', 'Echocardiography', 'Gadolinium', 'Generations', 'Goals', 'Hour', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Institution', 'Intervention', 'Learning', 'Magnetic Resonance Imaging', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Prognosis', 'Protocols documentation', 'Reading', 'Reporting', 'Resources', 'Sampling', 'Scanning', 'Series', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'cardiovascular imaging', 'clinical practice', 'clinical translation', 'computer science', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'empowered', 'experimental study', 'heart imaging', 'high reward', 'high risk', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging facilities', 'interest', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'reconstruction', 'response', 'risk prediction', 'routine practice', 'signal processing', 'single photon emission computed tomography', 'success']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2021,189806
"Artificial Intelligence Boosted Evolution and Detection of Genetically Encoded Reporters for In Vivo Imaging PROJECT SUMMARY Magnetic resonance (MR) reporter genes have the potential to monitor transgene expression non-invasively in real time at high resolution. These genes can be applied to interrogate the efficacy of gene therapy, to monitor viral therapeutics and viral gene delivery, to assess cellular differentiation, cell trafficking, and specific metabolic activity, and also assess changes in the microenvironment. Efforts toward the development of MR reporter genes have been made for over a decade, but, despite these efforts, the field is still in its early developmental stage. This reflects the fact that there are numerous complications, caused by the low sensitivity of detection, the need for substrates with their associated undesirable pharmacokinetics, and/or the difficult and, in some cases, delayed interpretation of signal changes. We have previously demonstrated that many of these challenges can be overcome with the use of a lysine rich protein (LRP) reporter gene, that is detectable by chemical exchange saturation transfer (CEST) MRI. However, to mature the CEST reporter gene technology and bring it towards clinical translation, its sensitivity and specificity need to be improved. In particular, the LRP reporter gene specificity is limited by the fact that the lysine amide exchangeable protons of LRP have the same chemical shift as amide protons from endogenous proteins. It is therefore difficult to distinguish the reporter CEST contrast from the background CEST contrast, both of which may be changing with time. The specificity is further limited by the sensitivity of the CEST contrast to intracellular pH where the qualitative CEST contrast cannot distinguish between exchange rate and concentration effects. Finally, a decrease in cytosolic pH, observed in many disease pathologies, reduces the amide proton exchange rate and hence the CEST reporter sensitivity. We therefore propose to develop improved MRI reporter genes and quantitative MRI detection methods that will facilitate the clinical translation of these methods for imaging biological therapeutics, such as oncolytic virotherapy. We hypothesize that CEST reporter genes with improved sensitivity and specificity along with improved quantitative CEST methods will enable viral infection and replication to be monitored longitudinally throughout OV tumor therapy. To test this hypothesis and establish the clinical potential of MRI reporter genes we will capitalize on two transformative technologies developed in our labs; (Aim 1) an artificial intelligence based genetic programming algorithm will be used for optimizing the sensitivity and specificity of the CEST reporter gene and (Aim 2) a CEST magnetic resonance fingerprinting (MRF) method will be used for the rapid quantification of both the reporter protein concentration and chemical exchange rate. (Aim 3) These methods will be validated for imaging oncolytic viral infection and replication in mouse glioblastoma tumor models. PROJECT NARRATIVE Cell and viral based therapies have the potential to revolutionize the treatment of many diseases. However, the optimization of such biological therapies depends critically on the ability to monitor the spread and persistence of the therapeutic agent and assess the tissue response. This project therefore proposes to develop and optimize a novel MRI reporter gene technology that allows for the imaging of biological therapeutics. The reporter gene technology will be demonstrated for monitoring oncolytic virotherapy in glioblastoma tumor models, however, the technology is generalizable to any biological therapeutic.",Artificial Intelligence Boosted Evolution and Detection of Genetically Encoded Reporters for In Vivo Imaging,10180072,R01EB031008,"['Algorithms', 'Amides', 'Artificial Intelligence', 'Biological Response Modifier Therapy', 'Cardiac', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical assessments', 'Collaborations', 'Detection', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Drug Kinetics', 'Evolution', 'Fingerprint', 'Gene Transfer', 'Genes', 'Genetic Programming', 'Glioblastoma', 'Goals', 'Histologic', 'Image', 'Infection', 'Longitudinal Studies', 'Lysine', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Medical Imaging', 'Metabolic', 'Methods', 'Modeling', 'Monitor', 'Mus', 'Oncolytic', 'Oncolytic viruses', 'Pathology', 'Performance', 'Physiologic pulse', 'Problem Solving', 'Protein Engineering', 'Proteins', 'Protons', 'Reporter', 'Reporter Genes', 'Resistance', 'Resolution', 'Schedule', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Tissues', 'Tumor Cell Line', 'Viral', 'Virus Diseases', 'Virus Replication', 'Water', 'Work', 'base', 'cancer imaging', 'clinical translation', 'deep learning', 'deep neural network', 'detection method', 'detection sensitivity', 'gene therapy', 'imaging modality', 'improved', 'in vivo imaging', 'neoplastic cell', 'neural network architecture', 'novel', 'oncolytic virotherapy', 'pre-clinical', 'radio frequency', 'rapid technique', 'response', 'therapeutic gene', 'tool', 'trafficking', 'transgene expression', 'tumor', 'viral gene delivery']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,680476
"Constrained Disentanglement (CODE) Network for CT Metal Artifact Reduction in Radiation Therapy  ABSTRACT The World Health Organization reported that cancer is the second leading cause of death globally and is re- sponsible for 9.6 million deaths in 2018. Approximately 50% of all cancer patients receive radiation therapy (RT). Many of them have metal implants, which induce image artifacts in the treatment planning CT images and compromise or preclude treatment in an estimated 15% of all radiation therapy patients. Despite extensive CT metal artifact reduction (MAR) research it remains one of the long-standing challenges in the CT field, without a clinically satisfactory solution. The overall goal of this project is to develop cutting-edge deep learning imaging methods and software solutions for commercial CT scanners to eliminate CT metal artifacts in general and improve RT in particular. We propose a three-pronged approach to systematically tackle this challenge in three specific aims: (1) adversarial learning techniques for estimation of sinogram missing data and metal traces; (2) constrained disentanglement (CODE) networks to remove CT image artifacts during image reconstruction, through post-processing, and in both data and image domains; and (3) systematic evaluation of our proposed CT MAR techniques and clinical translation into robust RT planning methods to maximize the RT treatment planning accuracy and thus improve patient outcomes. Our synergistic track records in CT MAR research, especially with deep imaging methods over the past three years, promises an unprecedented opportunity for a brand-new solution to CT MAR. For the first time we will integrate contemporary AI innovations in data preprocessing, image reconstruction, post-processing, observer studies and treatment planning synergistically in a unified data-driven framework, positioning this project uniquely to eliminate metal artifacts and their complications in radiation therapy. This project will be pursued through the long-term academic-industrial partnership among Dr. Ge Wang at Ren- sselaer Polytechnic Institute (RPI), Dr. Bruno De Man at GE Research Center (GRC), and Dr. Harald Paganetti at Massachusetts General Hospital (MGH). While our teams will collaborate closely through the whole project, GRC has a history of CT research and translation, including direct raw data processing, and will focus on Aim 1. RPI is a pioneering group in tomographic reconstruction, especially deep-learning-based CT imaging, and will lead Aim 2. The MGH team is at the forefront of radiation therapy research and will be responsible for Aim 3. Upon completion of this project, we will have redefined the state of the art of CT MAR, largely eliminating CT metal artifacts and substantially improving radiation therapy planning and delivery accuracy. With the above-proposed networks for CT MAR, metal artifacts will have been basically eliminated, targeting residual errors <10 HU for photon and proton therapy planning, with the goal of reducing the clinical diametric error to ±3% and the proton range error due to metal artifacts to <2mm. Since our approach is software-based and open-source, the path for technology transfer and clinical translation is clearly defined, as well tested before.  NARRATIVE Metal implants induce image artifacts in treatment planning CT images, with an estimated 15% of all radiation therapy patients being seriously affected in their radiation therapy. Despite extensive CT metal artifact reduction (MAR) research, it remains one of the long-standing challenges in the CT field, without a clinically satisfactory solution. The overall goal of this project is to develop cutting-edge deep learning methods and an AI-based software package for clinical CT scanner for elimination of CT metal artifacts in general and improvement of radiation therapy (RT) in particular.",Constrained Disentanglement (CODE) Network for CT Metal Artifact Reduction in Radiation Therapy,10184493,R01EB031102,"['Affect', 'Aging', 'Artificial Intelligence', 'Benchmarking', 'Cancer Patient', 'Cause of Death', 'Cessation of life', 'Clinic', 'Clinical', 'Communities', 'Computer software', 'Data', 'Dimensions', 'Estimation Techniques', 'Evaluation', 'General Hospitals', 'Goals', 'Human', 'Image', 'Implant', 'Institutes', 'Lead', 'Learning', 'Malignant Neoplasms', 'Massachusetts', 'Metals', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Network-based', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Photons', 'Positioning Attribute', 'Protons', 'Radiation therapy', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Residual state', 'Supervision', 'Techniques', 'Technology', 'Technology Transfer', 'Testing', 'Therapeutic Studies', 'Time', 'Trace metal', 'Translating', 'Translations', 'Treatment outcome', 'World Health Organization', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical imaging', 'clinical translation', 'computerized data processing', 'deep learning', 'dosimetry', 'experimental study', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'imaging software', 'improved', 'industry partner', 'innovation', 'learning network', 'learning strategy', 'man', 'meetings', 'open source', 'proton therapy', 'reconstruction', 'tomography', 'treatment planning']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2021,2593824
"Fast Multi-dimensional Diffusion MRI with Sparse Sampling and Model-based Deep Learning Reconstruction Project Summary: Neurodegenerative disorders are a significant public health and economic problem and are the leading cause of disability worldwide. Understanding the specific degenerative processes that are actively progressing over the course of the illness is crucial for developing targeted drugs therapies and deciding treatment options. Additionally, understanding the structural connectivity changes to tease apart the specific circuitry affected is crucial in developing circuit specific non-invasive brain stimulation therapies. Diffusion- based MRI assays can provide microstructural measures that are highly sensitive to (i) the neurodegenerative processes and (ii) connectivity changes. Advanced modeling approaches can be utilized to further enhance the specificity of the microstructural measures to the underlying neurodegenerative processes. However, their utility is often limited to pure white matter regions. At the typical spatial resolution of diffusion MRI (~2mm isotropic voxel size), significant partial volume effects exist in most brain voxels (e.g., voxels with multiple tissue types, heterogenous fibers with different properties). In whole brain studies, this compromises the specificity of the disease processes identified by the advanced modeling approaches; it also contributes to inaccurate connectivity mapping. Additionally, the diffusion parameter encoding space is currently limited to one or two shells of low b-values (b<2000s/mm2), which limits the unique determination of several relevant microstructural parameters. The main objective of the proposal is the development, validation and clinical translation of a diffusion MRI assay that enable efficient encoding of diffusion parameter space at sub- millimeter voxel resolution for joint microstructure and connectivity mapping in the whole brain. Our overall hypothesis is that the proposed framework can significantly improve the validity of microstructural modeling in most brain voxels. The proposed development will make use of SNR-efficient 3D multi-slab acquisitions. Coupled with time-efficient sparse k-q sampling, the encoding will span over multiple b-shells. To allow the unique determination of several relevant microstructural parameters, multicompartmental T2 information will be utilized. The proposed developments will be enabled by two advanced reconstruction methods: structured low- rank matrix completion, a novel integrative framework for MRI reconstructions that enables several capabilities including multi-echo imaging and self-calibrating reconstruction; and model-based deep learning, a novel deep architecture to solve MR reconstruction algorithms using neural networks in a systematic fashion. These methods overcome several inefficiencies associated with extending the 3D multi-slab acquisition for multi- dimensional imaging in the k-q-TE space. To ensure scientific rigor, we will comprehensively validate our technology on dedicated diffusion phantoms along with healthy volunteers using different quantification metrics. We also validate the capability of the dMRI assay using a multi-modal MRI study in a cross-sectional study on a cohort of Huntington's disease. PROJECT NARRATIVE Neurodegenerative disorders are a significant public health and economic problem affecting about 450 million people worldwide are the leading cause of disability and ill-health according to world health organization. The main objective of the proposal is the development, validation and translation of a non-invasive diffusion MRI assay, that enable efficient encoding of diffusion parameter space to characterize the neurodegenerative processes that drive the progression of neurodegeneration. We validate the framework in a cohort of Huntington's disease, with the prospect of extending these studies to understand the neurodegenerative cascade in the entire class of neurodegenerative diseases, including Parkinson's and Alzheimer's.",Fast Multi-dimensional Diffusion MRI with Sparse Sampling and Model-based Deep Learning Reconstruction,10183606,R01EB031169,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Architecture', 'Biological Assay', 'Biological Markers', 'Brain', 'Cause of Death', 'Clinical Research', 'Complement', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Demyelinations', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disadvantaged', 'Disease', 'Effectiveness of Interventions', 'Ensure', 'Fiber', 'Financial compensation', 'Health', 'Human', 'Huntington Disease', 'Image', 'Intervention', 'Iron', 'Joints', 'Lead', 'Learning Module', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurons', 'Outcome', 'Parkinson Disease', 'Pattern', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Physics', 'Play', 'Process', 'Property', 'Protocols documentation', 'Public Health', 'Recovery', 'Resolution', 'Sampling', 'Signal Transduction', 'Specificity', 'Structure', 'Study models', 'Symptoms', 'Techniques', 'Technology', 'Time', 'Tissue Model', 'Tissues', 'Translations', 'Validation', 'Water', 'Work', 'World Health Organization', 'advanced disease', 'axonal degeneration', 'base', 'biophysical model', 'brain circuitry', 'clinical translation', 'cohort', 'deep learning', 'design', 'disability', 'effectiveness evaluation', 'health economics', 'healthy volunteer', 'high resolution imaging', 'image reconstruction', 'improved', 'in vivo', 'multimodality', 'neural network', 'neuroinflammation', 'neuron loss', 'noninvasive brain stimulation', 'novel', 'physical property', 'reconstruction', 'targeted treatment', 'white matter']",NIBIB,UNIVERSITY OF IOWA,R01,2021,333401
"Measuring cortical plate and subplate thickness in the human fetal brain from magnetic resonance images PROJECT SUMMARY/ABSTRACT In the fetal brain, cortical plate (CP) thickness is thought to be related to the number and size of cells within a column, packing density, intracortical myelin, and synapses, and subplate (SP) thickness associated with the number of thalamic and cortical afferents and the amount of cortico-cortical connections. Estimation of cortical thickness postnatally with MRI has contributed greatly to our understanding of human brain development and cognitive function and disease onset and progression in various brain disorders. However, our knowledge and research of human in utero CP and SP thickness remains limited due to the lack of available techniques that automatically measure regional CP and SP thickness from fetal brain MRI. Compared to child or adult brains, fetal brains are much smaller in size and have different image contrast. Fetal brain MRI shows lower effective resolution and suffers from head motion which causes artifacts. Thus, it is challenging to extract accurate CP and SP regions and define geometrically appropriate thickness between the CP and SP surfaces. This study will develop a fully automatic pipeline to extract regional CP and SP thickness using multi-site fetal MRI datasets. We will develop the method for CP and SP segmentation with the identification of sulcal cerebrospinal fluid regions using deep convolutional neural networks. Based on the accurate segmentation, a deformable model method that is optimized and specialized for fetal brains will be developed to extract the CP and SP surfaces. CP and SP thickness will be measured based on vertex-wise correspondence between all CP and SP surfaces. We will perform reliability and sensitivity tests using different imaging subsets within the same subject and artificial data created by moving the CP and SP boundary. We will then define the growth rate of CP and SP thickness in all cortical regions in typically developing (TD) fetuses from 18 to 37 gestational weeks (GW). We hypothesize that the growth rate of CP and SP thickness, the maximum SP thickness, and/or the maximum growth GW of CP thickness will be variable across different cortical areas in TD fetuses. The growth of CP and SP thickness in fetuses with cerebral abnormalities (polymicrogyria and agenesis of corpus callosum) will be statistically compared to the growth of TD fetuses. Malformations of cortical development and cortico-cortical connections may result in altered growth of CP and SP thickness in fetuses with polymicrogyria and agenesis of corpus callosum. This study will lay the foundation for a novel biomarker that can lead to greater insight into the mechanisms of normal and altered in utero brain development. Our methods developed from the proposed study will be publicly distributed using a web-based neuroimage computation platform, which will enable more clinical applications of fetal CP and SP thickness analysis. PROJECT NARRATIVE The proposed project will develop a novel technology to measure cortical plate and subplate thickness in the human fetal brain using in vivo MRI, which in turn will enable us to understand trajectories (temporal dynamics) and inter-subject variabilities of fetal cerebral growth. The technology for fetal cortical and subplate thickness measurement will lay the foundation for clinical applications of fetal brain MRI analysis in many developmental disorders and extend the field of developmental brain imaging research. This study will provide a meaningful biomarker that could lead to greater insight into the mechanisms of normal and altered in utero brain development, allowing assessment of the impact of maternal exposures and informing strategies for future in utero therapies.",Measuring cortical plate and subplate thickness in the human fetal brain from magnetic resonance images,10366327,R01EB031170,"['37 weeks gestation', 'Adult', 'Algorithms', 'Animal Model', 'Area', 'Autopsy', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cell Size', 'Cerebrospinal Fluid', 'Cerebrum', 'Child', 'Clinical Research', 'Cognition Disorders', 'Corpus Callosum', 'Cortical Malformation', 'Data', 'Data Set', 'Development', 'Fetal Development', 'Fetus', 'Foundations', 'Future', 'Gene Expression', 'Gestational Age', 'Growth', 'Head', 'Human', 'Image', 'Knowledge', 'Lead', 'Magnetic Resonance Imaging', 'Manuals', 'Maternal Exposure', 'Measurement', 'Measures', 'Methods', 'Microgyria', 'Modeling', 'Morphologic artifacts', 'Motion', 'Mutation', 'Myelin', 'Neural Network Simulation', 'Neurons', 'Online Systems', 'Onset of illness', 'Pattern', 'Perinatal Hypoxia', 'Pregnancy', 'Research', 'Resolution', 'Shapes', 'Site', 'Structure', 'Study models', 'Surface', 'Synapses', 'Techniques', 'Technology', 'Testing', 'Thalamic structure', 'Thick', 'Thinness', 'Tissues', 'Translations', 'Variant', 'axon guidance', 'base', 'clinical application', 'cognitive function', 'computational platform', 'contrast imaging', 'convolutional neural network', 'deep learning', 'density', 'developmental disease', 'fetal', 'gray matter', 'human fetal brain', 'in utero', 'in vivo', 'insight', 'learning strategy', 'neuroimaging', 'neuron loss', 'new technology', 'novel marker', 'postnatal', 'prenatal', 'prenatal therapy', 'reconstruction', 'spatiotemporal', 'tool']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R01,2021,665529
"A Feasibility Study of a High-Throughput Live-Cell Microscopy Design for Visualizing Viral Particle Action and Nano-Carrier Delivery Performance Project Summary/Abstract Decades of basic research have afforded a general picture for how a viral particle may approach a cell, be internalized by the cell, and hijack the cell to produce more progenitors. The accumulated knowledge, in turn, has allowed one to formulate specific mechanistic questions. For instance, why would a particular mutation in a virus make it more effective in infecting a live cell? Is it because the mutation makes the virus stay on the cell surface longer (on time) but exhibiting the same cell-internalization propensity, or is it because the mutation makes it easier for the virus to invade the cell while the off time remains the same? Where inside a cell and when does a viral particle escape an endosomal enclosure and/or shed its capsid to release its genetic material? By analogy, similar questions can be formulated in designing nanoparticle-based drug delivery vessels. Many ingenious experiments using a diverse array of biochemical and biological tools have been devised to address them, and the insights have led to translational research that has direct therapeutic impacts. A direct observation and recording of these dynamical events that a viral particle may exhibit in its cell-invasion and multiplication cycle could potentially offer much more. Recently, our laboratory put forward a proof-of-principle imaging platform that allows one to do just that: While an integrated two-photon laser-scanning microscope continuously provides 3D sections of the environmental context of a moving virus-like nanoparticle, the nanoparticle is tracked in 3D. This is performed by moving the sample in order to keep the particle at the center of a microscope objective focus with a super-resolution localization precision (~10 nm) in all three dimensions and at a 10-microsecond time resolution. Even for events as simple as a virus-like nanoparticle approaching and landing on a cell, this prototype multiresolution microscope has allowed us to uncover that, unexpectedly, a virus-like particle tends to slow down significantly before its landing on a cell surface. While the prototype instrumentation demonstrates that direct 3D high-resolution visualization could indeed provide uniquely new information that has been inaccessible using conventional methods, its trajectory throughput is too low to be of widespread practical use. This developmental project is intended to test whether a new microscopy design would make this approach higher throughput. This is to be achieved by a new instrumentation design and a machine learning computational backend for dynamic content filtering. Quantitative measures for benchmarking and feasibility testing are also described. If feasible, the community would have a completely new and practical way of looking at viral particle actions and nano-carrier delivery performances. Project Narrative The goal of this project is to evaluate a new live-cell microscopy instrumentation design, intended for practical applications in areas such as the basic research of virology and drug delivery. The design leverages the advantages of concurrent 3D imaging at three different optical resolutions where the data acquisition is assisted by machine learning. If feasible, this high throughput yet high content instrumentation design would provide a completely new way of visualizing single viral particle actions or individual nano-carrier delivery performances— in real time with 3D contextual fidelity at a particle-localization precision as high as ~10 nm in all three axes with 10-μs time resolution.",A Feasibility Study of a High-Throughput Live-Cell Microscopy Design for Visualizing Viral Particle Action and Nano-Carrier Delivery Performance,10193517,R21EB031374,"['3-Dimensional', 'Address', 'Alpha Particles', 'Area', 'Basic Science', 'Behavior', 'Benchmarking', 'Biochemical', 'Biological', 'Capsid', 'Cell surface', 'Cells', 'Communities', 'Computational algorithm', 'Computer Assisted', 'Computer software', 'Computers', 'Coupling', 'Data', 'Data Set', 'Detection', 'Development', 'Diffuse', 'Drug Delivery Systems', 'Endosomes', 'Event', 'Exhibits', 'Feasibility Studies', 'Genetic Materials', 'Goals', 'Human', 'Image', 'Individual', 'Invaded', 'Knowledge', 'Laboratories', 'Laser Scanning Microscopy', 'Lasers', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microtubules', 'Monitor', 'Motion', 'Mutation', 'Optics', 'Performance', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Shapes', 'Supervision', 'Testing', 'Therapeutic', 'Three-Dimensional Imaging', 'Time', 'Training', 'Translational Research', 'Viral', 'Virus', 'Virus-like particle', 'Visualization', 'base', 'data acquisition', 'data streams', 'design', 'experimental study', 'feasibility testing', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'interest', 'live cell microscopy', 'nanocarrier', 'nanoparticle', 'neural network', 'optical imaging', 'particle', 'practical application', 'progenitor', 'prototype', 'spatiotemporal', 'statistics', 'tool', 'trait', 'two-photon', 'virology']",NIBIB,PRINCETON UNIVERSITY,R21,2021,363354
"Quality and Safety Monitoring of Clinical Computed Tomography Practice Abstract – Fifty percent of radiation exposure to the United States population is from medical imaging, half of which come from over 80 million computed tomography (CT) scans performed every year. This significant use has raised notable concerns regarding utilization costs, inappropriate applications, and the associated radiation risk. A recent Medicare reports hundreds of hospitals across the country have needlessly scanned their patients twice on the same day. Unnecessary repeated scans expose patients to extra radiation while increase expense, decrease reimbursement, and increase liability for the providers. Thus, the legislative and regulatory organizations have encouraged and mandated stricter oversight of medical imaging usage and its associated radiation. Concurrent to the mandate to better manage imaging risk is to ensure its value: One of the quintessential but most understated pillars of current CT practice is CT’s high value in caring for illness and injury across all ages. To ensure this benefit of CT examinations, there needs to be a careful balance between image quality and radiation safety. A poor quality, overly low dose exam is a disservice to the care of the patient while an exam with more radiation dose than necessary can undermine its safety. Therefore, proper CT imaging requires a comprehensive combined quality and dose monitoring program on a patient-by-patient basis to properly understand, manage, and mitigate radiation risk. Unfortunately, currently there is no such software available in the market that can simultaneously monitor CT radiation dose and its corresponding image quality. The objective of this fast-track project is to develop a first Software as a Service (SaaS)-based performance monitoring platform to track radiation dose and image quality concurrently. The platform aims to provide essential data and insight to improve CT performance through considering both patient safety and imaging quality simultaneously. Specifically, the project will develop a product that offers 1) a robust multi-infrastructure workflow to connect and collect clinical CT quality- and dose-relevant data; 2) a suite of patient-specific CT radiation dose and image quality assessment algorithms; 3) an implementation of a task manager to chain and automate dose and image quality calculations towards CT performance assessment; 4) a combined SQL- NoSQL database system for structured and un-structured quality- and dose-relevant data storage; and 5) a web-based dashboard for interactive and easy-to-use data analysis and visualization. The development utilizes machine-learning methodologies to devise robust and scalable techniques for extracting meaningful knowledge from hundreds of thousands of patient images. The system quantifies value for a value-based practice. It serves as an essential tool to minimize variability in quality and dose across a practice, to ensure consistent use of CT technology, and to ensure imaging radiation dose and quality levels match expected values. The system will be beta tested at healthcare facilities paving the way toward effective commercialization. 1 Project Narrative The dose and image quality in the clinical practice of computed tomography (CT) imaging is highly variable due to variability across diverse technical and human factors. More radiation dose yields better quality images, necessitating a balance between the two in a way that is patient-specific and trackable. The project aims to develop a tracking and analytics platform to minimize variability and to assure the balance of quality and dose across clinical practice.",Quality and Safety Monitoring of Clinical Computed Tomography Practice,10253256,R44EB031658,"['Address', 'Affect', 'Age', 'Algorithms', 'Architecture', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Contrast Media', 'Country', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Dental', 'Development', 'Devices', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Ensure', 'Equilibrium', 'Equipment', 'Exposure to', 'Fluoroscopy', 'Foundations', 'Goals', 'Health', 'Health Technology', 'Health care facility', 'Health system', 'Healthcare', 'Hospitals', 'Human', 'Image', 'Individual', 'Information Systems', 'Infrastructure', 'Injury', 'Insurance', 'Intuition', 'Knowledge', 'Mammography', 'Manufacturer Name', 'Medical Imaging', 'Medicare', 'Modeling', 'Monitor', 'Nuclear', 'Online Systems', 'Outcome', 'Patient Care', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Phase Transition', 'Population', 'Protocols documentation', 'Provider', 'Quality of Care', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Radiology Specialty', 'Reporting', 'Research', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'United States', 'Universities', 'X-Ray Computed Tomography', 'base', 'beneficiary', 'clinical imaging', 'clinical implementation', 'clinical practice', 'commercialization', 'computer infrastructure', 'cost', 'dashboard', 'data exchange', 'data management', 'data visualization', 'design', 'graphical user interface', 'imaging modality', 'imaging system', 'improved', 'informatics infrastructure', 'innovation', 'insight', 'interoperability', 'machine learning method', 'operation', 'patient safety', 'profiles in patients', 'programs', 'prototype', 'radiation risk', 'repaired', 'software as a service', 'tool']",NIBIB,"METIS HEALTH ANALYTICS, LLC",R44,2021,249708
"Quantitative Diffuse Correlation Spectroscopy for Assessing Human Brain Function PROJECT SUMMARY/ABSTRACT Acute brain injuries can lead to secondary brain damage that worsens the outcome. Reduced cerebral blood flow can induce ischemia, while excess blood flow can cause hemorrhage. Thus, there is a need for noninvasive, bedside, continuous cerebral blood flow monitoring approaches at neurointensive care units (NICUs). Existing technologies for continuous monitoring of cerebral blood flow have critical limitations. Functional near-infrared spectroscopy has been employed for this clinical need, but it suffers from being not quantitative and prone to errors due to signals from superficial scalp tissue. Moreover, it measures only limited information content of oxygen saturation. Additional blood flow contrast can provide a useful biomarker. Diffuse correlation spectroscopy (DCS) technique is an emerging diffuse optical technique for bedside monitoring of blood flow in humans. Currently, DCS operates in continuous-wave (CW) mode, which has limitations such as superficial signal sensitivity and inaccurate quantification of blood flow due to dependency to priori information of optical parameters. More recent time domain (TD) approach has low signal-to-noise ratio, costly, highly limited for clinical translation. The goal is to address these limitations by proposing a novel technology and method that can quantify both absolute static and dynamic parameters concurrently in a single instrument with fast data acquisition, thus, it is highly suitable for fast functional neuroimaging. It can also separate superficial and brain signals by discriminating early and late photons via time-gating. Additionally, longer wavelength at the infrared allows for enhanced depth penetration. It can quantify blood flow and optical parameters in near- real-time using deep learning, which is highly suitable for NICU settings. The proposed system and method will completely replace the current state-of-the-art (CW-DCS) and is superior TD approach, because it can provide higher signal-to-noise ratio (SNR) in the brain, its simplicity and significantly lower cost in instrumentation, which will lead to fast clinical translation. To achieve our goal, we will construct and optimize the instrument prototype, characterize the signal, and then we will test the system on phantom models and custom-developed analytical and Monte Carlo and deep learning models and determine the quantification accuracy with respect to static and dynamic parameters (Aim-1). We will optimize the system with respect to pulse-width, SNR for improved quantification accuracy of static and dynamic parameters (Aim-2). Then, we will test the system in healthy subjects and traumatic brain injury patients (Aim-3). This innovative DCS system and method will result in quantitative blood flow parameter with enhanced brain sensitivity and will eliminate the roadblocks in both CW and TD approaches, thereby will pave the way for fast clinical translation at NICU settings and for general neuroimaging applications. NARRATIVE The proposed novel optical technology provides quantitative metrics such as blood flow with higher sensitivity to deeper brain tissue. It provides superior information content than current clinical standard of continuous wave diffuse correlation spectroscopy. Ultimately, this optical imaging system will pave the way in the diffuse optical spectroscopy field and serve as a quantitative clinical tool for longitudinal monitoring of brain injuries at neurointensive care units, and other neuroimaging applications.",Quantitative Diffuse Correlation Spectroscopy for Assessing Human Brain Function,10265818,R01EB031759,"['Acute Brain Injuries', 'Address', 'Adult', 'Beds', 'Biological Markers', 'Blood flow', 'Brain', 'Brain Injuries', 'Brain region', 'Caring', 'Cerebrovascular Circulation', 'Cerebrum', 'Child', 'Clinic', 'Clinical', 'Custom', 'Dependence', 'Diffuse', 'Diffusion', 'Evaluation', 'FDA approved', 'Fourier Transform', 'Frequencies', 'Goals', 'Gold', 'Head', 'Hemorrhage', 'Human', 'Intervention', 'Ischemia', 'Lasers', 'Lead', 'Length', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Monte Carlo Method', 'Near-Infrared Spectroscopy', 'Noise', 'Optics', 'Outcome', 'Oxygen', 'Patients', 'Penetration', 'Performance', 'Photons', 'Physiologic pulse', 'Population', 'Premature Infant', 'Prognosis', 'Protocols documentation', 'Scalp structure', 'Secondary to', 'Signal Transduction', 'Skin', 'Source', 'Spectrum Analysis', 'Survivors', 'System', 'TBI Patients', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Traumatic Brain Injury', 'Width', 'base', 'brain tissue', 'clinical translation', 'clinically relevant', 'cost', 'cranium', 'data acquisition', 'deep learning', 'detector', 'digital', 'experimental study', 'heterodyning', 'imaging biomarker', 'imaging system', 'improved', 'innovation', 'instrument', 'instrumentation', 'neonate', 'neuroimaging', 'new technology', 'novel', 'novel strategies', 'optical imaging', 'phantom model', 'photon-counting detector', 'programs', 'prototype', 'response', 'simulation', 'time use', 'tool']",NIBIB,WRIGHT STATE UNIVERSITY,R01,2021,335364
"Deep Learning Reconstruction for Improved TOF PET Using Histo-Image Partitioning Project Summary  Clinical and research applications of the PET imaging are rapidly expanding from ever improving diagnostic and treatment assessment applications to guidance of personalized treatments, ultra-low dose imaging, and even interventional imaging procedures. Supporting these developments, reconstruction tools that are able to reliably handle both typical and (ultra-)low count situations, imperfect data, and data from specialized imaging geometries, with fast (near real-time) reconstruction performance are of crucial importance. The overall goal of this project is to develop and investigate robust and efficacious Deep Learning (DL) reconstruction approaches addressing these needs. A unique and innovative feature of the proposed approaches (compared to alternative DL applications) is the utilization of list-mode data histogrammed into a very efficient histo-image format. TOF data partitioned into the histo-image format are characterized by strong local properties, thus perfectly fitting convolutional neural network formalism and making DL training and reconstruction directly from realistic clinical data (in size and character) highly feasible and practical.  The clinical utility of PET systems has significantly improved over the years thanks to advances in instrumentation, data corrections, and reconstruction approaches. Nevertheless, full utilization of their potential through robust and fast quantitative reconstruction remains a challenge especially for the cases of very low count data, such as in low-count temporal (motion and dynamic) frames, delayed studies, longitudinal low-dose studies, and studies using new isotopes with long half-life and low positron fraction rates (e.g. in 89Zr-labeled CAR-T cell imaging), as well as in specialized PET systems with partial angular coverage, for which exact, artifact-free, reconstruction does not exist. These are the situations for which the developed DL approaches promise great potential due to the demonstrated success of the DL networks to be trained for imperfect and very low count data without reliance on accurate data models. Furthermore, pre-trained networks can provide ultra- fast, near real-time, performance in practical use.  Specific Aim 1 will develop tools for DL PET reconstruction using histo-image partitioning along with procedures for training of the proposed DL approaches, including novel approaches advancing the state-of-the- art of DL reconstruction directly from acquired PET data. Specific Aim 2 is directed towards study and evaluation of the performance of the investigated DL approaches for whole-body and long axial FOV scanner data for the wide range of counts from applications such as typical FDG, low dose, delayed, low activity isotope scans, and ultra-short frames in motion correction and dynamic studies. Specific Aim 3 will develop and apply motion correction protocols involving the proposed DL reconstruction tools and test and study their efficacy for clinically realistic situations involving non-rigid lung and heart motions. And finally, Specific Aim 4 is dedicated to an application and study of the developed DL approaches to specialized PET systems with partial angular coverage. 1 Project Narrative  The major goal of this project is to improve the diagnostic, treatment guidance, and research utility of quantitative positron emission tomography (PET) imaging, through the development of robust, near real-time, deep-learning based reconstruction approaches allowing efficacious use of standard, low dose, and novel low activity imaging molecular bio-tracers. The proposed work is relevant to public health, since an improvement in the reconstructed images will lead to more accurate diagnosis of diseases and more accurate treatment guidance and monitoring of the response to therapy, while allowing for decreased patient radiation dose. It will also facilitate quantitatively reliable tools for research investigations with new radiotracers for PET tailored to specific diseases. 2",Deep Learning Reconstruction for Improved TOF PET Using Histo-Image Partitioning,10276952,R01EB031806,"['3-Dimensional', 'Address', 'Algorithms', 'Application procedure', 'Archives', 'Area', 'Breast', 'Case Study', 'Clinical', 'Clinical Data', 'Clinical Research', 'Data', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Disease', 'Dose', 'Evaluation', 'Explosion', 'Geometry', 'Goals', 'Half-Life', 'Image', 'Imaging Techniques', 'Intervention', 'Investigation', 'Isotopes', 'Label', 'Lung', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Motion', 'Organ', 'Patients', 'Performance', 'Physics', 'Positron', 'Positron-Emission Tomography', 'Procedures', 'Property', 'Protocols documentation', 'Psychological Transfer', 'Public Health', 'Radiation Dose Unit', 'Research', 'Resolution', 'Running', 'Scanning', 'System', 'Techniques', 'Testing', 'Time', 'Tracer', 'Training', 'Training Technics', 'Validation', 'Work', 'accurate diagnosis', 'base', 'breast imaging', 'cellular imaging', 'chimeric antigen receptor T cells', 'clinical efficacy', 'clinically relevant', 'convolutional neural network', 'data modeling', 'deep learning', 'denoising', 'detector', 'disease diagnosis', 'efficacy evaluation', 'heart motion', 'improved', 'innovation', 'instrumentation', 'learning network', 'loss of function', 'molecular imaging', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'personalized medicine', 'proton therapy', 'radiotracer', 'reconstruction', 'response', 'solid state', 'statistics', 'success', 'tomography', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2021,620138
"Next-generation in-vivo fetal neuroimaging Next-Generation In-Vivo Fetal Neuroimaging The overall objective of this project is to dramatically improve fetal magnetic resonance imaging (MRI) to advance research in early human brain development and neurodevelopmental disorders, the burden of which is, unfortunately, high because of their life-long impact and high prevalence. Fetal MRI has been the technique of choice in studying prenatal brain development. Fetal motion, however, makes MRI slice acquisition unreliable at best, as the fetus frequently moves while the prescribed slices are imaged. Uncompensated fetal motion disrupts 3D coverage of the anatomy and reduces the spatial resolution of slice-to-volume reconstructions. Repeating the scans does not ensure full 3D coverage of the anatomy, but increases total acquisition time. This, in turn, dramatically reduces the success rate and reliability of fetal MRI in studying the development of transient fetal brain compartments that are selectively sensitive to injury over the course of fetal development. To mitigate these issues and improve fetal MRI, we propose to automatically measure fetal brain position and prospectively navigate slices to each new position in real-time. The impact of this approach will be to dramatically increase the success rate and spatial resolution of fetal MRI for the in-vivo investigation of developing brain compartments, while, in parallel, reducing scan time, effectively making fetal MRI less burdensome for the mother, more accurate, and cost effective. By eliminating the manual re- adjustment of stack-of-slice positions, the time that elapses between scans will be virtually continuous. Our proposed technique will also make fetal MRI less operator-dependent and thus, more reproducible across sites, which is essential to conducting multi-center studies and clinical trials. Prospective navigation of fetal MRI slices to compensate for motion requires the development of novel, real-time image processing algorithms to recognize the fetal brain and its position and orientation; to track fetal motion to steer slices; and to detect and re-acquire motion corrupted slices. In this project, we will develop innovative deep learning models to process fetal MRI slices in real-time; will translate those models into an integrated system to prospectively navigate fetal MRI slices; and will validate the system on fetuses scanned at various gestational ages. To assess the utility and impact of the proposed technology, we will measure subplate volume in fetuses. The four specific aims of this study are to 1) assess fetal MRI via variable density image acquisition and reconstruction; 2) achieve real-time recognition of the fetal brain in MRI slices; 3) develop a system of real-time fetal head motion tracking and steering of slices; and 4) measure the subplate volume in the developing fetal brain using MRI. These aims will collectively translate and validate new imaging and image processing techniques to advance fetal MRI, and effectively eliminate a critical barrier to making progress in the fields of developmental neurology and neuroscience. Project Narrative: The proposed research aims to develop, translate, and validate innovative in-vivo imaging technologies to improve imaging and studying the development of the human fetal brain before birth. The technology will enable and improve studies on the development of the brain in fetuses with congenital disorders or fetuses at risk of having neurodevelopmental issues later in life. This in-turn is expected to result in timely and more effective treatments and therapeutic interventions that will lead to vastly improved patient outcomes in both the short- and long-term, effectively reducing the burden of human disabilities arising from congenital disorders.",Next-generation in-vivo fetal neuroimaging,10280126,R01EB031849,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Birth', 'Brain', 'Cell Proliferation', 'Cell physiology', 'Classification', 'Clinical Trials', 'Cognitive', 'Complex', 'Congenital Disorders', 'Data', 'Data Set', 'Development', 'Fetal Development', 'Fetus', 'Gestational Age', 'Head', 'Health Care Costs', 'High Prevalence', 'Human', 'Hypoxia', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'Investigation', 'Life', 'Live Birth', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Mental Health', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Multicenter Studies', 'Neurodevelopmental Disorder', 'Neurology', 'Neurons', 'Neurosciences', 'Noise', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Real-Time Systems', 'Relaxation', 'Reproducibility', 'Research', 'Resolution', 'Role', 'Rotation', 'Sampling', 'Scanning', 'Second Pregnancy Trimester', 'Signal Transduction', 'Site', 'Slice', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Uterus', 'absorption', 'brain tissue', 'cognitive disability', 'congenital heart disorder', 'convolutional neural network', 'cost effective', 'deep learning', 'density', 'disability', 'effective therapy', 'fetal', 'fetus at risk', 'image processing', 'image reconstruction', 'imaging study', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'large datasets', 'migration', 'myelination', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'new technology', 'next generation', 'novel', 'prenatal', 'prospective', 'real-time images', 'reconstruction', 'recurrent neural network', 'success', 'virtual']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R01,2021,588593
"Computational Toolkit for Normalizing the Impact of CT Acquisition and Reconstruction on Quantitative Image Features Quantitative image features (QIFs) such as radiomic and deep features hold enormous potential to improve the detection, diagnosis, and treatment assessment of a wide range of diseases. Generated from clinically acquired Computed Tomography (CT) scans, QIFs represent small pixel-wise changes that may be early indicators of disease progression. However, detecting these changes is complicated by variations in the way that CT scans are performed, including variations in acquisition and reconstruction parameters. Ensuring reproducible QIFs is a prerequisite for developing machine learning (ML) models that achieve consistent performance across different clinical settings. This project's premise is that QIFs are sensitive to CT parameters such as radiation dose level, slice thickness, reconstruction kernel, and reconstruction method. The combined interactions among these parameters result in unique image conditions, each yielding its own QIF value. Moreover, some clinical tasks and algorithms are more sensitive to differences in QIF values than others. We hypothesize that a systematic, task-dependent framework to normalize scans and mitigate the impact of variability in CT parameters will identify reproducible QIFs and yield more consistent ML models. Three interrelated innovations will be pursued in this work: 1) a novel framework for characterizing the impact of different acquisition and reconstruction parameters on QIFs and ML models using patient scans with known clinical outcomes in multiple domains; 2) a systematic approach for selecting an optimal mitigation technique and evaluating the impact of normalization; and 3) an open-source software toolkit that formalizes the process of CT normalization, addressing real-world use cases developed by academic and industry collaborators. In Aim 1, we will evaluate how multiple CT parameters influence QIF values and model performance. Utilizing metrics of agreement and a heat map-based visualization, we will determine under which image acquisition and reconstruction conditions the QIFs and model performance are consistent. In Aim 2, we will develop and validate a generative adversarial network-based approach to normalization. Our investigation will focus on targeted mitigation of the set of imaging conditions that are most relevant to a clinical task and on the optimization of how these models are trained. In Aim 3, we will engage a spectrum of external stakeholders to guide the development and adoption of a software toolkit called CT-NORM. Three distinct clinical domains will drive our efforts: lung nodule detection (which relies on identifying small regions of high contrast differences to identify nodules), interstitial lung disease quantification (which depends on characterizing texture differences), and ischemic core assessment (which relies on detecting low contrast differences in brain tissue). CT-NORM will provide the scientific community with an approach and a unified toolkit to characterize and mitigate the impact of reconstruction and acquisition parameters on QIFs and ML model performance. By addressing critical sources of variability, we will improve the process of generating QIFs and facilitate the discovery of precise and reproducible imaging phenotypes of disease. PROJECT NARRATIVE Computed Tomography (CT) images play an integral role in screening and diagnosing diseases such as lung cancer, interstitial lung disease, and stroke. While artificial intelligence/machine learning models have been con- structed using quantitative image features, model performance can be affected by variations in how the CT images are acquired and reconstructed. This project aims to investigate the effects of varying CT parameters on these image-derived features and to use that information to identify optimal techniques to mitigate their effects in a task-dependent manner.",Computational Toolkit for Normalizing the Impact of CT Acquisition and Reconstruction on Quantitative Image Features,10426507,R56EB031993,"['Address', 'Adopted', 'Adoption', 'Affect', 'Agreement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Characteristics', 'Chest', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Dose', 'Ensure', 'Fostering', 'Goals', 'Head', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Industry', 'Industry Collaboration', 'Infarction', 'Institution', 'Interstitial Lung Diseases', 'Investigation', 'Link', 'Lung nodule', 'Machine Learning', 'Malignant neoplasm of lung', 'Maps', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Network-based', 'Nodule', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physics', 'Play', 'Process', 'Protocols documentation', 'Publications', 'Pulmonary Emphysema', 'Radiation Dose Unit', 'Reproducibility', 'Research', 'Role', 'Scanning', 'Seminal', 'Severity of illness', 'Slice', 'Source', 'Standardization', 'Stroke', 'Sum', 'Techniques', 'Texture', 'Thick', 'Thinness', 'Training', 'Translations', 'Variant', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'base', 'biomarker development', 'biomarker validation', 'brain tissue', 'clinical practice', 'clinical translation', 'computed tomography screening', 'disease diagnosis', 'disease phenotype', 'improved', 'innovation', 'large datasets', 'machine learning algorithm', 'multidisciplinary', 'neural network', 'novel', 'open source', 'open source tool', 'prospective', 'quantitative imaging', 'radiomics', 'reconstruction', 'screening', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R56,2021,611968
"Clinical glaucoma management enabled by visible-light OCT Project Summary This collaborative technology focused project seeks to develop, characterize, and validate visible-light optical coherence tomography (vis-OCT) as a functional tool to transform the clinical management of glaucoma. We will address two unmet needs in clinical glaucoma diagnosis and detection of progression: (1) the ability to measure retinal sublayer structure and (2) to accurately assess local retinal hemoglobin oxygen saturation (sO2). The earliest structural changes in glaucoma are thought to be a retraction of retinal ganglion cell (RGC) dendrites in the inner plexiform layer (IPL). Specifically, this would occur in the outer IPL, where RGC “off” cells synapse. Identification of loss of synapses, either by decreased scattering or by the change in IPL sublayers’ thicknesses, could serve as an earlier and more sensitive biomarker for glaucoma than any other. Measuring retinal sO2 and specific arteriole-venule couplets can determine the oxygen extraction in the regions served by those vessels. Our preliminary data indicate that regions showing damage in glaucomatous eyes have lower oxygen extraction than similar areas in healthy eyes. Our observation suggests that such oxygen extraction abnormalities can be measured well beyond the “floor effect” threshold noted with conventional OCT, allowing assessment of disease beyond the time point that conventional structural OCT becomes insensitive. To achieve our long-term goal, we will focus on new vis-OCT optical system design, imaging protocols, and data processing methodologies to identify both metabolic and ultra-fine anatomical alternations in early glaucoma, both of which are beyond the capabilities of existing imaging technologies. Project Narrative This proposal aims to develop a new clinical imaging modality, referred to as visible-light optical coherence tomography (vis-OCT), to improve the clinical care of glaucoma. The new vis-OCT clinical modality will offer the highest resolution and new functional imaging capabilities to grade the earliest glaucoma damages that are unable to be detected currently.",Clinical glaucoma management enabled by visible-light OCT,10279742,U01EY033001,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomy', 'Angiography', 'Anterior', 'Area', 'Back', 'Biological Markers', 'Biological Sciences', 'Biomedical Engineering', 'Blood Vessels', 'Blood capillaries', 'Caring', 'Cells', 'Clinical', 'Clinical Management', 'Color', 'Data', 'Dendrites', 'Detection', 'Diagnosis', 'Disease', 'Doppler Ultrasound', 'Eye', 'Floor', 'Foundations', 'Functional Imaging', 'Glaucoma', 'Goals', 'Hemoglobin', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Interdisciplinary Study', 'Lasers', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medicine', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Morphologic artifacts', 'Motion', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Oxygen', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Retina', 'Retinal Ganglion Cells', 'Rodent', 'Sampling', 'Scanning', 'Scientist', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissues', 'Ultrafine', 'Variant', 'Visible Radiation', 'arteriole', 'base', 'clinical care', 'clinical imaging', 'clinically translatable', 'computerized data processing', 'data acquisition', 'design', 'early detection biomarkers', 'healthy volunteer', 'image processing', 'imaging capabilities', 'imaging modality', 'improved', 'metabolic imaging', 'neurotoxic', 'programs', 'research clinical testing', 'retinal imaging', 'theories', 'tool', 'ultra high resolution', 'venule']",NEI,NORTHWESTERN UNIVERSITY,U01,2021,698124
"Multiscale theory of synapse function with model reduction by machine learning Project Summary/Abstract  This project constructs a unifying model that links synaptic morphodynamics, the fundamental process of learning and memory in the brain, to the underlying molecular signaling pathways that regulate it. The motivation for this work is a new class of machine learning methods for multiscale modeling that are a promising candidate for linking the disparate spatial and temporal scales involved, from s calcium events in nano-domains to actin reorganization on the order of minutes across a dendritic spine head. Previously, it has only been possible to study each of these scales in isolation. The project brings together experts in (1) modeling the biochemistry at synapses, (2) modeling the growth of the actin cytoskeleton, and (3) developing the theory and algorithms of multiscale modeling with machine learning. The result of this collaboration will be a milestone model in cellular neuroscience that mechanistically connects calcium signaling in dendritic spines to the growth of the actin cytoskeleton in spine remodeling. Currently, there are few models that can e ectively make predictions about actin structure formation based on changes in calcium in ux into the post-synaptic spine. Since the new data-driven models will be more computationally ecient than exact simulations, it will also be possible to incorporate them into coarse-scale models of synapses used in network simulations and in neuroengineering applications. Additionally, the methods developed in this work an important contribution to modeling in cellular neuroscience, particularly because they are data-driven and therefore widely applicable. Finally, the development of a suite of software tools for multiscale modeling with machine learning will catalyze future collaborations and scienti c developments in the neuroscience community, particularly using models that aim to connect cellular phenomena with mechanisms at sub-second resolution. Such models can potentially bene t the development of pharmaceutical targets for learning de cits associated with aging and neurological disorders such as Alzheimers. Project Narrative  The changing shape and size of synapses - synaptic morphodynamics - is the essential process of learning and memory in the brain, but is not well understood because of the wide range of spatial and temporal scales involved. This project mechanistically links the molecular signaling pathways in synapses to the growth of the actin cytoskeleton using a new class of machine learning methods for multiscale modeling. Its result will be a milestone model for understanding learning at cellular and sub-cellular resolution, as well as methods and software for ML- driven multiscale modeling that are broadly applicable in computational neuroscience, including the development of pharmaceutical targets for learning de cits associated with aging and neurological disorders such as Alzheimers.",Multiscale theory of synapse function with model reduction by machine learning,10263653,RF1DA055668,"['3-Dimensional', 'Actins', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Astrocytes', 'Biochemistry', 'Brain', 'Calcium', 'Calcium Oscillations', 'Calcium Signaling', 'Collaborations', 'Communities', 'Computer software', 'Cytoskeleton', 'Data', 'Dendritic Spines', 'Development', 'Docking', 'Ensure', 'Event', 'Future', 'Goals', 'Graph', 'Growth', 'Head', 'Image', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Morphogenesis', 'Motivation', 'Neurosciences', 'Pharmacologic Substance', 'Physics', 'Preparation', 'Process', 'Proteins', 'Reaction', 'Reproducibility', 'Research Personnel', 'Resolution', 'Shapes', 'Signal Pathway', 'Software Tools', 'Structure', 'Synapses', 'System', 'Time', 'Vertebral column', 'Work', 'base', 'calmodulin-dependent protein kinase II', 'computational neuroscience', 'data sharing', 'data tools', 'interoperability', 'machine learning algorithm', 'machine learning method', 'multi-scale modeling', 'nano', 'nervous system disorder', 'open source', 'particle', 'reconstruction', 'sharing platform', 'simulation', 'spatiotemporal', 'success', 'synaptic function', 'theories', 'tool']",NIDA,UNIVERSITY OF CALIFORNIA-IRVINE,RF1,2021,1134550
"Neurophysiology of Human Cortical Epilepsy ABSTRACT Epilepsy remains a devastating and poorly understood illness whose therapies are inadequate for many patients and, in large degree, unchanged for decades. The experiments proposed in this project utilize novel microelectrode recording techniques in patients with epilepsy as well as quantitative features and large data sets to obtain information about the neuronal dynamics underlying epilepsy at an unprecedented level of resolution. The primary hypothesis of this project is that this high resolution, multi-scale information can be applied to separate seizures into different classes which differ in the mechanisms which underlie seizure initiation. More specifically, we will be examining the role and interplay of widespread networks, different cortical layers, infraslow activity and both excitatory and inhibitory single neuronal activity as seizures start. We expect to find substantial differences in these different features of neural action in different kinds of seizures. This knowledge will foster the development of a more complete understanding of seizures and how they can be better detected, predicted and ultimately controlled. PROJECT NARRATIVE The experiments proposed in this project utilize novel microelectrode recording techniques as well as automatic clustering approaches based on quantitative features and large data sets to obtain information about the neuronal dynamics underlying epilepsy at an unprecedented level of resolution. We hope to use these assessments to better understand multiscale neurophysiological processes and demonstrate that there are different types of seizures which have contrasting mechanisms underlying their initiation. This knowledge will foster the development of a more complete understanding of the seizure and how it can be better detected, predicted and treated.",Neurophysiology of Human Cortical Epilepsy,10163920,R01NS062092,"['Adopted', 'Affect', 'Age of Onset', 'Amplifiers', 'Area', 'Behavior', 'Brain', 'Classification', 'Clinical', 'Data', 'Databases', 'Development', 'Epilepsy', 'Etiology', 'Focal Seizure', 'Fostering', 'Foundations', 'Goals', 'High Frequency Oscillation', 'Human', 'Individual', 'Intervention', 'Investigation', 'Knowledge', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Microelectrodes', 'Mind', 'Neurons', 'Patients', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Physiological', 'Physiology', 'Probability', 'Procedures', 'Process', 'Regression Analysis', 'Research', 'Resolution', 'Role', 'Seizures', 'Synapses', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Utah', 'Work', 'base', 'experimental study', 'large datasets', 'neural network', 'neurophysiology', 'novel', 'novel therapeutic intervention', 'personalized approach', 'relating to nervous system', 'response', 'side effect', 'spatiotemporal', 'success', 'surgery outcome', 'voltage']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,613503
Cognitive Heterogeneity in those with high Alzheimer's Disease Risk Project Summary Please see Research Strategy Narrative This supplement grant will extend the original parent grant’s use of deep machine learning methods that were proposed for analyzing the raw digital images from MRI scans and apply them to raw digital voice recordings. This is an advancement over the original methods of extracting measures from the digital voice recordings and instead just analyze them in the raw form.,Cognitive Heterogeneity in those with high Alzheimer's Disease Risk,10404703,RF1AG062109,"['Alzheimer&apos', 's disease risk', 'Cognitive', 'Grant', 'Heterogeneity', 'MRI Scans', 'Measures', 'Methods', 'Research', 'Voice', 'digital', 'digital imaging', 'machine learning method', 'parent grant']",NIA,BOSTON UNIVERSITY MEDICAL CAMPUS,RF1,2021,235089
"Multi-Resolution Docking Methods for Electron Microscopy Summary In the past decade, we have witnessed a revolutionary progress in camera technology and the attainable resolution of macromolecular assemblies via cryogenic electron microscopy (cryo-EM) and in the development of computational algorithms that relate the resulting 3D maps to atomic resolution structures. Whereas single- particle cryo-EM today is capable of directly solving atomic structures of biomolecular assemblies in isolation, electron tomography (ET) in unstained frozen-hydrated samples is widely used to capture the 3D organization of supramolecular complexes in their native (organelle, cell, or tissue) environments. We have identified three inter-related research areas where our computational modeling experience (historically rooted in pre-revolution multi-scale approaches) offers the biggest value to today's post-revolution EM community: (1) medium resolution cryo-EM modeling, (2) the segmentation and denoising of cryo-ET data, and (3) the validation of atomic models and their corresponding maps. The first aim is an extension of promising new ideas in flexible fitting as well as secondary structure prediction for medium resolution maps, which have been our key research areas in the past. medium resolution (5-10Å) maps are still widely used in EM and can be of significant biological importance. This is particularly true in the case of cryo-ET maps, which are harder to read than single particle cryo-EM maps because they often exhibit considerable noise, anisotropic resolution, and anisotropic density variations due to the low dose requirements and the missing wedge in the Fourier space. In the case of tightly packed or crowded macromolecular structures, the fusion of nearby biomolecular densities prevents an automated segmentation of geometric shapes, requiring a labor-intensive manual tracing by human experts. We are currently developing novel computational approaches to provide a more objective strategy for missing wedge correction in homogeneous specimen areas of tomograms. Our hybrid approach combines deconvolution and denoising with template matching in a unified mathematical framework that allows modeling constraints to be imposed in a least-squares optimization process. Our approach can also be extended to the flexible refinement of atomic structures using our damped dynamics flexible fitting approach by tuning the internal point-spread functions to the missing wedge of the ET data. To support these aims, we will quantitatively measure the fitness of an atomic model in local density regions and characterize the fitness of maps with reliable reference structures. The collaborative efforts supported by this grant will include the refinement of cytoskeletal filaments, molecular motors, bacterial chemoreceptor arrays, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established Internet-based mechanisms used by the Situs and Sculptor packages and as plugins for the popular UCSF Chimera graphics program. Project Narrative This project will help biological electron microscopists bridge a broad range of resolution levels, from the atomic to the living organism. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,10264899,R01GM062968,"['3-Dimensional', 'Algorithms', 'Architecture', 'Area', 'Biological', 'Cells', 'Characteristics', 'Chemoreceptors', 'Chimera organism', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational algorithm', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Crowding', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Databases', 'Deposition', 'Development', 'Docking', 'Dose', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Elements', 'Environment', 'Equilibrium', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Human', 'Hybrids', 'Hydration status', 'Internet', 'Laboratories', 'Least-Squares Analysis', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Mathematics', 'Measures', 'Medical', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular Motors', 'Molecular Structure', 'Morphologic artifacts', 'Nature', 'Noise', 'Organelles', 'Organism', 'Pattern', 'Plant Roots', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Specimen', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Tomogram', 'Training', 'Validation', 'Variant', 'Visualization software', 'Work', 'algorithmic methodologies', 'automated segmentation', 'base', 'beta pleated sheet', 'computer code', 'cryogenics', 'data repository', 'deep learning', 'denoising', 'density', 'detection method', 'electron tomography', 'experience', 'feature detection', 'fitness', 'flexibility', 'fundamental research', 'heuristics', 'high standard', 'image reconstruction', 'improved', 'interest', 'learning network', 'macromolecular assembly', 'novel', 'particle', 'prevent', 'process optimization', 'programs', 'reconstruction', 'theories', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2021,312737
"Model Based Deep Learning Framework for Ultra-High Resolution Multi-Contrast MRI Sensitive imaging biomarkers are urgently needed for screening of high‐risk subjects, determine early disease progression, and assess response to therapies in neurodegenerative disorders. The atrophy of several brain regions is an established biomarker in AD, which strongly correlates with AD neuropathology. The accuracy of subfield volumes and cortical thickness estimated from current MRI methods is limited because of the vulnerability to motion, low spatial resolution, low contrast between brain sub‐structures, and dependence of current segmentation frameworks on image quality. Short motion‐compensated MRI protocols to map the human brain at high spatial resolution with multiple contrasts, along with accurate and computationally efficient segmentation algorithms, are urgently needed tor early detection and management of subjects with neurodegenerative disorders. We propose to introduce a 15‐minute motion‐robust 3‐D acquisition and reconstruction scheme to recover whole‐brain MRI data with 0.2 mm isotropic resolution with several different inversion times on 7T, along with segmentation algorithms that are robust to acceleration. The key difference of this framework from current approaches, which rely on MRI data 1 mm resolution, is the quite significant increase in spatial resolution to 0.2 mm as well as the availability of multiple conteasts. This improvement is enabled by innovations in all areas of the data‐processing pipeline, including acquisition, reconstruction, and analysis. These innovations are facilitated and integrated by the model based deep learning framework (MoDL); this framework facilitates the joint exploitation the available prior information, including motion and models for magnetization evolution, with convolutional neural network blocks that learn anatomical information from exemplar data. The successful completion of this framework will yield sensitive biomarkers, which will be considerably less expensive than PET and does not involve radiation exposure. As 7T clinical scanners become more common, this framework can emerge as a screening tool for high‐risk subjects (e.g. APOE, PSEN mutations) and assess progression in patients with short follow‐up duration. Alzheimer’s disease (AD) is now a major public health concern with life expectancy at an all-time high. In US alone, the number of affected patients is expected to triple to 13.8 million by the year 2050. This proposal focuses on the development of an ultra-high resolution multicontrast MRI protocol, with the objective of improving the accuracy of brain atrophy rates in early AD subjects. The successful completion of this proposal will yield a biomarker that is sensitive to early brain changes in AD, which can facilitate early detection in high risk population, measure progression, and quantify the efficacy of brain sparing drugs.",Model Based Deep Learning Framework for Ultra-High Resolution Multi-Contrast MRI,10120861,R01AG067078,"['3-Dimensional', 'Acceleration', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Atrophic', 'Back', 'Biological Assay', 'Biological Markers', 'Brain', 'Brain region', 'Cadaver', 'Clinical', 'Clinical Protocols', 'Data', 'Data Set', 'Dependence', 'Development', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Evolution', 'Financial compensation', 'Goals', 'Graph', 'Hippocampus (Brain)', 'Human', 'Image', 'Joint repair', 'Joints', 'Learning', 'Life Expectancy', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Mutation', 'Neurodegenerative Disorders', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Positron-Emission Tomography', 'Protocols documentation', 'Public Health', 'Radial', 'Radiation exposure', 'Recovery', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Screening procedure', 'Shapes', 'Structure', 'Thick', 'Time', 'Training', 'Translating', 'Treatment Efficacy', 'Validation', 'Variant', 'base', 'brain shape', 'cerebral atrophy', 'cognitive testing', 'convolutional neural network', 'data analysis pipeline', 'deep learning', 'deep learning algorithm', 'direct application', 'entorhinal cortex', 'falls', 'follow-up', 'high risk', 'high risk population', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'mild cognitive impairment', 'nervous system disorder', 'neuropathology', 'novel', 'pre-clinical', 'reconstruction', 'respiratory', 'response', 'screening', 'segmentation algorithm', 'sex', 'ultra high resolution']",NIA,UNIVERSITY OF IOWA,R01,2021,727486
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10242780,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,344862
"University of Chicago Autoimmunity Center of Excellence PROJECT SUMMARY The focus of the University of Chicago ACE (UCACE) is in situ human autoimmunity. During the last funding cycle, we successfully developed techniques to fully characterize the transcriptional state of single B cells and plasmablasts sorted from tissue samples and to pair this with analyses of functional immunoglobulin repertoire. Application of this approach to lupus tubulointerstitial inflammation (TII) and renal acute mixed allograft rejection (AMR) suggest that the activation state, antigenic repertoire and mechanisms of antigenic-driven B cell selection in human inflammation is fundamentally different than that typically observed in secondary lymphoid organs (Collaborative Project). In Celiac disease, B cells expressing transglutaminase 2 (TG2) specific antibodies are massively expanded in the duodenal mucosa. A highly-restricted repertoire of VH genes encode these antibodies, most notably VH5-51. Remarkably, this VH gene is also over-represented in the recirculating IgA+ B cell pool which is rich in anti-microbial activity. These findings suggest a model in which microbial antigens select for pathogenic TG2 reactive antibodies in susceptible hosts (Principle Project). Our second technical innovation is unique to the UCACE (Collaborative Project). Previous work has demonstrated that by quantifying the distance between T and B cells in multicolor confocal images (Cell Distance Mapping, CDM) we could identify competent TFH cells and functional relationships with B cells. We have now implemented a deep convolutional neural network (DCNN) that accurately identifies both cell position and shape in multicolor confocal images. In mice, analysis of the DCNN output (CDM3) indicates that T cell shape as a function of distance from dendritic cells (DCs) discriminates between cognate and non- cognate T cell:DC interactions with a sensitivity and specificity approaching that of two-photon emission microscopy (TPEM). In lupus TII, CDM3 both confirmed that myeloid DCs present antigen to CD4+ T cells in situ and identified plasmacytoid DCs as an important antigen presenting cell (APC) in severe TII. Finally, in the Pilot Project, we are applying microfluidics to develop in vitro culture systems capable of studying cognate interactions between single cells. These projects demonstrate a novel pipeline of methodologies to identify in situ cell populations, characterize their function and quantify the adaptive cell networks through which they cooperate to drive local adaptive immunity and inflammation. PROJECT NARRATIVE The focus of the University of Chicago Autoimmunity Center of Excellence is in situ adaptive autoimmunity. Across autoimmune diseases such as lupus nephritis, rheumatoid arthritis and Celiac disease, local immune responses in affected tissues drive tissue damage leading to overall morbidity and mortality. The purpose of the UCACE is to better understand these in situ adaptive mechanisms, which will enable the development of more effective and less toxic therapies.",University of Chicago Autoimmunity Center of Excellence,10189478,U19AI082724,"['Acute', 'Affect', 'Affinity', 'Anatomy', 'Antibodies', 'Antigen-Presenting Cells', 'Architecture', 'Autoantibodies', 'Autoantigens', 'Autoimmune', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Biological Assay', 'Blood', 'CD4 Positive T Lymphocytes', 'Celiac Disease', 'Cell Communication', 'Cell Shape', 'Cells', 'Chicago', 'Dendritic Cells', 'Development', 'Disease', 'Duodenum', 'Equilibrium', 'Flow Cytometry', 'Funding', 'Genes', 'Genetic Transcription', 'Gluten', 'Helper-Inducer T-Lymphocyte', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunoglobulin A', 'Immunoglobulins', 'In Situ', 'In Vitro', 'Individual', 'Inflammation', 'Inflammatory', 'Kidney', 'Link', 'Lupus', 'Lupus Nephritis', 'Mediating', 'Methodology', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Morbidity - disease rate', 'Mucous Membrane', 'Mus', 'Myelogenous', 'Organ', 'Output', 'Pathogenicity', 'Pilot Projects', 'Plasmablast', 'Population', 'Positioning Attribute', 'Process', 'Rheumatoid Arthritis', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Specificity', 'System', 'T memory cell', 'T-Lymphocyte', 'Techniques', 'Testing', 'Tissue Sample', 'Tissues', 'Universities', 'Work', 'adaptive immunity', 'allograft rejection', 'antimicrobial', 'base', 'confocal imaging', 'convolutional neural network', 'disease heterogeneity', 'high throughput analysis', 'innovation', 'insight', 'macrophage', 'microorganism antigen', 'molecular phenotype', 'mortality', 'novel', 'peripheral blood', 'response', 'secondary lymphoid organ', 'single-cell RNA sequencing', 'transglutaminase 2', 'two-photon']",NIAID,UNIVERSITY OF CHICAGO,U19,2021,324000
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,10194566,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Evaluation', 'Feedback', 'Hand', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'effectiveness testing', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'ventilation', 'virtual reality', 'virtual reality simulator']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2021,314927
"Modulation of Lung Disease by Genetic/Epigenetic Profiling Project Summary/Abstract Therapeutic management of lung disorders hallmarked by the loss-of-function of the Cystic Fibrosis (CF) Transmembrane conductance Regulator (CFTR) leading to CF are challenged by genetic and epigenetic diversity found in the CF population. Given the Precision Medicine Initiative (All of Us for You (https://allofus.nih.gov/) and the large amount of genomic and phenomic diversity found in patients, it is now generally recognized that we must find new approaches to address the complexity in CF presentation in the clinic. This will require an understanding of fundamental principles dictating disease onset at birth, defined by familial genetic variation, and its progression, influenced by epigenetic programs, both unique to the individual. This proposal is about understanding the role of genetic and epigenetic diversity in CF in response to Histone DeACetylase (HDAC) activity. We have shown these relationships to be responsive to the activity of HDACs, proteins that manage the acetylation/deacetylation balance of the genome and the proteome (the epigenome) to integrate the complex functions linking the genome to the proteome and phenome. Based on the premise that the genome and epigenome are sensitive to manipulation(s) that will favor increased functionality of the CFTR variant fold, the objective of this proposal is to mechanistically define the impact of HDAC modulation on CFTR function observed at the bench and the bedside. We hypothesize that CF can be best understood based on the rationale that disease can be defined by the collective of variation found in the CF population that alters CFTR sequence-to-function-to-structure relationships in the individual as now described using Variation Spatial Profiling (VSP) and the new principle of Spatial CoVariance (SCV) (Wang and Balch, 2018, In press). It is the objective of this proposal to apply VSP/SCV to analysis of the role of the epigenome in CF. Key goals to be achieved in this proposal are to 1) define molecular, cellular and physiological states that 2) describe the role of genetic/epigenetic/proteomic diversity in the CF population to 3) provide a sequence-to-function-to-structure characterization of disease in the individual. Aim 1 will explore the impact of HDAC inhibitors (HDACi) to define, from a biochemical/genetic diversity perspective, how variation across the entire CF population will respond to rebalancing of acetylation/deacetylation dynamics. Aim 2 will focus on the role of HDAC7 in the management of CF genetic diversity using molecular, biochemical and cellular approaches. Aim 3 will analyze the role of select HDAC7-sensitive CFTR interactors to address their role in the management of CF variation from an epigenetic perspective. We hypothesize that the completion of these Aims will describe relationships in the population that define the epigenome-linked genome features that impact progression of CF in the individual. Our integrated genome/epigenome/proteome platform will advance our understanding of the contribution of genetic diversity in the progression and management of CF as a complex disease. Project Narrative CF is a complex loss-of-function disease caused by genetic and epigenetic variation in the Cystic Fibrosis Transmembrane conductance Regulator (CFTR). We will focus on understanding spatial relationships defined by genetic diversity across the CF population that are sensitive to Histone DeACetylase (HDAC) activity to understand the role of the acetylation/deacetylation balance in facilitating function in the individual. We will use a combination of genomic/epigenomic/proteomic approaches based on the principles of Variation Spatial Profiling (VSP) and Spatial CoVariance (SCV) to dissect the role of HDAC in integrated pathways that affect CFTR variant synthesis, folding, trafficking and stability/function at the cell surface that may be responsive to chemical and/or biological manipulation of the epigenome.",Modulation of Lung Disease by Genetic/Epigenetic Profiling,10134401,R01HL095524,"['Acetylation', 'Address', 'Affect', 'Amino Acids', 'Automobile Driving', 'Biochemical', 'Biochemical Genetics', 'Biological', 'Biology', 'Birth', 'Cell Death', 'Cell surface', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Complex', 'Cystic Fibrosis', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Deacetylation', 'Disease', 'Disease Progression', 'Environment', 'Epigenetic Process', 'Equilibrium', 'Fibrosis', 'Funding', 'Gaussian model', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'HDAC7 histone deacetylase', 'Health', 'Histone Deacetylase', 'Histone Deacetylase Inhibitor', 'Human', 'Immune', 'Individual', 'Inflammatory Response', 'Lead', 'Link', 'Lung diseases', 'Machine Learning', 'Membrane', 'Mendelian disorder', 'Modification', 'Molecular', 'Mucous body substance', 'Onset of illness', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Role', 'Structure', 'System', 'Therapeutic', 'Tissues', 'Variant', 'base', 'bench to bedside', 'cystic fibrosis patients', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'genomic platform', 'healthspan', 'insight', 'loss of function', 'novel strategies', 'phenome', 'phenomics', 'programs', 'response', 'spatial relationship', 'success', 'trafficking', 'transcription factor']",NHLBI,SCRIPPS RESEARCH INSTITUTE,R01,2021,483750
"Robust biomimetic models of human legs to solve high-dimensional real-time control problems Project Summary  Anatomically validated musculoskeletal models of human limbs computed faster than real-time are tools that will help advance the control of neuroprosthetics, rehabilitation, and the study of motor control principles. However, the current state-of-the-art models cannot be both accurate and fast. We propose to develop a new generation of validated real-time human leg models with musculoskeletal dynamics that are robust over the full range of multidimensional motion. The first aim is to validate a lower-limb model in the full range of static postures. The second aim is to validate a lower-limb model during dynamic locomotor tasks.  Building on our previous work, we will use OpenSim model repository as a starting point for the iterative process of validating the muscle anatomy and function using published anatomical data. We expect to recreate the full range of leg postures with the validated model. We will then collect data during locomotor tasks performed by healthy humans on the split-belt treadmill with simultaneous re- cordings of ground reaction forces, full-body motion capture, and surface electromyography from rep- resentative leg muscles. The model will be validated over a rich experimental dataset for locomotor pat- terns required in asymmetric stepping on a self-paced treadmill. We expect to validate the dynamic model by estimating in real-time the observed full body kinematics from muscle activity and ground reaction forces. The inverse solutions will allow us to estimate the ongoing spatiotemporal patterns of muscle activity.  At the conclusion of this study we will develop the detailed lower-limb model with high-di- mensional robust muscle path simulations to predict limb motion in real-time. The outcomes of this proposal will inform future work on the use of the real-time musculoskeletal models for the develop- ment of augmentation devices and the clinical assessment of locomotor deficits. Project Narrative The significance of this project is that it will address the major challenges in achieving intuitive human-computer interactions by allowing the simulation of high-dimensional muscle dynamics in real-time. The main innovation of this proposal is the rigorous validation of human leg model across large anthropomorphic variations (due to age and sex) and the robust performance using novel method for musculoskeletal simulations.",Robust biomimetic models of human legs to solve high-dimensional real-time control problems,10208921,R03HD099426,"['Address', 'Age', 'Anatomy', 'Articular Range of Motion', 'Basic Science', 'Behavioral', 'Biological', 'Biomimetics', 'Clinical', 'Clinical assessments', 'Data', 'Data Set', 'Development', 'Devices', 'Electric Stimulation', 'Electromyography', 'Engineering', 'Ensure', 'Evaluation', 'Exercise Physiology', 'Failure', 'Funding Opportunities', 'Future', 'Generations', 'Goals', 'Grant', 'Hand', 'Human', 'Intuition', 'Joints', 'Leg', 'Length', 'Limb Prosthesis', 'Limb structure', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Morphology', 'Motion', 'Movement', 'Muscle', 'Musculoskeletal', 'Musculoskeletal System', 'Neuromechanics', 'Orthopedics', 'Outcome', 'Participant', 'Pathway interactions', 'Pattern', 'Performance', 'Physical therapy', 'Polynomial Models', 'Posture', 'Process', 'Prosthesis', 'Publishing', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Signal Transduction', 'Slide', 'Speed', 'Surface', 'Technology', 'Testing', 'Time', 'Upper Extremity', 'Validation', 'Variant', 'Work', 'arm', 'base', 'computer human interaction', 'high dimensionality', 'human model', 'innovation', 'kinematics', 'locomotor deficit', 'locomotor tasks', 'model development', 'motor control', 'neuroprosthesis', 'novel', 'real time model', 'relating to nervous system', 'repository', 'sex', 'simulation', 'spatiotemporal', 'tool', 'treadmill']",NICHD,WEST VIRGINIA UNIVERSITY,R03,2021,76000
"Fast motion-robust fetal neuroimaging with MRI PROJECT SUMMARY/ABSTRACT Fetal-brain magnetic resonance imaging (MRI) has become an invaluable tool for studying the early development of the brain and can resolve diagnostic ambiguities that may remain after routine ultrasound exams. Unfortunately, high levels of fetal and maternal motion (1) limit fetal MRI to rapid two-dimensional (2D) sequences and frequently introduce dramatic artifacts such as (2) image misorientation relative to the standard sagittal, coronal, axial planes needed for clinical assessment and (3) partial to complete signal loss. These factors lead to the inefficient practice of repeating ~30 s stack-of-slices acquisitions until motion-free images have been obtained. Throughout the session, technologists manually adjust the orientation of scans in response to motion, and about 38% of datasets are typically discarded. Thus, subject motion is the fundamental impediment to reaping the full benefits of MRI for answering clinical and investigational questions in the fetus. The overarching goal of this project is to overcome the challenges posed by motion by exploiting innovations in deep learning, which have enabled image-analysis algorithms with unprecedented speed and reliability. We propose to integrate these into the MRI acquisition pipeline to unlock the potential of fetal MRI. We will develop practical pulse-sequence technology for automated and dynamically motion-corrected fetal neuroimaging without the need for external hardware or calibration. We hypothesize that this will radically improve the quality and success rates of clinical and research studies, while dramatically reducing patient discomfort and cost. We propose as Aim 1 to eradicate (2) the vulnerability of acquisitions to image-brain misorientation with rapid, automated prescription of standard anatomical planes. In Aim 2, we propose to address (3) motion during the scan with real-time correction of fetal-head motion. An anatomical stack-of-slices acquisition will be interleaved with volumetric navigators. These will be used to measure motion as it happens in the scanner and to adaptively update the slice tilt/position. We propose as Aim 3 to develop a 3D radial sequence and estimate motion between subsets of radial spokes for real-time self-navigation. Adaptively updating the orientation of spokes and selectively re-acquiring corrupted subsets at the end of the scan will enable 3D imaging of the fetal brain (1). Since the applicant has a physics background, the proposed training program at MIT and HMS will focus on deep learning and fetal development/neuroscience during the K99 phase to develop the skills needed for transitioning to independence in the R00 phase. The applicant’s goal is to become a fetal image acquisition and analysis scientist acting as bridge between deep learning, MRI and clinical fetal-imaging applications to shift the boundaries of what is currently possible with state-of-the-art technology. Fulfilling the research aims will promote this, as it will result in a practical framework for automation and motion correction, applicable to a wide variety of fetal neuroimaging sequences. PROJECT NARRATIVE Subject motion is the fundamental impediment to reaping the full benefits of fetal-brain magnetic resonance imaging, as it frequently produces images with dramatic artifacts. The goal of this project is to exploit innovations in deep learning and integrate them into the acquisition pipeline to overcome the challenges posed by motion in fetal neuroimaging studies. This will be achieved by using fast, automated scan prescription of standard anatomical planes and by adaptively updating the acquisition as motion happens in the scanner, based on sub-second navigator scans interleaved with the imaging sequence.",Fast motion-robust fetal neuroimaging with MRI,10197182,K99HD101553,"['3-Dimensional', 'Address', 'Algorithmic Analysis', 'Amniotic Fluid', 'Anatomy', 'Automation', 'Brain', 'Brain imaging', 'Calibration', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Data Set', 'Development', 'Diagnostic', 'Echo-Planar Imaging', 'Fetal Development', 'Fetus', 'Geometry', 'Goals', 'Head', 'Image', 'Individual', 'Label', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measures', 'Morphologic artifacts', 'Motion', 'Neurosciences', 'Patients', 'Phase', 'Physics', 'Physiologic pulse', 'Population', 'Positioning Attribute', 'Radial', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Sampling', 'Scanning', 'Scientist', 'Signal Transduction', 'Slice', 'Speed', 'Technology', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Training Programs', 'Translating', 'Ultrasonography', 'Update', 'Work', 'base', 'clinical investigation', 'convolutional neural network', 'cost', 'deep learning', 'echo detection', 'experience', 'fetal', 'image archival system', 'improved', 'innovation', 'interest', 'neuroimaging', 'novel', 'prospective', 'radiologist', 'reconstruction', 'repaired', 'research study', 'response', 'skills', 'success', 'tool', 'two-dimensional']",NICHD,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,109671
"Quantifying body shape in pediatric clinical research Project Summary/Abstract. Excess adiposity is associated with metabolic changes that significantly increase the risk of developing 13 types of cancer. It is estimated that up to 20% of cancer cases are caused by obesity and that obesity prevention can play a significant role in the reduction of cancer incidence. Among obese adolescents, the most rapid weight gain has been shown to occur between 2 and 6 years of age. Despite clear connections between these factors and obesity risk, the study of obesity in early childhood is limited by the lack of body composition technologies appropriate for this age range. The long term goal of the Shape Up! Keiki is 1) to provide pediatric phenotype descriptors of health derived from detailed body shape scans from high-speed and high depth resolution 3D cameras, and 2) to provide the tools to visualize and quantify body shape in research and clinical practice. Our approach addresses technology issues that have hindered body composition research in this age range including participants' inability to hold still, follow directions, small body size, and rapid fluid shifts. To develop our body composition models, we will recruit 360 ethnically-diverse children from birth to 5 years stratified by sex and BMI-Z. Our central hypothesis is that optical estimates of body composition suitably represent a 5-compartment (5C) body composition model for studies of adiposity and health in young children and are superior to that of simple anthropometry and demographics. Our specific aims and subaims are as follows: 1) identify the statistical shape descriptors from 3DO scans that best represent 5-compartment body composition in an ethnically-diverse pediatric population, 1(a) identify the relationships that best link 3DO shape descriptors of body subregions (arms, legs, trunk), and matching volumes and body composition measures, 1(b) calibrate automated 3DO anthropometry to clinically relevant girths and lengths, Exploratory) identify accessible combinations of 3DO and TBW that can be calibrated to criterion 5C measures of fat and hydration, 2) identify the factors that define the precision of accessible 3D optical body composition estimates to monitor change in body composition and metabolic health interventions, 3) contrast the association of body shape, 3DO, and 5C criterion body composition to pediatric health indicators including clinically relevant exposures (SES, nursing duration, birth method, nutrition) and development. The rationale for this study is that early life access to accurate body composition data will enable identification of factors that increase obesity, metabolic disease, and cancer risk, and provide a means to target interventions to those that would benefit. The expected outcome is that our findings would be immediately applicable to accessible gaming and imaging sensors found on modern computers. Project Narrative. The proposed research is relevant to public health because they have the potential to provide a better understanding of which young children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Quantifying body shape in pediatric clinical research,10299250,R01HD103885,"['3-Dimensional', '6 year old', 'Address', 'Adolescent obesity', 'Adult', 'Age', 'Air', 'Anthropometry', 'Award', 'Biometry', 'Birth', 'Body Composition', 'Body Size', 'Body Water', 'Body mass index', 'Cardiovascular Diseases', 'Characteristics', 'Child', 'Childhood', 'Clinical Research', 'Computers', 'Data', 'Descriptor', 'Development', 'Diagnosis', 'Dietary Factors', 'Discipline of Nursing', 'Disease', 'Disease Resistance', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fluid Shifts', 'Goals', 'Grant', 'Health', 'Hydration status', 'Image', 'Incidence', 'Institutes', 'Insulin Resistance', 'International', 'Intervention', 'Investigation', 'Leg', 'Length', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Monitor', 'Movement', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Obesity', 'Optics', 'Outcome', 'Participant', 'Personal Satisfaction', 'Phenotype', 'Play', 'Plethysmography', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Resources', 'Risk', 'Role', 'Scanning', 'Scientist', 'Shapes', 'Spectrum Analysis', 'Speed', 'Study models', 'Technology', 'Thinness', 'Time', 'United States National Institutes of Health', 'Weight', 'arm', 'cancer risk', 'cancer type', 'clinical practice', 'clinically relevant', 'demographics', 'disorder prevention', 'disorder risk', 'early childhood', 'ethnic diversity', 'experience', 'high risk', 'human disease', 'metabolomics', 'muscle form', 'nutrition', 'obesity in children', 'obesity prevention', 'obesity risk', 'pediatrician', 'predictive modeling', 'rapid weight gain', 'recruit', 'sensor', 'sex', 'tool', 'whole body imaging']",NICHD,UNIVERSITY OF HAWAII AT MANOA,R01,2021,659305
"Vector Flow Velocity Imaging of Human Placenta using Angle-resolved Ultrasound and Deep Learning This proposal describes a five-year research and career development program to prepare Dr. You Li for a career as an independent investigator. The program will build upon Dr. Li’s multidisciplinary background as a biomedical engineer, trained in medical ultrasound imaging, by providing expertise in obstetrics, the application of machine learning in medical imaging, and translational research. The PI will be mentored at Stanford University by Drs. Jeremy Dahl (primary mentor, medical ultrasound), Virginia Winn (co-mentor, obstetrics and gynecology), and Matthew Lungren (co-mentor, radiology and artificial intelligence). Human placenta plays a vital role in human development, and its abnormalities may cause significant consequences to both the mother and the fetus. Preeclampsia, in particular, is a common disorder that affects approximately 1 in 33 pregnancies in the United States and accounts for 18% of pregnancy-associated maternal death. Many placental abnormalities, including preeclampsia, are related to the hemodynamics and growth of vessels in placenta. Despite the severe consequences of placental abnormalities, our understanding in placenta and placental abnormalities is lacking. One primary reason for the gap of knowledge is the inability to observe the hemodynamics of placenta in vivo. Currently, B-mode and Doppler ultrasound are the primary imaging modalities in imaging the placenta and its vasculature. However, significant limitations exist in the ability of Doppler ultrasound to visualize and measure detailed flow velocities in placental vasculature. It has low sensitivity to small vessels in the placenta, including spiral arteries and chorionic villi, and can only measure flow velocity along the ultrasound beam direction, requiring tedious manual angle correction for flow along any of the visible vessels if quantitative information is desired. These limitations make conventional Doppler ultrasound poorly suited for imaging the hemodynamics of the complex vasculature of human placenta. To provide full and detailed characterization of placental hemodynamics, we propose to develop a vector flow velocity imaging technique using deep neural network models and multiple angle plane wave ultrasound transmits. This technique will be able to quantitatively image both the flow velocity magnitudes and flow directions of millimeter-diameter vessels in human placenta over a large field of view. Aim 1 and 2 will be focused on the technical development of the technique to provide a semi- real-time vector flow imaging system based on a research ultrasound scanner, paving way for Aim 3, which will be focused on validating the clinical value of the technique on a pilot clinical study to image the hemodynamics in spiral arteries and chorionic villi of pregnant women. Successful completion of the project will provide a novel technique for the scientific and early clinical assessment of placental hemodynamics, development, and abnormalities including the development of the villous tree structure, placenta accreta, preeclampsia, and placental insufficiency. During the project, the PI will receive training in machine learning, obstetrics, translational research, and career development skills, which will transition the PI into an independent faculty. Our understanding in human placenta and its abnormalities is limited, because we do not have a medical imaging device to non-invasively observe the blood flow in the small vessels of human placenta in vivo. To fill this gap, we propose to build a semi-real-time ultrasound vector flow velocity imaging system using deep learning models to provide detailed and quantitative imaging of the flow velocity magnitudes and flow directions in human placenta. The successful completion of the project will provide a novel ultrasound imaging technology for the scientific investigation and early clinical assessment of placental development and abnormalities.",Vector Flow Velocity Imaging of Human Placenta using Angle-resolved Ultrasound and Deep Learning,10371743,K99HD105019,"['Acoustics', 'Affect', 'Artificial Intelligence', 'Biology', 'Biomedical Engineering', 'Blood', 'Blood flow', 'Caliber', 'Chorionic villi', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Complex', 'Data', 'Data Science', 'Development', 'Discipline of obstetrics', 'Disease', 'Doppler Ultrasound', 'Faculty', 'Fetal Growth Retardation', 'Fetus', 'Future', 'Growth', 'Gynecology', 'Human', 'Human Development', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Investigation', 'Knowledge', 'Lateral', 'Machine Learning', 'Manuals', 'Maternal Mortality', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'Mothers', 'Network-based', 'Neural Network Simulation', 'Noise', 'Output', 'Pattern', 'Physiological', 'Placenta', 'Placenta Accreta', 'Placenta Diseases', 'Placental Insufficiency', 'Placentation', 'Play', 'Pre-Eclampsia', 'Pregnancy', 'Pregnant Women', 'Premature Labor', 'Program Development', 'Radiology Specialty', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Spiral Artery of the Endometrium', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Translational Research', 'Trees', 'Ultrasonic wave', 'Ultrasonography', 'Uncertainty', 'United States', 'Universities', 'Villous', 'Virginia', 'Visualization', 'base', 'career', 'career development', 'cohort', 'deep learning', 'deep neural network', 'design', 'early pregnancy', 'fetal', 'hemodynamics', 'human imaging', 'imaging modality', 'imaging system', 'in vivo', 'millimeter', 'multidisciplinary', 'neural network', 'neural network architecture', 'new technology', 'novel', 'programs', 'quantitative imaging', 'research and development', 'simulation', 'skill acquisition', 'skills', 'technique development', 'tenure track', 'tool', 'vector']",NICHD,STANFORD UNIVERSITY,K99,2021,127673
"Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support,10393815,R01GM109718,"['Communicable Diseases', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Economic Burden', 'Economics', 'Epidemic', 'Geography', 'Growth', 'Health', 'Health Personnel', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Methodology', 'Methods', 'Modeling', 'Policy Maker', 'Population', 'Privatization', 'Public Health', 'Resource Allocation', 'Resources', 'Risk', 'Science', 'Source', 'System', 'Techniques', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Work', 'base', 'data mining', 'health care delivery', 'improved', 'novel', 'provider networks', 'statistics', 'undergraduate student']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,11253
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,10197938,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process', 'vaccine hesitancy']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,321062
"A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images Abstract  The ability of accurate localize and characterize cells in light sheet fluorescence microscopy (LSFM) image is indispensable for shedding new light on the understanding of three dimensional structures of the whole brain. In our previous work, we have successfully developed a 2D nuclear segmentation method for the nuclear cleared microscopy images using deep learning techniques. Although the convolutional neural networks show promise in segmenting cells in LSFM images, our previous work is confined in 2D segmentation scenario and suffers from the limited number of annotated data. In this project, we aim to develop a high throughput 3D cell segmentation engine, with the focus on improving the segmentation accuracy and generality. First, we will develop a cloud based semi-automatic annotation platform using the strength of virtual reality (VR) and crowd sourcing. The user-friendly annotation environment and stereoscopic view in VR can significantly improve the efficiency of manual annotation. We design a semi-automatic annotation workflow to largely reduce human intervention, and thus improve both the accuracy and the replicability of annotation across different users. Enlightened by the spirit of citizen science, we will extend the annotation software into a crowd sourcing platform which allows us to obtain a massive number of manual annotations in short time. Second, we will develop a fully 3D cell segmentation engine using 3D convolutional neural networks trained with the 3D annotated samples. Since it is often difficult to acquire isotropic LSFM images, we will further develop a super resolution method to impute a high resolution image to facilitate the 3D cell segmentation. Third, we will develop a transfer learning framework to make our 3D cell segmentation engine general enough to the application of novel LSFM data which might have significant gap of image appearance due to different imaging setup or clearing/staining protocol. This general framework will allow us to rapidly develop a specific cell segmentation solution for new LSFM data with very few or even no manual annotations, by transferring the existing 3D segmentation engine that has been trained with a sufficient number of annotated samples. Fourth, we will apply our computational tools to several pilot neuroscience studies: (1) Investigating how topoisomerase I (one of the autism linked transcriptional regulators) regulates brain structure, and (2) Investigating genetic influence on cell types in the developing human brain by quantifying the number of progenitor cells in fetal cortical tissue. Successful carrying out our project will have wide-reaching impact in neuroscience community in visualizing and analyzing complete cellular resolution maps of individual cell types within healthy and disease brain. The improved cell segmentation engine in 3D allows scientists from all over the world to share and process each other’s data accurately and efficiently, thus increasing reproducibility and power. Project Narrative This proposal aims to develop a next generation cell segmentation engine for the whole brain tissue cleared images. Our proposed work is built upon our previous 2D nuclear segmentation project using deep learning techniques. However, we found that our current computational tool is limited in 2D segmentation scenario and insufficient of annotated training samples. To address these limitations, we will first develop a cloud-based semi-automatic annotation tool with the capacity of virtual reality. Our annotation tool is designed to be cross- platform, which allows us to partner with “SciStarter” (the largest citizen science projects in the world) and acquire large amount of cell annotations from the science enthusiastic volunteers. Meanwhile, we will develop next generation 3D cell segmentation engine using an end-to-end fully connected convolution neural network. To facilitate 3D cell segmentation, we will also develop a super resolution method to impute an isotropic high- resolution image from a low-resolution microscopy image. After the development of 3D cell segmentation engine, we will continue to improve its generality by developing a transfer learning framework which enables us to rapidly deploy our 3D cell segmentation engine to the novel microscopy images without the time-consuming manual annotation step. Finally, we will apply our segmentation tool to visualize and quantify brain structure differences within genetically characterized mouse and human brain tissue at UNC neuroscience center. In the end of this project, we will release the software (both binary program and source code) and the 3D cell annotations, in order to facilitate the similar neuroscience studies in other institutes. Considering the importance of high throughput computational tools in quantifying three dimensional brain structure, this cutting- edge technique will be very useful in neuroscience research community.",A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images,10244882,R01NS110791,"['3-Dimensional', 'Address', 'Affect', 'Anecdotes', 'Appearance', 'Area', 'Biological', 'Brain', 'Brain Diseases', 'Brain region', 'Cell Nucleus', 'Cells', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Development', 'Environment', 'Evaluation', 'Fluorescence Microscopy', 'Genetic', 'Genetic Transcription', 'Genotype', 'Gold', 'Human', 'Image', 'Individual', 'Institutes', 'Intervention', 'Knock-out', 'Label', 'Lead', 'Learning', 'Light', 'Link', 'Manuals', 'Maps', 'Methods', 'Microscopy', 'Modeling', 'Mus', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Nuclear', 'Performance', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Reproducibility', 'Resolution', 'Sampling', 'Science', 'Scientist', 'Shapes', 'Slice', 'Source Code', 'Stains', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Type I DNA Topoisomerases', 'Visual', 'Visualization', 'Work', 'annotation  system', 'autism spectrum disorder', 'base', 'bioimaging', 'brain tissue', 'cell type', 'citizen science', 'cloud based', 'computerized tools', 'contrast imaging', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'design', 'fetal', 'flexibility', 'high resolution imaging', 'improved', 'microscopic imaging', 'next generation', 'novel', 'programs', 'stem cells', 'stereoscopic', 'success', 'three dimensional structure', 'tissue processing', 'tool', 'two-dimensional', 'user-friendly', 'virtual reality', 'volunteer']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,335104
"A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images Abstract  The ability of accurate localize and characterize cells in light sheet fluorescence microscopy (LSFM) image is indispensable for shedding new light on the understanding of three dimensional structures of the whole brain. In our previous work, we have successfully developed a 2D nuclear segmentation method for the nuclear cleared microscopy images using deep learning techniques. Although the convolutional neural networks show promise in segmenting cells in LSFM images, our previous work is confined in 2D segmentation scenario and suffers from the limited number of annotated data. In this project, we aim to develop a high throughput 3D cell segmentation engine, with the focus on improving the segmentation accuracy and generality. First, we will develop a cloud based semi-automatic annotation platform using the strength of virtual reality (VR) and crowd sourcing. The user-friendly annotation environment and stereoscopic view in VR can significantly improve the efficiency of manual annotation. We design a semi-automatic annotation workflow to largely reduce human intervention, and thus improve both the accuracy and the replicability of annotation across different users. Enlightened by the spirit of citizen science, we will extend the annotation software into a crowd sourcing platform which allows us to obtain a massive number of manual annotations in short time. Second, we will develop a fully 3D cell segmentation engine using 3D convolutional neural networks trained with the 3D annotated samples. Since it is often difficult to acquire isotropic LSFM images, we will further develop a super resolution method to impute a high resolution image to facilitate the 3D cell segmentation. Third, we will develop a transfer learning framework to make our 3D cell segmentation engine general enough to the application of novel LSFM data which might have significant gap of image appearance due to different imaging setup or clearing/staining protocol. This general framework will allow us to rapidly develop a specific cell segmentation solution for new LSFM data with very few or even no manual annotations, by transferring the existing 3D segmentation engine that has been trained with a sufficient number of annotated samples. Fourth, we will apply our computational tools to several pilot neuroscience studies: (1) Investigating how topoisomerase I (one of the autism linked transcriptional regulators) regulates brain structure, and (2) Investigating genetic influence on cell types in the developing human brain by quantifying the number of progenitor cells in fetal cortical tissue. Successful carrying out our project will have wide-reaching impact in neuroscience community in visualizing and analyzing complete cellular resolution maps of individual cell types within healthy and disease brain. The improved cell segmentation engine in 3D allows scientists from all over the world to share and process each other’s data accurately and efficiently, thus increasing reproducibility and power. Project Narrative This proposal aims to develop a next generation cell segmentation engine for the whole brain tissue cleared images. Our proposed work is built upon our previous 2D nuclear segmentation project using deep learning techniques. However, we found that our current computational tool is limited in 2D segmentation scenario and insufficient of annotated training samples. To address these limitations, we will first develop a cloud-based semi-automatic annotation tool with the capacity of virtual reality. Our annotation tool is designed to be cross- platform, which allows us to partner with “SciStarter” (the largest citizen science projects in the world) and acquire large amount of cell annotations from the science enthusiastic volunteers. Meanwhile, we will develop next generation 3D cell segmentation engine using an end-to-end fully connected convolution neural network. To facilitate 3D cell segmentation, we will also develop a super resolution method to impute an isotropic high- resolution image from a low-resolution microscopy image. After the development of 3D cell segmentation engine, we will continue to improve its generality by developing a transfer learning framework which enables us to rapidly deploy our 3D cell segmentation engine to the novel microscopy images without the time-consuming manual annotation step. Finally, we will apply our segmentation tool to visualize and quantify brain structure differences within genetically characterized mouse and human brain tissue at UNC neuroscience center. In the end of this project, we will release the software (both binary program and source code) and the 3D cell annotations, in order to facilitate the similar neuroscience studies in other institutes. Considering the importance of high throughput computational tools in quantifying three dimensional brain structure, this cutting- edge technique will be very useful in neuroscience research community.",A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images,10463036,R01NS110791,"['3-Dimensional', 'Address', 'Affect', 'Anecdotes', 'Appearance', 'Area', 'Biological', 'Brain', 'Brain Diseases', 'Brain region', 'Cell Nucleus', 'Cells', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Development', 'Environment', 'Evaluation', 'Fluorescence Microscopy', 'Genetic', 'Genetic Transcription', 'Genotype', 'Gold', 'Human', 'Image', 'Individual', 'Institutes', 'Intervention', 'Knock-out', 'Label', 'Lead', 'Learning', 'Light', 'Link', 'Manuals', 'Maps', 'Methods', 'Microscopy', 'Modeling', 'Mus', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Nuclear', 'Performance', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Reproducibility', 'Resolution', 'Sampling', 'Science', 'Scientist', 'Shapes', 'Slice', 'Source Code', 'Stains', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Type I DNA Topoisomerases', 'Visual', 'Visualization', 'Work', 'annotation  system', 'autism spectrum disorder', 'base', 'bioimaging', 'brain tissue', 'cell type', 'citizen science', 'cloud based', 'computerized tools', 'contrast imaging', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'design', 'fetal', 'flexibility', 'high resolution imaging', 'improved', 'microscopic imaging', 'next generation', 'novel', 'programs', 'stem cells', 'stereoscopic', 'success', 'three dimensional structure', 'tissue processing', 'tool', 'two-dimensional', 'user-friendly', 'virtual reality', 'volunteer']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,233250
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,10138039,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Lymphatic System', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'detection limit', 'disability', 'effectiveness evaluation', 'geometric structure', 'in vivo', 'lymphatic circulation', 'lymphatic vasculature', 'lymphatic vessel', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,534438
"Development of advanced voltammetric method for basal neurotransmitter level measurement PROJECT SUMMARY We propose to develop and optimize an advanced neurochemical recording technique that would be able to measure relatively rapid physiologically representative second-to-second changes in basal concentrations of specific neurochemicals, such as dopamine, in the brains of awake behaving animals. Microdialysis, a commonly used in vivo sampling technique, is able to measure changes that occur in basal levels. However, in practice the sampling timescale is significantly limited to minute-to-minute changes and it suffers from poor spatial resolution and induces significant tissue damage. As well, conventional in vivo electrochemical recording techniques, such as fast-scan cyclic voltammetry, are intrinsically limited to measuring phasic (stimulation-induced) changes in neurochemical concentrations and not changes in basal concentrations. The proposed electrochemical technique we call Multiple Cyclic Square Wave Voltammetry (M-CSWV) will enable second-to-second measurements of basal extracellular levels of neurochemicals with exceptional spatial resolution, sensitivity, specificity, and minimal tissue disturbance. This proposal leverages our unique expertise in neuroscience, electrochemistry, software development, and engineering to develop and validate this novel neurochemical recording technology for broad use in basic neuroscience research, clinical brain neuromodulation, and a variety of electrochemical applications. Our initial animal studies will guide and inform the application of our investigational technique for use by the general neuroscience and medical community. Our proposal seeks to (1) establish M-CSWV as a reliable research tool that is capable of identifying and quantifying basal dopamine extracellular levels in vivo with unsurpassed sensitivity and selectivity; and (2) validate the use of M-CSWV for in vivo chronic selective measurement of basal dopamine concentrations and application in an animal model of drug-induced neurochemical sensitization. PROJECT NARRATIVE Neurochemicals in the brain, such as dopamine, transmit information between neurons to process input and produce normal behavior, but that occasionally when their levels are disrupted lead to neurologic and psychiatric disorders. We have developed a novel neurochemical recording method called Multi-Cyclic Square Wave Voltammetry that for the first time measures basal neurochemical concentrations in real-time in the brain with single-second time resolution and unprecedented chemical selectivity. Furthermore, we propose to standardize this novel technique for use in neuroscience research directed to understanding the neurochemical basis of neuropsychiatric diseases by demonstrating its capability to quantify basal levels in a well-known animal model of drug-induced neurochemical and behavioral sensitization.",Development of advanced voltammetric method for basal neurotransmitter level measurement,10246862,R01NS112176,"['Acute', 'Adsorption', 'Advanced Development', 'Amphetamines', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Biological', 'Brain', 'Cells', 'Characteristics', 'Chemicals', 'Chronic', 'Clinical', 'Communities', 'Computer software', 'Corpus striatum structure', 'Data', 'Data Analyses', 'Dialysis procedure', 'Dimensions', 'Disease', 'Dopamine', 'Dopaminergic Agents', 'Drug Modelings', 'Electrochemistry', 'Engineering', 'Equilibrium', 'Future', 'Goals', 'Implant', 'In Vitro', 'Injections', 'Investigation', 'Lead', 'Link', 'Literature', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Methods', 'Microdialysis', 'Microelectrodes', 'Modeling', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Neurotransmitters', 'Periodicity', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Physiological', 'Principal Component Analysis', 'Process', 'Publishing', 'Rattus', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Slice', 'Spectrum Analysis', 'Standardization', 'Stimulus', 'Surface', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Validation', 'Variant', 'awake', 'base', 'behavioral sensitization', 'carbon fiber', 'electric impedance', 'extracellular', 'in vivo', 'kinetic model', 'method development', 'nervous system disorder', 'neurochemistry', 'neuropsychiatric disorder', 'neuroregulation', 'neurotransmission', 'noradrenergic', 'novel', 'phase change', 'receptor', 'response', 'software development', 'temporal measurement', 'tool', 'two-dimensional']",NINDS,MAYO CLINIC ROCHESTER,R01,2021,334425
"Quantitative MR Imaging of Vascular Factors in Parkinsons Disease Abstract Vascular health has been shown to be an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases. Hence, the ability to measure reliably and quantitatively early hemodynamic changes in the aging brain can be a powerful tool for diagnosing, studying, and developing treatments. Arterial Spin Labeling (ASL) magnetic resonance imaging can yield quantitative perfusion images without the use of contrast agents. We propose that combining new ASL techniques, such as Velocity Selective Inversion (VSI) labeling pulses and magnetic resonance fingerprinting (MRF) with deep learning regression methods will allow quantification of multiple hemodynamic parameters beyond perfusion, thus providing a much more nuanced picture of the state of the vasculature. We also expect that the new technique will offer dramatic improvements in SNR, specificity and sensitivity of ASL, and that the proposed techniques will have many other applications in research and in the clinic. We propose to use these techniques to fill the knowledge gap regarding the relationship between vascular changes and Parkinson’s disease and its symptoms, particularly fatigue, whose pathogenesis is not well understood. If we are successful in this application, future work will use the hemodynamic parameters of interest as biomarkers to assess risk of neurodegeneration, determine therapeutic targets, and guide in the development of new therapies. Public Health Statement Vascular health is an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases We propose to develop a method that can produce quantifiable images of multiple blood flow related parameters with a single scan and without the use of contrast injections. We will use this method to gain a better understanding of the relationship between Parkinson’s disease and cerebral blood flow, and expect that our method will have multiple applications beside Parkinson’s disease.",Quantitative MR Imaging of Vascular Factors in Parkinsons Disease,10266020,R01NS112233,"['Address', 'Agreement', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteries', 'Biological', 'Biological Markers', 'Blood Vessels', 'Blood Volume', 'Blood flow', 'Bolus Infusion', 'Brain', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Contrast Media', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Etiology', 'Fatigue', 'Fingerprint', 'Future', 'Health', 'Human Volunteers', 'Hybrids', 'Image', 'Injections', 'Knowledge', 'Label', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Movement', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Noise', 'Parkinson Disease', 'Pathogenesis', 'Pathologic', 'Patients', 'Perfusion', 'Physiologic pulse', 'Public Health', 'Reproducibility', 'Research', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Spatial Distribution', 'Spin Labels', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Validation', 'Weight', 'Work', 'aging brain', 'deep learning', 'feeding', 'hemodynamics', 'imaging biomarker', 'insight', 'interest', 'machine learning algorithm', 'neural network', 'non-invasive imaging', 'novel therapeutics', 'patient stratification', 'perfusion imaging', 'relating to nervous system', 'success', 'support vector machine', 'therapeutic target', 'tool', 'vascular factor', 'vector', 'white matter']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,281031
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'open source tool', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future.   Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,10223132,R24MH114788,"['Archives', 'Atlases', 'BRAIN initiative', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Management Resources', 'Data Storage and Retrieval', 'Data Store', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Individual', 'Institution', 'Internet', 'Knowledge', 'Location', 'Metadata', 'Modeling', 'Modification', 'Multiomic Data', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Prognosis', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analysis pipeline', 'archive data', 'archived data', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data centers', 'data ecosystem', 'data ingestion', 'data integration', 'data pipeline', 'data repository', 'data resource', 'data standards', 'data submission portal', 'data visualization', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'machine learning algorithm', 'member', 'multiple data types', 'multiple omics', 'neural circuit', 'next generation', 'online resource', 'operation', 'programs', 'public repository', 'query tools', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2021,1263611
"Risk Assessment of Cerebral Aneurysm Growth with 4D flow MRI PROJECT SUMMARY The goal of this project is to determine the contribution of hemodynamic factors to risk assessment of unruptured intracranial aneurysms (UIAs) and calculate these factors from enhanced in vivo 4D flow MRI data. Even though most UIAs are stable, the majority of UIA patients are offered interventional treatment due to the grave risk presented if an aneurysm ruptures. Previous studies indicated that in addition to clinical (e.g., age, sex, comorbidities) and morphological (e.g., location and size) factors, UIA progression is affected by local blood flow dynamics. Hemodynamic factors associated with UIA growth can be obtained from computational and experimental models or from 4D flow MRI measurements; however, each approach has limitations. The previous NIH-funded project focused on developing image-based computational methods for predicting postoperative flow following interventions. The goal of this renewal is to use the developed framework to improve risk stratification of UIAs using image-based flow analysis. The proposed project will develop multi-parametric predictive models that combine clinical and morphological factors with hemodynamic factors calculated from augmented 4D flow MRI data. The UIA growth predicted by different models will be compared to outcomes observed in longitudinal imaging studies. The aims of the proposed project are, therefore, to: (1) determine the probability of UIA growth by utilizing morphological and clinical factors together with hemodynamic factors obtained from computational and experimental flow models by a) performing statistical analysis based on morphological and clinical factors obtained from longitudinal imaging, and b) extending statistical model by including hemodynamic factors computed from patient-specific models; (2) Enhance 4D flow MRI data by a) determining 4D flow reproducibility and variability with in vitro studies, and b) applying advanced data augmentation methods to improve the accuracy of calculated hemodynamic factors affecting aneurysm growth; (3) determine the probability of UIA growth based on multi-parametric analysis utilizing hemodynamic factors calculated from enhanced 4D flow MRI. Successful completion of the project will resolve the controversy regarding how hemodynamic factors affect aneurysm growth and establish 4D flow MRI as a diagnostic tool for UIA risk stratification. This collaborative project engages the cardiovascular engineering group at Purdue University and neurosurgeons, neuroradiologists and MRI physicists at Northwestern University, University of California San Francisco and Barrow Neurological Institute. This cross-disciplinary team will bring together experts in neurovascular surgeries, MRI velocimetry, patient-specific flow computations, experimental fluid mechanics and statistical analysis. Retrospective and prospective UIAs data obtained from these superb clinical centers will be used in this study. The outstanding engineering resources available at Purdue and world-class imaging resources at Northwestern, UC San Francisco and Barrow, as well as existing the data sharing agreements between these institutions and ongoing collaborations between the PIs, will ensure the project's success. PROJECT NARRATIVE The majority of brain aneurysms are treated, despite the fact that most of them have very low risk or rupture. Studies indicated that brain aneurysm risk factors include a range of clinical (e.g., patient’s age, sex, family history) and anatomical (e.g., aneurysm location, size and shape) parameters, as well as local blood flow dynamics. The proposed studies will determine the specific contribution of blood flow variables for improving the risk assessment of brain aneurysms and examine whether these variables can be reliably calculated from flow velocities measured with phase-contrast magnetic resonance imaging.",Risk Assessment of Cerebral Aneurysm Growth with 4D flow MRI,10231251,R01HL115267,"['4D MRI', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Aneurysm', 'Angiography', 'Artificial Intelligence', 'Blood flow', 'Brain Aneurysms', 'California', 'Cardiovascular system', 'Cerebral Aneurysm', 'Cerebrovascular Circulation', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Computer Models', 'Computing Methodologies', 'Data', 'Databases', 'Deposition', 'Diagnostic', 'Engineering', 'Ensure', 'Experimental Models', 'Family', 'Funding', 'Future', 'Goals', 'Growth', 'Guidelines', 'Hypertension', 'Image', 'In Vitro', 'Institutes', 'Institution', 'Intervention', 'Intracranial Aneurysm', 'Liquid substance', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Morphology', 'Multiparametric Analysis', 'Neurologic', 'Neurosurgeon', 'Noise', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Phase', 'Physics', 'Postoperative Period', 'Probability', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Rupture', 'Ruptured Aneurysm', 'San Francisco', 'Shapes', 'Site', 'Statistical Data Interpretation', 'Statistical Models', 'Techniques', 'Thrombus', 'Time', 'United States National Institutes of Health', 'Universities', 'Velocimetries', 'Work', 'base', 'clinical center', 'clinical risk', 'comorbidity', 'data sharing', 'enhancing factor', 'follow-up', 'hemodynamics', 'imaging study', 'improved', 'in vivo', 'indexing', 'mortality', 'neurovascular', 'novel strategies', 'particle', 'predictive modeling', 'prospective', 'residence', 'risk stratification', 'serial imaging', 'sex', 'shear stress', 'success', 'tool']",NHLBI,PURDUE UNIVERSITY,R01,2021,644477
"Functional Cardiovascular 4D MRI in Congenital Heart Disease SUMMARY / ABSTRACT Congenital heart disease (CHD) is the most common birth defect, affecting 1.2% of all live births. Imaging plays a major role in managing CHD but remains challenging for evaluating complex cardiac and vascular abnormalities across a wide range of age and habitus. To address these limitations, the PIs have developed cardiovascular 4D flow MRI which can measure complex 3D blood flow in-vivo, a task difficult or impossible to obtain with other imaging strategies. Recent efforts have focused on two forms of CHD: 1) bicuspid aortic valve (BAV) which is the most common form of CHD, and 2) single ventricle physiology (SVP), one of the most severe forms of CHD. Our 4D flow MRI studies have successfully identified new hemodynamic biomarkers to better characterize CHD. We were the first to establish a physiologic link between aberrant 3D blood flow, elevated wall shear stress (WSS), aortopathy phenotype, and aortic wall tissue degeneration on histopathology in patients with BAV. In patients with SVP, our findings demonstrated relationships between surgical correction strategies and flow distribution to the lungs, a known factor implicated in SVP outcome. We have achieved successful clinical translation at Northwestern, where 4D flow MRI is now used as a clinical tool in diagnostic MRI exams for patients with CHD and aortic disease. Over the past four years, the PIs have assembled one of the largest 4D MRI databases with over 2500 patient exams. For this renewal application, we identified a need to increase the dynamic range of 4D MRI flow sensitivity to account for data complexity (3D + time) and the wide age range in CHD by a combination of dual-venc flow encoding, compressed sensing, and SSFP imaging. Second, three is a need for longitudinal studies to identify predictors of BAV and SVP outcome. Third, making these unique but complex 4D MRI data sets and analysis tools more widely available to the greater research community is challenging. In addition, no automated methods currently exist for advanced processing such as atlas based analysis across large cohorts. Analysis is thus time consuming and requires manual interactions (e.g. 3D vessel segmentation) which limits reproducibility and translation. To address this need, an established Northwestern data archival and pipeline processing resource based on remote high-performance computing clusters (NUNDA) will be utilized for standardized data archival, sharing, and pipeline processing of 4D MRI data. This platform will provide the unique opportunity to utilize annotated data available in the 4D MRI database (>1300 BAV, SVP, and control 4D MRI data analyzed in the initial funding cycle) for application of machine learning concepts to establish (semi-)automated 4D MRI analysis workflows in NUNDA. Thus, the renewal application for this study aims to 1) develop a rapid (15 min) non-contrast 4D MRI for clinical translation, 2) leverage the existing large 4D MRI database to identify 4D MRI metrics predictive of long-term (> 5 years) CHD patient outcome, and 3) establish a remote NUNDA platform for 4D MRI data sharing and automated analysis across large cohorts. PROJECT NARRATIVE Our goal is to develop non-contrast 4D MRI, a new diagnostic test to achieve an improved assessment for the most common and one of the most severe forms of congenital heart disease: bicuspid aortic valve and single ventricle physiology. We will leverage an existing large 4D MRI database to allow for long-term 5-8-year follow-up to establish new measures for improved outcome prediction and therapy management for patients with bicuspid aortic valve and single ventricle physiology. A comprehensive data archive will be established to allow for the dissemination of the 4D MRI data, analysis tools, and study results to the greater research community.",Functional Cardiovascular 4D MRI in Congenital Heart Disease,10117035,R01HL115828,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Aortic Diseases', 'Archives', 'Atlases', 'Biological Markers', 'Blood flow', 'Cardiac Output', 'Cardiovascular system', 'Child', 'Clinical', 'Common Ventricle', 'Communities', 'Complex', 'Congenital Abnormality', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease Progression', 'Exposure to', 'Funding', 'General Anesthesia', 'Goals', 'Growth', 'Heart Abnormalities', 'Heart Rate', 'High Performance Computing', 'Histopathology', 'Hospitals', 'Image', 'Infant', 'Link', 'Live Birth', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Oxygen', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Play', 'Population', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Role', 'Secure', 'Sex Differences', 'Testing', 'Time', 'Translations', 'adverse outcome', 'analysis pipeline', 'aortic valve', 'automated analysis', 'base', 'bicuspid aortic valve', 'clinical translation', 'cluster computing', 'cohort', 'congenital heart disorder', 'data analysis pipeline', 'data archive', 'data complexity', 'data sharing', 'data standards', 'design', 'exercise capacity', 'flexibility', 'follow-up', 'hemodynamics', 'improved', 'improved outcome', 'in vivo', 'novel', 'novel diagnostics', 'outcome prediction', 'patient population', 'pediatric patients', 'prevent', 'shear stress', 'spatiotemporal', 'tissue degeneration', 'tool', 'vascular abnormality']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,709759
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,10168641,U01MH117072,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'automated algorithm', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodal data', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'preservation', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2021,1691053
"Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning PROJECT SUMMARY/ABSTRACT Selective attention is an essential cognitive ability that permits us to effectively process and act upon relevant information while ignoring distracting events. A network involving frontal and parietal cortex for top-down attentional control, referred to as the Dorsal Attention Network (DAN), is active during both spatial and non- spatial (feature-based) attention. However, we know very little about the fine structure of attentional control activity in the DAN, how this structure changes to represent different to-be-attended stimulus features, how the connectivity within the DAN, and between the DAN and sensory cortex shifts when attending different features, or how these top-down processes and their influence in sensory cortex unfold over time. This gap in our knowledge is a critical problem for our models and theories of attention, and because attentional deficits are involved in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia. The working model guiding this research is that top-down attentional control, based on different to-be-attended stimulus attributes, is guided by a smaller-scale neural fine structure within the DAN and prefrontal cortex that makes specific connections with specialized areas of visual cortex coding the attended attributes. Moreover, the time course of activity within the DAN in relation to that in sensory cortex follows a top-down cascading model, being earliest in frontal, then parietal cortex, and finally sensory cortex for preparatory, voluntary, attentional control. To identify the functional networks for attentional control for different forms of attention, and to define their time courses, this project uses innovative simultaneous recording of electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI) data. Advanced signal processing and modeling, including multivariate pattern analysis (MVPA), graph theoretic connectivity analysis, and Granger causality analysis will be used to reveal the fine functional anatomy and time course of attentional control and selection. The project includes three experiments that vary the to-be-attended stimulus attributes from spatial location to stimulus features (color and motion), and pursues three aims. Aim 1 is to reveal the fine structure of top-down preparatory attentional control for different to-be-attended stimulus features. Aim 2 is to elucidate the specific connectivity between fine structures for preparatory attentional control in the DAN and their target sensory structures in sensory cortex. Aim 3 is to reveal the time course of top-down attentional control for different to-be-attended stimulus attributes. PROJECT NARRATIVE The capacity to focus attention is at the core of human mental functioning, and therefore, elucidating the neural bases of attention remains a central challenge for neuroscience, representing an essential aim in translational efforts to ameliorate attentional deficits in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia.",Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning,10115818,R01MH117991,"['Anatomy', 'Attention', 'Attention Deficit Disorder', 'Attentional deficit', 'Brain', 'Code', 'Color', 'Cues', 'Data', 'Dementia', 'Discrimination', 'Dorsal', 'Etiology', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'Graph', 'Human', 'Inferior', 'Knowledge', 'Location', 'Machine Learning', 'Modeling', 'Motion', 'Neurosciences', 'Parietal Lobe', 'Pattern', 'Perception', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Research', 'Schizophrenia', 'Sensory', 'Specific qualifier value', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Work', 'attentional control', 'autism spectrum disorder', 'base', 'cognitive ability', 'data integration', 'experimental study', 'extrastriate visual cortex', 'frontal lobe', 'indexing', 'innovation', 'mental function', 'neuropsychiatric disorder', 'predictive modeling', 'relating to nervous system', 'selective attention', 'sensory cortex', 'signal processing', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2021,530307
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,10251140,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data repository', 'data sharing', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2021,747224
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10265564,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2021,221480
"CRCNS:  Neural Basis of Planning Humans and other animals can choose their actions using multiple learning algorithms and decision­ making strategies. For example, habitual behaviors adapted to a stable environment can be selected using so-called model-free reinforcement learning algorithms, in which the value of each action is incrementally updated according to the amount of unexpected reward. The underlying neural mechanisms for this type of reinforcement learning have been intensively studied. By contrast, how the brain utilizes the animal's knowledge of its environment to plan sequential actions using a model-based reinforcement learning algorithm remains unexplored. In this application, PIs with complementary expertise will investigate how different subdivisions of the primate prefrontal cortex contribute to the evaluation and arbitration of different learning algorithms during strategic planning in primates, using a sequential game referred to as ""4-in-a­ row"". Previous studies have revealed that with training, humans improve their competence in this game by gradually switching away from a model-free reinforcement learning towards a model-based reinforcement learning in the form of a tree search. In the first set of experiments, we will train non-human primates to play the 4-in-a-row game against a computer opponent. We predict that the complexity of the strategic planning and the opponent's move violating the animal's expectation will be reflected in the speed of animal's action and pupil diameters. Next, we will test how the medial and lateral aspects of prefrontal cortex contribute to the evaluation and selection of different learning algorithms during strategic interaction between the animal and computer opponent. We hypothesize that the lateral prefrontal cortex is involved in computing the integrated values of alternative actions originating from multiple sources and guiding the animal's choice, whereas the medial prefrontal cortex might be more involved in monitoring and resolving the discrepancies of actions favored by different learning algorithms. The results from these experiments will expand our knowledge of the neural mechanisms for complex strategic planning and unify various approaches to study naturalistic behaviors. By taking advantage of recent advances in machine learning and decision neuroscience, proposed studies will elucidate how multiple learning algorithms are simultaneously implemented and coordinated via specific patterns of activity in the prefrontal cortex. The results from these studies will transform the behavioral and analytical paradigms used to study high-order planning and their neural underpinnings in humans and animals. Strategic planning is commonly impaired in many psychiatric illnesses, including schizophrenia and depression, but their underlying neural mechanisms remain poorly understood. The proposed studies will elucidate the role of prefrontal cortex in implementing and arbitrating between multiple learning algorithms used for strategic planning.",CRCNS:  Neural Basis of Planning,10168643,R01MH118925,"['Algorithms', 'Animal Structures', 'Animals', 'Arbitration', 'Behavior', 'Behavioral', 'Brain', 'Caliber', 'Competence', 'Complex', 'Computers', 'Decision Making', 'Decision Trees', 'Economics', 'Environment', 'Evaluation', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Impairment', 'Individual', 'Knowledge', 'Lateral', 'Learning', 'Macaca mulatta', 'Machine Learning', 'Medial', 'Mental Depression', 'Mental disorders', 'Modeling', 'Monitor', 'Monkeys', 'Neurons', 'Neurosciences', 'Outcome', 'Participant', 'Pattern', 'Physiological', 'Play', 'Positioning Attribute', 'Prefrontal Cortex', 'Primates', 'Probability', 'Psyche structure', 'Psychological reinforcement', 'Pupil', 'Research', 'Rewards', 'Role', 'Schizophrenia', 'Series', 'Signal Transduction', 'Speed', 'Strategic Planning', 'Testing', 'Training', 'Trees', 'Update', 'base', 'expectation', 'experimental study', 'fictional works', 'improved', 'learning algorithm', 'neuromechanism', 'neurophysiology', 'nonhuman primate', 'predictive modeling', 'relating to nervous system', 'response', 'simulation', 'source guides']",NIMH,JOHNS HOPKINS UNIVERSITY,R01,2021,378388
"Quantitative MRI of Multiple Sclerosis - Resubmission - 1 Project Summary  In this project, we propose a novel T1 and T2 quantification method that generates quantitative T1 or T2 maps from weighted MR images. Magnetic resonance imaging (MRI) is commonly used as a tool to diagnose Multiple Sclerosis (MS) and track lesional changes over time. Because MRI has various contrasts that display different information about the underlying tissue microstructure and physiology, it can potentially be used as a tool to predict MS disease progression and even disability. However, there is no known measure derived from MR images of MS that correlates well with clinical disability as described by the Expanded Disability Status Score (EDSS). Previous efforts to correlate MRI features and EDSS have included calculating total lesion load on T1- and T2-weighted images, measuring the variations in the magnetic transfer ration of normal-appearing brain tissues, and calculating cerebral atrophy, each with a varying level of success. Yet, there has been little study of the evolution of relaxation times of the lesions over time and how it relates to disability. Because changes in the T1 (spin-lattice) and T2 (spin-spin) relaxation times of a tissue can reflect pathological changes in that tissue over time, quantitative T1 and T2 maps derived from MR images may be more indicative of microscopic changes that manifest as disability in MS patients.  The specific aims of this proposal are: (1) develop and validate novel T1 and T2 quantification method on spin-echo MR images, (2) extend the novel quantification method to common MS imaging sequences, and (3) apply the novel quantification method to MS datasets to predict EDSS using machine learning. Aim 1 will involve the validation of the quantification pipeline on both T1- and T2-weighted spin-echo MR images in vivo, resulting in a range of acceptable parameters for the novel quantification method. Aim 2 will extend the quantification pipeline to include commonly used and more complicated MS imaging sequences, again resulting in a range of acceptable parameters for the quantification method. Aim 3 will use the quantification pipeline to compare machine learning algorithms with and without quantification to determine the added value of quantification in the imaging of MS. Additionally, Aim 3 will result in a predictive machine learning model utilizing multiple imaging contrasts for the prediction of disability in MS. These results will provide a more thorough understanding of the role of MR quantification in the evaluation of neurological diseases, such as MS, and will offer a scientific foundation to extend the use of MR quantification as a potential imaging biomarker for other diseases and pathologies. Project Narrative The proposed research aims to develop and validate a T1 and T2 quantification method using internal reference values derived from T1- or T2-weighted MR images. This method will be applied to weighted images of patients who have been diagnosed Multiple Sclerosis and input into various classification algorithms to determine which method is most predictive of worsening clinical disability as described by the Expanded Disability Status Score. By doing this, we will determine the impact of this novel quantification method as a tool for both the analysis of patients with Multiple Sclerosis as well as a tool for the normalization of big MR datasets before being input into machine learning algorithms.",Quantitative MRI of Multiple Sclerosis - Resubmission - 1,10316992,F31NS118930,"['Affect', 'Age-Years', 'Attenuated', 'Axon', 'Brain', 'Cerebrospinal Fluid', 'Clinical', 'Coupled', 'Data', 'Data Set', 'Demyelinations', 'Dependence', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Ensure', 'Equation', 'Evaluation', 'Evolution', 'Fatty acid glycerol esters', 'Foundations', 'Frequencies', 'Image', 'Inflammation', 'Investigation', 'Learning', 'Lesion', 'Liquid substance', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Medical', 'Methods', 'Microscopic', 'Modeling', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Neuraxis', 'Pathologic', 'Pathology', 'Patient imaging', 'Patients', 'Physiology', 'Population', 'Prediction of Response to Therapy', 'Predictive Value', 'Process', 'ROC Curve', 'Recovery', 'Reference Values', 'Relaxation', 'Research', 'Role', 'Scanning', 'Signal Transduction', 'T2 weighted imaging', 'Techniques', 'Time', 'Tissues', 'United States', 'Validation', 'Variant', 'brain tissue', 'cerebral atrophy', 'classification algorithm', 'contrast enhanced', 'contrast imaging', 'data harmonization', 'digital', 'disability', 'gray matter', 'healthy volunteer', 'imaging biomarker', 'improved', 'in vivo', 'in vivo imaging', 'longitudinal dataset', 'machine learning algorithm', 'multiple sclerosis patient', 'nervous system disorder', 'novel', 'predictive modeling', 'prospective', 'simulation', 'subcutaneous', 'success', 'tool', 'treatment response', 'white matter']",NINDS,UNIVERSITY OF CHICAGO,F31,2021,45686
"Targeting pathologic spike-ripples to isolate and disrupt epileptic dynamics Project Summary Epilepsy is the world’s most common, serious brain disorder, affecting nearly 50 million people worldwide. For one-third of patients, seizures remain poorly controlled despite maximal medical management. In these patients, seizures often arise from a localized brain region, and neurosurgical interventions are the most effective treatment option. When successful, surgical interventions provide cure from seizures, and also prevent or reverse the disabling consequences of uncontrolled seizures. Critical to successful intervention is accurate identification of the core tissue responsible for generating seizures (i.e., the epileptogenic zone). Traditionally, this tissue would be surgically resected, but modern approaches aim to focally disrupt this tissue with targeted electrical stimulation (i.e. neuromodulation). Improvements in epilepsy care are now limited by (i) the inability to accurately identify the epileptogenic zone; (ii) a limited understanding of the mechanisms underlying epileptiform activity; (iii) a lack of understanding of how to target these mechanisms with neurostimulation. The most common approach to identify the epileptogenic zone is through continuous recording of a patient’s cortical electrical activity to capture seizures. However, because seizures are infrequent, this approach is expensive, time consuming, and unpleasant for patients. Moreover, this approach often fails to identify the epileptogenic zone, resulting in unsuccessful neurosurgical intervention in 20-70% of cases. To address this, interictal biomarkers of the epileptogenic zone that manifest between seizures are required. Two such biomarkers have been proposed: (a) interictal discharges or spikes, and (b) high frequency oscillations or ripples. While both signals have been extensively studied, neither accurately delimits the epileptogenic zone. Spikes are specific for epilepsy, but too spatially diffuse to identify the epileptogenic zone. Ripples are spatially focal, but represent both pathologic and physiologic processes. We address these limitations by focusing on the simultaneous occurrence of a spike and ripple, “spike-ripple” discharges, as an improved biomarker for the epileptogenic zone. Spike-ripples commonly occur in patients with epilepsy, improve the spatial specificity of spikes for the epileptogenic zone, and disentangle physiologic from pathologic ripples. Our interdisciplinary team will apply expertise in epilepsy, neurophysiology, neurosurgery, animal experiments, modeling, and statistics to: (i) develop a fully automated spike-ripple detector and compare its clinical utility to predict surgical outcome to spikes and ripples alone, (ii) identify the biological mechanisms that generate spike-ripple discharges using novel voltage imaging techniques in animal models combined with computational models; and (iii) develop principled neurostimulation protocols to disrupt the mechanisms that generate spike-ripples. Completion of these Aims will represent significant progress towards resolving fundamental questions in modern epilepsy research, an understanding of mechanisms in the core epileptogenic network that generate spike-ripples, and a principled approach to neurostimulation to focally disrupt these pathologic dynamics. Project Narrative Neurosurgical treatment of epilepsy often fails, and neurostimulation to treat epilepsy remains suboptimal and ad hoc. Identification of an improved biomarker - to target epilepsy treatment and assess treatment efficacy - is required. This project combines clinical data from human patients, experiments in animal models, and computer simulations of brain activity to develop an improved biomarker for epilepsy treatment, and to develop a deeper understanding of the mechanisms driving the pathological brain dynamics in epilepsy.",Targeting pathologic spike-ripples to isolate and disrupt epileptic dynamics,10096727,R01NS119483,"['Action Potentials', 'Address', 'Affect', 'Animal Experiments', 'Animal Model', 'Automobile Driving', 'Biological', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain region', 'Caring', 'Clinical', 'Clinical Data', 'Computer Models', 'Computer Simulation', 'Consumption', 'Diffuse', 'Electric Stimulation', 'Epilepsy', 'Event', 'Excision', 'Failure', 'Generations', 'High Frequency Oscillation', 'Human', 'Image', 'Imaging Techniques', 'Individual', 'Institution', 'Intervention', 'Intractable Epilepsy', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Pathologic', 'Pathologic Processes', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Physiological Processes', 'Protocols documentation', 'Recurrence', 'Refractory', 'Research', 'Resected', 'Seizures', 'Signal Transduction', 'Specificity', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'clinical practice', 'detector', 'effective therapy', 'excitatory neuron', 'experimental study', 'human data', 'imaging approach', 'improved', 'in silico', 'in vivo', 'inhibitory neuron', 'large datasets', 'models and simulation', 'mouse model', 'neurophysiology', 'neuroregulation', 'neurosurgery', 'novel', 'prevent', 'statistics', 'successful intervention', 'surgery outcome', 'voltage']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,698329
"National Center for Microscopy and Imaging Research: A BRAIN Technology Integration and Dissemination Resource PROJECT SUMMARY/ABSTRACT This project aims to disseminate validated technologies and resources of the National Center for Microscopy and Imaging Research (NCMIR) at UC San Diego to advance the completion of strategic goals of the BRAIN Initiative. The proposed technology integration and dissemination resource will provide the neuroscience community with technical help to obtain and manage large scale data, broadening the access to and incorporation of high throughput multiscale imaging tools and leading-edge analysis strategies in their studies. Richly integrated resources will be offered, including molecular probes, imaging platforms and data analysis tools certain to enable and hasten brain research. The types of research projects we will support, include: 1) investigations requiring the traversal of spatiotemporal scales to reveal new insight and understanding of specific neural populations; 2) investigations which aim to mark and track neuronal processes and/or visualize targeted connectomes of local circuits within large volumes of nervous tissue in multiple animal models; 3) projects which seek to perform nano-histological assessment of cellular and subcellular level alterations associated with learning, physiological state, or disease; and 4) projects performing higher resolution 3D morphometric analysis of subcellular underpinnings of function, with particular emphasis on synaptic function as influenced by subcellular constituents. This new center will leverage an administrative framework and information technology cyberinfrastructure which is already in place and has been refined over many years. In addition to providing a management structure, this framework includes a community outreach, project review, selection, and onboarding process refined and long practiced by the PI (and the assembled team). Additional mechanisms for tool/technology dissemination and training, data management and sharing, and mechanisms for cost-recovery and long-term sustainability will also be leveraged and expanded so as to maximize the reach and impact of our technologies and resources. PROJECT NARRATIVE This project aims to disseminate validated technologies and resources of the National Center for Microscopy and Imaging Research (NCMIR) at UC San Diego to hasten the completion of strategic goals of the BRAIN Initiative for unlocking the role of different cell types and producing maps of brain circuits and ultrastructure at multiple scales. NCMIR will provide specialized molecular probes, novel specimen preparation methods, leading- edge microscopy and imaging technologies, and scalable computational tools to help brain investigators traverse difficult to navigate spatial and temporal scales, deliver new insight into multiscale structure/function relationships, and provide a fundamental understanding of the macromolecular mechanisms underlying brain function.",National Center for Microscopy and Imaging Research: A BRAIN Technology Integration and Dissemination Resource,10116087,U24NS120055,"['3-Dimensional', 'Achievement', 'Actins', 'Animal Model', 'BRAIN initiative', 'Behavior', 'Biomedical Technology', 'Brain', 'Brain imaging', 'Chemicals', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data Analyses', 'Data Set', 'Disease', 'Electron Microscopy', 'Elements', 'Endoplasmic Reticulum', 'Extracellular Matrix', 'Genetic', 'Goals', 'Histologic', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Immersion', 'In Situ', 'Information Technology', 'Investigation', 'Label', 'Learning', 'Light', 'Maps', 'Measures', 'Methods', 'Microscopy', 'Mitochondria', 'Molecular', 'Molecular Probes', 'National Center for Research Resources', 'National Institute of General Medical Sciences', 'Nerve Tissue', 'Neurons', 'Neurosciences', 'Physiological', 'Population', 'Preparation', 'Process', 'Recovery', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Resources', 'Roentgen Rays', 'Role', 'Sampling', 'Scanning Electron Microscopy', 'Specimen', 'Stains', 'Structure', 'Structure-Activity Relationship', 'Subcellular Anatomy', 'Techniques', 'Technology', 'Training', 'Ultramicrotomy', 'Vertebral column', 'Vesicle', 'Visualization', 'Work', 'X ray microscopy', 'base', 'brain cell', 'brain research', 'brain tissue', 'cell type', 'computerized tools', 'connectome', 'cost', 'cryogenics', 'cyber infrastructure', 'data acquisition', 'data dissemination', 'data management', 'data sharing', 'deep learning', 'imaging platform', 'insight', 'instrument', 'instrumentation', 'interest', 'large scale data', 'light microscopy', 'microscopic imaging', 'multimodal data', 'multimodality', 'nano', 'novel', 'operation', 'preservation', 'reconstruction', 'relating to nervous system', 'spatiotemporal', 'success', 'synaptic function', 'tomography', 'tool', 'voltage']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,1133656
"CRCNS: Neural computations for continuous control in virtual reality foraging Neuroscience has been able to gain major insights by relating measurements of neural activity to the  brain’s sensory inputs and motor outputs. Yet most neural activity supports computations and cognitive functions (‘thoughts’) that are not directly measurable by the experimenter. The investigators for the  present proposal invented a novel method to model an animal's thoughts by combining eXplainable  Artificial Intelligence (XAI) cognitive models for naturalistic tasks with measurements of the animal’s  sensory inputs and behavioral outputs. This model, called Inverse Rational Control (IRC), infers the internal model assumptions under which an animal's actions would be optimal. It then provides estimates of time series of subjective beliefs about the world that are consistent with this internal model. These estimates provide targets for a dimensionality reduction framework that assesses task-relevant  computational dynamics within neural population activity. The investigators propose to use these analysis  tools to find neural representations and transformations that implement these cognitive processes. They will apply this to a complex, naturalistic task that they developed: catching fireflies in virtual reality. The  monkeys they successfully trained to perform this task demonstrably weigh uncertainty, develop  predictions and long-term strategies, and apply nonlinear dynamics — all computations that are  fundamental for brain function. The investigators propose first to apply their method to analyze existing behavioral data and neural recordings collected in a simple version of this task with a single target firefly.  They will then collect new data on a multi-firefly version of the task, which incentivizes animals to make and implement longer-term plans. To analyze this data, the investigators will generalize their approach to  allow them to learn which compressed representations are selected by the animal as the foundation for  their strategies. These results will be used to form predictions about neural computations that will be tested using the electrophysiological data collected from multiple brain regions during this project. The  results of this study will explain the computations required to perform a complex, strategic navigation task  in the presence of uncertainty, and will demonstrate a new paradigm for understanding naturalistic brain computations. RELEVANCE (See instructions):  This project will uncover the neural basis of cognitive processes in the primate brain that underlie spatial  navigation, strategic planning, and behavioral control. It will demonstrate how a powerful new paradigm  for understanding complex, natural brain computations can apply to a wide variety of tasks, to explain  either adaptive or pathologically structured behavior. This will provide crucial guidance for understanding  and improving disrupted human cognitive function. n/a",CRCNS: Neural computations for continuous control in virtual reality foraging,10266181,R01NS120407,"['Animals', 'Area', 'Artificial Intelligence', 'Behavior', 'Behavior Control', 'Behavioral', 'Belief', 'Brain', 'Brain region', 'Cognition', 'Cognitive', 'Complex', 'Data', 'Dimensions', 'Electrophysiology (science)', 'Environment', 'Fireflies', 'Foundations', 'Goals', 'Human', 'Incentives', 'Instruction', 'Juice', 'Learning', 'Location', 'Macaca', 'Measurable', 'Measurement', 'Memory', 'Methods', 'Modeling', 'Monkeys', 'Motor output', 'Neurons', 'Neurosciences', 'Nonlinear Dynamics', 'Output', 'Parietal', 'Parietal Lobe', 'Pathologic', 'Perception', 'Population', 'Prefrontal Cortex', 'Primates', 'Process', 'Research', 'Research Personnel', 'Research Proposals', 'Rewards', 'Sensory', 'Series', 'Strategic Planning', 'Structure', 'Testing', 'Thinking', 'Time', 'Training', 'Uncertainty', 'Utah', 'cognitive function', 'cognitive process', 'design', 'improved', 'insight', 'neurophysiology', 'novel', 'preference', 'relating to nervous system', 'sensory input', 'theories', 'tool', 'virtual reality', 'way finding']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2021,394496
"Quantitative Ultrasound Imaging Biomarkers of Crohn's Disease PROJECT SUMMARY Crohn's Disease (CD), a chronic inflammatory bowel condition, affects over 1 million Americans and costs billions of dollars annually. Frequent and accurate evaluation of bowel inflammation and fibrosis is critical to guide therapy. Ultrasound is safe, cost-effective, and widely available, thus provides an attractive alternative to contrast enhanced CT/MRI for frequent follow-ups. Here we propose a multi-parameter ultrasound imaging approach combining B-mode, VesselQuest (a new microvessel imaging method with much higher sensitivity than conventional Doppler), and Comb-push Ultrasound Shearwave Elastography (CUSE) for comprehensive evaluation of CD inflammation and fibrosis burden. Specific Aim 1: Technical Advancement. Synthetic Transmit Aperture imaging with coded virtual sources will be used to improve the resolution and penetration of the high definition version VesselQuestHD. Random Singular Value Decomposition (SVD) and randomized spatial down-sampling will be used to accelerate SVD for realtime VesselQuestRT imaging. We will improve CUSE with marching push beams for shear wave generation, and harmonic imaging for shear wave detection. Pilot patient tests will be conducted to optimize these technologies and pave the way for clinical studies below. Specific Aim 2: Comparison with MRI. We will study 100 CD patients to investigate efficacy of this new technology for disease evaluation and treatment outcome prediction. Patients starting a new medical therapy will have contrast enhanced MRI (used as reference standard) at baseline and 6-months post therapy, and ultrasound at baseline, 4-weeks, and 6-months. The correlation of ultrasound parameters with MRI scores at baseline and 6-months will be assessed. The efficacy of ultrasound for differentiating mild vs. severe disease will be assessed by ROC (Receiver Operating Characteristic) analysis. In addition, ROC analysis will be used to assess whether ultrasound parameters at baseline or 4-weeks can predict treatment response at 6-months. Specific Aim 3: Reproducibility Study. Two sonographers will repeatedly scan 45 CD patients. Intraclass correlation coefficients will be used to evaluate the inter-sonographer agreement for ultrasound parameters. The within patient variance component from the model will provide an estimate of the inter-sonographer variance, which represents a lower bound for the minimum detectable difference for longitudinal follow-ups. Specific Aim 4: Comparison with Surgical Pathology. We will study 50 CD patients to investigate the efficacy of this new technology for evaluating fibrosis, using surgical pathology as the reference standard. The association of ultrasound parameters with fibrosis category obtained from pathology will be assessed using Spearman rank correlation. In addition, ROC analysis will be used to assess whether individual or combined ultrasound parameters can distinguish between none-to-moderate versus severe fibrosis. Successful completion of this project will lead to a novel technology for frequent follow-ups of Crohn's disease. PROJECT NARRATIVE Crohn's Disease (CD) is a chronic inflammatory bowel condition that affects over 1 million Americans, costing billions of dollars every year. Frequent imaging follow-ups is critical for guiding therapy. In this study, we will develop and test a new ultrasound technology for accurate, safe, cost-effective, and frequent evaluation of Crohn's disease to guide treatment adjustments.",Quantitative Ultrasound Imaging Biomarkers of Crohn's Disease,10078606,R01DK120559,"['Affect', 'Agreement', 'American', 'Analysis of Variance', 'Anatomy', 'Area', 'Biological Markers', 'Categories', 'Chronic', 'Clinical', 'Clinical Research', 'Code', 'Comb animal structure', 'Crohn&apos', 's disease', 'Decision Making', 'Detection', 'Disease', 'Distal part of ileum', 'Doppler Ultrasound', 'Endoscopy', 'Evaluation', 'Excision', 'Fibrosis', 'Generations', 'Image', 'Imaging technology', 'Individual', 'Inflammation', 'Inflammatory', 'Intestines', 'Ionizing radiation', 'Length', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Modeling', 'Modification', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patient Schedules', 'Patients', 'Penetration', 'Prediction of Response to Therapy', 'ROC Curve', 'Randomized', 'Reference Standards', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Source', 'Speed', 'Surgical Pathology', 'Technology', 'Testing', 'Thick', 'Time', 'Treatment outcome', 'Ultrasonography', 'angiogenesis', 'contrast enhanced', 'cost', 'cost effective', 'disorder control', 'elastography', 'imaging approach', 'imaging biomarker', 'imaging modality', 'improved', 'multimodality', 'new technology', 'novel', 'outcome prediction', 'quantitative ultrasound', 'recruit', 'responders and non-responders', 'virtual']",NIDDK,MAYO CLINIC ROCHESTER,R01,2021,427438
Computational neuroscience of language processing in the human brain  ,Computational neuroscience of language processing in the human brain,10199330,U01NS121471,"['Address', 'Architecture', 'Area', 'Brain', 'Charge', 'Code', 'Cognition', 'Complement', 'Complex', 'Computer Models', 'Data', 'Data Set', 'Disease', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Hand', 'Human', 'Influentials', 'Investigation', 'Language', 'Language Development', 'Left', 'Lesion', 'Linguistics', 'Machine Learning', 'Modeling', 'Neural Network Simulation', 'Noise', 'Patients', 'Performance', 'Population', 'Psycholinguistics', 'Research', 'Sampling', 'Science', 'Semantics', 'Stimulus', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Variant', 'Word Processing', 'Work', 'artificial neural network', 'computational neuroscience', 'design', 'human data', 'human model', 'language impairment', 'language processing', 'lens', 'lexical', 'network models', 'neural network', 'neuroimaging', 'phrases', 'relating to nervous system', 'response', 'semantic processing', 'syntax']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2021,662552
"Resolving Spatiotemporal Determinants of Cell Specification in Corticogenesis with Latent Space Methods Project Summary High-throughput profiling of hundreds of thousands of cells in the central nervous system (CNS) is currently underway. One of the goals of the BRAIN initiative is to build a census of cell types in the CNS, however previous work in single cell RNA sequencing (scRNAseq) has demonstrated that reliance on small collections of marker genes for cell type/state/position classification is insufficient to account for the dynamic nature of and variation in cellular classes/states. Previous work from both myself and others has demonstrated that latent space methods identify low dimensional patterns from high dimensional profiling data can discover molecular drivers of cell types and states in scRNAseq. However, the use of algorithms untethered to biological constraints or not extensively functionally validated can lead to the arbitrary delineation of cell class/state and the trivial designation of “novel” cell types. As proper development of the CNS requires precise regulation and coordination of spatial and temporal cues, the overall objective of this application is to develop analytic and experimental methods that integrate spatiotemporal information with scRNAseq to learn meaningful latent spaces. Specifically, I will 1) generate a comprehensive collection of transcriptional signatures for spatial features of the brain, 2) build dimension reduction software to encode spatial and cell cycle information to account for the highly specific organization of cells in the CNS, 3) derive a statistic, projectionDrivers, that allows for quantification of the gene drivers of differential latent space usage, and 4) define a statistic, proMapR, that will tell you the probability of a cell existing in a particular location in the brain at a given point in time from the cell's transcriptional signature. The ability to define and validate biologically meaningful latent spaces not only enables multiOmic data integration and exploratory analysis of scRNA-seq data via the massive amount of publicly available data, but also lays the groundwork for multimodal data integration—a necessary next step to characterize how individual cells and complex neural circuits interact in both time and space. Resolving Spatiotemporal Determinants of Cell Specification in Corticogenesis with Latent Space Methods Applicant: Genevieve Stein-O’Brien, PhD MHS Proper development of the brain requires precise regulation and coordination of spatiotemporal cues. We hypothesize human genetic variation manifests phenotypic differences by introducing small biases in spatiotemporal determinants that have accumulated effect over development. To test this hypothesis, we build novel computational and experimental tools to resolve transcriptional regulation of anatomical identity (space) and cell cycle length (time) in the brain and apply these tools to induced pluripotent stem cells from ALS patients in a model of brain development to show the effect of genetic background.",Resolving Spatiotemporal Determinants of Cell Specification in Corticogenesis with Latent Space Methods,10188106,K99NS122085,"['ALS patients', 'Algorithms', 'Anatomy', 'Automobile Driving', 'BRAIN initiative', 'Bar Codes', 'Behavioral', 'Biological', 'Biological Assay', 'Brain', 'Brain region', 'CCRL2 gene', 'CRISPR/Cas technology', 'Catalogs', 'Cell Cycle', 'Cell Cycle Regulation', 'Cells', 'Censuses', 'Classification', 'Collection', 'Competence', 'Complex', 'Computer Models', 'Computer software', 'Coupled', 'Cues', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Doctor of Philosophy', 'Experimental Models', 'Gene Expression', 'Gene Expression Profile', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genetic study', 'Goals', 'Human Genetics', 'In Situ', 'Individual', 'Institutes', 'Knowledge', 'Lead', 'Learning', 'Length', 'Link', 'Location', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Nature', 'Neuraxis', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiologic pulse', 'Positioning Attribute', 'Probability', 'Process', 'Psychological Transfer', 'Regulation', 'Research', 'Retina', 'Statistical Models', 'Stochastic Processes', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Transcriptional Regulation', 'Validation', 'Variant', 'Work', 'analytical tool', 'base', 'biological systems', 'cell type', 'data integration', 'functional plasticity', 'genetic variant', 'genome wide association study', 'high dimensionality', 'improved', 'induced pluripotent stem cell', 'multimodal data', 'nervous system development', 'neural circuit', 'neuronal circuitry', 'neuropsychiatric disorder', 'novel', 'nucleotide analog', 'pedagogy', 'progenitor', 'relating to nervous system', 'repository', 'single-cell RNA sequencing', 'spatiotemporal', 'statistics', 'success', 'supervised learning', 'time use', 'tool']",NINDS,JOHNS HOPKINS UNIVERSITY,K99,2021,110674
"Direct sub-second measurement of neuromodulator signaling during risky decision-making PROJECT SUMMARY Much work in decision neuroscience has been predicated on the hypothesis that dopaminergic signaling plays a critical role in value representations and their updating, and recent work has linked abnormalities in such value representations to specific features of psychiatric illness (e.g., anhedonia in major depression). However, despite the fundamental role that risk plays in evaluating choice options as well as the role sensitivity to risk plays in psychiatric illness, including anxiety disorders at one extreme and health risk behaviors like substance use at another other, an understanding of the neurobiology of risk remains elusive. Indirect evidence from pharmacological studies have suggested both serotoninergic and noradrengergic signaling may play roles in representations of risk; however, direct measurement of serotonin or norepinephrine signaling during risky choice has yet to be examined in humans. Recent advances by MPI Montague’s group allow the unprecedented ability to track neuromodulator responses with high temporal resolution and chemical specificity. Specifically, MPI Montague’s team is able to directly and simultaneously measure dopamine and serotonin responses in awake humans with the temporal resolution (~ 1 ms) required to examine the relationship of neuromodulator release with decision-making processes. For signal identification and extraction, the recording method uses machine-learning algorithms (elastic net regression) combined with electrochemistry using only off-the shelf hardware and software. The product of this ‘elastic net electrochemistry’ is recordings of in vivo neuromodulator fluctuations at sub-second resolution. This application merges the decision neuroscience expertise of MPI King-Casas with these advances of MPI Montague to directly examine serotonergic, noradrenergic, and dopaminergic functioning during risky choice. To achieve this goal, we will record neuromodulator responses in participants with medication-resistant epilepsy who already have intracranial depth electrodes in place for phase-II monitoring. Depth electrodes will be implanted by our neurosurgery colleagues at Virginia Tech’s medical affiliate Carilion Clinic (Carilion Clinic PI: Witcher). During recording, participants will perform i) a risk elicitation task (Holt & Laury type task) and ii) a reward learning task (multi-arm bandit task) that have been shown by our group and others both to reliably evoke neural responses associated with risk and representations as they are monitored in a standard (i.e., non-surgical) hospital suite. Depth recordings will be made using a standard montage that includes multiple contacts along the dorsal-rostral axis of the medial prefrontal cortex. PROJECT NARRATIVE Despite the fundamental role that risk plays in evaluating choice options as well as the role sensitivity to risk plays in psychiatric illness, including anxiety disorders at one extreme and health risk behaviors like substance use at another other, an understanding of the neurobiology of risk remains elusive. Here, we take advantage of a new technology to directly measure serotonin, norepinephrine and dopamine on a sub-second basis to investigate the neurocomputational role of these neurotransmitters in risky choice.",Direct sub-second measurement of neuromodulator signaling during risky decision-making,10141302,R01MH122948,"['Anhedonia', 'Anxiety Disorders', 'Behavioral', 'Chemicals', 'Clinic', 'Computer software', 'Decision Making', 'Dopamine', 'Dorsal', 'Electrochemistry', 'Electrodes', 'Epilepsy', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Hospitals', 'Human', 'Implant', 'Implanted Electrodes', 'Learning', 'Link', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Medial', 'Medical', 'Mental disorders', 'Methods', 'Monitor', 'Morale', 'Neurobiology', 'Neuromodulator', 'Neurosciences', 'Neurotransmitters', 'Norepinephrine', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacology Study', 'Phase', 'Play', 'Prefrontal Cortex', 'Process', 'Resistance', 'Resolution', 'Rewards', 'Risk', 'Risk Behaviors', 'Role', 'Serotonin', 'Signal Transduction', 'Specificity', 'Testing', 'Update', 'Virginia', 'Work', 'arm', 'awake', 'base', 'experience', 'in vivo', 'machine learning algorithm', 'neurosurgery', 'new technology', 'noradrenergic', 'relating to nervous system', 'response', 'substance use', 'temporal measurement']",NIMH,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2021,654439
"Protein structure determination from low-resolution experimental data Project Abstract Determination of a protein’s three-dimensional structure is of critical importance in biology, providing insights to biological mechanisms and important targets for drug design. While high- resolution X-ray diffraction data provides an atomic view of cellular components, for many interesting and biologically relevant complexes, it may only be possible to obtain low-resolution structural information. Both cryo-electron microscopy and X-ray crystallography, when applied to large, flexible molecular machines, often produce data of 3-6 Å resolution. Extracting detailed atomic information from this data, critical in understanding function, the effects of mutation, or in designing drugs is impossible due to the low number of observations and the large conformational space proteins may adopt. I propose to develop computational methods for extracting high-resolution atomic models from this low-resolution data, bridging the “resolution gap” with computational methods. My proposed research develops and extends our labs’ methods for automatically inferring atomic accuracy models, from these “near-atomic” resolution sources of experimental data. We develop novel conformational sampling methods, guided by experimental data, to infer atomic information both in cases where homologous high-resolution data is available, and where it is not. Additionally, we propose development of methods for estimating model uncertainty; these are critical in understanding to what degree structural conclusions may be made from a particular dataset. Finally, in pushing the resolution limit further, we develop general tools for biomolecular forcefield optimization. These machine-learning tools will allow development of a next-generation forcefield, critical in extending the resolution limit of data from which we can infer atomic details. The overall goal of the proposed research is robust and accessible methods to determine protein structures to atomic accuracy from only sparse experimental data. Combined, the three aims in this proposal will lead to dramatic improvements in our ability to infer atomic interactions from sparse experimental data. This will lead to determination of structures that will reveal key insights into how biomedically important protein complexes perform their function and what goes wrong in human disease. Project Narrative This project develops computational tools for accurately determining protein structure from low- resolution experimental data. The proposed work will lead to dramatic improvements in our ability to model dynamic structures from sparse data. Obtaining accurate structures from this data will reveal insights into how biomedically important protein complexes perform their function, and what goes wrong in human disease.",Protein structure determination from low-resolution experimental data,10224234,R01GM123089,"['Address', 'Adopted', 'Biological', 'Biology', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Drug Design', 'Drug Targeting', 'Goals', 'Homologous Gene', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Mutation', 'Phase', 'Positioning Attribute', 'Proteins', 'Refit', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Source', 'Structure', 'System', 'Testing', 'Torsion', 'Uncertainty', 'Validation', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'atomic data', 'atomic interactions', 'computerized tools', 'exhaustion', 'flexibility', 'heterogenous data', 'human disease', 'improved', 'insight', 'method development', 'model building', 'next generation', 'novel', 'protein complex', 'protein structure', 'reconstruction', 'three dimensional structure', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2021,285983
"Data-driven solutions for temporal, spatial, and spatiotemporal dynamic functional connectivity Project Summary/Abstract  Existing approaches to estimate and characterize whole brain time-varying connectivity from fMRI data have shown considerable promise, with exponential growth in research in this field. We and others have developed a powerful set of tools that are now in wide use in the community. However, the impact of mental illness on brain connectivity is complex, and as we show, limitations in existing methods often result in missing important features associated with brain disorders (e.g. transient fractionation of the spatial structure of brain networks). Some of these important limitations include 1) the most widely-used approaches often require a number of prior and limiting assumptions that are not well studied, 2) methods often assume linear relationships either within or between networks over time, and 3) methods assume spatially fixed nodes and ignore the possibility of spatially fluid evolution of networks over time. We propose a novel family of models that builds on the well-structured framework of joint blind source separation to capture a more complete characterization of (potentially nonlinear) spatio-temporal dynamics while providing a way to relax other limiting assumptions. Our models will also produce a rich set of metrics to characterize the available dynamics and enable in depth comparison with currently avail- able models including those that are model based. We will extensively validate our approaches in a variety of ways including simulations and evaluation of rigor and robustness in large normative data sets. Finally, we will apply the developed tools to study the important area of dynamic properties in mental illnesses including schiz- ophrenia, bipolar disorder, and the autism spectrum. There is considerable evidence of disruption of dynamics in all three disorders, and as we show the use of static (or even exiting dynamic) approaches can miss important information about brain related differences associated with each. We will provide open source tools and release data throughout the duration of the project via a web portal and the NITRC repository, hence enabling other investigators to use our approaches and compare their own methods with our own. Our tools have wide appli- cation to the study of the healthy brain as well as many other diseases such as Alzheimer's disease and attention deficit hyperactivity disorder. 38 Project Narrative  There is considerable interest in approaches that capture time-varying connectivity, however existing ap- proaches suffer from three major limitations: 1) extraction of networks and estimation of dynamic features for the most widely used approaches typically makes many limiting assumptions and rely on user defined parameters whose optimality is not guaranteed (e.g. choice of window size, filter settings), 2) methods typically assume relatively simple linear relationships, and 3) most approaches assume the spatial nodes are fixed in time, effec- tively ignoring the possibility of functionally fluid nodes. We propose to address these limitations by developing a family of flexible spatio-temporal models that leverage and blend the concepts of joint blind source separation and deep learning, which we show can reveal important information missed by existing models. We will apply the proposed models to study spatial and temporal aspects of dynamic connectivity across mental illness includ- ing schizophrenia, bipolar disorder, and autism spectrum. 37","Data-driven solutions for temporal, spatial, and spatiotemporal dynamic functional connectivity",10156006,R01MH123610,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Area', 'Attention deficit hyperactivity disorder', 'Back', 'Behavior', 'Benchmarking', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Classification', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Data', 'Data Set', 'Diagnostic', 'Dimensions', 'Disease', 'Documentation', 'Ensure', 'Evaluation', 'Evolution', 'Family', 'Fingerprint', 'Fractionation', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Individual', 'Joints', 'Liquid substance', 'Mental disorders', 'Methods', 'Modeling', 'Moods', 'Nonlinear Dynamics', 'Patients', 'Property', 'Psychoses', 'Reproducibility', 'Research', 'Research Personnel', 'Schizophrenia', 'Source', 'Structure', 'Study models', 'Subgroup', 'Symptoms', 'Testing', 'Time', 'Validation', 'Work', 'autism spectrum disorder', 'base', 'blind', 'clinical care', 'clinically relevant', 'deep learning', 'flexibility', 'interest', 'multimodal data', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'open source tool', 'rapid growth', 'repository', 'simulation', 'social', 'social cognition', 'spatial integration', 'spatiotemporal', 'tool', 'translational impact', 'user-friendly', 'web portal']",NIMH,GEORGIA STATE UNIVERSITY,R01,2021,693368
"AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution Abstract. Whole-organ 3D immunohistochemistry is revolutionizing the field of neuroscience, enabling unprecedented insight into the distribution of neural cells and neurological markers throughout the brain in health and disease. LifeCanvas Technologies is at the forefront of the new field of spatial proteomics, providing a complete workflow for whole-organ preservation, tissue clearing, immunohistochemical labeling, and imaging. Nevertheless, an ongoing challenge for such studies is the need to rapidly, reproducibly and rigorously quantify terabyte-sized datasets from whole-organ imaging efforts. While progress has been made in applying Artificial Intelligence (AI) tools to enable detection of cellular and sub-cellular markers in neural tissue, one-size-fits-all algorithms are inadequate for analyzing complex, information-rich brain datasets due to varying biomolecular expression patterns (e.g. nuclear, cytoplasmic, membrane-bound) and region-specific heterogeneities in cell density and neural cell types. However, AI-driven algorithms targeting a subset of labeling patterns can be effective provided the availability of adequate training data. LifeCanvas Technologies LCT is optimally positioned to develop highly accurate algorithms serving a wide range of detection tasks through its access to high volumes of whole-organ image data containing a variety of label expression patterns via its Contract Research Organization and user base. LCT proposes to develop a data analysis program, SmartAnalytics, which will embed a suite of AI algorithms within a user-friendly software package to identify labeled cell locations and characterize morphological features across the whole brain at cellular and sub-cellular resolution. Specifically, LCT will use intact, 3D immunolabeled mouse brains to design AI algorithms to detect labeled cells imaged at cellular resolution and generate further algorithms for the segmentation of labeled features imaged at sub-micron resolution. Data from LCT’s Contract Research Organization and academic collaborations will be continually fed back to improve and expand the library of detection algorithms available within SmartAnalytics, and these developments will drive further customer adoption and enhancement of future versions of the software. SmartAnalytics will guide users through model application, quality-control testing, and the generation of output products such as figures and summary statistics. In summary, SmartAnalytics will be an evolving and user- friendly workflow execution program that enables neuroscientists to take full advantage of their 3D image data, driving new discoveries in brain function, development and disease. Narrative. The ability to readily and accurately quantify proteomic expression patterns that define neural cell- type specific distributions and morphologies across intact brains will enable unprecedented and unbiased insights into studies of brain function. LifeCanvas Technologies’ state-of-the-art tissue processing pipeline provides uniform clearing, labeling, and imaging of whole brains at cellular and sub-cellular resolution. By developing Artificial Intelligence algorithms to detect labeled cells and determine morphologies and by packaging these algorithms in a user-friendly software ‘SmartAnalytics’, LifeCanvas will enable neuroscientists to quantify image data and derive critical results towards a more complete understanding of brain function in development, health and disease.",AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution,10139966,R43MH125512,"['3-Dimensional', 'Adoption', 'Algorithms', 'Amyloid beta-Protein', 'Antibodies', 'Artificial Intelligence', 'Astrocytes', 'Automobile Driving', 'Back', 'Binding Proteins', 'Biological Markers', 'Brain', 'Brain imaging', 'Cell Density', 'Cell membrane', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cytoplasm', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Feedback', 'Future', 'Generations', 'Glial Fibrillary Acidic Protein', 'Health', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunohistochemistry', 'Individual', 'Institutes', 'Label', 'Libraries', 'Location', 'Maps', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neurologic', 'Neurons', 'Neurosciences', 'Nuclear', 'Organ', 'Organ Preservation', 'Output', 'Pattern', 'Positioning Attribute', 'Process', 'Proteins', 'Proteomics', 'Quality Control', 'Research Contracts', 'Resolution', 'Rosaniline Dyes', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissue imaging', 'Tissues', 'Training', 'algorithm development', 'base', 'biomarker-driven', 'cell type', 'cellular imaging', 'computerized data processing', 'cost', 'design', 'extracellular', 'improved', 'insight', 'intelligent algorithm', 'neuronal cell body', 'new technology', 'programs', 'relating to nervous system', 'segmentation algorithm', 'software development', 'statistics', 'submicron', 'terabyte', 'tissue processing', 'tool', 'user friendly software', 'user-friendly']",NIMH,"LIFECANVAS TECHNOLOGIES, INC.",R43,2021,226754
"Acquisition, extinction, and recall of attention biases to threat: Computational modeling and multimodal brain imaging Project Summary Classical aversive conditioning is a well-established laboratory model for studying acquisition and extinction of defensive responses. In experimental animals, as well as in humans, research to date has been mainly focused on the role of limbic structures (e.g., the amygdala) in these responses. Recent evidence has begun to stress the important contribution by the brain’s sensory and attention control systems in maintaining the neural representations of conditioned responses and in facilitating their extinction. The proposed research breaks new ground by combining novel neuroimaging techniques with advanced computational methods to examine the brain’s visual and attention processes underlying fear acquisition and extinction in humans. Major advances will be made along three specific aims. In Aim 1, we characterize the brain network dynamics of visuocortical threat bias formation, extinction, and recall in a two-day learning paradigm. In Aim 2, we establish and test a computational model of threat bias generalization. In Aim 3, we examine the relation between individual differences in generalization and recall of conditioned visuocortical threat biases and individual differences in heightened autonomic reactivity to conditioned threat, a potential biomarker for assessing the predisposition to developing the disorders of fear and anxiety. It is expected that accomplishing these research aims will address two NIMH strategic priorities: defining the circuitry and brain networks underlying complex behaviors (Objective 1) and identifying and validating new targets for treatment that are derived from the understanding of disease mechanisms (Objective 3). It is further expected that this project will enable a paradigm shift in research on dysfunctional attention to threat from one that focuses primarily on limbic-prefrontal circuits to one that emphasizes the interactions among sensory, attention, executive control and limbic systems. Project Narrative The learning and un-learning of a fear response through conditioning and extinction learning is a process that is of interest not only for basic neuroscience research, but also for clinical intervention and diagnostic procedures in a variety of psychiatric disorders. In the present proposal, building on strong preliminary data that suggest a pivotal role of visual and attention systems, along with limbic structures, in aversive learning, we seek to use simultaneous EEG-fMRI, combined with computational modeling and advanced analytical techniques including machine learning, to characterize—in time and space—the dynamics and communication within and among the brain’s visual, attention and limbic networks during the acquisition and extinction of conditioned fear in healthy populations. Furthermore, testing of the proposed computational model on a community sample stratified by their cardiac reactivity to threat will advance our understanding of the model’s capability to differentiate individual differences in threat response, and lay the foundation for identifying new biomarkers and treatment targets for disorders of fear, anxiety, and post-traumatic stress.","Acquisition, extinction, and recall of attention biases to threat: Computational modeling and multimodal brain imaging",10296986,R01MH125615,"['Acceleration', 'Address', 'Amygdaloid structure', 'Animals', 'Anxiety', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biological Markers', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Research', 'Communication', 'Communities', 'Complex', 'Computer Models', 'Computing Methodologies', 'Conditioned Reflex', 'Cues', 'Data', 'Deceleration', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease susceptibility', 'Electrophysiology (science)', 'Emotions', 'Etiology', 'Event-Related Potentials', 'Extinction (Psychology)', 'Foundations', 'Fright', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart Rate', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Laboratories', 'Learning', 'Limbic System', 'Machine Learning', 'Measurement', 'Mental Depression', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurosciences Research', 'Parietal', 'Perception', 'Population', 'Predisposition', 'Process', 'Psychophysics', 'Research', 'Research Domain Criteria', 'Role', 'Safety', 'Sampling', 'Scalp structure', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'Stress', 'Structure', 'Study models', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translational Research', 'Visual', 'Visual Cortex', 'Visual Perception', 'Visual attention', 'Visual evoked cortical potential', 'Work', 'advanced analytics', 'attentional bias', 'attentional control', 'aversive conditioning', 'base', 'classical conditioning', 'conditioned fear', 'conditioning', 'executive function', 'experience', 'experimental study', 'hemodynamics', 'imaging modality', 'indexing', 'innovation', 'interest', 'learning extinction', 'machine learning algorithm', 'multimodality', 'neuroimaging', 'novel', 'post-traumatic stress', 'potential biomarker', 'predictive modeling', 'relating to nervous system', 'response', 'tool', 'visual neuroscience']",NIMH,UNIVERSITY OF FLORIDA,R01,2021,450166
"MELD: accelerating MD modeling of proteins using Bayesian inference PROJECT SUMMARY This proposal is to develop MELD, a computational Bayesian accelerator that “melds” together molecular dynamics simulations with external knowledge. It is novel in harnessing information that has not been usable before – because it is too sparse, noisy, ambiguous, combinatoric, or too corrupted for traditional approaches. In contrast to the high-certainty restraints traditionally used in MD simulations, MELD leverages a much broader range of real-world high-uncertainty restraints. The first specific aim is to incorporate such information in protein structure determination, in several collaboration projects with experimentalists who perform solution x-ray scattering, ESR, and high-throughput alanine scanning structures of peptide protein complexes. The second aim is to also harness information about processes, trajectories, and dynamic routes to speed the identification of protein states. MELD promises to extend physics-based simulations for determining larger protein structures, for folding larger proteins, for binding more flexible ligands, and for exploring larger mechanistic actions, than current MD simulation methods can handle. PROJECT NARRATIVE Biomedical research and pharmaceutics depend on detailed understanding of the structures and motions of proteins. Molecular dynamics simulations provide the most detailed descriptions possible, however they cannot yet describe average to large sized protein structures or motions within a reasonable time frame. We propose to develop a new physics-based computational accelerator for Molecular Dynamics, called MELD, which incorporates many types of relevant external information that was too vague and difficult to compute to have been practically useful before.",MELD: accelerating MD modeling of proteins using Bayesian inference,10075288,R01GM125813,"['Affinity', 'Alanine', 'Automobile Driving', 'Bayesian Analysis', 'Bayesian Method', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biomedical Research', 'Collaborations', 'Combinatorics', 'Complex', 'Computers', 'Crystallization', 'Data', 'Event', 'Goals', 'Homology Modeling', 'Knowledge', 'Label', 'Laws', 'Learning', 'Ligands', 'Metagenomics', 'Methods', 'Modeling', 'Molecular Computations', 'Molecular Conformation', 'Motion', 'Pharmacy (field)', 'Physics', 'Process', 'Proteins', 'Psychological reinforcement', 'Resolution', 'Roentgen Rays', 'Route', 'Sampling', 'Scanning', 'Source', 'Speed', 'Structure', 'Supercomputing', 'System', 'TP53 gene', 'Testing', 'Time', 'Uncertainty', 'Virginia', 'base', 'blind', 'deep learning', 'experimental study', 'flexibility', 'improved', 'insight', 'molecular dynamics', 'novel', 'peptide structure', 'protein complex', 'protein structure', 'protein structure prediction', 'restraint', 'scale up', 'simulation']",NIGMS,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2021,317007
"Mapping the superficial white matter connectome of the human brain using ultra high resolution multi-contrast diffusion MRI Abstract In this 5-year R01 project entitled “Mapping the superficial white matter connectome of the human brain using ultra high resolution multi-contrast diffusion MRI,” we propose to create the first atlas of the human brain’s superficial white matter (SWM) using sub-millimeter ultra high resolution diffusion MRI (dMRI). The SWM is located between the deep white matter and the cortex. It plays an important role in neurodevelopment and aging, and it has been implicated in a large number of diseases including Alzheimer’s, Huntington’s, epilepsy, autism spectrum disorder, schizophrenia, and bipolar disorder. Despite its significance in health and disease, the SWM is vastly underrepresented in current descriptions of the human brain connectome. The SWM contains short, u- shaped association fiber bundles called u-fibers. Multiple challenges have thus far prevented comprehensive mapping of the human brain’s SWM. These challenges include the inadequate spatial resolution of dMRI data, which prevents u-fiber tracing using current tractography methods, as well as the small size, high curvature, and high inter-subject variability of the u-fibers. An additional challenge is the lack of ground truth information. Our understanding of human neuroanatomy relies heavily on the results of invasive tracer studies in monkeys, but the detailed neuroanatomy of the SWM in monkeys has not yet been systematically compiled or analyzed. We propose to address these challenges to create the most comprehensive description of the SWM to date. Our strategy includes using ultra high spatial resolution dMRI acquisitions (~700µm isotropic or better) at multiple echo times (TE), novel dMRI tractography methods designed for tracing u-fibers, anatomically informed machine learning to parcellate the u-fibers, and expert neuroanatomical generation of the SWM connectivity matrix from monkey tracer studies. Furthermore, we will develop a novel ontological framework to organize and name the SWM systems of the monkey and human brains. Overall, these steps will enable robust in-vivo tracing and capturing of inter-subject variability of the SWM of the human brain at an unprecedented spatial resolution. Our proposed deliverables will be the first comprehensive, anatomically curated atlases of the SWM in human and monkey, which will enable the study of the SWM in health and disease. We will publicly release all image data, tractography atlases, monkey connectivity matrices, extracted fascicles, and all software as open source. Narrative The human brain’s superficial white matter (SWM) plays an important role in neurodevelopment and aging and has been implicated in a large number of diseases. Despite its significance, the SWM is vastly underrepresented in current descriptions of the human brain connectome due to multiple challenges that have thus far prevented comprehensive mapping of the SWM. We propose to address these challenges to create the most comprehensive, anatomically curated maps of the SWM to date, which will enable its study in health and disease.",Mapping the superficial white matter connectome of the human brain using ultra high resolution multi-contrast diffusion MRI,10182286,R01MH125860,"['Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Architecture', 'Atlases', 'Auditory area', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Epilepsy', 'Fascicle', 'Fiber', 'Generations', 'Goals', 'Health', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Iron', 'Literature', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Monkeys', 'Morphology', 'Myelin', 'Names', 'Neuroanatomy', 'Ontology', 'Play', 'Relaxation', 'Resolution', 'Role', 'Schizophrenia', 'Source', 'System', 'Testing', 'Time', 'Tissues', 'Tracer', 'Translating', 'Visual', 'autism spectrum disorder', 'base', 'comparative', 'connectome', 'deep learning', 'design', 'experimental study', 'human subject', 'improved', 'in vivo', 'inter-individual variation', 'neurodevelopment', 'novel', 'novel strategies', 'open source', 'prevent', 'tractography', 'ultra high resolution', 'white matter']",NIMH,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,858769
"fMRI physiological signatures of aging and Alzheimer's Disease PROJECT SUMMARY/ABSTRACT The growing availability of large functional magnetic resonance imaging (fMRI) datasets has enabled new investigations into functional systems of the human brain. A challenge – but also opportunity – of fMRI arises from the fact that BOLD signal stems from multiple intertwined neural and physiological sources. One major contributor to fMRI signals arises from slow (<0.15 Hz) fluctuations in respiration volume (RV) and heart rate (HR); these systemic physiological fluctuations can account for a substantial proportion of fMRI signals across gray matter, and exhibit spatial patterns that overlap with functional networks. While often treated as a confound, the components of fMRI data linked with systemic physiology may itself present useful information about brain function and physiology, enabling novel investigation of brain vasculature, autonomic function, and brain-body interactions. However, many existing fMRI datasets lack concurrent physiological recordings, and current data-driven techniques do not unambiguously resolve low-frequency physiological signal sources without peripheral cardiac and respiratory recordings for reference. This proposal conducts novel analyses to establish associations between fMRI physiological responses, brain networks, and neurocognitive function. Further, new techniques are proposed for extracting RV and HR time series directly from fMRI data, thereby enriching existing fMRI datasets with missing physiological information. Through analysis of large, public datasets, we will: 1) optimize and validate a deep learning technique for reconstructing physiological time series from resting-state fMRI data alone, which generalizes to participants across the adult lifespan; and 2) relate brain-wide fMRI physiological features to age and phenotypic variation; and 3) probe the value of fMRI physiological responses as early markers of Alzheimer's Disease. We will make all of the resulting signals, models, and code readily available to the community, so that researchers can apply and extend our methods to enhance the value of many existing datasets. Through approaches for resolving neural and physiological sources underlying fMRI signal dynamics, this project also has implications for increasing the precision of fMRI for mapping brain circuits at the level of the individual. PROJECT NARRATIVE Results of this study are expected to increase understanding of brain networks and physiology in aging, and could produce novel fMRI indicators of age-related changes in brain function. Our proposed methods for reconstruct low-frequency respiratory and cardiac fluctuations from fMRI data would also increase the scientific value of existing datasets, enabling analyses of brain-body interactions in the many datasets that lack physiological recordings.",fMRI physiological signatures of aging and Alzheimer's Disease,10361105,RF1MH125931,"['Adult', 'Age', 'Aging', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Big Data', 'Blood Vessels', 'Brain', 'Brain Mapping', 'Brain Stem', 'Cardiac', 'Cell Nucleus', 'Cerebrovascular Circulation', 'Cerebrovascular system', 'Code', 'Cognitive', 'Communities', 'Complex', 'Coupling', 'Data', 'Data Set', 'Databases', 'Disease', 'Early Diagnosis', 'Emotional', 'Emotions', 'Exhibits', 'Frequencies', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Health', 'Heart Rate', 'Human', 'Individual', 'Individual Differences', 'Investigation', 'Link', 'Longevity', 'Machine Learning', 'Measurement', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Neurocognitive', 'Neurons', 'Neurosciences', 'Participant', 'Pattern', 'Peripheral', 'Phenotype', 'Physiological', 'Physiology', 'Process', 'Pulse Oximetry', 'Research Personnel', 'Respiration', 'Rest', 'Role', 'STEM research', 'Series', 'Signal Transduction', 'Source', 'Structure', 'System', 'Techniques', 'Time', 'Validation', 'Variant', 'Work', 'age difference', 'age related', 'base', 'cerebrovascular', 'deep learning', 'denoising', 'functional gain', 'gray matter', 'heart rate variability', 'indexing', 'insight', 'mind body interaction', 'novel', 'pathological aging', 'relating to nervous system', 'respiratory', 'response', 'stem']",NIMH,VANDERBILT UNIVERSITY,RF1,2021,1055589
"A Computational Framework for Distributed Registration of Massive Neuroscience Images Project Summary Neuroscience stands at the precipice of a new depth of understanding about how the brain works thanks to recent advances in imaging data acquisition technologies such as light-sheet ﬂuorescence microscopy (LSFM). How- ever, the lack of analytic tooling to mine this rich information's relationship across samples, timepoints, and data acquisition technologies prevents researchers from unlocking quantitative relationships. We propose the creation of an easy-to-use, distributed-computation image registration tools that will map large images into a common reference frame. This work will be based on the open source Insight Toolkit (ITK), a widely supported, standard library for reproducible, computational image analysis. We propose extending ITK's registration architecture with technologies and methods from deep learning and the scientiﬁc Python community to effectively register LSFM volumes and time series. This project has the potential to integrate recent advances in cell typing and circuit mapping that will ultimately elucidate the underlying mechanisms of brain development and function. Project Narrative Neuroscience stands at the precipice of a new depth of understanding about how the brain works thanks to recent advances in imaging data acquisition technologies; however, there is a lack of analytical tools that can mine these immense and rich datasets. We propose the creation of easy-to-use, distributed-computation image registration tools based on the Insight Toolkit (ITK). This project has the potential to integrate recent advances in whole-brain imaging of neural activity at a cellular resolution with cell typing and circuit mapping data to ultimately elucidate the underlying mechanisms of brain development and function.",A Computational Framework for Distributed Registration of Massive Neuroscience Images,10259930,RF1MH126732,"['Adopted', 'Adoption', 'Anatomy', 'Architecture', 'BRAIN initiative', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Cells', 'Clinical', 'Communities', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Documentation', 'Electron Microscopy', 'Electrophysiology (science)', 'Ensure', 'Fluorescence Microscopy', 'Genetic', 'Goals', 'Histopathology', 'Image', 'Image Analysis', 'Infiltration', 'Institutes', 'Laboratory Research', 'Letters', 'Libraries', 'Light', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Memory', 'Methods', 'Modality', 'Modernization', 'NPAS4 gene', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Ontology', 'Performance', 'Physiological', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Roentgen Rays', 'Sampling', 'Science', 'Series', 'Software Framework', 'Structure', 'Technology', 'Time', 'Tissues', 'Toxoplasmosis', 'Visualization', 'Work', 'analytical tool', 'base', 'bioimaging', 'cluster computing', 'computer framework', 'data acquisition', 'deep learning', 'design', 'experience', 'experimental study', 'image registration', 'imaging modality', 'imaging system', 'improved', 'insight', 'member', 'microCT', 'microscopic imaging', 'monocyte', 'neuroimaging', 'next generation', 'novel', 'open source', 'optical imaging', 'outreach', 'prevent', 'relating to nervous system', 'terabyte', 'tool', 'transcriptomics']",NIMH,"KITWARE, INC.",RF1,2021,1365152
"SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles PROJECT SUMMARY/ABSTRACT Human organ systems require temporally and spatially coordinated multicellular actions at a macroscale to actuate, sustain, or terminate dedicated and vital functions. Cells that comprise discrete or distributed physiologic systems that fail to respond to appropriate stimuli with coordination may cause significant morbidity and often mortality. Collective and coordinated physiologic activities typically involve millions to billions of cells that may span large physical distances. Technologies for quantifying the electrical, chemical, and mechanical coupling in these multicellular systems are critically important to understanding the underlying mechanisms of disease and develop therapeutic approaches. However, no technology currently exists to quantify rapid mechanical cell responses to transmitted distal perturbations for all cells within a collection of cells. This multi- PI proposal (Chiou (contact PI) and Teitell) aims to develop a new platform imaging technology called SPOT (single pixel optical technology) for concurrent and direct measurements of cellular traction forces over a 1.0 x 1.0 cm2 field of view (FOV) with cellular spatial resolution, and a 1,000 frames/sec temporal resolution. SPOT provides a 4-order of magnitude larger FOV than conventional traction force microscopy. Cardiomyocytes (CMs) are the test bed here because of a high potential for impact in cardiovascular disease, the leading cause of mortality in the Western World. We will demonstrate the ability for SPOT to determine quantitative indices of abnormalities for human CM contraction and relaxation in healthy and diseased states. We will establish proof of concept studies in SPOT screens for small molecules that augment or affect CM contraction in desmoplakin deficient states. We will build a platform that integrates SPOT for direct contraction force measurements and Optical Mapping for electrical property measurements for sheets of CMs. This will enable, for the first time, studies of temporal and spatial electromechanical coupling behaviors for sheets of CMs at single cell resolution. We will distinguish different subtypes of CMs, their distributions, their interactions, and their phenotypic responses under external perturbations. And we will apply this platform to investigate the structural and electromechanical coupling properties of hESC-derived CMs by integrating quantitative biomass and stiffness data measured using non-invasive live cell interferometry (LCI). Changes in biomass and cell stiffness are druggable biophysical parameters with correlates to mechanical contraction/relaxation cycles of CMs. In addition to detailed studies of CMs that have the potential to impact the number one killer of US citizens, SPOT applications should have utility and provide new insights in additional settings that require cell or tissue traction-force generation. Such settings could include models in a dish for wound healing, cancer cell metastasis, or models of diseases that affect cell and tissue structural integrity, such as connective tissue disorders Ehlers-Danlos or Marfan syndromes. PROJECT NARATIVE Our proposal is exclusively technology development but portends public health relevance because we will invent a way to quantify previously undiscoverable interactions and mechanical responses to external and internal perturbations in interconnected biological systems, as occurs in physiologic and pathologic states. We will develop, test and fine-tune a new technology platform called SPOT (Single Pixel Optical Technology) to extract mechanical responses at cellular resolution in a very wide field, in real-time, concurrently for all cells in a sheet to enable studies and potentially new-age therapeutics that are currently impossible.",SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles,10160919,R01GM127985,"['Address', 'Affect', 'Age', 'Area', 'Arrhythmogenic Right Ventricular Dysplasia', 'Beds', 'Behavior', 'Biomass', 'Cardiac', 'Cardiac Myocytes', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Collection', 'Color', 'Connective Tissue Diseases', 'Coupling', 'Data', 'Defect', 'Development', 'Disease', 'Disease model', 'Distal', 'Drug Screening', 'Electrophysiology (science)', 'Fibroblasts', 'Future', 'Generations', 'Genes', 'Genetic Diseases', 'Giant Cells', 'Goals', 'Heart Atrium', 'Human', 'Imaging technology', 'Interferometry', 'Left', 'Machine Learning', 'Marfan Syndrome', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Neoplasm Metastasis', 'Optics', 'Pathologic', 'Pharmacology Study', 'Phenotype', 'Physiological', 'Population', 'Process', 'Property', 'Regenerative research', 'Relaxation', 'Reporting', 'Resolution', 'Series', 'Spottings', 'Stimulus', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Traction', 'Traction Force Microscopy', 'Transplantation', 'Ventricular', 'Western World', 'biological systems', 'biophysical properties', 'body system', 'cancer cell', 'design', 'desmoplakin', 'electrical measurement', 'electrical property', 'human embryonic stem cell', 'human pluripotent stem cell', 'imaging platform', 'improved', 'indexing', 'insight', 'instrument', 'mechanical properties', 'mortality', 'new technology', 'patch clamp', 'prospective', 'public health relevance', 'response', 'screening', 'small molecule', 'technology development', 'temporal measurement', 'tool', 'wound healing']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,379224
"Development of a high throughput system for molecular imaging of different cell types in mouse brain tissues Development of a high throughput system for molecular imaging of different cell types in mouse brain tissues Mass spectrometry imaging (MSI) is a powerful tool for developing detailed molecular maps of biological tissues with high specificity and sensitivity. This label-free technique enables simultaneous imaging of multiple classes of molecules including lipids, metabolites, and proteins thereby advancing the understanding of tissue organization and function. In this project, we will advance brain cell census research by developing an innovative platform for the acquisition of a comprehensive spatially-resolved cell-specific atlas of lipids, metabolites, and proteins in mouse brain tissue. The platform will combine MSI with immunofluorescence imaging to place the detailed molecular maps into the spatial cellular context within the brain tissue, which will facilitate image registration to the common coordinate system. Furthermore, we will develop deep learning and data mining approaches to enable automated assignment of molecular signatures to different cell types and efficient data sharing and comparison with other techniques. This research will address the existing bottlenecks in the experimental throughout and molecular coverage of the current MSI technologies along with the limitations of data analysis tools. Furthermore, our approach will compensate for signal suppression during ionization also called ‘matrix effects’, which is particularly severe in imaging of brain tissue. Such matrix effects common to all the MSI modalities including commercial MALDI MSI instruments interfere with the accurate measurement of the spatial localization of molecules. To overcome these challenges, we will advance the capabilities of nanospray desorption electrospray ionization (nano-DESI) - an ambient ionization technique, which efficiently compensates for matrix effects and thereby enables accurate and sensitive imaging of chemical gradients for hundreds of metabolites and lipids in biological tissue sections. Nano-DESI MSI does not require sample pretreatment, has a sub-femtomole sensitivity, and high spatial resolution. The new nano-DESI MSI system will provide a 5-fold increase in the experimental throughput and improve the spatial resolution of protein imaging in whole tissue sections from ~80 µm to ~10 µm. Coupling nano-DESI MSI with a high- resolution ion mobility mass spectrometer will substantially enhance molecular coverage. Meanwhile, co- registration of MSI with immunofluorescence data will be used to generate comprehensive 3D molecular maps of the mouse brain tissue. Collectively, these efforts will establish a robust imaging platform, which will transform our ability to generate detailed molecular maps of different cell types in brain tissues. Project Narrative This research is focused on the development of a transformative technology for the high- throughput cell-specific imaging of molecules in brain tissue using mass spectrometry, immunofluorescence microscopy, and advanced data mining and deep learning tools. This novel correlative imaging approach will substantially enhance the range of biomolecules in the brain cell census data.",Development of a high throughput system for molecular imaging of different cell types in mouse brain tissues,10369883,RF1MH128866,"['3-Dimensional', 'Address', 'Anatomy', 'Atlases', 'Biological', 'Brain', 'Brain imaging', 'Cells', 'Censuses', 'Chemicals', 'Classification', 'Coupling', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Development', 'Disease', 'Electrospray Ionization', 'Goals', 'Graph', 'Health', 'Hour', 'Human', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Device', 'Imaging technology', 'Immunofluorescence Immunologic', 'Immunofluorescence Microscopy', 'Label', 'Link', 'Lipids', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Methods', 'Microfluidics', 'Mining', 'Molecular', 'Molecular Profiling', 'Mus', 'Neuroglia', 'Neurons', 'Peptides', 'Proteins', 'Proteomics', 'Research', 'Resolution', 'Robotics', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Spectrometry, Mass, Electrospray Ionization', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Structure', 'System', 'Techniques', 'Tissue imaging', 'Tissues', 'base', 'brain cell', 'brain tissue', 'cell type', 'data acquisition', 'data format', 'data integration', 'data mining', 'data sharing', 'deep learning', 'experimental study', 'high resolution imaging', 'high throughput technology', 'image registration', 'imaging approach', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'innovation', 'interest', 'ion mobility', 'ionization', 'ionization technique', 'large scale data', 'learning strategy', 'lipidomics', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'novel', 'tool']",NIMH,PURDUE UNIVERSITY,RF1,2021,1551972
"A 3D multimodal micron-scale human brain atlas bridging single cell data, neuropathology and neuroradiology Digitized reference brains, also referred to as Common Coordinate Frameworks (CCFs), together with superposed atlas annotations, are of central importance to neuroscience. They bear the same relation to neuroscience as do reference genomes and genome annotations to cellular and molecular biology. Strikingly, however, such reference brains for humans lag far behind the corresponding CCFs for non-human model organisms such as the laboratory mouse. Existing data sets either have sections spaced relatively far apart or lack in-plane resolution down to the micron scale. Crucially, existing data sets are not well connected to the major areas in medicine that deal with the human brain, namely neuroradiology and neuropathology. We will meet this need by creating an unprecedented micron-scale, 3D atlas that combines multiple MRI modalities as well as continuous serial section histology. In particular, the reference atlas will consist of Nissl, Myelin and H&E stains, with 20 micron contiguous serial sections, and approximately ~8000 sections/brain. We will do so using the tape-transfer method, which preserves tissue geometry even in the presence of disconnected pieces to the brain being sectioned, and permits 3D reassembly of the sections into a 3D volume. We will utilize diffeomorphic mapping methods to co-register the MRI and histological data, and will create a human brain CCF in which single-cell transcriptomic and epigenomic data can be pinned in order to create a Human Brain Cell atlas. We will use machine learning approaches to segment cells and processes in these images and to algorithmically detect cytoarchitectonic boundaries; such machine learning methods will also be used to predict histology and cytoarchitecture from MRI data, with our collected data as a training set. We will make our data freely available to scientists as well as medical professionals through an online data portal with a multi-resolution viewer for zooming and panning through terapixel image data, and also deposit the data in a shared data repository to make it easily accessible to other researchers. We will connect our data to a unique on-line neuropathology resource containing over a petabyte of neuropathological images, including H&E stained sections from the coronal plane. We expect that the reference brain data we produce will become the de- facto standard for a high-resolution reference atlas for the human brain. This project will contribute an important reference atlas that is missing from neuroscience: a multimodal, micron-scale 3D atlas of the human brain that links single-cell transcriptomic and epigenomic data sets to the clinically significant fields of neuroradiology and neuropathology. The reference brain data set consists of microstructural MRI measurements coupled with serial- section 3D histology with Nissl, Myelin and H&E stains in whole adult human brains. The project will yield quantitatively and qualitatively more information than the best such histological series available today; it will cross-link to major existing atlases; and it will provide a large database for training machine learning algorithms to predict histology from advanced MRI measurements.","A 3D multimodal micron-scale human brain atlas bridging single cell data, neuropathology and neuroradiology",10370064,RF1MH128875,"['3-Dimensional', 'Adult', 'Algorithms', 'Amygdaloid structure', 'Animal Model', 'Architecture', 'Archives', 'Area', 'Atlases', 'Autopsy', 'BRAIN initiative', 'Brain', 'Brain Stem', 'Brain imaging', 'Brain region', 'Callithrix', 'Cell physiology', 'Cells', 'Censuses', 'Clinical', 'Collection', 'Communities', 'Complement', 'Consent', 'Coupled', 'Cryoultramicrotomy', 'Data', 'Data Analyses', 'Data Set', 'Data Store', 'Databases', 'Deposition', 'Exclusion Criteria', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Geometry', 'Hippocampus (Brain)', 'Histologic', 'Histology', 'Human', 'Hypothalamic structure', 'Image', 'Institution', 'Laboratories', 'Laboratory mice', 'Letters', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modality', 'Molecular and Cellular Biology', 'Monkeys', 'Mus', 'Myelin', 'National Institute of Mental Health', 'Neurosciences', 'Process', 'Research Personnel', 'Resolution', 'Resources', 'Scanning', 'Scientist', 'Series', 'Slide', 'Source', 'Stains', 'Structure', 'Techniques', 'Thalamic structure', 'Thick', 'Tissue Banks', 'Tissue Preservation', 'Tissues', 'Training', 'United States National Institutes of Health', 'Ursidae Family', 'Wit', 'annotation  system', 'base', 'brain cell', 'brain tissue', 'clinically significant', 'crosslink', 'data centers', 'data portal', 'data repository', 'data sharing', 'digital', 'epigenomics', 'experience', 'genome annotation', 'histological image', 'human data', 'image archival system', 'in vivo', 'machine learning algorithm', 'machine learning method', 'multimodality', 'neuroimaging', 'neuropathology', 'petabyte', 'reference genome', 'success', 'tool', 'transcriptome', 'transcriptomics', 'virtual', 'water diffusion', 'whole slide imaging']",NIMH,COLD SPRING HARBOR LABORATORY,RF1,2021,5278129
"Advancing 3D optical body surface scan technology to assess physiological and psychological effects in highly obese population Project Summary Current techniques for measuring the physiological or psychological effects of obesity, and in particular bariatric surgery, either lack sensitivity, are invasive, or require expensive specialized devices. For measuring the physiological effects, BMI is commonly used to diagnose obesity despite the known shortcomings as a marker for metabolic syndrome. Biomarkers such as anthropometric measurements (e.g., waist-to-hip ratio) and visceral adipose tissue (VAT) have been shown to be superior to BMI in predicting health risks associated with obesity, but these measures lack sensitivity, specificity, or are expensive. Another key morbidity associated with obesity is non-alcoholic fatty liver disease (NAFLD) and non-alcoholic steatohepatitis (NASH). The gold standard to the diagnosis and assessment of these conditions is histologic evaluation of liver biopsies. Fibroscan transient elastography is a noninvasive test which can also assess fibrosis, but high BMI and severe steatosis can decrease its accuracy. These approaches are either invasive, expensive, or relatively inaccurate. Measures of self-body perception are commonly used to assess psychological aspects of obesity, as body image is an important motivator for diet, physical activity, and weight loss intention. Body image perception is commonly assessed using self-reports and cartoon-like line drawings which are non-subject specific and insensitive. Based on our preliminary work (R21HL124443) that developed optical body scanning technology to capture 3D body shapes using inexpensive hardware, we propose to use the technology to study the physiological and psychological effects on subjects with severe obesity:  · Develop prediction algorithm for hepatic steatosis, fibrosis, adiposity, and blood biomarkers using optical  scans. The optical scan and biopsy data will be used as the training and validation set to develop a  machine learning algorithm to cheaply and non-invasively predict the biomarkers from 3D body surface data.  · Develop the use of optical scans for measuring the physiological effects of obesity. We will conduct a  cross sectional and longitudinal study to further assess the use of optical surface scans to determine  health indicators associated with obesity (using data from surface scan, DXA and serum biomarkers) for  one year following surgery. We will establish a database of such data along with software for data mining  the database.  · Develop the use of optical scans for measuring the psychological effects of obesity. We will collect 3D  surface geometry of each subject using optical scans and morph these to produce subject-specific images of larger or smaller body shape. We will use these images to study perception related to obesity and in particular patients undergoing post-operative body changes Project Narrative Precise optical scanning of 3D whole body shape is now possible with cheap commercial scanners available on smart phones and tablets. These cheap and accessible scans may hold a heretofore-untapped wealth of health- related information that can be utilized with machine learning. In this proposal, we use the technology to study the physiological and psychological effects in subjects with severe obesity.",Advancing 3D optical body surface scan technology to assess physiological and psychological effects in highly obese population,10280172,R01DK129809,"['3-Dimensional', 'Adipose tissue', 'Biological Markers', 'Biopsy', 'Blood', 'Body Image', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Cartoons', 'Cellular Phone', 'Computer software', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Diet', 'Dual-Energy X-Ray Absorptiometry', 'Evaluation', 'Explosion', 'Face', 'Fatty Liver', 'Fibrosis', 'Geometry', 'Gold', 'Health', 'Histologic', 'Image', 'Intention', 'Liver Fibrosis', 'Longitudinal Studies', 'Longitudinal observational study', 'Machine Learning', 'Measurement', 'Measures', 'Metabolic Marker', 'Metabolic syndrome', 'Methodology', 'Mining', 'Morbid Obesity', 'Morbidity - disease rate', 'Obesity', 'Operative Surgical Procedures', 'Optics', 'Patient Self-Report', 'Patients', 'Perception', 'Physical activity', 'Physiological', 'Postoperative Period', 'Psychological Factors', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Serum', 'Shapes', 'Surface', 'Tablets', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Validation', 'Visceral', 'Waist-Hip Ratio', 'Weight', 'Work', 'bariatric surgery', 'base', 'cost', 'cost effective', 'data mining', 'elastography', 'high body mass index', 'high risk', 'innovation', 'insight', 'liver biopsy', 'machine learning algorithm', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'obese person', 'population based', 'prediction algorithm', 'predictive marker', 'psychologic', 'recruit', 'sensor', 'success', 'tool']",NIDDK,GEORGE WASHINGTON UNIVERSITY,R01,2021,593040
"VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS Abstract Contemporary fluorescence microscopy connects our understanding of molecular events from biochemistry and structural biology with their activities in living cells. Lattice light sheet microscopy (LLSM) has made it possible for us to track phenomena such as endocytic vesicle assembly or lipid kinase recruitment across an entire cell with high resolution, in both space and time, and with nearly single-molecule sensitivity. Development during the past year of lattice light sheet microscopy with adaptive optics (AO-LLSM) has overcome the optical limitations that have so far restricted most studies to individual cells in culture, allowing us to achieve comparable resolution and sensitivity in the complex optical environment of an intact, living, multicellular organism. It promises to bridge the gap between cells and organisms, through high sensitivity, volumetric imaging, with diffraction-limited resolution, of living tissues and developing embryos. We propose a research program in three overlapping stages: implementation of AO-LLSM (in collaboration with its developer), development of the new kinds of visualization and analysis software required by the scale and complexity of the datasets, and use of AO-LLSM to solve a problem in vertebrate development. To meet the computational challenges of analyzing the 4D data sets (from low signal-to-noise, the often non- punctate characteristics of the objects being studied, the temporally varying spatial complexity of the data, and the size of the data sets), we will develop new approaches using deep learning and related algorithms, with consultation from experts. As a paradigm application, we will study the consequences of Notch signaling and the related membrane-traffic and protein translocation events for cell differentiation in zebrafish early neurogenesis. AO-LLSM will for the first time allow us to relate molecular signaling events occurring on a timescale of seconds at cell interfaces to the ultimate fate of daughter cells many hours later. We therefore expect that in the course of resolving some long- standing issues in cell fate determination, we will develop microscopy approaches and computer visualization tools that are widely applicable to a range of model systems and biological questions. Narrative We will implement and apply a novel, live-cell imaging strategy (Lattice Light-Sheet Microscopy with Adaptive Optics: AO-LLSM) that spans, with diffraction-limited resolution, a range from molecules to tissues and from seconds to hours. We will use this new technology to study cell differentiation in the embryonic zebrafish brain, concentrating on how Notch-mediated signaling exerts long-range control over neuronal development. Obtaining accurate and comprehensive models of the underlying biology will require that we devise new and generalizable ways to display and analyze complex data sets, while overcoming the computational challenges posed by the low SNR of the imaging regime, the time-varying spatial complexity of the data, and the size of the data sets.",VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS,10136020,R35GM130386,"['Algorithms', 'Biochemistry', 'Biological', 'Biological Models', 'Biology', 'Brain', 'Cell Differentiation process', 'Cells', 'Characteristics', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data Set', 'Development', 'Embryo', 'Endocytic Vesicle', 'Environment', 'Event', 'Fluorescence Microscopy', 'Hour', 'Image', 'Individual', 'Light', 'Lipids', 'Mediating', 'Membrane Protein Traffic', 'Microscopy', 'Modeling', 'Molecular', 'Noise', 'Optics', 'Organism', 'Phosphotransferases', 'Protein translocation', 'Research', 'Resolution', 'Signal Transduction', 'Time', 'Tissues', 'Visualization', 'Visualization software', 'Zebrafish', 'adaptive optics', 'complex data', 'data complexity', 'daughter cell', 'deep learning', 'live cell imaging', 'neurogenesis', 'neuron development', 'new technology', 'notch protein', 'novel', 'novel strategies', 'programs', 'recruit', 'single molecule', 'structural biology']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2021,442500
"Development of an Open-Source and Data-Driven Modeling Platform to Monitor and Forecast Disease Activity PROJECT SUMMARY Reliable and real-time municipality-level predictive modeling and forecasts of infectious disease activity have the potential to transform the way public health decision-makers design interventions such as information campaigns, preemptive/reactive vaccinations, and vector control, in the presence of health threats across the world. While the links between disease activity and factors such as: human mobility, climate and environmental factors, socio-economic determinants, and social media activity have long been known in the epidemic literature, few efforts have focused on the evident need of developing an open-source platform capable of leveraging multiple data sources, factors, and disparate modeling methodologies, across a large and heterogeneous nation to monitor and forecast disease transmission, over four geographic scales (nation, state, city, and municipal). The overall goal of this project is to develop such a platform. Our long-term goal is to investigate effective ways to incorporate the findings from multiple disparate studies on disease dynamics around the globe with local and global factors such as weather conditions, socio- economic status, satellite imagery and online human behavior, to develop an operational, robust, and real- time data-driven disease forecasting platform. The objective of this grant is to leverage the expertise of three complementary scientific research teams and a wealth of information from a diverse array of data sources to build a modeling platform capable of combining information to produce real-time short term disease forecasts at the local level. As part of this, we will evaluate the predictive power of disparate data streams and modeling approaches to monitor and forecast disease at multiple geographic scales--nation, state, city, and municipality--using Brazil as a test case. Additionally, we will use machine learning and mechanistic models to understand disease dynamics at multiple spatial scales, across a heterogeneous country such as Brazil. Our specific aims will (1) Assess the utility of individual data streams and modeling techniques for disease forecasting; (2) Fuse modeling techniques and data streams to improve accuracy and robustness at the four spatial scales; (3) Characterize the basic computational infrastructure necessary to build an operational disease forecasting platform; and (4) Validate our approach in a real-world setting. This contribution is significant because It will advance our scientific knowledge on the accuracy and limitations of disparate data streams and multiple modeling approaches when used to forecast disease transmission. Our efforts will help produce operational and systematic disease forecasts at a local level (city- and municipality-level). Moreover, we aim at building a new open-source computational platform for the epidemiological community to use as a knowledge discovery tool. Finally, we aim at developing this platform under the guidance of a Subject Matter Expert (SME) panel comprising of WHO, CDC, academics, and local and federal stakeholders within Brazil. The proposed approach is innovative because few efforts have focused on developing an open-source computational platform capable of combining disparate data sources and drivers, across a heterogeneous and large nation, into multiple modeling approaches to monitor and forecast disease transmission, over multiple geographic scales.. In addition, we propose to investigate how to best combine modeling approaches that have, to this date, been developed and interpreted independently, namely, traditional epidemiological mechanistic models and novel machine-learning predictive models, in order to produce accurate and robust real-time disease activity estimates and forecasts. Project Narrative The proposed research is of crucial importance to public health surveillance and preparedness communities because it seeks to identify effective ways to utilize previously disconnected results, that have pointed out links between disease spread and factors such as socio-economic status, local weather conditions, human mobility, social media activity, to build an open-source and data driven, modeling platform capable of extracting and disseminating information from disparate data sources, and complementary modeling approaches, to (1) Evaluate the predictive power of disparate data streams and modeling approaches to monitor and forecast disease at multiple geographic scales: nation, state, city, and municipality; (2) Fuse complementary modeling approaches that have been developed independently and oftentimes not used in conjunction; (3) produce real- time and short term forecasts of disease activity in multiple geographic scales across a heterogeneous and large nation like Brazil.",Development of an Open-Source and Data-Driven Modeling Platform to Monitor and Forecast Disease Activity,10244988,R01GM130668,"['Area', 'Assimilations', 'Beds', 'Behavior', 'Brazil', 'Burn injury', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Climate', 'Communicable Diseases', 'Communities', 'Complement', 'Country', 'Data', 'Data Set', 'Data Sources', 'Dengue', 'Developing Countries', 'Development', 'Disease', 'Disease Outbreaks', 'Elements', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Geography', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'High Performance Computing', 'Human', 'Imagery', 'Individual', 'Influenza', 'Influenza B Virus', 'Institution', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Municipalities', 'Population Surveillance', 'Process', 'Public Health', 'Readiness', 'Research', 'Socioeconomic Status', 'Techniques', 'Testing', 'Time', 'Twitter', 'Vaccination', 'Vector-transmitted infectious disease', 'Water', 'Weather', 'Work', 'ZIKA', 'base', 'chikungunya', 'climate variability', 'computational platform', 'computer infrastructure', 'data infrastructure', 'data modeling', 'data streams', 'digital', 'disease transmission', 'economic determinant', 'economic disparity', 'experience', 'flu', 'genomic data', 'heterogenous data', 'improved', 'innovation', 'mathematical methods', 'meteorological data', 'multiple data sources', 'novel', 'open data', 'open source', 'pathogen', 'pathogen genomics', 'predictive modeling', 'social', 'social media', 'sociodemographics', 'socioeconomics', 'spreading factor', 'therapy design', 'time use', 'tool', 'transmission process', 'trend', 'vector control', 'vector-borne']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2021,364519
"Computational Tools to Characterize the Effects of Protein and RNA Variability in Function and Interactions Project Summary  The scientific goals of the funded parent project of this proposal (R35 MIRA for ESI) include the development of global probabilistic and computational models of biomolecules that characterize and quantify the landscape of protein variability and their interactions. The ultimate goal is to elucidate the landscape of functional mutations, which is hidden within the much larger non-functional space. We are using this functional landscape to engineer hybrid transcriptional regulators as well as to predict specificity networks in two-component systems. Another important goal is to devise models to characterize the sequence dependance on protein-protein and protein-RNA interactions. These models will allow us to encode and predict recognition from inferred landscapes and to integrate our results with experimental technologies. Devising the spectrum of functional biomolecular variability sculpted by evolutionary processes will be used to estimate the effects of mutations in disease, antibiotic resistance, biomolecular sensor design and the impact of sequence composition on interaction networks. As the research program of the parent grant benefits from generative modeling and atomistic molecular simulations, we have turned our attention to build a framework that will produce more accurate estimation of the sequence statistics of biomolecules and perform molecular dynamics in an efficient way. For this reason, we request additional funds to build a new Graphical Processing Unit (GPU) system based on NVIDIA A100 technology and large memory CPU nodes. This technology will accelerate the goals of the parent research program in problems related to machine learning, biomolecular simulation and linear algebra calculations. Project Narrative  In this proposal, an administrative supplement is requested to construct a new Graphical Processing Unit (GPU) system based on NVIDIA A100 technology and large memory CPU nodes to advance the scientific goals of the parent grant. A GPU framework will improve estimation accuracy of the sequence statistics of biomolecules and perform molecular dynamics in an efficient way. This technology will also accelerate the goals of the parent research program in problems related to mutational landscape determination, machine learning, biomolecular simulation and linear algebra calculations.",Computational Tools to Characterize the Effects of Protein and RNA Variability in Function and Interactions,10387914,R35GM133631,"['Administrative Supplement', 'Antibiotic Resistance', 'Attention', 'Computer Models', 'Development', 'Disease', 'Engineering', 'Funding', 'Genetic Transcription', 'Goals', 'Hybrids', 'Linear Algebra', 'Machine Learning', 'Memory', 'Modeling', 'Molecular', 'Mutation', 'Parents', 'Process', 'Proteins', 'RNA', 'RNA-Protein Interaction', 'Research', 'Scientific Advances and Accomplishments', 'Specificity', 'Statistical Models', 'System', 'Technology', 'base', 'computerized tools', 'design', 'improved', 'molecular dynamics', 'parent grant', 'parent project', 'programs', 'sensor', 'simulation', 'statistics']",NIGMS,UNIVERSITY OF TEXAS DALLAS,R35,2021,61830
"Spatiotemporal forecasting of COVID-19 by integrating machine learning and epidemiological modeling PROJECT SUMMARY/ABSTRACT In this ongoing COVID-19 pandemic, it is crucial to have an accurate and early prediction of the spread of highly infectious SARS-CoV-2. A correct prediction of the pandemic situation and future trends enables effective resource allocation and government policies to reduce the detrimental effect of COVID-19 on public health and economics. Although various epidemiological models have facilitated the prediction of the infection spread, their ensemble-averaging approach largely disregards critical information within the heterogeneity. Conventional epidemiological modeling is focused on the global average trends, which is limited in analyzing dynamic local information and does not allow local prediction due to spatial heterogeneity of the pandemic situations. Given the rapid changes of the COVID-19 pandemic, it is also challenging to take urgent responses to the new epidemiological data if we solely rely on human intelligence. Recently, machine learning (ML) is making tremendous progress and has shown that computers can outperform humans in analyzing complex high-dimensional datasets. Our lab has been addressing these challenges in cell biology by developing an ML platform for fluorescence live cell image analyses at the subcellular level. We established the method to deconvolve the subcellular heterogeneity of time series of cell protrusion, which identified distinct subcellular protrusion phenotypes with differential drug susceptibility. Thus, our goal is to leverage our ML platform to address these technical challenges in epidemiological modeling for rapid forecasting of COVID-19 spread at the county level in the United States. First, we will advance our ML platform for the deconvolution of spatial heterogeneity of COVID-19 dynamics. This method will integrate epidemiological models and ML to identify the clusters of US counties sharing similar temporal patterns. Second, we will apply our deep learning-based feature learning, where the deep neural networks learn the critical features guided by prior knowledge and well-established epidemiological mathematical models. This will allow us to generate fine-grained forecasting maps of Covid-19 spread. Our ML platform will bring unprecedented prediction power to epidemiology and enable us to take urgent responses to the current COVID-19 pandemic and future other infectious disease outbreaks. PROJECT NARRATIVE We propose to apply our machine learning framework for automated analyses of county-level dynamics of COVID-19 spread in the United States. By integrating machine learning and epidemiological models, we will identify infectious hot spots and forecast COVID-19 dynamics. This system will automatically update and learn new COVID-19 data and enable urgent predictions.",Spatiotemporal forecasting of COVID-19 by integrating machine learning and epidemiological modeling,10463952,R35GM133725,"['2019-nCoV', 'Address', 'COVID-19', 'COVID-19 pandemic', 'Cells', 'Cellular biology', 'Communicable Diseases', 'Complex', 'Computer Models', 'Computers', 'Consumption', 'County', 'Data', 'Data Set', 'Demography', 'Disease', 'Disease Outbreaks', 'Engineering', 'Epidemiologist', 'Epidemiology', 'Event', 'Eye', 'Fluorescence', 'Focal Infection', 'Future', 'Goals', 'Government', 'Grain', 'Health Policy', 'Heterogeneity', 'Hot Spot', 'Human', 'Image Analysis', 'Infection', 'Intelligence', 'Intervention', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Parents', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Policies', 'Predisposition', 'Public Health', 'Resource Allocation', 'SARS-CoV-2 infection', 'SARS-CoV-2 transmission', 'Series', 'Socioeconomic Status', 'System', 'Time', 'Training', 'United States', 'Update', 'automated analysis', 'base', 'deep learning', 'deep neural network', 'epidemiologic data', 'epidemiological model', 'health economics', 'high dimensionality', 'innovation', 'large datasets', 'learning strategy', 'live cell imaging', 'machine learning method', 'mathematical model', 'pandemic disease', 'prevent', 'response', 'spatiotemporal', 'trend', 'unsupervised learning']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2021,318600
"Unraveling subcellular heterogeneity of molecular coordination by machine learning PROJECT SUMMARY/ABSTRACT Recent advances in fluorescence microscopy allow researchers to acquire an unprecedented amount of live cell image data at high spatial and temporal resolutions. However, these images pose a significant challenge for data analyses due to massive subcellular heterogeneity. Although conventional computer vision algorithms have facilitated automatic image analysis, traditional ensemble-averaging of subcellular heterogeneity could lead to the loss of critical mechanistic details. Given the current rapid growth of cell biological data from new technological development, it is nearly impossible to keep up with the data generation if we solely rely on human intelligence for algorithm development and data analysis. Recently, machine learning (ML) is making tremendous progress and has shown that computers can outperform humans in the analysis of complex high dimensional datasets. Conventional ML application in cell biology, however, is usually limited to fixed cells or low spatial resolution setting (single cell resolution), which is limited in analyzing dynamic subcellular information. To fill this voids, we have been developing an ML framework for fluorescence live cell image analyses at the subcellular level. In our previous study, we established the method to deconvolve the subcellular heterogeneity of lamellipodial protrusion from live cell imaging, which identified distinct subcellular protrusion phenotypes with differential drug susceptibility. Thus, our goal is to advance this ML framework and address technical and cell biological challenges in the live cell analysis. The overall goal of our research is two- fold: i) advancing a new ML framework for cell biological research (technological development) and ii) applying our ML framework to integrate mechanobiology and metabolism in cell protrusion (targeted cell biological study). First, we will advance our ML framework for the deconvolution of subcellular heterogeneity of protrusion and molecular coordination in live cells. This method will integrate time-series modeling and ML to deconvolve subcellular molecular coordination. Second, we will develop deep learning based high-throughput fluorescence live cell imaging. This will include microscope automation, resolution enhancement, and data synthesis, which will build up the massive dataset for ML. Third, we will apply our ML framework to study the mechanosensitivity of subcellular bioenergetic status in cell protrusion. We will evaluate how AMPK reacts to mechanical forces and controls the subcellular organization of actin assembly and mitochondria to promote energy-demanding protrusion phenotypes. Our ML framework will bring unprecedented analytical power to cell biology by analyzing a large numbers of individual cells at the high spatial resolution and automatically extracting a multitude of subcellular phenotypes. This framework can be applied to various areas of cell biology such as cytoskeleton, membrane remodeling, and membrane-bound organelles. PROJECT NARRATIVE We propose to develop a novel machine learning framework for automated, large-scale analyses of single cells at the subcellular level. By integrating time-series modeling and machine learning, this new system will enable us to identify hidden phenotypes and molecular coordination from live cell movies. We will apply the developed technology to study the interplay between mechanical forces and metabolism in cell protrusion.",Unraveling subcellular heterogeneity of molecular coordination by machine learning,10267171,R35GM133725,"['Actins', 'Address', 'Algorithms', 'Area', 'Automation', 'Bioenergetics', 'Biological', 'Cells', 'Cellular biology', 'Complex', 'Computer Vision Systems', 'Computers', 'Cytoskeleton', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Fluorescence', 'Fluorescence Microscopy', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Individual', 'Lead', 'Machine Learning', 'Membrane', 'Metabolism', 'Methods', 'Microscope', 'Mitochondria', 'Modeling', 'Molecular', 'Organelles', 'Pharmaceutical Preparations', 'Phenotype', 'Predisposition', 'Research', 'Research Personnel', 'Resolution', 'Series', 'System', 'Technology', 'Time', 'algorithm development', 'base', 'biological research', 'cell growth', 'deep learning', 'high dimensionality', 'intelligent algorithm', 'live cell imaging', 'mechanical force', 'movie', 'novel', 'rapid growth', 'single cell analysis', 'temporal measurement']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2021,442500
"Building protein structure models for intermediate resolution cryo-electron microscopy maps Project Summary Cryo-electron microscopy (cryo-EM) is an emerging technique in structural biology, which is capable of determining three-dimensional (3D) structures of biological macromolecules. Compared to conventional structural biology techniques, such as X-ray crystallography and NMR, a major advantage of cryo-EM is its ability to solve large macromolecular assemblies. Moreover, recent technical breakthroughs in cryo-EM have enabled determination of 3D structures at nearly atomic-level resolutions. Cryo-EM will undoubtedly become a method of central importance in structural biology in the next decade. With the rapid accumulation of cryo-EM structure data, it has become crucial to develop computational methods that can effectively build and extract 3D structures of biological macromolecules from EM maps. The goal of this project is to develop computational methods for modeling both global and local structures and for interpreting 3D structures embedded in EM maps of around 4 Å to medium-resolution. Recently, we have developed a new de novo protein structure modeling method, MAINMAST, which can model protein structures from an EM density map without using existing template or fragment structures on the map. Based on the successful development of MAINMAST, we further extend the capability of MAINMAST toward more accurate modeling and for multiple-chain modeling. In addition, we will also develop novel modeling methods for medium-resolution EM maps, which combine a coarse-grained protein structure modeling technique, methods in protein structure prediction, and a low- resolution image processing approach with deep learning, a state-of-the-art powerful machine learning method. The proposed project capitalizes on the tremendous efforts and progress made in structural determination with cryo-EM by developing computational tools that allow researchers to perform efficient and reliable structure analyses for 3D EM density maps. The project will greatly facilitate investigation into the molecular mechanisms of macromolecule function by providing an efficient means of 3D structure modeling. Narrative Cryo-electron microscopy is an emerging technique for determining the three-dimensional structure of biological macromolecules. We propose to develop computational methods that can accurately and effectively model and interpret structures of biomolecules embedded in electron microscopy density maps and thereby facilitate the understanding of molecular mechanisms of protein function and disease.",Building protein structure models for intermediate resolution cryo-electron microscopy maps,10405197,R01GM133840,"['3-Dimensional', 'Award', 'Biological', 'Cloud Computing', 'Code', 'Communication', 'Computer software', 'Computers', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Detection', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Goals', 'Grain', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Libraries', 'Linux', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Nucleotides', 'Peer Review', 'Publishing', 'Pythons', 'Readiness', 'Research Personnel', 'Resolution', 'Running', 'Secondary Protein Structure', 'Source Code', 'Structural Models', 'Structure', 'Techniques', 'Three-dimensional analysis', 'Writing', 'X-Ray Crystallography', 'base', 'computer cluster', 'computerized tools', 'deep learning', 'density', 'image processing', 'improved', 'machine learning method', 'macromolecular assembly', 'macromolecule', 'novel', 'open source', 'programs', 'protein function', 'protein structure', 'protein structure prediction', 'simulation software', 'software development', 'sound', 'structural biology', 'three dimensional structure', 'user-friendly', 'web page', 'web server', 'web site']",NIGMS,PURDUE UNIVERSITY,R01,2021,116250
"Building protein structure models for intermediate resolution cryo-electron microscopy maps Project Summary Cryo-electron microscopy (cryo-EM) is an emerging technique in structural biology, which is capable of determining three-dimensional (3D) structures of biological macromolecules. Compared to conventional structural biology techniques, such as X-ray crystallography and NMR, a major advantage of cryo-EM is its ability to solve large macromolecular assemblies. Moreover, recent technical breakthroughs in cryo-EM have enabled determination of 3D structures at nearly atomic-level resolutions. Cryo-EM will undoubtedly become a method of central importance in structural biology in the next decade. With the rapid accumulation of cryo-EM structure data, it has become crucial to develop computational methods that can effectively build and extract 3D structures of biological macromolecules from EM maps. The goal of this project is to develop computational methods for modeling both global and local structures and for interpreting 3D structures embedded in EM maps of around 4 Å to medium-resolution. Recently, we have developed a new de novo protein structure modeling method, MAINMAST, which can model protein structures from an EM density map without using existing template or fragment structures on the map. Based on the successful development of MAINMAST, we further extend the capability of MAINMAST toward more accurate modeling and for multiple-chain modeling. In addition, we will also develop novel modeling methods for medium-resolution EM maps, which combine a coarse-grained protein structure modeling technique, methods in protein structure prediction, and a low- resolution image processing approach with deep learning, a state-of-the-art powerful machine learning method. The proposed project capitalizes on the tremendous efforts and progress made in structural determination with cryo-EM by developing computational tools that allow researchers to perform efficient and reliable structure analyses for 3D EM density maps. The project will greatly facilitate investigation into the molecular mechanisms of macromolecule function by providing an efficient means of 3D structure modeling. Narrative Cryo-electron microscopy is an emerging technique for determining the three-dimensional structure of biological macromolecules. We propose to develop computational methods that can accurately and effectively model and interpret structures of biomolecules embedded in electron microscopy density maps and thereby facilitate the understanding of molecular mechanisms of protein function and disease.",Building protein structure models for intermediate resolution cryo-electron microscopy maps,10266083,R01GM133840,"['3-Dimensional', 'Algorithms', 'Amino Acids', 'Area', 'Biological', 'Cells', 'Chimera organism', 'Code', 'Communication', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'Cryoelectron Microscopy', 'DNA', 'Data', 'Development', 'Disease', 'Electron Microscopy', 'Goals', 'Grain', 'Human', 'Intervention', 'Investigation', 'Knowledge', 'Ligands', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Multiprotein Complexes', 'Nature', 'Positioning Attribute', 'Preparation', 'Protein Region', 'Proteins', 'Publishing', 'RNA', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Side', 'Source Code', 'Structural Models', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Visualization software', 'X-Ray Crystallography', 'base', 'computerized tools', 'data acquisition', 'deep learning', 'density', 'detection method', 'graphical user interface', 'image processing', 'improved', 'machine learning method', 'macromolecular assembly', 'macromolecule', 'model building', 'novel', 'programs', 'protein function', 'protein structure', 'protein structure prediction', 'repository', 'software development', 'structural biology', 'three dimensional structure', 'tool']",NIGMS,PURDUE UNIVERSITY,R01,2021,305459
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,10187596,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,328051
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography-Administrative Supplement Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely address in this proposal. We will design novel data- driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following specific aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to reconstruct tomograms with improved resolution; (2) We will develop a saliency-based auto- picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be refined by a new subtomogram averaging algorithm that automatically down weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mitochondrial ultrastructures datasets to improve the final resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface α-tom to directly benefit the scientific community. α-tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, α-tom will be integrated into existing software platforms Scipion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo- ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to improve our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI α-Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the final subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the final results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography-Administrative Supplement,10388867,R01GM134020,"['3-Dimensional', 'Address', 'Administrative Supplement', 'Algorithmic Software', 'Algorithms', 'Benchmarking', 'Communities', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Image', 'In Situ', 'Machine Learning', 'Macromolecular Complexes', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Noise', 'Organelles', 'Performance', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Structure', 'System', 'Time', 'Tomogram', 'Weight', 'autoencoder', 'automated algorithm', 'base', 'design', 'graphical user interface', 'improved', 'innovation', 'machine learning algorithm', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'reconstruction', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,112836
"Administrative Equipment Supplement for GM135160 PROJECT SUMMARY Cellular shape change is a fundamental characteristic of metazoan cells that is key to development, physiology, and pathology. The formation and plasticity of neural networks are key examples of cell shape change during development and physiology, whereas cell shape and motility goes awry in cancers such as melanoma. The active control of the cytoskeleton is acknowledged as critical to cellular shape change, whereas the concurrent remodeling of the plasma membrane is perhaps less well appreciated. Although many cytoskeletal and membrane remodeling components are known and their biochemical and structural characteristics described, we lack a systematic understanding of how these disparate systems are regulated and coordinated to orchestrate cellular shape change. Perhaps the most important problem in cell morphogenesis is understanding how cells perceive cues in their environment and convert this extracellular information into shape changes through coordinated cytoskeletal dynamics and plasma membrane remodeling. Functions of small GTPases and kinases are well studied in regulating cytoskeletal dynamics and membrane remodeling. Work from my lab identified an emerging role for E3 ubiquitin ligases in regulated cellular shape change. We identified two E3 ubiquitin ligases, TRIM9 and TRIM67, which regulate cytoskeletal and exocytic proteins and cellular shape changes in response to netrin. Netrin is an extracellular morphogen that promotes neuronal morphogenesis and the progression of cancers, such as melanoma. TRIM9 and TRIM67 thus provided an excellent entry point for the lab to investigate how cytoskeletal and membrane remodeling are coordinated during netrin triggered morphogenesis and motility. TRIM9 and TRIM67 share similar sequences, localization, and interaction partners, however our studies identified distinct functions of these related proteins and antagonistic phenotypes associated with their deletion. The overarching goal of this program is to test the hypothesis that TRIM9 and TRIM67 coordinate cytoskeletal dynamics and exocytosis during netrin-dependent morphogenesis in neurons and migrating melanoma cells. Our work will provide fundamental mechanistic understanding of the regulation of the cytoskeleton and membrane trafficking during development and metastasis. PROJECT NARRATIVE Cellular shape change is a fundamental characteristic of cells, key to development, physiology, and pathology. The morphogen netrin promotes neuronal development and cancer progression, yet we know little about how cells interpret netrin into shape changes. Our work exploits developing neurons and migrating melanoma cells as model systems to examine how netrin alters cellular shape during development and metastasis.",Administrative Equipment Supplement for GM135160,10387434,R35GM135160,"['Actins', 'Address', 'Biochemical', 'Biological Models', 'Cell Shape', 'Cell membrane', 'Cells', 'Cellular Structures', 'Characteristics', 'Computer Vision Systems', 'Cues', 'Cytoskeletal Proteins', 'Cytoskeleton', 'Development', 'Environment', 'Equipment', 'Event', 'Exocytosis', 'Filopodia', 'Frequencies', 'Genetic', 'Goals', 'Knowledge', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Melanoma Cell', 'Membrane', 'Microfluidics', 'Microscopy', 'Microtubules', 'Monomeric GTP-Binding Proteins', 'Morphogenesis', 'Neoplasm Metastasis', 'Neuronal Plasticity', 'Neurons', 'Pathology', 'Peripheral', 'Phenotype', 'Phosphotransferases', 'Physiology', 'Play', 'Proteins', 'Publishing', 'Quantitative Evaluations', 'Regulation', 'Role', 'Shapes', 'Structure', 'System', 'TRIM Gene', 'Testing', 'Vesicle', 'Work', 'active control', 'cell motility', 'depolymerization', 'extracellular', 'genetic regulatory protein', 'melanoma', 'morphogens', 'neural network', 'neuron development', 'novel', 'polymerization', 'programs', 'protein transport', 'response', 'sensor', 'spatiotemporal', 'tool', 'trafficking', 'tumor progression', 'ubiquitin-protein ligase']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,90000
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,10234111,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2021,254846
"Dissecting the mechanism of cell migration at the systems level Project Summary/Abstract Cell migration is required for many important physiological and pathological processes such as embryonic development, wound healing, and cancerous invasion. As a process that involves concerted action of multiple ensembles of molecules over the length of the entire cell, cell migration cannot be understood using conventional molecular approaches alone without considering sensing, actuation, and control at the whole cell level. This project seeks to approach migrating cells in a top-down manner as an integrated mechanochemical system. Based on observations that likely represent the manifestation of a complex network of molecular interactions, we may deduct how the underlying machine operates. The project will be facilitated by the development of new technologies, including 3D printing of polyacrylamide hydrogels and machine learning for cell tracking, traction force microscopy, and super resolution imaging. We will address three important aspects. First, we will ask how cells initiate migration through a process known as symmetry breaking, which causes a symmetrically spreading cell to initiate directional migration. We will examine various anisotropic properties of the substrate as potential symmetry breaking cues. In addition, the function of filopodia as possible sensors for symmetry breaking will be studied with imaging and pharmacological approaches. Second, we will address several poorly understood aspects of 2D and 3D cell migration. By following migrating cells over a long distance at a high magnification, we expect to place the newly discovered process of contact following in the context of cell collectives. To understand how cell shape control, cell-cell interaction, and cell migration respond to 3D environment, we will use 3D printed polyacrylamide to create model systems and systematically vary geometrical and mechanical parameters. We will then extend the experiments to decellularized lung scaffolds, which have been used for tissue engineering, to determine how migration characteristics in 3D is related to the promotion of tissue formation. Another overlooked area we will examine is the function of the tail in defining cell polarity and mediating contact following. Third, we will seek mechanistic understanding of cellular responses to cyclic stretching, which occurs in various tissues. A novel imaging approach will allow us to determine the responses during the stretching and relaxation phase respectively. A combination of experimentation and computer modeling is planned to explain why epithelial cells respond to static stretching along the direction of forces but perpendicularly in response to cyclic stretching. We will also test the hypothesis that responses to cyclic stretching can cause cell intercalation, a fundamentally important process in embryonic morphogenesis. We expect our results to complement studies at the molecular level and bring paradigm shifting insights into cell migration for both basic cell biology and repair of tissue functions. Project Narrative This project seeks to fill important gaps of knowledge in cell migration, which is essential for many physiological and pathological processes such as embryonic development, wound healing, and cancerous invasion. We will use a top-down approach that treats migrating cells as an integrated mechanical system, and we are developing technologies such as 3D printing and artificial intelligence for fabricating experimental environments, following cell movements, and imaging interactions in 3D scaffolds. Knowledge in how migrating cells interact with the environment and with each other is expected to further our abilities to counter diseases and restore body functions.",Dissecting the mechanism of cell migration at the systems level,10153827,R35GM136345,"['3-Dimensional', '3D Print', 'Address', 'Area', 'Artificial Intelligence', 'Binding', 'Biological Models', 'Cancerous', 'Cell Communication', 'Cell Polarity', 'Cell Shape', 'Cells', 'Cellular biology', 'Characteristics', 'Complement', 'Complex', 'Computer Models', 'Cues', 'Deductibles', 'Development', 'Disease', 'Embryo', 'Embryonic Development', 'Environment', 'Epithelial Cells', 'Filopodia', 'Image', 'Knowledge', 'Length', 'Lung', 'Machine Learning', 'Mechanics', 'Mediating', 'Molecular', 'Morphogenesis', 'Pathologic Processes', 'Periodicity', 'Pharmacology', 'Phase', 'Physiological Processes', 'Process', 'Property', 'Relaxation', 'Resolution', 'Stretching', 'System', 'Tail', 'Technology', 'Testing', 'Tissue Engineering', 'Tissues', 'Traction Force Microscopy', 'base', 'cell motility', 'experimental study', 'imaging approach', 'insight', 'intercalation', 'migration', 'new technology', 'novel', 'polyacrylamide', 'polyacrylamide hydrogels', 'response', 'scaffold', 'sensor', 'tissue repair', 'wound healing']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R35,2021,339635
"NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins Project summary Nuclear magnetic resonance (NMR) spectroscopy is essential for the study structure, dynamics and function of proteins in near-native conditions. NMR studies have vital implications for therapeutic development. However, as the number of amino acids in the protein increases, NMR signals decay (relax) faster, yielding lower sensitivity and resolution, while the spectrum becomes more crowded. In these cases it is challenging to match observed signals to specific nuclei in the protein (called `resonance assignment') in order to meaningfully interpret NMR data. The overarching goal of our research is to push the boundaries of NMR enabling valuable insight about the dynamics and functions of currently intractable proteins. The objective of this project is to design an NMR platform consisting of coordinated, next-generation biochemical, biophysical, mathematical, and computational techniques. Our platform is built around an original approach to NMR spectroscopy in which new information about the local environment of each nucleus is encoded in the shape and pattern of its NMR signal. The rationale is that these patterns are a `fingerprint' – an intricate and unique signature that encodes key information about which atom is responsible for each resonance peak in the NMR spectrum. We will design and realize fingerprint patterns using two innovative approaches: 1) biochemically, by selectively introducing NMR-active isotopes into carefully chosen positions in the protein samples, and biophysically, and 2) by using specialized radiofrequency pulses to accurately control the quantum interactions that determine the NMR spectrum. The resulting fingerprints will be decoded using established algorithmic structures from machine learning, notably artificial neural networks. This will facilitate automated analyses that are accessible to non-NMR specialists. Our approach to spectroscopy holds promise in the study of therapeutically important proteins expressed in eukaryotic expression systems (e.g. G-protein coupled receptors and glycosylated proteins). Current NMR data from such proteins shows clear dynamics and interactions with other proteins, but cannot yet be properly interpreted because of the difficulty of relating each NMR peak to an amino acid in the protein sequence. Our platform will deliver two significant outcomes: 1) NMR resonance assignment for meaningful analyses of previously intractable systems. 2) Enable non-NMR specialists, to easily proceed from expressing their protein sample to using NMR to study dynamics and interactions via assigned spectra. This will have a positive impact on protein science and medical research. To support our mission we have assembled a team of leading experts to test our platform with their own protein systems. Project Narrative Nuclear magnetic resonance (NMR) spectroscopy is used to study the structure, function, interactions, and dynamics of proteins, with important implications for therapeutic development. However, interpreting NMR information is extremely challenging and labor intensive, especially for large proteins, which produce many overlapping, weak NMR signals. We are developing next-generation methods in which key information is more clearly visible and accessible in the NMR data, using a highly coordinated platform of emerging biochemical, biophysical, mathematical, and computational techniques.","NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins",10392661,R01GM136859,"['Algorithms', 'Amino Acid Sequence', 'Amino Acids', 'Biochemical', 'Biophysics', 'Cell Nucleus', 'Computational Technique', 'Crowding', 'Data', 'Environment', 'Fingerprint', 'G-Protein-Coupled Receptors', 'Goals', 'Isotope Labeling', 'Isotopes', 'Machine Learning', 'Mathematics', 'Medical Research', 'Methods', 'Mission', 'NMR Spectroscopy', 'Nuclear Magnetic Resonance', 'Outcome', 'Pattern', 'Physiologic pulse', 'Positioning Attribute', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Sampling', 'Science', 'Shapes', 'Signal Transduction', 'Specialist', 'Spectrum Analysis', 'Structure', 'System', 'Testing', 'Therapeutic Studies', 'artificial neural network', 'automated analysis', 'design', 'innovation', 'insight', 'next generation', 'protein function', 'quantum', 'radio frequency', 'therapeutic development']",NIGMS,DANA-FARBER CANCER INST,R01,2021,13250
"NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins Project summary Nuclear magnetic resonance (NMR) spectroscopy is essential for the study structure, dynamics and function of proteins in near-native conditions. NMR studies have vital implications for therapeutic development. However, as the number of amino acids in the protein increases, NMR signals decay (relax) faster, yielding lower sensitivity and resolution, while the spectrum becomes more crowded. In these cases it is challenging to match observed signals to specific nuclei in the protein (called `resonance assignment') in order to meaningfully interpret NMR data. The overarching goal of our research is to push the boundaries of NMR enabling valuable insight about the dynamics and functions of currently intractable proteins. The objective of this project is to design an NMR platform consisting of coordinated, next-generation biochemical, biophysical, mathematical, and computational techniques. Our platform is built around an original approach to NMR spectroscopy in which new information about the local environment of each nucleus is encoded in the shape and pattern of its NMR signal. The rationale is that these patterns are a `fingerprint' – an intricate and unique signature that encodes key information about which atom is responsible for each resonance peak in the NMR spectrum. We will design and realize fingerprint patterns using two innovative approaches: 1) biochemically, by selectively introducing NMR-active isotopes into carefully chosen positions in the protein samples, and biophysically, and 2) by using specialized radiofrequency pulses to accurately control the quantum interactions that determine the NMR spectrum. The resulting fingerprints will be decoded using established algorithmic structures from machine learning, notably artificial neural networks. This will facilitate automated analyses that are accessible to non-NMR specialists. Our approach to spectroscopy holds promise in the study of therapeutically important proteins expressed in eukaryotic expression systems (e.g. G-protein coupled receptors and glycosylated proteins). Current NMR data from such proteins shows clear dynamics and interactions with other proteins, but cannot yet be properly interpreted because of the difficulty of relating each NMR peak to an amino acid in the protein sequence. Our platform will deliver two significant outcomes: 1) NMR resonance assignment for meaningful analyses of previously intractable systems. 2) Enable non-NMR specialists, to easily proceed from expressing their protein sample to using NMR to study dynamics and interactions via assigned spectra. This will have a positive impact on protein science and medical research. To support our mission we have assembled a team of leading experts to test our platform with their own protein systems. Project Narrative Nuclear magnetic resonance (NMR) spectroscopy is used to study the structure, function, interactions, and dynamics of proteins, with important implications for therapeutic development. However, interpreting NMR information is extremely challenging and labor intensive, especially for large proteins, which produce many overlapping, weak NMR signals. We are developing next-generation methods in which key information is more clearly visible and accessible in the NMR data, using a highly coordinated platform of emerging biochemical, biophysical, mathematical, and computational techniques.","NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins",10387787,R01GM136859,"['Algorithms', 'Amino Acid Sequence', 'Amino Acids', 'Biochemical', 'Biophysics', 'Cell Nucleus', 'Computational Technique', 'Crowding', 'Data', 'Environment', 'Fingerprint', 'G-Protein-Coupled Receptors', 'Goals', 'Isotope Labeling', 'Isotopes', 'Machine Learning', 'Mathematics', 'Medical Research', 'Methods', 'Mission', 'NMR Spectroscopy', 'Nuclear Magnetic Resonance', 'Outcome', 'Pattern', 'Physiologic pulse', 'Positioning Attribute', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Sampling', 'Science', 'Shapes', 'Signal Transduction', 'Specialist', 'Spectrum Analysis', 'Structure', 'System', 'Testing', 'Therapeutic Studies', 'artificial neural network', 'automated analysis', 'design', 'innovation', 'insight', 'next generation', 'protein function', 'quantum', 'radio frequency', 'therapeutic development']",NIGMS,DANA-FARBER CANCER INST,R01,2021,75000
"NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins Project summary Nuclear magnetic resonance (NMR) spectroscopy is essential for the study structure, dynamics and function of proteins in near-native conditions. NMR studies have vital implications for therapeutic development. However, as the number of amino acids in the protein increases, NMR signals decay (relax) faster, yielding lower sensitivity and resolution, while the spectrum becomes more crowded. In these cases it is challenging to match observed signals to specific nuclei in the protein (called `resonance assignment') in order to meaningfully interpret NMR data. The overarching goal of our research is to push the boundaries of NMR enabling valuable insight about the dynamics and functions of currently intractable proteins. The objective of this project is to design an NMR platform consisting of coordinated, next-generation biochemical, biophysical, mathematical, and computational techniques. Our platform is built around an original approach to NMR spectroscopy in which new information about the local environment of each nucleus is encoded in the shape and pattern of its NMR signal. The rationale is that these patterns are a `fingerprint' – an intricate and unique signature that encodes key information about which atom is responsible for each resonance peak in the NMR spectrum. We will design and realize fingerprint patterns using two innovative approaches: 1) biochemically, by selectively introducing NMR-active isotopes into carefully chosen positions in the protein samples, and biophysically, and 2) by using specialized radiofrequency pulses to accurately control the quantum interactions that determine the NMR spectrum. The resulting fingerprints will be decoded using established algorithmic structures from machine learning, notably artificial neural networks. This will facilitate automated analyses that are accessible to non-NMR specialists. Our approach to spectroscopy holds promise in the study of therapeutically important proteins expressed in eukaryotic expression systems (e.g. G-protein coupled receptors and glycosylated proteins). Current NMR data from such proteins shows clear dynamics and interactions with other proteins, but cannot yet be properly interpreted because of the difficulty of relating each NMR peak to an amino acid in the protein sequence. Our platform will deliver two significant outcomes: 1) NMR resonance assignment for meaningful analyses of previously intractable systems. 2) Enable non-NMR specialists, to easily proceed from expressing their protein sample to using NMR to study dynamics and interactions via assigned spectra. This will have a positive impact on protein science and medical research. To support our mission we have assembled a team of leading experts to test our platform with their own protein systems. Project Narrative Nuclear magnetic resonance (NMR) spectroscopy is used to study the structure, function, interactions, and dynamics of proteins, with important implications for therapeutic development. However, interpreting NMR information is extremely challenging and labor intensive, especially for large proteins, which produce many overlapping, weak NMR signals. We are developing next-generation methods in which key information is more clearly visible and accessible in the NMR data, using a highly coordinated platform of emerging biochemical, biophysical, mathematical, and computational techniques.","NMR Fingerprinting: Leveraging optimal control pulse design, tailored isotope labeling, and machine learning to study intractable proteins",10159285,R01GM136859,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acids', 'Biochemical', 'Biological Models', 'Biophysics', 'COSY', 'Cell Nucleus', 'Chemicals', 'Communities', 'Complement', 'Computational Technique', 'Computer software', 'Coupling', 'Crowding', 'Cryoelectron Microscopy', 'Data', 'Drug Design', 'Environment', 'Fingerprint', 'Frequencies', 'G-Protein-Coupled Receptors', 'Goals', 'HMQC', 'Hour', 'Investigation', 'Isotope Labeling', 'Isotopes', 'Label', 'Machine Learning', 'Mainstreaming', 'Mathematics', 'Measurement', 'Measures', 'Medical Research', 'Methods', 'Mission', 'Modernization', 'Molecular Weight', 'NMR Spectroscopy', 'Nuclear', 'Nuclear Magnetic Resonance', 'Outcome', 'Pattern', 'Physiologic pulse', 'Positioning Attribute', 'Protein Dynamics', 'Proteins', 'Pyruvate', 'Relaxation', 'Research', 'Research Proposals', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Shapes', 'Side', 'Signal Transduction', 'Specialist', 'Spectrum Analysis', 'Structural Protein', 'Structure', 'System', 'TOCSY', 'Testing', 'Textbooks', 'Therapeutic', 'Therapeutic Studies', 'Time', 'Training', 'Vertebral column', 'X-Ray Crystallography', 'artificial neural network', 'automated analysis', 'base', 'control theory', 'cost', 'design', 'experimental study', 'innovation', 'insight', 'instrument', 'methyl group', 'next generation', 'nonlinear regression', 'novel', 'novel strategies', 'nuclear power', 'protein function', 'quantum', 'radio frequency', 'reconstruction', 'therapeutic development']",NIGMS,DANA-FARBER CANCER INST,R01,2021,445749
"Investigating how mechanical connectivity yields developmental robustness ABSTRACT  It is essential for the fate of an organism that key morphogenetic processes occur reproducibly even under tissue damage or environmental perturbations. While much is known about how genetic redundancy and regulation achieves robust development, less is understood about how a tissue mechanically ensures reproducible shape change when perturbed. This project uncovers how populations of physically interacting cells mechanically respond to challenging conditions and modify their collective behavior to still sculpt the correct final shape.  One way for cells to coordinate tissue-scale forces and movements is through direct mechanical connections. In fact, many developing tissues exhibit supracellular networks of actomyosin connections that link hundreds of cells. A large roadblock has been with the challenges of imaging and quantifying subcellular protein at the tissue scale. I adapted a topological smoothing algorithm originally used to trace high-noise filamentous structure of galaxies in the Universe to data to trace high-noise filamentous myosin structure in confocal images. This allowed for the first quantification of a supracellular myosin network across an entire tissue over developmental time. Subsequent analysis adopting techniques from network theory allowed me to identify that the robust folding of the Drosophila fruit fly embryo during ventral furrow formation is mechanically ensured by patterns in the supracellular network spanning its ventral cells.  This newly discovered importance of supracellular networks in coordinating robust shape change highlights the need for a comprehensive understanding of how supracellular networks form, and how their patterns impact the function and robustness of a population of cells. Deciphering robustness at the tissue-level, where the displacement and fate of hundreds of cells must be considered, requires techniques at the interface of cell and developmental biology, biophysics and computer science. The proposed project will take a highly interdisciplinary approach to identify how supracellular network patterns are controlled molecularly, at the cell level, and via tissue constraints. As well, how heterogeneity in tissue-level patterns impacts morphogenetic robustness will be addressed. Together this comprehensive study of the structure and function of supracellular networks will represent a new way to interpret mechanical robustness across diverse developing tissues. As well, a generalized description of mechanical robustness has the potential to uncover new paths to predict and control tissue malformation, which would represent a significant advance for both developmental biology and fetal medicine. PROJECT NARRATIVE The robust establishment of correct shape is essential for proper tissue function. Tissue shape change is a mechanical process that necessitates the coordinated force generation and motion of thousands of cells. Identifying how physically interacting cells mechanically respond to challenging conditions and modify their behavior to still sculpt the correct final shape will shed light onto many congenital disorders that result from morphogenetic dysregulation.",Investigating how mechanical connectivity yields developmental robustness,10261353,K99GM136915,"['Actomyosin', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Architecture', 'Behavior', 'Biophysics', 'Cell Culture Techniques', 'Cell Size', 'Cells', 'Cellular biology', 'Congenital Abnormality', 'Congenital Disorders', 'Data', 'Development', 'Developmental Biology', 'Disease', 'Drosophila genus', 'Early Diagnosis', 'Embryo', 'Engineering', 'Ensure', 'Exhibits', 'Galaxy', 'Generations', 'Genetic', 'Heterogeneity', 'Image', 'In Vitro', 'Light', 'Link', 'Location', 'Machine Learning', 'Maternal-fetal medicine', 'Mechanics', 'Molecular', 'Morphogenesis', 'Morphology', 'Motion', 'Movement', 'Myosin ATPase', 'Neural Tube Defects', 'Noise', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Property', 'Proteins', 'Regulation', 'Reproducibility', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Transportation', 'Work', 'cohesion', 'computer science', 'confocal imaging', 'congenital heart disorder', 'fetal', 'fetal medicine', 'fly', 'in vivo', 'interdisciplinary approach', 'malformation', 'mechanical force', 'mechanical properties', 'novel', 'optogenetics', 'theories', 'tissue-level behavior', 'transmission process']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,K99,2021,98836
"A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals PROJECT SUMMARY The aim of this proposal is to deliver an innovative and easy-to-use experimental platform for measuring and quantifying naturalistic behaviors of mammalian animal models used for biomedical research, including rodents and monkeys, across a range of spatial and temporal scales. This will require developing a method for tracking movements freely behaving animals with far higher spatiotemporal resolution and more kinematic detail than currently possible. To overcome the limitations of current technologies, a new solution is proposed that synergistically combines two methods - marker based motion capture and a video- based machine learning approach. First, using marker-based motion capture, the gold standard for 3D tracking in humans, the position of experimental subjects' head, trunk, and limbs will be tracked in 3D with submillimeter precision. An innovative marker design, placement strategy, and post-processing pipeline will ensure an unprecedentedly detailed description of rodent behavior over a large range of timescales. To make the system more efficient, robust, affordable and better suited for high-throughput longitudinal studies, the unprecedentedly rich and large 3D datasets generated by the motion capture experiments will be leveraged to train a deep neural network to predict pose and appendage positions from a set of 1-6 normal video cameras. To best capitalize on the large training datasets, the latest advances in convolutional neural networks for image analysis will be incorporated. Together, these advances will promote generalization of the high-resolution 3D tracking system to a variety of animals and environments, thus establishing a cheap, flexible, and easy-to use kinematic tracking method that can easily be scaled up and adopted by other labs. The large ground-truth datasets will allow the system to be benchmarked and compared against state-of-the art technologies in quantitative and rigorous ways. Preliminary studies have been very positive and suggest large improvements over current methods both when it comes to the range of behaviors that can be tracked and the precision with which they can be measured. Importantly, all new technology will be readily shared with the scientific community, thereby leveraging from this single grant the potential for numerous investigators to dramatically improve the efficiency of their research programs requiring rigorous quantitative descriptions of animal behavior. Narrative We will develop and disseminate innovative new technology for measuring precise 3D kinematics in freely moving animals over long time-periods. Our proposed experimental platform will illuminate how natural behaviors are organized and help us understand how they are controlled by the nervous system, and how this control goes awry in disease. The technological leap made possible by this grant will catalyze a host of studies on the neural mechanisms underlying motor control, learning, and mental disorders, and thus help in the discovery of new diagnostic and therapeutic approaches for afflicted patients.",A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals,10120068,R01GM136972,"['3-Dimensional', 'Address', 'Adopted', 'Anatomy', 'Animal Behavior', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Benchmarking', 'Biological Models', 'Biomedical Research', 'Brain', 'Callithrix', 'Cephalometry', 'Communities', 'Complex', 'Data', 'Data Set', 'Deer Mouse', 'Disease', 'Ensure', 'Environment', 'Gold', 'Grant', 'Hand', 'Head', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Learning Disorders', 'Lighting', 'Limb structure', 'Logic', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Movement', 'Mus', 'Nervous System Physiology', 'Nervous System control', 'Neurologic Deficit', 'Output', 'Patients', 'Performance', 'Positioning Attribute', 'Posture', 'Process', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'appendage', 'base', 'computer science', 'convolutional neural network', 'cost', 'deep neural network', 'design', 'expectation', 'experimental study', 'flexibility', 'improved', 'innovation', 'kinematics', 'motor control', 'neural network', 'neuromechanism', 'new technology', 'novel diagnostics', 'novel therapeutic intervention', 'programs', 'relating to nervous system', 'scale up', 'skeletal', 'spatiotemporal']",NIGMS,HARVARD UNIVERSITY,R01,2021,411071
"Super-multiplexed fluorescence nanoscopy for imaging-based proteomics PROJECT SUMMARY In situ immunofluorescence imaging is a powerful method to study the locations, expression levels and structures of proteins in cells and tissues. In particular, multiplexed imaging reveals the interaction networks of proteins, which allows us to understand the underlying mechanisms of many diseases. However, it has been challenging to perform multiplexed immunofluorescence imaging due to its extremely time-consuming process, high cost and lack of signal amplification. The limited spatial resolution achievable with confocal microscopy often fails to reveal complex spatial organization and to determine localizations of proteins. Here we propose super-multiplexed immunofluorescence nanoscopy that is capable of imaging more than twenty different proteins in 24 hours with nanoscale resolution. We will employ DNA-barcoded secondary nanobodies that are monovalent, open-source and designed for quantitative labeling. Repeated introduction and washing of fluorescent DNA imagers will generate highly multiplexed images. Moreover, we will develop unprecedentedly fast stimulated emission depletion (STED) microscopy that employs a parallelized line array of doughnut beams. It will feature a large imaging area and excellent optical sectioning capability. Photon reassignment, hyperspectral imaging and deep-learning will further facilitate rapid super-resolution-based protein profiling. Our new biochemical and optical tools will play crucial roles in diverse biomedical areas including brain proteomics and cancer profiling. PROJECT NARRATIVE We propose to develop highly multiplexed immunofluorescence super-resolution imaging tools. Our approach is fast, low cost and readily accessible, which will facilitate nanoscale imaging-based proteomics in cells and tissues.",Super-multiplexed fluorescence nanoscopy for imaging-based proteomics,10261562,R35GM138039,"['Area', 'Bar Codes', 'Biochemical', 'Brain', 'Cells', 'Complex', 'Confocal Microscopy', 'Consumption', 'DNA', 'Disease', 'Fluorescence', 'Hour', 'Image', 'Imaging Device', 'Immunofluorescence Immunologic', 'In Situ', 'Label', 'Location', 'Malignant Neoplasms', 'Methods', 'Microscopy', 'Nanoscopy', 'Optics', 'Photons', 'Play', 'Process', 'Proteins', 'Proteomics', 'Resolution', 'Role', 'Signal Transduction', 'Structural Protein', 'Time', 'Tissues', 'base', 'cost', 'deep learning', 'design', 'imager', 'multiplexed imaging', 'nanobodies', 'nanoscale', 'open source', 'protein profiling', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R35,2021,338947
"Super-multiplexed fluorescence nanoscopy for imaging-based proteomics PROJECT SUMMARY In situ immunofluorescence imaging is a powerful method to study the locations, expression levels and structures of proteins in cells and tissues. In particular, multiplexed imaging reveals the interaction networks of proteins, which allows us to understand the underlying mechanisms of many diseases. However, it has been challenging to perform multiplexed immunofluorescence imaging due to its extremely time-consuming process, high cost and lack of signal amplification. The limited spatial resolution achievable with confocal microscopy often fails to reveal complex spatial organization and to determine localizations of proteins. Here we propose super-multiplexed immunofluorescence nanoscopy that is capable of imaging more than twenty different proteins in 24 hours with nanoscale resolution. We will employ DNA-barcoded secondary nanobodies that are monovalent, open-source and designed for quantitative labeling. Repeated introduction and washing of fluorescent DNA imagers will generate highly multiplexed images. Moreover, we will develop unprecedentedly fast stimulated emission depletion (STED) microscopy that employs a parallelized line array of doughnut beams. It will feature a large imaging area and excellent optical sectioning capability. Photon reassignment, hyperspectral imaging and deep-learning will further facilitate rapid super-resolution-based protein profiling. Our new biochemical and optical tools will play crucial roles in diverse biomedical areas including brain proteomics and cancer profiling. PROJECT NARRATIVE We propose to develop highly multiplexed immunofluorescence super-resolution imaging tools. Our approach is fast, low cost and readily accessible, which will facilitate nanoscale imaging-based proteomics in cells and tissues.",Super-multiplexed fluorescence nanoscopy for imaging-based proteomics,10388887,R35GM138039,"['Area', 'Bar Codes', 'Biochemical', 'Brain', 'Cells', 'Complex', 'Confocal Microscopy', 'Consumption', 'DNA', 'Disease', 'Fluorescence', 'Hour', 'Image', 'Imaging Device', 'Immunofluorescence Immunologic', 'In Situ', 'Label', 'Location', 'Malignant Neoplasms', 'Methods', 'Microscopy', 'Nanoscopy', 'Optics', 'Photons', 'Play', 'Process', 'Proteins', 'Proteomics', 'Resolution', 'Role', 'Signal Transduction', 'Structural Protein', 'Time', 'Tissues', 'base', 'cost', 'deep learning', 'design', 'imager', 'multiplexed imaging', 'nanobodies', 'nanoscale', 'open source', 'protein profiling', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R35,2021,200000
"Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy In this proposed project, we plan to fill the knowledge gap of the relationships between microscopic self-assembled structures, collagen-molecule interactions and macroscopic fiber morphologies of type-I collagen, the primary component of most human tissues and a commonly used biomaterial for tissue engineering. By investigating collagen-water and collagen-protein interactions in in vitro systems that mimic basic aspects of physiologically relevant three- dimensional fibrillar tissue architectures, we aim to fill knowledge gaps in fundamental collagen research. We will achieve this goal by developing a hyperspectral imaging technique – vibrational sum frequency generation (VSFG) microscopy – at high repetition rates (400 kHz) and apply it to collagen. The long-term vision is to develop new biophysics methods to reveal molecular-level structures and interactions for pericellular space research and other complex biological environments, and eventually applying it to study various pericellular environment related diseases. In order to correlate spectral features to microscopic and macroscopic structures of type I collagen, we plan to apply machine-learning techniques to analyze our data and extract spectral signatures of collagen’s micro/macrostructures. We will two major scientific focuses: (A) understanding molecular signatures of microscopic self-assembly fibrils structures and its relationship to the macroscopic morphology (plan 1 and 2); and (B) investigating molecular level collagen-molecule interactions (plan 3 and 4). Specific plans include:  1. Obtaining hyperspectral VSFG images of collagen tissues to study their morphology in a  label free and non-invasive manner  2. Establishing molecular spectral signatures of self-assembled collagen fibril structures  3. Understanding collagen-water interaction in first solvation layer of collagen fibers.  4. Imaging spatial locations of chemicals and peptides that interact with collagens. If successful, the significance is that a label free, vibrational mode specific imaging technique specific for pericellular space will be available, which can reveal molecular level insights of collagen structures and its interactions with surrounding molecules, pertinent to fibrosis and cell— pericellular space interaction related diseases. This proposed project contributes to the scope of NIGMS by developing new technology to reveal fundamental molecular-level principle, mechanism and signatures related to morphology of collagen I at both micro- and macroscopic scales, and collagen-molecule interactions, laying foundations for biophysical/biochemical principles for future biomedical applications related to collagens. This proposed development of vibrational sum frequency generation microscopy, in the short term, will spatially resolve collagen tissues with chemical structure and molecular interaction information in a complicated environment. Machine learning and simulation approaches will be employed to build a data base to convert hyperspectral images of collagen into a spatial map with microscopic structures and molecular interaction information. In the long term, the fundamental biochemical knowledge learned from this development will lay foundations for rationally design biomedical approaches to monitor and control pericellular spaces and its interaction with cells, and further advance treatment to diseases related to it.",Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy,10259748,R35GM138092,"['3-Dimensional', 'Architecture', 'Binding', 'Biochemical', 'Biocompatible Materials', 'Biological', 'Biophysics', 'Cells', 'Chemical Structure', 'Chemicals', 'Collagen', 'Collagen Fiber', 'Collagen Fibril', 'Collagen Type I', 'Complex', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Fiber', 'Fibrosis', 'Foundations', 'Frequencies', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'In Vitro', 'Knowledge', 'Label', 'Location', 'Machine Learning', 'Maps', 'Microscopic', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Monitor', 'Morphology', 'National Institute of General Medical Sciences', 'Peptides', 'Physiological', 'Proteins', 'Research', 'Structure', 'Sum', 'System', 'Techniques', 'Tissue Engineering', 'Tissues', 'Vision', 'Water', 'biophysical techniques', 'design', 'human tissue', 'image reconstruction', 'insight', 'molecular imaging', 'new technology', 'self assembly', 'simulation', 'vibration']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R35,2021,395000
"Developing computational algorithms for histopathological image analysis Project Summary  Histopathology is the cornerstone of disease diagnosis and prognosis. With the advance of imaging technology, whole-slide image (WSI) scanning of tissue slides is becoming a routine clinical procedure and producing a massive amount of data that captures histopathological details in high resolution. Most current pathological image analysis methods, similar to general image analysis approaches, mainly focus on morphology features, such as tissue texture and granularity, but ignore the complex hierarchical structures of tissues. Cells are the fundamental building blocks to tissues. Different types of cells are first organized into cellular components, which together with the extracellular matrix, form different types of tissue architectures. Understanding the interactions among these different types of cells can provide critical insights into biology and disease status. However, there are some major computational challenges: (1) How to identify and classify different types of cells in tissue, (2) how to characterize the highly complex and heterogeneous spatial organization of tissue, and (3) how to integrate histopathology data with other types of data to study disease status and progression. The goal of this proposal is to develop novel computational methods to analyze histopathology image data to study disease status and progression. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, statistical modeling, and clinical pathology. Specifically, we will develop novel algorithms to: (1) classify different types of cells from histopathology tissue WSI scans, (2) characterize and quantify cell spatial distribution and cell-cell interactions, and (3) integrate histopathology data with other types data to study disease progression. All proposed methods were motivated by real-world biological and clinical applications across different types of diseases, such as liver diseases, infectious diseases, and cancer. If implemented successfully, the proposed study will facilitate the analysis and modeling of data generated from histopathology tissue slides to improve disease risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in histopathology imaging and computing have enabled the in-depth characterization of pathology tissues. The overarching goal of this proposal is to develop computational algorithms to analyze histopathology image data to study disease status and progression.",Developing computational algorithms for histopathological image analysis,10097119,R01GM140012,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Bayesian Method', 'Biological', 'Biology', 'Biomedical Research', 'Cell Communication', 'Cells', 'Classification', 'Clinical', 'Clinical Pathology', 'Communicable Diseases', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Diagnosis', 'Disease', 'Disease Progression', 'Evaluation', 'Extracellular Matrix', 'Genomics', 'Goals', 'Graph', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Intuition', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Physics', 'Procedures', 'Prognosis', 'Research', 'Resolution', 'Risk Assessment', 'Scanning', 'Slide', 'Spatial Distribution', 'Stains', 'Statistical Models', 'Structure', 'Texture', 'Tissue imaging', 'Tissues', 'base', 'cancer type', 'cell type', 'clinical application', 'clinical care', 'convolutional neural network', 'data integration', 'data modeling', 'deep learning algorithm', 'digital', 'digital pathology', 'disease diagnosis', 'disorder risk', 'drug discovery', 'experience', 'improved', 'insight', 'machine learning method', 'molecular pathology', 'multiple datasets', 'novel', 'outcome prediction', 'particle', 'pathology imaging', 'predictive modeling', 'software development', 'user friendly software', 'whole slide imaging']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,409167
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Developing novel algorithms for spatial molecular profiling technologies Project Summary The location, timing and abundance of mRNA and proteins within a tissue underlie the basic molecular mechanisms of cell functions and physiological and pathological developments. For example, the study of expression of thousands of genes simultaneously at different locations could reveal great insights into embryo development, the cooperation of molecular and cellular processes for high-order mental functions, and the molecular basis and clinical impact of intra-tumor heterogeneity. Recent technology breakthroughs in spatial molecular profiling (SMP), including both imaging-based technologies and sequencing-based technologies, have enabled the comprehensive molecular characterization of single cells while preserving their spatial and morphological contexts. Due to the huge potential to deepen our understanding of the molecular mechanisms of cellular and physiological phenotypes, SMP technologies are rapidly gaining attention and a large amount of such data will be generated. However, there are only few computational methods developed to analyze such rich but complex data, and the limitations of computational methods lead to such valuable data being largely under-used. The overarching goal of this study is to develop computational methods to analyze SMP data to characterize detailed molecular spatial distributions and associate such information with cellular phenotypes and physiological phenotypes. The specific aims are as follows: 1. develop novel spatio-statistical methods to characterize spatial distributions of gene expression; 2. develop computational methods to characterize cellular spatial organizations and investigate their relationship with molecular spatial distributions and disease status; 3. develop user-friendly software to facilitate researchers in SMP data analysis and visualization. In order to achieve this goal, we have assembled a strong team with complementary expertise in single-cell genomics, tissue image analysis, spatial modelling, machine learning and software development. If implemented successfully, this platform will greatly facilitate users in understanding molecular and cellular spatial organization in biological tissues and provide comprehensive insights into the underlying biological processes. Narrative The emerging spatial molecular profiling technology enables the comprehensive molecular characterization of cells while preserving their spatial contexts. The goal of this proposed study is to develop novel algorithms and bioinformatics tools to analyze spatial molecular profiling data, in order to characterize molecular spatial organizations and associate them with cellular phenotypes and disease status.",Developing novel algorithms for spatial molecular profiling technologies,10197672,R01GM141519,"['Algorithmic Software', 'Algorithms', 'Attention', 'Bayesian Modeling', 'Biological', 'Biological Process', 'Cell physiology', 'Cells', 'Characteristics', 'Clinical', 'Communities', 'Complex', 'Computational algorithm', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Feasibility Studies', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Graph', 'Heterogeneity', 'Image', 'Image Analysis', 'Infrastructure', 'Intuition', 'Lead', 'Location', 'Machine Learning', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathway interactions', 'Patient-Focused Outcomes', 'Pattern', 'Phenotype', 'Physiological', 'Proteins', 'Research', 'Research Personnel', 'Spatial Distribution', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Tissue imaging', 'Tissues', 'Variant', 'Visualization', 'base', 'bioinformatics tool', 'biological research', 'cell type', 'complex data', 'computerized tools', 'convolutional neural network', 'data structure', 'data visualization', 'deep learning', 'deep learning algorithm', 'disease diagnosis', 'experience', 'feature selection', 'flexibility', 'improved', 'informatics tool', 'insight', 'mental function', 'novel', 'preservation', 'software development', 'tool', 'tumor heterogeneity', 'user friendly software']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,370939
"Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow Project Summary/Abstract Low oxygen (hypoxic) environments are known to be important for maintaining the small number of adult stem cells in the human body, such as in bone marrow. These conditions are also believed to enable dormant cancer cells to survive and metastasize years or decades after the original tumor has been destroyed and the reason why bone marrow is one of the most common sites of cancer metastasis. Understanding of these conditions can drive the development of 3D cellular scaffolds for growing stem cells ex vivo, thus reducing the burden on requiring bone marrow transplants, and for developing therapeutics that prevent cancer relapse. This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. The technique is based on developments in x-ray luminescence computed tomography, an emerging molecular imaging technique capable of achieving cellular level resolution and high sensitivities. The approach uses x-rays to excite oxygen-sensitive nanophosphors that emit near-infrared photons to finally enable 3D oxygen measurements in deep bone marrow. Because the technique requires a multidisciplinary team with x-ray expertise, nanophosphor expertise, near-infrared detection expertise, and algorithms for quantifying the concentrations and minimizing dose, this STTR fast-track proposal involves several institutions with deep expertise in their respective domains. The proposed Phase I 6-month project is a proof-of- principle demonstration of a breadboard system used on nanophosphors in low oxygen solutions and embedded in bone. The proposed Phase II 24-month project is to develop a complete prototype system and experimentally verify its performance. Project Narrative This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. Local oxygen microenvironments and changes to oxygen tensions over only tens of micrometers are known to be important for maintaining stem cell growth and are suspected to also enable cancer metastases, but are poorly understood because there are no methods with the resolution and sensitivity required. The proposed solution will finally enable 3D oxygen measurements in deep bone marrow based on a newly developed technique called x- ray luminescence computed tomography (XLCT) and oxygen-sensitive nanophosphors for 10 to 100 µm imaging of oxygen concentrations.",Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow,10255544,R42GM142394,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Area', 'Biomedical Research', 'Biopsy', 'Blood', 'Bone Marrow', 'Bone Marrow Transplantation', 'Cancer Patient', 'Cancer Relapse', 'Cells', 'Chemicals', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Disease', 'Dose', 'Environment', 'Fiber', 'Film', 'Heterogeneity', 'Human body', 'Hypoxia', 'Image', 'Imaging Techniques', 'Institution', 'Light', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Measures', 'Metastatic Neoplasm to the Bone', 'Methods', 'Microscopy', 'Modality', 'Molecular', 'Monitor', 'Morphology', 'Nature', 'Neoplasm Metastasis', 'Noise', 'Organ Transplantation', 'Oxygen', 'Penetration', 'Performance', 'Phase', 'Photons', 'Production', 'Radiation Dose Unit', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Small Business Technology Transfer Research', 'Spatial Design', 'Surface', 'System', 'Techniques', 'Therapeutic', 'Thick', 'Time', 'Tissues', 'Visible Radiation', 'X-Ray Computed Tomography', 'adult stem cell', 'base', 'bone', 'cancer cell', 'cancer site', 'deep learning', 'deep learning algorithm', 'denoising', 'design and construction', 'detector', 'high resolution imaging', 'image processing', 'image reconstruction', 'imaging system', 'improved', 'insight', 'luminescence', 'malignant breast neoplasm', 'molecular imaging', 'multidisciplinary', 'phosphorescence', 'pre-clinical', 'prevent', 'prototype', 'quantum', 'response', 'scaffold', 'stem cell growth', 'stem cells', 'therapeutic effectiveness', 'tissue oxygenation', 'tomography', 'transmission process', 'tumor', 'two-photon']",NIGMS,"SIGRAY, INC.",R42,2021,252113
"Integrating Stochasticity into Biomolecular Mechanisms: A New Direction for Biomolecular Modeling Integrating Stochasticity into Biomolecular Mechanisms: A New Direction for  Biomolecular Modeling Abstract It is increasingly apparent that kinetic selection plays an important role in biology. However, we are just beginning to have the tools necessary to quantify, characterize and understand it. For biomolecular processes involving multiple rare-event transitions, the canonical assumption is that mechanisms proceed following a consistent order of transitions (following a single-pathway). However, increasing evidence from single molecule experiments and biophysical measurements suggests that multiple pathways are not only possible, but essential. The goal of the proposed research is to develop an experimentally-directed stochastic simulation framework for mapping out mechanistic heterogeneity. As applications, I will focus, first, on secondary active transport in the ClC Cl-/H+ antiporter and ATP hydrolysis driven translocation in several AAA+ ATPases, two processes involving chemical reactions and thus requiring multiscale methods that bridge the quantum to classical realms. The proposed approach to multiscale kinetic modeling is focused on multistep biomolecular transformations, which makes it unique to many other domains of established kinetic modeling. Thus, new methods will be developed and best practices from other domains will be adapted. It combines a bottom-up calculation of rate coefficients for kinetically relevant transitions from multiscale simulations, with a top-down parameter refinement based on experimental data. Innovation is proposed to refine the kinetic solution space with Bayesian parameter estimation, global sensitivity analysis, uncertainty quantification, reaction path analysis and machine learning methods. These methods will be used to better characterize the Cl-/H+ exchange mechanism in the ClC-ec1 antiporter in collaboration with Merritt Maduke (Stanford). The kinetic landscape for the wildtype system will be studied to address the role of pathway heterogeneity, the origin of the non-integral 2.2:1 Cl-:H+ stoichiometry, and the relevance of the alternating access mechanism. Similar to secondary active transport, ATP-driven processes inherently involve multiple rate-influencing steps (ATP binding, hydrolysis, Pi release, ADP release, and all of the associated conformational changes). A multiscale reactive molecular dynamics method will be developed to describe ATP hydrolysis. Additionally, enhanced free energy sampling will be used to characterize other transitions and multiscale kinetic models will be developed to probe the role of kinetic selectivity and to test the controversial stochastic versus sequential proposed mechanisms in AAA+ ATPases in collaboration with Chris Hill (University of Utah). Integrating Stochasticity into Biomolecular Mechanisms: A New  Direction for Biomolecular Modeling Narrative It is increasingly apparent that kinetic selection plays an important role in biology. However, we are just beginning to have the tools necessary to quantify, characterize and understand it. The proposed research aims to develop an experimentally-directed simulation framework for mapping out kinetic landscapes and mechanistic heterogeneity to understand the role of kinetic selection in biomolecular processes.",Integrating Stochasticity into Biomolecular Mechanisms: A New Direction for Biomolecular Modeling,10277296,R35GM143117,"['ATP Hydrolysis', 'ATP phosphohydrolase', 'Active Biological Transport', 'Address', 'Binding', 'Biology', 'Collaborations', 'Data', 'Event', 'Free Energy', 'Goals', 'Heterogeneity', 'Hydrolysis', 'Kinetics', 'Methods', 'Modeling', 'Molecular Conformation', 'Pathway interactions', 'Play', 'Process', 'Reaction', 'Research', 'Role', 'Sampling', 'Secondary to', 'System', 'Testing', 'Uncertainty', 'Universities', 'Utah', 'antiporter', 'base', 'biophysical properties', 'chemical reaction', 'experimental study', 'innovation', 'kinetic model', 'machine learning method', 'molecular dynamics', 'quantum', 'simulation', 'single molecule', 'stoichiometry', 'tool']",NIGMS,UNIVERSITY OF UTAH,R35,2021,364473
"Uncover Spatial-Constraint Related Morphome Using Tissue-on-a-Chip Platform and Data-Driven Mathematical Modeling PROJECT SUMMARY Cell behaviors and tissue developments often occur under spatial constraints (e.g., interstitial space, tissue lining, skull enclosure). The current in vitro systems are often open cultures, and thus miss the spatial constraints and other in vivo stimuli. The current in vivo models are often low throughput and hard-to-trace, therefore unable to unravel the complex interplay between intrinsic influences (e.g., genetics/epigenetics) and extrinsic ones (e.g., micro-environment). For example, cell membrane blebbing and brain folding are fundamental and impactful bio-behaviors under spatial constraints. Their biophysical and molecular mechanisms are not well understood. Lately, several experimental and theoretical tools have emerged to fascinate the modeling of complex bio-behaviors. This proposed study aims to parameterize morphological information, relate to the complex influences under spatial constraints, and unravel the mechanism of bio- behaviors in the two exemplified areas. It will be done through a morphome platform that integrates several experimental-theoretical tools (e.g., tissue-on-a-chip, data-driven modeling, machine-learning), which has been pre-defined by PI and Co-Is. We hope to 1) fill the compelling gaps in our understanding of membrane blebbing and brain folding process and 2) establish an effective strategy to uncover a broad range of basic biological processes. PROJECT NARRATIVE Many biological behaviors and functions are realized through the formation and changes of the shapes of biological systems. However, the mechanism of how some biological shapes are determined and changed in a limited body space remains unknown. How these shape-changes direct biological behaviors are also poorly understood. This work aims to uncover these processes and answer mechanistic questions that have not yet been fully addressed, with the hope of developing a new strategy for investigating biosciences. .",Uncover Spatial-Constraint Related Morphome Using Tissue-on-a-Chip Platform and Data-Driven Mathematical Modeling,10278972,R35GM143194,"['Address', 'Area', 'Behavior', 'Biological', 'Biological Process', 'Biological Sciences', 'Biophysics', 'Brain', 'Cell membrane', 'Complex', 'Data', 'Development', 'Epigenetic Process', 'Genetic', 'In Vitro', 'Machine Learning', 'Membrane', 'Modeling', 'Molecular', 'Morphology', 'Process', 'Shapes', 'Stimulus', 'System', 'Tissues', 'Work', 'biological systems', 'cell behavior', 'cranium', 'fascinate', 'in vivo', 'in vivo Model', 'interstitial', 'mathematical model', 'tool']",NIGMS,UTAH STATE UNIVERSITY,R35,2021,258012
"Quantification of myocardial blood flow using Dynamic PET/CTA fused imagery to determine physiological significance of specific coronary lesions Project Summary One of every 6 deaths in the USA in 2015 was caused by coronary artery disease (CAD). Traditionally, primarily anatomic considerations have been used to diagnose CAD. Fractional flow reserve (FFR), a physiological index of blood-flow reduction caused by coronary stenosis, has been shown by the FAME trials as a better predictor of clinical outcomes from coronary revascularization than that based on anatomy alone. PET-derived absolute myocardial blood flow (MBF), flow reserve (MFR) and relative flow reserve (RFR) have been shown to add clinical value in detecting CAD and risk assessment. Currently, PET measurements of MBF, MFR and RFR are not lesion specific, calculated either globally for the entire left ventricle (LV), or regionally to pre-defined vascular or segmental territories. This approach is limited by the intermixing of normal flow from normal regions with abnormal flow from abnormal regions thus reducing the measured degree of flow-impairment, diagnostic performance and culpable lesion location. We and others have shown that the variability alone of vessel pathway between patients leads to 18% misdiagnosis rate. We propose to develop algorithms to non-invasively measure MBF, MFR and RFR across specific coronary lesions for the entire coronary tree at least as accurately as those measured invasively during cardiac catheterization using fused coronary anatomy data obtained from CT coronary angiography (CTA) with dynamic PET (dPET) flow physiologic data. We hypothesize that our novel 3D fusion dPET/CTA approach will accurately and non- invasively predict lesion-specific severity as defined by invasive coronary angiography (ICA) FFR obtained with flow-wire/pressure-wire approaches. We anticipate that our dPET/CTA approach will be significantly more accurate than other existing non-invasive approaches. Exploiting our achievements in algorithm development, we will pursue our specific aims of 1) automating CTA myocardial border and vessel segmentation, 2) automating dPET/CTA 3D fusion to localize myocardial volumes of interest (VOIs) on dPET studies corresponding to the anatomical path of coronary vessels from CTA, and 3) calculating MBF and related flow parameters along coronary vessels using clinically accepted PET flow methods. Our dPET/CTA method will result in the following game-changing paradigm: 1) eliminate unnecessary ICAs in patients with no significant lesions, 2) avoid stenting physiologically insignificant lesions, 3) guide the PCI process to the location of significant lesions, 4) provide a flow-color-coded 3D roadmap of the entire coronary tree to guide bypass surgery, and 5) use less radiation and lower cost. Project Narrative  The aim of this work is to develop software tools to fuse coronary anatomy data obtained from CT coronary angiography with dynamic PET data (combination of anatomic and physiologic information) to noninvasively measure absolute myocardial blood flow, flow reserve and relative flow reserve across specific coronary lesions. These tools should reduce or eliminate unnecessary catheterizations and stenting and thus reduce patient risk, lower radiation exposure, and reduce the healthcare costs associated with unnecessary costly invasive treatments.",Quantification of myocardial blood flow using Dynamic PET/CTA fused imagery to determine physiological significance of specific coronary lesions,10198024,R01HL143350,"['3-Dimensional', 'Achievement', 'Algorithms', 'Anatomy', 'Automation', 'Blood Vessels', 'Blood flow', 'Bypass', 'Cardiac', 'Cardiac Catheterization Procedures', 'Caring', 'Catheterization', 'Cessation of life', 'Clinical', 'Code', 'Color', 'Computing Methodologies', 'Consumption', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Data', 'Databases', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Evaluation', 'Goals', 'Health Care Costs', 'Image', 'Imagery', 'Impairment', 'Left', 'Left ventricular structure', 'Lesion', 'Location', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Myocardial', 'Myocardial perfusion', 'Myocardium', 'Non-Invasive Lesion', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Selection', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perfusion', 'Physicians', 'Physiological', 'Positron-Emission Tomography', 'Principal Component Analysis', 'Procedures', 'Process', 'Radiation', 'Radiation exposure', 'Risk Assessment', 'Sampling', 'Selection for Treatments', 'Severities', 'Shapes', 'Software Tools', 'Stents', 'Surface', 'Thick', 'Three-Dimensional Image', 'Time', 'Trees', 'Unnecessary Procedures', 'Variant', 'Work', 'accurate diagnostics', 'algorithm development', 'base', 'clinical application', 'coronary lesion', 'cost', 'experience', 'image processing', 'improved', 'improved outcome', 'indexing', 'innovation', 'interest', 'multimodality', 'novel', 'patient variability', 'perfusion imaging', 'predict clinical outcome', 'pressure', 'prevent', 'software development', 'standard measure', 'tool']",NHLBI,EMORY UNIVERSITY,R01,2021,527950
"Automated, optimized, intelligent data collection for cryo-EM Project Summary Cryo-electron microscopy (cryo-EM) is now a widely established and indispensable method for determining the high-resolution structures of biomedically important molecules. Given that thousands of images, often acquired over the course of several days, are required to obtain such structures, automation software has played a critical role in the large-scale adoption of this method by the scientific community. In just the past five years, cryo-EM has revolutionized our understanding of entire biological systems, and in 2020 provided the first molecular descriptions of SARS-CoV-2 interaction with neutralizing antibodies. The widespread adoption of cryo-EM recently prompted the NIH to invest in three National Centers through the Transformative High Resolution Cryo- Electron Microscopy Program, providing free, high-end electron microscope access to biologists across the country. The exponential increase in the popularity of cryo-EM has led to an astonishing number of developments in sample preparation methodologies and image processing algorithms, which have improved attainable resolution of single particle reconstructions. However, comparatively little progress has been made in optimizing the quality of the cryo-EM data being collected. The pioneering software packages Leginon and Appion demonstrated the power of automated data acquisition and real-time processing (respectively), and there are now numerous programs for automated data acquisition and real-time processing. Despite advances in automation, optimally extracting the highest quality data from an EM sample still requires manual involvement of an expert electron microscopist. User intervention and expertise is necessary to run the appropriate image analyses, interpret the results, and make informed decisions on how the processed results relate to the ongoing data collection. However, even experts must content with the fact that the “best grid regions” differ drastically from sample to sample, and there are no established tools for automatically and quickly assessing the quality of the specimen across the various microenvironments of an EM grid. Given the ever-increasing incorporation of cryo-EM into labs’ research programs, it is imperative that data collection and processing be streamlined to match the growing needs of the structural community. We propose to develop a second generation Leginon/Appion software package, “Magellon”, to overcome existing bottlenecks and provide an avenue toward fully automated data acquisition that bypasses need for user input during data collection. Importantly, this software will support the computational infrastructure to enable real-time image processing results to inform on and modify the ongoing data collection regime by learning where to acquire images in regions that will yield the highest resolution structures. We will develop and incorporate new, fast image assessment routines, while also providing an application programming interface to enable the incorporation of extensions and plugins from developers in the community. Further, Magellon will enable straightforward, seamless import and export of data from its database to accommodate remote data acquisition at any of the regional or national cryo-EM centers. Narrative The development of therapeutics for diseases, which includes vaccines to fight viruses such as COVID-19, is substantially aided by directly visualizing the viruses or cellular components responsible for causing disease. The NIH has recently established three National Centers that contain the most powerful microscopes on the planet, enabling biologists across the country to look at these tiny disease-causing components. We will design and build a series of cutting- edge computer programs to help biologists take better pictures, so that we are able to more quickly make biomedically important discoveries.","Automated, optimized, intelligent data collection for cryo-EM",10317907,R01GM143805,"['2019-nCoV', 'Adoption', 'Algorithms', 'Automation', 'Automobile Driving', 'Biophysics', 'Buffers', 'Bypass', 'COVID-19', 'Code', 'Communities', 'Computer software', 'Country', 'Cryoelectron Microscopy', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Disease', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Feedback', 'Foundations', 'Generations', 'Goals', 'Hand', 'Heterogeneity', 'Ice', 'Image', 'Image Analysis', 'Institution', 'Intelligence', 'Intervention', 'Learning', 'Maintenance', 'Manuals', 'Methodology', 'Methods', 'Microscope', 'Molecular', 'Molecular Conformation', 'Output', 'Particle Size', 'Pathologic', 'Planets', 'Play', 'Preparation', 'Process', 'Research', 'Resolution', 'Role', 'Running', 'Sampling', 'Series', 'Site', 'Specimen', 'Structure', 'Thick', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Vaccines', 'Virus', 'Work', 'application programming interface', 'base', 'biological systems', 'cluster computing', 'comparative', 'computer infrastructure', 'computer program', 'computerized data processing', 'convolutional neural network', 'data acquisition', 'data mining', 'data quality', 'design', 'fighting', 'image processing', 'improved', 'innovation', 'migration', 'neutralizing antibody', 'next generation', 'open source', 'particle', 'portability', 'prediction algorithm', 'preservation', 'programs', 'real-time images', 'reconstruction', 'structural biology', 'therapeutic development', 'tool']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2021,655046
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,10165811,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'thrombotic', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,639595
"Ultrasonic perfusion imaging of peripheral vascular disease Project Summary Our 4-yr project aims to develop a new ultrasonic Doppler method named Higher-Order Perfusion Estimation (HOPE) imaging. Applications enabled by this technology are routine assessments of microvascular disease progression in diabetic patients with symptoms of peripheral artery disease (PAD). Technical advances include new ultrasonic echo sampling and filtering techniques that significantly increase the sensitivity and specificity of standard sonographic instruments to spatially disorganized patterns of red-blood-cell movement without the addition of contrast media. Sensitivity to slowly perfusing blood is increased by transmitting a sparse regular sequence of Doppler pulses over long durations (1-10s). To counter a concomitant increase in clutter-signal power in perfusing-blood frequency channels, spatiotemporal echo acquisitions are first rearranged into 3-D data arrays and a 3-D singular-value decomposition (3D-SVD) clutter filter is formed for each experiment. Our approach now successfully separates weak perfusing-blood echoes from other echo-signal sources in the peripheral vasculature because of the typically narrow eigen-bandwidth of clutter echoes in peripheral muscle. Preliminary results using echo simulation, microchannel flow phantoms, and preclinical models of mouse ischemic hindlimb and melanoma lesions demonstrate that our method is very well designed for monitoring steady peripheral microvascular flow patterns using commercial ultrasonic instruments (with software updates). Four aims are proposed to demonstrate the utility of HOPE imaging (both power and color-flow) for measuring blood flow and perfusion. Aim 1 expands preliminary studies in mouse models to evaluate perfusion measurement sensitivity at 12-24 MHz in diabetic animals, and to uncover mechanisms of the angiogenic response of tissues to sudden ischemia. Aim 2 continues development of HOPE imaging by improving perfusing- blood echo sensitivity and clutter-filter performance under more general imaging conditions (viz., broad eigen- bandwidth clutter and 3-D spatially varying perfusion). Aim 3 focuses on a progressively ischemic pig model using 5-12 MHz HOPE imaging, MR angiography, and radioactive microsphere techniques to calibrate and compare HOPE imaging results with standard clinical approaches. Aim 4 is a 4-yr, 150-patient study designed to evaluate the diagnostic performance of HOPE imaging at assessing PAD. The overall project aims to develop existing ultrasonic instruments into highly-effect tools for evaluating microvascular changes leading to common disabilities and major cardiovascular events. The three in vivo studies proposed in this plan are designed to develop and evaluate HOPE imaging specifically for PAD diagnosis, staging, and therapeutic monitoring. Project Narrative The project leverages a new understanding of the information contained within Doppler ultrasound echo signals to create a more effective diagnostic tool for imaging microvascular changes associated with peripheral arterial diseases. Success in this project brings effective new methods to existing instruments enabling medical professionals to track peripheral microvascular decline as well as treatment responses. This safe, low-cost method can also be applied to patients frequently helping them directly observe the effects of lifestyle decisions.",Ultrasonic perfusion imaging of peripheral vascular disease,10171895,R01HL148664,"['3-Dimensional', 'Anatomy', 'Angiography', 'Animals', 'Ankle', 'Blood', 'Blood Vessels', 'Blood flow', 'Cardiovascular system', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Color', 'Complex', 'Computer software', 'Contrast Media', 'Data', 'Development', 'Diabetic mouse', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease Progression', 'Doppler Ultrasound', 'Erythrocytes', 'Etiology', 'Evaluation', 'Event', 'Exercise Therapy', 'Failure', 'Family suidae', 'Frequencies', 'Gene Expression', 'Goals', 'Hindlimb', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Injectable', 'Ischemia', 'Legal patent', 'Lesion', 'Life Style', 'Link', 'Measurement', 'Measures', 'Medical', 'Methods', 'Microspheres', 'Microvascular Dysfunction', 'Monitor', 'Mus', 'Muscle', 'Names', 'Nitric Oxide', 'Operative Surgical Procedures', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Peripheral', 'Peripheral Vascular Diseases', 'Peripheral arterial disease', 'Physiologic pulse', 'Pre-Clinical Model', 'Production', 'Property', 'Radioactive', 'Recovery', 'Research', 'Research Design', 'Resolution', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Source', 'Staging', 'Surgeon', 'Symptoms', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Translations', 'Ultrasonics', 'Update', 'Work', 'angiogenesis', 'base', 'blood perfusion', 'cardiovascular health', 'cell motility', 'claudication', 'cohort', 'cost', 'design', 'diabetic', 'diabetic patient', 'disability', 'disease diagnosis', 'experimental study', 'imaging approach', 'improved', 'in vivo', 'in vivo imaging', 'indexing', 'instrument', 'melanoma', 'mouse model', 'multimodality', 'muscle metabolism', 'novel', 'nuclear imaging', 'perfusion imaging', 'phantom model', 'porcine model', 'quantitative imaging', 'research study', 'response', 'simulation', 'spatiotemporal', 'success', 'tool', 'treatment response']",NHLBI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,678480
"Pro-inflammatory activation of human macrophages regulated by lncRNAs Project Summary Macrophage activation promotes major inflammatory disorders, including arterial diseases. Its underlying mechanisms, however, remain obscure. The present study will establish a systems approach, involving computational prediction analyses, multi-omics, network science, and in vitro and in vivo validation, to discover long noncoding RNA (lncRNA)-mediated mechanisms for pro-inflammatory activation of macrophages and arterial disease. In Specific Aim 1, we will involve omics studies of human macrophages to identify lncRNAs and their interacting proteins and develop computational analyses to predict human lncRNAs that regulate macrophage activation. Specific Aim 2 will examine the functionality of candidate lncRNAs in macrophage activation in vitro and in vivo. The findings from the study will help to identify new mechanisms for macrophage activation and may provide molecular bases for new therapies. Project Narrative Inflammation plays a key role in coronary artery disease and other major vascular diseases, global health threats. Even with potent risk modifiers, e.g., statins, many patients still suffer vascular events. Long noncoding RNAs (lncRNAs) regulate various biological processes. We aim to discover lncRNAs that promotes vascular inflammation. The potential outcomes will offer new targets for much needed therapies for vascular diseases.",Pro-inflammatory activation of human macrophages regulated by lncRNAs,10199025,R01HL149302,"['Address', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Vessels', 'Cells', 'Communities', 'Complex', 'Computational Biology', 'Computer Analysis', 'Coronary Arteriosclerosis', 'Data', 'Development', 'Discipline', 'Disease', 'Drug usage', 'Endotoxemia', 'Event', 'Gene Expression Profiling', 'Goals', 'Hematopoietic Stem Cell Transplantation', 'Heterogeneity', 'Human', 'In Vitro', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lesion', 'Leukocytes', 'Life', 'Link', 'Machine Learning', 'Macrophage Activation', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Myocardial', 'NF-kappa B', 'Network-based', 'Outcome', 'Pathway Analysis', 'Patients', 'Plasma', 'Play', 'Protein Analysis', 'Proteins', 'Proteomics', 'RNA', 'Reporting', 'Residual state', 'Risk', 'Risk Factors', 'Role', 'Science', 'Signal Transduction', 'Small Interfering RNA', 'Splenocyte', 'System', 'Systems Biology', 'Tissues', 'Untranslated RNA', 'Validation', 'Vascular Diseases', 'arterial lesion', 'base', 'cytokine', 'experimental study', 'femoral artery', 'gain of function', 'global health', 'human disease', 'humanized mouse', 'in vivo', 'injured', 'loss of function', 'macrophage', 'modifiable risk', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel therapeutics', 'overexpression', 'protein protein interaction', 'single cell analysis', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'vascular inflammation']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,724962
"MRI based phosphocreatine mapping method to assess patients with peripheral arterial disease. Peripheral arterial disease (PAD) is caused by atherosclerosis, the buildup of plaque that can obstruct blood flow in the arteries to the lower extremities. The current assessment of patients with PAD targets the anatomic or hemodynamic burden of atherosclerotic plaque stenosis with measurement of ankle-brachial index (ABI), and several imaging other techniques. However, anatomic and hemodynamic indices do not always correlate with the functional limitations and disability that PAD patients experience, and prior work suggests that the PAD population would benefit from more specific functional tissue tests. We hypothesize that metabolic maps of phosphocreatine (PCr) measures, reflecting severe skeletal muscle (SM) ischemia or downstream mitochondrial changes, may fill that gap. PCr is the most abundant high- energy phosphate present in muscle. Energy metabolism and PCr play a vital role in cellular homeostasis, but there currently are no routine diagnostic tests to noninvasively quantify or map the distribution of PCr in patients with PAD.  Phosphorus (31P) magnetic resonance spectroscopy (MRS) is arguably the gold standard for the noninvasive assessment of SM mitochondrial function and high-energy phosphate content. However, due to the relatively low MR detection sensitivity and the requirement for unique hardware, 31P MRS is not used in routine clinical applications. Chemical exchange saturation transfer (CEST) MRI has emerged as a novel, high-sensitivity technique that may overcome several of the limitations of 31P MRS. However, CEST MRI is still under development and one major impediment for more widespread application is limited specificity for a particular metabolite due to spectral overlap of CEST signal from other metabolites and proteins and as well as the background signal from semi-solid macromolecules and direct saturation of water Our long-term goal is to develop clinically translatable CEST methods to extract and quantity PCr concentrations in skeletal muscle that provides a sensitive MRI approach to assess SM metabolism. If successful, this new technique should provide a completely new and sensitive method for detecting PCr in calf muscle and may play a pivotal role for the evaluation of regional musle pathophysiology change in many musculoskeletal diseases.  We recently developed two new CEST techniques, dubbed as polynomial and Lorentzian line-shape fitting (PLOF) method and artificial neural network based CEST quantification method (ANNCEST) that are able to detect PCr signal with high sensitivity and specificity. We will develop and optimize the PLOF and ANNCEST methods for PCr mapping through one novel animal model and in-magnet plantar flexion exercise for human leg. The optimized CEST MRI methods will be applied on PAD patients to validate that PCr dynamic curve is correlated with the severity of the PAD. Upon the successful completion of this proposal, we anticipate developing the first rapid, high-resolution skeletal muscle energetic functional exercise test. Our overall goal is to develop and optimize novel, sensitive and potentially widely available MRI techniques to characterize the regional distribution and kinetics of phosphocreatine, which reflects severe skeletal muscle ischemia or downstream mitochondrial changes in peripheral arterial disease. The technique is achieved through a novel MRI contrast mechanism, chemical exchange saturation transfer, and will be developed and applied on both animal model with low phosphocreatine concentration and patients with peripheral arterial disease. The new method can be translated to other clinical applications and metabolic diseases such as aging, myopathies, diabetes, obesity, heart failure where skeletal muscle abnormalities may contribute to exercise intolerance and fatigue.",MRI based phosphocreatine mapping method to assess patients with peripheral arterial disease.,10221043,R01HL149742,"['Address', 'Aging', 'Anatomy', 'Animal Model', 'Ankle', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Blood flow', 'Brain', 'Chemicals', 'Clinical', 'Creatine', 'Data', 'Development', 'Diabetes Mellitus', 'Energy Metabolism', 'Evaluation', 'Exercise', 'Exercise Test', 'Fatigue', 'Functional disorder', 'Funding', 'Glutamates', 'Glycogen', 'Glycosaminoglycans', 'Goals', 'Gold', 'Guanidinoacetate N-Methyltransferase', 'Heart failure', 'Homeostasis', 'Human', 'Image', 'Imaging Techniques', 'Ischemia', 'Kinetics', 'Knowledge', 'Leg', 'Lower Extremity', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Diseases', 'Metabolism', 'Methods', 'Mitochondria', 'Mus', 'Muscle', 'Muscle Mitochondria', 'Musculoskeletal Diseases', 'Myopathy', 'Network-based', 'Obesity', 'Patients', 'Peripheral arterial disease', 'Phosphocreatine', 'Phosphorus', 'Play', 'Polynomial Models', 'Population', 'Proteins', 'Recovery', 'Reproducibility', 'Resolution', 'Rodent', 'Role', 'Routine Diagnostic Tests', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Shapes', 'Signal Transduction', 'Skeletal Muscle', 'Solid', 'Specificity', 'Stenosis', 'Stress', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Water', 'Work', 'anatomic imaging', 'artificial neural network', 'base', 'clinical application', 'clinical practice', 'clinically translatable', 'detection sensitivity', 'disability', 'exercise intolerance', 'experience', 'hemodynamics', 'imaging platform', 'indexing', 'inorganic phosphate', 'macromolecule', 'magnetic field', 'mouse model', 'novel', 'radio frequency', 'rapid technique', 'skeletal muscle metabolism', 'spectroscopic imaging', 'success', 'validation studies']",NHLBI,HUGO W. MOSER RES INST KENNEDY KRIEGER,R01,2021,423225
"Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs) PROJECT SUMMARY A major concern with continuous flow ventricular assist devices (CF-VADs) is the resulting non-physiological flow with diminished pulsatility which has been shown to be a major risk factor for development of arteriovenous malformations (AVMs) and gastrointestinal (GI) bleeding. To address this issue, flow modulation via rapid changes in pump impeller speed has been proposed as a technique to introduce ‘artificial pulsatility’. However, given the inadequacy of large animal models with recreating CF-VAD associated non-surgical bleeding events, it is still unclear if artificial pulsatility can prevent these adverse events or what level of artificial pulsatility is even necessary. To evaluate the effects of pulsatility and identify promising flow modulation approaches we developed a vascular pulse perfusion model (VPPM) to culture Human Aortic Endothelial Cells (HAECs) under conditions of normal pulsatile flow or flow with diminished pulsatility (CF-VAD support). Our rationale for modeling arterial vessels is because pulsatility primarily affects the arterial side of the circulatory system and its effects are transduced by endothelial cells that line the large arterial vessels. The VPPM was validated as relevant model via direct comparison with aortic samples of patients with and without CF-VADs. Our published data also shows that loss of pulsatility is associated with an increase in production of pro-angiogenic/inflammatory cytokines. The relevance of these results is further strengthened by supporting data from patients that experience AVMs and GI bleeding events (both CF-VAD related and due to other conditions) showing similar elevated levels of pro- angiogenic/inflammatory cytokines. The VPPM therefore provides a powerful model to evaluate artificial pulsatility in the context of CF-VAD flow modulation and determine if restoring pulse pressure and/or pulse frequency can mitigate non-surgical bleeding events. Based on recent studies that suggest that pulse pressure < 35 mmHg is a major risk factor for development of GI bleeds, we hypothesize that “Diminished pulsatility associated with ‘CF-VAD support’ results in endothelial dysfunction and pro-inflammatory/pro-angiogenic soluble factor production. These changes can be mitigated via introduction of artificial pulsatility using flow modulation strategies where pulse pressure is preserved at > 35 mmHg”. Aim1 will evaluate response of patient derived endothelial cells within the VPPM to CF-VAD flow and quantify angiogenic/inflammatory soluble factor production, Aim2 will follow patients for up to 36 months to evaluate serum levels of pro-angiogenic/pro- inflammatory cytokines and non-surgical bleeding events which will then be compared to results from in-vitro studies within the VPPM and Aim3 will evaluate different flow modulation strategies using patient-derived endothelial cells to determine most promising patient-specific approaches via comparison of hemodynamic profiles and cytokine biomarkers using deep learning approaches. Successful completion of this project will enable identification of device-based strategies to prevent non-surgical bleeding in patients on CF-VAD support. PROJECT NARRATIVE This project seeks to determine the effects of diminished pulsatility during continuous flow ventricular assist device (CF-VAD) support on human aortic endothelial cells (HAECs). Changes in production of pro- angiogenic/pro-inflammatory cytokines will be used as biomarkers to evaluate the effects of loss of pulsatility and help validate new approaches to introduce artificial pulsatility in CF-VADs.",Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs),10116660,R01HL151663,"['Activities of Daily Living', 'Address', 'Adverse event', 'Affect', 'Age-Years', 'Aging', 'Animal Model', 'Animals', 'Antioxidants', 'Arteriovenous malformation', 'Biological Markers', 'Blood Vessels', 'Blood specimen', 'Brain hemorrhage', 'Cardiovascular system', 'Cell Line', 'Cells', 'Data', 'Development', 'Devices', 'Endothelial Cells', 'Endothelin-1', 'Endothelium', 'Event', 'Frequencies', 'Functional disorder', 'Gastrointestinal Hemorrhage', 'Heart failure', 'Hemorrhage', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Machine Learning', 'Mediating', 'Medical', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Perfusion', 'Physiologic pulse', 'Physiological', 'Production', 'Protocols documentation', 'Publishing', 'Pulsatile Flow', 'Pulse Pressure', 'Pump', 'Quality of life', 'Quantitative Evaluations', 'Refractory', 'Regulation', 'Risk Factors', 'Sampling', 'Serum', 'Sheep', 'Side', 'Signal Transduction', 'Speed', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Transducers', 'Translating', 'VWF gene', 'Validation', 'Work', 'base', 'cytokine', 'deep learning', 'endothelial dysfunction', 'experience', 'gastrointestinal', 'hemodynamics', 'improved', 'novel strategies', 'operation', 'patient response', 'preservation', 'pressure', 'prevent', 'response', 'safety testing', 'ventricular assist device']",NHLBI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,593704
"Accuracy and Precision in CT Quantification of COPD Through Virtual Imaging Trials Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of death. Increasing in prevalence, COPD is a major burden to patients and providers. Computed tomography (CT) can provide valuable information about the structural and functional abnormalities of the disease as demonstrated in numerous studies where quantitative CT is deployed to characterize and evaluate the treatment. For instance, the COPDGene study has recently shown the substantial role of quantitative CT in the redefinition of COPD diagnosis, and in evaluating the progression of emphysema over time. However, these biomarkers vary across different scanners, settings, and patient attributes. There is a crucial need to manage this variability by optimizing and harmonizing CT images for reliable biomarker quantifications across both current and emerging scanners. This goal is not possible through conventional methods of using physical phantoms or patient images. Physical phantoms are often oversimplified and not representative of the complex anatomy and physiology of COPD patients. Patient images are ground-truth-limited, i.e., the exact anatomy and physiology of the patient is not fully known. Further, patient-based comparisons require multiple acquisitions of the same subjects across different scanners and settings. This is not ethically possible since repeated imaging increases the absorbed radiation dose. These challenges can be overcome through the use of virtual imaging trials (VITs) where studies are performed in silico using computational models of patients and scanners. VITs can provide reliable and practical solution to the challenge of COPD imaging provided realistic models of patients and scanners. Such models are currently lacking in the context of COPD. We develop and then utilize realistic virtual imaging toolsets to systematically evaluate and optimize CT biomarkers in COPD patients across scanners, imaging parameters, and patient attributes. We develop the first library of realistic COPD patient models with diverse attributes and severities. Coupled with accurate models of different scanners, the phantoms will be used to generate sets of ground-truth-known virtual CT cases, to be disseminated to the research community and to be used to systematically evaluate the effects of current and emerging scanners, various patient attributes, and the effects of image processing algorithms (through a national challenge), on the accuracy and precision of COPD biomarkers. Further, we develop and optimize a truth-based artificial intelligence-based algorithm for COPD quantifications. We optimize the algorithm for accuracy and reproducibility, taking advantage of the ground-truth known simulated images . We then harmonize CT settings across different scanners to accurately and precisely assess COPD imaging biomarkers for both single time-point and longitudinal studies. The studies will be done for the top two image processing algorithms, identified in the challenge, as well as our developed algorithm. Through these efforts, the project will position CT as a more reliable method for improved characterization and monitoring of COPD. Narrative The project aims to systematically evaluate and optimize quantitative CT imaging biomarkers in Chronic Obstructive Pulmonary Disease (COPD) patients, across scanner makes and models, imaging parameters, and patient attributes. This will be performed by developing and using in silico models of COPD patients and CT scanners. The project will position CT alongside other diagnostic methods to accurately and precisely characterize COPD.",Accuracy and Precision in CT Quantification of COPD Through Virtual Imaging Trials,10298963,R01HL155293,"['Algorithms', 'Anatomy', 'Artificial Intelligence', 'Biological Markers', 'Cause of Death', 'Chronic Obstructive Airway Disease', 'Communities', 'Comparative Study', 'Complement', 'Complex', 'Computed Tomography Scanners', 'Computer Models', 'Coupled', 'Data', 'Data Set', 'Densitometry', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease model', 'Effectiveness', 'Environmental Risk Factor', 'Evaluation', 'Exposure to', 'Goals', 'Image', 'Interstitial Lung Diseases', 'Libraries', 'Longitudinal Studies', 'Lung', 'Lung diseases', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Patient imaging', 'Patients', 'Photons', 'Physiology', 'Positioning Attribute', 'Prevalence', 'Protocols documentation', 'Provider', 'Pulmonary Emphysema', 'Radiation exposure', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Role', 'Severities', 'Severity of illness', 'Smoking', 'Spirometry', 'Structure', 'Symptoms', 'System', 'Technology', 'Time', 'Tube', 'Variant', 'X-Ray Computed Tomography', 'base', 'cohort', 'disease diagnosis', 'human model', 'image processing', 'imaging biomarker', 'improved', 'in silico', 'in vivo', 'insight', 'intelligent algorithm', 'quantitative imaging', 'radiation absorbed dose', 'reconstruction', 'tool', 'virtual', 'virtual imaging', 'virtual patient', 'voltage']",NHLBI,DUKE UNIVERSITY,R01,2021,447232
"Multiplexed imaging of viral protein processing and assembly in live cells Project Summary Imaging the full lifecycle of viral proteins in vivo is essential for understanding the molecular processes underlying viral infection. Live-cell imaging has long been performed using fluorescent protein fusion tags such as GFP. However, these tags can alter the size and function of targeted proteins. Furthermore, slow maturation, degradation, and photobleaching of tags results in the loss of signal, making it difficult to track the early life and ultimate fate of many proteins. Viral polyproteins, in particular, remain refractory to imaging in vivo due to their hypersensitivity to tags and the extensive processing and assembly they undergo during viral biogenesis. The use of linear epitope tags reversibly labeled by genetically encoded live-cell probes can solve many of these issues. Unfortunately, engineering functional probes for live-cell imaging of epitopes has been costly and time-consuming. In the proposed research, we combine expertise in protein engineering, single- molecule microscopy, and biochemistry to refine and accelerate the rational design of orthogonal epitope/probe pairs for highly multiplexed imaging of full viral protein lifecycles in living cells. We demonstrate the power of our strategy in our Preliminary Data by creating novel scFvs that bind the commonly used HA and Flag epitopes with high affinity in a variety of demanding live-cell imaging scenarios. In Aim 1, we will use our tested strategy to develop scFv against additional viral epitope tags and validate their utility in imaging experiments. To identify chimeric scFv that are both soluble and active within the cellular milieu, we will graft known epitope-specific CDR loops onto a unique panel of stable scFv scaffolds. In Aim 2, we will use state-of- the-art computational protein modeling and design to develop novel predictive binding models for scFv:viral- epitope complexes, establish and test protocols for de novo scFv design, engineer large scFv libraries encoding multiple new peptide-binding solutions, and screen using phage display. In Aim 3, we will demonstrate the utility of our newly developed scFv in live-cell imaging experiments by probing several critical aspects of viral biology. Specifically, we will use our engineered scFv to visualize and quantify the translation dynamics of flavivirus transmembrane polyproteins, and to monitor alphavirus particle assembly kinetics. Overall, this project will provide a powerful new pipeline for generating scFv proteins that can track viral proteins in living cells. The reagents we generate will provide the virus molecular biology community with new, versatile imaging tools to better illuminate many important biological processes. Project Narrative Conventional technology for intracellular imaging of viral proteins is limited in spatial and temporal resolution. This project will generate next-generation genetically encoded probe proteins that allow scientists to image when a given segment of a viral protein emerges from the ribosome, and observe when that segment moves or is buried during viral protein assembly. These tags will be used to image previously inaccessible processes, including viral polyprotein translation and homo-oligomerization of viral capsid proteins.",Multiplexed imaging of viral protein processing and assembly in live cells,10455219,R56AI155897,"['Address', 'Affinity', 'Alphavirus', 'Antibodies', 'Binding', 'Biochemistry', 'Biogenesis', 'Biological Process', 'Biology', 'Capsid', 'Capsid Proteins', 'Cells', 'Chimera organism', 'Chimeric Proteins', 'Color', 'Communities', 'Complex', 'Computers', 'Consumption', 'Crystallization', 'Data', 'Development', 'Directed Molecular Evolution', 'Engineering', 'Ensure', 'Epitopes', 'Eukaryotic Cell', 'Flavivirus', 'Genetic Materials', 'Genetic Recombination', 'Genome', 'HIV-1', 'Hand', 'Homo', 'Hypersensitivity', 'Image', 'Imaging Device', 'Immunoglobulin Fragments', 'Infection', 'Investigation', 'Kinetics', 'Label', 'Lead', 'Libraries', 'Life', 'Light', 'Machine Learning', 'Mechanics', 'Microscopy', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Virology', 'Monitor', 'Peptides', 'Phage Display', 'Photobleaching', 'Polyproteins', 'Positioning Attribute', 'Process', 'Protein Dynamics', 'Protein Engineering', 'Proteins', 'Protocols documentation', 'Reagent', 'Recombinant Proteins', 'Refractory', 'Replication-Associated Process', 'Research', 'Research Personnel', 'Ribosomes', 'Scientist', 'Signal Transduction', 'Specificity', 'Technology', 'Testing', 'Time', 'Translations', 'Validation', 'Variant', 'Viral', 'Viral Proteins', 'Viral Structural Proteins', 'Virus', 'Virus Diseases', 'Virus Replication', 'cost', 'design', 'design and construction', 'experimental study', 'in vivo', 'in vivo imaging', 'live cell imaging', 'live cell microscopy', 'model design', 'molecular dynamics', 'molecular imaging', 'multiplexed imaging', 'next generation', 'non-invasive imaging', 'novel', 'particle', 'prediction algorithm', 'protein structure prediction', 'real-time images', 'scaffold', 'single molecule', 'spatiotemporal', 'success', 'temporal measurement', 'virology']",NIAID,COLORADO STATE UNIVERSITY,R56,2021,517692
"Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation Project Summary / Abstract  Almost 400,000 cases of out-of-hospital cardiac arrest (OHCA) occur each year in the United States. In patients requiring cardiopulmonary resuscitation (CPR) for prolonged periods, current CPR methods are unable to maintain adequate blood flow and oxygen delivery to the vital organs. Survival is <10% in patients with shockable rhythms and ~0% in those with non-shockable rhythms. Current American Heart Association (AHA) recommendations for CPR follow a “one-size-fits-all” paradigm. Our goal is to improve vital organ perfusion during prolonged CPR by “personalizing” compression/decompression therapy with a dynamic CPR method that changes compression characteristics over the course of CPR after taking into account the temporal changes of chest wall compliance and hemodynamics in order to increase the rate of neurologically intact survival after OHCA.  In this grant proposal, we are investigating the deployment of machine learning algorithms incorporated into a mechanical CPR device to predict and optimize hemodynamics during CPR. We will use state-of-the-art dynamical modeling in conjunction with closed-loop control algorithms to individualize CPR characteristics and optimize temporal blood flow. Our preliminary results suggest that deployment of machine learning prediction algorithms paired with control algorithms in a preclinical Ventricular Fibrillation model can adapt compression and decompression depth in real time, resulting in increased vital organ blood flow as compared to standard CPR techniques Based on these results, we hypothesize that optimization of compression depth, decompression depth, duty cycle, and compression rate of CPR will lead to better outcomes. Our proposed research will: 1) identify the most promising algorithm for the prediction of CPR hemodynamics 2) identify the best control algorithm to pair with this prediction algorithm in terms of optimizing CPR hemodynamics and return of spontaneous circulation 3) use the prediction and control pairing to improve 48h neurologically intact survival in a porcine model of ventricular fibrillation, as compared to standard CPR techniques. Throughout this process, we will identify non-invasive alternative measurements to provide to the algorithms with the ultimate goal of proceeding with device development and human trials. Project Narrative In light of a growing body of evidence which suggests that prolonged duration CPR is a dynamic process, without universally optimal “one-size-fits-all” parameters, advanced methods of CPR individualization may be applied to optimize cardiac and cerebral perfusion for these patients. We propose to study the effects of machine learning and optimal control techniques within the context of CPR, thus creating a closed-loop CPR system that has been trained by pre-clinical data to modify CPR characteristics and optimize blood flow. Our preliminary studies suggest that machine learning and control algorithms can be successfully deployed in a preclinical model to adapt compression and decompression depth, increasing vital organ blood flow as compared to standard CPR techniques. If our hypotheses are verified, a gateway for the first human trials is open.",Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation,10186125,R01HL157625,"['Acute', 'Algorithms', 'American Heart Association', 'Animal Experiments', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biofeedback', 'Blood Circulation', 'Blood flow', 'Carbon Dioxide', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Cerebrum', 'Cessation of life', 'Characteristics', 'Chest wall structure', 'Choices and Control', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Databases', 'Device or Instrument Development', 'Devices', 'E-learning', 'Early Mobilizations', 'Evaluation', 'Family suidae', 'Feedback', 'Frequencies', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Hospitals', 'Hour', 'Human', 'Knowledge', 'Learning', 'Light', 'Linear Regressions', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Near-Infrared Spectroscopy', 'Neurologic', 'Organ', 'Outcome', 'Oxygen', 'Patients', 'Performance', 'Perfusion', 'Phase I Clinical Trials', 'Pre-Clinical Model', 'Process', 'Publishing', 'Recommendation', 'Research', 'Resuscitation', 'Shock', 'Survival Rate', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Ventricular Fibrillation', 'Ventricular Tachycardia', 'algorithm training', 'base', 'clinically relevant', 'coronary perfusion', 'experience', 'experimental study', 'hemodynamics', 'improved', 'in vivo', 'indexing', 'innovation', 'machine learning algorithm', 'neural network', 'out-of-hospital cardiac arrest', 'porcine model', 'pre-clinical', 'prediction algorithm', 'pressure', 'prospective', 'time interval']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2021,608552
"A Geometric and Morphoelastic Study of Aortic Dissection Evolution Project Summary/Abstract: The natural evolution of aortic dissection is notoriously unpredictable under current methods of evaluation and management. There is an urgent need to more completely elucidate the biomechanical stability of type B aortic dissections and identify signatures in the imaging data allowing for optimal patient classification based on aortic fragility. The long-term goal is the development and validation of image-based analysis algorithms to classify aortic stability and allow a personalized risk stratification for a given patient’s aortic geometry providing the basis for optimizing clinical management. The overall objective of this proposal is to utilize modern approaches in differential geometry, continuum mechanics, and computer vision to discover and characterize high-risk geometric structures hidden within computed tomography angiography (CTA) data of fragile aortas. The central hypothesis of this application is the existence of a fundamental link between aortic shape and aortic stability as it relates to the risk of aortic dissection and fragility. The rationale for this work is development of an easily translatable geometry and mechanics-based algorithm to predict dissection stability and intervention timing by discovering a richer and more nuanced mapping of aortic shapes hidden in existing patient imaging data. The central hypothesis will be tested by pursuing three specific aims: 1) develop a modern geometric classification for aortic shapes, 2) develop a computational model that provides the mechanism underpinning the shape evolution of aortic dissections, and 3) develop a modern successor to the traditional ‘maximum diameter’ measure of aortic dissections that integrates geometric, finite element, and physiologic factors. Utilizing a large pre-identified CTA data set of normal and dissected aortas at various stages of disease and intervention, aim 1 will use tools from computer vision to reduce aortic shape to distributions of shape index and curvedness. Aim 2 will utilize advanced morphoelastic finite element growth models to discover the biomechanical mechanism underpinning aortic shape changes in aortic dissections and validate these models on patient specific geometries over clinically relevant time periods. These novel shape and mechanical stability classifiers will be used in both linear and non-linear dimensionality reduction methods to define aortic shape sub-spaces for different clinical scenarios in aim 3. This proposal is innovative as it challenges the status quo of evaluation and treatment by deploying novel measures and techniques that analyze clinically relevant aortic geometry and the evolution of aortic shape. Every patient is taken to the operating room under the full intent of having a positive clinical outcome. The research outlined is significant because it is expected to provide surgeons and patients a more discriminative framework with which to make better informed management decisions concerning type B aortic dissections and ultimately optimize outcomes. Project Narrative: The proposed research is relevant to public health because it seeks to inform upon the potential benefits of surgical versus medical intervention for type B aortic dissection through the development of modern geometric and mechanistically based selection criteria. Upon completion there will be a richer and more nuanced understanding of aortic stability as defined from computed tomography angiography imaging, which will allow for more optimal patient selection. Thus, the proposed research is relevant to the part of the NIH’s mission to enhance cardiovascular health and improve mortality.",A Geometric and Morphoelastic Study of Aortic Dissection Evolution,10280305,R01HL159205,"['Algorithmic Analysis', 'Algorithms', 'Angiography', 'Aorta', 'Behavior', 'Biomechanics', 'Caliber', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Pathways', 'Computer Models', 'Computer Vision Systems', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Dissection', 'Elasticity', 'Elements', 'Equilibrium', 'Evaluation', 'Evolution', 'Failure', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Injury', 'Intervention', 'Link', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathway interactions', 'Patient Selection', 'Patient imaging', 'Patients', 'Pattern', 'Physiological', 'Principal Component Analysis', 'Probability', 'Process', 'Public Health', 'Research', 'Risk', 'Role', 'Scanning', 'Selection Criteria', 'Shapes', 'Stress', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Walking', 'Work', 'X-Ray Computed Tomography', 'base', 'biomechanical model', 'blood pressure variability', 'cardiovascular health', 'clinically relevant', 'density', 'differential geometry', 'geometric structure', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'mortality', 'novel', 'patient population', 'preservation', 'risk stratification', 'simulation', 'surgical risk', 'tool']",NHLBI,UNIVERSITY OF CHICAGO,R01,2021,459189
"Development and Dissemination of Clinical CEST MRI Acquisition and Analysis Methods for Cancer Imaging Applications This research plan will continue our development of Chemical Exchange Saturation Transfer (CEST) MRI acquisition and analysis methods for imaging patients with cancer. AcidoCEST MRI with an exogenous contrast agent is an innovative variation of this technique that measures extracellular pH in solid tumors. We have also developed an exceptionally innovative method that acquires endogenous CEST MR images with multiple powers, which can measure the chemical exchange rate of endogenous proteins that can assess relative differences in pH. We will improve our CEST MRI acquisition methods by accelerating the imaging speed, reducing and eliminating complications due to patient motion, eliminating complications caused by fat signal, and expanding to 3D imaging methods. We will also improve image analysis methods that are required for CEST contrast from endogenous proteins and exogenous contrast agents.  Our research has strong impact because acidoCEST MRI can track changes in tumor acidosis in response to chemotherapy and chemoradiation therapy in patients who have breast cancer and head & neck cancer. Endogenous CEST MRI can improve the diagnoses of brain tumor recurrence vs. pseudoprogression, and evaluations of lung cancer vs. lung infection. We will perform clinical studies with our endogenous and exogenous CEST MRI methods to image patients with brain, breast, lung, and head & neck cancers.  To amplify the impact of our research, we will develop versions of our CEST MRI acquisition methods for the many versions of the 13 Siemens hardware platforms and software operating systems at the MD Anderson Cancer Center. We will also develop user-friendly CEST analysis methods for many researchers at MD Anderson. We will leverage our unique research environment and expertise with intra-institutional dissemination to provide inter-institutional dissemination, by sharing share these acquisition and analysis tools with other CEST MRI researchers. We will collaborate with NIST to provide the first CEST MRI phantom that can standardize the development and implementation of intra- and inter-institutional CEST MRI methods.  Our team of outstanding investigators includes experts in CEST saturation methods, CEST MR image analysis, clinical contrast agents, rapid MRI acquisition methods, high field 7T MRI, clinical radiology, biostatistics, histopathology and oncology. Based on our expertise and years of productivity in clinical CEST MRI, we have developed an exceptional research approach. As the world's largest cancer center and a health destination, the MD Anderson Cancer Center has the patient population that provides very strong institutional support for our clinical studies. NARRATIVE We will develop new acquisition and analysis methods that assess tumor acidosis with CEST MRI, using exogenous CEST agents and endogenous sources of CEST contrast. We will apply our new methods to evaluate tumor acidosis in patients with breast cancer, head & neck cancer, lung cancer, and brain cancers. We will disseminate our CEST MRI acquisition and analysis methods to other CEST MRI researchers, along with a NIST-approved standard for clinical CEST MRI studies.",Development and Dissemination of Clinical CEST MRI Acquisition and Analysis Methods for Cancer Imaging Applications,10231170,R01CA231513,"['3-Dimensional', 'Acidosis', 'Address', 'Biometry', 'Brain', 'Brain Neoplasms', 'Breast', 'Breast Cancer Patient', 'Cancer Center', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical/Radiologic', 'Communities', 'Computer software', 'Contrast Media', 'Custom', 'Destinations', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Fatty acid glycerol esters', 'Fingerprint', 'Glioblastoma', 'Goals', 'Head Cancer', 'Head and Neck Cancer', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Implant', 'Lead', 'Lesion', 'Lung', 'Lung infections', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Maps', 'Measures', 'Methods', 'Motion', 'Neck Cancer', 'Non-Malignant', 'Oncology', 'Operating System', 'Pathway interactions', 'Patient imaging', 'Patients', 'Pattern', 'Productivity', 'Proteins', 'Protocols documentation', 'Radiation therapy', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Signal Transduction', 'Solid Neoplasm', 'Source', 'Speed', 'Standardization', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Variant', 'base', 'cancer imaging', 'chemical standard', 'chemoradiation', 'chemotherapy', 'clinical imaging', 'clinical translation', 'design', 'extracellular', 'frontier', 'head and neck cancer patient', 'imaging modality', 'improved', 'in vivo', 'innovation', 'inter-institutional', 'interest', 'lung imaging', 'machine learning method', 'malignant breast neoplasm', 'ovarian neoplasm', 'patient population', 'preclinical study', 'prospective', 'respiratory', 'response', 'tool', 'treatment response', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF TX MD ANDERSON CAN CTR,R01,2021,637830
"Mitigating High Grade Radiation-Induced Lymphopenia through Pretreatment Autologous Lymphocyte Infusion PROJECT SUMMARY Radiation induced lymphopenia (RIL) is a common radiation-related toxicity that has been recognized for over a century but often ignored as clinically inconsequential. However, accumulating evidence has demonstrated strong association of high grade RIL (seen in 30-50% of patients) with poor prognosis. The pervasive role of radiotherapy in the curative management of solid tumors supports the need to develop mitigating strategies, particularly for patients with a high risk of developing grade 4 (G4) RIL. We have compelling evidence from both clinical and preclinical work that severe RIL impacts cancer control and therapy effectiveness, and methods to reduce RIL may improve treatment outcomes. To further develop these approaches for clinical translation, we have proposed 2 specific aims. In aim 1, we will build on our initial prediction model for G4 RIL and leverage our large database of esophageal cancer patients who have completed chemoradiation (CRT) to develop a better predictive model for G4 RIL so that we can rapidly and efficiently identify the highest risk patients for mitigating strategies. In aim 2, we will determine the feasibility and safety of raising the baseline lymphocyte levels by autologous lymphocyte infusion (ALI) prior to initiating CRT. Fundamentally, this research will allow us to develop the necessary computational tool capable of properly identifying patients at risk for developing severe RIL, and complete a small feasibility and safety study of using ALI as a way to raise the baseline pre-treatment lymphocyte levels so that the probability of developing G4 RIL could be possibly curtailed. By targeting the at-risk patients to receive RIL mitigating strategies, we will hopefully be able to improve the cancer outcomes of standard cancer therapies, and build on current innovative strategies of immunotherapy and radiation combinations. PROJECT NARRATIVE Radiation therapy, a key pillar in the management of cancers, causes a common yet ignored side effect of radiation induced lymphopenia (RIL). Severe RIL has been linked to poor outcomes of patients, presumably due to reduced immune surveillance thereby increasing disease recurrence after radiation therapy. We propose developing a prediction model to help identify who are most at risk for developing severe RIL, and conduct a pilot study to help reduce the impact of RIL so that clinical outcomes for these at-risk patients will improve in the future.",Mitigating High Grade Radiation-Induced Lymphopenia through Pretreatment Autologous Lymphocyte Infusion,10017926,R21CA240881,"['Applications Grants', 'Bayesian Prediction', 'Blood Component Removal', 'CD8B1 gene', 'Cancer Control', 'Characteristics', 'Clinical', 'Clinical Research', 'Collaborations', 'Combination immunotherapy', 'Complication', 'Data', 'Databases', 'Diagnosis', 'Disease', 'Distant', 'Effectiveness', 'Enrollment', 'Feasibility Studies', 'Future', 'Grant', 'Immunologic Surveillance', 'Immunotherapy', 'Incidence', 'Inferior', 'Infusion procedures', 'Link', 'Low Dose Radiation', 'Lymphocyte', 'Lymphocyte Count', 'Lymphopenia', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methods', 'Modeling', 'Nomograms', 'Normal tissue morphology', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phase I Clinical Trials', 'Phase I/II Clinical Trial', 'Pilot Projects', 'Play', 'Probability', 'Prognosis', 'Proliferating', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Recording of previous events', 'Recurrence', 'Risk', 'Risk Factors', 'Role', 'Safety', 'Solid Neoplasm', 'Statistical Models', 'Stem cell transplant', 'Time', 'Toxic effect', 'Training', 'Translating', 'Treatment outcome', 'Tumor Antigens', 'Tumor Escape', 'Tumor-Infiltrating Lymphocytes', 'Validation', 'Work', 'autologous lymphocytes', 'base', 'cancer radiation therapy', 'cancer therapy', 'chemoradiation', 'clinical translation', 'clinical trial enrollment', 'cohort', 'computerized tools', 'disorder control', 'esophageal cancer patient', 'fundamental research', 'high risk', 'high risk population', 'improved', 'innovation', 'personalized approach', 'pre-clinical', 'predictive modeling', 'prognostic value', 'radiation effect', 'response', 'risk stratification', 'safety and feasibility', 'safety study', 'side effect', 'tool', 'tumor']",NCI,UNIVERSITY OF TX MD ANDERSON CAN CTR,R21,2021,176175
"Functional Cancer Cell Maps FUNCTIONAL CANCER CELL MAPS SUMMARY I am currently an Academic Program Officer in Prof. Trey Ideker’s lab at UC San Diego. My title reflects the varied roles I play in the Ideker Lab, both scientifically and administratively, as I also serve as the Assistant Director of the Cancer Cell Map Initiative (CCMI) and the San Diego Center for Systems Biology (SDCSB). I am involved in a wide range of research projects, both within the Ideker Lab and across the various Centers. Central though to many of these efforts is the role I play supervising a number of projects using the CRISPR/Cas9­based approach to map genetic interactions in cancer cells. These functional maps can be used to identify protein complexes and pathways in cancer cells and to reveal genetic dependencies that might be therapeutically tractable. These studies will also provide us with the necessary training data to build “visible” AIs, machine learning models that not only make accurate predictions but also provide mechanistic insights. FUNCTIONAL CANCER CELL MAPS NARRATIVE Many cancers in adults are caused by mutations acquired over time. Research in both the Ideker Lab and the Cancer Cell Map Initiative seek to understand how these mutations alter the function of proteins leading to cancer using a variety of biochemical, genetic and computational approaches. We are particularly interested in understanding how combinations of mutated genes can disrupt normal cell physiology as knowing about these mechanisms can help us identify new drug targets or biomarkers.",Functional Cancer Cell Maps,10220907,R50CA243885,"['Adult', 'Biochemical Genetics', 'Biological Markers', 'CRISPR/Cas technology', 'Cell physiology', 'Data', 'Dependence', 'Genes', 'Genetic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Play', 'Research', 'Research Project Grants', 'Role', 'Supervision', 'Systems Biology', 'Therapeutic', 'Time', 'Training', 'academic program', 'base', 'cancer cell', 'insight', 'interest', 'new therapeutic target', 'protein complex', 'protein function']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R50,2021,127035
"Rapid motion-robust quantitative DCE-MRI for the assessment of gynecologic cancers PROJECT SUMMARY  Gynecologic cancers are some of the most lethal diseases affecting women. Globally, one woman dies of cervical cancer every two minutes. MRI is increasingly used in the evaluation of gynecologic and many other cancers. Beyond its established use for cancer staging, there has long been an interest in the use of MRI-derived quantitative metrics to gain insights into the tumor microenvironment. Parametric maps obtained from quantification of dynamic contrast enhanced (DCE) MRI data can be used to study tumor vascularity and identify tumors that are better perfused and oxygenated and thus more sensitive to some treatments such as chemotherapy and radiation. However, the relative slow imaging speed and motion sensitivity of current MRI technology results in non-reliable and non-reproducible quantification of DCE-MRI data, which restricts its application in clinical practice.  Our group is a world leader in development of rapid motion-resistant DCE-MRI techniques, in particular using combinations of radial imaging and compressed sensing. We developed the technique called GRASP, which was conceived as an academic-industrial partnership and has now been successfully translated into standard clinical practice. Though powerful, the first generation of GRASP has limitations. First, radial imaging is robust to motion, but not free of motion, which usually results in blurring. Second, GRASP uses a very simple sparsifying transform for compressed sensing, which can introduce issues with quantification. Third, GRASP was not originally developed for pharmacokinetic analysis and misses important ingredients such as integration of AIF estimation and T1 mapping. Fourth, image reconstruction time is still very long – in the order of several minutes.  We have developed new advances to circumvent these limitations and offer a new DCE-MRI technique with increased speed, motion-resistance and personalized AIF estimation and T1 mapping for pharmacokinetic analysis. Following the PAR-18-009 guidelines, our main goal is to form an academic-industrial partnership between Memorial Sloan Kettering Cancer Center and General Electric Healthcare to translate these new developments in quantitative DCE-MRI for use in patients with gynecologic and other type of cancers. Specific Aims are as follows: 1. Develop and implement a fast motion-resistant quantitative DCE-MRI technique that goes beyond GRASP  to offer increased speed and resistance to motion; dynamic T1 mapping; and personalized and automated  pharmacokinetic analysis 2. Evaluate the repeatability, reproducibility and preliminary tumor response assessment of the fast motion-  robust quantitative DCE-MRI technique (“DCE-new”) and compare DCE-new to standard of care DCE-MRI  (“DCE-standard”) in patients with gynecologic cancer 3. Develop and evaluate fast image reconstruction algorithms based on deep learning PROJECT NARRATIVE This project aims to establish an academic-industrial partnership between Memorial Sloan Kettering Cancer Center and General Electric Healthcare to develop and disseminate advances in dynamic contrast-enhanced (DCE) MRI for use in cancer patients. The new developments, which include radial imaging, compressed sensing, and deep learning, will deliver rapid motion-resistant DCE-MRI with high spatial and temporal resolution for more accurate and reproducible quantification of MRI-derived metrics. The new technology to be disseminated as a prototype on GE scanners will promote the use of quantitative DCE-MRI biomarkers in clinical practice, a long-desired goal.",Rapid motion-robust quantitative DCE-MRI for the assessment of gynecologic cancers,10267713,R01CA244532,"['Affect', 'Aftercare', 'Algorithms', 'Automation', 'Blood Vessels', 'Breathing', 'Cancer Patient', 'Chemotherapy and/or radiation', 'Clinical', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnostic Neoplasm Staging', 'Dimensions', 'Discipline of obstetrics', 'Disease', 'Drug Kinetics', 'Early treatment', 'Environment', 'Evaluation', 'Generations', 'Goals', 'Guidelines', 'Gynecologic', 'Gynecology', 'Healthcare', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'International', 'Learning', 'Licensing', 'Magnetic Resonance Imaging', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Manufacturer Name', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Methodology', 'Modeling', 'Monitor', 'Morphology', 'Motion', 'New York', 'Patients', 'Prediction of Response to Therapy', 'Qualitative Evaluations', 'Radial', 'Relapse', 'Reproducibility', 'Resistance', 'Speed', 'T2 weighted imaging', 'Techniques', 'Time', 'Training', 'Translating', 'Translations', 'Treatment Side Effects', 'Tumor stage', 'Universities', 'Woman', 'advanced disease', 'anticancer research', 'base', 'cancer imaging', 'cancer type', 'chemoradiation', 'clinical practice', 'contrast enhanced', 'convolutional neural network', 'deep learning', 'experience', 'image reconstruction', 'improved', 'improved outcome', 'individualized medicine', 'industry partner', 'insight', 'interest', 'magnetic resonance imaging biomarker', 'motion sensitivity', 'new technology', 'novel', 'population based', 'prototype', 'reconstruction', 'response', 'standard of care', 'success', 'temporal measurement', 'tool', 'treatment response', 'tumor', 'tumor microenvironment']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2021,568123
"A robust platform for multiplexed, subcellular proteomic imaging in human tissue Project Summary Multiplexed Ion Beam Imaging by Time of Flight (MIBI-TOF) uses secondary ion mass spectrometry and metal conjugated primary antibodies to simultaneously visualize dozens of proteins at subcellular resolution in a single tissue section. This technology is back compatible with archival formalin fixed, paraffin embedded tissue (FFPE) and has been used in peer-reviewed work to simultaneously visualize and quantify 36 proteins in retrospective human tissue cohorts. In line with the stated goals of the HuBMAP consortium to develop both “High-sensitivity, high-resolution imaging techniques that can rapidly provide spectral data over large areas of tissue” and “Quantitative imaging analysis tools, including automated 3D image segmentation, feature extraction, and image annotation,” the work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease. To achieve this, we will validate 100 FFPE antibodies and optimize ready-to-use multiplexed staining panels in lyophilized format that will permit storage for at least two years. Protocols and reagents for multiplexed signal amplification of protein and mRNA targets will be further refined, while next generation instrumentation will increase sample throughput to permit full tissue section imaging of up to 40 proteins in 1 hour. Standardized reagents and more robust instrumentation will be accompanied by an automated computational pipeline that utilizes a standard set of segmentation markers and machine learning to accurately identify nuclei and cell borders in any non-neural human tissue. This data will be used to cluster single cell events into functionally distinct populations according to morphology, protein expression, and histological distribution. The reagents and computational pipeline proposed here synergize with existing HuBMAP-funded platforms and could be readily generalized to virtually any high dimensional imaging modality. Thus, this work will not only provide a practical, back compatible imaging platform for high throughput multiplexed imaging, but will also accelerate development of other complimentary imaging technologies as well. Project Narrative Multiplexed ion beam imaging by time of flight (MIBI-TOF) is a new technology for visualizing dozens of proteins in standard clinical tissue biopsies at high resolution. The work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease.","A robust platform for multiplexed, subcellular proteomic imaging in human tissue",10247827,UH3CA246633,"['Allergic', 'Antibodies', 'Archives', 'Area', 'Back', 'Basic Science', 'Biopsy', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Communities', 'Data', 'Data Set', 'Decidua', 'Development', 'Disease', 'Equipment', 'Event', 'Extramural Activities', 'Feedback', 'First Pregnancy Trimester', 'Formalin', 'Foundations', 'Freeze Drying', 'Funding', 'Goals', 'Granuloma', 'Health', 'Hippocampus (Brain)', 'Histologic', 'Hour', 'Human', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Imaging technology', 'Immune', 'Immunosuppression', 'Individual', 'Institutes', 'Ions', 'Letters', 'Link', 'Machine Learning', 'Medical center', 'Messenger RNA', 'Metals', 'Morphology', 'Multiplexed Ion Beam Imaging', 'Noninfiltrating Intraductal Carcinoma', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathology', 'Peer Review', 'Phenotype', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Tuberculosis', 'Readiness', 'Reagent', 'Reproducibility', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Spectrometry, Mass, Secondary Ion', 'Stains', 'Standardization', 'Structure', 'Technology', 'Three-Dimensional Image', 'Time', 'Tissue Embedding', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Work', 'cancer immunotherapy', 'cohort', 'computational pipelines', 'computational platform', 'computerized tools', 'design', 'feature extraction', 'graphical user interface', 'high dimensionality', 'high resolution imaging', 'human imaging', 'human tissue', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'ion source', 'machine learning method', 'multiplexed imaging', 'new technology', 'next generation', 'protein expression', 'quantitative imaging', 'reagent standardization', 'technology validation', 'tool', 'tumor microenvironment', 'user-friendly', 'virtual']",NCI,STANFORD UNIVERSITY,UH3,2021,547000
"Machine learning accelerated on-line adaptive replanning Abstract. The overall goal of this proposal is to develop and test a novel machine learning (ML) accelerated On-Line Adaptive Replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided radiation therapy (RT) (MRgRT). During the multi-fraction RT process, the location, shape and size of tumors and normal organs vary significantly between the fractions. These interfraction variations are among the major factors that can limit the accuracy of RT targeting. The current standard practice of image-guided RT (IGRT), developed to address the interfraction variations based on cone-beam CT (CBCT), can only correct for translational errors, and thus does not fully account for interfraction changes. To address this issue, researchers recently introduced online adaptive replanning (OLAR) that generates a new plan based on the anatomy of the day and delivers the plan for the fraction. Currently, two main obstacles affect the success of OLAR: (1) the anatomy of the day cannot be delineated accurately based on CBCT, and (2) the time required to perform OLAR is long enough to render it impractical. One way to improve the delineation accuracy is to use MRI versus CT. MRI-guided OLAR is currently being introduced into the clinics to substantially improve RT targeting. However, the bottleneck is still the impractical length of time required to segment the anatomy of the day, which can exceed 30 minutes. Furthermore, available synthetic CT (sCT) generation methods are slow or inaccurate for MRI-guided OLAR. There is no method available to quickly and objective determine when OLAR is necessary. To address these issues, we plan to develop novel techniques in the MOLAR solution. We hypothesize that the MRI-based MOLAR solution will fully account for interfraction changes, thereby substantially improving tumor targeting during RT delivery and the effectiveness of RT. Specifically, we aim to (1) develop practical ML-based solutions to quickly determine the necessity of OLAR and to rapidly generate accurate synthetic CTs; (2) develop ML-based techniques to substantially accelerate segmentation for OLAR using a progressive three-step process; and (3) verify clinical practicality and effectiveness of MOLAR by retrospectively and prospectively applying the MOLAR on MRI sets to test its speed and effectiveness in accounting for interfraction variations. We will develop this novel MOLAR solution by forging unique collaborations between clinical physicists, radiation oncologists and industry developers via an established academic-industry partnership. The successful completion of this project will enable clinicians to routinely practice “image-plan-treat”, which is the optimal solution for MRgRT. This new paradigm will fully account for interfraction variations, improve tumor targeting, reduce normal tissue toxicity, and ultimately encourage clinicians to revise the current doses and/or dose fractionations to increase therapeutic gain, enhance patient quality of life, and/or substantially save on healthcare costs. Our proposed strategy represents a drastic departure from current practice. We firmly believe that this strategy is the future of RT delivery. Project Narrative: This R01 application proposes to develop and test a novel machine learning accelerated online adaptive replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided adaptive radiation therapy through a unique academic and industry partnership. The MOLAR solution aims to fully account for interfraction variations, thereby substantially improving the accuracy and effectiveness of radiation therapy (RT) for cancer. This solution will enable clinicians to routinely practice “image-plan-treat”, a drastic departure from current practice and representing the future of RT delivery.",Machine learning accelerated on-line adaptive replanning,10129924,R01CA247960,"['3-Dimensional', 'Accounting', 'Address', 'Adoption', 'Affect', 'Air', 'Anatomy', 'Clinic', 'Clinical', 'Collaborations', 'Dose Fractionation', 'Effectiveness', 'Electron Transport', 'Future', 'Generations', 'Goals', 'Health Care Costs', 'Image', 'Industry', 'Learning', 'Length', 'Location', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of pancreas', 'Maps', 'Methodology', 'Methods', 'Modality', 'Normal tissue morphology', 'Organ', 'Patients', 'Physiology', 'Process', 'Quality of life', 'Radiation Oncologist', 'Radiation therapy', 'Research Personnel', 'Shapes', 'Site', 'Speed', 'Surface', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Toxic effect', 'Variant', 'automated segmentation', 'base', 'bone', 'cancer radiation therapy', 'cone-beam computed tomography', 'convolutional neural network', 'electron density', 'forging', 'image guided', 'image guided radiation therapy', 'imaging modality', 'improved', 'industry partner', 'innovation', 'large datasets', 'neural network algorithm', 'novel', 'pancreatic cancer patients', 'prospective', 'prospective test', 'quantitative imaging', 'routine practice', 'soft tissue', 'success', 'targeted treatment', 'tool', 'treatment response', 'tumor']",NCI,MEDICAL COLLEGE OF WISCONSIN,R01,2021,495299
"Informatics Tools To Analyze And Model Whole Slide Image Data At The Single Cell Level Project Summary  Digital scanning of tissue slides, including both hematoxylin and eosin (H&E)-stained and immunohistochemistry (IHC)-stained slides, is becoming a routine clinical procedure. Technological advances in imaging, computing and molecular profiling have enabled in-depth tissue characterization at single-cell resolution while retaining the cell spatial information and its histological context. The confluence of these developments has created unprecedented opportunities for studying the relationships among tumor morphology, molecular events, and clinical outcomes. However, there is a lack of computational tools that can fully utilize the comprehensive information in tissue images at the single-cell level. The overarching goal of this proposal is to develop iSEE-Cell (image-based Spatial pattern ExplorEr for Cells), a suite of informatics tools to enable image data analysis, spatial modeling and data integration at single-cell resolution. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, spatial modelling, single cell genomics, cancer pathology and software development. Specifically, we will: 1. Develop algorithms to classify different types of cells based on nucleus morphology, that will be applicable to all types of tissue images. 2. Develop a powerful image restoration tool and quality enhancer for restoring blurred regions, enhancing low resolution/magniﬁcation into high resolution, and normalizing staining colors. 3. Develop and integrate tissue image analysis, spatial modeling and visualization tools into the iSEE-Cell platform. We will engage users, including informaticians, oncologists, pathologists, surgeons and cancer biologists, in the process of algorithm and tool development to collect feedback for the proposed informatics tools. All proposed methods were motivated by real-world biological and clinical applications. If implemented successfully, the proposed study will facilitate users in studying the tumor microenvironment and in improving cancer risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in imaging, computing and molecular profiling have enabled the in-depth tissue characterization of tumor tissues at single-cell resolution while retaining the histological context and spatial information of cells. The overarching goal of this proposal is to develop an informatics platform, iSEE-Cell (image-based Spatial pattern ExplorEr for Cells), which features a suite of informatics tools enabling image analysis, visualization and data integration at the single-cell level.",Informatics Tools To Analyze And Model Whole Slide Image Data At The Single Cell Level,10304819,U01CA249245,"['Advanced Malignant Neoplasm', 'Algorithms', 'Biological', 'Cancer Biology', 'Cell Nucleus', 'Cell model', 'Cells', 'Clinical', 'Color', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Enhancers', 'Ensure', 'Event', 'Feedback', 'Genomics', 'Goals', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Image', 'Image Analysis', 'Imaging technology', 'Immune', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Informatics', 'Infrastructure', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Non-Malignant', 'Oncologist', 'Outcome', 'Pathologist', 'Pathology', 'Pattern', 'Procedures', 'Process', 'Research', 'Resolution', 'Risk Assessment', 'Running', 'Scanning', 'Security', 'Slide', 'Stains', 'Standardization', 'Stromal Cells', 'Surgeon', 'Tissue imaging', 'Tissues', 'Tumor Tissue', 'Variant', 'Visualization', 'Visualization software', 'algorithm development', 'anticancer research', 'base', 'cancer cell', 'cancer risk', 'cancer type', 'cell type', 'cellular imaging', 'clinical application', 'community engagement', 'computer infrastructure', 'computerized tools', 'data integration', 'data management', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'digital pathology', 'experience', 'improved', 'informatics tool', 'insight', 'novel', 'outcome prediction', 'restoration', 'software development', 'tool', 'tool development', 'tumor', 'tumor microenvironment', 'usability', 'user-friendly', 'web services', 'whole slide imaging']",NCI,UT SOUTHWESTERN MEDICAL CENTER,U01,2021,407930
"Quantifying heterocellular communication and spatial intratumoral heterogeneity from high dimensional spatial proteomics data The tumor microenvironment (TME) is composed of malignant and non-malignant cells, each contributing to spatial intratumoral heterogeneity (ITH) and heterocellular communication altering the composition and architecture of the TME. A high degree of ITH is correlated to metastatic progression and therapeutic response. Previous studies investigating spatial ITH have been limited due to a steep trade-off between cellular resolution, spatial context, and dimensionality of biomarkers. A recent explosion of multi to hyperplexed imaging modalities (e.g., fluorescence imaging, mass-spec imaging) enable the quantiﬁcation of greater than 7 and up to > 100 biomarkers through sequentially multiplexed imaging of 2 to 3 biomarkers using iterative cycles of label-image-dye inactivation. The generation of this new type of data poses both unique opportunities and challenges. There are no state-of-the-art methods for harnessing the complexity of spatial data to infer tumor biology with a high dimensionality of biomarkers. In this project, we will probe the spatial complexity of a TME in hyperplexed immunofluorescence (HxIF) based spatial proteomics colorectal carcinoma (CRC) data (51 biomarkers + DAPI, 356 patient samples) to elucidate the heterocellular communication networks promoting spatial ITH through cellular phenotyping, microdomain extraction, and network biology inference algorithms. We will demonstrate the applicability of our algorithms to cancer types beyond CRC with multiplexed immunofluorescence breast cancer tissue samples  In Aim 1, we will continue to develop unsupervised learning algorithm for cellular phenotypic heterogeneity (LEAPH) to identify specialized, rare, and transitional cell populations. Initial results applying LEAPH on the HxIF CRC data have revealed cellular heterogeneity patterns consistent with CRC literature (STEM cell differentiation, immune evasion, macrophage evolution). We will incorporate machine learning- based methods into LEAPH to measure spatial distribution patterns of each phenotype and correlate them with CRC progression (e.g., recurrence). In Aim 2, we will quantify spatial ITH in greater detail by identifying differentially expressed pair- or group-wise spatial relationships based on outcome data (e.g., recurrence vs no-recurrence within 5 years) to reveal phenotypic domains, microdomains, with prognostic potential. We expect improvement of prognostic power with pair- or group-wise spatial interactions in comparison to the single-phenotype based spatial ITH characterization of Aim 1. In Aim 3, we will dissect the microdomain- specific heterocellular communication dynamics with causal inference network models. We expect to identify emergent signaling networks conferring malignant phenotypes, such as known features from CRC consensus molecular subtypes. The algorithms constructed in this project will be implemented and disseminated through the Tumor Heterogeneity Research Interactive Visualization Environment (THRIVE), an open source tool to assist cancer researchers in interactive hypotheses testing and guiding the design of therapeutic strategies. The recent explosion of next-generation, high-content, high-throughput spatial imaging technologies for intact tissues measuring protein expressions, DNA and RNA probes has attracted the interest of NIH and other international agencies in funding precision medicine efforts (e.g., HTAN, IOTN, HuBMAP, HCA, HPA). The overarching goal of this proposed project is to probe the spatial complexity of the tumor microenvironment in hyperplexed image datasets of tumor samples to elucidate the heterocellular communication networks promoting spatial ITH and related to disease progression through cellular phenotyping, microdomain extraction, and spatial network biology inference algorithms. The algorithms will be disseminated through the Tumor Heterogeneity Research Interactive Visualization Environment (THRIVE), an open source tool to assist cancer researchers in interactive hypotheses testing and guiding the rational design of therapeutic strategies.",Quantifying heterocellular communication and spatial intratumoral heterogeneity from high dimensional spatial proteomics data,10331796,F31CA254332,"['Algorithms', 'Architecture', 'Biological Markers', 'Biology', 'Cell physiology', 'Cells', 'Communication', 'Complex', 'Consensus', 'DNA Probes', 'Data', 'Data Set', 'Databases', 'Dimensions', 'Disease', 'Disease Progression', 'Drug resistance', 'Dyes', 'Environment', 'Epithelial', 'Evolution', 'Explosion', 'Funding', 'Gene Expression', 'Generations', 'Goals', 'Heterogeneity', 'Homeostasis', 'Human BioMolecular Atlas Program', 'Image', 'Imaging technology', 'Immune', 'Immune Evasion', 'Immunofluorescence Immunologic', 'Immunooncology', 'International Agencies', 'Isotopes', 'Label', 'Large Intestine Carcinoma', 'Learning', 'Literature', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Measures', 'Mesenchymal', 'Metastatic to', 'Methods', 'Modeling', 'Morphology', 'Mutation', 'Neoplasm Metastasis', 'Nerve Degeneration', 'Non-Malignant', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Property', 'Proteomics', 'RNA Probes', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'System', 'Systems Biology', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Tissue Sample', 'Tissues', 'Transitional Cell', 'Tumor Biology', 'United States National Institutes of Health', 'Validation', 'Visualization', 'Work', 'adaptive immunity', 'base', 'cancer type', 'cell type', 'cohort', 'design', 'differential expression', 'fluorescence imaging', 'high dimensionality', 'imaging modality', 'in silico', 'insight', 'interest', 'learning algorithm', 'macrophage', 'malignant breast neoplasm', 'malignant phenotype', 'molecular subtypes', 'multiplexed imaging', 'network models', 'next generation', 'open source tool', 'pathogen', 'precision medicine', 'predictive modeling', 'prognostic', 'prognostic model', 'prognostic value', 'protein expression', 'spatial relationship', 'statistics', 'stem cell differentiation', 'treatment response', 'tumor', 'tumor heterogeneity', 'tumor initiation', 'tumor microenvironment', 'tumor progression', 'tumorigenesis', 'unsupervised learning']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2021,45520
"A System for Xerostomia Risk Classification after Head & Neck Cancer Radiotherapy Summary Radiotherapy (RT) is a major component in the treatment of most head and neck cancer (HNC) cases. During irradiation, sensitive regions such as the salivary glands can sustain injury, resulting in xerostomia (dry mouth). This side effect is common and can significantly reduce quality of life during and post-treatment. The focus of this application is prediction during treatment planning of whether patients will suffer high-grade xerostomia (NCI CTCAE Grade 2-3) at the time of their first post-treatment follow-up visit, typically 3-6 months after RT (prevalence is approximately 40%). Predictions will enable clinicians to carry out treatment planning with improved knowledge of the likelihood of high-grade xerostomia development and allow better-informed and more timely anticipation of consequences such as eating difficulty. In this Phase 1 project, Oncospace Inc. will develop a Classification and Regression Tree (CART) prediction model using over 1200 complete HNC patient records. Associations between high-grade xerostomia and a wide range of dosimetric, clinical and demographic features will be automatically discovered and the features with the strongest associations will populate the nodes of a decision tree. The terminal leaf nodes will each contain the probability of high-grade xerostomia for the subset of patients in that node. In addition, leaf nodes will be assigned binary class labels designating a high- or low risk of high-grade xerostomia. This type of model provides transparency and interpretability, which are beneficial for clinical acceptance and for demonstration of safety to regulatory agencies. The software will be built using the Microsoft Azure cloud architecture and be deployed via a Software as a Service (SaaS) model. There are three distinct aims of this project:  1. Populate Oncospace Inc.’s Microsoft Azure CosmosDB database with data licensed from Johns Hopkins  University, including steps such as patient de-identification, data curation, and additional dataset feature engineering  2. Perform CART modeling and test model accuracy, using separate training and test datasets and a variety  of performance metrics, including sensitivity, specificity, AUC, and F1-score.  3. Design a clinically acceptable risk classification strategy and a user interface (UI) to communicate model  results. Expert input from a team of UI consultants and three radiation oncologists will be an integral part  of the development, testing, and evaluation processes. The successful completion of these aims will demonstrate the clinical and commercial feasibility of a xerostomia prediction model for HNC. Further development in Phase 2 will include deeper model personalization via incorporation of advanced image features (radiomics), as well as validation of model generalizability and commercial viability via the curation and use in model building of data from other institutions. Oncospace, formed in 2018, is uniquely positioned to carry out this work as the team includes the creators of the Pinnacle radiation therapy planning system, Tomotherapy radiation treatment delivery system, and HealthMyne Quantitative Imaging Decision Support platform. Oncospace has close clinical collaboration with Johns Hopkins University (JHU) for clinical feedback, validation and initial deployment. Oncospace has licensed three patents and subscription to complete patient treatment records for over 6,000 radiation oncology patients from JHU. The company has won the Microsoft Innovation Acceleration Award for its innovative platform to deliver AI-enabled healthcare solutions to the radiation oncology community. Page 1 of 1 Narrative During standard-of-care radiotherapy for head and neck cancer, the salivary glands often sustain radiation- induced injury leading to xerostomia (dry mouth). Machine learning-based predictions can be used to help create treatment plans that minimize the chance of severe xerostomia, and to better anticipate and manage its occurrence. The approach described in this application leverages a large database of head and neck cancer patients, including dosimetric, clinical and demographic features, to make well-informed predictions.",A System for Xerostomia Risk Classification after Head & Neck Cancer Radiotherapy,10255864,R43CA254559,"['Acceleration', 'Aftercare', 'Agreement', 'Anatomy', 'Architecture', 'Award', 'Benchmarking', 'Classification', 'Clinical', 'Collaborations', 'Common Terminology Criteria for Adverse Events', 'Community Clinical Oncology Program', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Decision Trees', 'Development', 'Disease', 'Dose', 'Eating', 'Economic Burden', 'Engineering', 'Ensure', 'Evaluation', 'Event', 'Feedback', 'Gland', 'Guidelines', 'Head Cancer', 'Head and Neck Cancer', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Image', 'Injury', 'Institution', 'Judgment', 'Knowledge', 'Label', 'Legal patent', 'Licensing', 'Machine Learning', 'Medical Records', 'Medicine', 'Modeling', 'Morbidity - disease rate', 'Neck Cancer', 'Organ', 'Outcome', 'Patients', 'Performance', 'Phase', 'Plant Leaves', 'Population', 'Positioning Attribute', 'Prevalence', 'Probability', 'Process', 'Quality of life', 'ROC Curve', 'Radiation', 'Radiation Oncologist', 'Radiation Oncology', 'Radiation therapy', 'Randomized Clinical Trials', 'Records', 'Reporting', 'Risk', 'Safety', 'Salivary Glands', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Training', 'Universities', 'Validation', 'Visit', 'Work', 'Xerostomia', 'base', 'cancer radiation therapy', 'cancer therapy', 'classification trees', 'clinical application', 'clinical decision support', 'cloud based', 'commercialization', 'data curation', 'design', 'follow-up', 'head and neck cancer patient', 'high risk', 'improved', 'inclusion criteria', 'individual patient', 'innovation', 'irradiation', 'model building', 'patient subsets', 'predictive modeling', 'prevent', 'product development', 'quantitative imaging', 'radiation-induced injury', 'radiomics', 'regression trees', 'side effect', 'software as a service', 'standard of care', 'treatment planning']",NCI,"ONCOSPACE, INC.",R43,2021,399916
"Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention, which is critical in reducing long term toxicity of cancers. To avoid excessively high radiation doses to organs-at-risk (OARs), OARs need to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dose distribution. Despite tremendous effort in developing semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability, as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria, thus leading to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. In summary, an accurate and fast process for segmenting OARs in treatment planning using CT scans is needed for improving patient outcomes and reducing the cost of radiation therapy of cancers. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, an automatic OAR segmentation product will be developed in this project with the three aims: 1) further improve the performance and robustness of OAR segmentation algorithms, focusing on addressing the heterogeneity issue of different clinical environments; 2) further enrich the functionalities and enhance usability of the cloud- based software product; and 3) perform clinical validation study on the algorithm performance and software usability at collaborating sites. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. The time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based automatic OAR segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers,10221655,R44CA254844,"['3-Dimensional', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Area', 'Artificial Intelligence', 'Atlases', 'Attention', 'Body Regions', 'Body part', 'Cancer Patient', 'Chest', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data', 'Development', 'Digital Imaging and Communications in Medicine', 'Dose', 'Early Diagnosis', 'Environment', 'Healthcare', 'Heterogeneity', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Label', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medical', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Online Systems', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Survival Rate', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Treatment Cost', 'Update', 'X-Ray Computed Tomography', 'algorithm development', 'automated segmentation', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinical heterogeneity', 'cloud based', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'dosimetry', 'healthcare community', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'life-long learning', 'millimeter', 'novel', 'phase 1 study', 'prototype', 'satisfaction', 'segmentation algorithm', 'simulation', 'software development', 'success', 'tool', 'treatment planning', 'usability', 'user-friendly', 'validation studies']",NCI,"CARINA MEDICAL, LLC",R44,2021,1000000
"Real-time MRI-guided adaptive radiotherapy of unresectable pancreatic cancer PROJECT SUMMARY Pancreatic cancer has the highest mortality rate of all cancers, with a 5-year survival rate of only 9%. Surgery still represents the only curative treatment option, though less than 20% of patients are candidates for resection. Approximately 30-40% of patients present with locally advanced unresectable tumors with no significant chance of long-term survival through standard treatments. The use of ablative radiation doses (biologically equivalent doses of 100Gy) produces results that are comparable to surgical resection in patients with inferior prognostic features. However, organ motion, due to respiratory motion, must be managed to minimize toxicity in the gastrointestinal tract. In this project, we will develop novel real-time volumetric MRI technology that can guide radiotherapy to enable the use of ablative doses with minimal risk. Our technique, called MR SIGnature Matching (MRSIGMA), pre-learns 3D motion states and assigns unique motion signatures during an offline learning phase and performs fast signature acquisition and matching during an online matching phase. We have demonstrated real-time tracking of liver tumors with an imaging latency (acquisition plus reconstruction) of about 250 ms using MRSIGMA. We will collaborate with Elekta to implement MRSIGMA on the Unity MR-Linac system and to link the output of MRSIGMA with the multileaf collimator (MLC) system to enable the radiation beam to track the 3D position and shape of the moving tumor in real-time. Specific Aims are as follows: 1. Develop deep learning reconstruction of undersampled dynamic MRI data for rapid motion database  generation during offline learning and adaptation during online matching  a. Develop a convolutional neural network for rapid reconstruction of motion-resolved data (< 10 seconds)  b. Detect anatomical changes, such as motion baseline drifts, and adapt the motion database accordingly  c. Perform initial validation on a dynamic MRI phantom and ten volunteers 2. Validate the potential of MRSIGMA for real-time volumetric tumor motion imaging on fifty patients with locally  advanced unresectable pancreatic cancer  a. Accuracy hypothesis: real-time MRSIGMA is noninferior to a non-real-time XDGRASP reference  b. Reproducibility hypothesis: two MRSIGMA scans present equivalent real-time imaging performance 3. Develop and validate on dynamic phantoms the proposed MRSIGMA-guided MLC tracking in collaboration  with Elekta  a. Develop software to control the MLC with the output of MRSIGMA  b. Evaluate tracking latency, geometric error, reproducibility and dosimetric accuracy PROJECT NARRATIVE This project will develop novel real-time 3D MRI technology, using continuous radial sampling, motion-resolved reconstruction, and deep learning, for MRI-guided adaptive radiotherapy of unresectable pancreatic cancer. Our new approach for real-time 3D MRI, named MR signature matching (MRSIGMA), pre-learns 3D motion states and corresponding signatures during an offline learning phase and then performs fast signature acquisition and matching to one of the pre-learned 3D motion states to minimize latency and offer a real-time solution. The novel real-time MRI technology will unlock the potential of the MR-Linac for pancreatic cancer and enable the use of curative doses rather than palliative doses, with minimal risk in patients who currently do not have a chance for long-term survival.",Real-time MRI-guided adaptive radiotherapy of unresectable pancreatic cancer,10299267,R01CA255661,"['3-Dimensional', 'Affect', 'Anatomy', 'Area', 'Biological', 'Breathing', 'Cancer Etiology', 'Cessation of life', 'Collaborations', 'Collimator', 'Data', 'Databases', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Dimensions', 'Dose', 'Electromagnetics', 'Excision', 'Gastrointestinal tract structure', 'Generations', 'Goals', 'Image', 'Implant', 'Inferior', 'Learning', 'Linear Accelerator Radiotherapy Systems', 'Link', 'Liver neoplasms', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Methods', 'Motion', 'Names', 'Oncology Group', 'Operative Surgical Procedures', 'Organ', 'Output', 'Patients', 'Performance', 'Phase', 'Positioning Attribute', 'Radial', 'Radiation', 'Radiation Dose Unit', 'Radiation Oncology', 'Radiation therapy', 'Reproducibility', 'Respiration', 'Sampling', 'Scanning', 'Shapes', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Three-Dimensional Imaging', 'Time', 'Toxic effect', 'Unresectable', 'Validation', 'base', 'convolutional neural network', 'curative treatments', 'deep learning', 'gastrointestinal', 'heart motion', 'imaging modality', 'minimal risk', 'mortality', 'novel', 'novel strategies', 'palliative', 'prognostic', 'real-time images', 'reconstruction', 'respiratory', 'soft tissue', 'software development', 'standard care', 'treatment planning', 'tumor', 'volunteer']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2021,640178
"Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers ABSTRACT  Gynecologic cancers are among the leading causes of cancer death in women worldwide. These patients typically are socioeconomically disadvantaged, with poor access to screening and vaccination. Consequently, they often present with locoregionally advanced disease, for which pelvic radiotherapy (RT) with concurrent cisplatin (i.e., chemoradiotherapy) is the standard of care. This treatment is limited, however, by high rates of treatment failure. Intensifying treatment through the delivery of chemotherapy doublets, either concurrently or as adjuvant therapy following chemoradiotherapy, is a promising strategy to improve outcomes. However, the delivery of intensive chemotherapy is complicated by high rates of gastrointestinal and hematologic toxicity. Strategies to reduce toxicity while increasing efficacy of chemoradiotherapy are needed.  Standard pelvic RT techniques encompass large volumes of normal tissue including bowel, bone marrow, bone, bladder, and rectum, leading to preventable radiation-induced toxicity. Image-guided radiation therapy (IGRT) can improve target localization and dosimetry, optimizing target dose while minimizing dose to surrounding normal tissues. However, IGRT can be highly resource intensive, and comparative effectiveness trials have been lacking. For this reason, there is considerable controversy as to the utility of IG-IMRT in this disease. Our research group has been at the forefront of developing novel, cost-effective IGRT approaches with wide potential to facilitate better delivery of concurrent and/or adjuvant chemotherapy.  Previously we have found that radiation-induced injury to hematopoietically active bone marrow is a critical determinant of tolerance to intensive chemotherapy. Using machine learning methods, we recently developed a multi-atlas-based IGRT method that can predict canonical distributions of active bone marrow, which can obviate the need for positron emission tomography (PET) in settings where this technology is unavailable or unaffordable. The proposed new research will study the ability of multi-atlas-based IGRT to reduce hematologic toxicity and improve chemotherapy delivery compared to standard treatment, using data from 450 patients enrolled to a randomized phase III trial (NRG-GY006). Furthermore, we will use serial whole body PET/CT to study the impact of radiation dose and chemotherapy intensity on the compensatory hematopoietic response, and have developed novel whole body radiomics biomarkers to quantify the inflammatory state, which we hypothesize can influence patients' outcomes and tolerance to chemotherapy.  The new research extends our work associated with a current R01 grant (1R01CA197059-01) to conduct correlative science associated with the GY006 trial. The overarching goal of this research line is to augment the therapeutic ratio of chemoradiotherapy for pelvic cancers using advanced image-guided radiation techniques. If successful, this research would significantly alter the approach to the treatment of many pelvic malignancies for which chemoradiotherapy is standard. PROJECT NARRATIVE In this study, we will test the ability of a novel method called multi-atlas-based image guided radiation therapy (IGRT) to reduce acute hematologic toxicity and improve chemotherapy delivery compared to conventional RT, which could obviate the need for expensive functional imaging in socioeconomically disadvantaged and resource constrained populations, such as patients with gynecologic cancers. In addition, we will use serial positron emission tomography to study effects of chemotherapy and radiation on the subacute compensatory hematopoietic response, and will seek to develop and validate novel whole body radiomics models of the inflammatory state as predictive biomarkers for gynecologic cancers. We are in an optimal situation to conduct impactful and innovative research in the context of an ongoing phase III cooperative group randomized registration trial (NRG GY006), affording us the opportunity to conduct rigorous correlative science on a large sample with high data quality, quality assurance, and carefully controlled treatment effects.",Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers,10108128,R01CA255780,"['Acute', 'Adjuvant Chemotherapy', 'Adjuvant Therapy', 'Aftercare', 'Aging', 'Atlases', 'Biological Markers', 'Bladder', 'Bone Marrow', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Chemotherapy and/or radiation', 'Cisplatin', 'Consumption', 'Data', 'Dependence', 'Disease', 'Distant', 'Dose', 'Effectiveness', 'Enrollment', 'Functional Imaging', 'Goals', 'Grant', 'Hematology', 'Hematopoiesis', 'Hematopoietic', 'Inflammatory', 'Injury', 'Intensity-Modulated Radiotherapy', 'Intestines', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neck', 'Normal tissue morphology', 'Organ', 'Outcome', 'Patient Selection', 'Patient-Focused Outcomes', 'Patients', 'Pelvic Cancer', 'Pelvis', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Positron-Emission Tomography', 'Predictive Factor', 'Process', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Randomized', 'Rectum', 'Recurrence', 'Research', 'Resources', 'Sampling', 'Science', 'Site', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Treatment Failure', 'Treatment outcome', 'Triapine', 'Vaccination', 'Woman', 'Work', 'advanced disease', 'base', 'bone', 'chemoradiation', 'chemotherapy', 'comparative effectiveness trial', 'cost', 'cost effective', 'data quality', 'dosimetry', 'fluorodeoxyglucose positron emission tomography', 'gastrointestinal', 'image guided', 'image guided radiation therapy', 'image-guided radiation', 'imaging approach', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality', 'novel', 'personalized medicine', 'phase III trial', 'predictive marker', 'quality assurance', 'radiation-induced injury', 'radiomics', 'recruit', 'response', 'screening', 'socioeconomic disadvantage', 'standard care', 'standard of care', 'tool', 'treatment effect', 'trial design', 'whole body imaging']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,276286
"Spectroscopy Assisted Laser Microdissection Abstract Molecular understanding of tumors relies greatly on appropriate samples to be prepared from epithelial cells in tissues. Epithelial cells, however, are often surrounded by other cell types and extracting pure populations of these cells is crucial for correct biospecimen preparation and resulting accuracy of molecular assays. Laser microdissection (LM) has contributed immensely in this effort due to its high spatial specificity in the extraction of defined cell populations and ease of use. While LM has enhanced the precision of biochemical analysis, several drawbacks remain. The necessity of staining and human supervision limits throughput, molecular yield and purity of samples. There is little explicit control or confidence in the purity of extracted cell populations while it is difficult to extract multiple cells from the same sample. Combining the morphologic specificity of microscopy and molecular sensitivity of spectroscopy, infrared (IR) spectroscopic imaging been employed to automate histopathologic recognition in complex tissues using artificial intelligence algorithms applied of spectral data. This project will demonstrate a completely automated instrument by coupling LM with IR microscopy. Termed spectroscopy-assisted laser microdissection (SLaM), the developed prototype will be validated using state of the art IR imaging systems and commercial LCM in terms of accuracy, speed and type fidelity. Last, the approach will be applied to extract cells of different types from the same prostate sample to demonstrate the capability to multiplex LM (muxLM) from the same tissue. The project directly addresses the need to reduce the time- and labor-intensive nature of LM. SLaM can maximize the quality and utility of biological samples used for downstream analyses by automation, high throughput and precision while enabling a comprehensive acquisition of cells without user fatigue or error, thereby providing a sample of higher integrity and quality for cancer molecular analysis. Project Narrative This project seeks to systematically develop and validate a new instrument for laser microdissection (LM). This infrared spectroscopic imaging powered prototype will recognize cells without staining, automates the laser capture of these cells and allows them to be extracted for biochemical assays at faster speed and higher accuracy than available with current technology. Since LM is critical to sample preparation in complex tissue, this project will make tissue-based analyses high throughput, automated and easier to use in biomedical research and in clinical protocols.",Spectroscopy Assisted Laser Microdissection,10284780,R21CA263147,"['Address', 'Animal Model', 'Area', 'Artificial Intelligence', 'Attention', 'Automation', 'Biochemical', 'Biological', 'Biological Assay', 'Biomedical Research', 'Carcinoma', 'Cell Extracts', 'Cells', 'Chemicals', 'Clinical', 'Clinical Protocols', 'Collecting Cell', 'Collection', 'Complex', 'Computer software', 'Coupling', 'Data', 'Development', 'Disease', 'Dissection', 'Dyes', 'Epithelial', 'Epithelial Cells', 'Fatigue', 'Fibroblasts', 'Film', 'Foundations', 'Goals', 'Hand', 'Heterogeneity', 'Histology', 'Human', 'Hybrids', 'Image', 'Imaging technology', 'Immune', 'Intervention', 'Label', 'Lasers', 'Learning', 'Light', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Microdissection', 'Microscopic', 'Microscopy', 'Molecular', 'Molecular Analysis', 'Morphology', 'Nature', 'Optics', 'Pathologist', 'Performance', 'Polymers', 'Population', 'Positioning Attribute', 'Preparation', 'Process', 'Prostate', 'RNA', 'Reaction', 'Research', 'Sampling', 'Slice', 'Slide', 'Solid', 'Specificity', 'Specimen', 'Spectrum Analysis', 'Speed', 'Spottings', 'Stains', 'Stromal Cells', 'Structural Chemistry', 'Supervision', 'System', 'Technology', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Tissue Stains', 'Tissues', 'Tube', 'Twin Multiple Birth', 'Validation', 'Variant', 'anticancer research', 'base', 'cell type', 'clinical application', 'clinical care', 'clinical diagnostics', 'design', 'design and construction', 'high throughput analysis', 'imaging system', 'improved', 'infrared microscopy', 'instrument', 'instrumentation', 'intelligent algorithm', 'interest', 'laser capture microdissection', 'mixed cell culture', 'molecular pathology', 'next generation sequencing', 'preservation', 'prototype', 'spectroscopic imaging', 'tumor', 'tumor microenvironment', 'user-friendly']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2021,188193
"A visible machine learning system to discover targeted treatment solutions in cancer Project Summary/Abstract Understanding of genetic interactions can lead to therapeutic design for individual cancer patients by targeting the specific genetic vulnerability in the cancer genome. For example, by identifying gene pairs that pose severe fitness defects when knocked out simultaneously (compared to separate knockouts), one can selectively kill cancer cells that harbor loss-of-function mutation in one protein by inhibiting its synthetic-lethal partner. Despite generation of large-scale data delineating the tumor transcriptome, proteome, metabolome, imaging, and so on, little is known regarding how different genes interact with each other and it is unclear how one can design targeted treatments based on the ‘omics data available. To address these challenges, the proposed research will develop a “visible” machine learning framework to systematically understand the higher-order genetic interactions (i.e. di-genic and tri-genic interactions) in cancer and design targeted treatments.  The first step for the proposed framework is to gain a holistic view of cancer pathways through combining the ‘omics data available. Multiple approaches have been applied to integrate data of similar forms, but there yet lacks an effective solution for integrating data of vastly different qualities and formats. To address this challenge, Yue Qin has developed a method to infer a hierarchical cancer cell map capturing cancer pathways at multi- scale resolution by fusing immunofluorescence (IF) imaging data and affinity purification-mass spectrometry (AP- MS).  During the F99 phase of the proposed research, by tying the architecture of a deep neural network to the hierarchical cancer cell map, Yue will develop a “visible” neural network (VNN) that can predict the cancer cell fitness from genetic perturbation (i.e. knockouts) and genomic backgrounds (i.e. mutations) while providing mechanistic insights in cancer pathways critical for genotype-phenotype prediction.  During the K00 phase of the award, Yue will develop genetic engineering approaches to experimentally map higher-order genetic interactions in cancer cells based on the mechanistic insights obtained from VNN during genotype-phenotype prediction. The data generated experimentally can directly inspire targeted treatment designs. In addition, the new data can be integrated into the hierarchical cancer cell map to improve accuracy and resolution of the inferred pathways, thus further improving the “visibility” of VNN in genotype-phenotype prediction. The combination of a computational focused training during F99 phase and experimental focused training during K00 phase will fully prepare Yue leading her own interdisciplinary research in cancer biology. In addition, the personalized training plan covering aspects including mentoring and teaching, scientific writing, and oral presentation will ensure Yue acquiring skills necessary for her future establishment as an independent investigator. Project Narrative This project proposes to establish a “visible” machine learning framework that systematically understands and efficiently maps higher-order genetic interactions (i.e. di-genic and tri-genic interactions) in cancer. Investigation of higher-order genetic interactions is critical for designing treatments that precisely target the genetic changes in individual cancer patients. Understanding the complex interplay among genes can further lead to effective design of combinatorial therapeutic solutions that maximize the synergy among treatments.",A visible machine learning system to discover targeted treatment solutions in cancer,10305321,F99CA264422,"['Address', 'Affinity Chromatography', 'Architecture', 'Award', 'Awareness', 'Binding Proteins', 'Biological', 'CRISPR screen', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cells', 'Cellular Structures', 'Complex', 'Critical Pathways', 'Data', 'Defect', 'Educational process of instructing', 'Ensure', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Engineering', 'Genetic Predisposition to Disease', 'Genome engineering', 'Genomics', 'Genotype', 'Image', 'Immunofluorescence Immunologic', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Knock-out', 'Lead', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Mentors', 'Methods', 'Modality', 'Mutation', 'Nature', 'Oral', 'Pathway interactions', 'Phase', 'Phenotype', 'Proteins', 'Proteome', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'System', 'Therapeutic', 'Training', 'Writing', 'base', 'cancer cell', 'cancer genome', 'combinatorial', 'deep neural network', 'design', 'empowered', 'experimental study', 'fitness', 'gene interaction', 'improved', 'insight', 'knockout gene', 'large scale data', 'loss of function mutation', 'metabolome', 'nanometer', 'neural network', 'neural network architecture', 'preservation', 'skills', 'synergism', 'targeted treatment', 'therapeutically effective', 'therapy design', 'transcriptome', 'tumor']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F99,2021,40429
"Dynamic µOCT for cellular tissue phenotyping Phenotyping cells and tissue is a critical function that spans basic science to clinical diagnosis. Yet, established methods for phenotyping cells in tissue are static, are evaluated when the tissue is dead, and typically involve destruction of the sample. This paradigm misses an entire dimension represented by cellular function and activity, information that is potentially of great significance in understanding cell/tissue state. Recently, a new field has emerged that uses coherence-gated imaging to quantify living tissue motion as a proxy of cellular function and activity. Coherence-based motility imaging is relatively new - much remains to be learned about the nature of its dynamic signal. In addition, many of the coherence-gated technologies described to date lack the resolution to investigate individual cells. The ones that are capable of seeing cells do not provide cross-sectional images and thus miss important architectural patterns associated with tissue maturation. We have developed a form of coherence-gated imaging called 1-µm optical coherence tomography (µOCT). µOCT has a resolution of 1 µm axial by 2 µm lateral, enabling cross-sectional visualization of tissue at the cellular level. Recently, we have discovered that by sequentially acquiring multiple µOCT images and computing the pixel-per-pixel power spectrum, we observe a dramatic increase in image contrast and new information emerging from the µOCT datasets. Preliminary studies with this new technology, termed dynamic µOCT (DµOCT), suggest that it can be used to visualize epithelial maturation, cell death/apoptosis, and cellular activity. In this grant, we will mature this technology by conducting key validation studies in a variety of clinically relevant human tissues, animal models, and spheroids to understand the dynamic signal and determine its accuracy for diagnosing pathology, activity, and response to therapy (apoptosis/necrosis) (Aim 1). We also will advance DµOCT further by increasing spatial and temporal resolution, creating new data mining analysis pipelines, and developing and validating technology and probes that enable DµOCT to be implemented in vivo (Aim 2). By expanding our understanding and implementation of this exciting technology, we hope to provide a powerful new tool that will have significant and wide-reaching impact in the biological and clinical sciences. In this proposal we will develop a cross-sectional imaging technology termed dynamic µOCT (DµOCT) that identifies distinct cells and tissues using intracellular motility signatures, a proxy of cell activity and state. Research will involve conducting a series of experiments in spheroids, animals, and human tissue to understand the nature of the dynamic signal and determine the diagnostic capacity of this technology for distinguishing disease, cell/tissue activity, and response to therapy. We additionally will develop next generation DµOCT technology that will increase resolution, provide more powerful diagnostic algorithms, and enable the use of DµOCT in living patients.",Dynamic µOCT for cellular tissue phenotyping,10221328,R01CA265742,"['3-Dimensional', 'ANXA5 gene', 'Algorithms', 'Animal Model', 'Antineoplastic Agents', 'Apoptosis', 'Apoptotic', 'Architecture', 'Area', 'Basic Science', 'Biological', 'Biological Sciences', 'Cancerous', 'Cell Death', 'Cell Line', 'Cell Maturation', 'Cell Proliferation', 'Cell physiology', 'Cells', 'Clinical', 'Clinical Sciences', 'Data', 'Data Set', 'Devices', 'Diagnostic', 'Dimensions', 'Disease', 'Epithelial', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Frequencies', 'Gold', 'Grant', 'Growth', 'Human', 'Image', 'Imaging technology', 'Immunohistochemistry', 'Individual', 'Label', 'Lateral', 'Light', 'Measures', 'Melanoma Cell', 'Metabolic', 'Metabolism', 'Methods', 'Microscopic', 'Modification', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'Movement', 'Mus', 'Nature', 'Necrosis', 'Optical Coherence Tomography', 'Optics', 'Organism', 'Organoids', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phase-Contrast Microscopy', 'Phenotype', 'Pilot Projects', 'Process', 'Propidium Diiodide', 'Proxy', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Signal Transduction', 'Skin', 'Source', 'Speed', 'Stains', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Upper digestive tract structure', 'Visualization', 'analysis pipeline', 'animal tissue', 'base', 'cell motility', 'clinical Diagnosis', 'clinically relevant', 'contrast imaging', 'data mining', 'diagnostic accuracy', 'disease diagnosis', 'drug efficacy', 'experimental study', 'histological slides', 'human tissue', 'imaging system', 'improved', 'in vivo', 'inhibitor/antagonist', 'machine learning algorithm', 'microdevice', 'mouse model', 'new technology', 'next generation', 'response', 'spatiotemporal', 'temporal measurement', 'three dimensional cell culture', 'tool', 'tumor', 'validation studies']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,619861
"Spatial omics technologies to map the senescent cell microenvironment Project Summary/Abstract Cellular senescence is a biological program whereby cells exit the cell cycle, typically as a consequence of DNA damage accumulation. After exerting their beneficial effects in young individuals by playing a role in tissue homeostasis, wound healing and tumor suppression, senescent cells are recognized and cleared by the immune system in response to their senescence-associated secretory phenotype (SASP). With age, immunosurveillance becomes increasingly dysregulated, senescent cells accumulate in tissues and their SASP leads to chronic inflammation which has been linked to many age-associated diseases including neurodegeneration, diabetes, osteoarthritis, fibrosis, heart disease and cancer. In addition, radiation and chemotherapy cause the accumulation of senescent cells in both normal and cancer tissues and create a microenvironment which can promote tumor relapse. Hence, methods to characterize the diversity of senescent cells in tissues are critical to improve our understanding of their roles in both normal physiology and disease and to develop more precise and effective senolytic and senostatic interventions. We propose to develop new technologies and integrative solutions to map the spatial epigenomic, transcriptome and proteomic states of senescent cells and their microenvironment in complex tissues. In the UG3 phase, we will develop spatial genomics, transcriptomics and proteomics methodologies to delineate senescent cells in a diverse set of murine tissues, including brain, liver and adipose tissue. We will also perform feasibility studies in a limited number of human samples available through tissue banks and collaborators, and in human cell culture. Our goal is to provide a proof of principle and evaluate the specificity and sensitivity of our proposed tools, technologies and methods (TTM) to identify and characterize the heterogeneity of senescent cells in multiple tissues. In the HG3 phase, we will optimize and expand our methodology to a variety of human tissues obtained from normal samples available from tissue banks, and via collaborations with other SenNet Tissue Mapping Centers (TMCs). Project Narrative Identification of senescent cells in tissues is particularly challenging as it requires detection of sets of markers that can be cell type specific. Our goal is to develop single cell multi-omic imaging technology to measure proteins, RNA and the DNA’s 3-dimensional conformation in senescent cells and in their microenvironment, in a diverse set of tissues. This new technology will allow us to better understand the heterogeneity of the senescent phenotype in tissues, and to study how senescent cells affect the status of neighboring cells.",Spatial omics technologies to map the senescent cell microenvironment,10384585,UG3CA268202,"['3-Dimensional', 'Adipose tissue', 'Affect', 'Age', 'Biological', 'Brain', 'Cell Aging', 'Cell Culture Techniques', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemotherapy and/or radiation', 'Chronic', 'Collaborations', 'Communities', 'Complex', 'DNA', 'DNA Damage', 'Data', 'Degenerative polyarthritis', 'Detection', 'Diabetes Mellitus', 'Disease', 'Dissociation', 'Feasibility Studies', 'Fibrosis', 'Generations', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Heart Diseases', 'Heterogeneity', 'Homeostasis', 'Human', 'Imaging technology', 'Immune system', 'Immunologic Surveillance', 'Individual', 'Inflammation', 'Intervention', 'Intrinsic factor', 'Laboratories', 'Link', 'Liver', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Molecular', 'Molecular Conformation', 'Multiomic Data', 'Mus', 'Nerve Degeneration', 'Nuclear', 'Outcome', 'Phase', 'Phenotype', 'Physiology', 'Play', 'Positioning Attribute', 'Production', 'Proteins', 'Proteomics', 'RNA', 'Relapse', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Series', 'Technology', 'Tissue Banks', 'Tissues', 'Transcript', 'Tumor Suppression', 'United States National Institutes of Health', 'Work', 'base', 'cell type', 'computer framework', 'epigenomics', 'high dimensionality', 'human tissue', 'improved', 'machine learning method', 'multidisciplinary', 'multiple omics', 'new technology', 'novel', 'programs', 'response', 'scale up', 'senescence', 'single cell sequencing', 'tool', 'transcriptome', 'transcriptomics', 'tumor', 'wound healing']",NCI,BROWN UNIVERSITY,UG3,2021,357900
"SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring Image-based evaluation of lymph nodes is an essential step in cancer diagnosis, treatment and monitoring. Current clinical practice mostly uses qualitative or semi-quantitative measures in evaluation and thus suffers from inaccuracy due to intra- and inter-observer variability and increased human efforts. This becomes a more serious issue in head and neck cancers due to the large number of clinically relevant lymph nodes. In this project an AI-based automatic segmentation software will be developed for quantitative cervical lymph node evaluation to increase the accuracy and reduce the cost. However, there are a few challenges in developing and deploying such a software due to different clinical practices such as usage of different modalities (MRI and/or CT) and complex clinical workflow. To address these challenges, a novel AI algorithm that can handle the variability in imaging modalities and support incremental learning using site-specific data to enhance its robustness will be developed; a private-cloud-based software framework with high usability will then be developed to incorporate this algorithm and provide advanced visualization and reporting for clinical usage. This software will have high impact on all stages of patient care for head and neck cancers and can be further extended to other cancers. n/a","SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10347278,5N91020C00048,"['Address', 'Algorithms', 'Artificial Intelligence', 'Cervical lymph node group', 'Clinical', 'Complex', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Evaluation', 'Head and Neck Cancer', 'Human', 'Image', 'Interobserver Variability', 'Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Modality', 'Monitor', 'Patient Care', 'Performance', 'Phase', 'Privatization', 'Reporting', 'Site', 'Small Business Innovation Research Grant', 'Software Framework', 'Visualization', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer prevention', 'clinical practice', 'clinically relevant', 'cloud based', 'cost', 'imaging modality', 'lymph nodes', 'novel', 'segmentation algorithm', 'usability']",NCI,"CARINA MEDICAL, LLC",N43,2021,55000
