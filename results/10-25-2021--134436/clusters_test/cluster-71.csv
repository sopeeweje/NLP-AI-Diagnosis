text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Vision in Natural Tasks Summary/Abstract  In the context of natural behavior, humans make continuous sequences of sensory-motor decisions to satisfy current behavioral goals, and vision must provide the information needed to achieve those goals. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks in natural locomotion, or the requisite information, and the proposal attempts to specify these.  in the context of natural gait, the patterns of optic flow are unexpectedly complex, raising questions about its role. The patterns of motion on the retina during locomotion depend critically on both eye and body motion, and these in turn depend on behavioral goals. Our first Aim is therefore to comprehensively describe the statistics of retinal motion patterns in a variety of terrains and task contexts. We will measure binocular eye and body movements while walking in outdoor terrains of varying roughness, crossing a busy intersection, and making coffee. These contexts will induce different gaze patterns. We will provide a comprehensive description of the motion stimulus in natural locomotion and help separate out self-motion signals from externally generated motion. These data will allow a more precise specification of the response patterns in cortical motion sensitive areas. Because of the complexity of natural motion patterns, we will re-examine the influence of optic flow on walking direction in a virtual reality environment and test alternative explanations for the role of flow.  A central task in walking is foot placement, and we will focus on identifying the image properties that make a good foothold. Stereo, structure from motion, and spatial image structure are all likely contenders. We directly investigate the role of stereo in foothold selection by examining gait patterns in stereo-deficient subjects in terrains with varying degrees of roughness. Using a different strategy, we will attempt to predict gaze locations and footholds in rough terrain using convolution neural nets (CNN’s) to identify potential search templates for footholds in rough terrain. We will describe fixation patterns from crosswalk and sidewalk navigation and attempt to make inferences about their purpose, and use Modular Inverse Reinforcement Learning (MIRL) to predict direction decisions and decompose the behavior into sub-tasks.  The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists The work will be strengthened by the investigation of stereo- deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available. Project Narrative  The central goal of this work is to understand vision in its natural context. This is very important information in order to devise suitable vision aids and rehabilitation strategies for individuals with visual impairments, and it is becoming increasingly accessible because of developments in technology for monitoring eye and body movements. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks and requisite information in natural locomotion, and the proposal attempts to specify these. The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists. The work will be strengthened by the investigation of stereo-deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available.",Vision in Natural Tasks,10246357,R01EY005729,"['Affect', 'Area', 'Behavior', 'Behavioral', 'Binocular Vision', 'Cells', 'Characteristics', 'Coffee', 'Collection', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Distant', 'Environment', 'Eye', 'Eye Movements', 'Gait', 'Goals', 'Grant', 'Head', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Link', 'Location', 'Locomotion', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Motor', 'Movement', 'Pattern', 'Psychological reinforcement', 'Retina', 'Rewards', 'Robot', 'Robotics', 'Role', 'Sampling', 'Seminal', 'Sensory', 'Signal Transduction', 'Speed', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Visit', 'Visual', 'Visual Fields', 'Visual impairment', 'Walkers', 'Walking', 'Work', 'base', 'convolutional neural network', 'cost', 'experimental study', 'foot', 'gaze', 'imaging properties', 'innovation', 'kinematics', 'novel', 'optic flow', 'rehabilitation strategy', 'response', 'sample fixation', 'statistics', 'virtual reality environment', 'vision aid', 'vision development', 'vision rehabilitation', 'visual information']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,370290
"Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1 Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at certain stages of the disease severity spectrum, specifically in the early stage and in advanced disease. These difficulties are due to a variety of causes that change over the course of the disease, including large between-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we build on our long-standing contribution to ocular imaging and propose novel and sensitive means to detect glaucoma and its progression that are optimized to the various stages of disease severity. We will use information gathered from visual fields (functional information) and a leading ocular imaging technology – optical coherence tomography (OCT; structural information) to map the capability of detecting changes across the entire disease severity spectrum to identify optimal parameters for each stage of the disease. Both commonly used parameters provided by the technologies and newly developed parameters with good diagnostic potential will be analyzed. We will use state-of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. We will also utilize a new imaging technology, the visible light OCT, to generate retinal images with outstanding resolution to extract information about the oxygen saturation of the tissue. This will provide in-vivo, real time, and noninvasive insight into tissue functionality. Taken together, this program will advance the use of structural and functional information with a substantial impact on the clinical management of subjects with glaucoma Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies that will substantially improve detection of glaucoma and its progression monitoring in order to prevent blindness.",Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1,10222677,R01EY013178,"['3-Dimensional', 'Blindness', 'Characteristics', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Data', 'Detection', 'Development', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Floor', 'Future', 'Glaucoma', 'Health', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Knowledge', 'Laboratories', 'Lead', 'Light', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Oxygen Consumption', 'Oxygen saturation measurement', 'Pathology', 'Research Proposals', 'Resolution', 'Retina', 'Retinal Diseases', 'Scanning', 'Severities', 'Severity of illness', 'Signal Transduction', 'Source', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissue Extracts', 'Tissues', 'Translating', 'Visible Radiation', 'Vision', 'Visual Fields', 'Width', 'advanced disease', 'analytical method', 'base', 'clinical practice', 'cohort', 'computerized', 'deep learning', 'density', 'ganglion cell', 'improved', 'in vivo', 'innovation', 'innovative technologies', 'insight', 'instrument', 'invention', 'knowledge base', 'longitudinal dataset', 'machine learning method', 'macula', 'mathematical methods', 'new technology', 'novel', 'novel strategies', 'ocular imaging', 'preservation', 'prevent', 'programs', 'research study', 'retinal imaging', 'retinal nerve fiber layer', 'tissue oxygenation', 'tool']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,666892
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,10237987,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'care providers', 'career', 'career development', 'cognitive interview', 'compare effectiveness', 'comparison intervention', 'design', 'functional disability', 'improved', 'improved functioning', 'insight', 'instrument', 'motor behavior', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual information', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2021,228623
"The Human Foveal Connectome The complex relationship of cone photoreceptor cells with retinal circuits, Müller glia, and retinal pigment epithelial (RPE) cells is essential to normal vision. Yet for the cones in the very center of the fovea that mediate peak visual acuity these relationships are poorly characterized. A longstanding barrier to a comprehensive understanding of cellular and subcellular foveal structure is the myriad interactions among a great diversity of cell types embedded and miniaturized within a complex three-dimensional architecture. The broad long-term objective of this new research program is to elucidate foveal microstructure directly by application of new methods of volume electron microscopy (connectomics). We will utilize retinal tissue acquired from an innovative organ donor program that will permit pre-recovery optical coherence tomography (OCT) imaging to assess retinal health status and foveal pit morphology and to guide connectomic reconstruction. Preliminary data from two donor eyes demonstrates feasibility of complete reconstructions of foveal cones and their associated synaptic pathways, Müller cells, and RPE cells. The first reconstructions of cone microcircuits from an adult born preterm indicate that the critical cells and synaptic pathways for foveal vision differ dramatically in structure and localization anticipated from previous work on non-human primates. Therefore in Aim 1 we propose to localize, identify and reconstruct quantitatively the synaptic visual pathways that arise from the central-most foveal cones. We will characterize all of the bipolar and ganglion cell circuits arising from these cones and test the new hypothesis that the dominant “midget” pathway subserving spatial acuity may be highly variable across individuals in both circuitry and pit localization. We will further test the hypothesis that beyond the midget circuit the foveal center gives rise to over twenty distinct but as yet uncharacterized visual pathways. The first reconstructions of Müller cells revealed the intimate wrapping of cone axons and abundance of processes in the plexiform layer and foveal floor. In Aim 2 we propose complete reconstructions of Müller cells to test the hypotheses that the foveal floor contains a novel Müller cell type restricted to inner retina and that morphology of individual Müller cells and their foveal distribution accounts for the macular pigment distribution. The first reconstructions of RPE cells provided new insights on the distribution of organelles important in clinical OCT and autofluorescence imaging. Therefore, in Aim 3 we propose to reconstruct and enumerate organelles in RPE cells in the cone-only fovea and the mixed rod-cone perifovea. We will directly test the hypothesis that RPE organelle content and distribution differs between cone-only fovea and rod-rich perifovea, accounting for the appearance of OCT bands and for topography of autofluorescence signal in clinical imaging. This proposal combines expertise and innovation in neurobiology, pathology, imaging, and connectomics. Outcomes will impact retinal neurobiology, clinical image interpretation, and pathophysiology of macular diseases, especially age-related macular degeneration. The human fovea is essential for best vision but understanding the crucial cellular interactions among photoreceptors, neural circuits and supporting non-neural cells in the foveal center is limited because the extremely miniaturized and complex three-dimensional structure and synaptic organization of this region is difficult to untangle with conventional methods. The proposed project will apply new methods of volume electron microscopy (“connectomics”) to reconstruct the human fovea for the first time. Outcomes will have broad significance for retinal neuroscience, clinical image interpretation, and the pathophysiology of macular disease, especially age-related macular degeneration.",The Human Foveal Connectome,10089446,R01EY028282,"['3-Dimensional', 'Accounting', 'Address', 'Adult', 'Age related macular degeneration', 'Aging', 'Anatomy', 'Apical', 'Appearance', 'Architecture', 'Area', 'Axon', 'Biological Process', 'Catalogs', 'Cells', 'Cellular Morphology', 'Characteristics', 'Clinical', 'Complex', 'Cone', 'Data', 'Development', 'Disease', 'Electron Microscopy', 'Eye', 'Female', 'Floor', 'Functional disorder', 'Future', 'Goals', 'Health Status', 'Human', 'Image', 'Image Analysis', 'Individual', 'Lead', 'Link', 'Lipofuscin', 'Location', 'Machine Learning', 'Mediating', 'Melanosomes', 'Methods', 'Miniaturization', 'Mitochondria', 'Morphology', 'Muller&apos', 's cell', 'Neurobiology', 'Neurosciences', 'Optical Coherence Tomography', 'Organ Donor', 'Organelles', 'Outcome', 'Pathway interactions', 'Photoreceptors', 'Pigments', 'Process', 'Recovery', 'Research', 'Resources', 'Retina', 'Retinal Cone', 'Retinal Diseases', 'Rod', 'Services', 'Signal Transduction', 'Source', 'Structure', 'Structure of retinal pigment epithelium', 'Supporting Cell', 'Synapses', 'Technology', 'Testing', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Visual Acuity', 'Visual Pathways', 'Work', 'cell type', 'clinical imaging', 'connectome', 'density', 'disorder of macula of retina', 'fovea centralis', 'ganglion cell', 'in vivo imaging', 'innovation', 'insight', 'macula', 'male', 'miniaturize', 'neural circuit', 'nonhuman primate', 'novel', 'pathology imaging', 'postsynaptic', 'programs', 'reconstruction', 'relating to nervous system', 'resilience', 'three dimensional structure', 'tool', 'visual performance']",NEI,UNIVERSITY OF WASHINGTON,R01,2021,452171
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,10316448,R00EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nerve damage', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R00,2021,247154
"Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye Age-related macular degeneration (AMD) is the leading cause of blindness in the elderly in the developed world; no cure exists and prevalence is rising rapidly. Because only primates have a macula and since no model of AMD exists in non-human primates, the disease course can only be elucidated through in-depth study of humans. Blindness in AMD is caused by progressive and irreversible death of rod and cone photoreceptors secondary to degeneration of the retinal pigment epithelium (RPE) that is essential for their health and function. Clinical imaging and histology have informed us greatly about the later stages of disease but fundamental knowledge to understand how AMD diverges from normal aging at onset is lacking. With advanced adaptive optics ophthalmoscopy (AOO) imaging methods, combined with clinical imaging and visual function testing, we will characterize healthy human retinal aging in cross-sectional study, by defining the in vivo RPE-photoreceptor cellular organization and microscopic autofluorescence variation with age and wavelength. This will produce the largest quantitative in vivo normative dataset of AOO cell-based metrics to date and we will use this data to generate new quantitative analysis tools needed to evaluate emerging therapies designed to prevent or slow vision loss in AMD (Aim 1). In a case-control study, we will then compare normal photoreceptor topography and RPE cell morphometry to clinically defined early AMD to quantitatively define the earliest cellular changes in AMD that can be detected in vivo. This work will identify the cellular alterations and phenotypes that differentiate normal aging from early AMD to facilitate early onset detection. These results will be contextualized by comparison to tissue-level alterations seen with aging and early AMD in clinical imaging, specifically choriocapillaris decline and drusen (Aim 2). The results of this study will result in a paradigm shift from the use of clinical diagnosis and classification systems for AMD that rely solely on tissue- level biomarkers or traditional funduscopic clinical signs to those that rely on rigorous quantitative in vivo cell- based metrics. Together, this knowledge and these tools will lay the foundation needed to develop and evaluate new preventative therapies that are needed to limit or prevent vision loss in AMD. Project Narrative Age-related macular degeneration is the leading cause of blindness in the elderly in the US and is a significant public health issue that is projected to worsen due to the rapidly aging population. Here we aim to understand how retinal cells change in normal aging and how these normal age-related changes differ from the changes that lead to age-related macular degeneration. This project will allow us to detect age-related macular degeneration earlier and will produce new tools to monitor retinal cells that will facilitate the development and testing of preventative therapies to slow or prevent vision loss in age-related macular degeneration.",Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye,10172913,R01EY030517,"['Age', 'Age related macular degeneration', 'Aging', 'Area', 'Atrophic', 'Biological Markers', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Case-Control Studies', 'Cells', 'Cessation of life', 'Choroid', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Cross-Sectional Studies', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic Procedure', 'Disease', 'Drusen', 'Elderly', 'Evaluation', 'Eye', 'Foundations', 'Genetic', 'Goals', 'Health', 'Histology', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Lead', 'Lipofuscin', 'Machine Learning', 'Maps', 'Melanins', 'Methods', 'Microscopic', 'Modeling', 'Monitor', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Perfusion', 'Phenotype', 'Photoreceptors', 'Prevalence', 'Preventive therapy', 'Preventive treatment', 'Primate Diseases', 'Primates', 'Public Health', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Photoreceptors', 'Risk', 'Secondary to', 'Spatial Distribution', 'Structure', 'Structure of retinal pigment epithelium', 'System', 'Techniques', 'Technology', 'Testing', 'Therapy Evaluation', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Work', 'adaptive optics', 'age related', 'aging population', 'base', 'clinical Diagnosis', 'clinical decision-making', 'clinical imaging', 'cohort', 'early onset', 'fluorophore', 'healthy aging', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'macula', 'morphometry', 'multimodality', 'neurovascular unit', 'nonhuman primate', 'normal aging', 'prevent', 'restorative treatment', 'retinal imaging', 'retinal rods', 'therapy design', 'tool']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,524330
"Diabetic Retinopathy: Genetics and Neurodegeneration (MSN246458) PROJECT SUMMARY/ABSTRACT Diabetes mellitus (DM) is the leading cause of vision loss among working aged adults. Its prevalence is increasing and despite the strides in knowledge and treatments, our understanding of the pathways leading to vision loss in DM remains limited. Hyperglycemia and duration of DM contribute to but do not fully explain the predisposition to develop diabetic retinal diseases. Given the predisposition for diabetic retinal diseases to cluster in families, genetic risk factors are thought to be important but none has so far been definitively implicated. Furthermore, data from small studies suggest that there are more phenotypes of diabetic retinal disease than are currently recognized in clinical practice. Diabetic retinal disease has traditionally been considered primarily a vascular process: diabetic retinopathy (DR) and diabetic macular edema (DME) are the main clinical manifestations. With improved imaging modalities and image analysis algorithms, there has been increasing recognition of a new clinical manifestation of diabetic retinal disease, diabetic retinal neurodegeneration (DRN). This is visible as alterations in thickness of retinal nerve fiber (RNFL) and/or ganglion cell layer (GCL) on optical coherence tomography (OCT) images. To date, DRN is poorly understood, and its role in clinical management of patients with DM has not been established. However, if retinal neurodegeneration occurs and is progressive, it can lead to profound visual difficulties for patients with DM. DRN may account for previously unexplained poor visual outcomes among patients with diabetic retinal disease despite standard of care treatment. Dr. Channa is a retina specialist, with prior research experience in retinal imaging and clinical trials of novel treatments for DME. In this K23 career development award she proposes to use a nationally representative dataset, the UK Biobank cohort to: 1) improve our understanding of DRN by determining RNFL and GCL thickness, using OCT imaging, in participants with DM (who have no DR or DME) compared to those who do not have DM 2) determine genetic factors associated with DR, DME and DRN. Dr. Channa proposes a career development plan, which includes mentorship, coursework, publications and clinical time. This will situate her as an independent clinician-scientist with expertise in translational research employing bioinformatics and computational skills in genomics and retinal image analysis to elucidate pathways of vision loss among patients with DM, ultimately leading to development of novel therapies. Her research work and career development will take place in the academic and collaborative environment of the largest medical center in the world, where she has institutional support and mentorship to develop as an independent clinician-scientist. PROJECT NARRATIVE In this career development award we aim to use genetic and retinal imaging data to enhance our understanding of the pathways that can lead to vision loss among people with diabetic retinal diseases. Improved understanding will translate into interventions aimed at preventing blindness from diabetes.",Diabetic Retinopathy: Genetics and Neurodegeneration (MSN246458),10320692,K23EY030911,"['Address', 'Adult', 'Affect', 'Algorithmic Analysis', 'American', 'Appearance', 'Artificial Intelligence', 'Bioinformatics', 'Blindness', 'Blood Vessels', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational algorithm', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Disease Pathway', 'Environment', 'Family', 'Fundus', 'Future', 'Ganglion Cell Layer', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genomics', 'Goals', 'Hyperglycemia', 'Image', 'Image Analysis', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Measurement', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Molecular', 'Nerve Degeneration', 'Nerve Fibers', 'Optical Coherence Tomography', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Predisposition', 'Prevalence', 'Prevention', 'Process', 'Publications', 'Race', 'Regression Analysis', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Risk Factors', 'Role', 'Sample Size', 'Scanning', 'Scientist', 'Specialist', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Translating', 'Translational Research', 'Vascular Endothelial Growth Factors', 'Vision', 'Visual', 'Work', 'aged', 'base', 'biobank', 'career development', 'clinical practice', 'cohort', 'collaborative environment', 'diabetes management', 'diabetic', 'disability', 'experience', 'family genetics', 'fiber cell', 'genetic risk factor', 'genome wide association study', 'genomic data', 'illness length', 'imaging modality', 'improved', 'large datasets', 'macular edema', 'nerve damage', 'novel', 'novel therapeutics', 'population based', 'prevent', 'retinal imaging', 'screening', 'skills', 'standard of care']",NEI,UNIVERSITY OF WISCONSIN-MADISON,K23,2021,248789
"Gaze-contingent computer screen magnification control for people with low vision ! Project Summary This application describes proposed research with the goal of facilitating use of a computer screen magnifier by people with low vision. Screen magnification is a well-established, popular technology for access of onscreen content. Its main shortcoming is that it requires the user to continuously control, with the mouse or trackpad, the location of the focus of magnification, in order to ensure that the magnified content of interest is within the screen viewport. This tedious process may be time-consuming and ineffective. For example, the simple task of reading the news on a web site requires continuous horizontal scrolling, which affects the experience of using this otherwise very beneficial technology, and may discourage its use, especially by those with poor manual coordination.  We propose to develop a software system that enables hands-free control of a screen magnifier. This system will rely on the user’s eye gaze (measured by a regular IR-based tracker, or from analysis of the images in a camera embedded in the screen) to update the location of the focus of magnification as desired. This research is inspired by preliminary work, which showed promising results with two simple gaze-based control algorithms, tested on three individuals with low vision.  This project will be a collaboration between the Department of Computer Science and Engineering at UC Santa Cruz (PI: Manduchi, Co-I: Prado) and the School of Optometry at UC Berkeley (PI: Chung). Dr. Legge from the Department of Psychology at U. Minnesota will participate as a consultant. Two human subjects studies are planned. In Study 1 with 80 low vision subjects from four different categories of visual impairment, we will investigate the failure rate of a commercial gaze tracker (Aim 1), and will record mouse tracks, gaze tracks, and images from the subjects while performing a number of tasks using two modalities of screen magnification (Aim 2). In Study 2, with the same number of subjects, we will repeat the Study 1 experiment, but using a gaze-based controller trained from the data collected in Study 1, and individually tunable for best performance (Aim 3). In addition, we will experiment with an appearance-based gaze tracker that uses images from the screen camera, thereby removing the need for specialized gaze tracking hardware, as well as with a computer tablet form factor (Aim 4). We expect that reading speed and error rate using our gaze-based controller will be no worse than using mouse-based control. If successful, this study will show that the convenience of hands-free control offered by the proposed system comes at no additional cost in terms of individual performance at the considered tasks. ! ! Project Narrative People with low vision often use screen magnification software to read on a computer screen. Since a magnifier expands the screen content beyond the physical size of the screen (the “viewport”), it is necessary to move the content using the mouse so that the portion of interest falls within the viewport. This project will facilitate use of a screen magnifier by means of a new software system that relies on the user’s own gaze to control scrolling when reading with magnification. !",Gaze-contingent computer screen magnification control for people with low vision,10226365,R01EY030952,"['Affect', 'Age', 'Algorithms', 'Appearance', 'Apple', 'Behavior Control', 'Benchmarking', 'Blindness', 'Categories', 'Collaborations', 'Communication', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Correlation Studies', 'Data', 'Data Set', 'Desktop Video', 'Engineering', 'Ensure', 'Eye', 'Face', 'Failure', 'Funding', 'Glass', 'Goals', 'Hand', 'Image', 'Individual', 'Learning', 'Location', 'Magic', 'Manuals', 'Measures', 'Minnesota', 'Modality', 'Mus', 'Operating System', 'Optometry', 'Performance', 'Peripheral', 'Process', 'Psychological reinforcement', 'Psychology', 'Reader', 'Reading', 'Research', 'Resort', 'Role', 'Schools', 'Science', 'Speech', 'Speed', 'Structure', 'Study Subject', 'System', 'Tablet Computer', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'algorithm development', 'algorithm training', 'base', 'computer science', 'control trial', 'cost', 'data acquisition', 'design', 'experience', 'experimental study', 'falls', 'gaze', 'human subject', 'interest', 'motor control', 'news', 'recurrent neural network', 'sample fixation', 'software systems', 'tool', 'web page', 'web site']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2021,358662
"Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings Project Summary: Darwin Babino, PhD, a trained pharmacologist/electrophysiologist, has spent the last ten years working on several disciplines in the vision sciences. His proposal entitled “Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings” presents his overarching goal to improve vision restoration approaches by developing methods to test the potential of these techniques thereby accelerating the development of effective interventions. Dr. Babino and his primary mentor, Dr. Russell Van Gelder, have assembled a strong team of co-mentors at the University of Washington SOM and collaborators to guide him through the proposed training and research. His previous training will be supplemented with goals to help his development as an independent investigator: 1) Study design and practical learning in performing panretinal (MEA) biological experiments; 2) Fundamental and advanced techniques of the proposed optogenetic and stem-cell restoration techniques; 3) Application of advanced machine learning techniques; 4) Develop leadership and professional skills to establish an independent group. The ability to assess the function of panretinal circuitry will foster our understanding of the advantages and weaknesses of different restoration techniques (Aim 1). The work proposed here will improve an existing retinal acuity assessment tool which combines machine learning techniques on novel, high-density multielectrode array recordings of ganglion cell responses in several mouse models. The utility of this system will be demonstrated in assessing visual potential of the mouse retina in three different approaches to vision restoration that are challenging for in vivo assessment (Aim 2). In collaboration with Dr. Deepak A. Lamba at UCSF, we will apply our system to animals which have undergone stem-cell replacement of retinal cells including photoreceptor cells. An optogenetics approach will also be evaluated in collaboration with Dr. John Flannery at UC Berkeley whose group has developed vectors for expressing rhodopsin and cone opsins in ganglion and bipolar cells. Finally, differences between native and restored vison with small molecule photoswitches, light-activated inhibitors of voltage-gated potassium channels, which confer light-dependent firing on treated cells, will be assessed. The resulting advanced electrophysiology application will help elucidate fundamental questions about the functional retina, mechanisms that lead to retinal degeneration and the potential of several therapeutics for the treatment of retinal diseases. Furthermore, this career development award will facilitate Dr. Babino’s development into an independent investigator by priming an R01 grant application. Project Narrative: Project Narrative: The prevalence of vision loss from retinal degeneration numbers in the millions world-wide and is expected to double by the year 2050, and despite the development of several promising approaches to restore vision in the blind, progress in developing these therapies has been hampered by challenges in analysis of these methods in animal models. We describe a novel system that analyzes, by machine learning, retinal ganglion cell output in native, degenerated and therapeutically treated blind retinas which can characterize the visual information content of the ‘reanimated’ blind retina and thereby facilitate the development of these technologies. The system developed through this grant, as well as the career development pursued by the investigator, will be readily applicable to the assessment of potential retinal acuity restoration by current and novel therapeutic approaches.",Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings,10244896,K99EY031333,"['Aftercare', 'Amacrine Cells', 'Animal Model', 'Animals', 'Applications Grants', 'Assessment tool', 'Behavioral Assay', 'Biological', 'Blindness', 'Cells', 'Collaborations', 'Cone', 'Contrast Sensitivity', 'Data', 'Development', 'Discipline', 'Dissection', 'Doctor of Philosophy', 'Ectopic Expression', 'Electrophysiology (science)', 'Electroretinography', 'Evolution', 'Feedback', 'Fostering', 'Ganglia', 'Genetic', 'Goals', 'Grant', 'Human', 'Image', 'In Vitro', 'Individual', 'Intervention', 'K-Series Research Career Programs', 'Knockout Mice', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Light', 'MW opsin', 'Machine Learning', 'Measurable', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Methods', 'Movement', 'Mus', 'Opsin', 'Output', 'Photoreceptors', 'Prevalence', 'Protocols documentation', 'Psychophysics', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Retinal gene therapy', 'Rhodopsin', 'Rod', 'Rodent', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Specificity', 'Stimulus', 'Synapsins', 'System', 'Systems Analysis', 'Systems Development', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Transgenic Organisms', 'Universities', 'Vertebrate Photoreceptors', 'Viral', 'Vision', 'Visual', 'Visual Acuity', 'Visual system structure', 'Voltage-Gated Potassium Channel', 'Washington', 'Wild Type Mouse', 'Work', 'base', 'behavior test', 'blind', 'career development', 'cell type', 'cost effective', 'density', 'effective intervention', 'experimental study', 'ganglion cell', 'improved', 'in vivo', 'induced pluripotent stem cell', 'inhibitor/antagonist', 'interest', 'light intensity', 'mimicry', 'mouse model', 'multi-electrode arrays', 'mutant', 'nonhuman primate', 'novel', 'novel therapeutic intervention', 'optogenetics', 'promoter', 'rapid eye movement', 'response', 'restoration', 'scale up', 'sight restoration', 'skills', 'small molecule', 'stem cell replacement', 'stem cells', 'technology development', 'therapy development', 'tool', 'vector', 'vision science', 'visual information']",NEI,UNIVERSITY OF WASHINGTON,K99,2021,113080
"Glaucoma Risk Prediction Using Machine Learning Integration of Image-Based Phenotypes and Genetic Associations PROJECT SUMMARY/ ABSTRACT  This proposal describes a 5-year training program to develop an academic career focused on improving glaucoma risk prediction through a combination of genomic and phenotypic risk. I will use supervised, semi- supervised and unsupervised machine learning methods to define novel structural and longitudinal image based endophenotypes for POAG aligned with disease subtype and progression. These endophenotypes will be used to discover new disease associated genomic loci. By including longitudinal data, we aim to identify genetic markers for progressive disease. We will use known POAG risk variants and novel genetic variants identified in these analyses to create several candidate genome wide polygenic risk scores (PRS) for POAG. Each candidate PRS with and without addition of demographic and image features will be tested for its utility to predict glaucoma risk is independent NEIGHBORHOOD and LIFE cohorts. We hypothesize that a PRS based on genetic variants associated with our endophenotypes will have improved POAG case predictive power compared to PRS based on cross-sectional genome wide association studies. The proposed studies have the potential to provide insight into disease pathogenesis and improve predictive power of genetic testing  I am well positioned to conduct this research and undertake the training proposed here. I have a strong quantitative science background with a degree in engineering, statistical training and established track records of large database research. Additionally, I have proposed a detailed career development plan that will allow me to 1) learn the fundamentals, applications and limitations of machine learning based approaches for automated fundus image analysis and 2) understand computational biology and statistical approaches to handle large genomics datasets. My training plan includes an MPH in quantitative methods at the HSPH with concentration in computational biology and statistical learning. Additionally, I am supported by a multidisciplinary team of committed mentors dedicated to my academic growth and progression into an independent clinician scientist. I will work with glaucoma genetics experts, Drs Wiggs and Segre, and leaders in statistical and machine learning, Drs Elze and Kalpathy-Cramer. I will have full access to the extensive resources at MEE, Partners Healthcare and the Harvard system for this work and my career development.  The research outlined here will improve our understanding of glaucoma pathogenesis and lay the foundation for development of multimodal precision medicine approaches for glaucoma screening and diagnosis. This research is cutting edge and prepares me well for my career as an independent NIH funded investigator with the aim to use longitudinal multi-modal clinical, imaging, testing and multi-omics data in multi- ethnic glaucoma patients to 1) understand pathways of vision loss, 2) develop precision medicine approaches to pre-symptomatically identify patients at high risk of functional vision loss and progression and 3) make these technologies a clinical reality in order to reduce the burden of unnecessary blindness. PROJECT NARRATIVE Glaucoma is a progressive, irreversible optic neuropathy with variable presentation and clinical course and we currently lack the ability to pre-symptomatically distinguish patients at risk of severe and progressive disease from those individuals unlikely to develop glaucoma-related vision loss. Using existing data from two large biobanks, this project will use cutting edge machine learning approaches to define POAG phenotypes aligned with disease subtype and progression, use these to discover novel disease related genetic associations, and test their utility for identifying glaucoma cases in independent cohorts. Ultimately, we aim to develop a precision medicine approach using imaging and genetic features to improve our assessment of disease risk for any individual.",Glaucoma Risk Prediction Using Machine Learning Integration of Image-Based Phenotypes and Genetic Associations,10191922,K23EY032634,"['Address', 'Attention', 'Blindness', 'Clinical', 'Computational Biology', 'DNA', 'Data', 'Data Set', 'Databases', 'Demographic Accounting', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Disease Progression', 'Early treatment', 'Engineering', 'Etiology', 'Eye', 'Foundations', 'Funding', 'Fundus', 'Genetic', 'Genetic Markers', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genomics', 'Genotype', 'Glaucoma', 'Goals', 'Growth', 'Healthcare', 'Heritability', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Left', 'Linear Regressions', 'Logistic Regressions', 'Machine Learning', 'Mentors', 'Meta-Analysis', 'Methods', 'Multiomic Data', 'Optic Nerve', 'Optical Coherence Tomography', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Primary Open Angle Glaucoma', 'Progressive Disease', 'ROC Curve', 'Records', 'Research', 'Research Personnel', 'Resources', 'Retina', 'Risk', 'Scanning', 'Science', 'Scientist', 'Series', 'Severity of illness', 'Structure', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Variant', 'Visual Fields', 'Work', 'base', 'biobank', 'career', 'career development', 'case control', 'cohort', 'demographics', 'disorder risk', 'disorder subtype', 'endophenotype', 'functional loss', 'fundus imaging', 'genetic association', 'genetic risk factor', 'genetic testing', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'genomic locus', 'high intraocular pressure', 'high risk', 'imaging genetics', 'improved', 'insight', 'interest', 'learning strategy', 'machine learning method', 'macula', 'multi-ethnic', 'multidisciplinary', 'multimodality', 'nerve damage', 'novel', 'optic nerve disorder', 'polygenic risk score', 'precision medicine', 'predictive modeling', 'predictive test', 'risk prediction', 'risk variant', 'screening', 'serial imaging', 'statistical and machine learning', 'statistical learning', 'unsupervised learning']",NEI,MASSACHUSETTS EYE AND EAR INFIRMARY,K23,2021,263101
"Developing an ultrafast fluorescence lifetime imaging ophthalmoscopy system for retinal imaging PROJECT SUMMARY Age-related macular degeneration (AMD) is an eye disease that affects the central part of the retina and leads to impairments in central vision and sharp vision. According to the report from Centers for Disease Control and Prevention, AMD affects ~0.8% of people in US between 50 and 60, 1.5% between 60 and 70, ~4.8% between 70 and 80, and nearly 12% over 80 years old. Fluorescence lifetime imaging ophthalmoscopy (FLIO) has become an important tool in retinal diagnosis as it provides critical information about retina that the traditional fundus autofluorescence microscopy cannot provide. Whereas more demonstrations of FLIO in retina diagnosis at different stages of AMD have been shown in recent years, FLIO has not reached widespread use in clinics due to a number of fundamental limitations. Here we are developing an ultrafast fluorescence lifetime imaging ophthalmoscopy (uFLIO) system for rapid acquisition of retinal fundus autofluorescence and reconstruction of fluorescence lifetime images around the posterior pole of retina. The acquired autofluorescence lifetime information will help us understand the states of the endogenous fluorophores within the retina, and their roles and changes during the development of retinal diseases. Project Narrative: Age-related macular degeneration (AMD) is an eye disease that affects the central part of the retina and leads to impairments in central vision and sharp vision. Here we are developing an ultrafast fluorescence lifetime imaging ophthalmoscopy system for rapid acquisition of retinal fundus autofluorescence and reconstruction of fluorescence lifetime images around the posterior pole of retina. The acquired autofluorescence lifetime information will help us understand the development of retinal diseases, including AMD.",Developing an ultrafast fluorescence lifetime imaging ophthalmoscopy system for retinal imaging,10288094,R21EY033106,"['Acute', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'American', 'Animal Model', 'Biochemistry', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Computer software', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Eye', 'Eye diseases', 'Fluorescence', 'Frequencies', 'Functional Imaging', 'Fundus', 'Ganglion Cell Layer', 'Generations', 'Glaucoma', 'Goals', 'Gold', 'Hour', 'Hypoxia', 'Image', 'Impairment', 'Joints', 'Lead', 'Lighting', 'Measures', 'Metabolic', 'Methods', 'Microscopy', 'Modeling', 'Motivation', 'Nerve Degeneration', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Photons', 'Photoreceptors', 'Physiologic pulse', 'Process', 'Publications', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Structure', 'System', 'Testing', 'Texas', 'Time', 'Universities', 'Vision', 'austin', 'base', 'biomarker identification', 'curve fitting', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'experience', 'experimental study', 'fluorescence lifetime imaging', 'fluorophore', 'functional loss', 'in vivo', 'instrumentation', 'interest', 'microscopic imaging', 'next generation', 'reconstruction', 'retinal imaging', 'technology development', 'tool']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R21,2021,222228
"HEALing LB3P: Profiling Biomechanical, Biological and Behavioral phenotypes Project Summary Identifying the optimal treatment for chronic low back pain (CLBP), the most prevalent of painful musculoskeletal disorders, on a patient-specific basis is an important and unresolved challenge. Tailoring interventions according to patient movement characteristics may improve clinical outcomes. Multi-modal studies are underway to characterize CLBP patients and to provide insight into the phenotypes associated with the experience of CLBP in relation to direct targeted and improved treatments. Comprehensive assessment of lumbar spine movement CLBP patients may be an important facet of such treatments such that patient-specific spine biomechanics may be included in predictive models to improve the ability to characterize them. To that end, the purpose of this administrative supplement is to explore additional clinical tools for characterizing lumbopelvic kinematics during functional tasks and daily activities. Specifically, this work aims to develop computer vision methods with which to characterize motions of the lumbar spine, thereby providing an accurate and unobtrusive clinical tool that can be used to supplement or replace currently considered tools such as wearable sensors, handheld sensors, and complex marker-based motion capture systems. This project will use video, marker-based 3D video motion capture data, and wearable inertial measurement data to create and validate single-camera computer-vision algorithms that can be used to compute known clinical metrics. During clinical assessments of patients in the Pitt LB3P Biomechanics Core study, participants are asked to perform functional tasks (e.g., repeated flexion/extension, axial rotation, lateral bending, lifting, chair rises) while wearing inertial measurement units (IMUs) attached to the upper back at T1, low back at L1 and L5, and thigh. The functional performance exams are also recorded by video. The standard metrics determined from these trials will include maximum and minimum lumbar spine and hip ROM, angular velocity at mid-excursion, maximum rotation acceleration, and phase angles for lumbar and hip joint rotation. The goal of this supplemental proposal is to use collected data to develop and train computer vision algorithms (so-called markerless motion capture) to quantify the metrics of interest. Use of video is much simpler for clinicians as it avoids the setup process required by wearable sensors. Recent developments in markerless motion capture have enabled simple camera systems to provide quantitative information about human motions but few studies have assessed computer vision for use in the clinical setting. The research plan in this proposal involves the use of existing data to train and validate computer vision algorithms, and then to further investigate their use in the clinical setting with single camera video to determine the extent to which video-based markerless motion capture may be clinically useful in the assessment of CLBP patients. Project Narrative Chronic low back pain (CLBP) is a common musculoskeletal disorder with major public health and socioeconomic impacts. A clinical measure that is used to characterize and ultimately prescribe treatment is the extent to which a patient has difficulty executing physical activities, but making reliable quantified measurements of patient motions can be challenging with conventional tools and even with modern motion capture systems. This research will investigate the degree to which a simple camera may be used in conjunction with machine-learning based computer vision algorithms to provide patient motion during physical activities that can be used in the assessment and treatment of CLBP.","HEALing LB3P: Profiling Biomechanical, Biological and Behavioral phenotypes",10415626,U19AR076725,"['3-Dimensional', 'Acceleration', 'Administrative Supplement', 'Algorithms', 'Back', 'Biological', 'Biomechanics', 'Characteristics', 'Chronic low back pain', 'Clinical', 'Clinical assessments', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'E-learning', 'Goals', 'Hip Joint', 'Hip region structure', 'Human', 'Intervention', 'Lateral', 'Lifting', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modernization', 'Motion', 'Movement', 'Musculoskeletal Diseases', 'Outcome', 'Pain', 'Participant', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Physical activity', 'Process', 'Public Health', 'Research', 'Rotation', 'System', 'Thigh structure', 'Training', 'Vertebral column', 'Work', 'base', 'behavioral phenotyping', 'experience', 'healing', 'improved', 'insight', 'interest', 'kinematics', 'multimodality', 'optimal treatments', 'pain patient', 'predictive modeling', 'sensor', 'socioeconomics', 'tool', 'wearable sensor technology']",NIAMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U19,2021,134064
"Radiomics signatures and patient outcomes in intracerebral hemorrhage PROJECT SUMMARY / ABSTRACT The following K23 proposal is for Dr. Sam Payabvash, a Neuroradiologist and Assistant Professor of Radiology at Yale University. Dr. Payabvash is a physician-scientist with specialized expertise at the intersection of neuroscience, neuroimaging, and computer vision. His career goal is to find new treatment targets and to provide personalized care for patients with cerebrovascular disease. Intracerebral hemorrhage (ICH) is one of the most devastating cerebrovascular diseases with no effective treatment. To date, imaging markers of ICH risk- stratification and outcome prediction have been subjective and descriptive in nature, leaving a large gap for automated assessment of imaging feautres embedded in medical images. Preliminary results by Dr. Payabvash have demonstrated the feasibility of a research plan to apply automated feature extraction pipelines and machine learning algorithms to harness the information in medical images for early risk-stratification and identification of potential treatment targets in ICH. In this proposal, Dr. Payabvash will use detailed clinical and imaging data of 3,991 patients from NIH-funded clinical trials, online archives, and institutional registries at Yale, Tufts, and University College of London. He will apply machine-learning algorithms to identify those imaging features of brain hemorrhage on baseline head CT scan that are related to symptom severity at presentation (aim 1). Then, he will use imaging features of hemorrhage to identify those patients who are at risk for early expansion of hematoma (aim 2a), or surrounding edema (aim 2b). These two “modifiable” indicators of poor outcome are considered potential treatment targets in ICH patients. Finally, he will combine admission clinical information and imaging features to build a risk-stratification tool for long-term outcome prediction (aim 3). Under the expert mentorship of Dr. Kevin Sheth (Chief of Neurocritical Care), Dr. Todd Constable (Director of MRI Research), and Dr. Ronald Coifman (Professor of Mathematics), this K23 award will allow Dr. Payabvash to (1) identify and address the most pressing issues in cerebrovascular disease with innovative neurogaming tools; (2) gain expertise in advanced statistical analysis of brain scans; and (3) expand his knowledge in machine learning and computer vision for assessment of medical images. Dr. Payabvash will receive didactic training in neuroimaging statistical analysis, machine learning, deep neural networks, and computer vision. The proposed research and career development plans draw on the wealth of resources available at Yale, including a Regional Coordinating Center for the NIH StrokeNet, the Center for Research Computing; High Performance Computing services, and cutting-edge image processing and analysis infrastructure. At the conclusion of this award period, Dr. Payabvash will be well-positioned to become an independently-funded investigator conducting high-quality research in advanced neuroimaging techniques and analysis aimed at improving the care of patients with cerebrovascular disease. PROJECT NARRATIVE Intracerebral hemorrhage (ICH) is a severely debilitating cerebrovascular disease, which affects over 70,000 patients per year in the U.S., and is responsible for over half of stroke-related disability worldwide. So far, the diagnosis, surveillance, and prediction of outcome in intracerebral hemorrhage have mainly relied on visual and subjective assessment of head CT scans. Computerized assessment of medical images and machine learning algorithms can extract hidden features from CT scans and provide innovative tools for accurate outcome prediction and personalized treatment decisions in patients with hemorrhagic stroke.",Radiomics signatures and patient outcomes in intracerebral hemorrhage,10301527,K23NS118056,"['Address', 'Admission activity', 'Affect', 'Age', 'Atlases', 'Award', 'Biologic Characteristic', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Brain scan', 'Caring', 'Cellularity', 'Cerebral hemisphere hemorrhage', 'Cerebrovascular Disorders', 'Cerebrum', 'Characteristics', 'Clinical', 'Clinical Trials', 'Computer Vision Systems', 'Data', 'Deterioration', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Edema', 'Funding', 'Future', 'Genomics', 'Goals', 'Grant', 'Growth', 'Head', 'Healthcare', 'Hematoma', 'Hemoglobin', 'Hemorrhage', 'Heterogeneity', 'High Performance Computing', 'Hour', 'Human', 'Image', 'Image Analysis', 'Inflammatory', 'Infrastructure', 'Knowledge', 'Lead', 'Lesion', 'Linear Models', 'Location', 'London', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Mentored Patient-Oriented Research Career Development Award', 'Mentorship', 'Modeling', 'Nature', 'Necrosis', 'Neurologic', 'Neurologic Deficit', 'Neurologic Symptoms', 'Neurosciences', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Prognostic Factor', 'Proteomics', 'Radiology Specialty', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rogaine', 'Scientist', 'Services', 'Severities', 'Shapes', 'Signal Transduction', 'Statistical Data Interpretation', 'Stroke', 'Symptoms', 'Techniques', 'Texture', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Writing', 'X-Ray Computed Tomography', 'automated analysis', 'base', 'bioimaging', 'blood-brain barrier disruption', 'career', 'career development', 'clinical risk', 'college', 'computerized', 'cytotoxic', 'data archive', 'deep neural network', 'density', 'disability', 'effective therapy', 'evidence base', 'feature extraction', 'feature selection', 'follow-up', 'functional independence', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'machine learning algorithm', 'metabolomics', 'modifiable risk', 'neuroimaging', 'neuroimaging marker', 'new therapeutic target', 'novel', 'online repository', 'outcome prediction', 'personalized care', 'personalized medicine', 'precision medicine', 'professor', 'prognostic', 'quantitative imaging', 'radiomics', 'research and development', 'risk stratification', 'skills', 'statistics', 'tool', 'treatment optimization']",NINDS,YALE UNIVERSITY,K23,2021,194939
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10247759,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'dietary', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2021,303091
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,10150027,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2021,695400
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists is time intensive, requires intensive training, and prone to introduce bias and error. Optical analysis of targets within tissue samples, cultures, or specimens is fundamental to detecting biological properties, including protein interaction within the central nervous system, sperm counts, digestive-system parasites, and immune response to viral infections like COVID-19. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce errors to clinical diagnostics. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting public confidence in scientific inquiry. Application of computer vision for cellular target detection is a promising approach to reducing human bias, subjectivity, and errors that limit the reproducibility of research and slow the development of effective medical treatments. Our image analysis software, called Pipsqueak AITM, and the underlying artificial intelligence (AI) technology developed during our NIH SBIR Phase I award, have significantly increased inter- and intra-rater reliability of tissue sample analysis and decreased analysis time for multiplexed biomarkers. Pipsqueak AI is available now as an integration to ImageJ/FIJI (https://Pipsqueak.ai), and is capable of returning hundreds of accurate cellular target detections to the user within 300ms of image upload. During the last 6 months, Pipsqueak usership has exploded to over 1000 active monthly users, indicating high demand for computer vision technologies that improve the speed and accuracy of micrograph quantification. Our pre-trained ML models are capable of detecting multiple cellular morphologies and target types with precision and reproducibility that greatly exceed human analysis. Here, we propose to develop a pre-trained biomedical image analysis platform that rapidly and accurately identifies diverse cellular targets, and make this technology commercially available as a cloud computer vision service, called Sightologist.aiTM. Our computer vision AI-as-a-service (AIaaS) will be made available to research and clinical end-users through our Pipsqueak AI software and through 3rd party product integrations. To achieve these goals, we will build on our SBIR Phase I progress that developed ML models for biomarker detection, and implement cloud distribution methods to deliver our computer vision service to remote users and applications. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments, including determining sperm counts, detecting diseases, and testing for immune response to viral infections like COVID- 19. Application of artificial intelligence for cellular target detection is a promising approach to reduce human bias, subjectivity, and errors that limit the reproducibility of research and slow the development of effective medical treatments. We propose a novel method to improve biomedical research reproducibility and clinical diagnostic quality by developing a cloud-based, artificial intelligence service, called Sightologist.aiTM that delivers computer vision for biomedical images to remote research and clinical users through Pipsqueak AITM software and 3rd party hardware and software integrations.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,10259501,R44GM134789,"['3-Dimensional', 'Architecture', 'Artificial Intelligence', 'Attention', 'Award', 'Biological', 'Biological Assay', 'Biological Markers', 'Biomedical Research', 'Brain', 'COVID-19', 'Cell Culture Techniques', 'Cellular Morphology', 'Clinical', 'Cloud Computing', 'Complement', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Detection', 'Development', 'Devices', 'Disease', 'Evidence Based Medicine', 'Genetic Research', 'Goals', 'Health', 'Home', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Immunologic Tests', 'Legal patent', 'Licensing', 'Location', 'Machine Learning', 'Maintenance', 'Manuals', 'Medical', 'Methods', 'Microscope', 'Microscopic', 'Microscopy', 'Modeling', 'Neuraxis', 'Neurosciences', 'Optics', 'Organism', 'Parasites', 'Pathologist', 'Performance', 'Phase', 'Process', 'Progress Reports', 'Property', 'Proteins', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sales', 'Sampling', 'Scientific Inquiry', 'Services', 'Small Business Innovation Research Grant', 'Specimen', 'Speed', 'Sperm Count Procedure', 'Standardization', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Update', 'Virus Diseases', 'application programming interface', 'automated analysis', 'bioimaging', 'cell dimension', 'cellular targeting', 'clinical diagnostics', 'cloud based', 'commercialization', 'convolutional neural network', 'detection method', 'gastrointestinal system', 'human error', 'image processing', 'improved', 'novel', 'prototype', 'software as a service', 'sperm cell', 'tool', 'two-dimensional', 'web app', 'web site']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R44,2021,948520
