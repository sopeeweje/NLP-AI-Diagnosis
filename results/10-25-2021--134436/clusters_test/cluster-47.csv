text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,10169447,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'cell type', 'cortical visual impairment', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'mouse genetics', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutic intervention', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2021,384357
"The Functions and Mechanisms of Perceptual Learning Project Summary/Abstract: Research in perceptual learning has demonstrated a remarkable ability of training or practice to enhance perception in the adult human. The last thirty years have yielded many important findings about how people learn, what limits transfer, how generalization can be improved, how to model learning, and the nature of visual plasticity. At the same time, learning and transfer have been measured at a relatively coarse scale that leads to relatively inaccurate measures of learning in individuals, which could be very important to choosing adapted training options. Related issues of estimation have also limited the types of training protocols that have been studied. The objective of this research is to use innovative new adaptive performance assessment (based on Bayesian principles) to provide unbiased and high precision estimates of learning in individuals. We also use computational neural network models to generate predictions about more complicated training regimens that are then tested experimentally. We develop a framework for searching among these predictions computationally to identify better (optimized) training methods. The long-term goal is to develop efficient new assessments of learning and transfer and the modeling techniques that may then be applied to improve clinical applications, rehabilitation, and perceptual expertise identified as key aspects of the NEI mission. Project Narrative: Perceptual learning through training visual tasks can contribute to enhancing visual skills and may prove useful in remediation of some visual limitations. The current project seeks to understand perceptual learning and generalization using new rapid assessment methods, advanced statistical methods, and computational models of learning. The proposed program of model and test development and empirical testing will help to define a framework for more reliably measuring learning in individuals and predicting the efficacy of training regimens in normal adults, that could be the basis of parallel applications in rehabilitative or developmental training.",The Functions and Mechanisms of Perceptual Learning,10244942,R01EY017491,"['Adult', 'Bayesian Method', 'Bayesian Modeling', 'Behavior', 'Clinical Protocols', 'Computer Models', 'Data', 'Development', 'Goals', 'Grain', 'Individual', 'Individual Differences', 'Investigation', 'Learning', 'Literature', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Nature', 'Neural Network Simulation', 'Perception', 'Perceptual learning', 'Performance', 'Play', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Research', 'Research Design', 'Rewards', 'Specificity', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'Visual', 'artificial neural network', 'base', 'clinical application', 'cognitive training', 'improved', 'innovation', 'model development', 'new technology', 'programs', 'relative effectiveness', 'remediation', 'skills', 'synergism', 'theories', 'visual plasticity']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2021,360275
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,10249061,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2021,437424
"Shared and specific mechanisms of auditory and visual category learning PROJECT SUMMARY/ABSTRACT The ability to learn new perceptual categories enables some of the most complex human behaviors, from speech perception to visual object recognition. Current understanding of the mechanisms involved in perceptual category learning relies on the fundamental assumption that the processes underlying such learning are shared across the senses. However, the vast majority of this work has focused on the visual modality. As a consequence, the research regarding how humans learn to group complex auditory information into categories has relied greatly on conclusions from the research in the visual domain without testing this critical assumption. However, recent evidence from the attention literature suggests that even seemingly domain-general cognitive processes, such as working memory, are accomplished via sensory-biased regions in frontal cortex. The current investigation will directly compare the computational and neural mechanisms supporting auditory and visual category learning by training the same individuals on categories in both modalities while in an fMRI scanner. Aim #1 of this investigation will identify the shared and sensory-biased circuits supporting feedback processing during auditory and visual category learning. If the neural circuits supporting perceptual category learning are shared across the modalities, it is expected that similar regions will be recruited to a similar extent during feedback processing. If instead, the neural circuits are distinct for particular modalities, it is expected that sensory-biased regions will emerge as supporting category learning for auditory and visual modalities. Aim #2 will utilize advanced machine learning techniques (multivariate pattern classification and representational similarity analyses) to characterize the emergence of category-level neural representations over the course of learning. Aim #3 will identify the functional and structural connectivity of the circuits as they contribute to perceptual category learning. The proposed research will directly test the fundamental assumption about the nature of this complex problem that affects everyday behaviors. This research has the potential to impact understanding of cases where modality- specific learning abilities might be impaired, such as phonetic learning and language-related impairments in dyslexia, autism, and specific language impairment. The proposed research will provide the training foundation to support the PI’s long-term objective of developing theories of perceptual category learning that are constrained by neurobiology and behavior and will specify the behavioral, computational, and neural mechanisms of such learning. This project presents the opportunity to directly test a critical assumption underlying understanding of perceptual category learning. The proposed research will take place in an exceptional training environment and the PI will be mentored by a team of knowledgeable and accomplished scientists. The research will provide the PI with training in functional magnetic resonance experiment design and analysis which will prepare her well for a career as an independent scientist in computational cognitive neuroscience. PROJECT NARRATIVE The proposed research will contribute to fundamental knowledge about how seemingly general-purpose cognitive systems may demonstrate modality specificity. The goal of this investigation is to characterize the differences in cognitive processing during category learning when the information comes from the auditory or visual modalities. The findings from this work may inform mechanistic approaches to understanding modality- specific deficits in language-based disorders, such as dyslexia, autism, and specific language impairment.",Shared and specific mechanisms of auditory and visual category learning,10197776,F32DC018979,"['Affect', 'Area', 'Attention', 'Auditory', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Corpus striatum structure', 'Disease', 'Dyslexia', 'Environment', 'Esters', 'Feedback', 'Finches', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hobbies', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Mentors', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Participant', 'Pattern', 'Process', 'Property', 'Research', 'Scientist', 'Sensory', 'Short-Term Memory', 'Specific qualifier value', 'Specificity', 'Speech', 'Speech Perception', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Work', 'auditory stimulus', 'autism spectrum disorder', 'base', 'behavior measurement', 'career', 'cognitive neuroscience', 'cognitive process', 'cognitive system', 'design', 'experimental study', 'frontal lobe', 'individual variation', 'innovation', 'learning ability', 'neural circuit', 'neuromechanism', 'object recognition', 'programs', 'recruit', 'relating to nervous system', 'response', 'sound', 'specific language impairment', 'theories', 'visual learning']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2021,65994
"Function and circuitry of adaptive inhibition in the retina Studies of the visual system face a number of challenges, two of which are the intricacy of the cell types and synaptic connections that comprise the nervous system, and the complexity of the computational processes that underlie vision. Although the retina is one of the most characterized and well understood neural circuits of the visual system, it nonetheless has a great diversity of cell types, connections and computations. The normal function of the retina is to convey information about natural visual scenes, which have complex spatial and temporal structure. The processing of natural scenes has the greatest relevance towards a fundamental understanding retinal function, and the greatest clinical relevance. Yet most studies of retinal visual processing and circuitry focus on responses to simple artificial stimuli rarely encountered normally, such as flashing spots, drifting stripes and flickering checkerboards. With respect to retinal cell types greatest diversity lies in a class of inhibitory interneurons known as amacrine cells. These cells make extensive lateral and feedback connections, and although they form stereotyped connections between each other, excitatory bipolar cells, and ganglion cells that transit signals in the optic nerve, the functional effects of nearly all of these cell types are poorly understood. This proposal aims towards a direct characterization of the functional effects of amacrine cells under ethologically relevant stimuli, including natural scenes. We combine approaches of perturbation and recording using electrical and optical methods as well as computational modeling to characterize the specific contributions of amacrine cells to stimuli that include the representation of moving objects. We take advantage of recently developed computational approaches that can simultaneously capture the retinal response to a broad range of stimuli including natural scenes, capture a wide range of phenomena previously characterized only with artificial stimuli, and that have internal units highly correlated with retinal interneurons. Our goals are to 1) Create a quantitative understanding of the functional contributions of a class of sustained amacrine cells in the salamander retina for specific stimuli including those that represent moving objects and natural scenes, and test hypotheses related to dynamic effects on visual sensitivity and sensory features generated by those amacrine cells 2) Use molecularly defined amacrine cells in the mouse to quantitatively characterize the functional contribution of specific amacrine cell types to specific stimuli including artificial moving objects and natural scenes. These studies create a new way to generate and test hypotheses related to the quantitative effect of any interneuron on retinal output under any visual stimulus. Understanding how retinal circuitry creates visual processing under natural scenes is critical to our understanding of retinal mechanisms and diseases involving the degeneration of the retinal circuitry. In addition, the computational descriptions of retinal responses will be directly useful in the design of electronic retinal prosthesis systems. The retina is a complex network of many cell types, including the most diverse but poorlyunderstood class of cells, amacrine cells. By understanding how inhibitory neurons change neural processing in the retina under natural visual scenes, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by creating accurate computational models of the retinal response to natural scenes, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Function and circuitry of adaptive inhibition in the retina,10086475,R01EY022933,"['Address', 'Amacrine Cells', 'Archives', 'Cells', 'Complex', 'Computer Models', 'Data', 'Disease', 'Electrophysiology (science)', 'Face', 'Feedback', 'Future', 'Goals', 'Injections', 'Interneurons', 'Lateral', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Nervous system structure', 'Neural Network Simulation', 'Neurons', 'Optic Nerve', 'Optical Methods', 'Output', 'Pathway interactions', 'Periodicity', 'Population', 'Process', 'Property', 'Research', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Salamander', 'Sensory', 'Signal Transduction', 'Spottings', 'Stereotyping', 'Stimulus', 'Structure', 'Synapses', 'System', 'Techniques', 'Testing', 'Theoretical Studies', 'Time', 'Vision', 'Visual', 'Visual system structure', 'biological systems', 'cell type', 'clinically relevant', 'computerized tools', 'computing resources', 'connectome', 'convolutional neural network', 'design', 'experimental study', 'extracellular', 'ganglion cell', 'inhibitory neuron', 'interest', 'neural circuit', 'novel strategies', 'photoreceptor degeneration', 'predicting response', 'receptive field', 'relating to nervous system', 'response', 'retinal prosthesis', 'sight restoration', 'therapy design', 'tool', 'visual processing', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2021,380427
"Neural coding of interneuron populations in the retina Abstract The vertebrate retina translates visual images into electrical signals in the optic nerve, initiating the basis of all visual perception. This process is accomplished by dozens of diverse types of interneurons, each of which comprises a population of many thousands of cells. Each of these populations cover the visual field, acting together to process different aspects of visual images. Although many informative studies of retinal neural function have used single cell recordings, understanding the coordinated actions of many cells requires the recording and analysis of cell populations. This proposal focuses on amacrine cells, a diverse population of inhibitory interneurons. In particular we study wide-field amacrine cells, a prominent class of cells that make long distance connections across the retina, acting to combine visual signals from distant locations in the image. We have little information assigning computations to specific cells of this type. Using genetically identified populations of wide-field amacrine cells in the mouse retina, we will record neural activity from these populations optically, along with simultaneously recording electrically from populations of retinal ganglion cells. Neural responses to complex stimuli including natural scenes will be interpreted using advanced computational models. The primary goals of these studies are to 1) perform the first population scale measurements of sparse wide-field amacrine cells, in particular to measure how their selectivity for visual features varies dynamically during natural scenes, 2) Analyze the neural code of these cells under natural scenes using state-of-the-art computational models that can capture retinal responses to arbitrarily complex stimuli, 3) Test the hypothesis that sparse wide-field amacrine cells perform similar computations on different channels of information, acting to remove correlations from the ganglion cell population during natural scenes. These results will have immediate applicability to the emerging field of retinal prostheses, as is used to treat prevalent diseases such as age-related macular degeneration and retinitis pigmentosa by replacing the function of the damaged retina with a high resolution electronic circuit. Measurements of the retinal neural code and the computations that are performed will be directly useful for incorporation into retinal prosthesis systems. Program Director/Principal Investigator (Last, First, Middle): Baccus, Stephen A. The retina is a complex network of many cell types, including the most diverse but poorly understood class of cells, inhibitory neurons. By understanding how inhibitory neurons represent visual information, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by capturing the responses of these neurons under natural visual stimuli with accurate computational models, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Neural coding of interneuron populations in the retina,10225643,R01EY025087,"['Address', 'Age related macular degeneration', 'Amacrine Cells', 'Anatomy', 'Cells', 'Code', 'Complex', 'Computer Models', 'Disease', 'Distant', 'Eye Movements', 'Goals', 'Image', 'Inner Plexiform Layer', 'Interneurons', 'Location', 'Measurement', 'Measures', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Neural Network Simulation', 'Neural Retina', 'Neurons', 'Neurophysiology - biologic function', 'Optic Nerve', 'Optics', 'Pharmacogenetics', 'Photoreceptors', 'Population', 'Population Heterogeneity', 'Principal Investigator', 'Process', 'Research', 'Resolution', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Retinitis Pigmentosa', 'Saccades', 'Signal Transduction', 'Stimulus', 'System', 'Testing', 'Translating', 'Vision', 'Visual', 'Visual Fields', 'Visual Perception', 'calcium indicator', 'cell type', 'comparative', 'convolutional neural network', 'ganglion cell', 'individual response', 'inhibitory neuron', 'object motion', 'optical imaging', 'photoreceptor degeneration', 'presynaptic', 'programs', 'relating to nervous system', 'response', 'retinal damage', 'retinal prosthesis', 'sample fixation', 'sight restoration', 'therapy design', 'visual information', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2021,375954
"Neural dynamics underlying spatiotemporal cognitive integration Project Summary  Our ability to visually interpret the world around us depends on bottom-up computations that extract relevant information from the sensory inputs but it also depends on our accumulated core knowledge about the world providing top-down signals based on prior experience. The goal of this proposal is to study the mechanisms by which visual information is integrated spatially and temporally to combine bottom-up and top- down knowledge. Towards this goal, we combine behavioral measurements, invasive neurophysiological recordings, and computational models. The behavioral data will provide critical constraints about human integrative abilities, particularly through eye movements and the dynamics of recognition. The invasive neurophysiological data will provide high spatiotemporal resolution of neural activity along the inferior temporal cortex and the interactions with pre-frontal cortex, which is hypothesized to be critical for conveying the type of top-down signals required for recognition. Ultimately, a central goal of our proposal is to formalize our understanding of these integrative process via a quantitative computational model. This computational model should be able to capture the behavioral and physiological results and provide testable predictions. During the current award, we have made significant progress towards elucidating the mechanisms underlying pattern completion whereby the visual system is capable of inferring the identity of objects from partial information. Here we consider a set of images and videos that are “minimal” in the sense that they are recognizable but where any further reduction in the amount of spatial or temporal information renders them unrecognizable. We have strong preliminary evidence that suggests that state-of-the-art purely bottom-up theories of recognition instantiated by deep convolutional networks cannot explain human behavior and physiology. Therefore, these types of stimuli provide an ideal arena to investigate how top-down signals, presumably from pre-frontal cortex, modulate the responses along ventral visual cortex to orchestrate recognition. Understanding the neural mechanisms by which core knowledge is incorporated into sensory processing is arguably one of the greatest challenges in Cognitive Science and may have important implications for many neurological and psychiatric conditions that are characterized by dysfunctional top-down signaling and remain poorly understood. Project narrative  Interpreting the world around us requires putting together current sensory experiences and our prior experience. It has been known for a long time that such prior core knowledge of the world plays a critical role in our perceptions. Yet, the mechanisms by which such experiences are merged with sensory stimuli remain poorly understood and elusive. Here we combine behavioral measurements, direct recordings of neural data from inside the human brain, and computational models to investigate the neural circuits that combine the senses and prior experiences. There are multiple neurological and psychiatric conditions that are characterized by abnormal top-down signaling, conditions that remain poorly understood and where successful treatment will necessitate deep understanding of their mechanistic basis. The current proposal combines state-of-the-art technologies, methods and models to tackle these questions and begin to shed light on one of the most challenging mysteries of the mind, the interplay between the senses and high-level cognition.",Neural dynamics underlying spatiotemporal cognitive integration,10248436,R01EY026025,"['Architecture', 'Automobile Driving', 'Award', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Bicycling', 'Brain', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Complex', 'Computer Models', 'Cues', 'Data', 'Data Set', 'Epilepsy', 'Eye Movements', 'Goals', 'Human', 'Image', 'Inferior', 'Investigation', 'Knowledge', 'Label', 'Left', 'Light', 'Link', 'Location', 'Measurement', 'Methods', 'Mind', 'Modeling', 'Monitor', 'Neurologic', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Perception', 'Physiological', 'Physiology', 'Play', 'Prefrontal Cortex', 'Process', 'Psychophysics', 'Resolution', 'Role', 'Route', 'Sensory', 'Signal Transduction', 'Source', 'Stimulus', 'Stream', 'Technology', 'Temporal Lobe', 'Testing', 'Time', 'Validation', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'base', 'behavior measurement', 'convolutional neural network', 'experience', 'experimental study', 'millisecond', 'network architecture', 'neural circuit', 'neuromechanism', 'neurophysiology', 'object recognition', 'relating to nervous system', 'response', 'sensory input', 'sensory stimulus', 'spatial integration', 'spatiotemporal', 'theories', 'visual cognition', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R01,2021,429225
"Guiding Attention in Real-World Scenes Project Summary Real-world scenes contain far more information than we can perceive at any given moment. Scene perception therefore requires attentional selection of relevant scene regions for prioritized processing. How are those aspects of the world that should receive priority selected? Although much past research has focused on how attention is guided by the visual properties of a scene, new evidence from meaning maps, developed in the previous funding period, established that the distribution of meaning across a scene plays a central and often dominant role in guiding attention. This surprising finding raises many important new questions about the nature of scene meaning and its specific role in attentional guidance. The overarching goal of this project is to understand in detail how the semantic features of a scene’s objects and functional spaces influence the guidance of visual attention in complex real-world scenes. The specific aims are: (1) To determine the role of object semantics in attentional guidance in scenes; (2) To determine the role of functional spaces in attentional guidance in scenes; (3) To determine how viewing task interacts with scene semantics in guiding attention. The project is innovative in expanding the traditional study of attention to explicitly consider the role of meaning. To this end, new semantic maps capitalizing on the meaning map concept will be used capture local region meaning continuously over a scene, allowing for direct investigation of the relationships of different types of meaning with attention. The project is innovative in (1) expanding the traditional study of visual attention to explicitly consider the role of semantics; (2) focusing on the semantics of both scene content (objects) and scene structure (space); (3) considering the role of meaning in attentional guidance in the context of viewing task; (4) integrating the use of a wide variety of cognitive science methods marshalled in the service of understanding the influence of meaning on visual attention in real-world scenes, including eyetracking, large-scale crowd-sourcing, computational image processing, computational semantic modeling, and deep convolutional neural networks. The project is significant in challenging current models of visual attention to account for the role of scene meaning. Because the proposed studies test competing models, the results will lead to the development of integrative theoretical frameworks that advance the field regardless of the outcome. While focused on basic science, the studies have potentially important translational implications by providing a more complete characterization of the processes associated with visual attention. The proposed studies may ultimately lead to the development of rehabilitation strategies for visual attention as it operates in the real world, better capitalizing on the use of a viewer’s knowledge to offset disrupted functions in those with attention and vision deficits. Project Narrative The visual world presents us with far more information than we can process at any given moment. How does the brain select those aspects of the world that should receive priority for visual analysis? This project investigates how we select and attend to meaningful information the natural environment given what we are currently trying to accomplish. The studies combine high-resolution eyetracking with models of meaning based on crowd-sourced human ratings, computer vision models of image processing, deep learning models of scene recognition and attention, and hybrid artificial intelligence models of complex concepts. The role of meaning in guiding attention is contrasted with the role of pre-semantic image features. The knowledge gained will increase our theoretical understanding of how visual attention and perception operate in complex meaningful scenes, assist in the identification of individuals with deficits in visual attention, and may ultimately lead to the development of targeted rehabilitation strategies for the real world.",Guiding Attention in Real-World Scenes,10250349,R01EY027792,"['Address', 'Artificial Intelligence', 'Attention', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognition', 'Cognitive Science', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Environment', 'Esthetics', 'Evaluation', 'Funding', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Individual', 'Investigation', 'Judgment', 'Knowledge', 'Lead', 'Maps', 'Marshal', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurologic', 'Outcome', 'Perception', 'Play', 'Population', 'Process', 'Property', 'Quality of life', 'Research', 'Resolution', 'Role', 'Semantics', 'Services', 'Spatial Distribution', 'Structure', 'Testing', 'Ursidae Family', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'base', 'behavior test', 'concept mapping', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'digital imaging', 'experimental study', 'grasp', 'image processing', 'imaging properties', 'innovation', 'insight', 'model development', 'rehabilitation strategy', 'visual information', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2021,369421
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10172909,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Regenerative capacity', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2021,741958
"Virtual prototyping for retinal prosthesis patients Project Summary/Abstract Retinal dystrophies such as retinitis pigmentosa and macular degeneration induce progressive loss of photoreceptors, resulting in profound visual impairment in more than ten million people worldwide. Visual neuroprostheses (‘bionic eyes’) aim to restore functional vision by electrically stimulating remaining cells in the retina, analogous to cochlear implants. A wide variety of neuroprostheses are either in development (e.g. optogenetics, cortical) or are being implanted in patients (e.g. subretinal or epiretinal electrical). A limiting factor that affects all device types are perceptual distortions and subsequent loss of information, caused by interactions between the implant technology and the underlying neurophysiology. Understanding the causes of these distortions and finding ways to alleviate them is critically important to the success of current and future sight restoration technologies. In this proposal, human visual psychophysics, computational modeling, data-driven approaches, and virtual reality (VR) will be combined to develop and experimentally validate optimized stimulation protocols for epiretinal prostheses. This approach is analogous to virtual prototyping for airplanes and other complex systems: to use a high-quality model of both the implant electronics and the visual system in order to generate a ‘virtual patient’. Retinal electrophysiological and visual behavioral data will be used to develop and validate a computational model of the expected visual experience of patients when electrically stimulated. One way of using this model will be to generate simulations of the expected perceptual outcome of electrical stimulation across a wide variety of electrical stimulation patterns. These will be used as a training set for machine learning algorithms that will invert the input-output function of the model to find the electrical stimulation protocol that best replicates any desired perceptual experience. The model can also be used to simulate the expected perceptual experience of real patients by using sighted subjects in a VR environment – ‘VR virtual patients’. These virtual patients will be used to discover preprocessing methods (e.g., edge enhancement, retargeting, decluttering) that improve behavioral performance in VR. Although current retinal prostheses have been implanted in over 250 patients worldwide, experimentation with improved stimulation protocols remains challenging and expensive. Implementing ‘virtual patients’ in VR offers an affordable and practical alternative for high-throughput experiments to test new stimulation protocols. Stimulation protocols that result in good VR performance will be experimentally validated in real prosthesis patients in collaboration with Second Sight Medical Products Inc. and Pixium Vision, two leading device manufacturers in the field. This work has the potential to significantly improve the effectiveness of visual neuroprostheses as a treatment option for individuals suffering from blinding retinal diseases. Project Narrative Inadequate stimulation paradigms are currently one of the main factors limiting the effectiveness of visual prostheses as a treatment option for individuals suffering from blinding retinal diseases. My goal is to develop and validate novel stimulation protocols for visual prosthesis patients that minimize perceptual distortions and thereby improve behavioral performance. Developing methods for generating better stimulation protocols through a combination of behavioral testing, virtual reality, computational modeling, and machine learning, has the potential to provide a transformative improvement of this device technology.",Virtual prototyping for retinal prosthesis patients,10248573,R00EY029329,"['Affect', 'Behavioral', 'Bionics', 'Cells', 'Clinical Trials', 'Cochlear Implants', 'Collaborations', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Data', 'Development', 'Devices', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Electronics', 'Electrophysiology (science)', 'Eye', 'Eye Movements', 'Family', 'Financial compensation', 'Future', 'Goals', 'Head', 'Human', 'Implant', 'In Vitro', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Machine Learning', 'Macular degeneration', 'Manufacturer Name', 'Medical', 'Medicare', 'Methods', 'Modeling', 'Motion', 'Neurons', 'Ocular Prosthesis', 'Online Systems', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perceptual distortions', 'Performance', 'Photoreceptors', 'Prosthesis', 'Prosthesis Design', 'Protocols documentation', 'Psychophysics', 'Rehabilitation therapy', 'Reporting', 'Retina', 'Retinal Diseases', 'Retinal Dystrophy', 'Retinitis Pigmentosa', 'Schedule', 'Severities', 'Shapes', 'Specialist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Visualization', 'Work', 'base', 'behavior measurement', 'behavior test', 'deep neural network', 'design', 'experience', 'experimental study', 'gaze', 'implantation', 'improved', 'machine learning algorithm', 'neurophysiology', 'neuroprosthesis', 'novel', 'object recognition', 'optogenetics', 'predictive modeling', 'prototype', 'regression algorithm', 'retinal prosthesis', 'sight restoration', 'simulation', 'spatiotemporal', 'success', 'virtual', 'virtual patient', 'virtual reality', 'virtual reality environment']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R00,2021,236458
"Intelligent Intensive Care Unit (I2CU): Pervasive Sensing and Artificial Intelligence for Augmented Clinical Decision-making Project Summary Although close monitoring and dynamic assessment of patient acuity are key aspects of ICU care, both are limited by the time constraints imposed on healthcare providers. Currently, dynamic and precise assessment of patient’s acuity in ICU rely almost exclusively on physicians’ clinical judgment and vigilance. Furthermore, important visual assessment details, such as facial expressions, posture, and mobility, are captured sporadically by overburdened nurses or are not captured at all. However, these visual assessment details are associated with critical indices such as physical function, pain and subsequent clinical deterioration. The PIs’ long-term goal is to sense, quantify, and communicate patient’s clinical condition in an autonomous and precise manner. The overall objective of this application is to develop the novel tools for sensing, quantifying, and communicating any patient’s condition in an autonomous, precise, and interpretable manner. The central hypothesis is that deep learning models will be superior to existing acuity clinical scores by predicting acuity in a dynamic, precise, and interpretable manner, using autonomous assessment of pain, emotional distress and physical function, together with clinical and physiologic data. The hypothesis has been formulated based on preliminary data and is well-grounded in clinical care literature. The rationale is that autonomous and precise patient quantification can result in enhanced clinical workflow and early intervention. The overall objective will be achieved by pursuing three specific aims. (1) Developing and validating an interpretable deep learning algorithm for precise and dynamic prediction of the patient’s clinical status to determine if it is more accurate in predicting daily care transition outcomes, while providing interpretable information to the physician. (2) Developing a pervasive sensing system for autonomous visual assessment of critically ill patients to determine if it can provide accurate visual assessment of a patient compared to human expert, and if it can enrich acuity prediction when combined with clinical data. (3) Implementing and evaluating an intelligent platform for real- time integration of autonomous visual assessment and acuity prediction in clinical workflow to determine accuracy in real-time prospective evaluation and to determine physicians’ risk perception and satisfaction. The approach is innovative, because it represents the first attempt to (1) dynamically predict precise patient trajectory, (2) autonomously perform visual assessment in the ICU, and (3) implement artificial intelligence platform in real time in clinical workflow. The proposed research is significant since it will address several key problems and critical barriers in critical care, including (1) lack of precise and real-time prediction of clinical trajectory, (2) manual repetitive ICU assessments, and (3) uncaptured patient aspects. Ultimately, the results are expected to improve patient outcomes and decrease hospitalization costs, as well as lifelong complications. Project Narrative The proposed research is relevant to public health because it can result in enhanced critical care workflow and early critical care intervention, ultimately improving patient outcomes and decreasing hospitalization costs. Thus, the proposed research is relevant to the part of NIH’s mission that pertains to advancing disease diagnosis through medical applications of new tools and technologies, as the proposed research applies advanced computational methods and sensing technologies to automatically quantify and convey patient status in real-time.",Intelligent Intensive Care Unit (I2CU): Pervasive Sensing and Artificial Intelligence for Augmented Clinical Decision-making,10154047,R01EB029699,"['Address', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical assessments', 'Collaborations', 'Color', 'Complex', 'Computing Methodologies', 'Critical Care', 'Critical Illness', 'Cues', 'Data', 'Data Set', 'Decision Making', 'Deterioration', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'Environment', 'Evaluation', 'Facial Expression', 'Fostering', 'Foundations', 'Frequencies', 'Goals', 'Health Personnel', 'Hospital Costs', 'Human', 'Image', 'Intelligence', 'Intensive Care Units', 'Intervention', 'Judgment', 'Literature', 'Manuals', 'Measurement', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Monitor', 'Nurses', 'Outcome', 'Pain', 'Pain Measurement', 'Patient-Focused Outcomes', 'Patients', 'Physical Function', 'Physicians', 'Physiological', 'Posture', 'Process', 'Process Assessment', 'Public Health', 'Reproducibility', 'Research', 'Risk Assessment', 'Sampling', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Visual', 'advanced disease', 'augmented intelligence', 'base', 'clinical care', 'clinical decision-making', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'disease diagnosis', 'emotional distress', 'improved', 'indexing', 'innovation', 'novel', 'prediction algorithm', 'prospective', 'prospective test', 'risk perception', 'satisfaction', 'sensor', 'sensor technology', 'tool', 'vigilance']",NIBIB,UNIVERSITY OF FLORIDA,R01,2021,632088
"Structural and functional tests of ganglion cell damage in glaucoma This project will use a combination of structural and functional measurements to test the hypothesis that early- stage damage in human glaucoma occurs first in the inner plexiform layer (IPL) of the retina – especially its OFF sub-lamina – as suggested by murine glaucoma models. In the first Aim, we will use a novel visible-light optical coherence tomograph (VIS OCT) to study structural changes in the retina of glaucoma patients. The newly developed VIS OCT has sufficient image contrast and resolution to segment the IPL boundaries and to define sub-lamination in volumetric OCT data, something not currently possible with existing near-infrared OCT instruments. We will make comparative measurements within the IPL and between the IPL, the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Because data from mouse models of glaucoma suggests that early damage occurs preferentially within the OFF sub-lamina of the IPL, we will make separate VIS OCT measurements biased for the OFF- and ON-sublaminae of the IPL and use machine learning approaches to determine whether a similar damage process can be demonstrated in human. To test whether OFF-pathway function is preferentially lost in glaucoma, we will use a novel Steady-State Visual Evoked Potential (SSVEP) paradigm that employs sawtooth increments and decrements to bias the measurement to ON vs OFF pathways, respectively, a paradigm our data suggests discriminates glaucoma from control patients. The second Aim will optimize this SSVEP measurement for testing localized areas of the visual field. The third Aim will make comparative measurements of visual-field, VIS OCT and SSVEP loss patterns in a large sample of glaucoma patients and in age- and sex-matched controls. Thickness and interface reflectivity amplitude maps derived from VIS OCT imaging of the RNFL, GCL and IPL including sublaminae will be correlated topographically with visual field defects to assess the relative sensitivity of our structural biomarkers at and near visual field locations with demonstrable losses on conventional (Humphrey) perimetry. Similarly, SSVEP responses from different locations in the visual field will be correlated topographically with visual field loss patterns and to VIS OCT losses, with special emphasis on correlating structural damage in OFF vs ON sub-laminae of the IPL with the functional correlates derived from regional decremental and incremental SSVEPs. Separately and in combination, our structural and functional measurements are designed to provide strong tests of the biological hypothesis that the OFF pathway is preferentially damaged in human glaucoma, and to reveal new biomarkers for the disease. Improving visual outcomes in glaucoma will require a better understanding of the earliest sites and processes of damage and methods to measure them quickly and accurately in patients. This project will address both needs through a combination of novel Optical Coherence Tomography and electrophysiological measurements. The new imaging and electrophysiological tests that will be developed here, either separately or together, could eventually replace conventional visual field testing which is time-consuming and unreliable.",Structural and functional tests of ganglion cell damage in glaucoma,10150874,R01EY030361,"['Address', 'Affect', 'Age', 'Animal Model', 'Area', 'Atrophic', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Clinical', 'Complex', 'Consumption', 'Data', 'Disease', 'Early Diagnosis', 'Early treatment', 'Economic Burden', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Frequencies', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Inner Plexiform Layer', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modification', 'Mus', 'Noise', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Perimetry', 'Process', 'Property', 'Resolution', 'Retina', 'Retinal Ganglion Cells', 'Rodent Model', 'Sampling', 'Scotoma', 'Severities', 'Signal Transduction', 'Site', 'Specificity', 'Speed', 'Structural defect', 'Structure', 'Synapses', 'Techniques', 'Testing', 'Thick', 'Time', 'Visible Radiation', 'Vision', 'Visual', 'Visual Fields', 'Visual evoked cortical potential', 'base', 'cell injury', 'comparative', 'contrast imaging', 'design', 'detection method', 'extrastriate visual cortex', 'field study', 'ganglion cell', 'improved', 'instrument', 'mouse model', 'novel', 'optic nerve disorder', 'response', 'retinal imaging', 'retinal nerve fiber layer', 'sex']",NEI,STANFORD UNIVERSITY,R01,2021,499625
"Natural image processing in the visual cortex Project Summary Signals from the natural environment are processed by neuronal populations in the cortex. Understanding the relationship between those signals and cortical activity is central to understanding normal cortical function and how it is impaired in psychiatric and neurodevelopmental disorders. Substantial progress has been made in elucidating cortical processing of simple, parametric stimuli, and computational technology is improving descriptions of neural responses to naturalistic stimuli. However, how cortical populations encode the complex, natural inputs received during every day perceptual experience is largely unknown. This project aims to elucidate how natural visual inputs are represented by neuronal populations in primary visual cortex (V1). Progress to date has been limited primarily by two factors. First, during natural vision, the inputs to V1 neurons are always embedded in a spatial and temporal context, but how V1 integrates this contextual information in natural visual inputs is poorly understood. Second, prior work focused almost exclusively on single-neuron firing rate, but to understand cortical representations one must consider the structure of population activity— the substantial trial-to-trial variability that is shared among neurons and evolves dynamically—as this structure influences population information and perception. The central hypothesis of this project is that cortical response structure is modulated by visual context to approximate an optimal representation of natural visual inputs. To test the hypothesis, this project combines machine learning to quantify the statistical properties of natural visual inputs, with a theory of how cortical populations should encode those images to achieve an optimal representation, to arrive at concrete, falsifiable predictions for V1 response structure. The predictions will be tested with measurements of population activity in V1 of awake monkeys viewing natural images and movies. Specific Aim 1 will determine whether modulation of V1 response structure by spatial context in static images is consistent with optimal encoding of those images, and will compare the predictive power of the proposed model to alternative models. Specific Aim 2 addresses V1 encoding of dynamic natural inputs, and will test whether modulation of V1 activity by temporal context is tuned to the temporal structure of natural sensory signals, as required for optimality. As both spatial and temporal are present simultaneously during natural vision, Specific Aim 3 will determine visual input statistics in free-viewing animals, and test space-time interactions in V1 activity evoked by those inputs. This project will provide the first test of a unified functional theory of contextual modulation in V1 encoding of natural visual inputs, and shed light on key aspects of natural vision that have been neglected to date. Project Narrative This project aims to determine how neurons in the visual cortex represent the inputs encountered during perceptual experience in the natural environment, through correct integration of visual information across space and time. In individuals with neurodevelopmental and psychiatric disorders, integration is often miscalibrated leading to perceptual impairments. Our study will advance knowledge of the relationship between natural sensory inputs and cortical activity, which is central to understanding normal cortical function and how it is impaired in patient populations.",Natural image processing in the visual cortex,10219265,R01EY030578,"['Address', 'Animal Testing', 'Area', 'Complex', 'Dependence', 'Development', 'Environment', 'Experimental Designs', 'Goals', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Light', 'Location', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Monkeys', 'Motion', 'Neurodevelopmental Disorder', 'Neurons', 'Perception', 'Population', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Sampling', 'Sensory', 'Signal Transduction', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'V1 neuron', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'base', 'computer framework', 'experience', 'experimental study', 'image processing', 'improved', 'model development', 'movie', 'neglect', 'patient population', 'relating to nervous system', 'response', 'sensory input', 'spatiotemporal', 'statistics', 'theories', 'vision science', 'visual information']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2021,404975
"Visual Stimulus Coding and Metabolic Demand in Macaque Primary Visual Cortex Project Summary/Abstract  The relationships between neural response properties, their anatomical underpinnings, and the metabolic profile of neural tissue are key issues that define the normal functional architecture of the cerebral cortex. Understanding how these different systems are organized and work together is fundamental to neuroscientific research. Recent advances in optical imaging of cerebral activity have made it possible to record activity of both neuronal and metabolic dynamics simultaneously.  In primate primary visual cortex (V1), the relationships between neuronal orientation and color selectivity have been related to distribution of the metabolic enzyme cytochrome oxidase (CO) and vascular dynamics. The pattern of CO distribution in macaque V1 is a defining characteristic of this brain area. In V1, metabolic demand varies locally and by layer, as evident by diffuse CO-dense patches of cortex surrounded by less dense CO regions in layer 2/3. The distribution of CO in neurons has also been shown to be related to the density and organization of the vasculature which supplies the cortical tissue with nutrients and metabolites.  The long-established idea of how these systems interact suggests that strongly orientation tuned neurons reside in only CO interpatch regions while unoriented color tuned neurons reside exclusively in CO patches. However, recent research has shown that such a functional segregation is unlikely. Because earlier techniques failed to measure cone-specific and orientation-specific responses in the same cells and relate them to the CO pattern, new techniques—such as 2-photon imaging—are needed to develop an accurate picture of the functional organization of V1. In addition, the vasculature surrounding tuned neurons has been shown to have its own tuning through changes in vessel dilation and contraction, and therefore are expected to be related to the CO pattern if neural sensitivity to specific stimuli is locally organized in V1.  The goal of this proposal is to characterize the interaction of neuronal visual stimulus tuning, CO compartment identity, and vascular dynamics in primate V1. In Aim 1 we will use multiphoton calcium imaging to record orientation and cone specific selectivity in V1 and align the imaged regions with histological sections of CO staining to determine how neurons with different response profiles are distributed among CO patch or interpatch regions. In Aim 2 we will examine whether vascular dynamics are related to cone-specific orientation selectivity and CO compartment identity. The findings of this study will give us comprehensive information on the basic organization of the V1 and fundamentally alter our understand of visual processing. Project Narrative The brain’s metabolic drives and vasculature dynamics are closely integrated with neural information coding, but these interactions are still poorly understood. This research aims to uncover and describe the organization and relationship between these characteristics in macaque primary visual cortex. Completion of this project will broaden our understand of the organization of information processing in the animal model of visual cortex that is most comparable to humans, and may lead to therapeutic targets to help humans with visual deficits.",Visual Stimulus Coding and Metabolic Demand in Macaque Primary Visual Cortex,10266764,F32EY030725,"['Anatomy', 'Animal Model', 'Architecture', 'Area', 'Autopsy', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Brain imaging', 'Calcium', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Code', 'Color', 'Cone', 'Diffuse', 'Dyes', 'Electrodes', 'Enzymes', 'Fluorescent Dyes', 'Foundations', 'Goals', 'Histologic', 'Histology', 'Human', 'Image', 'Imaging Techniques', 'Injections', 'Label', 'Lead', 'Macaca', 'Maps', 'Measures', 'Metabolic', 'Monitor', 'Neurons', 'Nutrient', 'Output', 'Pattern', 'Primates', 'Property', 'Reporting', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'Stains', 'Stimulus', 'System', 'Techniques', 'Tissues', 'V1 neuron', 'Visual', 'Visual Cortex', 'Work', 'adeno-associated viral vector', 'area striata', 'arteriole', 'cellular imaging', 'cytochrome c oxidase', 'density', 'hemodynamics', 'improved', 'indexing', 'information organization', 'information processing', 'metabolic profile', 'neural patterning', 'neurovascular coupling', 'optical imaging', 'orientation selectivity', 'relating to nervous system', 'response', 'segregation', 'therapeutic target', 'two-photon', 'vascular bed', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,F32,2021,70458
"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,10229447,R01EY031059,"['Affect', 'Animals', 'Brain', 'Collaborations', 'Complex', 'Cone', 'Data', 'Data Set', 'Development', 'Environment', 'Eye Movements', 'Future', 'Goals', 'Lateral Geniculate Body', 'Light', 'Light Adaptations', 'Machine Learning', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Movement', 'Mus', 'Neurons', 'Noise', 'Optics', 'Outcome', 'Output', 'Pathway interactions', 'Physiological', 'Population', 'Process', 'Property', 'Pupil', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Rod', 'Signal Transduction', 'Stimulus', 'Structure', 'Sunlight', 'Techniques', 'Testing', 'Theoretical model', 'Variant', 'Vision', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'base', 'blind', 'cell type', 'computational neuroscience', 'experimental study', 'in vivo', 'innovation', 'luminance', 'multi-electrode arrays', 'novel', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'retinal neuron', 'sight restoration', 'stimulus processing', 'visual processing', 'visual stimulus']",NEI,DUKE UNIVERSITY,R01,2021,487568
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,10231148,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'segmentation algorithm', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2021,191246
"Neural mechanisms of active vision in the fovea Neural mechanisms of active vision in the fovea In many ways human vision is like a camera, with a lens that forms an image on a spatially arranged sensor (the retina). However, it is unlike a camera because the sensor has uneven sampling and is constantly moving with the eyes. Recent behavioral and theoretical work suggest these eye movements serve a faciliatory role in high acuity vision – where the eye movements are part of the computations and enhance spatial resolution. However, the neurophysiological mechanisms to support this facilitation remain unknown. More broadly, little is known about the neural mechanisms that integrate across the retinal motion generated by eye movements, especially in the central visual field (the fovea). This is particularly important because over 8 million Americans suffer from central vision loss due to retinal disorders. Even if the retinal signals could be repaired, it is imperative to understand how the brain reads out foveal signals to ensure recovery of high-acuity visual processing, and fixational eye movements are a part of that process. The proposed career development plan aims to address these questions by measuring visual processing in the foveal representation of primary visual cortex (V1) during natural visual behavior. This proposal uses custom high-resolution eye-tracking, a novel visual foraging paradigm, largescale neurophysiology, and state-of-the-art machine learning to make these measurements possible. The proposed research will not only generate fundamental understanding of how eye-movements facilitate visual processing, but also will integrate the experimental and theoretical tools required to support neurophysiological studies of active visual processing without a loss of rigor or detail. The candidate has extensive expertise in awake- behaving neurophysiology and computational modeling and the training plan is designed to support his further training in statistical modeling, high-resolution eye-tracking, and modern machine-learning techniques for analyzing neural population data. The primary mentor, Dr. Daniel Butts, is a world expert in statistical models of neural activity during active vision; Co-mentor, Dr. Michele Rucci, is a world leader in high-resolution eye tracking and theoretical approaches to active vision; and Co-mentor, Dr. Jude Mitchell, is a pioneer in establishing the marmoset model of visual neuroscience and an expert in neurophysiology of visual attention. Together, they will provide the guidance to establish the candidate’s transition to a successful independent research career. The goal of this proposal is to identify the impact of fixational eye movements on neural representations in visual cortex in the central visual field. Over 9 million Americans have central vision loss from age-related macular degeneration. Results from this proposal will build a fundamental understanding of how retinal signals from the fovea are processed by visual cortex during natural visual behavior.",Neural mechanisms of active vision in the fovea,10106203,K99EY032179,"['Address', 'Age related macular degeneration', 'American', 'Behavior', 'Behavioral', 'Blindness', 'Brain', 'Callithrix', 'Code', 'Cognitive', 'Computer Models', 'Custom', 'Data', 'Data Set', 'Development', 'Development Plans', 'Disease', 'Ensure', 'Esthesia', 'Eye', 'Eye Movements', 'Foundations', 'Frequencies', 'Funding', 'Goals', 'Grant', 'Human', 'Image', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Modernization', 'Monkeys', 'Motion', 'Neurons', 'Outcome', 'Peripheral', 'Phase', 'Physiology', 'Population', 'Positioning Attribute', 'Primates', 'Process', 'Recovery', 'Research', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Saccades', 'Sampling', 'Series', 'Signal Transduction', 'Statistical Models', 'Stream', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'V1 neuron', 'V4 neuron', 'Vision', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual attention', 'Work', 'active vision', 'area striata', 'awake', 'base', 'career', 'career development', 'central visual field', 'computerized tools', 'design', 'extrastriate', 'extrastriate visual cortex', 'flexibility', 'fovea centralis', 'interest', 'lens', 'neural model', 'neuromechanism', 'neurophysiology', 'new technology', 'novel', 'professor', 'receptive field', 'relating to nervous system', 'repaired', 'response', 'retinal imaging', 'sample fixation', 'sensor', 'skills', 'spatial vision', 'spatiotemporal', 'statistics', 'tool', 'visual information', 'visual neuroscience', 'visual process', 'visual processing', 'visual tracking']",NEI,"UNIV OF MARYLAND, COLLEGE PARK",K99,2021,116969
"Statistical Unsupervised Learning VF for IIHTT & ONTT Summary Current assessments of visual field testing depend on algorithms, principally developed to diagnose and monitor progression in glaucoma, or on expert descriptive categorization of deficits. The algorithms do not work well for non-glaucomatous optic neuropathies as these disorders can both improve and deteriorate. Descriptive categorizations are not readily quantifiable to assess change over time. Unsupervised statistical learning archetypal analysis is a new way to investigate glaucoma and potentially other optic neuropathies. Both idiopathic intracranial hypertension and optic neuritis are disorders that often improve and respond to therapy. Archetypal analysis of the visual fields from two NEI sponsored clinical trials on each disorder, ONTT and IIHTT, will be investigated to determine if the findings parallel the reported outcomes and effects of therapy. We will also test whether machine learning quantifiable archetypes, which are disease-associated patterns of field deficits, are similar to expert determinations, whether they are sensitive to changes in optic nerve function, and if they reveal residual optic nerve dysfunction in eyes reported to be normal by prior study criteria. Adding cases of IIH and optic neuritis from the clinic will enhance the archetypes for each disorder for use in the clinic and new studies. Narrative Analysis of the visual fields of patients with optic neuropathies using machine learning will improve the evaluation and provide objective measurement, rather than the current descriptive methods. The approach, called archetypal analysis, should improve safety monitoring during clinical trials as well as uncover residual visual field deficits not seen with other types of analyses.",Statistical Unsupervised Learning VF for IIHTT & ONTT,10192112,R21EY032522,"['Acute', 'Affect', 'Algorithms', 'Clinic', 'Clinical Trials', 'Cost Savings', 'Detection', 'Deterioration', 'Diagnosis', 'Disease', 'Evaluation', 'Event', 'Eye', 'Face', 'Frequencies', 'Functional disorder', 'Future', 'Glaucoma', 'Head', 'Injury', 'Intervention', 'Intervention Studies', 'Lead', 'Machine Learning', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Methods', 'Military Personnel', 'Monitor', 'Optic Nerve', 'Optic Neuritis', 'Outcome', 'Outcome Study', 'Papilledema', 'Patients', 'Pattern', 'Perimetry', 'Physiologic Intraocular Pressure', 'Pseudotumor Cerebri', 'Reader', 'Reporting', 'Residual state', 'Safety', 'Shapes', 'Supervision', 'Testing', 'Time', 'Vision', 'Visit', 'Visual Fields', 'Weight', 'archetypal analysis', 'base', 'central visual field', 'clinical practice', 'eligible participant', 'field study', 'improved', 'longitudinal analysis', 'optic nerve disorder', 'prospective', 'response', 'statistical learning', 'successful intervention', 'treatment effect', 'treatment trial', 'trend', 'unsupervised learning']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R21,2021,331170
"Towards a computationally precise characterization of the human ventral visual pathway Project Summary/Abstract: Humans are extraordinarily visual animals, allocating a third of their cortex just to seeing what is in front of them. Visual recognition is supported by a series of hierarchically organized brain regions known collectively as the ventral visual cortex (VVC). Despite extensive research, we still lack a computationally precise understanding of how visual information is represented and transformed over stages of the human VVC. A key barrier has been the limitations of methods like functional MRI (fMRI) which make it difficult to test a large number of experimental stimuli. The research in this proposal will overcome this barrier by collecting fMRI responses to hundreds of stimuli, and analyzing these data using deep neural network based computational models and human interpretable algorithms such as image-synthesis and saliency mapping. In Aim 1 (K99 phase), I will focus on the category-selective regions of the VVC, that respond preferentially to images of faces (fusiform face area), scenes (parahippocampal place area), and bodies (extrastriate body area). I will develop and use new computational methods together with closed-loop experiments to address open questions such as: Is the hypothesized selectivity for these regions even correct? What is represented in the intermediate stages of processing? Are there functionally distinct regions within the category-selective regions? In Aim 2 (R00 phase), I will venture into the ~65% of VVC that lies outside the category-selective regions. I will develop and apply new data-driven clustering to divide these regions into their native components, and characterize them individually. Together, this endeavor will reveal the computational and neural basis of visual recognition in humans with an unprecedented precision. My background in experimental and analytical methods in monkey and human vision puts me in a unique position to accomplish this proposal which requires a seamless integration between neuroimaging experiments and state-of-the-art computational modeling. The proposed work will be initiated in the lab of Prof. Nancy Kanwisher (mentor). During the K99 phase, I will continue to be mentored by Prof. Kanwisher, and will also advance my expertise with computational modeling under the supervision of Dr. Jim DiCarlo (co-mentor), and ultra-high-resolution 7T neuroimaging with Dr. Jon Polimeni (collaborator). This proposed plan will significantly augment my theoretical understanding and experimental abilities, and put me on a path to independence. Project Narrative Public Health Relevance Statement How the collective action of distributed neural systems in the human visual pathway leads to our rich percept of the visual world is not well understood, and disorders of the circuits involved in perception, especially those involved in face and object recognition, can significantly impair normal social function. Understanding the neural computations that support human vision and their locations in the brain will offer valuable insights into the development of visual neuro-prostheses, guidance for neurosurgery, and strategies for recovery from brain damage.",Towards a computationally precise characterization of the human ventral visual pathway,10191834,K99EY032603,"['Address', 'Algorithms', 'Animals', 'Area', 'Behavior', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Computer Models', 'Computing Methodologies', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease', 'Encapsulated', 'Evolution', 'Eye', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Image', 'Impairment', 'Individual', 'Lead', 'Location', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Network-based', 'Neurosciences', 'Pattern', 'Perception', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Reading', 'Recovery', 'Research', 'Resolution', 'Rest', 'Series', 'Social Functioning', 'Stimulus', 'Supervision', 'System', 'Testing', 'Text', 'Vision', 'Visual', 'Visual Cortex', 'Visual Pathways', 'Visual Perception', 'Work', 'analytical method', 'base', 'cognitive ability', 'cohort', 'data quality', 'deep neural network', 'design', 'experimental study', 'extrastriate', 'fusiform face area', 'insight', 'interest', 'neuroimaging', 'neuroprosthesis', 'neurosurgery', 'object recognition', 'public health relevance', 'relating to nervous system', 'response', 'screening', 'theories', 'ultra high resolution', 'vision development', 'visual information', 'visual processing', 'visual stimulus']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,K99,2021,110175
"Perceptual integration of luminance, texture and color cues for visual boundary segmentation Project Summary One of the most essential computations performed by the visual system is segmenting images into regions corresponding to distinct surfaces. This in turn requires identifying the boundaries separating image regions, a process known as boundary segmentation. Computational analyses of natural images have revealed that many visual cues are available at region boundaries, including differences in luminance, texture, and color. It is known that these cues combine for tasks like edge localization and orientation discrimination. However, it remains unclear how these various cues are weighted and combined for boundary segmentation.  In collaborative work with Canadian colleagues at McGill University in Montreal, we have developed a novel machine learning framework for characterizing human performance on boundary segmentation tasks using naturalistic micro-pattern stimuli. Our method makes use of the Filter-Rectify-Filter (FRF) model often applied to characterizing texture boundary segmentation. The major innovation of our approach is that we fit the FRF model directly to thousands of psychophysical stimulus-response observations to estimate its major defining parameters. We have recently applied this approach to investigating spatial strategies for contrast boundary segmentation and comparing competing hypotheses of how contrast modulation is integrated across orientation channels. In this grant, we propose to apply both classical psychophysical techniques and our novel machine learning methodology to understanding the computations employed to combine luminance, texture and color cues for segmentation.  In Aim 1, we focus on modeling segmentation of luminance-defined boundaries, comparing the case where each surface has uniform luminance, giving rise to a sharp edge (luminance step), to the more naturalistic case where the two surfaces have differing proportions of dark and light micro-patterns on either side of the boundary with no sharp edge (luminance texture). We will apply our machine learning methodology to test the hypothesis that different neural mechanisms may be involved in segmenting these two different kinds of luminance boundaries. In Aim 2, we ask how observers integrate first-order (luminance) and second-order (texture) cues for boundary segmentation, and if there are differences in cue combination strategies for luminance steps and luminance textures. We will also compare models embodying competing hypotheses of the underlying neural mechanisms of cue combination. In Aim 3, we extend the analyses in Aims 1 and 2 beyond simple luminance differences to include differences in color. Finally, Aim 4 is a pedagogical aim of promoting undergraduate research. Project Narrative Segmenting natural images into regions corresponding to distinct surfaces is an essential visual task, yet the underlying computations for boundary segmentation remain poorly understood. In this project, we will apply classical psychophysical techniques and our novel machine learning methodology to understand how multiple cues, including luminance, texture, and color, combine to enable boundary segmentation. We hope to develop and test computational models of boundary segmentation, with the ultimate goal of gaining insight into the underlying neural mechanisms employed for this essential natural vision task.","Perceptual integration of luminance, texture and color cues for visual boundary segmentation",10201916,R15EY032732,"['Address', 'Biological', 'Color', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'Cues', 'Data', 'Discrimination', 'Educational process of instructing', 'Environment', 'Goals', 'Grant', 'Human', 'Image', 'Journals', 'Laboratories', 'Light', 'Literature', 'Machine Learning', 'Methods', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Positioning Attribute', 'Process', 'Psychophysics', 'Publications', 'Research', 'Response to stimulus physiology', 'Series', 'Side', 'Source', 'Stimulus', 'Surface', 'Techniques', 'Testing', 'Texture', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual system structure', 'Work', 'computer studies', 'experience', 'innovation', 'insight', 'interest', 'laboratory curriculum', 'luminance', 'machine learning method', 'neuromechanism', 'neurophysiology', 'novel', 'pedagogy', 'undergraduate research', 'undergraduate student', 'vision science']",NEI,FLORIDA GULF COAST UNIVERSITY,R15,2021,374345
"Noninvasive modulation of perception and cognition with flicker induced response modulation. Project Summary This project investigates the use of repetitive visual stimulation as a tool to improve visual cognition. Surprisingly, the repeated presentation of simple visual patterns can result in long-term plasticity, reflected in increased neural responses, but also in behavioral improvements that last for hours, even days. In current approaches using RVS, however, these improvements are limited to the specific, repeated patterns; this limits the practical usefulness of RVS. The proposed project builds on recent findings in the nonhuman primate demonstrating widespread and general increases in neural responses after the repeated presentation of a uniform grey screen with sinusoidally modulated luminance. The first aim is to show, using EEG, that such long-lasting increases in neural responses also occur in the human brain. The second aim is to determine which aspects of visual cognition are improved by this boost in neural responses. The project will assess improvements in low-level vision such as detection and visual acuity, but also higher-level visual processes such as visuospatial attention, and visual working memory. The pilot data already show widespread neural changes in the human brain and substantial behavioral improvements in, for instance, visual acuity. A successful tool to improve visual cognition would have a significant impact, as it could be used therapeutically in low vision conditions (e.g., amblyopia), but also in the elderly or healthy human subjects, to deliver a boost in performance. Relevance Repetitive visual stimulation (RVS) is a powerful driver of plasticity; just a few minutes of exposure can lead to a long lasting strengthening of neural responses. This could be beneficial to improve vision in amblyopia, in neuropsychiatric patients with reduced brain responses, or even in healthy subjects as a way to improve visual cognition. This project investigates a newly developed, improved method of RVS that has the potential to generate widespread behavioral improvements.",Noninvasive modulation of perception and cognition with flicker induced response modulation.,10222897,R01EY032744,"['Amblyopia', 'Area', 'Attention', 'Behavioral', 'Brain', 'Chemosensitization', 'Cognition', 'Cognitive deficits', 'Computer Models', 'Contrast Sensitivity', 'Data', 'Detection', 'Elderly', 'Electroencephalography', 'Frequencies', 'Goals', 'Health', 'Hour', 'Human', 'Human Volunteers', 'Laboratories', 'Lead', 'Methods', 'Modeling', 'Neurons', 'Occipital lobe', 'Parietal', 'Patients', 'Pattern', 'Perception', 'Performance', 'Photic Stimulation', 'Research', 'Rodent', 'Short-Term Memory', 'Specificity', 'Techniques', 'Testing', 'Therapeutic Uses', 'V1 neuron', 'Vision', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual impairment', 'Visuospatial', 'base', 'clinically relevant', 'density', 'experimental study', 'extracellular', 'human subject', 'improved', 'insight', 'luminance', 'neuropsychiatric disorder', 'neuropsychiatry', 'neuroregulation', 'nonhuman primate', 'recruit', 'recurrent neural network', 'relating to nervous system', 'response', 'spatial integration', 'tool', 'visual cognition', 'visual process', 'visual processing', 'visual stimulus']",NEI,RUTGERS THE STATE UNIV OF NJ NEWARK,R01,2021,75000
"An enhancement to nGoggle: a VR Goggle for Structural and Functional assessment in Glaucoma PROJECT SUMMARY  Assessments of functional loss and of structural damage to the optic nerve are typical evaluations per- formed in the diagnosis and monitoring of glaucoma. This proposal aims at developing the hardware system that will allow acquisition of fundus photographs using the nGoggle, a portable Brain-Computer Interface (BCI) which integrates a wearable, wireless, electroencephalogram (EEG) system and a head-mounted display to monitor electrical brain activities associated with visual field stimulation. In a previous project, we developed the nGoggle portable system for the assessment of visual function deficits in order to address limitations of standard automated perimetry (SAP), a traditional but subjective visual field test. We compared the diagnostic accuracies of the nGoggle and SAP in discriminating patients with glaucoma from healthy subjects and found that the BCI performed at least as well, if not better than SAP, with the additional advantage of portability and objectivity.  With rapid advancements in smartphone cameras, it is now possible to develop compact auto-focusing fundus cameras and integrate them into our neuro-monitoring nGoggle. Recently we developed an approach named Machine-to-Machine (M2M), a deep learning algorithm that was trained to analyze fundus photos and predict quantitative measurements of retinal nerve fiber layer thickness and neuroretinal rim provided by spectral domain-optical coherence tomography (SDOCT), with high correlation and agreement with the original SDOCT observations. This approach opens up the possibility of using simple fundus photographs to extract quantitative information about neural damage in glaucoma. By combining functional assessment currently provided by the nGoggle with structural assessment capability, this new system would result in a very unique device capable of portable structural and functional assessment of optic nerve damage for a multitude of eye conditions, not limited to glaucoma, such as age-related macular degeneration, retinal degenerations and non-glaucomatous optic neu- ropathies.  The specific aims of this Phase I SBIR project are (1) to incorporate a high-resolution auto-focusing fundus camera to the nGoggle head-mounted display in full compliance with ophthalmic instrument safety stand- ards and fundus camera functional standards, and (2) to demonstrate the ability of the nGoggle fundus camera to capture high-quality optical nerve images from a model eye. Successful development of this system will enable both structural and functional assessments of retinal conditions to be performed easily and inexpensively using a portable device. PROJECT NARRATIVE NGoggle Inc. proposes to develop a new wearable ophthalmic diagnostic instrument capable of performing con- current structural and functional assessment to diagnose and monitor optic neuropathies and retinal diseases. This project aims at developing a pair of compact high-resolution fundus cameras in full compliance with oph- thalmic instrument safety standards and integrating them into our neuro-monitoring nGoggle, an instrument with the demonstrated capability of estimating functional vision loss in glaucoma patients based on their electroen- cephalogram (EEG) responses evoked by visual stimuli. We also intend to demonstrate that the optic nerve images of model eyes taken by the integrated fundus cameras can yield consistent and compatible cup-to-disc ratios when compared with the measurements obtained from the same model eyes using optical coherence tomography (OCT). After successful demonstration, we plan to conduct clinical tests in the subsequent phase of this project.",An enhancement to nGoggle: a VR Goggle for Structural and Functional assessment in Glaucoma,10253661,R43EY032820,"['Address', 'Age related macular degeneration', 'Agreement', 'Algorithms', 'Anatomy', 'Blindness', 'Cellular Phone', 'Clinic', 'Clinical', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Electroencephalogram', 'Electroencephalography', 'Evaluation', 'Eye', 'Flare', 'Fundus', 'Fundus photography', 'Glaucoma', 'Healthcare', 'Image', 'Imaging technology', 'Light', 'Measurement', 'Modeling', 'Monitor', 'Names', 'Nerve', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Performance', 'Perimetry', 'Phase', 'Physiologic pulse', 'Publications', 'Reproducibility', 'Resolution', 'Resources', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Safety', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Structure', 'System', 'Systems Development', 'Testing', 'Thick', 'Time', 'Training', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Visual impairment', 'Wireless Technology', 'base', 'brain computer interface', 'brain electrical activity', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'detection test', 'diagnostic accuracy', 'disability', 'field study', 'functional loss', 'gaze', 'hazard', 'head mounted display', 'innovation', 'instrument', 'loss of function', 'nerve damage', 'neural network algorithm', 'optic nerve disorder', 'patient response', 'portability', 'prevent', 'relating to nervous system', 'retinal imaging', 'retinal nerve fiber layer', 'screening', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R43,2021,299600
"CRCNS: Resolving human face perception with novel MEG source localization methods A brief glimpse at a face quickly reveals rich multi-dimensional information about the person in front of us. How is this impressive computational feat accomplished? A recently revised neural framework for face processing suggests perception of face form information, i.e. face invariant features such as gender, age, and identity, are processed through the ventral visual pathway, comprising the occipital face area, fusiform face area, and anterior temporal lobe face area. However, evidence from fMRI remains equivocal about when, where, and how specific face dimensions of age, gender, and identity, are extracted. A key property of a complex computation is that it proceeds via stages and hence unfolds over time. We recently investigated the computational stages of face perception in a MEG study (Dobs et al., Nature Comms, 2019) and found that gender and age are extracted before identity information. However, this temporal information has yet to be linked to the spatial information available from fMRI because of limitations in current methods for spatial localization of MEG sources. Here, we propose to overcome these limitations and provide the full picture of how face computations unfold over both time and space in the brain by developing novel methods for localizing MEG sources, leveraging our team’s expertise in MEG and machine learning. In Aim 1 we will develop a new analytical MEG localization method called Alternating Projections that iteratively fits focal sources to the MEG data. In Aim 2 we will develop a novel data-driven MEG localization method based on geometric deep learning that reconstructs distributed cortical maps by learning statistical relationships in the non-Euclidean space of the cortical manifold. In Aim 3, we will first identify which method is most suitable to model human MEG face responses using fMRI face localizers as ground truth. We will then extract spatially and temporally accurate face processing maps to characterize the computational steps entailed in extracting age, gender, and identity information along the ventral visual pathway. A computationally precise characterization of the neural basis of face processing would be a landmark achievement for basic research in vision and social perception in humans. Insights into how face perception is accomplished in humans may further yield clues for how to improve AI systems conducting similar tasks. Further, the methods developed here may increase the power of MEG data to answer questions about the spatiotemporal trajectory of neural computation in the human brain. The proposed research is relevant to public health because it develops new brain imaging methods to improve the spatial and temporal resolution, and applies them to study visual processing of faces. The methods developed here will broaden our ability to answer questions about the spatiotemporal trajectory of neural computation in the human brain. In the field of vision, a principled understanding of the computational steps of face perception could lead to a better understanding of visual impairments.",CRCNS: Resolving human face perception with novel MEG source localization methods,10397180,R01EY033638,"['Achievement', 'Address', 'Age', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Basic Science', 'Brain', 'Brain imaging', 'Code', 'Communication', 'Complex', 'Computer software', 'Data', 'Dimensions', 'Face', 'Face Processing', 'Familiarity', 'Functional Magnetic Resonance Imaging', 'Gender', 'Gender Identity', 'Human', 'Lead', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Pathway interactions', 'Persons', 'Process', 'Property', 'Public Health', 'Research', 'Resolution', 'Signal Transduction', 'Social Perception', 'Source', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Vision', 'Visual Pathways', 'Visual impairment', 'analytical method', 'base', 'cohort', 'cortex mapping', 'deep learning', 'experimental study', 'face perception', 'fusiform face area', 'human data', 'human model', 'imaging modality', 'implementation tool', 'improved', 'innovation', 'insight', 'large scale data', 'learning strategy', 'millimeter', 'novel', 'operation', 'reconstruction', 'relating to nervous system', 'response', 'simulation', 'source localization', 'spatiotemporal', 'statistical learning', 'temporal measurement', 'theories', 'visual processing', 'volunteer']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,249632
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,10448533,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'effectiveness testing', 'experience', 'falls', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"BLUE IRIS LABS, INC.",R44,2021,18000
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,10312690,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'effectiveness testing', 'experience', 'falls', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2021,10487
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,10199754,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2021,40048
"Cortical visual processing for navigation Project summary Vision plays a key role in our ability to navigate through the environment, from identifying landmarks and obstacles to determining location and heading. While studies of visual cortex have provided an understanding of properties such as orientation selectivity and object recognition, much less is known about how cortical circuitry extracts and processes features from the visual scene to support navigation. In particular, there are two challenges. First, the nature of the visual stimulus is dramatically different in navigation, where the subject's movement through the world creates a complex and dynamic visual input, in contrast to standard synthetic stimuli presented to stationary subjects. Second, the types of visual features and computations that must be performed are different in navigation than in standard detection or discrimination paradigms. Our goal in this proposal is to determine how the brain extracts relevant visual features from the rich, dynamic visual input that typiﬁes active exploration, and investigate how the neural representation of these features can support visual navigation.  We will investigate this through three parallel aims, that build up from the representation of the visual scene in V1 during freely moving navigation, to the computation of speciﬁc variables needed for navigation. In our ﬁrst aim, we will measure the visual input in freely moving mice using miniature head-mounted cameras, together with neural activity in V1, to determine how neural dynamics represent the visual scene during natural navigation. In our second aim, we will use large ﬁeld-of-view two-photon imaging of multiple cortical areas, while mice navigate in a naturalistic open-world virtual reality system, to determine how visual features are represented across visual cortical areas. In our third aim, we will use 2-photon imaging in mice in a rotational arena to determine how visual input is used to dynamically update a key navigational variable: heading direction. Together, this project bridges foundational measurements in freely moving animals with mechanistic circuit investigations, to provide insights into an important aspect of visual system function. Project Narrative This project will study how the brain processes visual information to support navigation, which is important for guiding goal-directed movement through the world. The results of this work will provide knowledge about normal visual function and insights for treating impaired vision via prosthetic or assistive devices.",Cortical visual processing for navigation,10208550,R01NS121919,"['Animals', 'Area', 'Behavior', 'Behavioral', 'Brain', 'Code', 'Complex', 'Conflict (Psychology)', 'Cues', 'Data', 'Detection', 'Discrimination', 'Electrophysiology (science)', 'Environment', 'Foundations', 'Frequencies', 'Goals', 'Head', 'Hippocampus (Brain)', 'Image', 'Investigation', 'Knowledge', 'Location', 'Measurement', 'Measures', 'Modeling', 'Motion', 'Movement', 'Mus', 'Nature', 'Neural Network Simulation', 'Play', 'Population', 'Process', 'Property', 'Prosthesis', 'Rotation', 'Sampling', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Space Models', 'Stimulus', 'Structure', 'Testing', 'Update', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Visual system structure', 'Visuospatial', 'Work', 'deep neural network', 'entorhinal cortex', 'experimental study', 'high dimensionality', 'insight', 'novel', 'object recognition', 'optic flow', 'orientation selectivity', 'relating to nervous system', 'response', 'statistics', 'synergism', 'theories', 'two-photon', 'virtual reality', 'virtual reality system', 'virtual world', 'visual information', 'visual process', 'visual processing', 'visual stimulus']",NINDS,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2021,2833387
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
