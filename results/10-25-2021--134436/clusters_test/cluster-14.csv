text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),10135685,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratory of Neuro Imaging Resource', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data curation', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'image archival system', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2021,1193086
"Laboratory of Neuro Imaging Resource for Mapping Brain Aging and Alzheimer's Disease PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource for Mapping Brain Aging and Alzheimer's Disease,10289589,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratory of Neuro Imaging Resource', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'aging brain', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data curation', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'image archival system', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2021,408091
"A novel method for volumetric oxygen mapping in living retina PROJECT SUMMARY It is widely accepted that oxygen deficiency is a culprit and a marker of several major retinal diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma etc. However, it remains to be extremely challenging to measure oxygen in vivo in the eye, and no tools currently exist that can provide 3D oxygen distributions in the retina with high spatial resolution at appropriate imaging speeds. The goal of this project is to overcome these limitations and develop a new optical imaging technique for volumetric oxygen mapping in retina. Our approach will leverage the recently developed potent oxygen probes (such as Oxyphor 2P), whose phosphorescence decay times serve as quantitative markers of local oxygen partial pressures (pO2) in living tissues. To enable volumetric imaging with high throughput, we propose to develop a novel imaging instrument, termed oblique scanning laser ophthalmoscope (oSLO). oSLO is based on the concept of single lens scanned light sheet microscopy and enables volumetric phosphorescence lifetime imaging without time- consuming plane-by-plane pixel-wise sectioning. Our new method should be able to achieve 10 kilohertz voxel rate that is three orders of magnitude higher than the current state-of-the-art two-photon phosphorescence lifetime microscopy (2PLM). In this project we will: (Aim 1) develop a phosphorescence lifetime-based oSLO for volumetric pO2 mapping in living retina in mouse. The new design will allow parallel detection of signals at depth from each scanned location, so that the need in conventional depth sectioning is eliminated and imaging throughput is greatly increased. We will (Aim 2) dynamically image responses of retina and choroid to systemic hypoxia challenge using Oxyphor 2P. We will (Aim 3) then bridge oSLO measurements and label-free applications by multimodal imaging with visible light optical coherence tomography (vis-OCT). Using vascular pO2 as the ground-truth, we will develop a deep spectral training (DSL) algorithm to supervise the inverse calculation of vis-OCT for robust and reliable label-free retinal oximetry. This study will enable the first direct quantitative imaging of interactions between the two circulatory systems in retina (i.e. retinal and choroidal circulation), providing unprecedented information about retinal oxygen supply. IMPACT ON PUBLIC HEALTH: Successful completion of this program will deliver a new ground-breaking methodology for mapping oxygen in the retina that will greatly improve our understanding of retinal diseases. NARRATIVE Oxygen is essential in the retina, and the deficiency of oxygen is a culprit in a broad spectrum of retinal diseases. However, it remains challenging to measure oxygen in vivo in the eye. This multidisciplinary proposal is to develop a disruptive imaging method to provide unprecedented volumetric oxygen mapping in living mouse retina, as well as a deep learning method, to translate our oxygen measurements into label-free retinal oximetry for future clinical applications.",A novel method for volumetric oxygen mapping in living retina,10098478,R01EY032163,"['3-Dimensional', 'Address', 'Affect', 'Age related macular degeneration', 'American', 'Biochemistry', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cardiovascular system', 'Cell Respiration', 'Choroid', 'Consumption', 'Data', 'Data Set', 'Detection', 'Diabetic Retinopathy', 'Dyes', 'Eye', 'Fluorescence Angiography', 'Fundus', 'Future', 'Glaucoma', 'Goals', 'Human', 'Hypoxia', 'Image', 'Imaging Device', 'Imaging Techniques', 'Inhalation', 'Label', 'Lasers', 'Life', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medicine', 'Metabolic', 'Methodology', 'Methods', 'Microscopy', 'Multimodal Imaging', 'Mus', 'Nobel Prize', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Oxygen', 'Oxygen saturation measurement', 'Partial Pressure', 'Pathologic', 'Pathology', 'Photons', 'Physiology', 'Public Health', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Scanning', 'Signal Pathway', 'Signal Transduction', 'Speed', 'Supervision', 'Time', 'Tissues', 'Training', 'Translating', 'Vascular System', 'Visible Radiation', 'adaptive optics', 'algorithm training', 'base', 'choroidal circulation', 'clinical application', 'clinical translation', 'deep learning', 'design', 'hemodynamics', 'human imaging', 'imaging modality', 'improved', 'in vivo', 'learning network', 'learning strategy', 'lens', 'multidisciplinary', 'novel', 'novel imaging technique', 'optical imaging', 'phosphorescence', 'porphyrin a', 'programs', 'quantitative imaging', 'response', 'retina circulation', 'retinal imaging', 'sensor', 'success', 'tool', 'two photon microscopy', 'two-photon']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,552744
"Center for Genetic Studies of Drug Abuse in Outbred Rats Project Summary (Overall)  The purpose of this renewal application is to continue the successful activities of our center, which uses quantitative genetic techniques to study the genetic basis of drug abuse-related behaviors in outbred rats. When our center was initially funded in June 2014, our goal was to develop outbred N/NIH heterogeneous stock (HS) rats as a platform for genetic studies of behaviors that were difficult or impossible to study in mice. The first four years of funding have allowed us to establish a vibrant community of investigators using HS rats to study drug abuse and other traits, which we refer to as an ecosystem. This ecosystem includes both the investigators who are directly involved in this renewal application and many others who have obtained separate funding, some from NIDA, and some from other sources. The growth of this ecosystem reflects one of the ways that our center has served as national resource. We are proposing three projects that involved phenotyping HS rats for a variety of traits, including intravenous cocaine and nicotine self-administration, response to novelty, social behavior, reaction time, and delay discounting. Two of those projects are continuations from the prior funding period and are designed to increase our sample size from 1,600 to 3,200 rats per phenotype. We present data showing that such an increase produces an exponential increase in the number of significant findings. This approach parallels human genetics studies of SUD, which have also benefited tremendously from larger sample sizes. We will use these data to conduct genome-wide association studies (GWAS) and a suite of related techniques. In addition, we will measure gene expression in behaviorally naïve rats using RNASeq and use those data to identify expression quantitative trait loci (eQTLs). We will then integrate GWAS and eQTL data in an effort to identify specific genes that influence the behavioral phenotypes. Many of the behavioral domains being studied are known to be sexually dimorphic; our study will use both male and female rats, which will allow us to identify sex differences and sex by genotype interactions. We will also study genetic correlations, perform phenome-wide association studies (PheWAS), transcriptome wide association studies (TWAS) and explore a novel strategy called polygenic transcriptomic risk scores (PTRS), that is intended to allow translation of polygenic signals across species. Project 4 will use a network-based approach to extend our GWAS to account for known biological networks. This proposed renewal also includes a pilot project core to support new directions and take advantage of unforeseen opportunities. Finally we propose an administrative core that supports many activities of the center, including educational, career development and public outreach. The results of these studies will enhance our understanding of the role of genes in a range of psychologically complex behaviors and will provide novel biological insights that may support future efforts at preventing or treating drug abuse. Project Narrative (Overall)  Using powerful genetic, molecular and statistical techniques, we will study the genetic basis of traits that have well-established relevance to drug abuse. We expect that these studies will enhance our understanding of drug abuse and lead to the identification of specific genes and pathways. These discoveries will improve our understanding of genetic susceptibility to drug abuse in humans and may identify new opportunities to treat psychiatric disorders including but not limited to addiction.",Center for Genetic Studies of Drug Abuse in Outbred Rats,10160842,P50DA037844,"['Adolescent', 'Animal Model', 'Attention', 'Behavior', 'Behavioral', 'Biological', 'Brain region', 'Breeding', 'Cancer Grant Supplements (P30)', 'Cessation of life', 'Cocaine', 'Communities', 'Complex', 'Crime', 'Cues', 'DNA', 'Data', 'Databases', 'Development', 'Drug abuse', 'Ecosystem', 'Education', 'Esthesia', 'Female', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Recombination', 'Genetic Techniques', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Impulsivity', 'Inbred Strains Rats', 'Individual', 'Intravenous', 'Knowledge', 'Lead', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Molecular', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Drug Abuse', 'Network-based', 'Nicotine', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Productivity', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reaction Time', 'Regulation', 'Relapse', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Sample Size', 'Self Administration', 'Sex Differences', 'Signal Transduction', 'Social Behavior', 'Social Reinforcement', 'Source', 'Statistical Methods', 'Substance Use Disorder', 'System', 'Techniques', 'Translations', 'United States National Institutes of Health', 'addiction', 'behavior influence', 'behavioral phenotyping', 'behavioral study', 'career development', 'cocaine self-administration', 'cocaine use', 'cost', 'deep learning', 'design', 'discounting', 'drug abuse related behavior', 'effective therapy', 'genetic analysis', 'genetic approach', 'genome wide association study', 'genome-wide', 'improved', 'insight', 'male', 'nicotine use', 'novel', 'novel strategies', 'outreach', 'phenome', 'phenotypic data', 'premature', 'preservation', 'prevent', 'psychologic', 'response', 'sex', 'sexual dimorphism', 'success', 'sustained attention', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'virtual', 'web site']",NIDA,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P50,2021,3009655
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,10161678,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data harmonization', 'data reuse', 'data sharing', 'data tools', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic risk factor', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,619917
"Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping PROJECT SUMMARY Osteoarthritis (OA), a leading cause of chronic disability in the elderly population, occurs with the degradation of the extracellular matrix of articular cartilage, mainly composed of proteoglycan, collagen fibers, and water. Early diagnosis of cartilage degeneration requires the detection of changes in proteoglycan concentration and collagen integrity, preferably non-invasively and before any morphological changes occur. Spin-spin relaxation time (T2) and spin-lattice relaxation time in the rotating frame (T1ρ) can provide quantitative information about the structure and biochemical composition of the cartilage before morphological changes occur. Mono-exponential (ME) models can characterize the T2 and T1ρ relaxation processes and map it for articular cartilage in the knee joint. A recent meta-analysis showed that T1ρ provides more discrimination than T2 for OA. However, the ME model alone cannot provide distinct information from different compartments of the cartilage. Recent studies have shown that T1ρ relaxation might have bi-exponential (BE) components, following the hypothesis of the multi- compartmental structure of the cartilage. BE T2 relaxation has shown better diagnostic performance than ME for OA and can show the dispersion of the relaxation times, reflecting the heterogeneity in the macromolecular environment of water in the cartilage. BE analysis of cartilage typically requires a larger number of acquisitions with different spin-lock times (TSLs) or echo times (TEs), resulting in long scan time. High spatial resolution is also needed to visualize the thin and curved cartilage and fine structures in the knee joint. As a result, in vivo application of BE three-dimensional (3D) T1ρ and T2 mapping techniques is still very limited. Compressed sensing (CS) combined with parallel imaging (PI) can accelerate acquisition and reduce the scan time required for ME 3D T1ρ and T2 mappings. T1ρ scans can be reduced from 30 min to ~3 min with an error smaller than 6.5%. However, the error is two to three times larger for BE mapping. This problem can be potentially solved by optimizing the sampling times (TSLs for T1ρ and TEs for T2) and the free parameters of the CS approach (k- space sampling pattern, regularization function, regularization parameter, and minimization algorithm parameters) using fully sampled 3D knee joint datasets, supported by machine learning tools. The overarching goal of this proposal is to develop, optimize, and translate a high-spatial-resolution, rapid 3D magnetic resonance imaging sequence using data-driven learning-based CS for assessment of the human knee joint and using ME and BE 3D T1ρ (T2) mapping for improved biochemical characterization of cartilage and menisci on a standard clinical 3T scanner. PROJECT NARRATIVE Osteoarthritis of the knee is a leading cause of disability in elderly people, and no curative treatments exist. Early detection of osteoarthritis might help delay or prevent the onset of disability later in life. We propose a rapid and robust approach for the quantitative multi-compartment assessment of knee cartilage without using either exogenous contrast agent or hardware modifications as an early screening tool for osteoarthritis.",Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping,10296235,R01AR078308,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Biochemical', 'Biological Models', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Protocols', 'Collagen', 'Collagen Fiber', 'Contrast Media', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Diagnostic', 'Discrimination', 'Early Diagnosis', 'Elderly', 'Evaluation', 'Extracellular Matrix', 'Extracellular Matrix Degradation', 'Future', 'Goals', 'Heterogeneity', 'Human', 'Hydration status', 'Image', 'Imaging Techniques', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Meniscus structure of joint', 'Meta-Analysis', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Musculoskeletal', 'Pathologic Processes', 'Patients', 'Pattern', 'Performance', 'Population', 'Process', 'Proteoglycan', 'Protocols documentation', 'Relaxation', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Screening procedure', 'Slice', 'Structure', 'T2 weighted imaging', 'Techniques', 'Therapeutic Agents', 'Thick', 'Thinness', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Validation', 'Water', 'articular cartilage', 'base', 'cartilage degradation', 'curative treatments', 'design', 'disability', 'early screening', 'efficacy evaluation', 'healing', 'human data', 'improved', 'in vivo', 'learning algorithm', 'macromolecule', 'prevent', 'reconstruction', 'repaired', 'tool', 'water environment']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,531779
"The Dynamics of Human Atrial Fibrillation Project Summary  Atrial fibrillation (AF) is a major arrhythmia worldwide, causing palpitations, stroke and mortality, and affecting 2-5 million Americans. Unfortunately, therapy to eliminate AF has had limited success. In our last funding cycle, we focused on localized drivers as potential AF mechanisms. Mapping of drivers has now been validated by concurrent optical mapping of human AF, and their features and have been validated by several other methods in patients. Nevertheless, ablation results for these and other proposed mechanisms for AF outside the pulmonary veins are mixed. It is unclear if this reflects difficulties of AF mapping, or different mechanisms between patients.  The project will develop a novel mechanistic framework for AF that simplifies existing indices by building on scientific consensus that organized AF is easier to treat, and disorganized AF has worse prognosis. This concept spans many existing indices and may help to reconcile them. We have 3 specific aims: (1) To define if the impact of ablation depends on the extent of organizing surrounding the ablation site; (2) To establish candidate mechanisms for organized and disorganized AF zones in individual patients with specific profiles, using machine learning applied to known cases with and without ablation success in our large registry. This comprises detailed AF maps during ablation and after Maze surgery, clinical data and outcomes. (3) To use novel clinical tools to predict whether patients will respond to PVI, other ablation or Maze surgery based on whether targeted regions control larger atrial areas and their locations.  This study will deliver immediate translational and clinical impact, and directly enable personalized medicine for AF ablation. We use detailed clinical mapping in patients, signal processing and computer modeling to develop a novel mechanistic framework and widely applicable clinical tools. We will use tools including machine learning and statistics to classify mechanisms based upon outcomes from ablation in individual patients. We will make our data and code available online. Our team is experienced in electrophysiology, computer science, machine learning, biological physics and statistics. The proposal is thus highly feasible. The Dynamics of Human Atrial Fibrillation Narrative Atrial fibrillation (AF) is an enormous public health problem in the United States, affecting 2-5 million Americans and causing rapid heart beats, stroke, heart failure or death. In this project, the applicant will develop a novel framework to better understand human AF that builds on agreement between several concepts for the disease. The applicant will develop strategies to identify AF patients who will best respond to each of several therapies, to guide personalized therapy.",The Dynamics of Human Atrial Fibrillation,10220109,R01HL083359,"['Ablation', 'Acute', 'Address', 'Affect', 'Agreement', 'American', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological', 'Biometry', 'Body Surface', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Computer Models', 'Consensus', 'Data', 'Data Element', 'Disease', 'Electrocardiogram', 'Electrophysiology (science)', 'Fibrosis', 'Funding', 'Goals', 'Heart', 'Heart Atrium', 'Heart failure', 'Human', 'Image', 'Individual', 'Intervention', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Observational Study', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Palpitations', 'Paper', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Physics', 'Prediction of Response to Therapy', 'Procedures', 'Prognosis', 'Public Health', 'Pulmonary veins', 'Registries', 'Right atrial structure', 'Rotation', 'Schools', 'Site', 'Statistical Data Interpretation', 'Stroke', 'Structural defect', 'Techniques', 'Testing', 'Time', 'Tissues', 'United States', 'United States National Institutes of Health', 'Work', 'base', 'clinical application', 'cohort', 'computer science', 'demographics', 'digital', 'experience', 'genomic data', 'hands-on learning', 'indexing', 'individual patient', 'insight', 'mortality', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'patient stratification', 'personalized medicine', 'prevent', 'prospective', 'response', 'signal processing', 'statistics', 'success', 'therapy development', 'tool']",NHLBI,STANFORD UNIVERSITY,R01,2021,731282
"Tissue-specific protein interactome mapping in a vertebrate embryo Abstract Proteins rarely act in isolation, but rather function in multi-protein complexes. Accordingly, protein-protein interactomes are exceptionally valuable resources that provide deep mechanistic insights and generate myriad hypotheses. Current methods for interactome mapping, such as affinity purification mass-spectrometry (APMS), are extremely difficult to deploy in vivo, so little comprehensive interactome data yet exists for developing embryos and even less for specific tissues within embryos. This fact poses an especially acute problem for understanding highly dynamic processes in which post-transcriptional controls dominate, for example collective cell movements. Here, we will use tissue engaged in convergent extension, a crucial collective movement that elongates the axis of animal embryos, to test the efficacy of new label-free interactome mapping approaches. Successful completion of the project will therefore be significant both for developing broadly applicable new methods and also for providing systems-level insights into a disease- relevant, vertebrate collective cell movement. Project Narrative: This study centers on developing novel methods for systematically identifying protein-protein interactions in embryos. To explore the utility of the method, we focus our efforts on proteins involved in collective cell movements called convergent extension, which are governed by the planar cell polarity (or PCP) proteins. These experiments will be significant because defects in PCP proteins or convergent extension lead to “neural tube defects” such as spina bifida and anencephaly, as well as congenital skeletal dysplasias.",Tissue-specific protein interactome mapping in a vertebrate embryo,10271281,R21HD103882,"['Actomyosin', 'Acute', 'Adhesions', 'Affinity Chromatography', 'Amphibia', 'Anencephaly and spina bifida X linked', 'Animals', 'Biological', 'Cadherins', 'Cells', 'Cellular biology', 'Communities', 'Data', 'Data Set', 'Defect', 'Developmental Biology', 'Developmental Process', 'Disease', 'Dorsal', 'Embryo', 'Fractionation', 'Genetic', 'In Vitro', 'Label', 'Lead', 'Light', 'Machine Learning', 'Mammals', 'Mass Spectrum Analysis', 'Mesoderm', 'Methods', 'Modeling', 'Molecular', 'Movement', 'Multiprotein Complexes', 'Neural Tube Closure', 'Neural Tube Defects', 'Post-Transcriptional Regulation', 'Process', 'Protein Interaction Mapping', 'Protein-Protein Interaction Map', 'Proteins', 'Proteome', 'Proteomics', 'Rana', 'Resources', 'Sampling', 'Spectrometry', 'System', 'Testing', 'Tissues', 'Vertebrates', 'Work', 'Xenopus', 'base', 'cell motility', 'convergent extension', 'data integration', 'efficacy testing', 'embryo tissue', 'experimental study', 'improved', 'in vivo', 'insight', 'novel', 'planar cell polarity', 'protein complex', 'protein protein interaction', 'skeletal dysplasia', 'success', 'vertebrate embryos']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",R21,2021,191690
"Development and validation of MRI mapping of brain oxygen metabolism for clinical use The objective of this proposed research is to develop a noninvasive, challenge-free, and widely available method for quantitative mapping of cerebral oxygen extraction fraction (OEF). As the brain continuously consumes 20% of the total oxygen supply, oxygen deficiency easily causes severe brain tissue damages as in hypoxia in ischemia in stroke and Alzheimer's disease. Regional OEF is an essential, direct biomarker for tissue viability and function and highly desired for evaluating and stratifying treatments in these neurologic disorders. Widely distributed MRI provides the potential to overcome the 15O PET, the current reference standard but clinically not used due to its limited availability. In MRI, quantitative mapping of OEF requires estimating deoxyheme concentration [dH] from the MRI signal. Three major approaches have been proposed to estimate [dH] from MRI magnitude signal. However, they commonly suffer from poor sensitives and burdensome data acquisition schemes as the MRI magnitude signal which they utilize has a complex dependence on [dH]. Consequently, no MRI-based OEF mapping has been routinely used in clinical setting. Furthermore, none of these methods have been validated against the current reference standard, 15O PET.  Recently, we developed a promising, novel, non-invasive MRI-based OEF method that requires no vascular challenge and utilizes a single routine MR sequence. By integrating quantitative susceptibility mapping (QSM) modeling of often neglected MRI phase signal and quantitative blood oxygenation level dependent (qBOLD) modeling of MRI magnitude signal, our model (QSM+qBOLD=QQ) can distinguish deoxyheme iron in venous vasculature from diffusive other susceptibility sources. In our preliminary data, QQ has been validated against 15O-PET in healthy adults and showed OEF abnormalities in ischemic stroke, multiple sclerosis, and brain tumor. However, for clinical use, data acquisition and processing scheme of QQ should be improved to ensure the accuracy of OEF as a lack of data at short echo time and a non-optimal signal modeling with gradient-based solvers in current setting hinders the accurate OEF estimation.  In this K99/R00 project, we will establish a clinically readily applicable MRI toolset for quantitative OEF mapping, which is validated and available to every MRI scanner, by improving QQ. We will achieve this through 4 specific aims. Aim1. Develop optimal data acquisition for MRI-OEF mapping. Aim 2. Develop data processing algorithms for robust OEF estimation. Aim 3. Perform technical validation of MRI-OEF against 15O PET. Aim 4. Perform clinical validation of MRI-OEF in patients with intracranial stenosis. Our experience and preliminary data give us confidence that we will very likely succeed this this proposed project. In a timely fashion, the project will lead to a novel, validated, non-invasive, challenge-free, routinely usable and quantitative MRI OEF mapping, offering the potential to replace invasive, complicated current standard 15O PET OEF. This tool will lead to better understanding and management of neurovascular disorders, e.g. stroke. The proposed research will develop a non-invasive, challenge-free, widely available imaging method to map cerebral oxygen extraction fraction (OEF), a direct biomarker for tissue viability and essential for patient care strategies. Successful development will lead to easily and widely usable tool for quantitative mapping of OEF, which can be routinely used on all 3T MRI scanners to study brain functions and neurologic disorders including stroke.",Development and validation of MRI mapping of brain oxygen metabolism for clinical use,10283579,K99NS123229,"['Adult', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Blood', 'Blood Vessels', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Cerebrum', 'Clinical', 'Complex', 'Consumption', 'Data', 'Dependence', 'Development', 'Diffuse', 'Disease', 'Elderly', 'Ensure', 'Formulation', 'Functional Magnetic Resonance Imaging', 'Future', 'Gases', 'Gaussian model', 'Half-Life', 'Hour', 'Hypoxia', 'Image', 'Infarction', 'Inhalation', 'Institution', 'Intracranial Arterial Stenosis', 'Iron', 'Ischemia', 'Ischemic Stroke', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Metabolism', 'Methods', 'Modeling', 'Multiple Sclerosis', 'Noise', 'Oxygen', 'Participant', 'Patient Care', 'Patients', 'Phase', 'Positron-Emission Tomography', 'Predisposition', 'Property', 'Reference Standards', 'Research', 'Sampling', 'Scheme', 'Severity of illness', 'Signal Transduction', 'Site', 'Source', 'Speed', 'Stroke', 'Techniques', 'Time', 'Tissue Viability', 'Tissues', 'Tracer', 'Validation', 'Venous', 'Weight', 'base', 'blood oxygen level dependent', 'brain tissue', 'cerebral atrophy', 'clinical practice', 'computerized data processing', 'data acquisition', 'deep learning', 'experience', 'imaging modality', 'improved', 'neglect', 'nervous system disorder', 'neurovascular', 'new technology', 'novel', 'quantitative imaging', 'radioligand', 'simulation', 'tissue biomarkers', 'tool']",NINDS,WEILL MEDICAL COLL OF CORNELL UNIV,K99,2021,100560
"Integrative analysis of genomics and imaging data from the BRAIN Initiative and other public data sources Constructing an integrated picture of human brain function requires understanding how the effects of molecular and genetic factors propagate upwards, through many intervening layers of structure and interaction, to influence behavioral, psychiatric and cognitive traits. Projects such as the BRAIN Initiative (BI) recognize that building such a picture requires the convergent efforts of experts across genetics, genomics, neuroscience, and clinical studies, and have created resources to aid the integration of data from these disciplines. However, the challenge of combining experimental methods and theoretical models spanning vast length/time scales remains significant. One of the more promising avenues of addressing this challenge is the use of interpretable deep-learning approaches to learn high-dimensional structure inherent in data. By embedding constraints from known biological structure, investigators can relate the models’ internal representations to identifiable factors from neuroscience. This proposal will draw on the extensive resources in BI archives, along with other public resources, to integrate data from genetics, functional genomics, and neuroimaging. Through secondary analysis on this data we will build deep, multilevel polygenic models of high-level traits, such as cognitive, affective and psychiatric traits. We will trace the mechanisms underlying such traits to specific regions, cell types, functional connectivity patterns and structural imaging features. Additionally, by embedding biological structure at intermediate levels (tissue and cell-type gene regulatory networks; structural/functional constraints from MRI data), we will build models that improve on additive heritability measures of polygenic risk. In the process, we will harmonize BI data with other publicly available brain omics and imaging datasets. We will deposit all resources and models into relevant BI archives. The proposal is framed as follows. First, we will combine genetics with genomics-based networks from multiple brain regions and cell types, and develop predictive models of region- and cell-type-specific omics variation. These will be included in an interpretable deep model of cognitive and psychiatric traits (Aim 1). Second, we will learn predictive models of structural and functional imaging features from genetic predictors, which will likewise be embedded in interpretable deep models of high-level traits (Aim 2). Third, an integrated, polygenic model will be built by combining both functional-genomics- and neuroimaging-based features, allowing the impact of both subcomponents to be assessed. Furthermore, we will extend our previous work to develop compression-based interpretability methods, which allow a network to be coarse-grained and interpreted at varying levels of resolution. Such interpretation will include the exploration of subphenotypic structure in psychiatric disorders and interactions between traits (Aim 3). We expect the proposed approach to have wide-ranging implications, including insights into mechanistic underpinnings of brain function, new frameworks for integrative multilevel analysis, and the development of methods and resources for future research. Although cognitive, behavioral and psychiatric traits all exhibit substantial amounts of heritability, knowledge of the mechanisms by which genetic variation is linked to such traits remains limited, partly because of the difficulty in building models reflecting the many levels of structure in the human brain across which genetic variation is filtered. We propose to develop an interpretable deep-learning framework to allow data across genetics, functional genomics, and neuroimaging domains to be combined in learning deep, multilevel polygenic models of high-level traits, while harmonizing data across BRAIN Initiative and other large-scale resources. Our predictive modeling framework will embed known and learned biological structural constraints, and permit investigators to relate the models’ internal representations to desired levels of analysis, by developing network-compression based coarse-graining and interpretability methods.",Integrative analysis of genomics and imaging data from the BRAIN Initiative and other public data sources,10190025,RF1MH123245,"['Address', 'Adult', 'Affective', 'Archives', 'Atlases', 'Autopsy', 'BRAIN initiative', 'Behavioral', 'Biological', 'Brain', 'Brain Diseases', 'Brain region', 'Cells', 'Clinical Research', 'Cognitive', 'Collection', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Deposition', 'Discipline', 'Exhibits', 'Functional Imaging', 'Future', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Grain', 'Heritability', 'Human', 'Image', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Length', 'Link', 'Magnetic Resonance Imaging', 'Measures', 'Mental disorders', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Genetics', 'Network-based', 'Neurosciences', 'Pattern', 'Phenotype', 'Polygenic Traits', 'Process', 'Regulator Genes', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Structural Models', 'Structure', 'Techniques', 'Theoretical model', 'Thick', 'Time', 'Tissues', 'Twin Multiple Birth', 'Variant', 'Work', 'base', 'behavior influence', 'biobank', 'brain cell', 'cell type', 'connectome', 'data harmonization', 'data integration', 'deep learning', 'design', 'functional genomics', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genomic data', 'high dimensionality', 'human disease', 'improved', 'in vivo', 'insight', 'interest', 'method development', 'model building', 'multilevel analysis', 'neural circuit', 'neuroimaging', 'phenomics', 'phenotypic data', 'predictive modeling', 'psychologic', 'repository', 'secondary analysis', 'trait']",NIMH,YALE UNIVERSITY,RF1,2021,1309909
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,10129203,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'human model', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,336445
"Resolving and understanding the genomic basis of heterogeneous complex traits and diseases Parent grant Resolving and understanding the genomic basis of heterogeneous complex traits and diseases. Hundreds of genomics studies have exposed major gaps in our understanding of the mechanistic relationships between genomic variation, cellular processes, tissue function, and trait variation. The goal of the parent project is to develop a suite of computational frameworks that integrate massive collections of genomic and biomedical data to make the following three advances: Direction 1: Discern and leverage mechanism-based subtypes of complex traits and diseases. Direction 2: Characterize physiology and disease along the human lifespan and across the sexes. Direction 3: Find analogous contexts in model organisms for studying human traits/diseases. As demonstrated by us and others, genome-wide molecular networks are grand unifiers of molecular data and knowledge, and serve as powerful tools to contextually understand the roles genes play in cellular pathways, tissue physiology, phenotype/disease mechanisms, and drug action. Hence, a central aspect of our parent project is to develop multiple machine learning approaches to leverage molecular networks to generate accurate, testable hypotheses about the roles genes play in defining subtypes, age/sex differences, and cross-species analogs of a range of complex disorders.  As part of this work, we have developed GenePlexus github.com/krishnanlab/GenePlexus, an open source software to run and benchmark our state-of-the-art approach for combining genome-scale networks with supervised machine learning (ML) to get accurate novel predictions about various gene attributes (e.g., pathway membership or disease association; Liu*, Mancuso*, et al., 2020 Bioinformatics). Similarly, our group has committed efforts to make all our other computational methods available to the broader biomedical research community in the form of software tools for open science. We have released such software with nearly all our papers. Other recent examples include: ● PecanPy github.com/krishnanlab/PecanPy for parallelized, efficient, and accelerated node2vec. ● Expresto github.com/krishnanlab/Expresto for imputing unmeasured genes in transcriptomes. ● Txt2Onto github.com/krishnanlab/Txt2Onto for annotating –omics samples based on free-text metadata. Goal of the supplement project and current prototype GenePlexus: A cloud platform for network-based machine learning The goal of the proposed supplement is to take our software development to the next level by a building a new cloud-based GenePlexus platform to enable: i) biomedical/experimental researchers to seamlessly take advantage of network-based ML to generate interpretable genome-wide predictions, and ii) computational researchers to run network-based ML, retrieve results, and integrate with existing data analysis workflows. The project team, which includes the PI, a postdoc trained in cloud computing, and two professional software engineers – has worked together over the past six months to develop a prototype of the GenePlexus platform (in the form of a web-server mounted on Microsoft Azure; Fig. 1). Figure 1: Screenshots of the current prototype of the GenePlexus webserver that implements our original GenePlexus software github.com/krishnanlab/GenePlexus. When a user uploads a geneset, GenePlexus creates a virtual machine that trains a ML model, leveraging pre-saved data. In addition to predicting genes in the network functionally similar to the user-supplied genes, GenePlexus provides enables the user to interpret the custom-built ML model in terms of its similarity to thousands of models that were trained to predict genes associated with biological processes (from Gene Ontology) and diseases (from DisGeNET). In addition to retrieving the prediction results in multiple convenient formats, users can visualize the top predicted genes as a network graph. Narrative We are proposing to bring together two powerful approaches in biomedical data science – genome-scale network analysis and supervised machine learning (ML) – in the form of a cloud platform called GenePlexus. This platform will enable both biologists and bioinformaticians to easily perform network-based ML on massive genome-scale molecular networks and get novel interpretable predictions about gene attributes of interest. This work represents a significant step towards making AI more accessible to all researchers and labs and will help us and the community learn general design principles and best practices for running, storing, retrieving, and sharing ML models and results.",Resolving and understanding the genomic basis of heterogeneous complex traits and diseases,10406616,R35GM128765,"['Address', 'Animal Model', 'Architecture', 'Benchmarking', 'Bioinformatics', 'Biological Process', 'Biomedical Research', 'Cell physiology', 'Cloud Computing', 'Collection', 'Communication', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Graph', 'High Performance Computing', 'Hour', 'Human', 'Hypertension', 'Information Networks', 'Knowledge', 'Longevity', 'Machine Learning', 'Memory', 'Metadata', 'Modeling', 'Molecular', 'Nature', 'Network-based', 'Neurosciences', 'Ontology', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Physiology', 'Play', 'Postdoctoral Fellow', 'Privacy', 'Processed Genes', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Security', 'Services', 'Sex Differences', 'Software Engineering', 'Software Tools', 'Text', 'Tissues', 'Training', 'Variant', 'Work', 'analog', 'autism spectrum disorder', 'base', 'biomedical data science', 'cloud based', 'cloud platform', 'computational suite', 'computer framework', 'computing resources', 'cost', 'data structure', 'design', 'disease phenotype', 'drug action', 'experience', 'genome-wide', 'genomic variation', 'improved', 'interest', 'large datasets', 'learning community', 'molecular scale', 'novel', 'open data', 'open source', 'parent grant', 'parent project', 'prototype', 'sex', 'skills', 'software development', 'supervised learning', 'tool', 'trait', 'transcriptome', 'virtual machine', 'web server']",NIGMS,MICHIGAN STATE UNIVERSITY,R35,2021,234750
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,10151580,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,610412
"Genomic Insights into Human Population Mixture and its Role in Adaptation and Disease Project Summary  Recent studies have shown that population mixture (or `admixture') is pervasive throughout human evolution and has played a major role in shaping human genetic and phenotypic variation. Despite the ubiquity and importance of population mixture, we still lack adequate methods to characterize the impact of admixture on a genomic scale and leverage this information for effective gene mapping. Addressing these topics is the central focus of research in my lab. In this proposal, our goal is to develop new methods to reconstruct fine-scale genomic ancestry in admixed groups and leverage this information to identify novel disease and adaptive mutations and genes. The application of these methods to large genomic surveys will help to discover novel disease and adaptive variants.  The first step in characterizing the genomic impact of admixture is to infer the ancestry of each chromosomal segment, referred to as local ancestry. Towards this goal, we are developing new methods for local ancestry inference using machine-learning approaches that are ideally suited for classification problems and computationally tractable for large datasets. Our preliminary results show that our method is highly accurate and applicable across a range of demographic models. With reliable local ancestry inference, we will be well placed to study the impact of admixture on disease architecture and evolution of complex traits. We propose to use Admixture Mapping, a method to identify disease associations by leveraging ancestry differences across the genome, between cases and controls or among cases alone. By applying Admixture Mapping to complex admixed groups like South Asians and Latinxs, we aim to discover new population- specific disease associations and advance our understanding of disease architecture. Further, we will develop a novel method to leverage the demographic history of admixed groups to identify adaptive variants. By applying the method to study selection at various timescales in human evolution, we will uncover candidate genes and pathways related to adaptive gene flow and characterize its role in shaping human genetic variation. Finally, we will build reference-free ancestral genomes by recovering chromosomal segments of our lost ancestors hidden in admixed genomes. We will use these genomes to reconstruct the demographic history of our ancestors, as well as understand the fitness effects of population mixtures and the phenotypic legacy of our extinct ancestors.  The successful completion of the proposed project will provide new statistical tools to leverage patterns of admixture to perform effective disease mapping and evolutionary inference in diverse, admixed groups. Application of these methods to large-scale genomic datasets will provide insights into the genetic, evolutionary, and functional impact of admixture during human evolution. Algorithms proposed here will be implemented in freely available software for use by other researchers. Project Narrative Although population mixture or admixture is pervasive through human evolution, we still lack adequate statistical methods to study its functional and evolutionary impact. Our goal in this proposal is to develop a suite of computational methods to characterize the local genomic structure of admixed populations and use this information for a range of applications from gene mapping to reconstructing ancestral genomes. These tools will help to analyze data from admixed groups as efficiently as homogeneous populations, and provide novel insights into the genetic and phenotypic legacy of admixture in human evolution.",Genomic Insights into Human Population Mixture and its Role in Adaptation and Disease,10276371,R35GM142978,"['Address', 'Admixture', 'Algorithms', 'Architecture', 'Candidate Disease Gene', 'Chromosome Mapping', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genetics', 'Latinx', 'Machine Learning', 'Methods', 'Modeling', 'Mutation', 'Pathway interactions', 'Pattern', 'Phenotype', 'Play', 'Population', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Shapes', 'South Asian', 'Statistical Methods', 'Surveys', 'Variant', 'admixture mapping', 'case control', 'computational suite', 'fitness', 'genomic data', 'insight', 'large datasets', 'novel', 'structural genomics', 'tool', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R35,2021,376839
"Dominance on the human genome and non-additive polygenic models for predicting complex traits Project Abstract Dominance is one of the most fundamental concepts in genetics and has many key implications in population genetics, as it ultimately determines how selection manifests in a population. However, despite its unarguable importance, dominance is also one of the least characterized quantities in genetics, especially in humans, with the major challenge being current methods cannot distinguish dominance from the fitness effect of genomic variants. This proposed K99/R00 work will systematically address this longstanding problem from a dual- perspectives, by inferring dominance in humans and quantitatively model its role in shaping the phenotypes of complex traits and diseases. Specifically, in Aim1, I will develop a powerful machine learning-based method to infer the realistic distribution of dominance on the human genome in megabase-scale, leveraging archaic introgressed ancestry in non-African populations that is sensitive to dominance variation in genomic regions. In Aim 2, I will develop non-additive polygenic models accounting for dominance in full genomic regions to identify complex traits profiled in UK Biobank that deviate from additive models, improve the accuracy of phenotype and disease risk predictions, and contribute to an in-depth understanding of complex trait biology. Finally, in Aim 3 (R00 phase), I will extend these approaches to infer dominance variation in worldwide populations and investigate how dominance, combined with selection and admixture, determines complex trait phenotypes in diverse human populations. The mentored phase of this work will take place at the Department of Ecology and Evolutionary Biology at UCLA, where Dr. Zhang will have access to rich training opportunities and be supported by active scientific communities, including numerous seminar series, journal clubs, and networking activities. Dr. Kirk Lohmueller (primary mentor) and Dr. Sriram Sankararaman (co-mentor) will train Dr. Zhang in computational and statistical methods in population genetics, machine learning applications, and large-scale disease association data analysis. The research trainings, collaborations, and professional development during the K99 phase will assist Dr. Zhang in becoming an independent investigator in human population genetics. Project Narrative Dominance plays a vital role in human evolutionary genetics both in terms of its fitness effect on functional genomic variants and how it shapes complex trait phenotypes, while its distribution on the human genome and biological effects on complex traits are poorly characterized. This work will fill a critical knowledge gap by producing a complete picture of dominance distribution in humans, which will shed a light into many unsolved questions in genetics, including the evolution of dominance. This work will further provide comprehensive statistical frameworks to model the relationship between dominance and complex trait phenotypes, which will substantially improve the transferability of biomedical applications in historically understudied populations, including disease risk prediction and the development of precision medicine.",Dominance on the human genome and non-additive polygenic models for predicting complex traits,10283330,K99GM143466,"['Accounting', 'Address', 'Admixture', 'Affect', 'Biological', 'Biology', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Data Analyses', 'Demography', 'Development', 'Disease', 'Ecology', 'European', 'Evolution', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Human', 'Human Genome', 'Individual', 'Journals', 'Knowledge', 'Light', 'Machine Learning', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'Modernization', 'Mutation', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Play', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Series', 'Shapes', 'Statistical Methods', 'Study Subject', 'Testing', 'Training', 'Variant', 'Work', 'base', 'biobank', 'disorder risk', 'experience', 'fitness', 'functional genomics', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'human population genetics', 'improved', 'insight', 'machine learning method', 'novel', 'polygenic risk score', 'precision medicine', 'predictive modeling', 'risk prediction', 'simulation', 'training opportunity', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,K99,2021,82828
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10251375,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'open source tool', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2021,700000
"Development of machine learning software to quantitatively map telomere induced senescence in tissue sections during aging PROJECT SUMMARY/ABSTRACT Cellular senescence is a pillar of aging, acting as a key driver of aging and age-related diseases. Telomeres play a major role in cellular senescence. When telomeres become critically short or damaged, they elicit a DNA damage response (DDR) that drives senescence. Our laboratory developed sophisticated methods to detect senescent cells in tissues based on the co-localization between telomeres and the DDR. Furthermore, we recently developed SenoQuant, a software that simplifies the measure of Telomere associated foci (TAF), reducing quantification time from weeks to hours. We now propose to apply emerging technologies such as machine learning and deep learning to map TAF more accurately and robustly in human tissue sections. This will address several challenges inherent to TAF analysis, including nuclei detection, staining artifacts, and quantification time. Furthermore, in collaboration with the Tissue Mapping Centers we will tailor SenoQuant to the analysis of specific human tissues. Finally, we propose to integrate TAF with multiplexed imaging methods such as Imaging Mass Cytometry (IMC), allowing the detection of multiple senescence markers in tissues simultaneously. We anticipate that this technology will greatly advance the spatially-resolved mapping of senescent cells in human tissues and will be a great resource for the aging and cell senescence community. PROJECT NARRATIVE This project will contribute to fundamental knowledge about the nature and distribution of senescent cells in human tissues during the aging process. Specifically, it will generate cutting- edge technology that will allow the reliable mapping of senescent cells across multiple tissues. This technology will not only assist the generation of a human atlas of senescence but also have great potential in clinical practice as a prognostic tool, as a measure of biological age as well as efficacy of treatments.",Development of machine learning software to quantitatively map telomere induced senescence in tissue sections during aging,10376395,UG3CA268103,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Atlases', 'Biological', 'Biopsy', 'Cell Aging', 'Cell Nucleus', 'Cells', 'Chronic', 'Collaborations', 'Communities', 'Computer software', 'Computing Methodologies', 'Cytometry', 'DNA Damage', 'Data', 'Detection', 'Development', 'Disease', 'Emerging Technologies', 'Fluorescence Microscopy', 'Functional disorder', 'Generations', 'Hour', 'Human', 'Image', 'Impairment', 'Intervention', 'Knowledge', 'Laboratories', 'Length', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mitochondria', 'Morphologic artifacts', 'Mus', 'Nature', 'Phenotype', 'Play', 'Process', 'Proteins', 'Research', 'Resources', 'Role', 'Signal Transduction', 'Signaling Protein', 'Spatial Distribution', 'Stains', 'Suspensions', 'Technology', 'Time', 'Tissues', 'Treatment Efficacy', 'age related', 'base', 'clinical practice', 'deep learning', 'extracellular', 'human tissue', 'imaging modality', 'innovation', 'innovative technologies', 'insight', 'learning network', 'microscopic imaging', 'multiplexed imaging', 'neural network', 'next generation', 'prognostic tool', 'response', 'senescence', 'single cell technology', 'telomere', 'tissue resource']",NCI,MAYO CLINIC ROCHESTER,UG3,2021,556500
