text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,10244996,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Pooling', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data infrastructure', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phenotyping algorithm', 'phrases', 'portability', 'preservation', 'privacy preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2021,1487619
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10136739,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2021,496453
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,10132284,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,576876
"A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications PROJECT SUMMARY/ABSTRACT  In radiology practices, timely and accurate formulation of reports is closely linked to patient satisfaction, physician productivity, and reimbursement. While the American College of Radiology and the Radiological Soci- ety of North America have recommended implementation of structured reporting to facilitate clear and consistent communication between radiologists and referring clinicians, cumbersome nature of current structured reporting systems made them unpopular amongst their users. Recently, the emerging techniques of deep learning have been widely and successfully applied in many different natural language processing tasks (NLP). However, when adopted in a certain speciﬁc domain, such as radiology, these techniques should be combined with extensive domain knowledge to improve efﬁciency and accuracy. There is, therefore, a critical need to take advantage of clinical NLP and deep learning to fundamentally change the radiology reporting. The long-term goal in this appli- cation is to improve the form, content, and quality of radiology reports and to facilitate rapid generation of radiol- ogy reports with consistent organization and standardized texts. The overall objective is to use radiology-speciﬁc ontology, NLP and computer vision techniques, and deep learning to construct a radiology-speciﬁc knowledge graph, which will then be used to build a reporting system that can assist radiologists to quickly generate struc- tured and standardized text reports. The rationale for this project is that through integration of new clinical NLP technologies, radiology-speciﬁc knowledge graphs, and development of new reporting system, we can build au- tomatous systems with a higher-level understanding of the radiological world. The speciﬁc aims of this project are to: (1) recognize and normalize named entities in radiology reports; (2) construct a radiology-speciﬁc knowledge graph from free-text and images; and (3) build a reporting system that can dynamically adjust templates based on radiologists' prior entries. The research proposed in this application is innovative, in the applicant's opinion, because it combines deep learning, NLP techniques, and domain knowledge in a single framework to construct comprehensive and accurate knowledge graphs that will enhance the workﬂow of the current reporting systems. The proposed research is signiﬁcant because a novel reporting system can expedite radiologists' workﬂow and acquire well-annotated datasets that facilitate machine learning and data science. To develop such a method, the candidate, Dr. Yifan Peng, requires additional training and mentoring in clinical NLP and radiology. During the K99 phase, Dr. Peng will conduct this research as a research fellow at the National Center for Biotechnology Information. He will be mentored by Dr. Zhiyong Lu, a leading text mining and deep learning researcher, and co- mentored by Dr. Ronald M. Summers, a leading radiologist and clinical informatics researcher. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Peng to achieve the career goals of becoming an independent investigator and leader in the study of clinical NLP. PROJECT NARRATIVE The proposed research is relevant to public health because it entails a new strategy to construct a radiology- speciﬁc knowledge graph to facilitate the development of a new reporting system that enables rapid generation of structured radiology reports. The proposed knowledge graph and reporting system will contribute to advancement in understanding of the radiological world, and promise to enhance clinical communication and patient-centric care. Thus, the proposed research is relevant to the part of the NLM's mission that pertains to applying deep knowledge of clinical terminology and natural language processing to improve clinical data science and health services.",A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications,10224953,R00LM013001,"['Address', 'Adopted', 'American College of Radiology', 'Award', 'Biotechnology', 'Caring', 'Client satisfaction', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communication', 'Complex', 'Computer Vision Systems', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Formulation', 'Generations', 'Goals', 'Health Services', 'Hospitals', 'Hybrids', 'Image', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Mission', 'Modeling', 'Mus', 'Names', 'Natural Language Processing', 'Nature', 'Nomenclature', 'North America', 'Ontology', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Physicians', 'Picture Archiving and Communication System', 'Process', 'Productivity', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resort', 'Societies', 'Standardization', 'Structure', 'System', 'Systems Development', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Voice', 'Writing', 'base', 'career', 'career development', 'convolutional neural network', 'deep learning', 'deep neural network', 'impression', 'improved', 'innovation', 'knowledge graph', 'lexical', 'long short term memory', 'neural network', 'neural network architecture', 'novel', 'radiologist', 'repository', 'response', 'syntax', 'text searching']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,R00,2021,236549
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,10139100,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2021,20000
"Scientific Questions: A New Target for Biomedical NLP Project Summary  Natural language processing (NLP) technology is now widespread (e.g. Google Translate) and has several important applications in biomedical research. We propose a new target for NLP: extraction of scientific questions stated in publications. A system that automatically captures and organizes scientific questions from across the biomedical literature could have a wide range of significant impacts, as attested to in our diverse collection of support letters from researchers, journal editors, educators and scientific foundations. Prior work focused on making binary (or probabilistic) assessments of whether a text is hedged or uncertain, with the goal of downgrading such statements in information extraction tasks—not computationally capturing what the uncertainty is about. In contrast, we propose an ambitious plan to identify, represent, integrate and reason about the content of scientific questions, and to demonstrate how this approach can be used to address two important new use cases in biomedical research: contextualizing experimental results and enhancing literature awareness. Contextualizing results is the task of linking elements of genome-scale results to open questions across all of biomedical research. Literature awareness is the ability to understand important characteristics of large, dynamic collections of research publications as a whole. We propose to produce rich computational representations of the dynamic evolution of research questions, and to prototype textual and visual interfaces to help students and researchers explore and develop a detailed understanding of key open scientific questions in any area of biomedical research. Project Narrative The scientific literature is full of statements of important unsolved questions. By using artificial intelligence systems to identify and categorize these questions, the proposed work would help other researchers discover when their findings might address an important question in another scientific area. This work would also make it easier for students, journal editors, conference organizers and others understand where science is headed by tracking the evolution of scientific questions.",Scientific Questions: A New Target for Biomedical NLP,10223438,R01LM013400,"['Address', 'Area', 'Artificial Intelligence', 'Awareness', 'Biomedical Research', 'Characteristics', 'Collection', 'Computerized Patient Records', 'Cues', 'Data', 'Elements', 'Environment', 'Evolution', 'Expert Systems', 'Foundations', 'Genes', 'Goals', 'Gold', 'Information Retrieval', 'Journals', 'Letters', 'Link', 'Literature', 'Manuals', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Phenotype', 'Proteomics', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Signal Transduction', 'Source', 'Students', 'System', 'Taxonomy', 'Technology', 'Text', 'Time', 'Translating', 'Uncertainty', 'Update', 'Visual', 'Work', 'design', 'dynamical evolution', 'experimental study', 'genome wide association study', 'genome-wide', 'graduate student', 'high throughput screening', 'innovation', 'journal article', 'news', 'novel', 'pharmacovigilance', 'prototype', 'symposium', 'text searching', 'tool', 'transcriptome sequencing', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2021,453141
"Transfer Learning for Digital Curation of the EMR Clinical Narrative Project Summary This proposal is in response to PAR 18-796 to seek support for advancing methodologies for a transfer learning framework for the digital curation of the Electronic Medical Records (EMR) clinical narrative. In the current era of increasing importance of Artificial Intelligence (AI) in biomedicine, our proposal tackles a critical AI component – automated annotation of health-related text. Since 2015 the development and application of machine learning (ML) methods has exploded propelled by the convergence of plentiful digitized unstructured data (text, speech, images), hardware and the refinement of neural networks or deep learning. 2018 marked a turning point in Natural Language Processing (NLP), particularly transfer learning through pre-trained models like Universal Language Model Fine-tuning for Text Classification, Allen AI's ELMO, OpenAI's Open-GPT. In November 2018, Google published the Bidirectional Encodings Representations from Transformers (BERT), a transformer-based model pre-trained on massive general text databases (3.3B words total). The publication reported using BERT representations to build classifiers for 11 NLP tasks which outperformed the state-of-the- art (SOTA) with large margins. The NLP research community jumped to the idea of exploring this new framework but quickly came to the realization that building BERT-style models from scratch is affordable and feasible to only a few. Thus, research investigation proceeded in the direction of using these gigantic models as resources for language representations. Scientific efforts focused on pre-trained models (e.g. BERT) as a source of extracting high quality language features or fine-tuning on a specific task, i.e. using a model as a checkpoint and re-training with much smaller amounts of task-specific data to produce predictions by typically adding one fully-connected layer on top of the representations and training for a few epochs. This general watershed shift in NLP to transfer learning which parallels the developments in computer vision a few years ago coupled with our latest work brings to the forefront a critical NLP research topic ripe for exploration – a transfer learning framework for the digital curation of the EMR clinical narrative. The proposed work is research of novel scientific methods for extracting detailed information from health-related text especially the EMR, the major source of phenotype data for patients. Precise phenotype information is needed to advance translational research, particularly to unravel the effects of genetic, epigenetic, and systems changes on responsiveness. This research is in line with the latest developments in neural deep learning approaches and AI in general and is expected to enhance biomedical research and through that the health of the public. Project Narrative/Relevance We propose research on transfer learning methods for the digital curation of a key biomedical asset – the clinical narrative as part of the Electronic Medical Record. This research is in line with the latest developments in neural deep learning approaches and artificial intelligence in general and is expected to enhance biomedical research and through that the health of the public.",Transfer Learning for Digital Curation of the EMR Clinical Narrative,10092340,R01LM013486,"['Adverse event', 'Apache', 'Appearance', 'Area', 'Artificial Intelligence', 'Automated Annotation', 'Biomedical Research', 'Brain Aneurysms', 'Classification', 'Clinical', 'Clinical Investigator', 'Communities', 'Computer Vision Systems', 'Computerized Medical Record', 'Coupled', 'Data', 'Data Science', 'Data Set', 'Databases', 'Development', 'Disease', 'E-learning', 'Engineering', 'Epigenetic Process', 'Evaluation', 'Event', 'Genetic', 'Health', 'Hepatotoxicity', 'Image', 'Information Retrieval', 'Intuition', 'Investigation', 'Label', 'Language', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Methotrexate', 'Modeling', 'Multiple Sclerosis', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Procedures', 'Psychological Transfer', 'Public Health', 'Publications', 'Publishing', 'Rare Diseases', 'Reporting', 'Research', 'Resources', 'Rheumatoid Arthritis', 'Semantics', 'Severities', 'Signs and Symptoms', 'Source', 'Speech', 'Structure', 'Supervision', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translational Research', 'Vision', 'Work', 'autism spectrum disorder', 'base', 'comorbidity', 'computing resources', 'deep learning', 'deep neural network', 'digital', 'imaging Segmentation', 'improved', 'informatics tool', 'learning strategy', 'machine learning method', 'multitask', 'neural network', 'next generation', 'novel', 'open source', 'phenotypic data', 'relating to nervous system', 'response', 'support vector machine', 'unstructured data']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,376125
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,10126722,F31MD014941,"['Address', 'Anxiety', 'Awareness', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'provider behavior', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'substance use', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2021,46036
"CRCNS: Discovering Computational Principles of Language Processing in the Brain A critical characteristic of human language is our ability to understand multi-word sequences whose meaning is greater than the sum of their parts. Recent work from the PIs of this proposal (Toneva and Wehbe, 2019; Jain and Huth, 2018) and others (Schrimpf et al., 2020a; Caucheteux & King, 2020) has shown that cortical representations of multi-word sequences can be modeled much more accurately than before by using neural network language models, a machine learning technique that has revolutionized the natural language processing (NLP) field (Devlin et al., 2019; Radford et al., 2019). However, under the current paradigm these models must first be trained on separate NLP tasks and only then used to model the brain, creating a guess-and-check cycle that is not guaranteed to converge on the actual computations that humans perform. Here we propose to break this cycle by directly training neural network models to estimate the functions that the brain uses to combine words. To be able to optimally predict fMRI and MEG responses, these models will need to capture the composition principles governing which words the brain attends to, and how information is combined across words. These models will help uncover specific computations underlying language processing in the brain, enable computational testing of neurolinguistic theories, and inspire or directly improve models used in NLP.  Accomplishing these goals, however, will require overcoming one major obstacle. Training neural net- work language models typically requires orders of magnitude more data than existing neuroimaging datasets. To address this issue, one central goal of this proposed project is to collect a very large fMRI and MEG dataset comprising roughly one million words of natural language stimuli. We plan to use the unique dataset and computational modeling framework to address three scientific aims. Aim 1: Create brain activity prediction benchmarks to foster interaction between neuroscience and NLP. Aim 2: Use data-driven models to test existing neurolinguistic theories & develop new accounts of the computations underlying word composition in the brain. Aim 3: Leverage information in different brain areas to help solve computationally defined language tasks.  Successful completion of the proposed work will provide mechanistic insight into language processing, with a computational architecture tracing information flow among brain areas and describing the tasks they perform. Beyond its basic cognitive neuroscience implications, we expect this work will enable better understanding of language impairments and help identify targeted therapies. RELEVANCE (See instructions): Through collecting, analyzing, and disseminating large-scale neuroimaging datasets collected while participants listen to natural, narrative speech, this proposal aims to improve our understanding of the normal function of the language system. Specifically, this work seeks to improve and validate computational models of speech language processing in the human brain. n/a",CRCNS: Discovering Computational Principles of Language Processing in the Brain,10395748,R01DC020088,"['Address', 'Affect', 'Architecture', 'Area', 'Benchmarking', 'Brain', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Epilepsy', 'Excision', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Instruction', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Neurosciences', 'Participant', 'Patient-Focused Outcomes', 'Psychological Transfer', 'Research', 'Research Personnel', 'Resolution', 'Running', 'Speech', 'Stimulus', 'Sum', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Work', 'brain surgery', 'cognitive neuroscience', 'driving force', 'experimental study', 'improved', 'in silico', 'innovation', 'insight', 'language impairment', 'language processing', 'multitask', 'natural language', 'neural network', 'neuroimaging', 'post stroke', 'response', 'targeted treatment', 'theories', 'therapy design', 'tumor']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,389252
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,10144364,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,805312
"Extended Methods and Software Development for Health NLP Project Summary Our program vision is to unravel the information buried in health-related narratives by advancing text-processing methods in a unified way across all the genres of health texts and distributing them through an advanced NLP software platform under solid governance and sustainability. The crosscutting theme is the investigation of methods for health NLP made possible by big data, fused with health knowledge. The underlying theme of this renewal is the development of methods towards generalizable, efficient and knowledge-rich models in the context of modern machine learning techniques, particularly models implementing attention mechanisms and using large unlabeled datasets. There is growing penetration of deep learning approaches in the field of health natural language processing. Our proposal aims to address critical methodological gaps and understudied areas in the current unprecedented fast-paced environment. Therefore, our renewal lays out novel and much needed explorations of health NLP research which we will advance through our specific aims. Our datasets will continue to span the spectrum of health-related data – Electronic Medical Records clinical narrative, patient-authored on- line community posts, and health-related social media. The evaluation of the methods we will develop will be performed on the key clinical tasks of concept extraction, relation extraction, and phenotyping with comparisons to other traditional or deep learning algorithms as baselines. We will demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine. Finally, we will disseminate our work through community activities to advance the state of the art in health natural language processing. Project Narrative There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,10209178,R01GM114355,"['Address', 'Adult', 'Algorithms', 'Apache', 'Area', 'Attention', 'Big Data', 'Childhood', 'Clinical', 'Communities', 'Community Health', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Set', 'Detection', 'Development', 'Environment', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Health', 'Healthcare', 'Information Retrieval', 'Institution', 'Investigation', 'Joints', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Ontology', 'Patients', 'Penetration', 'Personal Satisfaction', 'Phenotype', 'Physicians', 'Public Health', 'Publications', 'Research', 'Risk', 'Solid', 'Source', 'Supervision', 'System', 'Techniques', 'Text', 'Time', 'Training', 'Training and Infrastructure', 'Uncertainty', 'Unified Medical Language System', 'Vision', 'Work', 'commercialization', 'data streams', 'deep learning', 'deep learning algorithm', 'design', 'electronic data', 'health data', 'health knowledge', 'insight', 'learning strategy', 'medical specialties', 'method development', 'multitask', 'neural network', 'novel', 'online community', 'open source', 'point of care', 'precision medicine', 'programs', 'social media', 'software development', 'structured data', 'tool', 'translational medicine']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2021,463346
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this field typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind  admission risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modifiable risks and their associated phenotypes driving hospital  admissions; (2) using natural language processing techniques (NLP) to build classification models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to significantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close  mentoring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a  supportive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identification and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,10134412,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Disease', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'clinical center', 'clinical encounter', 'comorbidity', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'preventive intervention', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'statistical learning', 'structured data', 'supportive environment', 'trend', 'trial design', 'unstructured data']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2021,173801
"Peripheral Artery Disease: Long-term Survival & Outcomes Study (PEARLS) Project Summary/Abstract Background: Peripheral artery disease (PAD) is a common and highly morbid condition. Nearly 25% of patients die within 3 years of diagnosis, likely due to a high incidence of cardiovascular (CV) events: myocardial infarction (MI) or stroke. A significantly larger proportion experience disability due to leg pain, poor mobility and amputation. The cost of PAD-related hospital care alone exceeds $21 billion. However, research regarding long-term survival, CV, and limb outcomes in PAD and the impact of existing treatments remain limited in large part due to the poor accuracy of PAD diagnosis codes. Our team has developed a novel approach using natural language processing (NLP) to identify PAD patients with a high degree of accuracy within the Veterans Health Administration (VHA). Significance: The Peripheral Artery Disease: Long-term Survival & Outcomes Study (PEARLS) study will advance scientific knowledge for PAD in several ways. We will use our NLP tool to assemble one of the largest cohorts of PAD in the world and follow them long-term to assess the trajectory of survival and clinical outcomes, evaluate utilization of recommended treatments (medications, risk factor control and revascularization) and the association of above treatments with the above outcomes. Collectively, our work will address important gaps in PAD research and yield insights regarding strategies to improve care delivery in this high-risk population. Innovation: The use of an informatics-based method to assemble a cohort of newly diagnosed PAD patients in a large integrated health system is highly innovative. We believe that our approach for cohort identification will be transformational and promote big data analytics for research, improving care delivery, and future clinical trials. Specific Aims: A1. Develop a national cohort of Veterans with newly diagnosed PAD using a novel NLP algorithm. A2. Examine patterns of medical and invasive management and determine patient- and facility-level correlates. A3. Determine the impact of medical and invasive management of PAD on long-term outcomes. Methodology: We will implement our NLP algorithm to identify patients with new PAD diagnosis in VHA during 2015-2020 and obtain data on clinical and treatment related variables. We will follow our cohort longitudinally for mortality, CV events (MI, stroke) and limb events (amputation). We will examine utilization of PAD treatments and risk factor control, identify patient-level and hospital-level predictors of treatment using multi-level models. We will use discrete survival models to evaluate the association of PAD treatments with long-term outcomes. Implementation/Next Steps: Key deliverables will include a) an understanding of which patient groups are at greatest risk for mortality and adverse outcomes; (b) determining the relative impact of PAD treatments on long- term outcomes which can be useful for decision-making and c) an assessment of site-level variation in treatment patterns. We envision that our findings will help us develop comprehensive disease management program to improve quality of care and reduce disparities in use of effective treatments. Project Narrative Peripheral artery disease (PAD) is a common and highly morbid condition that is a major cause of leg amputation, and associated with a high risk of heart attack, stroke and death. We propose to create a large cohort of PAD patients who will be identified using a novel method developed by our research team and followed long-term to advance our understanding of the trajectory of survival and clinical outcomes in PAD and the impact of existing treatments on patient outcomes. Our work will advance PAD research and provide important insights regarding how best to improve PAD care.",Peripheral Artery Disease: Long-term Survival & Outcomes Study (PEARLS),10275610,R56HL158803,"['Address', 'Algorithms', 'American', 'Amputation', 'Ankle', 'Arteries', 'Big Data', 'Big Data Methods', 'Biometry', 'Blood Pressure', 'Blood Vessels', 'Blood flow', 'Cardiology', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Chronic Care', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Coronary Arteriosclerosis', 'Data', 'Data Element', 'Decision Making', 'Diabetes Mellitus', 'Diagnosis', 'Disease Management', 'Disease Outcome', 'Electronic Health Record', 'Epidemiology', 'Ethnic Origin', 'Event', 'Face', 'Funding', 'Future', 'Glycosylated hemoglobin A', 'Guidelines', 'Health system', 'Hospitals', 'Incidence', 'Income', 'Informatics', 'Integrated Health Care Systems', 'International Classification of Disease Codes', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Leg', 'Life Style', 'Limb structure', 'Longitudinal cohort', 'Low income', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Natural Language Processing', 'Newly Diagnosed', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Pain in lower limb', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Predictive Value', 'Primary Health Care', 'Quality of Care', 'Race', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Science', 'Scientific Advances and Accomplishments', 'Severities', 'Site', 'Specificity', 'Stroke', 'Symptoms', 'Testing', 'Toes', 'Treatment Factor', 'United States', 'Variant', 'Veterans', 'Veterans Health Administration', 'Work', 'adverse outcome', 'base', 'care delivery', 'care outcomes', 'cohort', 'comorbidity', 'cost', 'critical limb Ischemia', 'disability', 'discrete data', 'disease diagnosis', 'disparity reduction', 'effective therapy', 'ethnic minority population', 'experience', 'glycemic control', 'high risk', 'high risk population', 'improved', 'indexing', 'innovation', 'insight', 'limb amputation', 'mortality', 'mortality risk', 'multilevel analysis', 'novel', 'novel strategies', 'patient subsets', 'programs', 'stroke event', 'survival outcome', 'time use', 'tool']",NHLBI,UNIVERSITY OF IOWA,R56,2021,634307
"Leveraging linked registry and electronic health records to examine long-term patient outcomes after peripheral vascular intervention"" Leveraging linked registry and electronic health records to examine long-term patient outcomes after peripheral vascular intervention Project Summary/Abstract Peripheral arterial disease (PAD) affects over 200 million people worldwide. Peripheral vascular interventions (PVI) are the most common procedures that are performed to manage PAD. Existing randomized controlled trials (RCTs) and observational studies of patient outcomes after PVIs all had limited follow-up lengths due to difficulties in long-term data collections. In addition, heterogeneity of treatment effect (HTE) for stent placement vs. percutaneous transluminal angioplasty (PTA) alone has not been well understood with the current approach of effect modifier assessment. Real-world data (RWD), particularly registries linked with electronic health data (EHR), are useful for studying long-term outcomes after vascular procedures. However, methods for working with multiple data sources and analyzing unstructured text data are still evolving. The proposed research aims to address current evidence gaps in long-term patient outcomes after PVI procedures. This will be facilitated by innovatively apply and refine data linkage, natural language processing (NLP), and effect modifier assessment methods. Specifically, this project will link registry and EHR data to 1) examine long-term major adverse limb events after stent placement vs. PTA alone as well as assess heterogeneity of treatment effect by patient characteristics; 2) develop an NLP pipeline with machine learning methods to analyze unstructured text data and examine long-term efficacy endpoints after stent placement vs. PTA alone, and; 3) establish feasibility and updating requirements for the deployment of the NLP tool for long-term PVI outcome assessment to other institutions. To support the research activities and the transition toward independence, the candidate will undertake the following career development activities during the award period: 1) gaining an in- depth understanding of NLP and machine learning methods; 2) refining data science expertise to integrate EHR into medical device epidemiologic research; 3) strengthening knowledge in current and novel vascular disease treatment; 4) developing and improving skills in grant writing and academic leadership; 5) training in responsible conduct of research. The candidate will be mentored by a team of experts with complementary strengths in surgical and device outcomes research, natural language processing and machine learning, and vascular disease and surgery. The proposed career development and research activities will develop the candidate's skillset and expertise and lead to an R01 level application. The candidate's long-term goal is to become an independent researcher focusing on the development and application of advanced multidisciplinary methods in the evaluation of surgical and device outcomes in the vascular disease area, supporting clinical, patient, and regulatory decision-making. Project narrative The proposed research will evaluate long-term patient outcomes after peripheral vascular interventions for peripheral arterial disease and assess heterogeneity of treatment effect. These will be supported by implementing and advancing data linkage, natural language processing, and effect modifier assessment methods for vascular research. The proposed research is relevant to NIH's mission to foster fundamental knowledge generation and innovative research strategies that will ultimately help protect and improve health.","Leveraging linked registry and electronic health records to examine long-term patient outcomes after peripheral vascular intervention""",10283367,K01HL159315,"['Address', 'Adverse event', 'Affect', 'Algorithms', 'Amputation', 'Area', 'Award', 'Balloon Angioplasty', 'Blood Vessels', 'Characteristics', 'Clinical', 'Data', 'Data Analyses', 'Data Collection', 'Data Linkages', 'Data Science', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electronic Health Record', 'Evaluation', 'Event', 'Fostering', 'Generations', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Hospitals', 'Informatics', 'Institution', 'Intervention', 'Knowledge', 'Label', 'Lead', 'Leadership', 'Length', 'Lesion', 'Limb structure', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medical Device', 'Mentors', 'Methods', 'Mission', 'Natural Language Processing', 'Natural Language Processing pipeline', 'New York City', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Outcome Assessment', 'Outcomes Research', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Peripheral', 'Peripheral arterial disease', 'Predictive Value', 'Procedures', 'Quality of life', 'Radiology Specialty', 'Randomized', 'Randomized Controlled Trials', 'Registries', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Research Support', 'Sampling', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Stents', 'Symptoms', 'System', 'Text', 'Training', 'United States National Institutes of Health', 'Update', 'Vascular Diseases', 'Work', 'Writing', 'career development', 'cohort', 'electronic structure', 'epidemiology study', 'follow-up', 'health data', 'improved', 'innovation', 'interdisciplinary approach', 'machine learning method', 'multidisciplinary', 'multiple data sources', 'novel', 'patient registry', 'patient subsets', 'responsible research conduct', 'skills', 'tool', 'treatment effect', 'unstructured data']",NHLBI,WEILL MEDICAL COLL OF CORNELL UNIV,K01,2021,162252
"Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports Abstract Unexpected findings, or incidentalomas, are increasing dramatically with the growth in the use of imaging technology within healthcare organizations. Incidentalomas may indicate significant health problems, such as malignancy in the medium or long term. However, they also may lead to overinvestigation, unnecessary radiation exposure, overtreatment, substantial downstream expenditures, and patient anxiety. Several systematic reviews have explored the prevalence and outcomes of incidentalomas. These studies used inconsistent and often inappropriate synthesis methods, commonly only focusing on one imaging scan or organ in a very limited number of patients. As a result, there is need for large-scale study of incidentalomas that can inform their follow up and guide efforts to optimize health outcomes. To address this need, we propose to build natural language processing (NLP) approaches to identify cancer-related incidentalomas reported in radiology reports (Aim 1) and to create the first large-scale incidentaloma database covering over half-a-million patients (Aim 2). Our research dataset will contain radiology reports, clinical notes containing imaging orders, as well as structured data such as demographic information (e.g., age) and diagnoses codes of patients who received radiologic imaging tests in University of Washington Medical Center (UWMC), Harborview Medical Center (HMC), Seattle Cancer Care Alliance (SCCA), and Northwest Hospital and Medical Center (NWMC) between 2007-2019. Our patient population will be linked to Hutchinson Institute for Cancer Outcomes Research (HICOR) data repository for detailed cancer outcomes and claims data. The created database will be used for clinical and economic analysis of incidentalomas (Aim 3). We will (1) evaluate the concordance between radiologists' documentation of incidentaloma follow-up and established clinical guidelines for thyroid, lung, adrenal, kidney, liver, and pancreas incidentalomas, (2) determine risk of subsequent cancer diagnosis and median survival for each category of incidentaloma, and (3) determine the incremental cost associated with follow-up imaging in patients with incidentalomas. All models and their implementations produced during the execution of this project will be shared with the community as open source. Additionally, the de-identified incidentaloma database will be made available to the research community under a data use agreement. By identifying risk factors for cancer diagnosis and death for common incidental findings, we will be able to provide critical information for future clinical practice guideline development and appropriate use criteria. We assembled a highly interdisciplinary team of experts in NLP, medical informatics, radiology, oncology, health outcomes, and health economics to ensure the successful completion of the proposed project. Project Narrative Incidentalomas may indicate significant health problems, such as malignancy to the patient in the short or medium term, but also may lead to overtreatment, which comes with substantial downstream expenditures as well as patient anxiety. In this project, we will build natural language processing approaches to extract cancer related incidentalomas reported in radiology reports (Aim 1) and create the first large scale incidentaloma database for half-a-million patients who received radiologic imaging tests in University of Washington Medical Center, Harborview Medical Center, Seattle Cancer Care Alliance, and Northwest Hospital and Medical Center between 2007 and 2019 (Aim 2). This database will be used for clinical and economic analysis of incidentalomas (Aim 3).",Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports,10116614,R01CA248422,"['Abdomen', 'Active Learning', 'Address', 'Adherence', 'Adrenal Glands', 'Age', 'Agreement', 'Angiography', 'Anxiety', 'Caregivers', 'Categories', 'Cessation of life', 'Chest', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Code', 'Communication', 'Communities', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Economics', 'Ensure', 'Epidemic', 'Expenditure', 'Funding', 'Future', 'Gold', 'Growth', 'Guidelines', 'Health', 'Healthcare', 'Hospitals', 'Image', 'Imaging technology', 'Incidental Findings', 'Institutes', 'Interdisciplinary Study', 'Investigation', 'Kidney', 'Lead', 'Link', 'Liver', 'Lung', 'Lung nodule', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical Informatics', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Oncology', 'Organ', 'Outcome', 'Outcomes Research', 'Pancreas', 'Pancreatic Cyst', 'Patient Noncompliance', 'Patient risk', 'Patients', 'Performance', 'Prevalence', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Project Grants', 'Risk', 'Risk Factors', 'Running', 'Scanning', 'Semantics', 'Services', 'Technology', 'Testing', 'Text', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Universities', 'Washington', 'base', 'cancer care', 'cancer diagnosis', 'cancer risk', 'clinical database', 'cohort', 'comorbidity', 'cost', 'data repository', 'economic evaluation', 'economic impact', 'follow-up', 'health care delivery', 'health care service organization', 'health economics', 'improved', 'machine learning method', 'mortality', 'novel', 'open source', 'overtreatment', 'patient population', 'radiological imaging', 'radiologist', 'repository', 'structured data', 'surveillance imaging', 'systematic review', 'tumor']",NCI,UNIVERSITY OF WASHINGTON,R01,2021,674025
"Extraction of Symptom Burden from Clinical Narratives of Cancer Patients using Natural Language Processing Project Summary / Abstract Cancer patients frequently experience high levels of pain, tiredness, shortness of breath, decreased appetite, nausea, drowsiness, anxiety, and decreased sense of wellbeing, often related to the disease itself, its treatments, or both. This high symptom burden leads to significant impairment of cancer patients’ quality of life and may be associated with impaired survival. Optimal symptom management is required to minimize symptom burden and maximize quality of life for cancer patients throughout the course of their disease. Supportive care in cancer (SCC) teams are multidisciplinary teams that are focused on the prevention and management of the adverse effects of cancer and its treatments across the continuum of the cancer experience from diagnosis through treatment and beyond. These teams typically lack the resources to see all cancer patients and need to prioritize patients with the highest need, often relying on oncology physicians for referral. However, oncology physicians are often too focused on curing cancer than treating its symptoms. As a result, SCC services are often accessed by chance even when available, often later in the cancer trajectory. To improve recognition of SCC needs and to identify the symptom burden of cancer patients for better management and care, we propose to build natural language processing (NLP) approaches that can automatically extract symptom information from unstructured narratives. The proposed systems will utilize neural nets and build on the state of the art information extraction methods. To accomplish our goals, we will create a dataset of clinical notes for a large cohort of prostate cancer and Diffuse Large B Cell Lymphoma (DLBCL) patients treated in Seattle Cancer Care Alliance (SCCA) and Huntsman Cancer Institute (HCI) between 1.1.2015 and 1.1.2020. We focus on these two types of cancer as examples of two very different and prevalent cancer types. We propose to represent symptom burden documented in clinical narratives with a generalizable frame representation that captures fine-grained details including presence/absence, change-of- state, severity, characteristics, duration, frequency, and anatomy information related to patient symptoms. We will use active learning to create a diverse and representative gold standard annotated with symptom frames to train and test the proposed neural-based NLP approaches. All models and their implementations produced during the execution of this project will be shared with the community as open source resources. After successful completion of the project, the developed NLP methods will be integrated into the information access methods of SCCA and HCI clinical repositories. Project Narrative Cancer patients commonly experience pain, tiredness, shortness of breath, decreased appetite, nausea, drowsiness, anxiety, and decreased sense of wellbeing as well as impaired quality of life due to complications of the cancer itself, and/or cancer treatments. In this project, we will develop natural language processing (NLP) approaches to automatically extract detailed symptom information documented in clinical narratives of a large cohort of prostate cancer and Diffuse Large B Cell Lymphoma (DLBCL) patients treated in Seattle Cancer Care Alliance (SCCA) and Huntsman Cancer Institute (HCI) between 1.1.2015 and 1.1.2020. After successful completing of the project, the developed NLP methods will be integrated into the information access methods of SCCA and HCI.",Extraction of Symptom Burden from Clinical Narratives of Cancer Patients using Natural Language Processing,10179677,R21CA258242,"['Active Learning', 'Address', 'Adoption', 'Adverse effects', 'Affect', 'Anatomy', 'Anxiety', 'Cancer Burden', 'Cancer Patient', 'Caring', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Data', 'Data Set', 'Decision Support Systems', 'Desire for food', 'Diagnosis', 'Disease', 'Documentation', 'Drowsiness', 'Electronic Health Record', 'Engineering', 'Evaluation', 'Frequencies', 'Funding', 'Future', 'Goals', 'Gold', 'Grain', 'Hospitals', 'Impairment', 'Information Retrieval', 'Institutes', 'Institution', 'Intervention', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Nausea', 'Oncology', 'Outcome', 'Outpatients', 'Pain', 'Palliative Care', 'Patients', 'Performance', 'Physicians', 'Practice Guidelines', 'Prevention', 'Professional Organizations', 'Provider', 'Publications', 'Quality of life', 'Records', 'Reporting', 'Resources', 'Semantics', 'Services', 'Severities', 'Shortness of Breath', 'Specialist', 'Structure', 'Supervision', 'Supportive care', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Utah', 'Visit', 'Washington', 'Well in self', 'Work', 'base', 'cancer care', 'cancer complication', 'cancer therapy', 'cancer type', 'care systems', 'cohort', 'cost effectiveness', 'deep learning', 'experience', 'field study', 'implementation barriers', 'improved', 'innovation', 'instrument', 'large cell Diffuse non-Hodgkin&apos', 's lymphoma', 'learning strategy', 'multidisciplinary', 'novel', 'oncology service', 'open source', 'patient health information', 'relating to nervous system', 'repository', 'symptom management', 'symptomatic improvement']",NCI,UNIVERSITY OF WASHINGTON,R21,2021,444461
"NCATS CHALLENGE AWARD - INITIAL OBLIGATION - LITCOIN NLP CHALLENGE With an ever-growing number of scientific studies in various subject domains, there is a vast landscape of biomedical information which is not easily accessible in open data repositories to the public. Open scientific data repositories are either incomplete or too vast to be explored to their potential without a consolidated linkage map that relates all scientific discoveries. This massive amount of medical knowledge can be computationally transformed into knowledge graphs that can be used in an open data repository and has the potential to assist in identifying gaps in medical research and accelerating research for unexplored medical domains through scientific investigations.  However, open medical data on its own is not enough to deliver its full potential for public health. Engaging technologists, members of the scientific and medical community and the public in creating tools with open data repositories, funders can exponentially increase that data’s utility and value to help solve pressing national health issues. The LitCoin Natural Language Processing (NLP) Challenge seeks to spur innovation by rewarding the most creative and high impact uses of biomedical publication free text to create knowledge graphs that can link concepts within existing research, to allow researchers to find connections that may have been difficult to discover without them. n/a",NCATS CHALLENGE AWARD - INITIAL OBLIGATION - LITCOIN NLP CHALLENGE,10505128,561955,"['Award', 'Communities', 'Data', 'Data Scientist', 'Ensure', 'Health', 'Investigation', 'Knowledge', 'Link', 'Maps', 'Medical', 'Medical Research', 'Medicine', 'Natural Language Processing', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Rewards', 'Technology', 'Text', 'data repository', 'innovation', 'knowledge graph', 'member', 'open data', 'tool']",NCATS, ,N01,2021,100000
