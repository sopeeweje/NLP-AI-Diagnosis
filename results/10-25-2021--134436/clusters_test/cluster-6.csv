text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10188526,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2021,388359
"Development of machine learning approaches to population pharmacokinetic model selection and evaluation of application to model-based bioequivalence analysis. PROJECT SUMMARY  The proposed project is for development an evaluation of a deep learning/reinforcement learning approach to population pharmacokinetic model selections. We proposed to develop a command line application using the Python programing language. Python is the current industry standard for development or artificial intelligence applications, and the required packages for deep learning/reinforcement learning are readily available (e.g., Pytorch and Tensorflow). The applicants have previously developed a related machine learning approach using Genetic Algorithm. For purposes of comparison and to make the resulting application generally available, the existing Genetic Algorithm solution will be ported to Python. Both applications (Deep learning/reinforcement learning and Genetic Algorithm) will use NONMEM ® for parameter estimation for the population pharmacokinetic models examined. A common solution linking the model selection algorithm (Deep Learning/Reinforcement Learning and Genetic Algorithm) to NONMEM will be used for both, and is currently under development, with an early version available on github.com. This common solution will facilitate future work using other algorithms for model selection, e.g. particle swarm optimization or simulated annealing. This work will be completed in the first year of the project. All final code will be place in the public domain in github.com.  The second year of the project will consist of evaluation of the solutions (Genetic algorithm and Deep Learning/Reinforcement Learning). This evaluation will include assessment of a range of measures of the “goodness” of the model (“fitness in Genetic Algorithm and “reward signal” in Deep Learning/Reinforcement Learning). These measure of model “goodness” may include objective function value, parsimony penalties, importance of successful covariance step. Within the scope of this project, these measures will be objective and numerical. Future projects may include the addition of subjective evaluations of model “goodness” in the model selection algorithm. CONFIDENTIAL Page 1 of 1 PROJECT NARRATIVE The current project is intended to improve both the efficiency and robustness of Population Pharmacokinetic analysis. These improvements are expected to have an impact of both the timeline for Population Pharmacokinetics models (resulting in getting new drug to patients more quickly) and the value of the models in drug development decision making. We feel that the rapidly evolving field of machine learning can be leveraged in drug development, reproducing the gains made in other fields including drug discovery and diagnostics. CONFIDENTIAL Page 1 of 1",Development of machine learning approaches to population pharmacokinetic model selection and evaluation of application to model-based bioequivalence analysis.,10375078,U01FD007355,[' '],FDA,"NUVENTRA, INC.",U01,2021,125000
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'open source tool', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Deep learning for understanding gene regulation in diseases via 'omics' integration PROJECT SUMMARY We propose to develop and refine neural networks gene expression to understand gene regulation in diseases. We will design deep learning frameworks to integrate various datasets (histone modifications, 3D conformation, sequences, and SNPs) and model their relationship with the gene expression. Our proposed models will explicitly capture the underlying structure and complexity of the biological data to learn meaningful connections. For example, we will use a graph-based neural network to model the 3D conformation of the DNA as a graph and learn from the connections between different genomic regions to predict gene expression. One of our critical goals for using these methods is to extract relevant signals that could be contributing to the up- and down-regulation of genes. We will accomplish this goal by applying interpretation methods for neural networks. These methods will allow us to assign importance scores to the input features that contribute the most towards a particular prediction of interest. Comparing these scores for genes across healthy and disease cell lines will provide insights into gene misregulation and serve as a hypothesis driving tool for biological experiments. We also propose a novel Bayesian inference-based interpretation method to improve explanations of graph-based neural networks that could be applied to various tasks. Finally, given the improvement of single-cell technologies and imputation methods, we will extend our deep learning frameworks to model relationships between signals like chromatin accessibility and DNA methylation with gene expression. This direction will allow us to explore the effectiveness of the imputation methods in removing noise and generating high-quality single-cell samples for usage in deep learning modeling of gene regulation. Looking at the modeled relationships across the cell's developmental stages could pinpoint timepoints for potential misregulation in diseases. Therefore, this proposal aims to develop unified approaches that utilize datasets spanning multiple repositories to leverage their collective knowledge and improve our understanding of diseases in a data-driven manner. PROJECT NARRATIVE We propose to use deep learning to integrate multiple genomic datasets and connect them to gene expression. We will develop interpretation methods to extract signals related to misregulated genes in diseases. We will extend these frameworks to single-cell datasets.",Deep learning for understanding gene regulation in diseases via 'omics' integration,10294097,R35HG011939,"['3-Dimensional', 'Automobile Driving', 'Bayesian Analysis', 'Biological', 'Cell Line', 'Cells', 'Chromatin', 'DNA', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Disease', 'Effectiveness', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genomic Segment', 'Goals', 'Graph', 'Knowledge', 'Learning', 'Methods', 'Modeling', 'Molecular Conformation', 'Noise', 'Sampling', 'Signal Transduction', 'Structure', 'Up-Regulation', 'base', 'deep learning', 'design', 'experimental study', 'gene repression', 'genomic data', 'histone modification', 'improved', 'insight', 'interest', 'neural network', 'novel', 'repository', 'single cell technology', 'three-dimensional modeling', 'tool']",NHGRI,BROWN UNIVERSITY,R35,2021,379507
"Interpretable deep learning models for translational medicine Understanding the state of cellular signaling systems provides insights to how cells behave under physiological and pathological conditions. Cellular signaling systems are organized as hierarchy (cascade) and signals of a molecular is often compositionally encoded to control cellular processes, such as gene expression. This project aims to develop advanced deep learning models (DLMs) to simulate cellular signaling systems based on gene expression data. In last 3 years, the project has made significant progresses, but the challenges remain. Importantly, contemporary DLMs behave as “black boxes”, in that it is difficult to interpret how signals are encoded and how to interpret which signal a hidden node represent in a DLM. This black-box nature prevents researchers from gaining biological insights using DLMs, even though these models can be much superior in modeling data than other types of models in many tasks, e.g., predicting drug sensitivity of cancer cells. In this competitive renewal, we propose to develop novel DLMs and innovative inference algorithms to train “interpretable” DLMs and apply them in translational research. The proposed research is innovative and of high significance in several perspectives: 1) Our novel DLMs and algorithms take advantage of big data resulting from systematic chemical/genetic perturbations of cellular signaling machinery, so that we can use the perturbation condition as side information to reveal how signals are encoded in a DLM. 2) We integrate principles of causal inference and information theory with deep learning method to make DLMs interpretable. As results, that researchers can gain mechanistic insights from such models. 3) Innovative application of interpretable DLMs will advance translational research. For example, we will train interpretable DLMs to model cellular signaling at the level of single cells and use this information investigate inter-cellular interactions among cells in tumor microenvironment to shed light on immune evasion mechanisms of cancers. We will also use information derived from interpretable DLMs to predict cancer cell drug sensitivity. We anticipate that our study will bring forth significant advances not only in deep learning methodology but also in precision medicine. This project aims to develop advance machine learning methods, referred to as deep learning models, to simulate cellular signaling systems, at both multiple cell and single cell levels. Success of these models will enable researchers to investigate cellular behaviors under physiological and pathological condition, and such information can be used to guide therapy of cancer patients.",Interpretable deep learning models for translational medicine,10171908,R01LM012011,"['Affect', 'Algorithms', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Cancer Patient', 'Cancer cell line', 'Cell model', 'Cell physiology', 'Cells', 'Data', 'Disease', 'Event', 'Gene Expression', 'Genetic', 'Genetic Transcription', 'Grain', 'Human', 'Immune Evasion', 'Immunotherapy', 'Individual', 'Information Theory', 'Intervention', 'Knowledge', 'Learning', 'Libraries', 'Light', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'MicroRNAs', 'Mining', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Network-based', 'Organoids', 'Outcome', 'Paper', 'Pathologic', 'Pathway interactions', 'Patients', 'Pharmacology', 'Phenotype', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Cancer Genome Atlas', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Yeasts', 'base', 'biological systems', 'cancer cell', 'cancer therapy', 'cell behavior', 'chemical genetics', 'data modeling', 'deep field survey', 'deep learning', 'deep learning algorithm', 'design', 'drug sensitivity', 'experience', 'genome-wide', 'innovation', 'inquiry-based learning', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'novel', 'patient response', 'pre-clinical', 'precision medicine', 'precision oncology', 'predicting response', 'prevent', 'response', 'single-cell RNA sequencing', 'success', 'theories', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'translational impact', 'translational medicine', 'translational model', 'tumor', 'tumor microenvironment']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,309404
"Deep Learning Methods to Integrate Biological Information for Analysis of Single-cell RNAseq Data Project Summary The broad long-term objective of the project concerns the development of novel machine learning methods and computational tools for modeling genomic data motivated by important biological questions and experiments. The analysis of single-cell RNAseq (scRNAseq) data presents substantial computational and bioinformatics challenges. The specific aim of the project is to develop novel model-based deep learning methods with prior biological information considered for modelling scRNAseq data. These problems are all motivated by the PI’s close collaborations with biomedical investigators. The proposed approaches are designed to integrate biological information for improving both analytical performance and biological interpretability. The methods hinge on novel integration of biological insights and deep learning methods for analysis of the noisy, sparse, and over-dispersed scRNAseq data, including zero- inflated negative binominal model, autoencoder, deep embedding, hyperbolic embedding, and reversed graph embedding. The new methods can be applied to two important biological problems using the scRNAseq technologies: cell type identification and discovery via clustering analysis and cell developments via trajectory inference. They will facilitate effective analyses of the increasingly important scRNAseq data sets and contribute to the important on-going studies that the PI is currently collaborating on, Paneth cell regulation and regeneration of human hair follicles. The project will develop practical and feasible computer programs in order to implement the proposed methods, and to evaluate the performance of these methods through real applications. The work proposed here will contribute deep learning methods to modeling scRNAseq data and to studying complex phenotypes and biological systems and offer insights into each of the biological areas represented by the various data sets. All programs developed under this grant and detailed documentation will be made available free-of-charge to interested researchers. Undergraduates researchers from diverse backgrounds will be recruited as an integral part in the project for implementing most critical parts of the proposed aims. The research project will stimulate the interests of students so that they can consider a career in the biomedical sciences. Project Narrative This project aims to develop deep learning methods for analysis of single-cell RNA sequencing data, which have been generated for investigating various biomedical problems. The novel deep learning methods are expected to offer more insights into each of the biomedical areas represented by the various data sets. The research project will stimulate the interests of undergraduate trainees so that they can consider a career in the biomedical sciences.",Deep Learning Methods to Integrate Biological Information for Analysis of Single-cell RNAseq Data,10291567,R15HG012087,"['Algorithms', 'Architecture', 'Area', 'Binomial Model', 'Bioinformatics', 'Biological', 'Cells', 'Charge', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Dimensions', 'Documentation', 'Dropout', 'Euclidean Space', 'Event', 'Frequencies', 'Goals', 'Grant', 'Graph', 'Hair follicle structure', 'Human', 'Investigation', 'Knowledge', 'Lead', 'Maps', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Natural regeneration', 'Paneth Cells', 'Pennsylvania', 'Performance', 'Phenotype', 'Regulation', 'Research Personnel', 'Research Project Grants', 'Science', 'Scientist', 'Students', 'Supervision', 'Technology', 'Transcript', 'Triplet Multiple Birth', 'Universities', 'Visualization software', 'Work', 'autoencoder', 'base', 'biological systems', 'career', 'cell type', 'computer program', 'computerized tools', 'data visualization', 'deep learning', 'design', 'experimental study', 'flexibility', 'genomic data', 'improved', 'insight', 'interest', 'learning strategy', 'loss of function', 'machine learning method', 'medical schools', 'novel', 'programs', 'recruit', 'single cell analysis', 'single-cell RNA sequencing', 'transcriptome', 'transcriptome sequencing', 'undergraduate student']",NHGRI,NEW JERSEY INSTITUTE OF TECHNOLOGY,R15,2021,450849
"Developing deep learning models for precision oncology Project Summary/Abstract The goal of this study is to develop machine learning methods, especially deep learning models (DLMs), to learn a better representation of activation states of cellular signaling pathways in an individual tumor and use such information to predict its sensitivity to anti-cancer drugs. Cancer is mainly caused by somatic genome alterations (SGAs) that perturb cellular signaling pathways, and aberrations in pathways eventually lead to cancer development. Precision oncology aims to accurately detect and target tumor-specific aberrations, but challenges remain. Currently, there is no well-established method to detect the activation states of signaling pathways, and the common practice of using mutation status of a targeted gene as the indicator for prescribing a molecularly targeted drug has limitations. To overcome such limitation, we hypothesize that, by closely simulating the hierarchical organization of cellular signaling systems, DLMs can be used to systematically identify major cancer signaling pathways, to detect tumor-specific aberrations in signaling pathways, and to predict cancer cell sensitivity to anti-cancer drugs.  We will develop models that more precisely represent the state of signaling systems in cancer cells and use such information to enhance precision oncology. I will design and apply innovative DLMs to cancer big data, including large-scale pharmacogenomic data and cancer omics data to learn unified representation of aberrations in signaling systems caused by driver SGAs in cancer cell, despite of their different growth conditions, such as in cell culture, PDX and real tumor. This will enable us to transfer the models trained using cell lines and PDXs to clinical setting (real tumors) in future. By the nature of drugs that may share common target proteins, we develop model DLM-MLT (the combination of DLM and multi-task learning) to predict the sensitivity of tumor samples to multiple drugs at once. Furthermore, we will develop model BioSI-DLM to use various perturbations (ex. SGA/LINCS perturbation data) as side information to learn better representation that potentially map latent variables in a DLM to biological entities. We hypothesize that the representation learned from our designed models will significantly improve the prediction accuracy compared with the conventional indication for drug treatment (ex. mutation state of the drug targeting protein). In summary, our study uses deep learning based machine learning methods to learn better and concise representation embedded in the cancer omics data to reflect the personalized genomic changes, which could be used to guide the personalized treatment. Our study could significantly contribute to the development of cancer ontology and promote the development of precision medicine. Project Narrative Cancer is among the leading causes of death worldwide. The proposed project aims to develop machine learning methods, especially deep learning, to study cellular signaling systems and disease mechanism. A better representation embedded in the cancer omics data will improve the prediction of drug sensitivity and patient survival. Our study promotes the development of precision medicine to guide the personalized treatment based on patient’s unique genetic changes.",Developing deep learning models for precision oncology,10059265,K99LM013089,"['Antineoplastic Agents', 'Big Data', 'Biological', 'Biological Markers', 'Cancer cell line', 'Cause of Death', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Clinical', 'Data', 'Development', 'Disease', 'Drug Targeting', 'Foundations', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Human', 'Individual', 'Knowledge', 'Label', 'Lead', 'Learning', 'Malignant Neoplasms', 'Maps', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Nature', 'Oncogenic', 'Ontology', 'PIK3CA gene', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Proteins', 'Proteomics', 'Rattus', 'Research Activity', 'Resistance', 'Sampling', 'Side', 'Signal Pathway', 'Signal Transduction', 'System', 'Testing', 'The Cancer Genome Atlas', 'Training', 'Work', 'Yeasts', 'base', 'cancer cell', 'deep learning', 'design', 'drug sensitivity', 'experimental study', 'improved', 'innovation', 'machine learning method', 'model design', 'molecular drug target', 'molecular phenotype', 'multi-task learning', 'mutational status', 'novel', 'patient derived xenograft model', 'personalized medicine', 'precision medicine', 'precision oncology', 'response', 'transcription factor', 'transcriptomics', 'tumor', 'tumor xenograft']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,91506
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'open source tool', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"Enhancing low count PET and SPECT imaging with deep learning methods Abstract (Parent) Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Enhancing low count PET and SPECT imaging with deep learning methods,10403701,R01EB022075,"['90Y', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical Trials', 'Disease', 'Dose', 'Ensure', 'External Beam Radiation Therapy', 'Foundations', 'Future', 'Goals', 'Image', 'Joint repair', 'Lesion', 'Liver parenchyma', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modeling', 'PET/CT scan', 'Parents', 'Patient-Focused Outcomes', 'Patients', 'Phase I Clinical Trials', 'Physics', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Safety', 'Testing', 'Toxic effect', 'Training', 'base', 'clinical practice', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'next generation', 'novel', 'novel strategies', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,82804
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Abstract Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,10206138,R01EB022075,"['90Y', 'Address', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Disease', 'Dose', 'Ensure', 'Evaluable Disease', 'External Beam Radiation Therapy', 'Failure', 'Foundations', 'Funding', 'Future', 'Goals', 'Hepatotoxicity', 'Image', 'Joint repair', 'Joints', 'Lesion', 'Liver', 'Liver parenchyma', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motivation', 'Noise', 'PET/CT scan', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Photons', 'Physics', 'Pilot Projects', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Reporting', 'Safety', 'Scanning', 'Testing', 'Time', 'Toxic effect', 'Training', 'base', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'multimodal data', 'multimodality', 'next generation', 'novel', 'novel strategies', 'personalized cancer therapy', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,657625
"Center for Molecular Imaging Technology and Translation (CMITT) Administrative Supplement #4 Abstract Alzheimer's Disease (AD) is characterized by the presence and distribution of intracellular neurofibrillary tangles tau and extracellular amyloid-β. Tau pathology is deeply associated with cognitive decline in AD in a region-specific manner. It will be highly valuable to predict how tau burden would spread in the future given a baseline tau PET measurement. Such approach can be used to predict how region-wise tau burden changes versus age and, therefore, stratify potential candidates for AD therapy based on their “trajectory” of progression. It can also be used to determine how different a tau PET distribution is after a therapy from the predicted distribution if no therapy is applied. The recent availability of longitudinal tau PET data provides us a unique opportunity for technology development: to model tau-propagation using state-of-the-art deep learning methods. However, current available longitudinal tau PET datasets are relatively small, therefore, insufficient to train a deep neural network. To solve this problem, we propose a novel approach that incorporates a simple mathematical model in the training of the deep neural network. We first develop a simple network diffusion model that fits part of the available longitudinal tau PET data. We then generate a very large number of longitudinal tau PET datasets using the fitted model to pretrain a U-net-like autoencoder deep neural network. Finally, we further train the neural network by freezing all the parameters except those directly associated with the bottleneck layer of the neural network. This approach makes it possible to model tau propagation directly from measured longitudinal tau PET data while avoid overfitting caused by insufficient training data. Narrative To model tau-propagation in Alzheimer's Disease using longitudinal tau PET data, we propose a novel deep-learning based approach that incorporates a network diffusion model in the training of the deep neural network. Our approach makes it possible to model tau propagation directly from measured longitudinal tau PET data while avoid overfitting caused by insufficient training data.",Center for Molecular Imaging Technology and Translation (CMITT) Administrative Supplement #4,10287986,P41EB022544,"['Administrative Supplement', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Alzheimer&apos', 's disease therapy', 'Amyloid beta-Protein', 'Area', 'Brain', 'Clinical', 'Data', 'Data Set', 'Development', 'Diffusion', 'Disease Progression', 'Freezing', 'Future', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging technology', 'Impaired cognition', 'Intervention', 'Investigation', 'Measurement', 'Measures', 'Medial', 'Memory impairment', 'Methodology', 'Methods', 'Modeling', 'Neurofibrillary Tangles', 'Pathologic', 'Pathology', 'Pattern', 'Performance', 'Positron-Emission Tomography', 'Problem Solving', 'Standardization', 'Structure', 'Temporal Lobe', 'Time', 'Tracer', 'Training', 'Translations', 'Work', 'autoencoder', 'base', 'deep learning', 'deep neural network', 'entorhinal cortex', 'extracellular', 'falls', 'follow-up', 'learning strategy', 'mathematical model', 'molecular imaging', 'neocortical', 'neural network', 'novel', 'novel strategies', 'relating to nervous system', 'response', 'spatiotemporal', 'targeted treatment', 'tau Proteins', 'tau aggregation', 'technology development', 'uptake']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,P41,2021,328969
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,10231217,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data repository', 'data space', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,436674
"Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning Cerebrovascular disease remains a common cause of death and major disability in the United States, and identifying and preventing strokes should be a high priority. Direct measurement of regional cerebral blood flow (CBF) is challeng- ing in these patients, since we do not have a non-invasive, radiation-free imaging method that has been appropriately validated against gold standard techniques. This is important, because there is compelling evidence that measuring the CBF change before and after a stress test meant to increase CBF (a measurement known as cerebrovascular reserve [CVR]) can identify patients at increased stroke risk. Stress tests have been a mainstay of the diagnostic workup of cardiology patients for many years, and we believe strongly that their use will benefit cerebrovascular disease patients as well. The goal of this project is to improve the quality of arterial spin label (ASL) MRI using deep learning, a powerful form of machine learning, that is currently undergoing tremendous progress. We will then to apply this in a prospective, adaptive validation trial against oxygen-15 water PET CBF, using simultaneous PET/MRI to minimize biological variability. Finally, we will apply this improv- ed tool to study the effects of gender on CVR and its reproducibility. Successful completion of this study will result in a validated methodology to assess CVR in cerebrovascular disease patients without the use of radiation or contrast. As such, it will provide solid, evidence-based recommendations for clinicians developing new paradigms and interventions in patients with impaired CVR. There is strong evidence that imaging of cerebrovascular reserve (CVR), the ability to increase cerebral blood flow (CBF) in response to a challenge, can identify patients at increased risk of stroke. Therefore, measuring CVR would be extremely useful for designing clinical trials of interventions to mitigate this risk. However, current methods to measure CBF and CVR are suboptimal, and do not work well in patients with cerebrovascular disease. The goals of this project are • to improve non-contrast, radiation-free arterial spin label MRI methods  using deep learning, a powerful form of artificial intelligence that has  shown tremendous progress for computer vision • to validate these methods against a CBF gold-standard, oxygen-15 water  PET, using simultaneous PET/MRI, using an adaptive “play-the-winner” strategy • to apply them to assess gender differences in CVR and test their  reproducibility, with the goal of establishing age and gender normative  ranges to better identify outliers.",Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning,10205063,R01EB025220,"['Acetazolamide', 'Address', 'Age', 'Artificial Intelligence', 'Biological', 'Blood flow', 'Brain', 'Brain imaging', 'Bypass', 'Cardiac', 'Cardiology', 'Carotid Stenosis', 'Cause of Death', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'Clinical', 'Clinical Trials Design', 'Computer Vision Systems', 'Consensus', 'Cytolysis', 'Data', 'Deposition', 'Diagnostic', 'Excision', 'Gadolinium', 'Gender', 'Goals', 'Gold', 'Guidelines', 'ImProv', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Intervention', 'Intervention Trial', 'Japanese Population', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Noise', 'Nutrient', 'Outcome', 'Oxygen', 'Patient Triage', 'Patients', 'Physiologic pulse', 'Physiological', 'Play', 'Positron-Emission Tomography', 'Premenopause', 'Procedures', 'Radiation', 'Reference Standards', 'Reproducibility', 'Rest', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Solid', 'Spin Labels', 'Stress Tests', 'Stroke prevention', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Waste Products', 'Water', 'Woman', 'Xenon', 'base', 'blood flow measurement', 'cerebral hemodynamics', 'cerebrovascular', 'cerebrovascular imaging', 'clinical application', 'cohort', 'convolutional neural network', 'deep field survey', 'deep learning', 'design', 'direct application', 'disability', 'evidence based guidelines', 'gender difference', 'imaging modality', 'improved', 'learning network', 'men', 'nervous system disorder', 'novel strategies', 'performance tests', 'prospective', 'response', 'stressor', 'stroke risk', 'systematic review', 'time use', 'tool']",NIBIB,STANFORD UNIVERSITY,R01,2021,657093
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,10179376,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,449722
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,10189581,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Comparative Effectiveness Research', 'Computer Models', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'algorithm development', 'artificial neural network', 'automated segmentation', 'base', 'clinical decision-making', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'fall injury', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'risk prediction', 'secondary outcome', 'segmentation algorithm', 'skills', 'standard of care', 'support vector machine', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2021,186183
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning.",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,10225646,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'software infrastructure', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2021,755740
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,10149998,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air Movements', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Smoking History', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'Visualization', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'former smoker', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'respiratory morbidity', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2021,185497
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10247802,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2021,747733
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,P41EB028741,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2021,1527478
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,10127641,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2021,589357
"Deep learning for decoding genetic regulation and cellular maps in craniofacial development Project Summary A deep understanding of gene regulation and function during craniofacial development is not only important for our biological knowledge, but also critical to identify causal variants and genes underlying many dental, oral, and craniofacial (DOC) diseases. Numerous -omics datasets at the genomic, epigenomic, (single-cell) transcriptomic levels have been generated for craniofacial development and DOC diseases. These datasets are highly heterogeneous (e.g. platforms, species, tissues, developmental stages) and cross-species (e.g. human and mouse), requiring novel analytical approaches for decoding genetic regulation, molecular function, and cellular maps in craniofacial development. Critically, because of practical unavailability of human embryonic craniofacial tissue, there is a big gap between the abundant -omics and functional studies in murine craniofacial development and large-scale human genetic studies of DOC diseases. In this proposal, we combine machine learning, genomics, single-cell RNA sequencing (scRNA-seq), complex disease genetics, developmental biology to design novel methods aiming to decode complex genetic regulation and cellular maps during craniofacial development. We propose three specific aims. Aim 1. To develop a deep learning method, DeepFace, for characterizing and prioritizing genetic variants and regulation during craniofacial development. DeepFace is designed to decipher functional impact of noncoding variants and will be the first deep learning method to integrate cross-species functional features in craniofacial development. We will validate DeepFace by using data from genome-wide association studies (15 datasets) and case-parent trio-based whole genome sequencing (3 datasets) of orofacial clefts (OFCs). This validation will identify potential causal variants, both common and de novo mutations, in OFCs. Aim 2. To develop deep learning methods for time-series scRNA-seq data analysis in craniofacial development. We will develop novel algorithms including TTNNet for integrating time-series scRNA- seq data and DrivAER for tracing developmental trajectories and identifying driving transcription factors in craniofacial development. We will validate the methods using scRNA-seq datasets from the FaceBase consortium and to-be-generated data for mouse palate formation. Aim 3. To experimentally validate and characterize the top ranked novel mutations (Aim 1) and regulators (Aim 2). Building on our previous studies, strong preliminary data and highly experienced team, this proposal is timely to develop machine learning methods to effectively address the current gap between the genomics studies in murine craniofacial development and human genetic studies of orofacial clefts. The successful completion will provide 1) the NIDCR research community a suite of novel methods and analytical tools for genomic/epigenomic/scRNA-seq data, and 2) the mechanistic assessment on the mutations/genes and transcriptional regulators that are potentially involved in OFCs and related craniofacial diseases. Project Narrative Numerous -omics datasets at the genomic, epigenomic, (single-cell) transcriptomic levels have been generated for craniofacial development and dental, oral, and craniofacial (DOC) diseases; however, these data are highly heterogeneous, limiting the analysis for the understanding of DOC biology and discovery of causal mutations and regulators in DOC diseases. In this proposal, we will develop novel deep learning approaches to decode complex genetic regulation and cellular maps during craniofacial development and apply the methods to orofacial cleft genetic data.",Deep learning for decoding genetic regulation and cellular maps in craniofacial development,10235696,R01DE030122,"['Address', 'Algorithms', 'Atlases', 'Automobile Driving', 'Biological', 'Biology', 'CRISPR/Cas technology', 'Cell Proliferation', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Dental', 'Development', 'Developmental Biology', 'Developmental Process', 'Disease', 'Embryo', 'Enhancers', 'FaceBase', 'Funding', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Regulation', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic study', 'Genomics', 'Genotype-Tissue Expression Project', 'Human', 'Human Genetics', 'Knock-in', 'Knock-out', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Molecular', 'Morphology', 'Mus', 'Mutation', 'National Institute of Dental and Craniofacial Research', 'Oral', 'Palate', 'Parents', 'Phenotype', 'Play', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Series', 'Structure', 'Time', 'Time Series Analysis', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analytical tool', 'base', 'causal variant', 'cell motility', 'cell type', 'cleft lip and palate', 'craniofacial', 'craniofacial development', 'craniofacial tissue', 'data integration', 'de novo mutation', 'deep learning', 'deep learning algorithm', 'design', 'epigenomics', 'experience', 'gene function', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'genomic tools', 'heterogenous data', 'learning strategy', 'machine learning method', 'novel', 'orofacial cleft', 'programs', 'secondary analysis', 'single-cell RNA sequencing', 'success', 'transcription factor', 'transcriptomics', 'whole genome']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2021,585184
"Optimizing Oral Cancer Screening and Precision Management of Potentially Malignant Oral Lesions Project Summary  Despite treatment advances over the past several decades, cancer-specific survival for oral cancers remains bleak, mostly due to the majority of cases being diagnosed at late stages. Early-stage detection of cancers (most often oral squamous cell carcinoma (OSCC)) would enable less disfiguring, less costly therapy with curative intent. However, limitations of traditional visual-tactile examination for oral cancerous and pre- cancerous lesions have hindered cancer detection and support for screening. Visual inspection for separation of benign from precancerous or cancerous lesions is inaccurate, and therefore standard practice entails referral and scalpel biopsy of most potentially malignant oral lesions. Furthermore, approximately 20% of potentially malignant oral lesions contain some degree of epithelial dysplasia or carcinoma, and therefore early identification could allow curative treatment as the majority of OSCC typically starts as dysplasia, and the degree of dysplasia is correlated with the rate of malignant transformation. Detractors of oral screening cite the high prevalence of benign oral lesions and mild dysplasia as circumstances placing patients at risk of harms from over-testing and over-treatment. Thus, screening efforts could be transformed by adjunctive diagnostic tests that offer highly accurate cytopathologic information at the point of care, such as the NIDCR-supported Point-of-Care Oral Cytopathology Tool. Computer vision-assisted precision imaging tests have recently shown strong diagnostic performance for oral lesion characterization, but their potential pitfalls and promises must be thoroughly investigated before clinical application. Similarly, machine learning could bolster optical tests for visualizing potentially malignant lesions. If successful, these artificial intelligence devices could aid decision- making, preventing unnecessary scalpel biopsies for low-risk lesions and enabling risk-stratified surveillance or treatment. Our team of experts in computer disease simulation modeling, machine learning, oral medicine, and economic evaluation will transform a disease simulation model to provide analysis at the point of care, and evaluate the different potential uses of precision imaging diagnostics for translation to clinical care. We will expand our existing disease model of potentially malignant oral lesions to represent lesion characteristics and clinical risk categories (e.g. based on tobacco and alcohol use) through incorporation of large longitudinal datasets (Aim 1), in order to evaluate whether artificial intelligence-assisted cytologic testing can improve the effectiveness and cost-effectiveness of screening for low, moderate, or high risk categories (Aim 2). Finally, we will evaluate whether adjuncts for lesion visualization render favorable effectiveness and cost effectiveness of screening across risk categories, with or without artificial intelligence support, and develop a user interface for the model (Aim 3). This work will produce an analytic engine to guide clinical translation of artificial intelligence- aided diagnostics for oral lesion detection and characterization, to overcome insufficient screening reliability. Project Narrative Early stage oral cancers and precancers are currently under-detected, representing missed opportunity to improve the poor outcomes of oral cancer. While screening with conventional visual-tactile examination is limited in accuracy, artificial intelligence-assisted precision diagnostics could shift the cancer prevention paradigm toward screening for the broader population if enabling reliable triage of oral lesions for risk-based management. The proposed disease simulation model will evaluate the benefits and harms of harnessing these devices and precision treatment thresholds, guiding translation toward cancer control.",Optimizing Oral Cancer Screening and Precision Management of Potentially Malignant Oral Lesions,10298437,R01DE030169,"['Address', 'Adult', 'Affect', 'Alcohol consumption', 'American', 'Appearance', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Control', 'Cancer Detection', 'Cancerous', 'Carcinoma', 'Caring', 'Categories', 'Cells', 'Characteristics', 'Clinical', 'Complex', 'Computer Vision Systems', 'Computers', 'Consultations', 'Cytology', 'Cytopathology', 'Data', 'Decision Aid', 'Decision Making', 'Decision Modeling', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic tests', 'Disease', 'Disease model', 'Dysplasia', 'Early Diagnosis', 'Early identification', 'Effectiveness', 'Goals', 'Health', 'Health Benefit', 'High Prevalence', 'Histologic', 'Image', 'Incidence', 'Intraepithelial Neoplasia', 'Lesion', 'Longitudinal cohort study', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of pharynx', 'Methods', 'Mild Dysplasia', 'Modeling', 'National Institute of Dental and Craniofacial Research', 'Optics', 'Oral', 'Oral Diagnosis', 'Oral Examination', 'Oral Medicine', 'Oral Stage', 'Organ', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Population', 'Precision therapeutics', 'Procedures', 'Quality of life', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Science', 'Screening for Oral Cancer', 'Specialist', 'Structure', 'Tactile', 'Testing', 'Tissues', 'Tobacco use', 'Translating', 'Translations', 'Triage', 'United States National Institutes of Health', 'Visual', 'Visualization', 'Work', 'base', 'cancer prevention', 'clinical application', 'clinical care', 'clinical decision-making', 'clinical risk', 'clinical translation', 'cost', 'cost effective', 'cost effectiveness', 'curative treatments', 'diagnostic screening', 'disorder risk', 'economic evaluation', 'economic outcome', 'health economics', 'high risk', 'improved', 'improved outcome', 'longitudinal dataset', 'malignant mouth neoplasm', 'models and simulation', 'mortality risk', 'mouth squamous cell carcinoma', 'new technology', 'oral care', 'oral diagnostics', 'oral lesion', 'oral premalignancy', 'overtreatment', 'personalized diagnostics', 'personalized management', 'point of care', 'premalignant', 'premature', 'prevent', 'risk stratification', 'scalpel', 'screening', 'screening guidelines', 'tool']",NIDCR,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,641960
"Optimization of PET Image Reconstruction for Lesion Detection Optimization of PET Image Reconstruction for Lesion Detection Abstract PET is a molecular imaging modality widely used in oncology studies due to its high sensitivity and the potential of early diagnosis. For neuroendocrine tumors (NETs), 68Ga-DOTATATE PET has been recently used in clinical routine for imaging NETs in adult and pediatric patients since 2016. It plays an important role in the diagnosis and staging of NETs. However, compared to 18F-FDG PET, the image quality of 68Ga-DOTATATE PET is lower due to much larger positron range, shorter half-life, and lower dose administration limited by generator capacity. All of these compromises the lesion detectability of 68Ga-DOTATATE PET, especially for small lesions, and can potentially lead to inaccurate NET diagnosis. As 68Ga-DOTATATE PET is increasingly used in clinics, there is an urgent and unmet need to further optimize 68Ga-DOTATATE PET/CT imaging for NET detection. Recently, data-driven methods have been developed for PET image denoising, where the PET system model is not considered. As the tumor-to-background ratio of 68Ga-DOTATATE PET is greater than 18F-FDG PET, the lesion recovery of 68Ga-DOTATATE PET can be hugely influenced by the smoothing effects as well as potential mismatches between training and testing datasets. In this study, we propose a novel data- informed and lesion detection-driven image reconstruction framework. The PET system model, image denoising module, and lesion-detection module will all be included in this reconstruction framework. The two specific aims of this exploratory proposal are (1) to develop a lesion detection-driven PET image reconstruction framework and validate it based on comprehensive computer simulations, (2) to apply the proposed reconstruction framework to existing clinical 68Ga-DOTATATE PET/CT datasets and test it based on various figure-of-merits. We expect that the integrated outcome of the specific aims will be a novel and robust image reconstruction framework to better recover lesions in a 68Ga- DOTATATE PET scan, which is essential for NET managements. Optimization of PET Image Reconstruction for Lesion Detection  Project Narrative Positron emission tomography (PET) is an imaging modality widely used in oncology. This project aims to develop a novel lesion detection-driven PET image reconstruction framework. Success of this project can enhance the lesion detectability of current PET imaging protocols, e.g. 68Ga-DOTATATE PET/CT scanning for neuroendocrine tumors (NETs).",Optimization of PET Image Reconstruction for Lesion Detection,10206141,R03EB030280,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Biological Models', 'Clinic', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Distant Metastasis', 'Dose', 'Early Diagnosis', 'Enhancing Lesion', 'FOLH1 gene', 'Gallium', 'Goals', 'Half-Life', 'Image', 'Incidence', 'Injections', 'Label', 'Lead', 'Lesion', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neuroendocrine Tumors', 'Noise', 'Oncology', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Physics', 'Play', 'Positron', 'Positron-Emission Tomography', 'Prevalence', 'Prognosis', 'Protocols documentation', 'Radionuclide Imaging', 'Reader', 'Recovery', 'Recurrence', 'Resolution', 'Role', 'Savings', 'Sensitivity and Specificity', 'Staging', 'Testing', 'Time', 'Tracer', 'Training', 'United States', 'Validation', 'Vendor', 'X-Ray Computed Tomography', 'base', 'cancer type', 'deep learning', 'denoising', 'effectiveness validation', 'experience', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'molecular imaging', 'neural network', 'neuroendocrine differentiation', 'novel', 'pediatric patients', 'pentetreotide', 'radiologist', 'radiotracer', 'reconstruction', 'routine imaging', 'success', 'treatment optimization', 'treatment planning', 'tumor']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R03,2021,89563
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287
"Deep Learning Image Analysis Algorithms to Improve Oral Cancer Risk Assessment for Oral Potentially Malignant Disorders Abstract Oral potentially malignant disorders (OPMD) are a group of mucosal diseases in the oral cavity with a risk of progressing to oral squamous cell carcinoma. Risk assessment is traditionally done through a combination of clinical and histologic evaluation. Leukoplakia is a common type of OPMD that is given a histologic grading score that is supposed to be related to its risk of progression. However, there is tremendous intra- and inter- observer heterogeneity in dysplasia grading, leading to variability and uncertainty in risk assessment and treatment planning. This also hinders the ability to study the biology of these lesions. We propose to use whole slide imaging on routine hematoxylin and eosin (H&E) stained sections in combination with deep learning methods to build a consistent risk scoring system for OPMD. Our methods will identify cell, nucleus, and tissue architectural features relevant to risk of progression in OPMD. These features will be tested in a large retrospective case-control study and then validated prospectively. We will also explore combining them with genomic and immune biomarkers in order to improve the prognostic power and explore the biolo gy of progression in OPMD. We hope that these efforts will improve and standardize risk assessment for OPMD. This could lead to improved treatment and prevention options by enabling risk stratification and allowing future clinical trials be conducted in a more uniform patient cohort. Similarly, it could improve our understanding for the biology of OPMD and the process of progression to cancer. Project Narrative Oral potentially malignant disorders (OPMD) are a common and heterogeneous group of mucosal lesions in the oral cavity without robust and consistent biomarkers for their risk of progression to can cer. Here we propose to use whole slide imaging analysis of routine clinical samples to develop a more robust risk assessment process. These analyses will be combined with genomic and immune biomarkers that should provide improved clinical risk assessment as well as new insights on the biology of progression in OPMD.",Deep Learning Image Analysis Algorithms to Improve Oral Cancer Risk Assessment for Oral Potentially Malignant Disorders,10209773,R01DE030656,"['Affect', 'Algorithmic Analysis', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Biology', 'Biopsy', 'Case-Control Studies', 'Cell Nucleus', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Computational algorithm', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Disease', 'Dysplasia', 'Epithelial Cells', 'Evaluation', 'Future', 'General Population', 'Genomics', 'Goals', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histology', 'Histopathologic Grade', 'Image', 'Image Analysis', 'Immune', 'Immunologic Markers', 'Individual', 'Intraepithelial Neoplasia', 'Lead', 'Lesion', 'Leukoplakia', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Mucous Membrane', 'Oral', 'Oral Leukoplakia', 'Oral cavity', 'Oral mucous membrane structure', 'Pathologic', 'Pathology', 'Patient Care', 'Patient risk', 'Patients', 'Performance', 'Prevention', 'Procedures', 'Process', 'Process Assessment', 'Prognostic Marker', 'Protocols documentation', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Marker', 'Sampling', 'Slide', 'Stains', 'Standardization', 'Statistical Models', 'System', 'TP53 gene', 'Testing', 'Therapeutic Intervention', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Uncertainty', 'Validation', 'base', 'cancer diagnosis', 'cancer risk', 'cell type', 'clinical care', 'clinical risk', 'cohort', 'data integration', 'deep learning', 'disorder risk', 'genomic biomarker', 'genomic data', 'high risk', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'malignant mouth neoplasm', 'mouth squamous cell carcinoma', 'mutational status', 'novel', 'oral plaque', 'phenotypic data', 'predict clinical outcome', 'predictive modeling', 'prognostic value', 'prospective', 'risk stratification', 'treatment planning', 'whole slide imaging']",NIDCR,UNIVERSITY OF TX MD ANDERSON CAN CTR,R01,2021,691555
"Multimodal Intraoral Imaging System for Oral Cancer Detection and Diagnosis in Low Resource Setting Oral and oropharyngeal squamous cell carcinoma (OSCC) together rank as the sixth most common cancer worldwide, accounting for 400,000 new cancer cases each year. Two-thirds of these cancers occur in low- and middle-income countries (LMICs). While the 5-year survival rate in the U.S. is 62%, the survival rate is only 10- 40% and cure rate around 30% in the developing world. The poor survival rate in LMICs is mainly due to late diagnosis and the resultant progression of disease to an advanced stage at diagnosis. Therefore, it is imperative to diagnose precursor and malignant lesions in LRS early and expeditiously.  To meet the need for technologies that enable comprehensive oral cancer screening and diagnosis in low resource settings (LRS) to identify the suspicious lesions, triage the high-risk subjects and thereby enable appropriate treatment management and follow up, this project brings together an interdisciplinary team with complementary expertise in optical imaging, oncology, deep learning, technology translation, and commercialization. The team will develop, validate, and clinically translate a multimodal intraoral imaging system for oral cancer detection and diagnosis with better sensitivity and specificity. This work will address key barriers to adopting optical imaging techniques for oral cancer in LRS by building on the team’s experience in 1) developing and evaluating dual-mode (polarized white light imaging [pWLI] and autofluorescence imaging [AFI]) mobile imaging probes; 2) evaluating a low-cost, portable optical coherence tomography (OCT) system for oral cancer detection and diagnosis in a nodal center setting in India; and 3) developing and evaluating deep learning-based image classification algorithms for clinical decision-making guidance. As each of these key techniques has been demonstrated separately for oral cancer imaging in LRS, the potential of successfully developing a multimodal intraoral imaging system for accurate, objective and location-resolved diagnosis of oral cancer and transitioning to a new capability to medical professionals in LRS is very high. To achieve the project objective, the team proposes three Aims: 1) develop a portable, semi-flexible, and compact multimodal intraoral imaging system; 2) evaluate the clinical feasibility of the prototyped intraoral imaging system and develop deep learning-based image processing algorithms for early detection, diagnosis, and mapping of oral dysplastic and malignant lesions; and 3) validate the capability of the prototyped intraoral imaging system for diagnosing oral dysplasia and malignant lesions.  Successful completion of this project will lead to the transition of a multimodal intraoral imaging system and deep learning image classification that leverage the individual strengths of multiple technologies and deliver new and urgently-needed capabilities to the end users in LRS. This integrated system will 1) detect suspicious regions with high sensitivity and specificity; 2) triage the high-risk subjects; and 3) guide the selection of biopsy sites and map lesion heterogeneity to improve treatment planning and intra-operative guidance. The goal of this Academic-Industrial Partnerships project is to develop, validate, and clinically translate a multimodal intraoral imaging system for oral cancer detection and diagnosis in low resource settings (LRS). Successful completion of this project will lead to the transition of a multimodal intraoral imaging system enabled with deep learning image classification and deliver imperative capabilities to the dental professionals in LRS, significantly reducing the morbidity and mortality of oral cancer.",Multimodal Intraoral Imaging System for Oral Cancer Detection and Diagnosis in Low Resource Setting,10234778,R01DE030682,"['Accounting', 'Address', 'Adopted', 'Algorithms', 'Anatomy', 'Area', 'Arizona', 'Benign', 'Biopsy', 'California', 'Cancer Center', 'Cancer Detection', 'Classification', 'Clinical', 'Dental', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Dysplasia', 'Early Diagnosis', 'Ensure', 'Faucial pillar', 'Goals', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Techniques', 'India', 'Individual', 'Infrastructure', 'Institution', 'Lesion', 'Light', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Medical', 'Methods', 'Modality', 'Morbidity - disease rate', 'Multimodal Imaging', 'Network-based', 'Nodal', 'Oncology', 'Optical Coherence Tomography', 'Oral', 'Oral Diagnosis', 'Oral cavity', 'Oropharyngeal', 'Oropharyngeal Squamous Cell Carcinoma', 'Output', 'Participant', 'Performance', 'Resolution', 'Resources', 'Risk', 'Scanning', 'Schedule', 'Screening for Oral Cancer', 'Sensitivity and Specificity', 'Site', 'Stage at Diagnosis', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Training', 'Translating', 'Translations', 'Triage', 'Universities', 'Work', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer prevention', 'classification algorithm', 'clinical decision-making', 'clinical diagnostics', 'commercialization', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'experience', 'flexibility', 'follow-up', 'high risk', 'image guided', 'image processing', 'imaging probe', 'imaging system', 'impression', 'improved', 'industry partner', 'innovation', 'intraoral probe', 'low and middle-income countries', 'malignant mouth neoplasm', 'malignant oropharynx neoplasm', 'miniaturize', 'mortality', 'multimodality', 'neural network', 'optical imaging', 'oral care', 'oral dysplasia', 'oral lesion', 'portability', 'prototype', 'recruit', 'response', 'rural area', 'screening', 'standard of care', 'tongue root', 'tool', 'treatment planning', 'user-friendly']",NIDCR,UNIVERSITY OF ARIZONA,R01,2021,693571
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,10415277,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'teleophthalmology', 'tool']",NEI,WAKE FOREST UNIVERSITY HEALTH SCIENCES,K23,2021,171651
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,10105327,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'teleophthalmology', 'tool']",NEI,DUKE UNIVERSITY,K23,2021,22123
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,10089451,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,376028
"Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography Project Abstract / Summary Primary open angle glaucoma (POAG) is a leading cause of blindness in the United States and worldwide. It is estimated that over 2.2 million Americans suffer from POAG and that over 130,000 are legally blind from the disease. As the population ages, the number of people with POAG in the United States will increase to over 3.3 million in 2020 and worldwide to an estimated 111.8 million by 2040. POAG is a progressive disease associated with characteristic functional and structural changes that clinicians use to diagnose and monitor the disease. Over the past several years, spectral domain optical coherent tomography (SDOCT) has become the standard tool for measuring structure in POAG. This 3D imaging modality provides a wealth of information about retinal structure and POAG-related retinal layers. This large amount of data is hard for clinicians to interpret and use effectively to help guide treatment decisions. Instead, summary metrics such as average layer thicknesses are used to reduce SDOCT images to a handful of values. While these metrics are useful, they can be difficult to interpret and they throwaway important information regarding voxel intensity and texture, relationships across retinal layers, and the overall 3D structure of the retina. Relying too heavily on these metrics limits our ability to gain a deeper understanding structural contributions to POAG, the relationship between structure and visual function, and how structural (and functional) changes progress in POAG. Recent advances in artificial intelligence and deep learning, however, offer new data-driven tools and techniques to interpret 3D SDOCT images and learn from the large SDOCT datasets being collected in clinics around the world. This proposal will apply state-of-the-art deep learning techniques to 3D SDOCT data in order to (1) develop more accurate POAG detection tools, (2) reveal structure-function relationships, and (3) predict structural and functional progression in POAG. This proposal also details a training plan to help the PI transition from a postdoctoral scholar to an independent researcher. The mentored phase of this award will be supervised by the primary mentor, Dr. Linda Zangwill, and a multidisciplinary mentoring team including Dr. Robert Weinreb (Ophthalmology), Dr. David Kriegman (Computer Science and Engineering), and Dr. Armin Schwartzman (Biostatistics). Performing the proposed research, formal coursework, and mentored career development will the provide the PI with highly sought- after skills and experience to help ensure a successful transition into independence. Project Narrative Three-dimensional imaging techniques such as optical coherence tomography have become an essential tool in the clinical care of glaucoma and other eye diseases. These imaging techniques provide clinicians with huge amounts of structural information, but interpreting the data and using it effectively to improve outcomes remains challenging in clinical glaucoma management. This project will improve patient care by applying powerful deep learning techniques to provide clinicians with critical decision support information to more accurately detect glaucoma, reveal associations between structure and visual function, and predict glaucoma progression.",Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography,10219269,K99EY030942,"['3-Dimensional', 'Affect', 'Age', 'American', 'Artificial Intelligence', 'Award', 'Biometry', 'Blindness', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Computational Technique', 'Cornea', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Ensure', 'Evaluation', 'Eye', 'Eye diseases', 'Frequencies', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Learning', 'Length', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Modeling', 'Monitor', 'Ophthalmology', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Population', 'Primary Open Angle Glaucoma', 'Probability', 'Progressive Disease', 'Race', 'Research', 'Research Personnel', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'South Korea', 'Standardization', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Texture', 'Thick', 'Thinness', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Training', 'Translating', 'United States', 'Universities', 'Vision', 'Visual Fields', 'Visualization', 'Width', 'Work', 'base', 'career development', 'clinical care', 'college', 'computer science', 'deep learning', 'experience', 'field study', 'imaging modality', 'improved', 'improved outcome', 'individual patient', 'large datasets', 'legally blind', 'macula', 'multidisciplinary', 'predictive modeling', 'preservation', 'research clinical testing', 'retinal nerve fiber layer', 'sex', 'skills', 'standard measure', 'three dimensional structure', 'tomography', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2021,117347
"Deep learning for oral premalignancy evaluation PROJECT ABSTRACT: The overall objective of this proposal is the development and validation of rapid, deep learning-based digital pathology biomarkers for predicting risk and biological evolution of premalignant lesions progression to invasive oral cavity squamous cell carcinoma (OCSCC). To accomplish this task, we have assembled a team of clinical experts in oral premalignancy biology and patient care, and will deploy a cutting-edge computational pipeline to create computational models using a massive data set of more than 4000 samples. This project seeks to meet a critical unmet need in characterizing and risk stratifying the precursor lesions for OCSCC. Premalignant oral dysplasias transform to OCSCC at an overall 15% rate. Unfortunately, no unified grading schema exists to reflect the risk of progression from premalignancy to OCSCC, and interrater agreement between pathologists is low. The ability to prioritize the aggressiveness of dysplasias would be of significant benefit for guiding oral premalignancy management, as patients with OCSCC suffer from 55% five-year survival, high post-treatment relapse rate, and morbid diagnostic and treatment options. The current histopathology standard for premalignancy risk is hematoxylin and eosin (HE) slide evaluation by an expert pathologist. With a prevalence approaching 10%, the high frequency of oral premalignant lesions makes HE data abundant, and this large amount of data is an ideal use application for artificial intelligence methods. Deep Learning is an emerging discipline within artificial intelligence where digital image information can be automatically processed in order to recognize patterns in digital histology images and accomplish classification tasks. Deep learning is the focus of our lab, and we have both published and preliminary data relevant to premalignancy progression prediction. The central hypotheses of this proposal is that tissue patterns within oral premalignancy digital pathology samples can be automatically risk-stratified using deep learning, and contain important hidden information, and contain important hidden information about individual prognosis. In order to evaluate this hypothesis, this proposal seeks to train, validate, and interrogate a series of deep learning-based predictors to automatically assess progression risk in oral premalignancy digital pathology images. Each deep learning classifier will be built from patient histology samples and directly observed clinical outcomes. To accomplish the proposal tasks, we will build a global, multi-institution repository of more than 4000 patient samples: the Oral Premalignancy Repository for Deep Learning (OPR-DL), designed for deep learning research. This application responds to Notice of Special Interest NOT-CA-20-031, which seeks to “advance early detection of head and neck cancer (HNC) … distinguishing benign from malignant lesions”; “Discover … technologies that could complement currently available clinical methods (e.g. pathology)”; and “validate imaging-based applications and data analysis tools”. This tool could guide treatments, minimize unnecessary diagnostic interventions, and improve care in resource- constrained environments. PROJECT NARRATIVE: There is a critical need in oral healthcare to improve the pathological classification of those oral premalignant lesions that eventually progress to cancer from those that do not. In this proposal we plan to build a series of computational risk models using a form of artificial intelligence called deep learning to quantify oral cavity squamous cell carcinoma (OCSCC) progression risk directly from premalignancy digital pathology images. To accomplish this impactful task we will combine our clinical experience in oral pathology and OCSCC care, our leading-edge deep learning platform, and a multi-institutional data set of more than 4000 patient samples.",Deep learning for oral premalignancy evaluation,10427078,R56DE030958,"['Aftercare', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Benign', 'Biological', 'Biological Markers', 'Biology', 'Biopsy', 'Caring', 'Case-Control Studies', 'Categories', 'Classification', 'Clinical', 'Clinical Management', 'Companions', 'Complement', 'Computer Models', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Dysplasia', 'Early Diagnosis', 'Environment', 'Evaluation', 'Event', 'Evolution', 'Frequencies', 'Genomics', 'Goals', 'Grant', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Healthcare', 'Hematoxylin and Eosin Staining Method', 'High grade dysplasia', 'Histologic', 'Histology', 'Histopathology', 'Human', 'Hyperplasia', 'Image', 'Individual', 'Institution', 'International', 'Intervention', 'Lesion', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical', 'Methods', 'Mild Dysplasia', 'Modeling', 'Moderate Dysplasia', 'National Institute of Dental and Craniofacial Research', 'Neurons', 'Oral', 'Oral Pathology', 'Outcome', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Prevalence', 'Process', 'Prognosis', 'Prospective cohort', 'Publishing', 'Relapse', 'Research', 'Resources', 'Risk', 'Sampling', 'Series', 'Severe dysplasia', 'Slide', 'Specialist', 'Stains', 'Technology', 'Testing', 'Tissues', 'Training', 'Validation', 'base', 'cancer invasiveness', 'cohort', 'computational pipelines', 'deep learning', 'design', 'digital', 'digital imaging', 'digital pathology', 'experience', 'follow-up', 'histological specimens', 'improved', 'interest', 'learning classifier', 'mouth squamous cell carcinoma', 'multiple datasets', 'novel', 'oral dysplasia', 'oral lesion', 'oral premalignancy', 'pathology imaging', 'predictive marker', 'premalignant', 'repository', 'risk prediction', 'risk stratification', 'tool', 'tumor progression']",NIDCR,UNIVERSITY OF CHICAGO,R56,2021,330611
"Non-invasive automated wound analysis via deep learning neural networks Project Summary: Each year millions of Americans develop chronic wounds, which require advanced wound care that has been estimated to cost $50 Billion annually. However, our understanding of chronic wounds and how to treat them has been limited by a lack of established methods to objectively characterize and measure wound features. Detailed assessments of wounds in the clinic and research laboratory often occur through histological analysis of tissue biopsies. This information can provide insight into cellular migration into the wound, cellular proliferation at the edge of the wound, infection, and fibrosis. However, the collection, creation, and analysis of histology sections is inherently invasive, time-consuming, and qualitative. The goal of this proposal is to develop an image analysis pipeline that can provide automated quantitative analysis of wounds and lay the groundwork for a non- invasive real-time “optical biopsy” that can provide information identical to standard histopathology. Our central hypothesis is that artificial intelligence approaches using deep learning convolutional neural networks can be coupled with in vivo multiphoton microscopy and existing quantitative image analysis methods to achieve this goal with the same accuracy as traditional biopsies with histological staining and expert analysis. In Aim 1, we will training and validate neural networks capable of segmenting and quantifying standard wound histology based on training from three independent wound healing research labs. In Aim 2, we will adapt this network to perform segmentation and quantification of in vivo label-free multiphoton microscopy images of skin wounds to provide rapid readouts of wound organization and metabolic function. Finally in Aim 3, we will develop and validate a network capable of generating virtual histology images from our stain-free non-invasive in vivo MPM images, which can be coupled with the networks developed in Aim 1 and 2 to provide a comprehensive assessment of wound microstructure and metabolism. In the near-term, this proposal will develop a series of robust analysis tools that can be applied to existing H&E-stained or unstained skin tissue sections commonly studied by wound healing researchers. In the long-term, the combination of label-free multiphoton microscopy and machine learning-based image analysis will enable completely non-invasive wound histology that can be performed in real-time at the point of care to guide debridement and wound care. Public Health Relevance: Non-healing wounds, such as diabetic foot ulcers, have emerged as a major health concern, particularly for older adults. This project will develop image analysis tools that can be combined with advanced optical imaging to provide a non-invasive optical biopsy of wounds to guide treatment and wound product development.",Non-invasive automated wound analysis via deep learning neural networks,10183917,R01EB031032,"['Address', 'Adoption', 'American', 'Animal Model', 'Architecture', 'Artificial Intelligence', 'Biochemical', 'Biopsy', 'Cell Count', 'Cell Proliferation', 'Cell physiology', 'Cellular Infiltration', 'Cellularity', 'Classification', 'Clinic', 'Clinical', 'Clinical assessments', 'Collagen', 'Collection', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Debridement', 'Dermatologic', 'Dermis', 'Diabetic Foot Ulcer', 'Disease', 'Elastin', 'Elderly', 'Epidermis', 'Excision', 'Feedback', 'Fibrosis', 'Fluorescence', 'Functional disorder', 'Future', 'Generations', 'Geometry', 'Goals', 'Granulation Tissue', 'Hair follicle structure', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Injury', 'Keratin', 'Label', 'Laboratory Research', 'Lipids', 'Machine Learning', 'Manuals', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'NADH', 'Operative Surgical Procedures', 'Optical Biopsy', 'Outcome', 'Pathologist', 'Psychological Transfer', 'Research', 'Research Personnel', 'Series', 'Skin', 'Skin Tissue', 'Source', 'Stains', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Visual', 'Wound Infection', 'analysis pipeline', 'automated analysis', 'automated segmentation', 'base', 'cell motility', 'cell type', 'chronic wound', 'cofactor', 'convolutional neural network', 'cost', 'crosslink', 'deep learning', 'deep neural network', 'histological image', 'histological stains', 'image processing', 'imaging Segmentation', 'in silico', 'in vivo', 'in vivo optical imaging', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'non-healing wounds', 'non-invasive imaging', 'optical imaging', 'pentosidine', 'point of care', 'product development', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'second harmonic', 'skin wound', 'tool', 'two-photon', 'virtual', 'wound', 'wound care', 'wound closure', 'wound healing']",NIBIB,UNIVERSITY OF ARKANSAS AT FAYETTEVILLE,R01,2021,424813
"Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing ABSTRACT No real-time quantitative devices are clinically used to assess oral lesions during routine examination, making in-clinic diagnostic and longitudinal monitoring challenging. Instead, lesions are evaluated through visual inspection and then histopathological analysis of tissue samples extracted during biopsy. Identifying premalignant and malignant oral lesions early is critical to ensuring effective treatment is provided to patients with malignancies. Oral cancer currently has one of the lowest 5-year survival rates (50% or less) among major cancer types, largely due to the challenges in identifying premalignant and malignant lesions early. Clearly, a real-time in-clinic device able to classify oral lesions as benign, premalignant, or malignant has the potential to provide immediate impact to patient care. Significantly different electrical property signatures have been observed between benign and malignant tissues in a variety of organs, including tongue; since the bioelectrical properties are so dependent on tissue architecture and morphology, we hypothesize that sensing and imaging these properties in the context of oral lesions will enable us to accurately characterize and classify morphologically-different benign, premalignant, and malignant oral lesions. We have developed an endoscopic electrical impedance imaging (EII) device for use in intraoperative surgical margin assessment that we aim to optimize for in-clinic oral lesion assessment. We aim to take the significant step of translating our extensive experience in impedance imaging to develop an oral lesion imaging device that can be deployed safely, and in the clinic, to provide real-time feedback regarding oral lesion classification. We propose constructing a novel chip-on-tip EII probe to sense and image at near microscopic resolution oral lesions in an effort to provide clinicians with real-time, accurate classification of oral lesion pathology that can be used for diagnostic and longitudinal monitoring purposes. The probe will be evaluated on a series of in vivo human oral lesions and compared with histopathological analysis of biopsy samples. The low-cost of a device such as this makes it an ideal technology for low-resource settings and the safety and real-time capabilities of the system make it ideal for continuously following lesions. PROJECT NARRATIVE Visual inspection of oral lesions is not sufficient for accurately classifying lesions as benign, premalignant, or malignant. The electrical properties of oral lesion have the potential to be used as a contrast mechanism to accurately classify oral lesions so that optimal treatment can be provided to patients with malignant lesions. We intend to deploy a novel small field of view chip-on-tip electrical impedance imaging (EII) probe in a cohort of patients with oral lesions to evaluate the efficacy of using EII for oral lesion classification.",Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing,10287597,R21DE031095,"['Architecture', 'Area', 'Benign', 'Biological Markers', 'Biopsy', 'Biopsy Specimen', 'Cancerous', 'Carcinoma', 'Carcinoma in Situ', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Contralateral', 'Custom', 'Data', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Dysplasia', 'Electrodes', 'Electronics', 'Ensure', 'Epithelial', 'Excision', 'Feedback', 'Frequencies', 'Hand', 'Histologic', 'Human', 'Hyperplasia', 'Image', 'Imaging Device', 'Ionizing radiation', 'Length', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Microscopic', 'Monitor', 'Morphology', 'Noise', 'Normal tissue morphology', 'Oral Characters', 'Oral cavity', 'Organ', 'Oropharyngeal', 'Pathology', 'Patient Care', 'Patients', 'Positioning Attribute', 'Procedures', 'Property', 'Research Design', 'Resolution', 'Resources', 'Safety', 'Sampling', 'Series', 'Signal Transduction', 'Site', 'Squamous Cell', 'Surgical margins', 'Survival Rate', 'System', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Translating', 'Visual', 'analog', 'base', 'bioelectricity', 'cancer type', 'cohort', 'cost', 'design', 'effective therapy', 'efficacy evaluation', 'electric impedance', 'electrical impedance tomography', 'electrical property', 'experience', 'extracellular', 'imaging probe', 'imaging properties', 'in vivo', 'interest', 'malignant mouth neoplasm', 'monitoring device', 'novel', 'optimal treatments', 'oral lesion', 'oral tissue', 'premalignant', 'pressure', 'pressure sensor', 'programs', 'response', 'soft tissue']",NIDCR,DARTMOUTH COLLEGE,R21,2021,191061
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10254429,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data repository', 'data sharing', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source tool', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'supplemental oxygen']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2021,196921
"Dual Energy CT-enabled Asymptomatic Pulmonary Embolism Detection on Non-contrast CT Project Summary Asymptomatic pulmonary embolism (PE) are often incidentally discovered from contrast computed tomography (CT) scans that do not target PE. It has a mean prevalence of 2.6% among patients and associated with increased mortality rate and recurrence of PE. Currently non-contrast CT are not read by radiologists for PE, because the hyperintensity signal of thrombolysis on NCCT is weak. Hence, around 2.6% of the patients with NCCT can have asymptomatic PE but are not diagnosed at all, which is potentially a large population.  We propose a deep learning-based automatic PE detection algorithm for single-energy NCCT to improve the cost-effectiveness to discover asymptomatic PE from NCCT. The algorithm will be used to identify patients with higher probability of PE and call for human reading or contrast CT scans. A major challenge is training data accumulation due to the relatively low prevalence of asymptomatic PE and hardness of reading NCCT. To overcome this challenge, we propose to utilize dual energy CT (DECT), which is becoming routinely used for PE diagnosis, to generate virtual non-contrast (VNC) images as training images. We propose to use deep learning algorithm for the VNC generation to fill the image quality gap between VNC images and real single-energy NCCT, which ensures that our PE detection algorithm trained on VNC images can be readily applied to real NCCT.  The expected outcome of the project is (1) a deep learning algorithm to generate realistic VNC images from contrast DECT; (2) a deep learning algorithm to screen PE from NCCT with high sensitivity. Project Narrative Asymptomatic pulmonary embolism (PE) is a pulmonary disorder which is usually incidentally found on contrast computed tomography (CT), but patients with non-contrast CT are often overlooked. This project will develop a deep learning-based PE detection algorithm for single-energy, non-contrast CT scans. Dual energy CT, which is an emerging technology for PE detection, will aid the development of algorithm by dramatically reducing the required human efforts.",Dual Energy CT-enabled Asymptomatic Pulmonary Embolism Detection on Non-contrast CT,10287287,R21EB031939,"['3-Dimensional', 'Acute', 'Algorithms', 'American', 'Appearance', 'Benign', 'Biological', 'Brain hemorrhage', 'Calcium', 'Chest', 'Clinical', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Embolism', 'Emerging Technologies', 'Ensure', 'Generations', 'Goals', 'Hardness', 'Hemorrhage', 'Human', 'Image', 'Inherited', 'Iodine', 'Label', 'Location', 'Low Prevalence', 'Lung diseases', 'Malignant - descriptor', 'Manuals', 'Modeling', 'Noise', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Prevalence', 'Probability', 'Pulmonary Embolism', 'Reader', 'Reading', 'Recurrence', 'Scanning', 'Signal Transduction', 'Specificity', 'Testing', 'Texture', 'Training', 'Validation', 'X-Ray Computed Tomography', 'algorithm development', 'algorithm training', 'attenuation', 'base', 'cohort', 'college', 'contrast enhanced', 'contrast imaging', 'cost effectiveness', 'deep learning', 'deep learning algorithm', 'deep neural network', 'detector', 'digital', 'image reconstruction', 'improved', 'mortality', 'prevent', 'radiologist', 'screening', 'supervised learning', 'thrombolysis', 'validation studies', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2021,448656
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'open source tool', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Enabling Next Generation Machine Learning for Large Scale Image Analysis Project Summary/Abstract Deep learning has transformed medical image analysis by delivering clinically meaningful results on challenging problems like prostate cancer detection and lung screening. In pathology, industry is making signiﬁcant invest- ments to develop deep learning tools for diagnostic use in clinical labs. FDA approval of whole-slide digital pathology images (WSIs) for use in primary diagnosis is further increasing interest, adoption, and investment in this technology. Judgments made by pathologists are the basis for the treatment of many diseases, yet in- terobserver variability among pathologists is signiﬁcant, and errors can lead to overtreatment or even treatment of healthy patients. Pathology is also facing workforce issues as demand for pathologist services is outpacing growth of trained pathologists. Computational pathology tools based on deep learning can help address these problems by providing reproducible diagnoses, performing ”second reads” for human pathologists, automating tasks to improve pathologist efﬁciency, and helping general pathologists evaluate challenging cases. GPU accel- erators have played a signiﬁcant role in advancing deep learning methods to build computational pathology tools, with machine learning frameworks (MLFs) like Pytorch and Tensorﬂow providing researchers with abstractions to quickly develop models that utilize GPUs. Evolution of GPUs and MLFs has been driven by analysis of small images, and so these tools cannot be easily applied directly WSIs or other large medical images like three dimen- sional MRI or CT. Adapting medical imaging problems to small image paradigms supported by GPUs and MLFs leads to suboptimal performance and increased implementation effort and complexity. More recent approaches that use streaming or ”uniﬁed memory” allow direct analysis of entire WSIs and have demonstrated performance advantages. These approaches can be slow, complex to implement, and are highly speciﬁc to a choice of network architecture which limits exploration and development of new architectures. More general-purpose, efﬁcient, and user-friendly frameworks are required to allow the development of WSI scale deep learning.  This project will develop techniques to automatically map deep learning networks implemented in common MLF architectures to one or more GPUs for arbitrarily large input images and activation layers. The proposed software will include a performance modeler to estimate the runtime of a given network on available GPU acceler- ators. These strategies will enable a new paradigm in deep learning for medical images, allowing the development of novel networks that are purpose-built for medical applications. Developers will be able to rapidly create and evaluate these networks using familiar MLF packages. This project will provide approaches to overcome GPU memory bottlenecks, a scheduler to map the network to available GPUs, integration with common MLFs, and demonstration using computational pathology use cases. Narrative The proposed tools will help software developers overcome the limitations of current computing hardware to design more accurate deep learning models for use in clinical diagnostics. These models will be able to analyze very large digitized images of glass slides to aid pathologists in tasks like cancer detection. The ability to analyze these images in their entirety instead of in small parts will improve the diagnostic accuracy of models and will accelerate algorithm development efforts.",Enabling Next Generation Machine Learning for Large Scale Image Analysis,10384903,R41EB032722,"['3-Dimensional', 'Address', 'Adoption', 'Architecture', 'Area', 'Cancer Detection', 'Caring', 'Classification', 'Clinical', 'Community Hospitals', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evolution', 'Generations', 'Glass', 'Goals', 'Government Agencies', 'Graph', 'Growth', 'Health', 'Healthcare Systems', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Incidence', 'Industry', 'Interobserver Variability', 'Investments', 'Judgment', 'Label', 'Lead', 'Learning', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Medical', 'Medical Imaging', 'Medical Students', 'Memory', 'Methods', 'Modeling', 'Movement', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Phase', 'Play', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Rural Hospitals', 'Schedule', 'Screening for Prostate Cancer', 'Services', 'Slide', 'Stream', 'Techniques', 'Technology', 'TensorFlow', 'Time', 'Training', 'Work', 'aging population', 'algorithm development', 'base', 'clinical application', 'clinical diagnostics', 'convolutional neural network', 'deep learning', 'design', 'diagnostic accuracy', 'digital imaging', 'digital pathology', 'implementation efforts', 'improved', 'interest', 'learning network', 'learning strategy', 'medical specialties', 'network architecture', 'neural network', 'next generation', 'novel', 'overtreatment', 'pathology imaging', 'prototype', 'screening', 'tool', 'tumor', 'user-friendly']",NIBIB,"RNET TECHNOLOGIES, INC.",R41,2021,256581
SCH: Leverage clinical knowledge to augment deep learning analysis of breast images  n/a,SCH: Leverage clinical knowledge to augment deep learning analysis of breast images,10435785,R01EB032896,"['Clinical', 'Knowledge', 'breast imaging', 'deep learning']",NIBIB,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,149066
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'substance use', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10162578,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2021,753275
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'open source tool', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746
"Neurodegenerative diseases and the role of green space: A deep learning assessment PROJECT SUMMARY Alzheimer’s disease and related dementias (ADRD) have well-established risk factors such as physical activity (PA), depression, and hypertension (HTN). These risk factors disproportionately affect racial minority populations, but the mechanisms underlying racial health disparities are not well understood. In this, geographic factors could be key, as PA, depression and HTN are strongly affected by geographic exposures, including green space. However, green space is typically measured with questionnaires, which have substantial error, or satellite-based indexes that are nonspecific and provide no information on the type of vegetation (e.g., tree vs. grass), nor whether the vegetation is within view at the street level. As a result, no study has quantified the contribution of green space to racial disparities in ADRD. And while novel technologies such as Google Street Views (GSV) imaging are promising data sources for capturing unique measures of green space, managing, processing, and analyzing high-dimensional data present significant logistical and analytical challenges, especially when linking these data to existing data from large prospective cohorts. Finally, we need to understand green space in the context of other potentially correlated geographic exposures, or the urban exposome—the totality of life- course geographic exposures (the set of green space, air pollutants, noise, built environment, and social environment)—to estimate which factors drive health. This proposal will address these challenges by using GSV imaging to assess the effect of green space on PA, depression, and HTN, as well as subsequent ADRD risk within the Multi-Ethnic Study of Atherosclerosis (MESA)—a 10-year longitudinal study of 6,814 men and women without clinical cardiovascular disease at baseline from 4 racial/ethnic groups (Non-Hispanic White, African-American, Chinese, and Hispanic). Aim 1 will quantify the effect of specific aspects of green space (e.g. trees, grass, shrubs, plants) on ADRD and cognitive decline and evaluate whether these associations differ according to race/ethnicity. Aim 2 will determine the indirect effect of green space on ADRD that is mediated through PA, depression, and HTN. Aim 3 will quantify exposome associations with ADRD and cognitive decline using untargeted data-driven approaches in conjunction with dimension reduction techniques and evaluate whether they differ according to race/ethnicity. This research plan is complemented by a training plan that builds on the applicant’s background in epidemiology and biostatistics and includes new training in (1) implementing deep learning algorithms to analyze high-resolution geographic data, (2) cognitive function epidemiology, and (3) developing and refining data-driven approaches to perform exposome-informed epidemiological studies. These combined plans will successfully prepare the applicant for an independent research career focused on identifying modifiable geographic determinants of ADRD in diverse populations using innovative measures of geographic context. Project Narrative Green space or trees and natural vegetation can provide mental health benefits and possibly lower risk of neurodegenerative diseases such as Alzheimer’s disease and related dementias (ADRD); however, green space is often measured poorly in epidemiologic research. I propose to integrate high-resolution images from Google Street Views to derive ground-level objective measurements of green space into a diverse prospective cohort study using deep learning algorithms, mediation analysis and geographic mixtures. This research will enable unprecedented perspectives on exposures that drive ADRD and related cognitive decline risk, and will provide translational insights into potential interventions to optimize opportunities for ADRD prevention and reduce racial disparities in ADRD.",Neurodegenerative diseases and the role of green space: A deep learning assessment,10146274,K99AG066949,"['Accounting', 'Address', 'Adult', 'Affect', 'African American', 'Age', 'Air Pollutants', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'Baltimore', 'Biological', 'Biometry', 'Cardiovascular Diseases', 'Chicago', 'Chinese People', 'Cities', 'Clinical', 'Complement', 'Complex', 'County', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Diagnosis', 'Dimensions', 'Elderly', 'Environment', 'Environmental Hazards', 'Epidemiology', 'Ethnic Origin', 'Ethnic group', 'Exposure to', 'Family', 'Funding', 'Geographic Factor', 'Geography', 'Goals', 'Green space', 'Health', 'Health Benefit', 'Healthcare', 'Hispanics', 'Hypertension', 'Image', 'Imagery', 'Impaired cognition', 'Incidence', 'Individual', 'Intervention', 'Lead', 'Life Cycle Stages', 'Link', 'Literature', 'Logistics', 'Longitudinal Studies', 'Los Angeles', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Multi-Ethnic Study of Atherosclerosis', 'Neurodegenerative Disorders', 'New York', 'Noise', 'Not Hispanic or Latino', 'Pathway interactions', 'Patients', 'Physical activity', 'Plants', 'Poaceae', 'Population', 'Population Heterogeneity', 'Prevalence', 'Prevention', 'Prevention strategy', 'Prospective cohort', 'Prospective cohort study', 'Questionnaires', 'Race', 'Research', 'Resolution', 'Risk', 'Risk Factors', 'Role', 'Social Environment', 'Social Impacts', 'Techniques', 'Time', 'Training', 'Trees', 'United States National Institutes of Health', 'Woman', 'aged', 'base', 'built environment', 'career', 'cognitive function', 'cohort', 'comorbidity', 'deep learning', 'deep learning algorithm', 'dementia risk', 'design', 'economic impact', 'epidemiology study', 'ethnic minority population', 'healthy aging', 'high resolution imaging', 'indexing', 'innovation', 'insight', 'longitudinal analysis', 'men', 'multidimensional data', 'neurocognitive disorder', 'new technology', 'novel', 'physical inactivity', 'public health intervention', 'racial and ethnic', 'racial disparity', 'racial health disparity', 'racial minority', 'segmentation algorithm', 'skills', 'urban public health']",NIA,HARVARD SCHOOL OF PUBLIC HEALTH,K99,2021,118800
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,10137892,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Prognosis', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'prognostic model', 'recurrent neural network', 'risk prediction', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,482108
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,10202485,R01AR074492,"['3-Dimensional', 'Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Canes', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Extracellular Matrix', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Societies', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'efficacy evaluation', 'flexibility', 'gait examination', 'gait rehabilitation', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'kinetic model', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2021,425647
"HEALing LB3P: Profiling Biomechanical, Biological and Behavioral phenotypes ABSTRACT Chronic Low Back Pain (CLBP) is a complex multi-factorial condition, as well as the most prevalent painful musculoskeletal disorder worldwide. Identifying the optimal treatment for CLBP on a patient-specific basis is an important and unresolved challenge in medicine. Tailoring interventions according to patient movement characteristics may improve clinical outcomes. Patients with CLBP are heterogenous in terms of their symptoms, clinical exam findings, and conventional medical imaging results. For most patients, the optimal treatment plan is unknown, therefore it is challenging for the clinician to prescribe an appropriate and cost- effective course of treatment. One important clinical characteristic that can be used for classification is severity of physical impairment (problems in lumbar spine structure and function) and resulting activity limitation (difficulty executing activities). A common approach to assess the impact of physical impairment is using patient-reported outcomes (PROs), wherein patients rate their perceived ability to perform various activities in their usual environment. PROs are subjective and discrepancies have been observed between how patients score PROs and how they perform activities when observed in the clinic. It is advantageous to complement PROs with objective performance-based measures of physical function. Therefore, the overall hypothesis of the Biomechanical Core of the parent grant is that including patient-specific spine biomechanics in predictive models improves our ability to characterize CLBP patients. To that end, the purpose of this administrative supplement is to expand upon Specific Aim 2 of the Biomechanical Core, which is to characterize lumbopelvic kinematics during functional tasks and daily activities using wearable (inertial) motion sensors. Specifically, this work will aim to develop deep (machine) learning algorithms that can correctly identify and characterize motions of the lumbar spine during both clinical and field assessments. During the clinical assessments, participants will be asked to perform functional tasks while wearing inertial measurement units (IMUs). Collected data will be used to develop and train machine learning algorithms to identify tasks of interest such as activities of daily living and aberrant/painful motions. The deep learning algorithms developed will be used to label lumbar motion data collected continuously during field assessment in patients' homes over a 7-day testing period. The supplemental data will be compared with the standard data analyses approaches proposed for the overall study and included with the LB3P phenotyping. Moreover, the deep learning algorithms will serve as the foundation for the development of ecological momentary interventions that are responsive to patient's real-world functional impairments related to CLBP. PROJECT NARRATIVE Identifying the optimal treatment for chronic Low Back Pain (CLBP) on a patient-specific basis is an important and unresolved challenge in medicine. This supplemental proposal aims to develop deep (machine) learning algorithms that can correctly identify and characterize motions of the lumbar spine during both clinical and field assessments. These data will be compared with the standard data analyses approaches proposed for the overall study, included with the phenotyping proposed in the parent proposal, and will serve as the foundation for the development of ecological momentary interventions that are responsive to patient's real-world functional impairments related to CLBP.","HEALing LB3P: Profiling Biomechanical, Biological and Behavioral phenotypes",10406064,U19AR076725,"['Acceleration', 'Activities of Daily Living', 'Administrative Supplement', 'Algorithms', 'Back', 'Biological', 'Biomechanics', 'Characteristics', 'Chronic low back pain', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical assessments', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Ecological momentary assessment', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Goals', 'Hip Joint', 'Hip region structure', 'Home', 'Impairment', 'Intervention', 'Label', 'Lateral', 'Lifting', 'Low Back Pain', 'Measurement', 'Medical Imaging', 'Medicine', 'Motion', 'Movement', 'Musculoskeletal Diseases', 'Outcome', 'Pain', 'Parents', 'Participant', 'Patient Outcomes Assessments', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Physical Function', 'Research', 'Rotation', 'Severities', 'Structure', 'Symptoms', 'Testing', 'Thigh structure', 'Training', 'Universities', 'Validation', 'Vertebral column', 'Visual', 'Walking', 'Work', 'behavioral phenotyping', 'classification algorithm', 'clinical examination', 'cost effective', 'data standards', 'deep learning algorithm', 'experience', 'falls', 'functional disability', 'healing', 'improved', 'insight', 'interest', 'kinematics', 'machine learning algorithm', 'motion sensor', 'multimodality', 'optimal treatments', 'pain patient', 'parent grant', 'performance based measurement', 'predictive modeling', 'supervised learning', 'treatment planning']",NIAMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U19,2021,176168
"Ultra-Fast Knee MRI with Deep Learning ABSTRACT Fast, robust and reliable quantitative knee joint MR imaging would be a significant step forward in studying joint degeneration, injury and osteoarthritis (OA). Automation of compositional and morphological feature extraction of the tissues in the knee it is an essential step for translation to clinical practice of promising quantitative techniques. It would enable the analysis of large patient cohorts and assist the radiologist/clinician in augmenting the value of MRI. Automation of several human tasks has been achieved in the last few years by the usage of Deep Learning techniques. With the availability of large amounts of annotated data and processing power, using the concepts of transforming data to knowledge by the observation of examples, supervised learning can today accomplish challenges never demonstrated before. In addition to image analysis and interpretation, Deep Learning is revolutionizing the acquisition and reconstruction aspects of the pipeline. Models can learn a direct mapping between under sampled k-space and image domain. While Deep Learning application to musculoskeletal imaging showed promising results when applied in a controlled setting, it is well understood that generalization beyond the statistical distribution of the training set is still an unmet challenge. In MRI this translates into poor performances when trained models are tested on different imaging protocols or images acquired on different MRI systems. With this proposal, we aim to leverage on this recent advancement and filling the existing gaps. We aim to study novel integrated models able to simultaneously accelerate MRI acquisition and automate the image processing that can overcome the limitation of single domain application. Fast image acquisition and accurate image post processing are typically considered to be separate problems. However, the neural networks optimization design gives us an opportunity to integrate the two to maximize both acceleration and machine-based image processing and interpretation. We will use both publicly available benchmark dataset (FastMRI) and internally collected dataset to build deep learning models able to accurately reconstruct under sampled MRI acquisitions. We will use a dataset prospectively acquired during the course of this study to validate the clinical applicability of the developed methods. Specifically, we will test the hypothesis that the proposed integrated pipeline can be applied in clinical setting for a fast and intelligent knee scan obtaining image quality comparable to standard acquisition and automated processing accuracy comparable with human reproducibility. Additionally, we propose to make our annotated image datasets and trained models a shared resource, a centralized, open evaluation platform for MRI reconstruction and image post processing techniques. NARRATIVE This study aims to use Deep Learning to simultaneously accelerate knee MRI acquisition and automate post processing pipelines including multi tissue segmentation, detection and severity staging of osteoarthritis degenerative changes. The proposed study builds a novel translational platform to revolutionize knee MR images in research studies, but also is paradigm-shifting in that it may provide a first step towards on real time automatic image inspection and personalized imaging protocolling.",Ultra-Fast Knee MRI with Deep Learning,10177641,R01AR078762,"['3-Dimensional', 'Acceleration', 'Area', 'Automation', 'Bayesian Modeling', 'Benchmarking', 'Cartilage', 'Characteristics', 'Clinical', 'Collection', 'Complement', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Ensure', 'Evaluation', 'Human', 'Image', 'Image Analysis', 'Injury', 'Intelligence', 'Knee', 'Knee joint', 'Label', 'Lead', 'Learning', 'Licensing', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Patient Triage', 'Patients', 'Performance', 'Probability', 'Process', 'Protocols documentation', 'Protons', 'Radiology Specialty', 'Reader', 'Reading', 'Reproducibility', 'Research', 'Resolution', 'Resource Sharing', 'Sampling', 'Scanning', 'Severities', 'Signal Transduction', 'Staging', 'Standardization', 'Statistical Distributions', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Translations', 'Uncertainty', 'Vendor', 'base', 'clinical application', 'clinical practice', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'convolutional neural network', 'data space', 'data to knowledge', 'deep learning', 'density', 'design', 'domain mapping', 'experimental study', 'feature extraction', 'heterogenous data', 'image processing', 'image reconstruction', 'imaging system', 'joint destruction', 'learning ability', 'musculoskeletal imaging', 'neural network', 'new technology', 'novel', 'open source', 'preservation', 'prospective', 'radiologist', 'reconstruction', 'recruit', 'research study', 'sensor', 'supervised learning', 'tool', 'validation studies']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,574344
"New Computational Methods for Data-driven Protein Structure Prediction Proteins play fundamental roles in all biological processes. Accurate description of protein structure is an important step towards understanding of biological life and highly relevant in the development of therapeutics and drugs. Although experimental structure determination has been greatly improved, there is still a very large gap between the number of available protein sequences and that of solved protein structures, which can only be filled by computational prediction. The long-term goal of this project is to apply machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing sequence, structure and functional data and to develop data-driven computational methods and tools for structure and functional prediction. We believe that by developing sophisticated algorithms to extract knowledge from the increasing sequence and structure data, we can model protein sequence-structure relationship very accurately and improve structure and functional prediction greatly. This project has already produced a few CASP-winning, widely-used data- driven algorithms and web servers (http://raptorx.uchicago.edu) for protein structure modeling. This renewal will further develop machine learning (especially deep learning) algorithms for protein structure modeling without good templates. The specific aims are: (1) developing deep learning (DL) algorithms for the prediction of protein contact and distance matrix; (2) developing distance-based algorithms for fast and accurate ab initio folding of proteins without templates; (3) developing DL algorithms for template-based modeling with only weakly similar templates. This renewal will lead to further understanding and new models of protein sequence-structure relationship and yield publicly available resources for automated, accurate, quantitative analysis for a wide range of proteins. The impact will be multiplied by tens of thousands of worldwide users employing our web servers to study a wide variety of proteins relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure relationship and to predict protein structures. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,10246779,R01GM089753,"['Abbreviations', 'Address', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computing Methodologies', 'Coupling', 'Crystallography', 'Data', 'Development', 'Disease', 'Foundations', 'Genetic Transcription', 'Geometry', 'Goals', 'Health Care Costs', 'Homology Modeling', 'Hydrogen Bonding', 'Knowledge', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Membrane Proteins', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Molecular Conformation', 'Occupations', 'Pharmaceutical Preparations', 'Play', 'Preventive therapy', 'Process', 'Protein Family', 'Proteins', 'Residual state', 'Resources', 'Role', 'Sequence Analysis', 'Sequence Homologs', 'Structural Models', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'System', 'Time', 'Torsion', 'Training', 'Translations', 'Variant', 'Vertebral column', 'Work', 'base', 'biological research', 'computerized tools', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'experimental study', 'human disease', 'improved', 'learning strategy', 'model building', 'neural network', 'novel diagnostics', 'novel therapeutics', 'prediction algorithm', 'predictive modeling', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'simulation', 'therapeutic development', 'three-dimensional modeling', 'web server']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2021,321599
"Distance-based ab initio protein structure prediction Project Summary Predicting the three-dimensional structures of proteins without using known structures from the Protein Data Bank (PDB) as templates (ab initio) remains a grand challenge of computational biology. Whereas template-based modeling is now a mature field, ab initio modeling is a comparatively nascent one, especially for large proteins with complex topologies and multiple domains. The need for advances in ab initio modeling is evident. A lot of protein sequences do not have (recognizable) templates in the PDB, and the pace of experimental structure determination is incommensurate with the scale of the problem. Herein, we propose a new approach to ab initio modeling that consists of novel deep learning architectures to predict inter- residue distances and domain boundaries as well as robust, iterative optimization methods to construct tertiary structures from the predicted distances. This project builds on the success of our current R01, particularly the outstanding performance of the Cheng group in the 2018 worldwide protein structure prediction experiment – CASP13 – where our MULTICOM suite ranked among the top three tertiary structure predictors, alongside Google DeepMind’s AlphaFold. The methods will be implemented as open-source tools for the emerging field of distance-based ab initio protein structure modeling. We will apply the methods to study protein homo-oligomers and self-assemblies, based on our novel discovery that the quaternary structure contacts within homo-oligomers can be predicted by deep learning methods from the co-evolutionary signals embedded in multiple sequence alignments of protein monomers. Furthermore, we will apply the methods to predict the folds, functional sites, superfamilies, and protein-protein interactions of proteins that contain “essential Domains of Unknown Function” (eDUFs), a group of evolutionarily conserved, essential proteins that represents an important uncharted region of protein function/fold space. The predictions for a diverse and representative subset of eDUFs will be experimentally validated through a unique collaboration with the structural biology group of Dr. Tanner. Project Narrative Three-dimensional protein structure information is indispensable in modern biomedical research, but experimental techniques will only resolve a small fraction of known proteins due to the considerable cost. This project will develop cutting-edge computational methods based on modern artificial intelligence (AI) technology to reliably predict protein structures from sequence information alone. The prediction tools will be applied through collaborations with experimental scientists and disseminated to the community.",Distance-based ab initio protein structure prediction,10251061,R01GM093123,"['3-Dimensional', 'Amino Acid Sequence', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Biomedical Research', 'C-terminal', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Conflict (Psychology)', 'Dependence', 'Development', 'Genome', 'Hereditary Disease', 'Homo', 'Maps', 'Methods', 'Modeling', 'Modernization', 'Mutate', 'Performance', 'Play', 'Problem Solving', 'Protein Engineering', 'Protein Region', 'Proteins', 'Recurrence', 'Renaissance', 'Residual state', 'Role', 'Scientist', 'Sequence Alignment', 'Signal Transduction', 'Site', 'Structural Models', 'Structural Protein', 'Structure', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Weight', 'X-Ray Crystallography', 'base', 'biophysical techniques', 'comparative', 'convolutional neural network', 'cost', 'deep learning', 'design', 'drug development', 'empowered', 'experience', 'experimental study', 'improved', 'learning network', 'learning strategy', 'long short term memory', 'monomer', 'novel', 'novel strategies', 'open source tool', 'protein data bank', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure prediction', 'reconstruction', 'recurrent neural network', 'self assembly', 'structural biology', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tool']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,342174
"Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization PROJECT SUMMARY Assisted Reproduction Technology (ART) is a clinical treatment for infertile couples who want to achieve a pregnancy. In ART, embryologists fertilize eggs retrieved from the patient or a donor, culture the resulting embryos in vitro, and then transfer the selected embryo(s) to the mother's uterus. While ART is responsible for 1.9% of babies born in the United States as of 2018, selecting which embryo to transfer is a signiﬁcant challenge. The difﬁculty comes from the complexity of confounding factors and the lack of understanding of human pre-implantation embryo development. Because of this difﬁculty, multiple embryos are often transferred to increases the potential of success, resulting in multiple pregnancy rates of nearly 20%, which can lead to signiﬁcant morbidity and medical expenses to patients. The ideal is to transfer only a single embryo, but this necessitates the ability to select the best embryo from a cohort. Here, we propose to create a clinical decision support system to improve embryo selection in ART. To this end, we will develop novel deep learning models for robust embryo feature extraction and interactive data visualization methods for human-in-the-loop analysis. We will ﬁrst extract and analyze visual features from routinely collected images of embryos. We will then combine these visual features with patients' electronic health record (EHR) data to develop interpretable computation models that score embryos on their viability. We plan to integrate our machine learning solutions into an easily accessible cloud service platform that will be adaptable across clinics to improve ART embryo selection and clinical data analysis. Our research goals will be achieved by novel machine learning-based models for morphological feature extrac- tion and importance estimation of each confounding factor and a clinical decision support system for ART. For morphological feature extraction, we plan to conduct semi-supervised learning of convolutional neural networks to minimize manual labeling that requires extensive human effort. Our feature extraction model will be the ﬁrst comprehensive classiﬁcation and segmentation method for ART. To aid in embryo selection, we will develop novel deep learning-based models to predict probabilities of achieving pregnancy by accepting visual features and EHR data as the input. We will also develop visual analytic tools that allow analysts to better understand and steer these deep learning models. We will estimate the importance of each input interpretable factor in embryo selection to explain the prediction to embryologists. Finally, we will develop EmbryoProﬁler, a clinical decision support system for ART, that combines our machine learning-based models with a user-facing suite of visual analytic tools to support user guidance and clinical decision making. EmbryoProﬁler will help facilitate daily operation in clinics, foster human-guided decision making, enrich data-driven embryo analysis, and enhance the ability to select the developmentally most competent embryo for transfer to improve ART success rates. Our project will create state-of-the-art analysis approaches for ART clinicians. PROJECT NARRATIVE Assisted Reproductive Technology (ART) is a widespread treatment for infertility, over 300,000 treatment cycles were performed in the US in 2018, but success rates remain low. In this project, we will develop novel machine learning algorithms and a clinical decision support system to assist embryologists in embryo selection. Our tools will also enable embryologists and biologists to obtain new information on the earliest stages of human embryo development, which will advance the fundamental science of human biology and lead to further improvements in ART practice.",Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization,10185936,R01HD104969,"['Adopted', 'Age', 'Assisted Reproductive Technology', 'Back', 'Cell Lineage', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Cloud Service', 'Communities', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Computers', 'Couples', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Making', 'Detection', 'Development', 'Discipline', 'E-learning', 'Electronic Health Record', 'Embryo', 'Embryo Transfer', 'Embryonic Development', 'Fostering', 'Goals', 'Human', 'Human Biology', 'Image', 'Image Analysis', 'In Vitro', 'Judgment', 'Knowledge', 'Label', 'Lead', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Mothers', 'Multiple Pregnancy', 'Obesity', 'Patients', 'Pattern', 'Physiological', 'Pre-implantation Embryo Development', 'Pregnancy', 'Pregnancy Rate', 'Privacy', 'Probability', 'Research', 'Science', 'Scientist', 'Secure', 'Security', 'Text', 'Time', 'Trees', 'United States', 'Ursidae Family', 'Uterus', 'Visual', 'Visualization', 'Visualization software', 'analytical tool', 'base', 'blastocyst', 'clinical decision-making', 'clinical practice', 'cloud based', 'cohort', 'convolutional neural network', 'data cleaning', 'data curation', 'data management', 'data visualization', 'deep learning', 'embryo cell', 'embryo monitoring', 'feature extraction', 'human-in-the-loop', 'implantation', 'improved', 'infertility treatment', 'insight', 'large scale data', 'machine learning algorithm', 'microscopic imaging', 'model design', 'multi-task learning', 'multimodality', 'novel', 'operation', 'predictive modeling', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'zygote']",NICHD,HARVARD UNIVERSITY,R01,2021,730410
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,10168666,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'aggressive therapy', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'disability risk', 'improved', 'improved outcome', 'intervention effect', 'large datasets', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,555363
Deep learning based estimation of TMS electric fields N/A per FOA PA-21-071. N/A per FOA PA-21-071.,Deep learning based estimation of TMS electric fields,10405791,R01NS109498,"['base', 'deep learning', 'electric field']",NINDS,UNIVERSITY OF MINNESOTA,R01,2021,80493
"Diagnosis of indeterminate brain lesions using MRI-based machine learning and polygenic risk models PROJECT SUMMARY In 2017 an MRI was performed at a rate of over one for every 10 US residents. The majority of these were brain MRIs. Indeterminate mass lesions are present on over 1% of brain MRIs in individuals over 45 years old. Misinterpretation of brain MRI can lead to significant iatrogenic morbidity and mortality. For example, tumefactive Central Nervous System Inflammatory Demyelinating Disease (CNSIDD) is commonly misdiagnosed as a malignancy, even following pathological review. This results in inappropriate brain biopsies, debulking and radiation. While early tumor resection is associated with favorable outcome in patients with high- grade glioma, observation, biopsy at an alternate site or nonsurgical options are often more appropriate for other indeterminate mass lesions that can encompass low-grade primary brain tumor, CNSIDD, CNS lymphoma and brain metastasis. Thus, to prevent iatrogenic morbidity, there is a critical need for scalable and reproducible methods to distinguish CNSIDD from other brain lesions, and to accurately diagnose brain tumors prior to biopsy. We recently published a polygenic risk model demonstrating that the 25 known glioma germline risk variants can estimate absolute and lifetime glioma risk. The clinical significance of these models is driven by germline variants that are associated with >4-fold increased risk of glioma. We have also shown that the same 25 germline variants can predict glioma molecular subtype. As a complementary approach, we have shown that imaging characteristics differ across glioma, CNSIDD, CNS lymphoma and brain metastases. We have successfully utilized MRI-based machine learning to predict the molecular subtype in high-grade glioma. We hypothesize that both germline genotyping and MRI-based machine learning provide an opportunity to diagnose indeterminate mass lesions as well as predict glioma molecular subtype prior to surgery and thus personalized treatment. The project has the following three aims: Aim 1: Develop and validate a MRI-based machine learning model to differentiate adult diffuse glioma from tumefactive CNSIDD, CNS lymphoma and solitary brain metastases of unknown primary. Aim 2: Evaluate sensitivity and specificity of the polygenic glioma risk model to differentiate adult diffuse glioma from tumefactive CNSIDD, CNS lymphoma and solitary brain metastases. Aim 3: Integrate the polygenic glioma subtype model and MRI-based machine learning model to predict adult diffuse glioma molecular subtype and validate the integrated model using a prospective cohort. The proposed project will further enhance the care of patients by determining if an early MRI lesion is actually a glioma. Early definitive surgery in these patients could be curative. PROJECT NARRATIVE Indeterminate mass lesions are present on over 1% of brain MRIs in individuals over 45 years old, and misinterpretation of brain MRI can lead to significant iatrogenic morbidity and mortality. To prevent iatrogenic morbidity, there is a critical need for scalable and reproducible methods to distinguish indeterminate brain lesions from each other, and to accurately diagnose brain tumors prior to biopsy. We hypothesize that both germline genotyping and MRI-based machine learning provide an opportunity to diagnose indeterminate mass lesions as well as predict glioma molecular subtype prior to surgery and thus personalized treatment.",Diagnosis of indeterminate brain lesions using MRI-based machine learning and polygenic risk models,10224946,R01NS113803,"['Academic Medical Centers', 'Adult', 'Biological Assay', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain Pathology', 'Central Nervous System Lymphoma', 'Characteristics', 'Clinical', 'Data', 'Demyelinating Diseases', 'Development', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffuse', 'Effectiveness', 'Excision', 'Genotype', 'Glioma', 'Iatrogenesis', 'Image', 'Individual', 'Inflammatory', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measures', 'Metastatic malignant neoplasm to brain', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Mutate', 'Neoplasm Metastasis', 'Neuraxis', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Patients', 'Predictive Value', 'Predisposition', 'Primary Brain Neoplasms', 'Prospective cohort', 'Prospective cohort study', 'Publishing', 'Radiation', 'Reproducibility', 'Research', 'Risk', 'Running', 'Sensitivity and Specificity', 'Site', 'Specificity', 'Training', 'Tumor Debulking', 'Variant', 'Work', 'accurate diagnosis', 'base', 'clinically significant', 'cohort', 'cost', 'diagnostic accuracy', 'improved', 'molecular subtypes', 'mortality', 'personalized medicine', 'prevent', 'prospective', 'risk variant', 'tool', 'tumor']",NINDS,MAYO CLINIC ROCHESTER,R01,2021,623080
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,10164762,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Villous Atrophy', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'dietary', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'systemic inflammatory response', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2021,192552
"Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders The purpose of this training and research application is to study the functional impact of mobile element insertions (MEIs) in neurological disorders (NDs) using new developments in deep learning techniques. MEIs are transposable DNA fragments that are able to insert throughout the human genome. There are at least 124 independent MEIs associated with human diseases. Approximately 20% of these diseases represent a spectrum of NDs, yet the overall contribute of MEIs to the etiology of NDs has not been systematically estimated. To address this, we will (1) characterize functional MEIs in GTEx cohorts in healthy individuals; (2) build a comprehensive functional map of MEIs to determine tissue-specific and brain-specific impact; and (3) impute transcriptional changes on various NDs where whole-genome sequencing (WGS) data will be generated. The proposed application will also develop an extensive research program for Dr. Dadi Gao, a computational biologist and statistical geneticist who has trained in functional genomic studies of alternative splicing in neurodegenerative disorders and therapeutic targeting of a splicing defect that causes a severe neurodevelopmental disorder. He has developed novel methods to investigate regulation of the transcriptome and to facilitate analyses in drug development. He now seeks to expand his expertise by applying statistical and deep learning models on large cohorts of sequencing data from controls and cases with NDs from post-mortem tissues, then impute functional consequences of MEIs from WGS in large-scale disease cohorts. The training plan consists of two years of mentored research to learn new skills in genome analysis, MEI characterization, and advanced deep learning techniques, followed by three years of shaping an independent laboratory. The research plan is developed to comprehensively explore functional variation in the genome by decomposing transcriptomic changes against MEIs. Dr. Michael Talkowski at Massachusetts General Hospital, Harvard, and the Broad Institute will serve as the primary mentor, while Dr. Manolis Kellis at MIT and the MIT Computational Biology Group, and the Broad Institute will serve as a co-mentor and close collaborator. These mentors are recognized experts in genomic structural variants, functional genomics, the genetics of neurological disorders, and computational modeling to establish functional elements in the human genome. In addition, a team of independent investigators from basic and translational research will provide Dr. Gao with comprehensive feedback to keep both his science and career development on track. The highly collaborative environment in CGM, MGH, Harvard Medical School, the Broad Institute and the University of Michigan Medical School will prepare Dr. Gao for his transition to an independent investigator. This outstanding mentorship team and training program will facilitate the career development of Dr. Gao as he seeks to redefine the functional maps of MEIs in the human genome and to impute their impact in large-scale neurological disorders. Mobile element insertions (MEIs) represent a largely undefined component of the genetic architecture of neurological disorders, as a number of MEIs have been associated with alternative splicing in these disorders but large-scale genome-wide functional characterization has not been systematically performed across tissues. This program study will functionally characterize the impact of MEIs on alternative splicing from whole-genome sequencing and transcriptome sequencing in large cohorts using new developments in deep learning models. These results will enhance our understanding of the etiological role and pathogenic mechanisms associated with MEIs in neuronal development and human neurological disorders.",Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders,10261424,K99NS118109,"['Address', 'Algorithms', 'Alternative Splicing', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Basic Science', 'Biology', 'Blood', 'Brain', 'Brain Diseases', 'CRISPR/Cas technology', 'Cells', 'Chromosome Pairing', 'Cohort Studies', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Insertion Elements', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Disease', 'Disease model', 'Dorsal', 'Elements', 'Etiology', 'Event', 'Evolution', 'Excision Repair', 'Familial Dysautonomia', 'Feedback', 'Fellowship', 'Filipino', 'General Hospitals', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Haplotypes', 'Human', 'Human Genome', 'Individual', 'Institutes', 'International', 'Introns', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Linear Regressions', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Mind', 'Minisatellite Repeats', 'Modeling', 'Molecular', 'Mosaicism', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'Neurons', 'Outcome', 'Pathogenicity', 'Pattern', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Prefrontal Cortex', 'Process', 'Property', 'RNA Splicing', 'Regulation', 'Research', 'Research Personnel', 'Retroelements', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Shapes', 'Short Interspersed Nucleotide Elements', 'Source', 'Specificity', 'Structure', 'TAF1 gene', 'Techniques', 'Therapeutic Trials', 'Tissue-Specific Splicing', 'Tissues', 'Training', 'Training Programs', 'Transcription Alteration', 'Translational Research', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'X-linked dystonia parkinsonism', 'brain tissue', 'career development', 'cohort', 'collaborative environment', 'convolutional neural network', 'deep learning', 'drug development', 'functional genomics', 'functional outcomes', 'gene function', 'genetic architecture', 'genome analysis', 'genome editing', 'genome sequencing', 'genome-wide', 'human disease', 'in silico', 'insight', 'medical schools', 'mind control', 'nervous system disorder', 'neuron development', 'novel', 'programs', 'response', 'skills', 'statistical learning', 'structural genomics', 'therapeutic target', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,126866
"Detection and evolution of diffusely abnormal white matter in multiple sclerosis: a deep learning approach Multiple sclerosis (MS) is the most widespread non-traumatic, demyelinating disorder in young adults. Magnetic resonance imaging (MRI) aids in both diagnosing MS and assisting clinical management of patients. In addition to focal MS lesions, diffusely abnormal white matter (DAWM) is also seen on brain MRI in MS patients. While not understood completely, DAWM is thought to be a predictor of disease burden, possibly appears early on in the disease, and may be a marker of neurodegeneration in MS. However, longitudinal studies of DAWM are lacking, and segmentation of DAWM is manual, making it difficult to study the evolution of DAWM. The main objective of this proposal is to longitudinally study the development of DAWM in MS. This objective will be realized by analyzing preexisting longitudinal MRI data acquired on 1008 MS patients who participated in phase 3, blinded, multi-center clinical trial, referred to as CombiRx that was supported by NIH. The CombiRx data includes multi-contrast MRI and various clinical measures. Automatic identification of DAWM is a critical component of this proposal. Based on our preliminary studies, deep Learning (a class of machine learning algorithms) has the potential to automatically identify DAWM and estimate its volume. We will use the large CombiRx MRI data for training, validation, and testing of the deep learning models, and to study DAWM evolution in this MS cohort. The proposal has two major aims. In the first aim we will develop a deep learning model based on fully-convolutional neural networks for automatic segmentation of DAWM, gray matter, normal appearing white matter, and T2-hyperintense lesions guided by manual segmentation of two neuroimaging experts. In the second aim we will segment DAWM and all brain tissues, including focal lesions, at baseline and all available follow-up scans in the CombiRx cohort (up to 6.5 years). The temporal changes in volume, location, and MRI parameters of DAWM and focal T2 lesions will be computed. We will finally test whether DAWM is precursor to focal T2 lesions, associated with T2 lesion resolution, or a separate disease process altogether. If DAWM is shown to occur early on in the disease, it is possible to intervene sooner for improved outcome. Similarly, if DAWM is shown to be related to disease activity, it can serve as an objective and quantitative measure of the disease. Such an objective measurement would be highly valuable in developing targeted therapies and also in evaluating the treatment effect in MS patients. The main objective of this proposal is to study the evolution of diffusely appearing white matter (DAWM) in multiple sclerosis (MS) using a novel deep learning approach. The results of this study are expected to be highly valuable in evaluating the treatment effect in individual MS patients. These results can also help reduce time and money in conducting clinical trials substantially, which would lead to early introduction of promising drugs into the market. Finally, if DAWM occurs early on in the disease, as suggested by some of the publications, it is possible to therapeutically intervene sooner for improved outcome.",Detection and evolution of diffusely abnormal white matter in multiple sclerosis: a deep learning approach,10217627,R21NS118320,"['Affect', 'Artificial Intelligence', 'Attenuated', 'Big Data', 'Blinded', 'Brain', 'Cerebrospinal Fluid', 'Characteristics', 'Clinical', 'Clinical Management', 'Complex', 'Conduct Clinical Trials', 'Data', 'Demyelinating Diseases', 'Demyelinations', 'Detection', 'Development', 'Diagnosis', 'Diffuse', 'Disease', 'Disease Progression', 'Engineering', 'Evolution', 'Frequencies', 'Functional disorder', 'Future', 'Gliosis', 'Goals', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Label', 'Lead', 'Learning', 'Lesion', 'Liquid substance', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Multi-Institutional Clinical Trial', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'Nature', 'Nerve Degeneration', 'Pathologic Processes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Prevalence', 'Process', 'Protons', 'Publications', 'Randomized Clinical Trials', 'Recovery', 'Relapsing-Remitting Multiple Sclerosis', 'Reporting', 'Resolution', 'Resources', 'Role', 'Scanning', 'T2 weighted imaging', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'axonopathy', 'base', 'brain tissue', 'burden of illness', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'density', 'follow-up', 'gray matter', 'imaging modality', 'improved outcome', 'large datasets', 'machine learning algorithm', 'model development', 'multiple sclerosis patient', 'nervous system disorder', 'neuroimaging', 'novel', 'success', 'targeted treatment', 'treatment effect', 'white matter', 'young adult']",NINDS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,234000
"Pooled analysis of multiple sclerosis findings on multi-site 7 Tesla MRI Project Summary/Abstract Background: Although current MRI performs well as a tool to measure white matter (WM) inflammation in MS, its ability to quantify gray matter (GM) pathology, meningeal inflammation, and chronic inflammatory changes are limited. For this reason, researchers have looked to 7-tesla (7T) MRI for more robust in vivo measures of pathology. Although the increased sensitivity of 7T MRI for these aspects of MS have stimulated much interest, the impact of previous studies have been limited due to small sample sizes, varying methodologies, cumbersome analysis methods, and conflicting results – all of which have limited the generalizability of findings and more widespread dissemination of the use of this tool. Objective: In this study, we aim to advance the use of 7T MRI as a tool for diagnosis, prognosis, and treatment effect monitoring by performing multi-site, large sample size evaluation of imaging correlates of cortical and deep GM lesions, chronic active WM lesions (WM lesions with paramagnetic rims on MRI), and meningeal inflammation (leptomeningeal inflammation (LME) on MRI) and validation of their clinical relevance. We also will look develop automated tools for identification and quantification of these findings on 7T MRI. Study Design: Imaging and clinical data will be derived from previous and ongoing studies of the use of 7T MRI in MS performed at multiple collaborative sites under the umbrella of the North American Imaging in MS (NAIMS) Collaborative, including the University of Maryland, Baltimore, Harvard-Brigham and Women’s Hospital, the National Institutes of Neurological Disorders and Stroke, the University of Pennsylvania, and the Montreal Neurological Institute at McGill University. This includes data on up to 814 individual persons with MS, 1232 individual study visits, and a follow up period of up to 5 years. GM lesions, WM lesions with paramagnetic rims, and LME will be identified on 7T, with critical evaluation of methods and their relationship to clinical data. Further, the manual analysis results will be used as training sets for deep learning algorithms for identification of these abnormalities on future 7T MRI scans. Impact: This study would provide the data on measurement variability and generalizable clinical importance of the imaging findings being investigated, along with providing automated tools for future, high-throughput studies. In advancing these precise measures of aspects of MS pathology only poorly measured on lower field MRI, this study will lead to more accurate MS diagnoses, improvements in the ability to monitor changes in MS pathology over time, and perhaps lead to the screening of new pharmaceutical interventions to target GM lesions, WM lesions with paramagnetic rims, and LME. Project Narrative In this study, multiple institutions performing research using 7-tesla (7T) MRI research on patients with multiple sclerosis (MS) will combine data for a large scale, pooled analysis project. The investigators will refine methods for visualizing cortical and deep gray matter lesions, chronically inflamed white matter lesions, and meningeal inflammation on 7T MRI in MS and will evaluate their clinical relevance on a large scale and develop machine learning algorithms for future identification. It is expected that validating findings on 7T and their clinical relevance along with providing automated tools for analysis will lead to the use of 7T MRI as a more widespread clinical tool, resulting in earlier diagnoses, better prognostication, and more effective treatment monitoring in MS.",Pooled analysis of multiple sclerosis findings on multi-site 7 Tesla MRI,10278178,R01NS122980,"['Algorithmic Analysis', 'American', 'Autopsy', 'Baltimore', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Conflict (Psychology)', 'Consumption', 'Data', 'Data Pooling', 'Demyelinations', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Functional disorder', 'Future', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Impaired cognition', 'Individual', 'Inflammation', 'Inflammatory', 'Institutes', 'Institution', 'Intervention', 'Lead', 'Lesion', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Maryland', 'Masks', 'Measurement', 'Measures', 'Meningeal', 'Meninges', 'Methodology', 'Methods', 'Monitor', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurologic', 'Outcome', 'Pathology', 'Patient Care', 'Pennsylvania', 'Persons', 'Pharmacologic Substance', 'Phase', 'Predisposition', 'Prognosis', 'Protocols documentation', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Scanning', 'Site', 'Standardization', 'Structure', 'Thalamic structure', 'Time', 'Training', 'Universities', 'Validation', 'Visit', 'Visualization', 'Woman', 'accurate diagnosis', 'clinical care', 'clinically relevant', 'cognitive disability', 'comparative', 'deep learning algorithm', 'disability', 'effective therapy', 'follow-up', 'gray matter', 'high throughput analysis', 'imaging study', 'in vivo', 'insight', 'interest', 'large datasets', 'machine learning algorithm', 'magnetic field', 'multiple sclerosis patient', 'physically handicapped', 'prognostic', 'prognostic tool', 'screening', 'tool', 'treatment effect', 'white matter']",NINDS,UNIVERSITY OF MARYLAND BALTIMORE,R01,2021,535821
"Next Generation Brain PET Imaging Abstract Gold-standard quantitative imaging studies are often difficult to implement, limited by financial and logistical issues, or expose the patient to unnecessary risks. Deep learning has shown great promise in recent years for many medical applications; one use is to synthesize improved images. Such image trans- formation methods offer the potential to improve the quality, value, and accessibility of medical imaging. The goal of this project is to develop deep convolutional neural network approaches to FDG PET imaging, the most commonly performed clinical brain- focused PET study in the USA. Using simultaneous PET/MRI, we will train networks to produce diagnostic PET images from ultra-low dose PET and MR images. We will explore the three reimbursed clinical indications for this imaging modality (tumor recurrence, dementia, and epilepsy) using both quantitative metrics and repeated reader studies to assess equivalence and evaluate possible AI generalization bias related to simultaneity, scanner type, age, gender, and disease prevalence. Next, we will evaluate whether we can move beyond ultra-low dose and remove the radiation dose altogether, synthesizing FDG brain PET images from MR inputs only, relying on the information in multi-modal functional MRI. Finally, we will assess whether we can use deep networks to combine imaging and non- imaging data such as clinical and genetic information to further improve image transformation and predict future images and image-based biomarkers. Significantly reducing or even eliminating the need for radiation to produce brain FDG PET images would be truly transformative while the ability to predict the future will enable personalized radiology and enhance our ability to perform clinical trials. Project Narrative Artificial intelligence methods, particularly deep learning, can be used to improve image quality or synthesize new images from existing data and to predict future imaging. We will apply this to determine its performance for brain metabolic imaging using simultaneous FDG brain PET/MRI in realistic clinical populations, significantly reducing or eliminating the radiotracer dose as well as incorporating non-imaging, clinical data to improve AI-based image synthesis. This will revolutionize brain PET imaging, enable us to examine future disease trajectories in a personalized manner, and lay the groundwork to understand its use for other modalities and in other disease settings.",Next Generation Brain PET Imaging,10279862,R01NS123025,"['Age', 'Air', 'Architecture', 'Artificial Intelligence', 'Brain', 'Brain imaging', 'Cerebrovascular Circulation', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cyclotrons', 'Data', 'Data Set', 'Dementia', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Disease', 'Disease Progression', 'Dose', 'Epilepsy', 'FDA approved', 'Functional Magnetic Resonance Imaging', 'Future', 'Gender', 'Genetic', 'Genetic Markers', 'Glioblastoma', 'Goals', 'Gold', 'Human', 'Image', 'Link', 'Logistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Medical', 'Medical Genetics', 'Medical Imaging', 'Metabolic', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Patients', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Prevalence', 'Protocols documentation', 'Provider', 'Radiation', 'Radiation Dose Unit', 'Radiology Specialty', 'Reader', 'Recording of previous events', 'Recurrence', 'Risk', 'Risk Factors', 'Running', 'Rural Community', 'Site', 'Specific qualifier value', 'Spin Labels', 'Structure', 'Technology', 'Tracer', 'Training', 'Travel', 'Water', 'acute stroke', 'base', 'chronic stroke', 'convolutional neural network', 'cost', 'deep learning', 'disease natural history', 'fluorodeoxyglucose', 'fluorodeoxyglucose positron emission tomography', 'genetic information', 'imaging biomarker', 'imaging modality', 'imaging study', 'improved', 'metabolic imaging', 'multimodal data', 'multimodality', 'neural network', 'next generation', 'patient population', 'patient safety', 'prospective', 'quantitative imaging', 'radiologist', 'radiotracer', 'sex', 'stroke patient', 'targeted imaging', 'tumor', 'underserved community']",NINDS,STANFORD UNIVERSITY,R01,2021,564570
"Paneth cell phenotype as a predictive biomarker for ulcerative colitis ABSTRACT One of the challenges for the management of ulcerative colitis (UC; a subtype of inflammatory bowel disease) is the lacking of a predictive biomarker that can help stratify patients for personalized treatment strategies. We have previously shown that in Crohn’s disease (CD; another subtype of inflammatory bowel disease), the morphologic phenotype of small intestinal Paneth cells readily predicts outcome in post-surgical CD patients. Given the shared genetic etiology and clinical features between CD and UC, we hypothesize that Paneth cell phenotype will also predict outcome in UC. Our long-term goal is to define the clinical indications of inflammatory bowel disease of which Paneth cell phenotype can predict outcome. The objective of this grant is to determine to the extent of which Paneth cell phenotype predicts development of ileal complications in UC. The central hypothesis is that in UC patients undergoing total colectomy and ileal pouch anal anastomosis (IPAA), the Paneth cell phenotype obtained at time of colectomy will predict development of pouchitis and de novo CD in the ileal pouch. Our rationale is that Paneth cell phenotype will offer better outcome prediction over current practice. Our specific aims will test the following hypotheses: (Aim1) Paneth cell phenotype correlates with ileal complications in UC patients with IPAA; (Aim 2) Deep learning will reduce observer variation and enhance rigor and reproducibility of Paneth cell phenotype analysis in surgical pathology specimens, and also identify novel clinical factors that correlate with Paneth cell function; (Aim 3) Serum markers that correlate with Paneth cell phenotype could be used to predict outcome in UC. Upon conclusion, we will understand the role for Paneth cell function in modulating disease course in IBD. This contribution is significant since it will establish Paneth cell phenotype as a critical predictive biomarker for IBD. The proposed research is innovative because we use state-of-the-art deep learning approach to build an imaging analysis pipeline, and to identify novel clinical factors that affect Paneth cell functions. Identifying how epithelial cells with innate immune function affect disease course will provide insight into other inflammatory disorders. PROJECT NARRATIVE The proposed research is relevant to the public health because ulcerative colitis, which is increasing in prevalence worldwide, represents a major national cost measured by both patient suffering and economic burden. Despite significant advances in care, clinical trial data demonstrate remission rates is at best of 40%. Strategies that stratify patients based on Paneth cell function represent a novel approach for outcome prediction. Upon conclusion, we will establish that Paneth cell phenotype is a predictive cellular biomarker for ileal complications in ulcerative colitis patients undergoing total colectomy and ileal pouch anal anastomosis. We will also define the underlying genetic associations and molecular pathways of abnormal Paneth cell phenotype in these patients. In addition, we will develop deep learning algorithms that will streamline the interpretation of Paneth cell phenotype for pathology specimens, and define serum markers that correlate with Paneth cell phenotype to allow for less invasive and more frequent monitoring.",Paneth cell phenotype as a predictive biomarker for ulcerative colitis,10269023,R01DK124274,"['Affect', 'Anastomosis - action', 'Anus', 'Biological', 'Biological Markers', 'Caring', 'Cell physiology', 'Cellular Morphology', 'Chronic', 'Classification', 'Clinical', 'Clinical Trials', 'Colectomy', 'Complex', 'Cost Measures', 'Crohn&apos', 's disease', 'Data', 'Development', 'Disease', 'Disease Management', 'Disease remission', 'Economic Burden', 'Epithelial Cells', 'Excision', 'Genetic Markers', 'Genetic Predisposition to Disease', 'Goals', 'Grant', 'Ileal Reservoirs', 'Image', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Interobserver Variability', 'Longterm Follow-up', 'Manuals', 'Medical Genetics', 'Medical center', 'Methods', 'Molecular', 'Molecular Target', 'Monitor', 'Morphology', 'Mucous Membrane', 'Natural History', 'Natural Immunity', 'Observer Variation', 'Operative Surgical Procedures', 'Paneth Cells', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Positioning Attribute', 'Postoperative Period', 'Pouchitis', 'Prevalence', 'Process', 'Prognosis', 'Prognostic Marker', 'Public Health', 'Reproducibility', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Serum', 'Serum Markers', 'Small Intestines', 'Specimen', 'Standardization', 'Subgroup', 'Surgical Pathology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Ulcerative Colitis', 'Universities', 'Washington', 'Work', 'aggressive therapy', 'analysis pipeline', 'base', 'cell type', 'clinical practice', 'clinically relevant', 'cohort', 'combinatorial', 'deep learning', 'deep learning algorithm', 'dysbiosis', 'experience', 'experimental study', 'gastrointestinal', 'gene environment interaction', 'genetic association', 'gut homeostasis', 'improved', 'innate immune function', 'innovation', 'insight', 'intestinal epithelium', 'novel', 'novel strategies', 'outcome prediction', 'patient stratification', 'personalized medicine', 'phenotypic biomarker', 'predictive marker', 'prognostic', 'treatment strategy']",NIDDK,WASHINGTON UNIVERSITY,R01,2021,362276
"Predictive Markers and Mechanisms of Persistent Psychotic-like Experiences in Children: An Adolescent Brain and Cognitive Development Study Analysis PROJECT TITLE Predictive Markers and Mechanisms of Persistent Psychotic-like Experiences in Children: An Adolescent Brain and Cognitive Development Study Analysis PROJECT SUMMARY/ABSTRACT My long-term career goal is to establish a highly influential and independent research program and become a broad spectrum leader and innovator in computational psychiatry. I therefore propose the following training goals: 1) To gain formalized training in computational psychiatry methods and statistics, including deep learning and structural equation modeling, 2) to obtain a deeper understanding of the field of developmental psychopathology, and 3) to acquire training in developing and sustaining an independent investigator position with his own laboratory. To meet the first goal, I will meet regularly with University of California Davis (UCD) faculty co-mentors Ian Davidson and Emilio Ferrer, attend relevant UCD classes, and complete a Research Plan with the following Specific Aims: 1) Using deep learning from Adolescent Brain and Cognitive Development (ABCD) Study data (demographic/clinical information, neurocognitive testing, neuroimaging data, and environmental metrics), predict child psychotic-like experience (PLE) distress scores the following year (i.e., baseline data predicting year one PQ-BC distress, year one data predicting year two distress, etc.), and 2) Using rules-based guidance from deep learning using explainable AI (XAI) algorithms, use sequential, structural equation modeling (SEM) of latent profiles (i.e., longitudinal trajectories, e.g., emerging, absent, remitting, persistent) to test hypotheses regarding the longitudinal mechanism(s) which may lead to persistent PLEs in the ABCD cohort. In Aim 1, XAI methods will be used identify the rules used by the deep learner to make decisions; in Aim 2, these rules will then be used to create latent constructs for modeling profiles of longitudinal trajectories. If r2>0.80 is consistently achieved for each iterative analysis in Aim 1, it suggests that ABCD instruments may predict PLE severity one year after measurement at a potentially clinically implementable level and help generate future hypotheses for personalized interventions aimed at reducing risk for persistent PLE distress. For Aim 2, insight will be gained with regard to how brain structure, brain function, neurocognitive ability, and environmental influences interact to influence the time course of PLE expression. To meet the second goal, I will receive mentoring including guided readings via monthly meetings with co-mentor Dr. Ellen Leibenluft, a world-renowned psychiatrist specializing in developmental research and Section Chief at the NIMH. I will also attend developmental classes, seminars, and workshops offered by UCD. To meet the third goal, I will attend weekly meetings with mentor Dr. Cameron Carter, from whom I will gain overarching career guidance. This will include learning how to create and oversee a laboratory, obtaining recommendations for society memberships, acquiring networking opportunities, securing grant sponsorships, and receiving RCR-related guidance. I will also attend mentoring and grantsmanship workshops offered by UCD, attend an off-campus workshop providing hands-on activities to provide exposure to fundamental management skills, complete a formalized UCD RCR plan, and gain mentoring experience by advising a research assistant and postdoc. PROJECT NARRATIVE Child psychotic-like experiences (PLEs) are common disturbances of perception and ideation that occur in childhood and that (if they become persistent) may be risk factors for poor mental health in adolescence and beyond. As risk factors that predict persistent PLEs have not been reliably identified, the goal of this study is to use deep learning combined with explainable artificial intelligence to identify features from multimodal data in the Adolescent Brain and Cognitive Development Study dataset that predict future levels of PLE distress, and then use these features to model PLE trajectories using structured equation modeling. The results of this study will help develop novel, personalized ways to prevent persistent PLEs from developing and ultimately improve mental health.",Predictive Markers and Mechanisms of Persistent Psychotic-like Experiences in Children: An Adolescent Brain and Cognitive Development Study Analysis,10298283,K01MH125096,"['Adolescence', 'Adolescent', 'Affect', 'Age', 'Algorithms', 'Artificial Intelligence', 'Behavior', 'Brain', 'California', 'Child', 'Childhood', 'Classification', 'Clinical', 'Cognition', 'Computing Methodologies', 'DSM-III', 'Data', 'Data Set', 'Decision Making', 'Development', 'Device or Instrument Development', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Distress', 'Early Intervention', 'Educational workshop', 'Environment', 'Equation', 'Event', 'Exposure to', 'Faculty', 'Family', 'Family history of', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Grant', 'Influentials', 'Interview', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Manic', 'Measurement', 'Measures', 'Mental Health', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'National Institute of Mental Health', 'Neurocognitive', 'Nutritional', 'Output', 'Patient Self-Report', 'Perceptual disturbance', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Predictive Factor', 'Prevention strategy', 'Psychiatrist', 'Psychiatry', 'Psychopathology', 'Psychoses', 'Questionnaires', 'Reading', 'Recommendation', 'Recording of previous events', 'Research', 'Research Assistant', 'Research Personnel', 'Research Project Grants', 'Rest', 'Risk', 'Risk Factors', 'Schedule', 'Secure', 'Severities', 'Societies', 'Structure', 'Substance abuse problem', 'Suicide attempt', 'Sum', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vocational Guidance', 'adverse outcome', 'base', 'career', 'career development', 'cognitive development', 'cohort', 'deep learning', 'deep learning algorithm', 'demographics', 'environmental stressor', 'experience', 'follow-up', 'gray matter', 'ideation', 'improved', 'individualized medicine', 'individualized prevention', 'innovation', 'insight', 'meetings', 'multimodal data', 'multimodality', 'neurocognitive test', 'neuroimaging', 'novel', 'novel diagnostics', 'personalized intervention', 'personalized medicine', 'predictive marker', 'prevent', 'programs', 'skills', 'socioeconomics', 'statistics', 'tool', 'trustworthiness', 'tv watching', 'white matter']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,K01,2021,173020
"Deep Learning Approaches to Risk Stratification in Acute Gastrointestinal Bleeding PROJECT SUMMARY  Acute gastrointestinal bleeding accounts for over 2.2 million hospital days and 19.2 billion dollars of medical charges annually. 52% to 55% of patients with acute gastrointestinal bleeding are unnecessarily hospitalized, leading to wasted resources. Although risk stratification of patients presenting with gastrointestinal bleeding is recommended, risk-assessment scoring systems are not commonly used in practice, have sub- optimal performance, may be applied incorrectly, and are not easily updated.  Most current risk scores were designed for use based on the location of the bleeding source: upper or lower gastrointestinal tract. However, the location of the bleeding source is not always clear at presentation. A risk score that bases initial assessment on presenting symptoms (e.g., hematemesis, melena, hematochezia) is more relevant and useful in clinical practice. The electronic health record can be used to identify patients with acute gastrointestinal bleeding symptoms and extract clinical data to automatically calculate risk scores that are made available to providers. Machine learning (field of study that gives computers the ability to learn without being explicitly programmed), particularly deep learning using neural networks (collection of nodes that process and transmit information), can create electronic health record-based models that perform better than clinical risk scores for gastrointestinal bleeding and are well-suited for learning from new data.  This proposal will use deep learning tools on electronic health record data to decrease unnecessary hospitalization in patients with acute gastrointestinal bleeding by identifying low risk patients. The goals are to 1) Develop and validate an accurate and clinically useful deep learning algorithm for initial risk stratification superior to existing clinical risk scores 2) Develop and validate a dynamic deep learning tool to model risk over time, and 3) Pilot the best performing algorithms in the electronic health record. Deep learning algorithms will be developed using a dataset of electronic health record data of 7,000 patients with acute gastrointestinal bleeding from two academic hospitals in the Yale-New Haven Health System. Validation will be performed on a separate dataset of patients at Partners Healthcare in Boston, Massachusetts. Neural network approaches will be applied to patients’ data updated over time to evaluate the trajectory towards requiring transfusion of red blood cells. Finally, a pilot study will implement the best-performing algorithms in the electronic health record for a 3-month period to test feasibility of deployment and acceptability to providers and patients. Planned coursework includes deep learning with biomedical data, risk assessment and longitudinal analysis.  This work has potential to generate cost savings through better integrated risk stratification of patients presenting with overt gastrointestinal bleeding. To meet the research and educational goals of this proposal, the mentorship team includes a primary mentor in gastrointestinal bleeding and co-mentors in deep learning, electronic health record-based clinical trial design of prognostic algorithms, and implementation science. PROJECT NARRATIVE The NIH Artificial Intelligence Working Group recently challenged the medical community to train researchers in both healthcare and computer science, proposing that dual training is fundamental to advance artificial intelligence into healthcare and assure these models are safe, interpretable, and effectively integrated into real- world systems. Acute gastrointestinal bleeding is the most common cause of hospitalization for gastrointestinal diseases and many patients are unnecessarily hospitalized. A symptom-based risk assessment tool is more clinically useful than existing scores; this can be developed with deep learning approaches and deployed on the electronic health record to decrease unnecessary and costly hospitalizations.",Deep Learning Approaches to Risk Stratification in Acute Gastrointestinal Bleeding,10215914,K23DK125718,"['Accident and Emergency department', 'Acute', 'Acute Renal Failure with Renal Papillary Necrosis', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Blood', 'Boston', 'Caring', 'Charge', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Trials Design', 'Collection', 'Communities', 'Computers', 'Cost Savings', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Electronic Health Record', 'Erythrocyte Transfusion', 'Feces', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Goals', 'Health system', 'Healthcare', 'Hematochezia', 'Hemorrhage', 'Hemostatic Agents', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Intervention', 'Learning', 'Length of Stay', 'Location', 'Lower Gastrointestinal Tract', 'Machine Learning', 'Massachusetts', 'Medical', 'Medical center', 'Melena', 'Mentors', 'Mentorship', 'Modeling', 'Outcome', 'Outpatients', 'Patient Triage', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pilot Projects', 'Process', 'Provider', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Assessment', 'Sepsis', 'Site', 'Source', 'Standardization', 'Symptoms', 'System', 'Time', 'Training', 'Transfusion', 'United States National Institutes of Health', 'Update', 'Validation', 'Work', 'acute symptom', 'base', 'clinical decision support', 'clinical practice', 'clinical risk', 'computer science', 'data modeling', 'deep learning', 'deep learning algorithm', 'design', 'feasibility testing', 'field study', 'gastrointestinal', 'gastrointestinal symptom', 'implementation science', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'neural network', 'outcome prediction', 'patient health information', 'patient stratification', 'point of care', 'predictive modeling', 'prognostic', 'prospective', 'risk stratification', 'time use', 'tool', 'tool development', 'working group']",NIDDK,YALE UNIVERSITY,K23,2021,193538
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,10145719,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2021,378183
"Dialysis access monitoring using a digital stethoscope-based deep learning system This SBIR Phase I project will develop a deep learning-based algorithm to analyze the sound of blood flow in newly created arteriovenous fistulas (AVFs) used for hemodialysis access. This monitoring tool can help to identify fistulas that are unlikely to mature in patients who need surgical intervention to achieve successful maturation. The specific aims of the study are (1) to create the world’s first deep learning-scale database of newly created AVF sounds from hemodialysis patients, and (2) develop and evaluate the performance of a deep learning classification model trained via semi-supervised learning to discriminate between patients with AVFs likely to mature and patients with AVFs unlikely to mature. By integrating this deep learning algorithm into Eko’s mobile and cloud software platform, we anticipate this algorithm will enable better monitoring of the maturation process for newly created fistulas. During Phase I of the project, we will recruit study subjects in access centers at the University of North Carolina (UNC). SBIR Project Narrative In creating the world’s largest annotated dataset of mature AV fistula sounds and corresponding ultrasounds, Eko will gain unprecedented insights into fistula blood flow. We expect this to advance our scientific understanding of the fluid dynamics of fistulas, and help explain how and why hemodialysis access fails at such a high rate over time. A clinical decision support algorithm trained from this dataset can help healthcare systems detect fistula failures earlier, leading to more timely interventions that can avert costly complications, prolong life expectancy, and improve quality of life for hemodialysis patients as their care transitions from clinic to home care.",Dialysis access monitoring using a digital stethoscope-based deep learning system,10255460,R43DK129107,"['Academic Medical Centers', 'Algorithms', 'Arteriovenous fistula', 'Artificial Intelligence', 'Auscultation', 'Blood Vessels', 'Blood flow', 'Bluetooth', 'Caring', 'Cellular Phone', 'Classification', 'Clinic', 'Collection', 'Data', 'Data Set', 'Databases', 'Detection', 'Dialysis procedure', 'Distal', 'Early Intervention', 'Educational process of instructing', 'Eko', 'End stage renal failure', 'Enrollment', 'Ensure', 'Failure', 'Fistula', 'Goals', 'Health', 'Healthcare Systems', 'Heart Sounds', 'Hemodialysis', 'Home', 'Internet', 'Intervention', 'Interventional radiology', 'Lead', 'Legal patent', 'Life Expectancy', 'Liquid substance', 'Location', 'Maintenance', 'Measurement', 'Medicare', 'Meta-Analysis', 'Modeling', 'Monitor', 'Nephrology', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physical Examination', 'Positioning Attribute', 'Procedures', 'Quality of life', 'Renal Replacement Therapy', 'Research Design', 'Small Business Innovation Research Grant', 'Standardization', 'Stenosis', 'Stethoscopes', 'Study Subject', 'Survival Rate', 'System', 'Tablet Computer', 'Time', 'Training', 'Transplantation', 'Ultrasonography', 'Validation', 'algorithm training', 'analog', 'arteriovenous graft', 'base', 'clinical database', 'clinical decision support', 'clinically relevant', 'cloud based', 'cloud software', 'commercialization', 'convolutional neural network', 'cost', 'data streams', 'deep learning', 'deep learning algorithm', 'deep neural network', 'digital', 'evaluation/testing', 'experience', 'follow-up', 'improved', 'innovation', 'insight', 'patient home care', 'premature', 'recruit', 'skills', 'sound', 'standard of care', 'supervised learning', 'systematic review', 'tool']",NIDDK,"EKO DEVICES, INC.",R43,2021,299358
"Deep Learning of Pancreas MRI to Predict Progression of T1D. Project Summary The TrialNet Pathway to Prevention study has provided crucial early screening for relatives of individuals with type 1 diabetes (T1D). The presence of autoantibodies conveys high risk for progression from Stage 1 T1D, defined by the presence of multiple diabetogenic autoantibodies, to Stage 3 T1D, or symptomatic disease. However, the time to progression can be variable. A variety of genetic and metabolic indices have attempted to predict progression of T1D, with varying degree of success. Additional biomarkers are needed to improve prediction of progression, and these biomarkers must be correlated with immunological markers or metrics that assess beta cell function. The overall goal of the proposed study is to establish an imaging biomarker to predict progression. We propose to improve T1D prediction by 1) co-registering longitudinal MRI taken during progression of T1D to identify spatial evolution characteristic of disease evolution, 2) harnessing deep learning techniques to identify image features characteristic of the pancreas in T1D, and 3) integrated imaging and functional metrics to build a predictive model of T1D progression. This work builds upon work we have performed indicating that pancreas size, shape, and structure are altered in new onset type 1 diabetes. These imaging metrics are also altered in individuals at risk for developing T1D. This study will identify imaging features characteristic of the pancreas that accompany progression to T1D. The techniques developed may prove useful for monitoring patients at risk for T1D and predicting progression to symptomatic disease, which is associated with lower incidence of diabetic ketoacidosis at diagnosis, better glycemic control, and corresponding improvements in long-term complications. The ability to predict progression would further facilitate the design of new therapeutic trials which are shorter and less expensive by stratifying patient populations and providing intermediate end points. Project Narrative This proposal seeks to build a model that predicts progression of type 1 diabetes (T1D) incorporating quantitative pancreas MRI. The model will integrate longitudinally-acquired imaging metrics assessing pancreas size, shape, and structure with functional assays of beta cell function. Deep learning techniques will be developed to classify pancreas features characteristic of T1D progression.",Deep Learning of Pancreas MRI to Predict Progression of T1D.,10296257,R03DK129979,"['Artificial Intelligence', 'Autoantibodies', 'Beta Cell', 'Biological Assay', 'Biological Markers', 'Biomedical Engineering', 'Cell physiology', 'Characteristics', 'Complex', 'Data', 'Diabetes Mellitus', 'Diabetic Ketoacidosis', 'Diagnosis', 'Disease', 'Evolution', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Goals', 'Human', 'Image', 'Immunologic Markers', 'Incidence', 'Individual', 'Institutes', 'Insulin-Dependent Diabetes Mellitus', 'Lead', 'Lesion', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Modeling', 'Morphology', 'Pancreas', 'Participant', 'Pathologic Processes', 'Pathology', 'Pathway interactions', 'Patient Monitoring', 'Pattern', 'Positioning Attribute', 'Prevention', 'Protocols documentation', 'Radiology Specialty', 'Reader', 'Resources', 'Risk', 'Science', 'Shapes', 'Structure', 'Techniques', 'Texture', 'Therapeutic Trials', 'Time', 'Work', 'austin', 'deep learning', 'design', 'diabetes control', 'diabetogenic', 'early screening', 'glycemic control', 'high risk', 'imaging biomarker', 'improved', 'indexing', 'insight', 'insulin dependent diabetes mellitus onset', 'inter-individual variation', 'islet cell antibody', 'non-diabetic', 'novel therapeutics', 'patient population', 'patient stratification', 'predictive modeling', 'progression marker', 'success']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R03,2021,158500
"BOND: Benchmarking based on heterogeneous biOmedical Network and Deep learning novel drug-target associations Project Summary/Abstract The applicant’s goals are to develop the necessary skills to become an independent translational biomedical informatics researcher in the area of computational drug repurposing. Exploring novel drug-target interactions (DTI) plays a crucial role in drug development. In order to lower the overall costs and uncover more potential screening targets, computational (in silico) methods have become popular and are commonly applied to poly-pharmacology and drug repurposing. Although machine learning-based strategies have been studied for years, there is no standardized benchmark that provides large-scale training datasets as well as diverse evaluation tasks to test different methods. Furthermore, the existing methods suffer from remarkable limitations, where 1) results are often biased due to a lack of negative samples, 2) novel drug-target associations with new (or isolated) drugs/targets cannot be explored, and 3) the comprehensive topological structure cannot be captured by feature learning methods . Therefore, in the era of big data, the applicant proposes a study to tackle the challenges by achieving two aims. • Aim 1 (K99 Phase): Develop a large scale benchmark for evaluating drug-target prediction based on the  generation of a multipartite network from heterogeneous biomedical datasets. • Aim 2 (R00 Phase): Adapt a deep learning model to build an accurate predictive model based on a novel  feature learning algorithm that mines the multi-dimensional biomedical network (multipartite network). In the mentored phase, the applicant will integrate heterogeneous biomedical datasets and build a benchmark for evaluation of the drug-target prediction based on well-designed strategies. The applicant will receive training in standardization tools for data integration, tools, and skills for data management, evaluation methods for drug-target predictions, and state-of-the-art machine learning/deep learning methods in computer-aided pharmacology. Complementary didactic, intellectual, and professional training will help prepare the applicant for the R00 phase where he will develop a deep learning-based predictive model and multi-dimensional graph embedding methods for feature learning. Together, these novel studies will advance the current computational drug repurposing by providing 1) comprehensive benchmarking for testing and evaluation, and 2) a scalable and accurate predictive model based on a biomedical multi-partite network. The applicant will be mentored by senior, established investigators with substantial expertise in Semantic Web, computational biology, cancer genomics, drug development, and machine learning/deep learning. Importantly, this project will provide a foundation for the applicant to establish independent research programs in 1) computational drug repurposing in real cases, 2) investigation of the diverse hidden associations in system biology (e.g., associations between drugs, genetics, and diseases), and 3) precision medicine aimed applications leveraging biomedical knowledgebases and electronic health records. Project Narrative The field of computational drug repurposing lacks a large scale benchmark that provides comprehensive and standard evaluation tasks as well as a scalable and accurate prediction model that can handle large biomedical datasets. This study aims to utilize Semantic Web technology to construct a multi-partite network based on heterogeneous biomedical databases and develop a deep learning-based predictive model based on the network. The proposed investigation will advance this field by providing a large scale benchmark for evaluation as well as a predictive model based on state-of-the-art technology.",BOND: Benchmarking based on heterogeneous biOmedical Network and Deep learning novel drug-target associations,10227201,K99GM135488,"['Address', 'Algorithms', 'Area', 'Base Ratios', 'Benchmarking', 'Big Data', 'Clinic', 'Computational Biology', 'Computer Assisted', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Dimensions', 'Disease', 'Drug Evaluation', 'Drug Targeting', 'Electronic Health Record', 'Employment', 'Evaluation', 'Foundations', 'Generations', 'Genetic', 'Goals', 'Graph', 'Investigation', 'Learning', 'Learning Module', 'Link', 'Machine Learning', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Play', 'Positioning Attribute', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Silver', 'Source', 'Standardization', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Training', 'Ursidae Family', 'Validation', 'base', 'biomedical informatics', 'cancer genomics', 'computer based Semantic Analysis', 'cost', 'data integration', 'data management', 'data tools', 'deep learning', 'deep neural network', 'design', 'drug development', 'drug repurposing', 'flexibility', 'heterogenous data', 'improved', 'in silico', 'knowledge base', 'large scale data', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'new therapeutic target', 'novel', 'precision medicine', 'predictive modeling', 'predictive test', 'programs', 'repository', 'screening', 'skills', 'tool']",NIGMS,MAYO CLINIC ROCHESTER,K99,2021,8333
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"Functional annotation of new genes aided by deep learning New genes (NGs) are generated by multiple mechanisms and their end-piece sequences are identified as the chimeric transcript sequence from multiple human sources including healthy and disease tissues. Therefore, NGs have been recognized as important biomarkers and therapeutic targets for precision medicine. Many efforts have been made to study individual NG function and to identify relevant drug targets. However, the current in-depth research and achievements are mainly concentrated on several driver NGs, and classical cancer drugs have been directly used to target the NG domains, such as the kinase domain of BCR-ABL1 fusion protein in leukemia. Some of the fusion proteins with retaining DNA-binding domains such as transcription factors can directly bind their target genes, such as the EWSR1-FLI fusion actively recruiting BAF complex. Recently, the downstream effectors of driver FGs have emerged as therapeutic targets. For example, targeting the downstream CCND2 inhibited RUNX1/ETO-driven leukemic expansion in vitro and in vivo and inhibition of STAT5, the downstream factor of NUP214-ABL1 led to the induction of leukemia cell death. However, the functions of most identified FGs have not been systematically investigated. This is mainly due to the limitations of traditional tools and the high cost of experimental procedures. Therefore, there is an urgent need to develop new tools for analyzing NG breakpoint-specific features systemically in the human genome and predict their originating and regulatory mechanisms, such as upstream and downstream effectors. In-depth annotation based on NG structure is important for understanding the cellular mechanisms of NGs. Effective use of systematic bioinformatics tools for functional annotation can provide a deeper insight into the role of NGs in the development and progression of diseases such as cancers to find direct and indirect therapeutic targets. In this study, we will develop five bioinformatics tools for the functional annotation and feature analysis of NGs, a predictive pipeline for automatic analysis of downstream effects of NGs, and a predictive method for tracing the origin of NGs. This project will be a substantial contribution to public health by systematically function of new genes (NGs) in human disease. These systematic annotation results will be performed through ChimerAnno (a tool for functional annotation of human chimeric genes), FGviewer (a tool for visualizing multi- tiered functional features of fusion genes), NGeffector with DeepChIP (a tool for predicting NG downstream effectors with enhanced transcription factor binding site prediction with deep learning), DeepCLIP (a tool for providing evidence of origin of NGs for trans-splicing mechanism), FusionAI (a tool for feature extraction of human new genes' breakpoint (BP)), FusionGDB 2.0 (updated fusion gene annotation aided by deep learning), and NewGeneDB (a knowledgebase of new genes). This study will advance our knowledge in NG regulatory deep annotating the mechanisms in diseases and open up the possibility of novel treatments of cancer future by providing powerful tools and platforms for analyzing NGs. and other diseases in the",Functional annotation of new genes aided by deep learning,10386314,R35GM138184,"['ABL1 gene', 'Achievement', 'Antineoplastic Agents', 'Binding', 'Binding Sites', 'Biological Markers', 'CCND2 gene', 'Cell Death', 'Chimeric Proteins', 'Complex', 'DNA Binding Domain', 'Development', 'Disease', 'Disease Progression', 'Drug Targeting', 'EWSR1 gene', 'Future', 'Gene Structure', 'Genes', 'Human', 'Human Genome', 'In Vitro', 'Individual', 'Knowledge', 'Leukemic Cell', 'Malignant Neoplasms', 'Methods', 'NUP214 gene', 'Phosphotransferases', 'Procedures', 'Public Health', 'RUNX1 gene', 'Recruitment Activity', 'Regulator Genes', 'Research', 'Role', 'Source', 'Stat5 protein', 'Tissues', 'Trans-Splicing', 'Transcript', 'Update', 'base', 'bioinformatics tool', 'cancer therapy', 'chimeric gene', 'cost', 'deep learning', 'feature extraction', 'fusion gene', 'gene function', 'human disease', 'in vivo', 'insight', 'knowledge base', 'leukemia', 'novel', 'precision medicine', 'predictive tools', 'therapeutic target', 'tool', 'transcription factor']",NIGMS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R35,2021,100000
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10389487,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Prognosis', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,243920
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10256621,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Prognosis', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,447500
"Unsupervised optimization of protein therapeutics using closed-loop in vitro synthesis, nanosensing, and deep-learning Project Summary Overview of research: The Reuel Group at Iowa State University (founded Fall 2016) seeks to develop new materials, methods, and measurement devices for biomanufacturing, biotherapeutics, and biosensors. We have active work-streams in 1) optical nanosensors for protein binding, enzymatic activity, and cell membrane disruption, 2) scalable and reliable cell free protein synthesis (CFPS) methods for protein prototyping (extract and genetic template improvements), 3) microfluidics for droplet generation and measurement of CFPS products, interrogated by nanosensors, 4) algorithms for `big data' generated from nanosensors (machine learning and deep learning methods), 5) engineered endospores for time-delayed synthetic biology circuits, and 6) resonant radio frequency sensors for biomanufacturing, wound healing, and water quality. The overall vision of the research program is to simplify and improve the design and manufacturing of biological products (cells and proteins) for applications in therapies, advanced materials, and bio-electronics. Protein based therapies have demonstrated in clinic to be a potent tool in the treatment of many diseases. In recent years, the design, build, and test cycle to find therapies for new disease targets has improved dramatically using techniques such as surface display coupled to evolutionary selection. However, these mutagenic approaches have a few limitations, namely: 1) they require a suitable, naturally occurring sequence as a starting point, 2) they frequently optimize solely on a single desired feature, and 3) they operate as a `black box', meaning that generalizable design rules for in silico prediction of future products is not possible. It is the purpose of this MIRA for ESI research plan to design a closed-loop system that allows for unsupervised design and discovery of protein therapeutics that overcomes these limitations. Over the next five years we will build and integrate the system components which include enzymatic DNA synthesis coupled to cell free protein synthesis to rapidly prototype libraries of custom proteins in micro-droplet reactors. These proteins will then be characterized in the micro-droplets using optical nanosensors, to test for desired features such as stability, binding affinity, selectivity, hydrolytic activity, and/or membrane penetration. This will produce a large labeled data set (tying sequence to phenotypic properties) that can be used to train a deep learning neural network to self-determine sequence patterns for specific properties. Once the tuning coefficients of the network are found, the algorithm will then predict next best sequences which will be synthesized, tested, etc. such that the design loop progresses unsupervised until optimization criteria are met. This new approach will result in faster development of protein therapies that are optimized based on multiple criteria and not tied to existing, natural sequences. For patients this translates to more efficacious therapies with less side effects and a potential for reduced cost (due to shortened design timeline). At the end of the five-year project we will seek to translate this technology, via NIH SBIR funding, such that the new technology can make an impact on actual therapies. Project Narrative This project seeks to develop advanced tools to enable faster discovery and design of protein-based drugs for new disease targets. These tools would enable optimization of multiple parameters simultaneously, creating more potent therapies with less side effects. Thanks to speeding up the development cycle and reducing the time to market, these tools also have the potential to reduce end cost to patients.","Unsupervised optimization of protein therapeutics using closed-loop in vitro synthesis, nanosensing, and deep-learning",10252011,R35GM138265,"['Affinity', 'Algorithms', 'Big Data', 'Binding', 'Binding Proteins', 'Biological Products', 'Biological Response Modifier Therapy', 'Biomanufacturing', 'Biosensor', 'Cell membrane', 'Cells', 'Clinic', 'Coupled', 'Custom', 'DNA biosynthesis', 'Data Set', 'Development', 'Devices', 'Disease', 'Electronics', 'Engineering', 'Funding', 'Future', 'Generations', 'Genetic Template', 'In Vitro', 'Iowa', 'Label', 'Libraries', 'Machine Learning', 'Measurement', 'Membrane', 'Methods', 'Microfluidics', 'Optics', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Phenotype', 'Property', 'Protein Biosynthesis', 'Protein Engineering', 'Proteins', 'Research', 'Small Business Innovation Research Grant', 'Speed', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Uses', 'Time', 'TimeLine', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Vision', 'Work', 'base', 'cost', 'deep learning', 'deep neural network', 'design', 'efficacious treatment', 'falls', 'improved', 'in silico', 'learning strategy', 'nanosensors', 'new technology', 'novel strategies', 'programs', 'prototype', 'radio frequency', 'sensor', 'side effect', 'synthetic biology', 'therapeutic protein', 'tool', 'treatment optimization', 'water quality', 'wound healing']",NIGMS,IOWA STATE UNIVERSITY,R35,2021,363953
"New Methods and Tools for Computational Drug Discovery Project Summary  My goal is to develop effective and efﬁcient computational methods for drug discovery, apply these methods to ﬁnd new and efﬁcacious drugs to treat diseases, and deploy these methods in easy-to-use open source tools. My research group pioneered the development and integration of deep neural networks in user-friendly molecular docking software for structure-based drug design to predict poses and potency of small molecules binding to their molecular targets. We will build on our foundational work by using deep learning to simultaneously solving the scoring and sampling problems, which will overcome scalability limitations inherent in current approaches.  We propose to develop the ﬁrst deep generative models for structure-based drug design. Unlike tra- ditional screening, generative modeling is not limited to a predeﬁned chemical space. In generative mod- eling, a deep neural network learns an underlying distribution of molecular structures and properties represented as a latent space. New structures can be extracted from this learned latent space to have desirable properties. Ideally, a generative model will produce novel, near-optimal molecular structures almost instantaneously. We hypothesize that training generative models using existing 3D protein and ligand structures will allow us to create general models that can be productively applied to new, struc- turally enabled targets due to the richness and universality of protein-ligand interactions. We will further develop these methods to support the generation of optimized lead candidates, where the generative process is updated to include results from experimental assays as the drug discovery process progresses.  We will continually apply our methods to identify small molecule modulators of molecular interac- tions relevant to normal physiology and disease. For example, using our current tools, we identiﬁed the ﬁrst inhibitors of the proﬁlin-actin interaction, an anti-angiogenesis target with relevance to cancer and diabetic retinopathy, and we plan to further improve these compounds with the goal of identifying candi- dates for clinical testing. We will apply our methods to address other under-explored molecular targets, such as NFATc2, which is implicated in cancer and autoimmune diseases. These prospective applications of our methods will provide unbiased and realistic evaluations that further inform their development.  Finally, all of our code and trained deep neural network models will be deployed either as new tools for generative modeling or as enhancements to our widely used open source tools for computational drug discovery: (1) PHARMIT, an interactive web application for structure-based drug discovery; (2) GNINA, a C/C++ deep learning framework for molecular docking; and (3) the newly released LIBMOLGRID, a Python library for accelerated molecular gridding that integrates with popular deep learning toolkits. These tools and methods will make the drug discovery process more accessible and efﬁcient. Project Narrative  The research supported by this award will develop new computational methods and tools for drug discovery so that novel therapeutics can be discovered more quickly and with less expense. The de- veloped methods will be evaluated prospectively in drug discovery projects of high relevance to human health. The resources developed will be readily accessible through open-access web sites and open-source software.",New Methods and Tools for Computational Drug Discovery,10161412,R35GM140753,"['3-Dimensional', 'Actins', 'Address', 'Autoimmune Diseases', 'Award', 'Binding', 'Biological Assay', 'Chemicals', 'Code', 'Computer software', 'Computing Methodologies', 'Development', 'Diabetic Retinopathy', 'Disease', 'Docking', 'Drug Design', 'Evaluation', 'Foundations', 'Generations', 'Goals', 'Health', 'Human', 'Libraries', 'Ligands', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Neural Network Simulation', 'Pharmaceutical Preparations', 'Physiology', 'Process', 'Property', 'Proteins', 'Pythons', 'Research', 'Research Support', 'Resources', 'Sampling', 'Structural Models', 'Structure', 'Training', 'Update', 'Work', 'antiangiogenesis therapy', 'base', 'computerized tools', 'deep learning', 'deep neural network', 'drug discovery', 'improved', 'inhibitor/antagonist', 'lead candidate', 'lead optimization', 'novel', 'novel therapeutics', 'open source', 'open source tool', 'profilin', 'prospective', 'research clinical testing', 'screening', 'small molecule', 'tool', 'user-friendly', 'web app', 'web site']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R35,2021,367975
"Elucidating sequence, structural and dynamic basis of the functional regulation of membrane proteins Project Summary The overall aim of the research is Shukla group is to develop computational methods that facilitate investigation of rare conformational transitions in proteins and help guide the design of experiments to validate the in silico predictions. In par- ticular, we apply these computational methods to investigate functional regulation of membrane proteins such as membrane transporters and G-protein coupled receptors (GPCRs). Here, we propose development of transfer learning based methods to predict the effect of mutations on protein function and apply these methods to investigate monoamine transporters, sugar transporters and Class C GPCRs. Deep mutagenesis, whereby tens of thousands of mutational effects are determined by combining in vitro selections of sequence variants with Illumina sequencing, is an emerging technology for indirectly interrogating and observing protein conformations in living cells; the solving of an integrative structure of a neuronal class C G protein-coupled receptor in an active conformation by deep mutagenesis-guided modeling is one prominent example of this approach's success. Using deep mutagenesis and molecular dynamics simulations to inform each other, we plan to determine the mechanism of ion- coupled neurotransmitter import by monoamine transporters at atomic resolution. Fluorescent substrates have enabled us to use ﬂuorescence-based sorting of libraries of transporter mutants to ﬁnd mutations along the entire permeation pathway that increase or decrease substrate import. These comprehensive mutational landscapes will be used to interpret and support/reject hypotheses from simulations, including the role of ion-coupling in substrate transport regulation, proposed free energy barriers in the conformational-free energy landscape that limit import kinetics, and how sodium-neurotransmitter symport is coupled by a shared cytosolic exit pathway. Other notable features that arise from the deep mutational scans (e.g. putative regulatory sites) will be further explored, and a machine learning algorithm will be applied to transfer mutagenesis information to related transporters; the predicted mutational landscapes will then be validated by a small number of informative targeted mutants. We will further relate sequence to conformation and activity in metabotropic neurotransmitter receptors and sugar transporters. Finally, we plan to improve the proposed transfer algorithms by using deep learning techniques, which will facilitate integration of features derived from simulation datasets and multiple deep mutational scans to inform the effect of mutations on related proteins or tasks. The success of the proposed research program of results will be measured by development of algorithms that can accurately predict the variant effects on protein structure and function, elucidation of the mechanisms of ion-coupled regulation of neurotransmitter transport, selectivity mechanisms in sugar transporters and activation mechanisms of class C GPCRs. Narrative Advanced computational methods are needed to obtain comprehensive mechanistic understanding of the regulation of substrate transport via membrane transporter proteins. The research projects pursued in the PI's lab employ a synergistic combination of experiments, computational modeling and data-driven approaches to investigate neurotransmitter and sugar transporters.","Elucidating sequence, structural and dynamic basis of the functional regulation of membrane proteins",10275155,R35GM142745,"['Algorithms', 'Carrier Proteins', 'Cells', 'Computer Models', 'Computing Methodologies', 'Coupled', 'Coupling', 'Data', 'Data Set', 'Development', 'Emerging Technologies', 'Fluorescence', 'Free Energy', 'G-Protein-Coupled Receptors', 'In Vitro', 'Investigation', 'Ion Cotransport', 'Ions', 'Kinetics', 'Libraries', 'Measures', 'Membrane Proteins', 'Membrane Transport Proteins', 'Methods', 'Modeling', 'Molecular Conformation', 'Mutagenesis', 'Mutation', 'Neurons', 'Neurotransmitter Receptor', 'Neurotransmitters', 'Pathway interactions', 'Protein Conformation', 'Proteins', 'Psychological Transfer', 'Regulation', 'Research', 'Research Project Grants', 'Resolution', 'Role', 'Site', 'Sodium', 'Sorting - Cell Movement', 'Structure', 'Techniques', 'Variant', 'algorithm development', 'base', 'conformational conversion', 'deep learning', 'design', 'experimental study', 'improved', 'in silico', 'machine learning algorithm', 'molecular dynamics', 'monoamine', 'mutant', 'mutation screening', 'neurotransmitter transport', 'programs', 'protein function', 'protein structure function', 'simulation', 'success', 'sugar']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R35,2021,354588
"Machine Learning and Control Principles for Computational Biology Summary/Abstract With our increasing ability to measure biological data at scale and the digitalization of health records, computational thinking is becoming ever more important in the biological science and healthcare. The research directions proposed in this grant look to build robust machine learning models and tool for computational biology by including principles and analysis from other engineering fields, like control, that have a proven record of incorporating robustness into the systems they have automated. This increased robustness will save resources during the development of these machine learning models. It will also lead to more reliable diagnostics, clinical tools, and machine learning based biological discoveries. We have proposed three future research directions at the intersection of machine learning, control, and computational biology (a) modeling dynamical systems, (b) robust optimization schemes (c) control principles for in vivo modeling of microbial communities. The first proposed research area involves the development of flexible models for performing inference on dynamical systems models with time-series data. Dynamical systems models are able to learn mathematically causal relationships between variables, compared to other models whose parameters may only have correlative relationships. Our flexible models will be differentiable allowing them to be trained using the same efficient algorithms and hardware that have propelled deep learning models into the spotlight. These differentiable methods will allow for us to more easily integrate the uncertainty associated with biological measurements into our models. The second research area looks to develop more robust gradient optimization algorithms, the work horse for training deep neural networks. Many of the popular algorithms used to train deep neural networks were not explicitly designed to be robust. By developing more robust optimization techniques machine learning models trained on disparate data sets at different hospital or labs will be more reproducible and will require less time for tuning parameters, ultimately saving resources as well. These robust optimization techniques will also aid in the certification of machine learning based tools that will ultimately be deployed in the clinic. The third research area we propose is an approach for the discovery and design of robust microbial communities. Communities of commensal, or engineered, bacteria have long been proposed as alternative therapies for the treatment of gut related illness (“bugs as drugs”). We propose a top down approach to identifying putative microbial consortia members from time-series experiments with germ free mice colonized by complex flora. By beginning the consortia design process in vivo we hope to overcome the challenge that many other attempts at consortia construction have encountered where in vitro designed communities do not reproduce their intended properties once transferred into living host organisms. The tools from this work will be built using open access software and all data will be made easily accessible and explorable to the public. Narrative The recent public successes of deep learning have reinvigorated computational thinking around healthcare and biology. This work develops rigorous methods and tools ensuring the efficient application of machine learning principles to computational biology. This will save resources and make these tools more reliable when they are ultimately deployed for diagnostic, research, or clinical purposes.",Machine Learning and Control Principles for Computational Biology,10276879,R35GM143056,"['Algorithms', 'Alternative Therapies', 'Area', 'Bacteria', 'Biological', 'Biological Models', 'Biological Sciences', 'Biology', 'Certification', 'Clinic', 'Clinical', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostics Research', 'Engineering', 'Ensure', 'Equus caballus', 'Germ-Free', 'Grant', 'Healthcare', 'Hospitals', 'In Vitro', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Mus', 'Organism', 'Pharmaceutical Preparations', 'Process', 'Property', 'Reproducibility', 'Research', 'Resources', 'Savings', 'Scheme', 'Series', 'System', 'Techniques', 'Time', 'Training', 'Uncertainty', 'Work', 'base', 'computational reasoning', 'computerized tools', 'deep learning', 'deep neural network', 'design', 'digital health', 'dynamic system', 'experimental study', 'flexibility', 'health record', 'in vivo', 'in vivo Model', 'mathematical learning', 'member', 'microbial community', 'microbiota', 'success', 'tool']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,447500
"Cardiac CT Deblooming PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the most common type of heart disease, killing over 370,000 Americans annu- ally2. Cardiac CT is a safe, accurate, non-invasive method widely employed for diagnosis of CAD and planning therapeutic interventions. With the current CT technology, calcium blooming artifacts severely limit the accuracy of coronary stenosis assessment. Similarly, stent blooming artifacts lead to overestimation of in-stent restenosis. As a result, many coronary CT angiography (CCTA) scans are non-diagnostic and result in patients receiving costly and invasive coronary angiography (ICA) procedures.  Based on extensive feasibility results, the goal of this project is to use deep learning innovations to fundamen- tally eliminate blooming artifacts without costly redesign of the CT hardware. A consortium between GE Re- search, Rensselaer Polytechnic Institute and Weill Cornell Medicine will develop dedicated imaging protocols and machine learning methods to avoid or minimize blooming artifacts and evaluate the clinical impact of the proposed solutions. In Aim 1, the CT scan protocol will be optimized and paired with deep learning reconstruc- tion and post-processing algorithms to generate high-resolution CT images and prevent blooming artifacts. In Aim 2, image-domain and raw-data-domain deep learning processing algorithms will be developed to correct for residual blooming. After successful demonstration of the proposed methods on phantom scans and emulated clinical datasets, in Aim 3 the proposed CT methods will be clinically demonstrated and optimized based on 100 patients with coronary artery disease, using intravascular ultrasound as the ground-truth reference.  At the end of the project, we will have demonstrated and publicly disseminated a systematic methodology to essentially remove blooming artifacts in cardiac CT without a costly hardware upgrade. This will be another suc- cess of deep learning, enabling accurate coronary stenosis assessment and eliminating many unnecessary diag- nostic catheterizations. PROJECT NARRATIVE Blooming artifacts severely limit the accuracy of coronary stenosis assessment with cardiac CT, leading to un- necessary invasive coronary angiography procedures. The goal of this project is to eliminate blooming artifacts without costly redesign of the CT hardware, but based on optimized scan protocols and deep-learning-based image reconstruction and post-processing techniques. The proposed CT methods will be clinically demonstrated and optimized based on CT scans of 100 patients with coronary artery disease and using intravascular ultrasound as the ground-truth reference.",Cardiac CT Deblooming,10250305,R01HL151561,"['Address', 'Algorithms', 'American', 'Angiography', 'Area', 'Attenuated', 'Calcium', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Collaborations', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Data Set', 'Diagnosis', 'Goals', 'Heart', 'Heart Diseases', 'High Resolution Computed Tomography', 'Hospitals', 'Image', 'In Vitro', 'Institutes', 'Lead', 'Measurement', 'Medicine', 'Metals', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'New York', 'Noise', 'Outcome', 'Patients', 'Physics', 'Plant Roots', 'Presbyterian Church', 'Prevention', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Scanning', 'Speed', 'Stenosis', 'Stents', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Training', 'Ultrasonography', 'Validation', 'X-Ray Computed Tomography', 'base', 'calcification', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'diagnostic catheterization', 'image reconstruction', 'improved', 'in silico', 'in vivo', 'innovation', 'learning network', 'machine learning method', 'man', 'microCT', 'mortality', 'prevent', 'reconstruction', 'recruit', 'restenosis', 'simulation', 'success', 'temporal measurement', 'virtual', 'virtual reality simulation']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2021,978149
"Multifidelity and multiscale modeling of the spleen function in sickle cell disease with in vitro, ex vivo and in vivo validations Project Summary The spleen plays a key role in the human immune system but also clears senescent red blood cells (RBC) from the circulation and those altered by acquired or inherited diseases. In patients with sickle cell disease (SCD), the spleen is one of the first targets of pathogenic processes and a potential protector against major complications. Under hypoxic conditions, mutated sickle hemoglobin (HbS) polymerizes to fibers which increase both the stiffness and adhesion of RBC. Splenic filtration of altered RBC prone to sickling (a process that cannot be directly observed in human subjects) contributes to anemia and likely triggers acute splenic sequestration crises (ASSC). On the other hand, it potentially prevents complications associated with intravascular sickling. Self- amplified blockade of vessels with sickled RBCs is indeed a hallmark of vaso-occlusive crises, acute chest syndrome, and acute hepatic crises, that severely impact the life quality and expectancy of patients with SCD. We propose to formulate and validate a new predictive modeling framework for how the spleen filters altered RBC in SCD by synergistically integrating in silico, in vitro, ex vivo and in vivo data using multifidelity-based neural networks (NN). This will deliver predictive models that can continuously learn when new data become available, a paradigm shift in biomedical modeling. We will develop multiscale/multifidelity computational models (and corresponding NN implementations) that link sub-cellular, cellular, and vessel level phenomena spanning across four orders of magnitude in spatio-temporal scales. This scale coupling will be accomplished using a molecular dynamics/dissipative particle dynamics (MD/DPD) framework. We will validate these predictive computational models by data from in vitro and ex vivo experiments, and RBC quantitative features collected in SCD patients. Specifically, we will use three new spleen-on-a-chip microfluidic devices with oxygen control and the unique human spleen perfusion setup of our foreign partner, with the following aims: Aim 1: Develop and validate a splenic inter-endothelial slit filtration model; Aim 2: Develop new models of RBC macrophage adhesion and of phagocytosis in the spleen; Aim 3: Perform Spleen-on-a-Chip experiments and validation; Aim 4: Validate the predictive framework based on RBC samples from patients. Realization of our four Specific Aims will significantly increase our understanding of the complex pathogenic and protective roles of the spleen in SCD. Feeding our new multifidelity neural networks with morphological and functional measures of RBC circulating in SCD patients will lead to models for residual spleen function in SCD, which should help predict the risk of acute splenic sequestration crises, and guide optimal timing for Stem Cell Transplantation or Gene Therapy. The new paradigm in using deep learning tools to integrate data from different sources will be applicable to modeling many other blood diseases. Project Narrative In patients with sickle cell disease (SCD), the spleen is the target of early pathogenic processes and a potential protector against major complications. We will formulate and validate predictive multiscale models for red blood cell (RBC) filtration by the spleen based on new deep learning neural networks fed with data from simulations, experiments using new spleen-mimetic microfluidics, and RBC quantitative features from ex vivo perfusion of human spleens and from SCD patients. These models will be used to predict acute splenic sequestrations crises and guide treatment decisions in patients with SCD.","Multifidelity and multiscale modeling of the spleen function in sickle cell disease with in vitro, ex vivo and in vivo validations",10237409,R01HL154150,"['Accounting', 'Acute', 'Adhesions', 'Adhesiveness', 'Adhesives', 'Anemia', 'Biomechanics', 'Blood Circulation', 'Blood specimen', 'Cell Communication', 'Cell Shape', 'Cell model', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Complication', 'Computer Models', 'Coupling', 'Data', 'Decision Making', 'Devices', 'Endothelium', 'Erythrocytes', 'Expectancy', 'Fiber', 'Filtration', 'Goals', 'Hematological Disease', 'Hepatic', 'Hereditary Disease', 'Hereditary Spherocytosis', 'Human', 'Hypoxia', 'Immune system', 'In Vitro', 'Lead', 'Learning', 'Life', 'Link', 'Malaria', 'Measures', 'Mechanics', 'Medical', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Molecular', 'Morphology', 'Mutate', 'Organ', 'Output', 'Oxygen', 'Paper', 'Paris, France', 'Pathogenicity', 'Patients', 'Perfusion', 'Phagocytosis', 'Physicians', 'Play', 'Polymers', 'Process', 'Prognosis', 'Proteins', 'Quality of life', 'Residual state', 'Risk', 'Role', 'Sampling', 'Shapes', 'Sickle Cell', 'Sickle Cell Anemia', 'Sickle Hemoglobin', 'Source', 'Spleen', 'Stem cell transplant', 'Surface', 'System', 'Training', 'Validation', 'acute chest syndrome', 'base', 'biophysical properties', 'cohort', 'deep learning', 'deep neural network', 'design', 'ex vivo perfusion', 'experimental study', 'feeding', 'gene therapy', 'high dimensionality', 'human subject', 'improved', 'in silico', 'in vivo', 'learning progression', 'macrophage', 'mimetics', 'molecular dynamics', 'mouse model', 'multi-scale modeling', 'neural network', 'particle', 'predictive modeling', 'prevent', 'retention rate', 'senescence', 'sickling', 'simulation', 'spatiotemporal', 'tool', 'transplantation therapy', 'vaso-occlusive crisis']",NHLBI,BROWN UNIVERSITY,R01,2021,663001
"Population-level Pulmonary Embolism Outcome Prediction with Imaging and Clinical Data: A Multi-Center Study Project Summary Pulmonary embolism (PE) is a leading cause of death in the United States. Risk stratification for acute PE treatment can reduce mortality. Risk scoring systems use clinical and laboratory electronic medical record (EMR) data. In addition, biomarkers on computed tomography imaging can identify which patients with PE are at high risk of death, independent of clinical data. Despite advances in clinical and image-driven scoring systems, improving outcomes in acute PE depends on implementation of patient-specific EMR and imaging data analytic prognostic models at the point of care. The promise of digital medicine stems in part from the hope that by digitizing health data, we can leverage computer information systems to understand and improve care. A method that can make use of these data to predict patient-specific outcomes could not only provide major benefits for patient safety and healthcare quality but also reduce healthcare costs. Unfortunately, most of this information is not yet included in predictive statistical models that clinicians use to improve care delivery. This is because traditional computational methods and techniques are insufficient at accurately analyzing such high volumes of heterogeneous data. The goal of this proposal is to develop an automated precision medicine approach to achieve point-of-care risk stratification for PE patient outcomes using a fusion deep learning strategy that can simultaneously analyze health records and imaging data. An ideal PE risk-scoring system would not only predict mortality, but also assess the risk for the many debilitating long-term consequences of acute PE. Such a system would, therefore, facilitate optimal management and would likely require intelligent use of clinical, laboratory, and imaging data together in order to provide accurate patient -specific risk scoring for multiple PE outcome measures. In order to build a robust model, we propose to apply distributed training of deep learning models across four large US healthcare institutions. By distributing the algorithm rather than the data, we avoid sharing individually identifiable patient information. If successful, this project will be the first endeavor to leverage diagnostic imaging (pixel) data in combination with structured and unstructured EMR data to predict outcomes. We have the ideal research team, experience, and methods to develop an automated risk-scoring system for acute PE patients. Using a powerful combination of clinical, laboratory, and imaging data, this system will provide patient-specific risk scoring for multiple PE outcome measures. Further, this project will foster multi- center collaborations, which will afford us the opportunity to investigate the generalizability of our approach to different populations of PE patients and to train, test, and ultimately deploy our automated predictive model in a variety of clinical environments. Project Narrative Pulmonary embolism (PE) remains a leading cause of death in the United States. This project aims to develop a new ensemble deep learning model and train the model in a distributed fashion on multi-institutional data to automate the risk stratification of PE by integrating diagnostic computed tomography imaging with clinical electronic medical record data. This precision-medicine approach has the potential to rapidly and accurately perform PE risk assessment at the point of care, which could help reduce adverse clinical outcomes and increase our understanding of post-PE complications.",Population-level Pulmonary Embolism Outcome Prediction with Imaging and Clinical Data: A Multi-Center Study,10298306,R01HL155410,"['Acute', 'Algorithms', 'Angiography', 'Anticoagulant therapy', 'Architecture', 'Biological Markers', 'Blood Vessels', 'Cardiogenic Shock', 'Caring', 'Cause of Death', 'Chest', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Computational Technique', 'Computerized Medical Record', 'Computers', 'Computing Methodologies', 'Data', 'Data Analytics', 'Data Set', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Evaluation', 'Exhibits', 'Fostering', 'Funding', 'Goals', 'Health Care Costs', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Heart Arrest', 'Hemorrhage', 'Hospitals', 'Image', 'Individual', 'Information Systems', 'Institution', 'Intelligence', 'Laboratories', 'Learning', 'Lung', 'Medical Imaging', 'Medicine', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'Neurologic', 'Outcome', 'Outcome Measure', 'Outpatients', 'Pathology Report', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Prognosis', 'Pulmonary Embolism', 'Pulmonary Hypertension', 'Radiology Specialty', 'Recurrence', 'Research', 'Resuscitation', 'Risk', 'Risk Assessment', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Site', 'Source', 'Statistical Models', 'Structure', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Training', 'United States', 'X-Ray Computed Tomography', 'base', 'breast imaging', 'care delivery', 'chronic thromboembolic pulmonary hypertension', 'clinical care', 'clinical predictors', 'data de-identification', 'data repository', 'deep learning', 'demographics', 'design', 'digital medicine', 'electronic structure', 'experience', 'health care quality', 'health data', 'health record', 'heterogenous data', 'high risk', 'hospital readmission', 'imaging biomarker', 'improved', 'improved outcome', 'indexing', 'learning strategy', 'mortality', 'mortality risk', 'outcome prediction', 'patient safety', 'patient stratification', 'point of care', 'precision medicine', 'predictive modeling', 'primary outcome', 'prognostic model', 'prospective', 'radiological imaging', 'risk stratification', 'secondary outcome', 'stem']",NHLBI,STANFORD UNIVERSITY,R01,2021,483327
"Deep learning models to predict primitive streak formation in human development Project Summary Congenital birth defects affect an estimated 3% of live births. To develop effective treatment strategies, a thorough understanding of early human development is necessary. Our lab recently developed and in vitro model of human gastrulation, the process by which the three germ layers (endoderm, ectoderm, mesoderm) are formed around week three of gestation. This so-called “gastruloid” model is formed by treating human embryonic stem cells with purified differentiation factors that cause them to self-organize into a pattern resembling a gastrulating embryo. One of the key events during this process is formation of the primitive streak—a migration of specialized mesenchymal stem cells along the embryonic midline that will form all mesodermal tissues including the heart, lungs, blood vessels, and cells of the circulatory system. At the same time, cells on the periphery of the embryo begin forming extraembryonic mesoderm, which will ultimately become placental tissue. Despite the critical importance of these cell fate changes, it is currently unclear which population of embryonic stem cells will differentiate to form primitive streak or extraembryonic mesoderm and how these cell fate decisions are determined. The research objective of this fellowship proposal is to understand when and how human stem cells differentiate into primitive streak and extraembryonic mesoderm during gastrulation. My overall approach is to use time-lapse fluorescence imaging to monitor differentiation decisions in real time and at single-cell solution. I will then employ a specialized type of machine learning known as deep learning to accurately track the movement and signaling behavior of individual cells. Next, I will develop a computational model that uses a cell’s image patterns to accurately predict how each cell “chooses” between differentiation fates. The two specific research aims are: 1) to identify the subpopulation of human embryonic stem cells that will commit to primitive streak; and 2) to determine the combination of intracellular and extracellular signaling events that govern differentiation to extraembryonic mesoderm. The proposed work includes novel experimental procedures (specifically, real-time imaging of gastruloids formation in Aim 1) as well as unique neural network architectures that accurately predict binary cell fate outcomes of individual stem cells based on their signaling history. These methods will be generalizable to other biological systems. The proposed training plan focuses on generating and applying cutting-edge statistical methods tasked with full single-cell feature data incorporation in order to make robust, theoretically and biologically sound predictions about human stem cell fate decisions. A better understanding of early human development will inform future cellular therapies to prevent and treat congenital birth defects. To support my training, I have assembled a strong mentorship team with expertise in stem cell biology, live-cell imaging, machine learning methodologies, and causal inference. Project Narrative Early human development is a crucial time period in which the structures of primitive streak and extraembryonic mesoderm are formed and errors in cellular differentiation can have dire consequences. This fellowship proposal seeks to advance our fundamental understanding of how human embryonic stem cells decide specific differentiation fates using advanced machine learning methodologies. The findings from this work will help develop future stem cell therapies for treatment of birth defects and miscarriages in early primitive streak and extraembryonic mesoderm formation, ultimately improving public health.",Deep learning models to predict primitive streak formation in human development,10141600,F31HL156464,"['Affect', 'Antibodies', 'Architecture', 'Behavior', 'Bilateral', 'Biological', 'Blood Vessels', 'Brachyury protein', 'Cardiovascular system', 'Cell Cycle', 'Cell Lineage', 'Cell Therapy', 'Cells', 'Characteristics', 'Computer Models', 'Congenital Abnormality', 'Cues', 'Data', 'Data Analyses', 'Data Set', 'Defect', 'Dependence', 'Development', 'Differential Equation', 'Ectoderm', 'Embryo', 'Embryonic Development', 'Endoderm', 'Event', 'Fellowship', 'Future', 'Gaussian model', 'Generations', 'Germ Layers', 'Goals', 'Heart', 'Human', 'Human Development', 'Human body', 'Image', 'Individual', 'Inherited', 'Live Birth', 'Lung', 'Machine Learning', 'Mentorship', 'Mesenchymal Stem Cells', 'Mesoderm', 'Mesoderm Cell', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Monitor', 'Movement', 'Outcome', 'Pattern', 'Placenta', 'Population', 'Positioning Attribute', 'Pregnancy', 'Prevention', 'Primitive Streaks', 'Problem Solving', 'Procedures', 'Process', 'Public Health', 'Recording of previous events', 'Regenerative Medicine', 'Reporter', 'Research', 'Research Training', 'Signal Transduction', 'Specific qualifier value', 'Spontaneous abortion', 'Stains', 'Statistical Methods', 'Stream', 'Structure', 'Surface', 'System', 'Time', 'Tissues', 'Training', 'Work', 'base', 'biological systems', 'blastomere structure', 'bone morphogenetic protein 4', 'cell type', 'cellular imaging', 'daughter cell', 'deep learning', 'differentiation protocol', 'effective therapy', 'embryonic stem cell', 'extracellular', 'fluorescence imaging', 'gastrulation', 'human embryonic stem cell', 'human imaging', 'human model', 'human stem cells', 'improved', 'in vitro Model', 'live cell imaging', 'machine learning method', 'migration', 'molecular marker', 'morphogens', 'movie', 'neural network', 'neural network architecture', 'novel', 'pluripotency', 'precursor cell', 'prevent', 'real-time images', 'recurrent neural network', 'repaired', 'self organization', 'self-renewal', 'skills', 'sound', 'statistical learning', 'stem cell biology', 'stem cell differentiation', 'stem cell fate', 'stem cell therapy', 'stem cells', 'time use', 'treatment strategy', 'undergraduate student']",NHLBI,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2021,37550
"Using Deep Learning to Predict Induced Pluripotent Stem Cell-Derived Cardiomyocyte (iPSC-CM) Differentiation Outcomes ABSTRACT Human induced pluripotent stem cell derived cardiomyocytes (iPSC-CMs) provide transformative new avenues to combat heart diseases. They have been used extensively to model disease mechanisms and predict drug responses. Despite significant advancements in iPSC-CMs differentiation, differentiation outcomes still vary across batches, cell lines, and protocols, resulting in significant experimental variability. As a result, characterizing differentiation outcomes is essential. The current standards to characterize iPSC-CM differentiation outcomes involve monitoring for functional or genetic attributes of cardiomyocytes during the differentiation. However these processes are prohibitively time consuming, imprecise, or expensive. Discovering earlier time points and scalable, accurate markers that can determine differentiation outcomes is critical for eliminating a severe bottleneck in cardiomyocyte differentiation and creating better iPSC-CM materials. Given the rising importance of iPSC-CMs in cardiovascular research, advances in iPSC-CM differentiation would widely accelerate the search for cures. Here, I propose leveraging Artificial Intelligence (AI), deep learning and computer vision to develop scalable, accurate methods for characterizing and predicting iPSC-CM differentiation outcomes. To achieve this, I will first use deep learning models to identify markers and time points that can be used to predict and determine differentiation outcomes. I have differentiated iPSC-CMs and obtained a dataset of images at each day of differentiation that are labeled with their final differentiation outcome. I will analyze the dataset using a deep learning model—an image classifier—to determine the earliest time point that can be used to predict differentiation outcomes. I will then correlate results with transcriptomic data to gain mechanistic insight. To evaluate whether deep learning methods are scalable and accurate models for predicting differentiation outcomes, I will differentiate genetically diverse iPSCs lines to create an additional dataset to fine tune the model and then evaluate the model’s potential for scalability. To validate the accuracy of the model, I will first verify that the model’s predictions align with conventional functional and genetic markers of differentiated cardiomyocytes. Then, I will functionally, morphologically, and genetically compare predictions made by the model against existing methods for evaluating differentiating outcomes. Completion of this proposal will eliminate a main bottleneck in iPSC-CM differentiation; create an extensive iPSC- CM differentiation ‘morphology atlas’; and accelerate the application of AI and deep learning to iPSC-CMs. Additionally, the outlined training will provide me with the computational and regenerative medicine expertise required to later succeed as an independent investigator and physician scientist. PROJECT NARRATIVE Characterization of induced pluripotent stem cell derived cardiomyocyte (iPSC-CM) differentiation outcomes is currently prohibitively time intensive, imprecise, and expensive. The proposed studies will leverage Artificial Intelligence, deep learning, and computer vision to build a label free method to characterize and predict iPSC- CM differentiation outcomes. Completion of these studies will eliminate a main bottleneck in iPSC-CM differentiation, create a morphological atlas of the differentiation process, and accelerate the application of deep learning to the field of iPSC-CMs, all of which will result in advancements in cardiovascular research.",Using Deep Learning to Predict Induced Pluripotent Stem Cell-Derived Cardiomyocyte (iPSC-CM) Differentiation Outcomes,10144653,F30HL156478,"['Artificial Intelligence', 'Atlases', 'Cardiac Myocytes', 'Cardiovascular system', 'Cell Line', 'Computer Models', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Differentiation Antigens', 'Disease model', 'Doctor of Philosophy', 'Drug Modelings', 'Evaluation', 'Genetic', 'Genetic Markers', 'Goals', 'Heart Diseases', 'Human', 'Image', 'In Vitro', 'Knowledge', 'Label', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Outcome', 'Phase', 'Phenotype', 'Physicians', 'Process', 'Production', 'Protocols documentation', 'Regenerative Medicine', 'Research', 'Research Personnel', 'Scientist', 'Structure', 'Time', 'Training', 'base', 'cardiac tissue engineering', 'combat', 'contrast imaging', 'cost', 'deep learning', 'drug response prediction', 'experience', 'induced pluripotent stem cell', 'insight', 'learning strategy', 'predictive modeling', 'transcriptomics']",NHLBI,STANFORD UNIVERSITY,F30,2021,37994
"Deep learning tools for the automated analysis of hematopathology whole slide images and the development of prognostic algorithms for hematopoietic stem cell transplant recipients PROJECT SUMMARY/ABSTRACT  The bone marrow is the primary site of hematopoiesis and its examination is central to the diagnosis and management of patients with hematological diseases. Pathology slides from clinical hematopathology services represent a treasure trove of real-world data on the biology of human bone marrow. However, human examination is time-intensive and limited in its quantitative precision, preventing our ability to perform large- scale studies or identify new morphologic markers of disease. Machine learning and image processing methods can be applied to the analysis of whole-slide images (WSIs), which will lead to improvements in our understanding of the hematological system, as well as our ability to diagnose and manage hematological diseases.  The objective of this research is to build deep learning-based tools for the automated classification of bone marrow aspirates and use these tools to study hematopoiesis in hematopoietic stem cell transplant recipients. The central hypothesis is that automated methods can be developed for the classification, characterization, and quantification of cell morphology on human bone marrow aspirates and that these tools can identify morphologic features predictive of outcome after hematopoietic stem cell transplant. The long-term goal is to develop a suite of artificial intelligence tools for the quantitative analysis of hematopathology WSIs that can be used to improve our understanding of hematopoiesis and our management of patients with hematologic diseases through the development of digital hematopathology tools, stains, and biomarkers for research and clinical applications. This approach is innovative because it applies cutting-edge image analysis technology to the quantitative and scalable study of human bone marrow specimens from clinical pathology archives to drive discovery of new biological insights and clinical biomarkers. PROJECT NARRATIVE Our understanding of human hematopoiesis, hematological diseases and hematopoietic stem cell transplantation relies on morphologic examination of the bone marrow. Deep learning methods applied to human bone marrow whole-slide images from clinical services will improve our understanding of normal hematopoiesis and our ability to diagnose and treat hematological conditions, by enabling automated and standardized quantitation of morphologic features, which can then be applied to clinical slide archives and associated with clinical outcomes. We propose to build tools for the automated classification and morphologic characterization of normal bone marrow cells, and to apply these tools to study patients who have received hematopoietic stem cell transplants, allowing us to examine the process of hematopoiesis in human bone marrow after transplant and identify features predictive of transplant outcome.",Deep learning tools for the automated analysis of hematopathology whole slide images and the development of prognostic algorithms for hematopoietic stem cell transplant recipients,10286424,K38HL159128,"['Age', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Aspirate substance', 'Autologous Transplantation', 'Award', 'Basophilic Erythroblast', 'Basophils', 'Biological', 'Biological Markers', 'Biology', 'Biopsy', 'Blood Cell Count', 'Blood Cells', 'Blood Platelets', 'Bone Marrow', 'Bone Marrow Cells', 'Bone Marrow Examination', 'Bone Marrow Transplantation', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Chromatin', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Pathology', 'Clinical Services', 'Color', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Disease Marker', 'Engraftment', 'Erythroblasts', 'Erythrocytes', 'Erythroid', 'Evaluation', 'Failure', 'Goals', 'Hematological Disease', 'Hematology', 'Hematopathology', 'Hematopoiesis', 'Hematopoietic', 'Hematopoietic Stem Cell Transplantation', 'Homologous Transplantation', 'Human', 'Human Biology', 'Image Analysis', 'Label', 'Large granular lymphocyte', 'Lymphoid', 'Machine Learning', 'Marrow', 'Mature Lymphocyte', 'Measures', 'Megakaryocytes', 'Metamyelocyte', 'Methods', 'Morphology', 'Myelocyte', 'Myelogenous', 'Normal Cell', 'Nuclear', 'Outcome', 'Pathologist', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physiological', 'Plasma Cells', 'Polychromatophilic Erythroblast', 'Population', 'Process', 'Progranulocytes', 'Pronormoblasts', 'Race', 'Recovery', 'Research', 'Segmented Neutrophil', 'Services', 'Shapes', 'Site', 'Slide', 'Specimen', 'Stains', 'Standardization', 'System', 'Technology', 'Texture', 'Time', 'Training', 'Transplant Recipients', 'Transplantation', 'Vacuole', 'algorithm training', 'automated algorithm', 'automated analysis', 'base', 'bone cell', 'cell type', 'classification algorithm', 'classifier algorithm', 'clinical application', 'clinical biomarkers', 'cohort', 'deep learning', 'digital', 'eosinophil', 'granulocyte', 'image processing', 'improved', 'innovation', 'insight', 'learning classifier', 'learning strategy', 'monocyte', 'morphometry', 'myeloblast', 'neutrophil', 'outcome prediction', 'peripheral blood', 'post-transplant', 'prevent', 'prognostic', 'sex', 'success', 'tool', 'whole slide imaging']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K38,2021,119318
"Multi-Center Implementation and Validation of Efficient Magnetic Resonance Imaging and Analysis of Atherosclerotic Disease of the Cervical Carotid Abstract: Numerous investigations over the past decades have yielded substantial innovations in MR methods for the characterization of extracranial carotid atherosclerosis. Images obtained with these innovations under ideal conditions have given clinicians rich information about disease in the arterial wall and the hope for tools critically needed for adequate management of this insidious disease. Despite this, the great potential power of this technology has not made it into the routine clinical armamentarium. Indeed, because of the need for gadolinium-based contrast agents (GBCA), the long exam time (typically about 45 minutes to obtain the multiple contrasts in the 5 or 6 necessary sequences), and the steep learning curve required to interpret multi- contrast MRI most practitioners still revert to the simplified metric of diameter stenosis in assessing risk. After many collective years of investigations, the consortium of investigators collaborating on this proposal believes that the time is right to address these remaining limitations and ultimately shift the clinical paradigm. Overarching hypothesis: To achieve the great potential in the management of cervical carotid disease, a highly efficient and easily used MRI technique is required. Our hypothesis is that this can be accomplished using multi-parametric non-contrast MRI sequences coupled with the latest high signal to noise ratio (SNR) neck-shape-specific (NSS) RF coils and innovative machine learning (deep neural network) analysis methods. Aim 1: We will install identical RF coils, MRI sequences, and protocols at each of our 5 participating centers as well as rigorously test the accuracy of measurements and reproducibility of image quality from all centers. Aim 2: We will develop, train, and validate a user friendly, deep learning neural network system for the quantitative analysis of several key components considered to be present in the vulnerable atherosclerotic plaque. Aim 3: We will apply the analysis to a cohort of carotid disease subjects to establish the repeatability of the quantitative measures, as well as the accuracy of characterization in comparison to histopathology. Although we will develop and test the image quality, reproducibility and reliability in a network of highly skilled academic centers, we will design these methods to be applicable in the community hospital setting. At the conclusion of this project, we propose to have an integrated solution that can be used in subsequent investigations such as: the effect of pharmacologic intervention in modifying the composition of the plaque; studying the evolution of features of the untreated atheromatous disease over time; and, eventually, investigating the metrics that are predictive of deleterious outcomes, and that can be used in improving intervention strategies in this population. On successful completion, the RF coils and MRI sequences and analysis methods will be made available to other imaging centers in a manner that ultimately changes the paradigm of diagnosis and managing the treatment of cervical carotid atherosclerotic disease. Narrative: The goal of this project is to develop and test at multiple centers a highly efficient and easily used MRI technique for the analysis and management of cervical carotid disease. We will accomplish this using multi- parametric non-contrast MRI sequences coupled with the latest high signal to noise ratio (SNR) neck-shape- specific (NSS) RF coils and innovative machine learning (deep neural network) analysis methods.",Multi-Center Implementation and Validation of Efficient Magnetic Resonance Imaging and Analysis of Atherosclerotic Disease of the Cervical Carotid,10280858,R01HL159200,"['3-Dimensional', 'Address', 'Arterial Fatty Streak', 'Atherosclerosis', 'Caliber', 'Carotid Arteries', 'Carotid Artery Plaques', 'Carotid Atherosclerotic Disease', 'Cervical', 'Classification', 'Clinical', 'Collaborations', 'Community Hospitals', 'Computer software', 'Contrast Media', 'Coupled', 'Data', 'Diagnosis', 'Disease', 'Equipment', 'Evolution', 'Gadolinium', 'Goals', 'Histology', 'Histopathology', 'Image', 'Intervention', 'Investigation', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Neck', 'Noise', 'Outcome', 'Pathway Analysis', 'Patients', 'Pharmacology', 'Physiologic pulse', 'Population', 'Protocols documentation', 'RF coil', 'Reading', 'Reporting', 'Reproducibility', 'Research Personnel', 'Risk', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Stenosis', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Vendor', 'base', 'clinical practice', 'cohort', 'deep neural network', 'design', 'experience', 'imaging modality', 'improved', 'innovation', 'patient population', 'skills', 'stroke risk', 'success', 'tool', 'user-friendly']",NHLBI,UNIVERSITY OF UTAH,R01,2021,1331073
"Deep learning to enable the genetic analysis of aorta Project Summary / Abstract Aortic disease is an important contributor to cardiovascular morbidity and sudden death. Key discoveries, including identification of the causal gene for Marfan’s syndrome (FBN1), have advanced our knowledge of syndromic aneurysm and dissection, but to date there remains insufficient information on sporadic thoracic aortic disease. For example, despite growing knowledge of the importance of aortic disease, there is no guideline for screening for ascending aortic disease, and no therapy to treat its underlying molecular mechanisms. While there is likely some overlap between thoracic and abdominal aortic disease, they are embryologically distinct and likely have different genetic and clinical risk factors. In Dr. Pirruccello’s preliminary work, he developed an automated deep learning model to quantify the diameter of the thoracic aorta using cardiovascular magnetic resonance imaging (MRI). He applied the model in the UK Biobank and conducted a genome-wide association study for the diameter of ascending and descending thoracic aorta in nearly 40,000 participants. These results cemented the feasibility of the approach of (1) training deep learning models to extract biologically relevant information from imaging, and (2) conducting genetic analyses on these deep learning model-based phenotypes. This now paves the way for a more comprehensive analysis of additional aortic traits, and downstream evaluation of genetic risk factors for both thoracic and abdominal aortic disease. First, Dr. Pirruccello proposes to develop models for additional aortic traits including thoracic aortic strain and distensibility, and abdominal aortic diameter. Second, after developing additional models to extract those features, Dr. Pirruccello proposes to conduct genetic analyses on these traits in the UK Biobank, elucidating the common and rare genetic variation that leads to variability in the aorta’s size and distensibility at several levels. Third, he proposes to produce polygenic scores, permitting modeling of the clinical and genetic risk for abnormalities in aortic size and distensibility that may predispose to aortic aneurysm and dissection. This work will take place in the Division of Cardiology at the Massachusetts General Hospital, and at the Broad Institute of MIT and Harvard. Dr. Pirruccello will perform this research under the mentorship of Dr. Patrick Ellinor, the Director of the Cardiovascular Disease Initiative at the Broad Institute, and Dr. Mark Lindsay, an expert in genetic aortic disease at the Massachusetts General Hospital Thoracic Aortic Center. Dr. Pirruccello’s goal is to become a computational cardiovascular geneticist with expertise in machine learning. He is dedicated to becoming an independent investigator and to use the research performed for the K08 as a springboard for an R01. Project Narrative Aortic disease is an important contributor to cardiovascular morbidity and sudden death. Key discoveries, including identification of the causal gene for Marfan’s syndrome (FBN1), have advanced our knowledge of syndromic aneurysm and dissection, but to date there remains little information about the genetic basis for sporadic thoracic aortic disease. This proposal aims to expand our understanding of the genetic basis for variation in the properties of the aorta, and to use those factors to predict who may be at high risk of developing clinical aortic disease.",Deep learning to enable the genetic analysis of aorta,10283972,K08HL159346,"['Abdomen', 'Advisory Committees', 'Aneurysm', 'Aorta', 'Aortic Aneurysm', 'Aortic Diseases', 'Architecture', 'Award', 'Biological', 'Caliber', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chest', 'Cholesterol', 'Clinical', 'Complication', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Developed Countries', 'Development', 'Dilatation - action', 'Disease Outcome', 'Dissection', 'Evaluation', 'FBN1', 'Faculty', 'Fellowship', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic Variation', 'Goals', 'Human Genetics', 'Image', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Life', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Manuscripts', 'Marfan Syndrome', 'Massachusetts', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Nature', 'Operative Surgical Procedures', 'Participant', 'Pathologic', 'Peer Review', 'Phenotype', 'Play', 'Positioning Attribute', 'Preventive therapy', 'Property', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Risk', 'Risk Factors', 'Role', 'Software Engineering', 'Students', 'Sudden Death', 'Syndrome', 'Testing', 'Thoracic aorta', 'Training', 'Variant', 'Work', 'abdominal aorta', 'base', 'biobank', 'career', 'causal variant', 'clinical risk', 'clinically relevant', 'cohort', 'college', 'computer science', 'deep learning', 'exome sequencing', 'experience', 'genetic analysis', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic locus', 'high risk', 'human data', 'imaging study', 'insight', 'interest', 'medical schools', 'new therapeutic target', 'rare variant', 'screening guidelines', 'skills', 'therapeutic target', 'trait', 'university student']",NHLBI,MASSACHUSETTS GENERAL HOSPITAL,K08,2021,169560
"A prospective multiethnic HFpEF cohort from California's Central Valley ABSTRACT This is a new U01 application to establish a Clinical Center (CC) for a prospective multiethnic HFpEF cohort from California central valley for deep phenotyping analyses. The investigative team is diverse, multidisciplinary, and complementary with investigators from School of Medicine, College of Engineering and College of Agricultural and Environmental Sciences. The investigative team is highly collaborative and has strong track records of previous participation in large-scale research networks involving electronic data from heterogeneous sources, including EHRs, mobile health technologies, and direct-to-participant mailings/web portals. UC Davis Heart Failure Network has one of the most diverse patient population in the country, with a large representation of Latino population from California Central Valley. Our network has an extensive catchman area with a momentous growth in patient volume. The proposed deep phenotyping will take advantage of the newly developed total-body PET scan at UC Davis to decipher the roles of organ-specific variations in metabolic syndrome and inflammation in a diverse and heterogenous HFpEF population. One unique feature of the proposed study is the use of functional connectomics analyses to directly exploit the heterogeneity in the HFpEF population. Indeed, it is the heterogeneity that provides the necessary data needed to derive the interconnections to test the critical network drivers, that will provide eventual insights into potential molecular targets for therapy as well as the unbiased classifications of subtypes of HFpEF. Finally, functional connectomics analyses enable modular “plugin” of new datasets (e.g., microbiomes), derived from deep phenotyping analyses from other CCs in the HeartShare Network. Therefore, our proposed study promises to contribute both technically and conceptually to the overall understanding of the molecular mechanisms underlying the heterogenous disease in HFpEF. Project Narrative This is a new U01 application to establish a Clinical Center (CC) for a prospective multiethnic HFpEF cohort from California central valley for multiscale novel deep phenotyping analyses. Our proposed study promises to contribute both technically and conceptually to the overall understanding of the molecular mechanisms underlying the heterogenous disease in HFpEF.",A prospective multiethnic HFpEF cohort from California's Central Valley,10327488,U01HL160274,"['Aging', 'Agriculture', 'Area', 'Atrial Fibrillation', 'Blood flow', 'California', 'Cardiovascular Diseases', 'Cardiovascular system', 'Catchment Area', 'Center for Translational Science Activities', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinics and Hospitals', 'Community Hospitals', 'Complex', 'Coronary Arteriosclerosis', 'Country', 'Coupled', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'EFRAC', 'Ecology', 'Electronic Health Record', 'Engineering', 'Enrollment', 'Event', 'Foundations', 'Funding', 'Genomics', 'Growth', 'Health Technology', 'Heart', 'Heart failure', 'Heterogeneity', 'Hispanics', 'Hypertension', 'Image', 'Incidence', 'Inflammation', 'Inflammatory', 'Latino', 'Learning', 'Machine Learning', 'Metabolic', 'Metabolic syndrome', 'Mining', 'Molecular', 'Molecular Analysis', 'Morbidity - disease rate', 'Obesity', 'Organ', 'Participant', 'Patients', 'Phase', 'Phenotype', 'Population', 'Population Heterogeneity', 'Positron-Emission Tomography', 'Progressive Disease', 'Proteomics', 'Pulmonary Hypertension', 'Quality of life', 'Records', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Source', 'Structure', 'Syndrome', 'Testing', 'Text', 'Therapeutic', 'United States', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biomedical referral center', 'career development', 'clinical center', 'cohort', 'college', 'comorbidity', 'connectome', 'electronic data', 'functional status', 'indexing', 'innovation', 'insight', 'mHealth', 'medical schools', 'metabolomics', 'microbiome', 'minority communities', 'molecular targeted therapies', 'mortality', 'multi-ethnic', 'multidisciplinary', 'multiple omics', 'next generation', 'novel', 'participant enrollment', 'patient engagement', 'patient population', 'phenomics', 'phrases', 'preservation', 'programs', 'prospective', 'protocol development', 'recruit', 'remote monitoring', 'sex', 'skill acquisition', 'text searching', 'web portal']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,U01,2021,277890
"Rapid response for pandemics: single cell sequencing and deep learning to predict antibody sequences against an emerging antigen ABSTRACT One of the “holy grails” in immunology is to be able to directly predict tight-binding variable chain antibody sequences in silico against foreign or non-self `antigenic' proteins. Immunoglobulin chain rearrangement can potentially encode approximately 1016 different variants of antibody heavy and light chain sequences. However, only a small fraction of the sequence space is generally accessed for evolving antibodies against foreign proteins. The computational challenge is to go from a model of the structure of an antigen to predicting a set of antibody chain sequences that can bind tightly to the antigen. If solved, it might be possible to move in less than 24 hours from the first cryo-electron-microscopic structure of a novel viral protein to advance a set of potent antibody-like molecular candidates for testing. Towards solving this problem, this project aims to develop a deep learning architecture that will take as input thermodynamic, quantum mechanical (density functional), and local structure- based network topographical features of the antigens and their cognate antibodies, and will output their respective binding affinity constants. We will design a generative adversarial network (GAN), which we think is uniquely suited for regression-based ML approaches for the immune system, to discover associations between the epitope and the variable chain features. This approach requires a large data stream of antigen and cognate antibody sequences, which until recently was difficult to obtain. A recently described single B-cell receptor (BCR) specific tagging method coupled with single cell deep sequencing (“linking B cell receptor to antigen specificity through sequencing” or LIBRA- seq) can rapidly isolate and sequence the BCR variable chain coding regions that can bind with high selectivity to antigenic epitopes. Towards the specific project goals, in Task 1, LIBRA-seq will be used to rapidly identify and generate candidate immunoglobulin coding sequences in response to specific linear and nonlinear epitopes (against controls), chosen through computational/molecular modeling and prioritized with SARS-CoV-2 Spike protein epitopes (but not restricted to these), injected into a mouse model, to generate large training sets; in Task 2, these training sets, along with other data sets already available in public databases, will generate a series of structural features (described above), which will be used to train the GAN; in Task 3, the predicted epitope-antibody interactions will be validated by direct experiments with synthetic antibody and phage-display systems. Thus, the proposed strategy combines foundational principles in evolutionary biology, genomics, structural chemistry, and computer science to the solution of a general biological engineering problem. Results from this project are expected to lay the foundations for a rigorously tested and fully automated machine- learning system that could rapidly generate synthetic antibody candidates from the structure of a novel virus protein, which can enhance the rapid response ability against a future pandemic. The ability to develop targeted antibody therapy against non-infectious or chronic diseases, and on the production of antibody-based industrial enzymes, will also be dramatically enhanced if this project were to be successful. The team: The team-leads of this multi-institutional research project comprise a computer scientist, a protein crystallographer, an immunologist, and a molecular biologist. 1 NARRATIVE The readiness for a future viral pandemic will critically depend on being able to accurately predict, entirely using computers, neutralizing antibody structures directly from the virus's protein structure. Vaccines and therapeutics can then be manufactured and tested with unprecedented rapidity. We propose to make this goal a reality by engaging the advantages of single-cell genomic deep sequencing and the latest advances in deep machine learning.",Rapid response for pandemics: single cell sequencing and deep learning to predict antibody sequences against an emerging antigen,10274223,R01AI169543,"['Affinity', 'Amino Acid Sequence', 'Antibodies', 'Antibody Formation', 'Antibody Specificity', 'Antibody Therapy', 'Antigen-Antibody Complex', 'Antigens', 'Architecture', 'B-Cell Antigen Receptor', 'B-Cell Receptor Binding', 'B-Lymphocytes', 'Base Sequence', 'Binding', 'Biological', 'Biology', 'Cells', 'Chronic Disease', 'Code', 'Computer Models', 'Computers', 'Computing Methodologies', 'Coupled', 'Data', 'Data Set', 'Databases', 'Degenerative Disorder', 'Development', 'Diagnosis', 'Economics', 'Electrons', 'Engineering', 'Enzymes', 'Epitopes', 'Equilibrium', 'Foundations', 'Future', 'Genes', 'Genomics', 'Goals', 'Hour', 'Immune system', 'Immunize', 'Immunoassay', 'Immunoglobulins', 'Immunologist', 'Immunology', 'Industrialization', 'Ligands', 'Light', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurable', 'Mechanics', 'Methods', 'Microscopic', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Computations', 'Mus', 'Nature', 'Network-based', 'Neural Network Simulation', 'Output', 'Passive Immunotherapy', 'Phage Display', 'Phase', 'Play', 'Problem Solving', 'Process', 'Production', 'Proteins', 'Readiness', 'Reagent', 'Research Project Grants', 'SARS-CoV-2 antigen', 'SARS-CoV-2 spike protein', 'Savings', 'Scientist', 'Series', 'Specificity', 'Structural Chemistry', 'Structural Models', 'Structure', 'Surface Plasmon Resonance', 'System', 'Testing', 'Therapeutic', 'Therapeutic antibodies', 'Thermodynamics', 'Time', 'Training', 'Vaccines', 'Validation', 'Variant', 'Viral', 'Viral Antigens', 'Viral Proteins', 'Work', 'base', 'combat', 'computer science', 'data streams', 'database structure', 'deep learning', 'deep neural network', 'deep sequencing', 'density', 'design', 'experimental study', 'high dimensionality', 'in silico', 'innovation', 'insight', 'large datasets', 'machine learning method', 'molecular modeling', 'mouse model', 'neutralizing antibody', 'novel', 'novel virus', 'pandemic disease', 'pandemic preparedness', 'pathogen', 'physical property', 'protein structure', 'quantum', 'response', 'scaffold', 'simulation', 'single cell sequencing', 'synthetic antibodies', 'therapeutic evaluation', 'three dimensional structure']",NIAID,KECK GRADUATE INST OF APPLIED LIFE SCIS,R01,2021,1851627
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10228687,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'risk prediction', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2021,394824
"Cyst-X: Interpretable Deep Learning Based Risk Stratification of Pancreatic Cystic Tumors Project Summary The overall goal of this project is to develop a new diagnostic tool, called Cyst-X, for accurate detection and characterization of pre-cancerous pancreatic cysts and improve patient outcome through precise decisions (surgical resection or surveillance). Pancreatic cancer is the most fatal cancer among all cancers due to its poor prognosis and lack of early detection methods. Unlike other common cancers where precursor lesions are well known (colon polyps-colon cancer, ductal carcinoma in situ (DCIS)-breast cancer), pancreas cancer precursors (cysts) are poorly understood. Diagnosing pancreatic cancer at earlier stages may decrease mortality and morbidity rates of this lethal disease. One major approach for diagnosing pancreatic cancer at earlier stages is to target pancreatic precancerous pancreatic neoplasms (cysts) before they turn into invasive cancer. Once cysts are detected with radiology imaging such as magnetic resonance imaging (MRI), they should be characterized with respect to their malignant potential. Low-risk cysts remain harmless; hence, patients should remain under surveillance program. On the other hand, high-risk cysts can progress into an aggressive cancer, therefore, patients should undergo surgical resection if possible. Despite this, international guidelines for risk stratification of pancreatic cysts are woefully deficient (55-76% accuracy for determining characteristics of low-risk vs high risk cystic tumors, while only 40-50% accuracy detecting cysts with MRI). Combined, these critical barriers indicate that there is an urgent need for improving characterization of pancreatic cystic tumors. Based on our preliminary results, which support the development of an image-based diagnostic decision tool, we hypothesize that our proposed Cyst-X will produce higher diagnostic accuracy for characterizing pancreatic cysts and provide better patient management compared to the current guidelines. Towards this overarching hypothesis, we will first use powerful deep learning methods (specifically deep capsule networks) for automatically detecting and segmenting the pancreas and pancreatic cysts from multi-sequence MRI scans (Aim 1). Next, we will create an interpretable image-based diagnosis model for characterizing pancreatic cysts (Aim 2). Accurate characterization is necessary for such a diagnostic model; however, emphasis will also be placed on interpretability of the machine generated diagnostic model. Visual explanation of the discriminative features will help radiologists obtain higher decision rates in patient management. In Aim 3, we will validate the proposed Cyst-X framework in a multi-center study. A total of 1200 multi-sequence MRI scans will be collected from three participating clinical centers (Mayo Clinic, Columbia University Medical Center, Erasmus Medical Center). Comprehensive evaluations will be made to test the validity and generalizability of Cyst-X. All evaluations will be made with respect to the international guidelines and biopsy proven ground truths. Our proposed study has wide implications: specifically, in the long term, it will influence early diagnosis of pancreatic cancer and clinical decision making to improve survival rates of pancreatic cancer. Project Narrative Unlike other common cancers for which early detection and surgical resection have reduced cancer deaths (e.g. colon polyps for colon cancer, ductal carcinoma in situ lesions and breast cancer), pancreas cancer precursors, such as commonly observed pancreatic cysts, are poorly understood. Towards the long-term goal of early detection of pancreatic cancer, our objective in this proposal is to accurately detect and characterize pancreatic cysts before they turn into aggressive cancer. The outcome of this research will be a new diagnostic tool, named Cyst-X, which will establish a better clinical strategy than the current guidelines by recommending a more selective use of invasive testing, surgery, and surveillance.",Cyst-X: Interpretable Deep Learning Based Risk Stratification of Pancreatic Cystic Tumors,10391173,R01CA246704,"['Academic Medical Centers', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Colon Carcinoma', 'Colonic Polyps', 'Cyst', 'Cystic Neoplasm', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Epithelial cyst', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'High Prevalence', 'Histopathology', 'Image', 'In Situ Lesion', 'Individual', 'International', 'Lead', 'Lesion', 'MRI Scans', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Medical center', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Mucinous Cystadenoma', 'Mucinous Neoplasm', 'Multicenter Studies', 'Names', 'Noninfiltrating Intraductal Carcinoma', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Outcomes Research', 'Pancreas', 'Pancreatectomy', 'Pancreatic Cyst', 'Pancreatic cystic neoplasia', 'Papillary', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Prognosis', 'Property', 'Radiology Specialty', 'Recommendation', 'Reference Standards', 'Research', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Series', 'Serous Cystadenoma', 'Side', 'Structure', 'Surveillance Program', 'Survival Rate', 'System', 'Technology', 'Testing', 'Time', 'Trust', 'Universities', 'Unnecessary Surgery', 'Visual', 'automated algorithm', 'base', 'cancer invasiveness', 'cancer type', 'capsule', 'clinical center', 'clinical decision-making', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'detection method', 'detection platform', 'diagnostic accuracy', 'efficacy validation', 'experimental study', 'follow-up', 'high risk', 'improved', 'learning strategy', 'malignant breast neoplasm', 'mortality', 'novel diagnostics', 'pancreatic neoplasm', 'premalignant', 'prognostic significance', 'radiological imaging', 'radiologist', 'radiomics', 'risk stratification', 'screening', 'stem', 'tool']",NCI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,438819
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,10116348,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2021,41552
"Deep learning characterization of renal tumors Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning characterization of renal tumors,10444047,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,JOHNS HOPKINS UNIVERSITY,R03,2021,39613
"Leveraging deep learning for markerless motion management in radiation therapy Leveraging deep learning for markerless motion management in radiation therapy Project Summary Organ motion is a predominant limiting factor for the maximum exploitation of modern radiation therapy (RT). Adverse influence of the organ motion is aggravated in hypofractionated treatment because of protracted dose delivery. Current image guided RT often relies on the use of implanted fiducial markers (FMs) for online/offline target localization, which is invasive and costly, and introduces possible bleeding, infection and discomfort of the patient. In this project, we harness the enormous potential of deep learning and investigate a novel markerless localization strategy by combined use of a pre-trained deep learning model and kV X-ray projection or cone beam CT images. We hypothesize that incorporation of deep layers of image information allows us to visualize otherwise invisible target in real-time and greatly reduce the uncertainties in beam targeting. Specific aims of the project are to: (1) Develop a DL-based tumor target localization framework for image guided RT (IGRT); (2) Apply the DL-based strategy to localize prostate target on 2D kV X-ray projection and 3D CBCT images; and (3) Evaluate the potential clinical impact of the DL strategy for pancreatic IGRT. This study brings up, for the first time, highly accurate markerless target localization based on deep learning and provides a clinically sensible solution for IGRT of prostate and pancreas cancers or other types of cancers. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision RT. Given its significant promise to optimally cater for inter- and intra-fractional uncertainties, the study should lead to substantial improvement in patient care and enables us to utilize maximally the technical capability of modern RT such as IMRT and VMAT. Given the dose responsive nature of various cancers and that the proposed method requires no hardware modification, this research should lead to a widespread impact on the management of neoplasmic diseases affected by organ motion. Leveraging deep learning for markerless motion management in radiation therapy Project Narrative This project is aimed at establishing a deep learning-based image guidance strategy for motion management in prostate and pancreas radiation therapy. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision radiation therapy. The research should thus lead to a widespread impact on the management of various neoplasmic diseases affected by organ motion.",Leveraging deep learning for markerless motion management in radiation therapy,10235308,R01CA256890,"['3-Dimensional', 'Affect', 'Brain', 'Clinical', 'Complication', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Disease', 'Dose', 'Duodenum', 'Felis catus', 'Head and neck structure', 'Hemorrhage', 'Image', 'Implant', 'Infection', 'Intensity-Modulated Radiotherapy', 'Investigation', 'Lead', 'Learning', 'Liver', 'Location', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Malignant neoplasm of prostate', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Nature', 'Neoplasms', 'Normal tissue morphology', 'Organ', 'Pancreas', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Prostate', 'Radiation Dose Unit', 'Radiation Oncology', 'Radiation therapy', 'Radiosurgery', 'Research', 'Retrospective Studies', 'Roentgen Rays', 'Site', 'System', 'Techniques', 'Time', 'Training', 'Uncertainty', 'Vertebral column', 'X-Ray Computed Tomography', 'base', 'cancer type', 'cone-beam computed tomography', 'conventional therapy', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experimental study', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'improved', 'indexing', 'learning strategy', 'novel', 'pancreas imaging', 'predictive modeling', 'real time model', 'respiratory', 'treatment planning', 'tumor']",NCI,STANFORD UNIVERSITY,R01,2021,442403
"Virtual Biopsy with Tissue-level Accuracy in Glioma Project Summary This is a Bioengineering Research Grant (BRG) proposal in response to PAR-19-158 to further develop and validate a non-invasive panel of the most critical glioma molecular markers (IDH, 1p/19q, MGMT) using standard clinical MRI T2-weighted images and deep learning, and extend the performance to tissue-level accuracies. Currently, the only reliable way of obtaining molecular marker status is through direct tissue sampling of the tumor, requiring either a craniotomy and stereotactic biopsy or a large open surgical resection. Noninvasive determination of molecular markers with tissue-level accuracy would be transformational in the management of gliomas, reducing or eliminating the risks and costs associated with a neurosurgical procedure, accelerating the time to definitive treatment, improving patient experience and ultimately patient outcomes and survival time. Artificial intelligence such as deep learning has emerged as a powerful method for classification of imaging data that can exceed human performance. Preliminary work using our novel voxel-wise classification-segmentation approach with the NIH/NCI TCIA glioma database has outperformed any prior noninvasive methods for determination of IDH, 1p/19q, and MGMT methylation, achieving accuracies of 97%, 93%, and 95%, respectively. The approach however, needs to be validated beyond the TCIA and accuracies need to be extended in order to achieve tissue level performance. This will be accomplished by using our top-performing voxel-wise classification framework, leveraging marker-specific targeted sample sizes, and gaining a final boost from deep-learning artifact correction networks. In Aim 1 we will curate a database of over 2000 gliomas including 500 subjects from our institution, 1200 subjects from our external collaborators, and over 300 subjects from the TCIA. We will train our voxel-wise deep learning classifiers to determine molecular status based on clinical T2-weighted MR images with target accuracies of 97%. In Aim 2 we will rigorously evaluate the motion and noise sensitivity of the networks and create an artifact correction network with the goals of 1) recovering accuracies in the setting of large amounts of motion/noise and 2) further boosting accuracy to tissue-level performance even in the absence of visible artifact. In Aim 3 we will deploy a complete end-to-end clinical workflow and evaluate real-world live performance of the AI tool on 300 prospectively acquired brain tumor cases and 300 subjects from our external collaborators. The AI tool will be made available for deployment at other medical centers. The developed framework can also be extended to additional markers in a straightforward fashion. In summary, this BRG proposal will further develop, refine and validate a non-invasive MRI-based method for determining the most critical glioma molecular markers rivaling tissue-level accuracies to significantly reduce and in many cases eliminate the need for stereotactic biopsy. Project Narrative Knowledge of molecular status for a variety of markers in gliomas has moved to the forefront in clinical decision- making. This requires direct tissue sampling either from an invasive brain biopsy or open surgical resection. In this Bioengineering Research Grant proposal in response to PAR-19-158, we will develop and validate a non- invasive method to determine a panel of the most critical molecular markers (IDH, 1p/19q and MGMT methylation) with near tissue-level accuracies using routine T2-weighted (T2w) MR images and deep learning algorithms to significantly reduce and in many cases eliminate the need for stereotactic biopsy in glioma.",Virtual Biopsy with Tissue-level Accuracy in Glioma,10226632,R01CA260705,"['19q', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Automation', 'Biology', 'Biomedical Engineering', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Classification', 'Clinical', 'Computerized Medical Record', 'Craniotomy', 'Data', 'Data Set', 'Databases', 'Digital Imaging and Communications in Medicine', 'Excision', 'Glioma', 'Goals', 'Human', 'Hyperacusis', 'Image', 'Institution', 'Knowledge', 'MGMT gene', 'Magnetic Resonance Imaging', 'Manuals', 'Medical center', 'Methods', 'Methylation', 'Molecular', 'Molecular Analysis', 'Morphologic artifacts', 'Motion', 'Neurosurgical Procedures', 'Noise', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Process', 'Prognosis', 'Prospective cohort', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'T2 weighted imaging', 'Testing', 'The Cancer Genome Atlas', 'The Cancer Imaging Archive', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'clinical decision-making', 'clinical implementation', 'clinical translation', 'contrast imaging', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'large datasets', 'learning classifier', 'learning strategy', 'molecular marker', 'motion sensitivity', 'mutational status', 'novel', 'prospective', 'response', 'surgical risk', 'tool', 'tumor', 'virtual biopsy']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,655597
"A clinical tool for automated detection and delineation of intracranial metastases from MRI As the management of multiple intracranial metastases is rapidly evolving, the demands for detection and delineation of a large number of potentially very small metastatic lesions in the brain on 3D magnetic resonance images (MRI) are increasing dramatically. Artificial intelligence (AI) systems can assist both the radiologist as well as radiation oncologist in their roles in management of patients with multiple tumors metastatic to the brain. In response to PAR-20- 155, we have assembled an academic-industrial partnership including investigators from three academic institutes and an industrial AI team to develop, translate and validate AI systems to address this unmet clinical question. In this proposal, a neural network system based upon multiple scale 3D fully convolutional one-stage objective detectors containing segmentation heads will be optimized and investigated. Training and testing data will be provided from clinical images of patients treated with radiosurgery to multiple small metastases acquired from three academic centers, curated by experts, and augmented by addition of realistic synthetic lesions injected into images. The clinical utility of the network will be investigated for its ability to assist a) radiologists in detecting multiple metastases accurately and efficiently, and b) radiation oncologists in delineating multiple metastatic lesions to support selection of therapeutic strategies and planning of treatments. Project Narrative As the management of multiple intracranial metastases is rapidly evolving, the demands for detection and delineation of a large number of potentially very small metastatic lesions in the brain on 3D magnetic resonance images (MRI) are increasing dramatically. We aim to develop an artificial intelligence (AI) system to assist both the radiologist as well as radiation oncologist in their roles in management of patients with multiple tumors metastatic to the brain. The intended clinical utilities of the system will be evaluated through observer studies and radiation dose analyses.",A clinical tool for automated detection and delineation of intracranial metastases from MRI,10275302,R01CA262182,"['3-Dimensional', 'Address', 'Anatomy', 'Architecture', 'Artificial Intelligence', 'Blinded', 'Brain', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Treatment', 'Computer Assisted', 'Data', 'Detection', 'Diagnosis', 'Dose', 'Equilibrium', 'Expert Systems', 'Feedback', 'Head', 'Image', 'Industrialization', 'Inferior', 'Injections', 'Institutes', 'Institution', 'Lesion', 'Magnetic Resonance Imaging', 'Medical', 'Metastatic malignant neoplasm to brain', 'Michigan', 'Neoplasm Metastasis', 'New York', 'North Carolina', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Quality of life', 'Radiation Dose Unit', 'Radiation Oncologist', 'Radiation therapy', 'Radiosurgery', 'Research Personnel', 'Role', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Translating', 'Tumor Volume', 'Uncertainty', 'Universities', 'Variant', 'base', 'clinical imaging', 'deep learning', 'deep neural network', 'detection method', 'detector', 'improved', 'industry partner', 'neural network', 'object recognition', 'radiologist', 'response', 'tool', 'treatment planning', 'tumor']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,456195
"SPECT with a Compton Camera for Thyroid Cancer Imaging SPECT with a Compton Camera for Thyroid Cancer Imaging ABSTRACT The thyroid gland is butterfly-shaped in the lower front of the neck, and secretes hormones for normal biological functions. The incidence of thyroid nodules increases with age, involving more than half of the population. Thyroid cancer is the most common type of endocrine-related cancer and the most common cancer in young women, with over 50K new cases per year in the United States. To detect and treat thyroid cancer, it is desired to characterize the nodule accurately. Currently, single photon emission computed tomography (SPECT) and computed tomography (CT) are used with radioiodine scintigraphy to evaluate patients with thyroid cancer. The gamma camera for SPECT contains a mechanical collimator that greatly compromises dose efficiency and limits diagnostic sensitivity. Fortunately, the Compton camera is emerging as an ideal approach for mapping the distribution of radiopharmaceuticals inside the thyroid. It is because the Compton camera requires no mechanical collimation and in principle rejects no gamma ray photon. Hence, radiation dose will be reduced by orders of magnitude in screening and follow-up scans of patients. In this R21 project, we will design a high-efficiency and high-quality tomographic imaging system with a Compton camera dedicated to thyroid cancer imaging, and develop an associated software package for Compton scattering based SPECT imaging. The major innovation lies in the deep learning empowered image reconstruction and the Timepix3-based Compton camera for thyroid cancer imaging. The proposed techniques help reduce radiation dose dramatically, improve the imaging speed, and enhance image quality and diagnostic performance, having a great potential for clinical translation. The three specific aims are defined as follows: (1) a Monte Carlo simulator will be developed for gamma ray Compton data synthesis; (b) deep reconstruction algorithms will be developed for Compton camera based SPECT, and (c) a SPECT system will be designed in numerical simulation and phantom experiments for ultra-low-dose thyroid imaging. Upon the completion of this project, the simulation and reconstruction software tools should have been developed for tomographic imaging of the radiotracer distribution in the human thyroid, and a point of care (POC) SPECT system will have been designed with the Compton camera and experimentally verified for a superior diagnostic performance at an ultra-low dose. The synergy among the deep learning techniques and the cutting-edge Timepix3 camera will have been demonstrated for a follow-up R01 proposal. NARRATIVE A high-efficiency and high-quality Compton camera based SPECT imaging system will be designed for thyroid cancer imaging. This will benefit not only new thyroid cancer patients (>50K per year in USA alone) who need diagnosis and treatment but also thyroid cancer survivors (>800K in USA alone) who need long-life following-up to monitor and combat any recurrence of cancer.",SPECT with a Compton Camera for Thyroid Cancer Imaging,10286795,R21CA264772,"['3-Dimensional', 'Age', 'Algorithms', 'Biological Process', 'Butterflies', 'Cancer Patient', 'Cancer Survivor', 'Collimator', 'Compton radiation', 'Computer software', 'Conceptions', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Disease', 'Distant Metastasis', 'Dose', 'Endocrine', 'Gamma Cameras', 'Gamma Rays', 'Geometry', 'Goals', 'Gold', 'Hormones', 'Human', 'I131 isotope', 'Image', 'Image Enhancement', 'Incidence', 'Iodine Isotopes', 'Label', 'Learning', 'Life', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Mechanics', 'Monitor', 'Monte Carlo Method', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Papillary', 'Patients', 'Performance', 'Photons', 'Population', 'Prognosis', 'Publishing', 'Radiation', 'Radiation Dose Unit', 'Radioactive Iodine', 'Radioisotopes', 'Radionuclide Imaging', 'Radiopharmaceuticals', 'Recurrence', 'Scanning', 'Signal Transduction', 'Software Tools', 'Speed', 'System', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'United States', 'Visible Human Project', 'X-Ray Computed Tomography', 'attenuation', 'base', 'cancer imaging', 'cancer recurrence', 'clinical translation', 'combat', 'deep learning', 'deep neural network', 'design', 'detector', 'digital', 'dosage', 'empowered', 'experimental study', 'follow-up', 'image reconstruction', 'imaging system', 'improved', 'innovation', 'point of care', 'prototype', 'radiotracer', 'reconstruction', 'screening', 'simulation', 'single photon emission computed tomography', 'synergism', 'system architecture', 'tomography', 'tool', 'uptake', 'virtual', 'young woman']",NCI,UNIVERSITY OF MASSACHUSETTS LOWELL,R21,2021,407750
"Domain-Knowledge Informed Deep Learning for Early Detection of Pancreatic Cancer PROJECT SUMMARY The goal of this project is to leverage deep-learning algorithms on Electronic Health Records (EHRs) to improve early detection of pancreatic ductal adenocarcinoma (PDAC), a malignancy with high mortality and morbidity. Although numerous risk factors have been identified, PDAC is most often found in later stages when effective treatments are not feasible or their survival benefit is limited. In this R21, we aim to develop novel structured methodologies for systematically incorporating feature grouping strategy from expert domain knowledge into the training procedure of deep-learning algorithms for improving PDAC diagnosis. The overarching hypothesis for this study is that the groups of highly correlated variables will combine to form superior and interpretable predictors compared to individual clinical variables (current proposal). Furthermore, these new predictors represented by the group of related data will be useful for other downstream tasks such as risk factor identification via causal discovery (future research). The proposed research presents an innovative approach towards unifying human and artificial intelligence, using explainable algorithms to build interpretable prediction models, in contrast to conventional deep-learning algorithms which are non-traceable by humans due to their black-box nature. An optimal strategy for creating composite (grouped) variables should maximize both predictive power as well as human-interpretability. We will thus explore a variety of grouping strategies relying heavily on human-expert knowledge (e.g. clinical workflows) as well as auto-correlation tests. An effective grouping strategy will allow our prediction model to learn the relative importance of both individual measurements as well as interpretable groups of measurements in predicting PDAC. Examples in the literature show that such grouped predictors often have superior predictive power compared to their individual components, which can be attributed to the mutual information shared within the group. Different types of explainable (attention) neural networks may also be applied depending on the group characteristics to further improve interpretability as well as prediction accuracy. We believe that similar methodologies applied to predictive modeling in healthcare data have the potential to fundamentally advance clinical decision making with improved model interpretability. The success of this proposal will be leveraged in a larger ongoing project which aims to establish new causal relationships between various risk factors associated with PDAC. This involves an advanced graph-based approach for building interpretable models. Our direct application of causal discoveries in the future research will be a program for collecting patient-generated health data (PGHD) for PDAC early diagnosis. The goal of this proposal is to develop new protocols for the early detection of pancreatic cancer using a novel strategy for combining human-expert knowledge with deep-neural embeddings. Our study involves a structured exploration of feature grouping strategies using Electronic Health Records (EHRs) to develop predictive and potentially insightful deep learning models. We will be able to propose new predictors represented by groups of related data that are expected to have superior predictive ability for improving pancreatic cancer diagnosis.",Domain-Knowledge Informed Deep Learning for Early Detection of Pancreatic Cancer,10317236,R21CA265400,"['Academic Medical Centers', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Cancer Etiology', 'Categories', 'Cessation of life', 'Characteristics', 'Chronology', 'Clinical', 'Complex', 'Data', 'Data Analytics', 'Data Set', 'Diagnosis', 'Early Diagnosis', 'Electronic Health Record', 'Goals', 'Graph', 'Grouping', 'Healthcare', 'Hospitals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measurement', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Pancreatic Ductal Adenocarcinoma', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Predictive Factor', 'Procedures', 'Protocols documentation', 'Provider', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Savings', 'Scheme', 'Series', 'Signs and Symptoms', 'Statistical Study', 'Structure', 'Survival Rate', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Visit', 'associated symptom', 'base', 'cancer diagnosis', 'clinical decision-making', 'data format', 'data quality', 'deep learning', 'deep learning algorithm', 'demographics', 'design', 'direct application', 'effective therapy', 'electronic structure', 'feature extraction', 'health data', 'improved', 'innovation', 'knowledge base', 'mortality', 'multimodal data', 'multimodality', 'neural network', 'novel', 'novel strategies', 'pancreatic ductal adenocarcinoma model', 'predictive modeling', 'programs', 'relating to nervous system', 'risk prediction', 'screening', 'success']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R21,2021,176874
"Artificial Intelligence Enabled Multi-Spectral Autofluorescence Imaging for Real-time Determination of Muscle in Bladder Tumor During Resection PROJECT SUMMARY For adequate diagnosis and staging, transurethral resection of bladder tumor (TURBT) specimens must extend into the bladder muscle wall. Studies indicate that for patients with high-grade bladder cancer, 5-year mortality was 8% when the muscle was present in the TURBT specimen, and 13% when absent. For this reason, if there is not sufficient muscle in the specimen after the initial resection, guidelines recommend repeat TURBT. Almost half of TURBTs do not contain muscle as confirmed post-operatively by histopathologic examination. There are currently no practical tools available to surgeons to determine during the procedure whether the resected specimen includes sufficient muscle tissue. The goal of this project is to develop an imaging device that will be used for point-of-surgery detection of muscle in TURBT specimen in real-time. We will use ultraviolet light-emitting diodes to selectively excite different native fluorescent molecules in the tissue sample. We will further increase the biochemical information content by complementing the autofluorescence data with multi-wavelength reflectance images. We hypothesize that the combined multi-spectral autofluorescence and reflectance images will provide a snapshot of the integral biomolecular information of the tissue and, when combined with deep learning, capture latent biochemical and morphological differences that are encoded in the multispectral images. Our hypothesis is based on the fact that the connective tissue lamina propria and epithelial tissue have different biochemical make-up than the muscularis propria. We will employ a deep learning framework on the acquired images to develop a training algorithm from >200 ex vivo TURBT specimens from > 50 patients. The measured tissue will be processed for histopathological investigation to create true labels for algorithm training. We will interpret the deep learning classification results by correlating the extracted class features from the trained neural network with input image parameters, and consequently attribute them with known biological differences of the tissue types. To test the algorithm, we will acquire independent image sets from 80 samples from 20 patients and assess the concordance between our results and pathologists’ reading of the Hematoxylin and Eosin (H&E) slides. We will also use a convolutional neural network trained using a generative adversarial-network model to transform wide-field autofluorescence images acquired from unlabeled tissue sections into H&E images of the same samples. The virtual H&E images will be evaluated by pathologists to recognize major histopathological features in images generated with our virtual staining technique and compared with the histologically stained images of the same samples. Project Narrative For adequate diagnosis and staging, transurethral resection of bladder tumor (TURBT) specimens must extend into the bladder muscle wall. The goal of this project is to develop an imaging device that will be used to detect presence of muscle in TURBT specimens in real-time during surgery. We reason that combined multi-spectral autofluorescence and reflectance images provides a snapshot of the integral biomolecular information of the tissue and, when combined with deep learning, will capture latent biochemical and morphological differences of tissues that can be leveraged to provide the surgeon with an indication of the completeness of TURBT through a user-friendly graphic interface.",Artificial Intelligence Enabled Multi-Spectral Autofluorescence Imaging for Real-time Determination of Muscle in Bladder Tumor During Resection,10325131,R43CA265673,"['Algorithms', 'Artificial Intelligence', 'Biochemical', 'Biological', 'Bladder', 'Bladder Neoplasm', 'Cells', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Collagen', 'Complement', 'Connective Tissue', 'Cystoscopes', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Dinucleoside Phosphates', 'Elastin', 'Endoscopy', 'Epithelial', 'Excision', 'Extracellular Matrix', 'Flavin-Adenine Dinucleotide', 'Fluorescence', 'Goals', 'Gold', 'Guidelines', 'Hematoxylin and Eosin Staining Method', 'Histopathology', 'Hospitals', 'Image', 'Imaging Device', 'Institutional Review Boards', 'Investigation', 'Label', 'Lamina Propria', 'Malignant neoplasm of urinary bladder', 'Maps', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Morphology', 'Muscle', 'Network-based', 'Neurons', 'Niacinamide', 'Operative Surgical Procedures', 'Optics', 'Outpatients', 'Pathologist', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Postoperative Period', 'Predictive Value', 'Procedures', 'Process', 'Prognosis', 'Reading', 'Research Personnel', 'Resected', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Slide', 'Specimen', 'Staging', 'Stains', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Transurethral Resection', 'Ultraviolet Rays', 'Validation', 'Work', 'absorption', 'algorithm training', 'base', 'cancer recurrence', 'care costs', 'chromophore', 'classification algorithm', 'clinical translation', 'commercialization', 'convolutional neural network', 'cost effective', 'deep learning', 'deep neural network', 'detrusor muscle', 'fluorophore', 'histological stains', 'histopathological examination', 'imaging system', 'improved', 'in vivo', 'malignant breast neoplasm', 'minimally invasive', 'mortality', 'network models', 'neural network', 'optical imaging', 'performance tests', 'point of care', 'prognostic significance', 'real-time images', 'research clinical testing', 'response', 'standard of care', 'tool', 'user-friendly', 'validation studies', 'virtual']",NCI,CYTOVERIS INC,R43,2021,399948
