text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Intention-aware Recommender System for Improving Trauma Resuscitation Outcomes PROJECT SUMMARY Critically injured patients have a four-fold higher risk of death from medical errors than other hospitalized patients, with nearly half of preventable deaths related to errors during the initial resuscitation phase. Although protocols, simulation, and leadership training improve team performance in this setting, as many as 12 protocol deviations per resuscitation have been observed, even with experienced teams. Given adverse outcomes that can result from performance gaps, there is a critical need to establish novel approaches for applying real-time decision support in critical-care settings. The long-term goal is to implement decision support for trauma resuscitation and other fast-paced, high-risk critical care settings that improves performance, reduces errors, and prevents adverse outcomes. The overall objective for this renewal is to vertically advance what was achieved during the first funding period by designing, implementing and testing an intention-aware recommender system that (1) recognizes and tracks current goals using sensor data, the output from patient monitors, and data captured from digital devices, (2) derives recommendations that support adherence to goal- based protocols, and (3) displays these recommendations in real time on wall displays. The central hypothesis is that decision support aligning with intentions (“intended” or “current” goals) will enhance protocol compliance, leading to improved outcomes related to trauma resuscitation. The rationale for this renewal is that recommendations supporting protocol compliance that are aligned with team intentions are more likely to be adopted by being less distracting and associated with lower cognitive load. Guided by preliminary data, the central hypothesis will be tested by pursuing two specific aims: 1) design and implement an automated real- time approach for predicting and monitoring the assessment and treatment goals of trauma resuscitation; and 2) generate and display a recommended plan of activities that supports current goal pursuit during trauma resuscitation. For the first Aim, machine learning approaches will be applied for recognizing goals using data obtained from sensors and other digital data sources. Under the second Aim, a machine learning strategy will be implemented and tested that generates recommendations responsive to team intentions. The proposed research is innovative because it focuses on development of real-time methods that integrate goals as an input for making recommendations that meet the most current and relevant information needs. The proposed research is significant because it is expected to improve the care of severely injured and other critically ill patients by promoting timely and appropriate achievement of critical assessment and treatment goals in settings that remain at high-risk for medical errors. The results of this research continuum are expected to have an important positive impact on the outcome by addressing the mismatch between complex decision-making and human vulnerability to error that remain in critical care settings. PROJECT NARRATIVE The proposed project is relevant to public health because it focuses on the design and implementation of a novel real-time decision support system that will reduce errors associated with adverse patient outcomes by providing recommendations that support the current information needs of multidisciplinary trauma teams. The proposed project is relevant to the part of the NLM's mission related to development of biomedical communications systems, methods, and technologies, and information dissemination and utilization among health professionals.",Intention-aware Recommender System for Improving Trauma Resuscitation Outcomes,10163257,R01LM011834,"['Achievement', 'Address', 'Adherence', 'Adopted', 'Adoption', 'Area', 'Awareness', 'Caring', 'Cessation of life', 'Communication', 'Complex', 'Computer Vision Systems', 'Critical Care', 'Critical Illness', 'Data', 'Data Sources', 'Decision Making', 'Decision Support Systems', 'Development', 'Devices', 'Failure', 'Funding', 'Goals', 'Health Professional', 'Hemorrhage', 'Human', 'Human Activities', 'Information Dissemination', 'Injury', 'Intention', 'Leadership', 'Literature', 'Machine Learning', 'Manuals', 'Medical', 'Medical Errors', 'Methods', 'Mission', 'Monitor', 'Morbidity - disease rate', 'Multiple Trauma', 'Outcome', 'Output', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Process', 'Progress Reports', 'Protocol Compliance', 'Protocols documentation', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Resuscitation', 'Risk', 'Safety', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Trauma', 'Variant', 'Work', 'adverse outcome', 'base', 'cognitive load', 'computerized', 'design', 'digital', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'instrument', 'learning strategy', 'member', 'mortality risk', 'multidisciplinary', 'novel', 'novel strategies', 'preference', 'prevent', 'preventable death', 'radio frequency', 'sensor', 'severe injury', 'simulation', 'success']",NLM,CHILDREN'S RESEARCH INSTITUTE,R01,2021,654500
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence PROJECT SUMMARY Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease. The largest proportion of medical errors involve medications. Medication errors result in 3 million outpatient medical appointments, 1 million emergency department visits, and 125,000 hospital admissions each year. Astoundingly, over 4 billion prescriptions are dispensed every year in the United States alone. Although dispensing error rates are generally low at 0.06%, the sheer volume of dispensed medications translates to 2.4 million incorrectly dispensed medications each year. In the pharmacy, dispensing errors arise when pharmacists do not detect that the medication filled inside a prescription vial is different from the medication ordered on the prescription's label. These dispensing errors can result in patient harm, added strain on the healthcare system, and costly legal action against the pharmacy. Machine intelligence (MI) can be employed to assist in the verification process to help avoid dangerous and costly pharmacy dispensing errors.4–6 However for the human-MI partnership to function optimally, the MI should be capable of conveying accurate information that encourages providers to make sound cognitive decisions such that optimal trust is maintained, and temporal and cognitive demand is reduced. Imperative to this goal is to design MI from which interpretable information can be extracted, convey this information in an effective manner and calibrate user's trust in MI as either over-trust or under-trust can lead to near miss and incident errors. This proposed project will further our knowledge for designing interpretable MI outputs and inform the development of MI models that encourage pharmacy staff to make sound clinical decisions that lead to better patient outcomes while improving work-life at lower costs of care. This study develops interpretable MI methods in the context of medication images classification and designs effective MI advice and reasoning that lead to lower cognitive demand and increased trust in the MI. Our hypothesis is that interpretable MI will lead to improved work performance and more calibrated trust compared to uninterpretable M. The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance. PROJECT NARRATIVE Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease and the largest proportion of medical errors involve medications. These dispensing errors occur approximately 2,400,000 times every year in the United States alone and can result in patient safety issues and add unnecessarily to the already strained healthcare system.The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance.",Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence,10183536,R01LM013624,"['Artificial Intelligence', 'Cardiovascular Diseases', 'Cause of Death', 'Classification', 'Clinical', 'Cognitive', 'Dangerousness', 'Data', 'Decision Making', 'Detection', 'Development', 'Emergency department visit', 'Evaluation', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Human', 'Image', 'Knowledge', 'Label', 'Lead', 'Legal', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical Errors', 'Medication Errors', 'Methods', 'Modeling', 'Outpatients', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance at work', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Process', 'Provider', 'Research', 'Stream', 'System', 'Testing', 'Time', 'Translating', 'Trust', 'Uncertainty', 'United States', 'Vial device', 'Work', 'base', 'care costs', 'cost', 'deep learning', 'design', 'experience', 'experimental study', 'improved', 'insight', 'medical appointment', 'patient safety', 'prevent', 'sound', 'support tools', 'tool', 'visual tracking']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,288814
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,10066353,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2021,373738
"Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events The frequency of diagnostic errors in emergency departments (ED) is largely unknown but likely to be significant. There is a compelling need to create measurement methods that provide diagnostic safety data to clinicians and leaders who in turn can act upon these data to prevent diagnostic harm. Electronic trigger (e- trigger) tools mine vast amounts of clinical and administrative data to identify signals for likely adverse events and have demonstrated capability to identify diagnostic errors. Such tools are more efficient and effective than other methods and can reduce the number of records requiring human review to those at highest risk of harm.  In prior work, we used rules-based e-trigger algorithms to identify patterns of care suggestive of missed or delayed diagnoses in primary care and inpatient settings. For instance, a clinic visit followed several days later by an unplanned hospitalization could be indicative of potential problems with the diagnostic process at the clinic visit. We also proposed a knowledge discovery framework, the Safer Dx Trigger Tools Framework, to enable health care organizations (HCOs) to develop and implement e-trigger tools to measure diagnostic errors using comprehensive electronic health record (EHR) data. Review and analysis of these cases can uncover safety concerns and provide information on diagnostic process breakdowns and related contributory factors, which in turn could generate learning and feedback for improvement purposes.  Sophisticated techniques from machine learning (ML) and data science could help inform ‘second generation’ e-trigger algorithms that better identify diagnostic errors and/or harm than rules-based e-triggers that require substantial manual effort and chart reviews. In contrast to rules-based systems, ML techniques could help learn from examples and accurately retrieve charts with diagnostic error without the need for “hand crafting” of an e-trigger. We will apply e-triggers to comprehensive EHRs that contain longitudinal patient care data (progress notes, tests, referrals) that provide an extensive picture of patients’ diagnostic journeys. Using national VA data, including data from 9 million veterans, and data from Geisinger health system, a pioneer HCO that serves approximately 3 million patients, we propose the following aims: Aim 1 – To develop, refine, test, and apply Safer Dx e-triggers to enable detection, measurement, and learning from diagnostic errors in diverse emergency department (ED) settings. We will calculate the frequency of diagnostic errors in the ED based on these e-triggers and describe the burden of preventable diagnostic harm. Aim 2 - To explore machine learning techniques that yield robust, accurate models to predict diagnostic errors using EHR-enriched data derived from expert-labeled patient records containing diagnostic errors (from Aim 1).  To our knowledge this is the first ML application in diagnostic error measurement, which could help scale up expert-driven e-trigger development and refinement. Newly developed e-triggers can be pilot tested and implemented at other HCOs, enabling them to create actionable safety-related insights from digital data. Narrative The process of making a diagnosis in emergency departments can be vulnerable to error. To study the risks involved, we will develop strategies to better identify electronic medical records of patients who may have had a diagnostic error in their care. We will test the use of human-derived rule-based algorithms and data-driven machine learning methods that can more accurately and efficiently identify these medical records than other currently available methods used in measurement of patient safety.",Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events,10254269,R01HS027363,[' '],AHRQ,BAYLOR COLLEGE OF MEDICINE,R01,2021,500000
"Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study PROJECT SUMMARY/ABSTRACT  While much research has been conducted on patient safety since the Institute of Medicine published “To Err is Human” in 2000, there is a comparative dearth of research on diagnostic errors in the hospital setting. The broad, long-term objectives of the proposed research is to better understand the incidence, causes, and risk factors for diagnostic errors in the inpatient setting. This work will provide foundational research for the development of interventions to reduce these errors, including predictive tools, targets for intervention, and a methodology for outcome assessment in future trials of interventions. To achieve this overall goal, we will carry out the following specific aims: 1) To determine the incidence of diagnostic errors among patients who die in hospital or are transferred to the ICU two days or more after admission to a general medicine service through a structured, standardized adjudication process of patient records, 2) To combine adjudication data with data from Vizient to determine which specific factors contribute to risks for diagnostic errors, and to use risk estimates to calculate incidence and impact of factors contributing to those errors, and 3)To create machine- learning models that can be used to retrospectively identify patients in whom a diagnostic error was likely to have taken place. The research will involve a retrospective evaluation of 2000 patients admitted to general medicine units at 20 US hospitals participating in a national research collaborative and which also contribute data to a benchmarking and purchasing organization (Vizient). Using the Safer-Diagnosis (Safer-Dx) and Diagnostic Error Evaluation and Research (DEER) taxonomy tools, both adapted for the inpatient setting, adjudicators will review electronic medical record data and determine the presence or absence of diagnostic errors using a rigorous training and continuous review process to ensure reliability across sites, adjudicators, and time. Standard modelling techniques will be used to understand the population-attributable risk of each of the DEER process failure points to diagnostic error as well as the contributions of several patient, provider, and system-level risk factors. Lastly, advanced machine-learning methods will be used to create models that can identify patients in whom diagnostic error occurred, with superior performance to standard approaches such as logistic regression. Together, these approaches will provide a broad and representative picture of the incidence of diagnostic errors among hospitalized patients who have suffered harm, develop models of patient and system-based factors that make a diagnostic error more or less likely, and build advanced, efficient, and scalable tools needed to support future surveillance and improvement programs for a variety of institutions. This research will establish a foundation from which healthcare systems can assess and achieve excellence in diagnosis in the inpatient setting. PROJECT NARRATIVE  This study seeks to accurately define the incidence of diagnostic errors among patients suffering serious inpatient events in a large network of US hospitals. Without a reliable method for determining the presence of diagnostic errors across many organizations, it is not otherwise possible to understand the incidence, impact, predictors, and underlying causes of these errors, to create and optimize future solutions to reduce diagnostic errors, to directly test the effects of these solutions, or to teach physicians how to avoid diagnostic pitfalls in the future. Our study addresses these issues while being responsive to the RFA’s goals of developing robust estimates of incidence and risk and using approaches that leverage electronic data, and our approach represents a novel application of rigorous outcome adjudication and advanced modeling techniques to the problem of inpatient diagnostic errors.",Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study,10254271,R01HS027369,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,496877
"An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases. Project Summary / Abstract Diagnostic errors are increasingly recognized as a cause of pain, suffering and increased healthcare costs. Diagnostic delays are an important class of diagnostic errors. While many diagnostic errors occur in hospital settings, emergency departments visits may be especially important to consider because they treat critically ill patients and because most decisions to admit patients to the hospital are made in emergency departments. Thus, to enable a more complete understanding of diagnostic delays requires consideration of healthcare visits across a range of healthcare settings including clinic visits, emergency department visits and hospitalizations. Delays in diagnosing infectious diseases are important to consider. For contagious infectious diseases, diagnostic delays increase the risk of additional exposures, potentially generating more cases. Second, many infectious diseases can be effectively treated, but even short delays in treatment lead to worse clinical outcomes. However, with the exception of a few infectious diseases (e.g., tuberculosis), diagnostic delays for infectious diseases are understudied. Thus, there is a critical need to investigate the incidence, risk factors and clinical impact for diagnostic delays for infectious diseases. The overarching goal of our research is to investigate diagnostic delays associated with infectious diseases using existing data along with methods from the fields of computer science and statistics. While our research relies upon “big data”, we will also use clinical experts to review and contribute to all of our results. Our subject matter experts incorporate expertise in infectious diseases, emergency medicine, acute care, medical education, diagnostic reasoning, healthcare epidemiology, public health, industry, and professional infectious disease societies. Specifically, we will 1) determine the incidence of diagnostic delays for a wide range of infectious diseases; 2) identify the risk factors associated with diagnostic delays for infectious diseases that are frequently delayed or have serious outcomes; and 3) estimate the impact of diagnostic delays in terms of healthcare costs and mortality. With our data, methods and clinical experts, we will be able to translate our results into future interventions designed to decrease diagnostic delays and improve healthcare outcomes. In addition, while our proposal focuses on infectious diseases, the methods and approaches that we will develop can be adopted to investigate non-infectious diseases and conditions. Project Narrative Diagnostic delays for infectious diseases contribute to worse clinical outcomes, increased healthcare costs and, for some infectious diseases, outbreaks of great public health importance. We will use existing large data sets along with machine-learning techniques and expert clinical guidance to detect patterns of healthcare visits representing diagnostic delays. Our goal is to characterize the incidence, risk factors and clinical impact of diagnostic delays for a wide range of infectious diseases to inform future interventions.","An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases.",10251921,R01HS027375,[' '],AHRQ,UNIVERSITY OF IOWA,R01,2021,490881
"A Comprehensive Strategy to Detect Glaucoma Worsening Earlier and With Fewer Tests ABSTRACT  This is an application for a K23 Mentored Patient-Oriented Research Career Development Award. The goal of this proposal is to provide the candidate with the advanced skills needed to establish an independent research program in the area of glaucoma diagnostic testing with special expertise in test error correction and predictive modeling of future glaucoma outcomes. To facilitate this long-term goal, in the current proposal, the candidate’s main research goal is to reduce the time and number of tests necessary to detect glaucoma worsening by (1) correcting for errors in previously obtained visual field (VF) and peripapillary optical coherence tomography (OCT) tests by using multilevel models with Bayesian analysis (MLB) and generative adversarial networks (GAN) (2) stratifying eyes at high and low risk for rapid glaucoma worsening at the baseline clinical visit using deep convolutional neural networks (DCNN). These aims are based on high quality preliminary data which show that: (1) the effect of VF reliability metrics and OCT signal strength on test error can be quantified and thus corrected for and (2) machine learning methods can predict risk of future VF progression with fair accuracy with baseline visit VF data alone and therefore adding structural (OCT) and clinical information from the baseline visit is likely to improve model accuracy. The main hypotheses of the proposed research aims are (1) correcting for test errors with MLB and GAN will reduce the time needed to detect worsening by 10 and 20% respectively (2) combining baseline visit structural (OCT), functional (VF) and clinical data as inputs into DCNNs will allow us to achieve an area under the receiver operating curve of at least 0.8 at predicting the risk of future rapid glaucoma worsening. The candidate proposes a comprehensive training plan, combining formal coursework, meetings, seminars and workshops overseen by his diverse group of mentors. Specific training goals include: (1) Receiving training in multi-level regression modeling and Bayesian analysis techniques. (2) Becoming adept at data science with a special emphasis on learning Python for data extraction, manipulation and analysis. (3) Furthering knowledge of machine learning techniques with a specific emphasis on deep learning including DCNNs and GANs. (4) Continuing training in the ethical and responsible conduct of research. The training plan will be executed in coordination with the set of research activities mentioned above. Results from this research proposal will be used to develop a subsequent R01 research proposal that will facilitate the candidate’s transition to an independent researcher. PROJECT NARRATIVE The main aim of this study is to reduce the time and number of tests needed to accurately detect worsening of glaucoma by 1) correcting visual field and optical coherence tomography tests for errors and 2) accurately predicting future disease worsening based on baseline visit clinical, functional and structural data. This research will impact public health by identifying high risk patients earlier so that they can be appropriately managed to prevent vision loss and also by reducing unnecessary testing which places a significant burden on the healthcare system and patients.",A Comprehensive Strategy to Detect Glaucoma Worsening Earlier and With Fewer Tests,10105960,K23EY032204,"['Accounting', 'Affect', 'Area', 'Bayesian Analysis', 'Blindness', 'Calendar', 'Clinical', 'Clinical Data', 'Coupled', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Educational workshop', 'Effectiveness', 'Ethics', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Healthcare', 'Healthcare Systems', 'Image', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Physiologic Intraocular Pressure', 'Population', 'Public Health', 'Pythons', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resources', 'Risk', 'Signal Transduction', 'Stream', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Visit', 'Visual Acuity', 'Visual Fields', 'Work', 'base', 'clinical decision-making', 'compare effectiveness', 'convolutional neural network', 'deep learning', 'demographics', 'field study', 'high risk', 'improved', 'longitudinal database', 'machine learning method', 'meetings', 'model design', 'multilevel analysis', 'neural network architecture', 'predictive modeling', 'preservation', 'prevent', 'programs', 'responsible research conduct', 'retinal nerve fiber layer', 'skills', 'tool', 'wasting']",NEI,JOHNS HOPKINS UNIVERSITY,K23,2021,191187
"Decoding the dynamic representation of reward predictions across mesocorticostriatal circuits during learning Reward learning is a fundamental cognitive function, and the brain has a dedicated neuromodulatory system – based on dopamine – that supports this process. Changes to the dopamine system that are triggered by exposure to drugs of abuse are thought to underlie the behavioral changes observed in addiction. Here we propose to use a treasure trove of previously recorded neural data from throughout the mesocorticostriatal circuitry that supports reward learning, to elucidate the computational role of each component of the circuit, their interactions, and how these components are affected by cocaine. Our brains constantly generate predictions about what rewards might be available, and compare these predictions to actual outcomes. The neuromodulator dopamine is thought to report these ‘prediction error’ signals, the result of the ongoing comparison between expected and obtained rewards, that are key to updating predictions so they are more accurate in the future. Predicting the timing of rewards, and not just their identity or value, is an important component of this process, but it remains a mystery how the brain forms and uses predictions about time in reward learning. Based on a novel theoretical model we recently developed, we will test the computational role of three key brain areas that comprise the brain circuit critical for reward learning, using a state-of-the- art methods from machine learning to jointly decode the learning processes that drive neural activity from multiple brain areas along with behavior as rats perform a reward learning task. In Aim 1, we hypothesize that neural activity in the orbitofrontal cortex is uniquely important for representing high level ‘task states’ and will test for patterns in OFC neural activity that follow the hidden structure of the task. In Aim 2, we will decode the representation of reward predictions about the amount and timing of rewards, and test whether they are separable in VS neural activity. In Aim 3, we will test how activity in VS and OFC controls dopamine activity, and in particular how each input component enables prediction errors to be temporally precise. In Aim 4, we will test how exposure to cocaine changes neural activity that represents reward predictions in the VS, and the impact of this disruption on dopamine prediction errors in the VTA. This innovative multi-level study will leverage numerous existing neural and behavioral data from rats performing a well-validated reward-learning task, to reveal the computational, neural and behavioral mechanisms of the reward prediction and learning circuitry in the brain, and the source of their disruption in addiction. Dysfunction of mesolimbic and corticostriatal circuitry is implicated in addiction, and is known to produce critical deficits in timing (for example, impulsivity) and reward learning. Here we will use a treasure trove of 8 existing datasets to test novel predictions about the neural basis of timing and reward learning, employing state-of-the-art tools from machine learning to ‘decode’ reward predictions jointly from multiple brain areas and from behavior, in intact neural circuits as well as after damage from lesions or exposure to cocaine. Our findings will lay bare the neural computations that support reward prediction and will allow us to link aberrant reward learning in addiction back to its basis in the circuitry of the brain.",Decoding the dynamic representation of reward predictions across mesocorticostriatal circuits during learning,10153745,R01DA050647,"['Adaptive Behaviors', 'Affect', 'Animals', 'Area', 'Back', 'Basal Ganglia', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Behavioral Model', 'Brain', 'Cocaine', 'Collaborations', 'Computer Models', 'Data', 'Data Set', 'Disease', 'Dopamine', 'Event', 'Exposure to', 'Functional disorder', 'Future', 'Impairment', 'Impulsivity', 'International', 'Joints', 'Learning', 'Lesion', 'Link', 'Machine Learning', 'Neuromodulator', 'Neurons', 'Odors', 'Outcome', 'Pattern', 'Poverty', 'Process', 'Rattus', 'Reporting', 'Research', 'Rewards', 'Role', 'Shapes', 'Signal Transduction', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Update', 'Ventral Striatum', 'Ventral Tegmental Area', 'Work', 'addiction', 'base', 'brain circuitry', 'cocaine exposure', 'cognitive function', 'computer framework', 'cost', 'dopamine system', 'drug of abuse', 'experience', 'frontal lobe', 'innovation', 'machine learning method', 'neural circuit', 'neural correlate', 'neuromechanism', 'neurophysiology', 'neuroregulation', 'novel', 'programs', 'relating to nervous system', 'reward circuitry', 'synergism', 'theories', 'tool']",NIDA,PRINCETON UNIVERSITY,R01,2021,283500
"Receptors, microcircuits and hierarchical connectivity in predictive coding and sensory awareness SUMMARY The standard view of how we make sense of the world around us focuses on reconstructing our environment from the information received by our sensory organs. In this view, low-level brain areas (e.g., primary sensory cortex) represent basic features of objects, which are elaborated on in successive processing stages, until representations become increasingly complex in high-level areas (e.g., frontal cortex). An alternative view is predictive coding (PC), in which we model our environment to generate sensory predictions. In PC, high-level brain areas generate predictions of sensory activity and transmit them to low-level areas. A prediction that does not match the sensory information gives rise to a prediction error. This error signal is sent from low- to high-level brain areas to update the model of our environment, thereby improving future predictions to minimize errors. Modeling studies show PC is a fast and efficient way to process sensory information, and PC provides innovative hypotheses for understanding sleep and anesthesia, particularly when disconnected consciousness occurs (consciousness without awareness of the environment), like dreaming. PC also holds great promise for conceptualizing and treating brain disorders, including schizophrenia and depression. But key central features of PC have not been empirically tested and little is known about the underlying neural mechanisms. The goal of the proposed project is to characterize the neural dynamics, circuits and receptors enabling PC. There are two principle hypotheses. First, predictions depend on N-methyl-D-aspartate receptors (NMDAR) because NMDAR influence the activity of high-level brain areas where predictions are generated, and NMDAR are enriched on neurons in lower-level areas receiving predictions. Second, in disconnected consciousness, a breakdown of information transmission from low-level to high-level brain areas, as well as a breakdown of computations within each area, explains why models of our environment are not updated by external sensory information. These breakdowns prevent the comparison of predictions and sensory information, as well as the transmission of prediction errors to high-level brain areas. To test these hypotheses, we use a cross-species experimental design connecting cellular, circuit and systems levels to behavior. We will perform electroencephalography, machine learning and computational modeling to define the neural basis of PC in humans performing prediction tasks. Then we will manipulate PC using different anesthetic agents with diverse mechanisms, establishing causal relationships between receptors, large-scale brain networks and PC. In parallel, we will simultaneously record activity from sensory and high-level brain areas of non-human primates (NHPs) using the same PC tasks and pharmacological interventions to measure cellular and circuit level contributions to PC. Investigating PC will illuminate the fundamental mechanisms of perception, providing critical insights to guide therapeutic development for multiple health conditions. NARRATIVE This research advances our understanding of how the brain generates predictions which shape how we perceive the world, otherwise known as predictive coding. Predictive coding is relevant to public health because it holds great promise in conceptualizing and treating brain disorders, including depression, schizophrenia, delirium and dementia, as well as understanding sleep and anesthesia. Progress in understanding the basic mechanisms of predictive coding, as well as predictive coding deficits, is a necessary step in developing more effective treatment strategies for multiple health conditions.","Receptors, microcircuits and hierarchical connectivity in predictive coding and sensory awareness",10216373,R01NS117901,"['Adrenergic Receptor', 'Agonist', 'Anesthesia procedures', 'Anesthetics', 'Area', 'Auditory', 'Auditory area', 'Awareness', 'Behavior', 'Brain', 'Brain Diseases', 'Code', 'Complex', 'Computer Models', 'Conscious', 'Cues', 'Data', 'Delirium', 'Dementia', 'Dexmedetomidine', 'Disinhibition', 'Dose', 'Dreams', 'Electroencephalography', 'Environment', 'Experimental Designs', 'Feedback', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Individual', 'Interneurons', 'Intervention', 'Ketamine', 'Link', 'Macaca', 'Machine Learning', 'Measures', 'Mediating', 'Mental Depression', 'Modality', 'Modeling', 'Molecular Target', 'Monitor', 'N-Methyl-D-Aspartate Receptors', 'Neurons', 'Organ', 'Parietal Lobe', 'Pathway interactions', 'Perception', 'Pharmacology', 'Process', 'Propofol', 'Public Health', 'Pulvinar structure', 'Reaction Time', 'Reporting', 'Research', 'Role', 'Schizophrenia', 'Sedation procedure', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Sleep', 'Study models', 'System', 'Temporal Lobe', 'Testing', 'Thalamic Nuclei', 'Unconscious State', 'Update', 'base', 'effective therapy', 'experience', 'experimental study', 'frontal lobe', 'human data', 'improved', 'innovation', 'innovative technologies', 'insight', 'multi-electrode arrays', 'neural correlate', 'neuromechanism', 'neurophysiology', 'nonhuman primate', 'paired stimuli', 'postsynaptic', 'prevent', 'receptor', 'relating to nervous system', 'response', 'sedative', 'sensory cortex', 'sensory stimulus', 'therapeutic development', 'transmission process', 'treatment strategy', 'visual stimulus']",NINDS,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,458246
"Eliminating Critical Systematic Errors In Structural Biology With Next-Generation Simulation PROJECT SUMMARY/ABSTRACT Data collection in macromolecular crystallography is subject to significant systematic errors that prevent successful data collection on many systems and, ultimately, limit the accuracy of resulting structures. Creating simulation technologies that can account for these errors will have significant impact on three fronts: 1) solving new structures by better accounting for radiation damage, which is responsible for 80% of failed anomalous phasing attempts, 2) improving multi-crystal averaging by simulating non-isomorphism, which will open the gateway to arbitrary gains in signal-to-noise, 3) discriminating hotly contested alternative interpretations such as the presence or absence of a bound ligand, by creating simulations with more realistic solvent models. To move towards “damage-free data” from a synchrotron, we will start by calibrating radiation damage curves on model and DBP samples. Using these curves we will incorporate realistic 3D models of radiation damage to non-cuboid crystals (RADDOSE 3D) into our diffraction image simulator (MLFSOM) to yield a 3D Dose Distribution and Illumination map along the crystal. This will result in a new generation of wavelength- dependent absorption factors for the crystal to complement existing absorption corrections. At the beamline, we will measure a 3D map of the crystal using cone beam online x-ray absorption radiography and a 2D map of the beam profile. These advances will allow us to generate zero-dose extrapolation values, in an open format, that account for experimental crystal and beam geometry. To improve multi-crystal averaging, we will begin by characterizing how non-isomorphism varies as a function of humidity, radiation damage, and functional state. By updating the classic “Crick and Magdoff” simulations of non-isomorphism with increasing complexity, we will develop a singular value decomposition approach to parameterize non-isomorphism. Using the corrections derived from this analysis, we will correct the non-isomorphism present in multi-crystal experiments, enabling the determination of novel structures, including those collected using serial crystallography at next-generation light sources. To enable enhanced simulation for robust interpretation of experimental data, we will leverage new solvent models in macromolecular crystallography and small angle X- ray scattering. Our work will create standard protocols for comparing solvent density to alternative interpretations and to quantitatively assess how likely each simulated situation is compared to the real macromolecular crystallography or SAXS data. In addition to distinguishing between different interpretations of the experimental data, improving solvent models will enhance understanding of how macromolecules influence and interact with other molecules near their surface. Collectively, we expect the benefits of eliminating these critical systematic errors be transformative to both methods development and functional studies. PROJECT NARRATIVE Data collection in macromolecular crystallography is subject to significant systematic errors that prevent successful soilution on many systems and, ultimately, limit the accuracy of resulting structures. Creating simulation technologies that can account for these errors will have significant impact on three fronts: 1) solving new structures by better accounting for radiation damage, which is responsible for 80% of failed anomalous phasing attempts, 2) improving multi-crystal averaging by simulating non-isomorphism, which will open the gateway to arbitrary gains in signal-to-noise, 3) discriminating hotly contested alternative interpretations such as the presence or absence of a bound ligand, by creating simulations with more realistic solvent models.",Eliminating Critical Systematic Errors In Structural Biology With Next-Generation Simulation,10162611,R01GM124149,"['3-Dimensional', 'Accounting', 'Active Sites', 'Area', 'Complement', 'Computer software', 'Cone', 'Crystallization', 'Crystallography', 'Data', 'Data Collection', 'Data Set', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Error Sources', 'Evolution', 'Generations', 'Geometry', 'Humidity', 'Image', 'In Situ', 'Knowledge', 'Ligands', 'Light', 'Lighting', 'Maps', 'Measures', 'Metals', 'Methods', 'Minor', 'Modeling', 'Molecular Conformation', 'Muramidase', 'Noise', 'Phase', 'Positioning Attribute', 'Protein Region', 'Protocols documentation', 'Radiation induced damage', 'Reaction', 'Resolution', 'Roentgen Rays', 'Sampling', 'Side', 'Signal Transduction', 'Solvents', 'Source', 'Spottings', 'Structure', 'Surface', 'Synchrotrons', 'Syncope', 'System', 'Technology', 'Update', 'Weight', 'Work', 'absorption', 'beamline', 'computerized tools', 'conformer', 'curve fitting', 'density', 'electron density', 'experimental study', 'improved', 'interest', 'macromolecule', 'method development', 'next generation', 'non-Native', 'novel', 'novel strategies', 'prevent', 'simulation', 'structural biology', 'success', 'three-dimensional modeling', 'trend', 'vector']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,309526
"Hidden Markov methodology for machine learning applied to identifying physiological states of shock in the intensive care unit via biomedical and unstructured text data PROJECT SUMMARY There is a void of well-developed machine learning tools for the clinical hospital setting for patient monitoring and diagnosis. This absence is particularly relevant for an intensive care unit (ICU), where structured and unstructured data are continuously recorded on numerous aspects of the health status of each patient. The methods that have been developed are predominantly exclusive to the research literature, and they are focused on models/algorithms trained on a single data type such as continuous response vitals data or natural language data. Likewise, the metrics to evaluate these machine learning tools are often focused on a single metric such as out-of-sample prediction error. For machine learning tools to really become effective they need to be built from models that are able to incorporate varying data types, simultaneously, for making inferences on the health state of a patient, and they need to be evaluated on a variety of metrics. Some of these metrics must be precise (e.g., out-of-sample prediction error and false negative/positive rate), but other qualitative metrics must also be considered such as clinical utility/feasibility, scalability, and the practicality of the user interface to a clinician. By analogy to hypothesis testing problems, there is an important difference between statistical signiﬁcance and practical signiﬁcance. The proposed research is aimed at developing statistical methodology to address these key aspects, and to engineer machine learning tools to be applied to hospital patient monitoring and diagnosis. In particular, the focus is on rapid identiﬁcation of critically ill patients at risk for bleeding and physiological de- terioration such as shock. For the purpose of this research, shock is divided into four categories: hypovolemic shock, distributive shock, neurogenic shock, and cardiogenic shock. Historical ICU patient encounter data is gathered with numerous examples of patients exhibiting each of these health states, as well as a baseline en- counters exhibiting no shock. However, the timeline and detection for clinician diagnosis of shock is not precise and is not without error. Accordingly, training data labels are only ever partially available, and the developed machine learning methodology will account for the semi-supervised nature of the problem. To make inference on the shock-related health state of ICU patients the machine learning methodology will incorporate a variety of response data types. These emitted responses include continuously monitored vitals data, laboratory results, functional wave form data on blood pressure, unstructured text data on clinician and procedural notes, and typi- cal cross-sectional data on medical history and demographic information. The data integration challenges from building all of these responses into a single parsimonious model will be a strong contribution of the proposed research. Additionally, the proposed research plan spans from the methodological development of the research ideas to production-end software with a clinical user-interface. PROJECT NARRATIVE Bleeding is often difﬁcult to detect at onset, leading to signiﬁcant delays in diagnosis and management accom- panied by progressive physiologic compromise, shock, and even death. Delays in the recognition and treatment of deteriorating patients have consistently been associated with increased mortality. The development and im- plementation of a coherent and interpretable machine learning framework for data-driven monitoring of the early detection of bleeding and shock in critically ill hospital patients is the public health relevance of the proposed research.",Hidden Markov methodology for machine learning applied to identifying physiological states of shock in the intensive care unit via biomedical and unstructured text data,10098894,R56HL155373,"['Address', 'Admission activity', 'Allogenic', 'Blood Pressure', 'Cardiogenic Shock', 'Categories', 'Cessation of life', 'Clinical', 'Complex', 'Computer software', 'Critical Illness', 'Custom', 'Data', 'Detection', 'Deterioration', 'Development', 'Diagnosis', 'Early Diagnosis', 'Engineering', 'Event', 'Exhibits', 'Functional disorder', 'Health', 'Health Status', 'Hematologic Neoplasms', 'Hemorrhage', 'Hospitals', 'Hybrids', 'Hypotension', 'Hypovolemic Shock', 'Intensive Care Units', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Literature', 'Liver diseases', 'Machine Learning', 'Measurement', 'Medical History', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nature', 'Operative Surgical Procedures', 'Oxygen', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Prevalence', 'Process', 'Production', 'Research', 'Risk', 'Sampling', 'Sepsis', 'Shock', 'Structure', 'Supervision', 'Systemic blood pressure', 'Tachycardia', 'Testing', 'Text', 'Time', 'TimeLine', 'Tissues', 'Training', 'Transfusion', 'Trauma', 'United States National Institutes of Health', 'algorithm training', 'blood product', 'data framework', 'data integration', 'data streams', 'experience', 'hands-on learning', 'improved', 'individualized medicine', 'innovation', 'interest', 'machine learning method', 'mortality', 'natural language', 'neurogenic shock', 'preventable death', 'public health relevance', 'research and development', 'response', 'statistical learning', 'statistics', 'structured data', 'tool', 'unstructured data']",NHLBI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R56,2021,494527
"Developing a clinical decision support tool for the identification, diagnosis, and treatment of critical illness in hospitalized patients PROJECT SUMMARY Up to 5% of hospitalized adult patients on the medical-surgical wards develop clinical deterioration requiring intensive care. Medical errors are common before deterioration events, including delays and misjudgments in identification, diagnosis, and treatment, and these errors lead to increased morbidity and mortality. Therefore, it is critically important to improve the care of high-risk ward patients to decrease preventable in-hospital deaths.  The current paradigm for attempting to decrease mortality from deterioration has several limitations. First, most early warning scores designed to identify high-risk patients are based only on vital signs and have limited accuracy. Clinical notes are an underutilized, rich source of information comprising nearly 80% of electronic health record (EHR) data. Natural language processing (NLP) can extract important risk factors from clinical notes for machine learning models to improve accuracy over existing tools. Second, current early warning scores only tell clinicians that a patient is at high risk but provide no information regarding what clinical condition is causing a patient’s deterioration. This leads to diagnostic and treatment errors, which results in worse patient outcomes. Developing tools to enhance diagnostic accuracy for high-risk ward patients could lead to fewer medical errors, decreased costs, and improved outcomes. Third, the initial treatment decisions for deteriorating patients are made by clinicians with limited experience caring for critically ill patients, which can result in delays of potentially life-saving therapies. By utilizing a large, granular, multicenter dataset, algorithms to predict the treatments a patient should receive can be developed, resulting in early, targeted, potentially life-saving therapy.  The long-term goal is to develop and implement clinically useful decision support tools to decrease preventable death from deterioration. The overall objective of this project is to develop a clinical decision support tool for the identification, diagnosis, and treatment of patients at high risk of deterioration. This objective will be pursued in the following three specific aims: 1) Develop machine learning models to identify patients at high risk of deterioration using both structured data and unstructured clinical notes; 2) Develop models to predict the diagnosis that is causing the deterioration event and the potentially life-saving treatments that should be provided to high-risk patients; 3) Develop a clinical decision support tool with a graphical user interface incorporating the models from Aims 1 and 2 via user-centered design principles and then test its effectiveness, efficiency, and user satisfaction in a case-based simulation study. This research is innovative because it will utilize NLP, reinforcement learning, interpretable machine learning, and multi-task transfer learning approaches. The proposed research is significant because it will provide clinicians with powerful new tools that can be implemented in the EHR to identify, diagnose, and make treatment recommendations for high-risk patients. This will result in the delivery of early, personalized care to decrease preventable death from deterioration. PROJECT NARRATIVE The proposed research is relevant to public health because it focuses on developing a clinical decision support tool for the identification, diagnosis, and treatment of hospitalized patients at high risk of clinical deterioration. This work will result in novel algorithms that can be implemented to deliver early, personalized care to decrease preventable morbidity and mortality from deterioration. Therefore, the proposed research is relevant to the part of the NIH’s mission that pertains to enhancing health, lengthening life, and reducing illness and disability.","Developing a clinical decision support tool for the identification, diagnosis, and treatment of critical illness in hospitalized patients",10182492,R01HL157262,"['Admission activity', 'Adult', 'Adult Respiratory Distress Syndrome', 'Algorithms', 'Antibiotics', 'Caring', 'Cessation of life', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Decision Making', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Etiology', 'Event', 'Fatigue', 'Goals', 'Gold', 'Health', 'Health system', 'Hospital Mortality', 'Hospitals', 'Hour', 'Human', 'Intensive Care', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Manuals', 'Medical', 'Medical Errors', 'Mission', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Provider', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Recommendation', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Savings', 'Sepsis', 'Source', 'Structure', 'Supervision', 'Testing', 'Time', 'Trees', 'United States National Institutes of Health', 'Work', 'base', 'case-based', 'clinical Diagnosis', 'clinical decision support', 'clinical practice', 'clinical risk', 'common treatment', 'cost outcomes', 'design', 'diagnostic accuracy', 'disability', 'discrete time', 'experience', 'graphical user interface', 'high risk', 'improved', 'improved outcome', 'innovation', 'iterative design', 'learning strategy', 'machine learning method', 'mortality', 'multitask', 'novel', 'optimal treatments', 'personalized care', 'personalized intervention', 'predictive modeling', 'preventable death', 'recurrent neural network', 'satisfaction', 'simulation', 'structured data', 'support tools', 'tool', 'user centered design', 'ward']",NHLBI,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,574395
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"A MICROFLUIDIC AND MACHINE LEARNING-ENABLED SMARTLAB FOR AUTONOMOUS REMOTE EXECUTION AND ITERATION OF MULTISCALE LIVE CELL ASSAYS FOR DRUG DISCOVERY Preclinical drug discovery assay development depends on the presence of scientists to develop, initiate and monitor assays. Interruptions and errors in the execution of these activities incur extra time and expense to restart experiments and the waste of previously expended time and reagents. The innovative SmartLab framework envisioned by this project addresses the significant, costly risks of interruptions and errors in preclinical cell-based assays by enabling their remote, autonomous initiation, execution and iteration.  Advantages of the SmartLab framework include (1) reduction in risk of human error; (2) unimpeded continuation of experiments when in-person lab operations are interrupted and (3) maximized experimental efficiency through adaptive experimental feedback. Collectively these advantages will benefit human health by dramatically improving the robustness and efficiency of preclinical assay frameworks used for drug discovery. n/a",A MICROFLUIDIC AND MACHINE LEARNING-ENABLED SMARTLAB FOR AUTONOMOUS REMOTE EXECUTION AND ITERATION OF MULTISCALE LIVE CELL ASSAYS FOR DRUG DISCOVERY,10505107,5N95021C00014,"['Address', 'Artificial Intelligence', 'Biological Assay', 'Cells', 'Cellular Assay', 'Data Analyses', 'Data Storage and Retrieval', 'Development', 'Drug usage', 'Feedback', 'Goals', 'Health', 'Human', 'Infrastructure', 'Interruption', 'Machine Learning', 'Microfluidics', 'Monitor', 'Persons', 'Reagent', 'Risk', 'Scientist', 'Secure', 'Time', 'assay development', 'base', 'cloud based', 'cost', 'drug discovery', 'experimental study', 'human error', 'improved', 'innovation', 'instrumentation', 'operation', 'pre-clinical', 'prototype', 'remote control', 'wasting']",NIDA,"CAIRN BIOSCIENCES, INC.",N43,2021,331500
