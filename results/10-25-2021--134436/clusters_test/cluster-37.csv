text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"FLYBASE: A DROSOPHILA GENOMIC AND GENETIC DATABASE FLYBASE: SUMMARY For the past twenty-four years, FlyBase has provided a centralized resource for Drosophila genetic and genomic data to enable researchers to further their research. Drosophila is one of the premier model organisms and provides cost-effective help in elucidating the etiology of human genetic diseases. FlyBase has three main goals. 1. To continue curation of literature and reagents relevant to Drosophila research, so that researchers can continue to rely on FlyBase to find the latest innovations in the field. We will prioritize curation of data sets relevant to gene expression, cellular functions, signaling pathways, and human diseases, and display the information in an intuitive, integrated, readily searchable format. 2. To improve FlyBase's utility to the human genetics and population genetics communities, by curating and integrating relevant data sets, and developing tools that enable better access to this wealth of data. As a member of the Alliance for Genomic Research (AGR), FlyBase will work with other Model Organism Databases (MODs) to integrate data sets and develop tools to enable cross-species analyses. This effort will have a major impact on the fly community, accelerating the development of models of human diseases. 3. To facilitate more integrative analyses and approaches, FlyBase will continue to expand its utility as a platform for integrating and displaying large-scale studies, transcriptomics and proteomics data sets. In addition, FlyBase will improve access and display of tools available within the community, and incorporate the most useful data sets and tools for visualizing complex data sets to enable more researchers to take a more global approach to their genetic research. ! NARRATIVE-FlyBase_renewal FlyBase provides a crucial centralized resource for drosophila genetic and genomic data to enable researchers both in the drosophila community and broader biomedical sciences community to further their research. Drosophila is one of the premier model organisms and provides cost-effective help in elucidating the etiology of human genetic diseases. We will work closely with other Model Organism Databases (MODs) of the Alliance for Genomic Research (AGR) to integrate data sets and develop tools to enable cross-species analyses and expedite development of drosophila human disease models.  ",FLYBASE: A DROSOPHILA GENOMIC AND GENETIC DATABASE,10136664,U41HG000739,"['Adopted', 'Adult', 'Advisory Committees', 'Alleles', 'Animal Model', 'Antibodies', 'Archives', 'Cell physiology', 'Chemicals', 'Cloud Service', 'Communities', 'Community Developments', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease model', 'Documentation', 'Drosophila genus', 'Drosophilidae', 'Electronic Mail', 'Ensure', 'Etiology', 'Experimental Models', 'Feedback', 'FlyBase', 'Freezing', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Databases', 'Genetic Diseases', 'Genetic Research', 'Genome', 'Genomics', 'Geographic Locations', 'Goals', 'Human', 'Human Genetics', 'Image', 'Improve Access', 'Internet', 'Intuition', 'Investigation', 'Link', 'Literature', 'Maintenance', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Newsletter', 'Nucleotides', 'Ontology', 'Output', 'Pathway interactions', 'Pattern', 'Peer Review', 'Persons', 'Phenotype', 'Population', 'Population Genetics', 'Positioning Attribute', 'Process', 'Production', 'Proteomics', 'Publications', 'Publishing', 'Quality Control', 'Reagent', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Signal Pathway', 'Structure', 'Technology', 'Testing', 'Training', 'Transgenes', 'Transgenic Organisms', 'Translational Research', 'Triage', 'Twitter', 'Untranslated RNA', 'Update', 'Variant', 'Work', 'base', 'complex data', 'cost', 'cost effective', 'data access', 'data curation', 'data dissemination', 'data integration', 'data resource', 'data submission', 'data tools', 'genome annotation', 'genomic data', 'human disease', 'human model', 'improved', 'information display', 'innovation', 'large scale data', 'member', 'model development', 'model organisms databases', 'mutant', 'outreach', 'personalized medicine', 'reference genome', 'relating to nervous system', 'small molecule', 'study population', 'symposium', 'text searching', 'tool', 'tool development', 'transcriptomics', 'web page', 'web site']",NHGRI,HARVARD UNIVERSITY,U41,2021,3039925
"Genomic Resource for the Yeast Saccharomyces PROJECT SUMMARY/ABSTRACT The Saccharomyces Genome Database (SGD) is the comprehensive resource providing the highest quality reference information about the genome, and its elements, of the budding yeast, Saccharomyces cerevisiae. Saccharomyces cerevisiae provides fundamental knowledge about eukaryotic genetics, genome maintenance and regulation, and a variety of cellular processes. SGD provides a comprehensive resource that facilitates experimentation in biological systems, and S. cerevisiae informs genetic medicine via annotation of human disease-related phenotypes and gene function through functional complementation between yeast and human homologs. S. cerevisiae is the most well studied eukaryote and the experimental literature for this yeast contains these results. SGD synergizes results from a large variety of molecular and biochemical assays, extending this information by assimilating the results of large-scale genomics assays, provides connections to fungal species and model eukaryotes via orthology, and incorporates formalized and controlled vocabularies to represent biological concepts. SGD maintains and broadens relationships with the greater scientific community and makes technical improvements through the development of tools and the use of third-party software that enhances the work of scientists and educators. SGD is a founding member of both the Gene Ontology Consortium and the Alliance for Genome Resources, and also collaborates with many components of the NCBI and EBI. SGD provides a substantial service organization, and maintains this service to the scientific community, reaching out to scientists in the greater biomedical research community to serve those who have a need for genetic information that can be provided via the synergized results on yeast genes, their products, and their functions. RELEVANCE TO PUBLIC HEALTH, PROJECT NARRATIVE Saccharomyces cerevisiae is a model for understanding eukaryotic genetics, genome maintenance and regulation, and cellular processes. S. cerevisiae informs genetic medicine via annotation of human disease-related phenotypes and gene function through functional complementation between yeast and human homologs. SGD provides a comprehensive online resource that facilitates experimentation and computational analysis to understand fundamental biological processes.",Genomic Resource for the Yeast Saccharomyces,10089297,U24HG001315,"['Adopted', 'Attention', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell physiology', 'Cells', 'Collaborations', 'Communities', 'Complement', 'Computer Analysis', 'Computer software', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Documentation', 'Education and Outreach', 'Elements', 'Eukaryota', 'Genes', 'Genetic', 'Genetic Medicine', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Biology', 'Internet', 'Knowledge', 'Learning', 'Learning Module', 'Lighting', 'Literature', 'Maintenance', 'Maps', 'Metadata', 'Modeling', 'Molecular', 'Ontology', 'Paper', 'Phenotype', 'Public Health', 'Regulation', 'Research', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Services', 'Update', 'Variant', 'Work', 'Yeasts', 'biological systems', 'citizen science', 'cloud storage', 'data standards', 'design', 'gene function', 'gene product', 'genetic information', 'genome database', 'genome resource', 'heterogenous data', 'human disease', 'member', 'new technology', 'novel', 'online resource', 'pedagogy', 'service organization', 'text searching', 'tool', 'tool development']",NHGRI,STANFORD UNIVERSITY,U24,2021,1851854
"Biomedical Data Translator Development of Autonomous Relay Agent: ARAX This project would continue collaborative work within the Translator consortium by a multi-site team (“Team X-ray”) at Oregon State University (PI Stephen Ramsey) and at two partner institutions, Pennsylvania State University (PI Koslicki) and the Institute for Systems Biology (PI Eric Deutsch; Co-I Jared Roach). Team X-ray was highly productive in Translator's feasibility assessment phase and the team brings critical expertise to Translator (see Resources). Component type: We propose to create, validate, and integrate an autonomous relay agent (ARA) called ARAX . ARAX will be a middleware component in the new Translator architecture that will extend significantly beyond the capabilities of the prototype reasoning tool (RTX) that we created in the feasibility assessment phase. Depending on the input request, ARAX's main output will be ranked subgraphs with clearly explained ranking basis. ARAX will leverage code and algorithms from RTX and will have an explicit application focus area, as described below. Main problems that ARAX is trying to address: Connections within a biomedical knowledge graph have highly variable degrees of (i) confidence (due to ambiguous predicates and/or due to highly variable degrees of reliability of knowledge types) and (ii) potential relevance to the user's query. Such edge-significance variability leads to both incorrect and difficult-to-interpret results which together pose a significant problem for creating broadly useful tools for computer-based biomedical reasoning. We propose to address this problem by explicitly accounting for these two types of edge variability in the reasoning algorithms–spanning a broad range of biomedical query types–that ARAX will provide to Translator. In addition to these broad capabilities, as described in the Project Plan, we will incorporate advanced algorithms in ARAX for responding to queries relating to disease therapy, including (1) drug repositioning for known disease, leveraging knowledge about the disease’s pathogenesis [1] ; and (2) therapeutic recommendations for rare diseases based on symptoms and the putative causal genetic variant. Plan for implementation of the project: In our Project Plan we describe a five-year timeline for creating, validating, and integrating ARAX within Translator, beginning with a three-month sprint leading to a prototype of ARAX by mid-March 2020. Key components of the plan include: (1) leveraging the BioThings Explorer software framework to enable ARAX to dynamically map between compounds, proteins, pathways, variants, phenotypes, and diseases based on knowledge source application programming interfaces in the Translator registry; (2) leveraging COHD and related Translator resources to obtain biomedical semantic distance information; (3) leveraging an application programming interface endpoint for the RTX biomedical knowledge graph, KG2; and (4) implementing probabilistic reasoning algorithms leveraging provenance information and dynamically determined edge relevance scores to improve reasoning. We will systematically use machine-learning to align ranking scores with measures of output quality. Collaboration strengths of our team include (i) developing technical standards for communications between Translator software agents (leveraging PI Deutsch’s extensive past experience); (ii) developing knowledge graph standards (leveraging PI Ramsey’s and PI Koslicki’s expertise); and (iii) deriving use-case vignettes that speak to the transformative potential of Translator (leveraging Co-I Roach’s and PI Ramsey’s expertise). In the development phase, our team would continue to collaborate with other teams and with NIH stakeholders in an adaptive, high-bandwidth, and team-boundary-agnostic fashion, as detailed in the Project Plan. Key challenges to building the proposed system are (1) the need to be able to ""chain"" together analytical steps between tools and (2) the need for cooperative development of standards that enable Translator components to interact; we address them in detail in the Project Plan. n/a",Biomedical Data Translator Development of Autonomous Relay Agent: ARAX,10333468,OT2TR003428,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Area', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Computers', 'Development', 'Disease', 'Institutes', 'Institution', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Oregon', 'Output', 'Pathogenesis', 'Pathway interactions', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Proteins', 'Rare Diseases', 'Recommendation', 'Registries', 'Resources', 'Roentgen Rays', 'Semantics', 'Site', 'Software Framework', 'Source', 'Symptoms', 'System', 'Systems Biology', 'Therapeutic', 'TimeLine', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'application programming interface', 'base', 'data translator', 'experience', 'genetic variant', 'improved', 'knowledge graph', 'middleware', 'prototype', 'tool']",NCATS,OREGON STATE UNIVERSITY,OT2,2021,897051
"DOCKET: accelerating knowledge extraction from biomedical data sets Component type: This Knowledge Provider project will continue and significantly extend work done by the Translator Consortium Blue Team, focusing on deriving knowledge from real-world data through complex analytic workflows, integrated to the Translator Knowledge Graph, and served via tools like Big GIM and the Translator Standard API. The problem: We aim to solve the “first mile” problem of translational research: how to integrate the multitude of dynamic small-to-large data sets that have been produced by the research and clinical communities, but that are in different locations, processed in different ways, and in a variety of formats that may not be mutually interoperable. Integrating these data sets requires significant manual work downloading, reformatting, parsing, indexing and analyzing each data set in turn. The technical and ethical challenges of accessing diverse collections of big data, efficiently selecting information relevant to different users’ interests, and extracting the underlying knowledge are problems that remain unsolved. Here, we propose to leverage lessons distilled from our previous and ongoing big data analysis projects to develop a highly automated tool for removing these bottlenecks, enabling researchers to analyze and integrate many valuable data sets with ease and efficiency, and making the data FAIR [1]. Plan: (AIM 1) We will analyze and extract knowledge from rich real-world biomedical data sets (listed in the Resources page) in the domains of wellness, cancer, and large-scale clinical records. (AIM 2) We will formalize methods from Aim 1 to develop DOCKET, a novel tool for onboarding and integrating data from multiple domains. (AIM 3) We will work with other teams to adapt DOCKET to additional knowledge domains. ■ The DOCKET tool will offer 3 modules: (1) DOCKET Overview: Analysis of, and knowledge extraction from, an individual data set. (2) DOCKET Compare: Comparing versions of the same data set to compute confidence values, and comparing different data sets to find commonalities. (3) DOCKET Integrate: Deriving knowledge through integrating different data sets. ■ Researchers will be able to parameterize these functions, resolve inconsistencies, and derive knowledge through the command line, Jupyter notebooks, or other interfaces as specified by Translator Standards. ■ The outcome will be a collection of nodes and edges, richly annotated with context, provenance and confidence levels, ready for incorporation into the Translator Knowledge Graph (TKG). ■ All analyses and derived knowledge will be stored in standardized formats, enabling querying through the Reasoner Std API and ingestion into downstream AI assisted machine learning. ■ Example questions this will allow us to address include: (Wellness) Which clinical analytes, metabolites, proteins, microbiome taxa, etc. are significantly correlated, and which changing analytes predict transition to which disease? [2,3] (Cancer) Which gene mutations in any of X pathways are associated with sensitivity or resistance to any of Y drugs, in cell lines from Z tumor types? (All data sets) Which data set entities are similar to this one? Are there significant clusters? What distinguishes between the clusters? What significant correlations of attributes can be observed? How can this set of entities be expanded by adding similar ones? How do these N versions of this data set differ, and how stable is each knowledge edge as the data set changes over time? Collaboration strengths: Our team has extensive experience with biomedical and domain-agnostic data analytics, integrating multiple relevant data types: omics, clinical measurements and electronic health records (EHRs). We have participated in large collaborative consortia and have subject matter experts willing to advise on proper data interpretation. Our application synergizes with those of other Translator teams (see Letters of Collaboration). Challenges: Data can come in a bewildering diversity of formats. Our solution will be modular, will address the most common formats first, and will leverage established technologies like DataFrames and importers (like pandas.io) where possible. Mapping nodes and edge types onto standard ontologies is crucial for knowledge integration; we will collaborate with the Standards component to maximize success. n/a",DOCKET: accelerating knowledge extraction from biomedical data sets,10330627,OT2TR003443,"['Address', 'Big Data', 'Cell Line', 'Clinical', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Electronic Health Record', 'Ethics', 'FAIR principles', 'Gene Mutation', 'Individual', 'Ingestion', 'Knowledge', 'Knowledge Extraction', 'Letters', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Methods', 'Ontology', 'Outcome', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'Records', 'Research', 'Research Personnel', 'Resistance', 'Resources', 'Specific qualifier value', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Work', 'experience', 'indexing', 'interest', 'interoperability', 'knowledge graph', 'knowledge integration', 'large datasets', 'microbiome', 'novel', 'success', 'tool', 'tumor']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT2,2021,676757
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,10111538,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2021,1354555
"Single Cell Transcriptomic and Genetic Diversity by Single Molecule Long Read Sequencing PROJECT SUMMARY Defining the features of cellular mixtures, where diverse cell types with distinct genomic characteristics are physically intermingled together, is a central problem in biology. During the past decade, single cell sequencing technologies have enabled a new era of high throughput and high resolution interrogation of cell type diversity, vastly expanding our understanding of the role that cell types play in development and disease. Yet, current studies in single cell genomics rely on short-read sequencing and thus suffer from limitations, including: (1) Most studies rely on short read counting which limits the study of alternative splicing. (2) Cell states are reflected by static snapshots, and while population dynamics can be deduced through trajectory and RNA velocity estimation, robust estimation of these parameters remains a major challenge. (3) Despite advances in single-cell DNA sequencing, there is yet no cost-effective way to simultaneously characterize both the genetic variants and transcriptome-level changes in a cell, which is crucial for diseases such as cancer. This proposal is motivated by technological breakthroughs in single-molecule sequencing (SMS) and the recent adaptation of SMS to the massively parallel sequencing of single cell transcriptomes in our lab. We propose to develop computational methods to harness the power of SMS in single cell transcriptomics. In particular, we have developed a new genomic approach which allows one to repeatedly interrogate complete transcripts from single cells using SMS long reads, rather than 3' or 5' counting with short reads. This technology allows experimental designs where specific transcript subsets and/or cellular subsets can be repeatedly targeted for deeper joint short and long read analysis over many iterations, which we will exploit to conduct analyses that were previously intractable. PROJECT NARRATIVE During the past decade, single cell sequencing technologies have enabled a new era of high throughput and high resolution interrogation of cell type diversity, vastly expanding our understanding of the role that cell types play in development and disease. This proposal is motivated by technological breakthroughs in single-molecule sequencing (SMS) and the recent adaptation of SMS to the massively parallel sequencing of single cell transcriptomes. We propose to develop computational methods to harness the power of SMS in single cell transcriptomics, thus improving the analysis disease-related changes in individual genomes and cells.",Single Cell Transcriptomic and Genetic Diversity by Single Molecule Long Read Sequencing,10250524,R01HG006137,"['Accounting', 'Address', 'Alternative Splicing', 'Benchmarking', 'Biology', 'Cell Differentiation process', 'Cells', 'Characteristics', 'Computing Methodologies', 'DNA', 'DNA sequencing', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Event', 'Experimental Designs', 'Future', 'Gastrointestinal Melanoma', 'Gene Fusion', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic approach', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Individual', 'Joints', 'Learning', 'Lymphocyte', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Massive Parallel Sequencing', 'Methods', 'Mutation', 'Pathogenesis', 'Play', 'Population', 'Population Analysis', 'Population Dynamics', 'Procedures', 'Protein Isoforms', 'Psychological Transfer', 'RNA', 'RNA Splicing', 'Recording of previous events', 'Research Design', 'Resolution', 'Role', 'Somatic Mutation', 'Spliced Genes', 'Technology', 'Tissues', 'Transcript', 'Uncertainty', 'base', 'cancer type', 'cell type', 'cost effective', 'cytokine', 'deep learning', 'denoising', 'design', 'detection method', 'genetic variant', 'improved', 'longitudinal analysis', 'method development', 'response', 'single cell sequencing', 'single molecule', 'single-cell RNA sequencing', 'transcriptome', 'transcriptome sequencing', 'transcriptomics']",NHGRI,UNIVERSITY OF PENNSYLVANIA,R01,2021,595908
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,10214625,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2021,3125
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,10136665,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2021,345658
"Center for Translational Research in Health Disparities Abstract: Diversity in the rates of progression and mortality of COVID-19 disease within infected African American (AAs) subgroups are clearly not just a function of the underlying health conditions that increase the rate of mortality for COVID -19 patients, such as hypertension, obesity and diabetes, but may also be affected by host genetic factors. Here we propose a series of studies to advance the understanding of our knowledge in relative to the health inequity in COVID-19 disease. This is a multiple-collaborative study between Genomic, Imaging research labs and Statistical studies. Research teams in Morehouse School of Medicine (MSM) have established intimate relationships that position the institute to focus their research works on underserved minorities. We plan to develop and disseminate technological approaches in identifying host factors that disproportionately affect AAs COVID-19 infected patients. Given that the discovery, and establishment of translational implementation of novel solutions to health disparities in high-risk minority COVID-19 infected is our overall goals. Recently, angiotensin-converting enzyme 2 (ACE2), encoded on the X-chromosome, has been shown to be a functional receptor for COVID-19 to enter host target cells and the concern might arise regarding whether ACE2 variants between and within subgroups would increase the morbidity and mortality of COVID-19 infected patients. Therefore, the long-term goal is to compare how genetic variants of the ACE2 receptor, chemokine (CCL2) and human leukocyte antigen (HLA) genes (influence the immune system’s response to viruses and bacteria), affects COVID-19 disease severity among people but no underlining disease like diabetes, heart or lung disease with those with mild or no disease manifestations. Short-term goal; we will focus on two aims; Aim: 1-Determine genetic variations in ACE2 gene on obtained DNA samples from COVID-19 infected patients and evaluate for potential correlation between ACE2 variant frequencies in relationship to COVID-19 disease progression and mortalities between and within AAs and non-Hispanic Caucasian CAs subgroup;. COVID-19 is caused by SARS-CoV-2 which uses host cell ACE2, TMPRSS2, EZRIN and other proteins for entry. Differences in ACE2 or TMPRSS2/EZRIN genes expression and SNPs may justify the disease disparity and aim 2 will address how COVID-19 spike engagement with host cell receptor is precisely regulated and how host cells respond to cytokines elicited by COVID-19 infection using lung organoids. A recent correlation study suggested that the decrease expression of ACE2 /TMPRSS2/EZRIN are predictors of decreased susceptibility to COVID-19 infection and could be attributed to COVID-19 morbidity in Africa American patients. Aim-2: Modeling COVID-19-elicited disease disparity using lung organoids. Clinical validation of ACE2 and EZRIN will help to develop better strategies for COVID 19 diagnosis and treatment to reduce the observed COVID-19 disease progressive outcome and mortality gaps between African American and Caucasians patients. . Given the facts of a significant racial disparity in COVID-19 disease among African American (AA) and Caucasians, there is an utmost need to understand the COVID-19 infectivity host factors biology. Apart from socioeconomic factors and underlying comorbidities, AA clearly differ from Caucasians on a number of accounts, including COVID-19 mortalities genetic predisposition, which favors for high incidence and mortality rate COVID- 19 disease manifestations. Studies clearly demonstrate that ACE 2 encoded on the X-chromosome which COVID-19 virus use to entry host may be differentially expressed among individuals, therefore, we propose to determine that ACE2 and other genes, such as Ezrin plays vital role in regulating the COVID-19 virus infectivity resulting in racial disparity and the clinical validation of ACE2 and ezrin will help to develop better strategies for COVID 19 diagnosis and treatment to reduce the observed COVID-19 disease progressive outcome gaps between African American and Caucasians.",Center for Translational Research in Health Disparities,10221307,U54MD007602,"['2019-nCoV', 'ACE2', 'Address', 'Affect', 'Africa', 'African American', 'American', 'Bacteria', 'Biology', 'Blood specimen', 'CCL2 gene', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 morbidity', 'COVID-19 mortality', 'COVID-19 patient', 'COVID-19 severity', 'COVID-19 treatment', 'Caucasians', 'Cells', 'Center for Translational Science Activities', 'Clinical', 'Correlation Studies', 'DNA', 'Data', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Female', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Heart Diseases', 'Hospitals', 'Hypertension', 'Image', 'Immune response', 'Incidence', 'Individual', 'Institutes', 'Integration Host Factors', 'Knowledge', 'Lung', 'Lung diseases', 'Minority', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Morehouse School of Medicine', 'Not Hispanic or Latino', 'Obesity', 'Organoids', 'Outcome', 'Patients', 'Peripheral Blood Mononuclear Cell', 'Play', 'Population', 'Positioning Attribute', 'Predisposition', 'Progressive Disease', 'Proteins', 'Receptor Cell', 'Research', 'Risk', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Series', 'Socioeconomic Factors', 'Statistical Study', 'Subgroup', 'TMPRSS2 gene', 'Testing', 'Validation', 'Variant', 'Virus', 'Work', 'X Chromosome', 'chemokine', 'comorbidity', 'cytokine', 'differential expression', 'disease disparity', 'ezrin', 'genetic variant', 'health disparity', 'health inequalities', 'high risk', 'machine learning algorithm', 'male', 'mortality', 'novel', 'outcome prediction', 'predictive modeling', 'racial disparity', 'receptor', 'transcriptome sequencing', 'underserved minority']",NIMHD,MOREHOUSE SCHOOL OF MEDICINE,U54,2021,177500
"UniProt: A Protein Sequence and Function Resource for Biomedical Science PROJECT SUMMARY/ABSTRACT This project continues the development of the UniProt Knowledgebase, which aims to provide the scientific community with a comprehensive, high-quality, and freely accessible resource of protein sequences and functional information. Proteins are an essential bridge between human genetics, the environment and phenotype. While human genetics has increasing power to find correlations between genotype and phenotype, knowledge of how proteins function, provided by UniProt, is essential for the mechanistic understanding critical to develop health outcomes through improved and personalized diagnostics, prognostics, and treatments. Biomedical research is being revolutionized by methods from the field of Artificial Intelligence, particularly Machine Learning (ML) approaches such as Deep Learning (DL). These approaches now outstrip the ability of humans in many fields and are state-of-the-art when sufficient data is available. UniProt provides gold standard training data for hundreds of ML applications in biomedical research. The work in this proposal will enhance the readiness of UniProt for use in ML and will integrate ML methods to enhance our efficiency. UniProt curators extract and synthesize experimental knowledge of proteins from papers in human and machine- readable forms using a range of standard ontologies. This proposal will further structure protein knowledge in UniProt, developing complete, machine-readable catalogs of the functional impact of human variation and of human protein networks and complexes, essential to understanding human disease. Efficiency of curation will be improved using DL models, developed in collaboration with text mining experts, to automate the identification of relevant papers and accelerate extraction of knowledge. This extracted knowledge will be validated by our expert curators and also the wider research community who will be actively engaged to further scale curation. ML approaches will also be used to infer annotations for proteins with no experimental characterization, using community challenges to develop faster, more accurate, scalable approaches to annotate the deluge of uncharacterized proteins. UniProt is an exemplar FAIR resource and has served the scientific community with metronomic data releases despite an exponential growth in data volumes. Streamlined production processes will scale efficiently and sustainably with both the growing data volume and complexity. We will explore novel technologies to ensure the continued timely release of data to the community according to the FAIR principles. UniProt is an international hub of protein data that serves hundreds of thousands of users annually. We will continue using user-centric approaches to develop the UniProt website in response to user needs and new data types. We will engage with our stakeholders and collaborators by introducing an annual strategic partnership meeting. We will engage our communities through webinars, social media, hackathons and attendance at scientific meetings to broaden the efficient and impactful use of our data. PROJECT NARRATIVE Proteins shape our cells, tissues, and organs in response to the complex interplay of genomics with environmental and developmental cues, and thereby hold the key to understanding how individual genomic variation affects our phenotype, disease susceptibility, and drug responses. UniProt provides a reference resource that efficiently standardizes and organizes knowledge of proteins and their functions in forms that both humans and machines can understand and interpret. The UniProt knowledge framework enables biomedical researchers to rapidly understand what is already known, enabling them to design insightful experiments to understand human disease at a molecular level.",UniProt: A Protein Sequence and Function Resource for Biomedical Science,10267787,U24HG007822,"['Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Biomedical Research', 'Catalogs', 'Cells', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Disease', 'Disease susceptibility', 'Distance Learning', 'Ensure', 'Environment', 'FAIR principles', 'Genomics', 'Genotype', 'Glean', 'Gold', 'Growth', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Human Microbiome', 'Individual', 'International', 'Internet', 'Knowledge', 'Knowledge Extraction', 'Literature', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Sequence Data', 'Molecular Structure', 'Ontology', 'Organ', 'Orthologous Gene', 'Outcome', 'Paper', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Production', 'Protein Array', 'Proteins', 'Publications', 'Readability', 'Readiness', 'Research', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Site', 'Standardization', 'Structural Protein', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Triage', 'Variant', 'Work', 'biomedical data science', 'biomedical resource', 'crowdsourcing', 'data access', 'data reuse', 'deep learning', 'design', 'experience', 'experimental study', 'formycin triphosphate', 'genetic architecture', 'genomic variation', 'hackathon', 'human disease', 'improved', 'innovation', 'knowledge base', 'learning strategy', 'machine learning method', 'macromolecular assembly', 'meetings', 'new technology', 'pathogen', 'personalized diagnostics', 'prognostic', 'protein function', 'response', 'social media', 'symposium', 'text searching', 'web site', 'webinar']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U24,2021,250000
"UniProt: A centralized protein sequence and function resource PROJECT SUMMARY/ABSTRACT The mission of the Universal Protein Resource (UniProt) is to support biomedical research by providing a freely available, stable, comprehensive, richly and accurately annotated protein sequence knowledgebase (www.uniprot.org). UniProt integrates, interprets and standardizes data from a multitude of sources to achieve the most comprehensive catalog of protein sequences and functional annotation available to date, providing information from hundreds of thousands of publications for tens of millions of proteins from tens of thousands of species. The activities proposed here will increase the utility of UniProt for biomedical research and precision medicine. The expert curated functional information provided by UniProt is widely acknowledged to be of exceptional quality and is continuously updated as new knowledge becomes available. Our first aim will be to continue to curate the scientific literature to ensure UniProt remains up to date. We will also work with the text-mining community to continue to improve curation efficiency. The curated records (0.5 million) are complemented by the (80 million) records for uncharacterized proteins. To ensure their usefulness for the community we will continue to develop our automatic annotation systems to annotate these proteins based on the knowledge of characterized proteins. Our third aim is to connect to and integrate protein data from resources around the world to make UniProt the worldwide global hub of protein information. The integration of clinical variation data as well as metabolomics information with proteins will help to support the multi-omics approaches of precision medicine. Our fourth aim describes the production of the resource to ensure that our data is freely available according to the FAIR principles. UniProt forms a foundation for hundreds of life sciences data resources. Continuous software development is needed to ensure delivery of this key component of the life science infrastructure. The UniProt website is used by hundreds of thousands of scientists every month. The final aim describes how we will enable this community to make best use of UniProt, through user training, outreach and improved user interfaces, driven by user testing. PROJECT NARRATIVE UniProt is the world’s leading resource of protein sequence and functional information, covering all species including Homo sapiens, model organisms and pathogens. UniProt annotates protein function using community- standard ontologies to support the interpretation of genomic and other datasets on which biomedical research and precision medicine depend. The activities described here will increase the utility of UniProt for biomedical research and precision medicine, enhancing research efficiency and understanding of human disease.",UniProt: A centralized protein sequence and function resource,10372430,U24HG007822,"['Amino Acid Sequence', 'Animal Model', 'Biological Sciences', 'Biomedical Research', 'Catalogs', 'Clinical', 'Communities', 'Complement', 'Data', 'Data Set', 'Education and Outreach', 'Ensure', 'FAIR principles', 'Foundations', 'Genomics', 'Homo sapiens', 'Infrastructure', 'Knowledge', 'Literature', 'Mission', 'Ontology', 'Production', 'Proteins', 'Publications', 'Records', 'Research', 'Resources', 'Scientist', 'Source', 'Testing', 'Update', 'Variant', 'Work', 'annotation  system', 'base', 'biomedical resource', 'data resource', 'data science resource', 'data standards', 'human disease', 'improved', 'knowledge base', 'metabolomics', 'multiple omics', 'pathogen', 'personalized approach', 'precision medicine', 'protein function', 'software development', 'text searching', 'web site']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U24,2021,1916827
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,10131237,R00HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Visualization', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data complexity', 'data framework', 'data integration', 'data reduction', 'data standards', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'learning classifier', 'multidimensional data', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R00,2021,249000
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,10085664,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'detection limit', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,305167
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,10251876,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Hi-C', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2021,526482
"Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity Project Summary Antimicrobial resistance is an increasing problem, and current drug pipelines are not keeping pace with the rise of antimicrobial resistance. An alternative strategy is to boost host immunity. An often overlooked side-effect of the vitamin and mineral supplementation projects of the 1940s is that these supplements greatly reduced infectious disease burden. Recent work has shown that further gains may be possible, especially in adding phytochemicals back to highly processed diets typically consumed in the United States. However, we lack a fundamental understanding of how these components are processed by the microbiome, and how diet-derived molecules, microbiome and host immune system work together to resist infectious disease. A key barrier preventing us from making these discoveries is that each individual assay (microbiome, host gene expression metabolome, dietary compounds) is expensive and highly multivariate. Three key insights that enable the current project are the miniaturization of DNA and RNA sequencing assays on advanced nanoliter- scale liquid handling robots, greatly reducing the cost, the combination of untargeted and targeted mass spectrometry on the same samples in high throughput to enable discovery of a much greater chemical space, and the ability to use explicitly spatial maps on multiple scales to integrate the dataset throughout the body and enable both visual analytics and deep learning approaches based on spatial data. These breakthroughs will provide a fundamentally new understanding of how dietary metabolites promote disease resistance, and will allow us to develop a new infrastructure to integrate results from many investigators in different laboratories studying various aspects of these systems. Additionally, the results will allow us to choose biomaterials and biomarkers in human subjects that provide maximum information about internal nutritional and immune status. Results will be tested against the NHANES and American Gut cohorts. The results of this project will therefore be: 3D maps of mouse models showing how the microbiome, diet, and host gene expression produce immunity; an infrastructure for creating and sharing these maps; and a preliminary test of whether the results extend to large human populations. Project Narrative The public health relevance of this proposal is that it will provide an infrastructure for analyzing impacts of dietary components and microbiomes throughout the body. The analysis of these maps will help us identify dietary components that improve resistance to infectious disease.",Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity,10226176,DP1AT010885,"['3-Dimensional', 'American', 'Antimicrobial Resistance', 'Back', 'Biocompatible Materials', 'Biological Assay', 'Biological Markers', 'Chemicals', 'Communicable Diseases', 'Consumption', 'DNA sequencing', 'Data', 'Data Set', 'Diet', 'Dietary Component', 'Disease Resistance', 'Enhancers', 'Gene Expression', 'Human', 'Immune system', 'Immunity', 'Individual', 'Infrastructure', 'Laboratory Study', 'Liquid substance', 'Maps', 'Mass Spectrum Analysis', 'Metabolite Interaction', 'Microbe', 'Minerals', 'Miniaturization', 'National Health and Nutrition Examination Survey', 'Nutritional status', 'Pharmaceutical Preparations', 'Phytochemical', 'Population', 'Process', 'Research Personnel', 'Resistance', 'Robot', 'Sampling', 'Supplementation', 'System', 'Testing', 'United States', 'Visual', 'Vitamins', 'Work', 'base', 'burden of illness', 'cohort', 'cost', 'deep learning', 'dietary', 'human subject', 'immunological status', 'improved', 'insight', 'metabolome', 'microbiome', 'mouse model', 'nanolitre scale', 'prevent', 'public health relevance', 'side effect', 'transcriptome sequencing']",NCCIH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",DP1,2021,885000
"Conceptualizing Actionability in Clinical Genomic Screening Project Summary/Abstract. Clinical genomic sequencing (CGS) produces large amounts of data, much of which is hard to characterize or may have a negligible influence on health. The concept of actionability is commonly used to help separate information that may be useful from information that is likely irrelevant for patients. Actionability directs attention to whether genomic information warrants action and reflects its initial development as a strategy to augment diagnosis and treatment in sick patients. As CGS expands towards healthy populations in primary care settings, actionability is still widely embraced despite little consensus regarding its definition and use. Because this ambiguity could become an obstacle to the successful implementation of clinical genomic sequencing in healthy populations, greater clarity about this concept is necessary. The proposed research will fulfill this need by characterizing the emergence and varied meanings of actionability in clinical genomics, focusing on clinical genomics' transition into primary care settings. By identifying underlying values and assumptions related to actionability, this research will push beyond definitional disputes and provide a deeper framework for assessing how genetic information is valued. The specific aims are: 1. Identify and characterize, through in-depth interviews, how genomics experts and primary care providers conceptualize what makes genomic information actionable for healthy populations. 2. Identify and characterize, through a natural language processing (NLP) analysis of published literature, how the concept of actionability emerged, spread, and is used throughout clinical genomics. 3. Convene a workshop with genomics experts, primary care providers, and ELSI scholars to produce a white paper on actionability and the ethical, effective integration of CGS into primary care, guided by the results from Aims 1 and 2. This K99/R00 Pathway to Independence Award includes a highly-structured, mentored training program that will support the candidate's goal to become an independent, mixed-methods ELSI investigator focused on assessing the value of genomic information. To achieve this career goal, the candidate will: 1. Receive training in genetic and genomic science to facilitate collaboration with genomics care teams and make scientifically accurate policy recommendations 2. Build new methodological skills in biomedical informatics and natural language processing to conduct generalizable research 3. Publish and engage with scientific and medical audiences to have a more direct impact on future guidelines and policies. 4. Develop a collaborative and interdisciplinary research network. This training will include coursework, guided readings, network building, and sustained mentorship by a highly-qualified team of faculty with expertise in ELSI research, bioethics, clinical genomics, biomedical informatics, and the history and sociology of medicine. This training will prepare the candidate to transition to an independent ELSI investigator focused on ethical issues related to the actionability of genomic health information – an ELSI research priority in Genetic and Genomic Healthcare. Project Narrative. This K99/R00 Pathway to Independence Award will prepare the candidate to become an independent, mixed-methods ELSI researcher pursing a research program on ethical issues related to the actionability of genomic information. The study examines the values and assumptions underlying conceptualizations of the actionability of genomic information for healthy populations. Results of the study will contribute to the ethical and effective implementation of genomic sequencing into care for healthy populations.",Conceptualizing Actionability in Clinical Genomic Screening,10262950,K99HG010905,"['American', 'Award', 'Bioethics', 'Caring', 'Clinical', 'Collaborations', 'Consensus', 'Data', 'Development', 'Diagnosis', 'Disease', 'Disputes', 'Educational workshop', 'Ethical Issues', 'Ethics', 'Faculty', 'Future', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Individual', 'Interdisciplinary Study', 'Intervention', 'Interview', 'Laboratories', 'Level of Evidence', 'Literature', 'Medical', 'Medical Genetics', 'Medical Sociology', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Natural Language Processing', 'Outcome', 'Paper', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Penetrance', 'Policies', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Provider', 'Publishing', 'Qualitative Methods', 'Reading', 'Recommendation', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Science', 'Severities', 'Structure', 'Surveys', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Variant', 'biomedical informatics', 'care providers', 'career', 'clinical implementation', 'directed attention', 'ethical legal social implication', 'genetic information', 'genome sciences', 'health management', 'innovation', 'lifestyle intervention', 'medical schools', 'prevent', 'primary care setting', 'programs', 'screening', 'skills']",NHGRI,UNIVERSITY OF PENNSYLVANIA,K99,2021,103809
"BioGRID: An open resource for biological interactions and network analysis Complex physical and genetic interaction networks determine the properties of all biological systems and underlie human development, health and disease. Decades of biological experiments have identified myriad molecular processes that underpin specific biological processes, described in the primary biomedical literature. More recent technological innovations combined with complete genome sequence information have led to the development of a wide variety high-throughput (HTP) methods to generate physical and genetic interaction data on an unprecedented scale. Because human interaction networks are often directly analogous to networks in more tractable model organisms, it is essential that the hundreds of thousands of biological interactions discovered across the major model organisms, as well as humans, are archived in a well- annotated manner that provides a means for rigorous analysis and computation. To capture, integrate, and interrogate this wealth of data from both the literature and HTP datasets, we developed the BioGRID database as an open repository for physical and genetic interactions (www.thebiogrid.org). BioGRID contains over 2,000,000 total interactions from 75,760 publications. In 2020, BioGRID averaged 151,735 page views, 19,407 unique visitors and 7,537 file downloads per month. Our recently released Open Repository for CRISPR Screens (ORCS), averages 8,725 page views, 1,646 unique visitors, and 268 downloads per month. In addition, the extensive BioGRID data compendium is widely disseminated by many partner databases, meta- databases, and software tools. Here, we propose to markedly enhance the data content, the database architecture, and the user interface of BioGRID. We will expand the amount and types of data available through BioGRID, with a particular focus on translating knowledge from model organism networks to humans using ortholog mapping and a novel framework for mapping phenotypes and diseases across species. We will significantly expand CRISPR-based genetic interactions, chemical and drug interactions, and post-translational modifications, which we will integrate with our core physical and genetic interactions and organize around focused curation efforts around particular biological themes. Use of text-mining algorithms and AI methods will be extended to enhance curation rates and coverage of the proteome. User access to the large datasets in BioGRID will be facilitated by data-rich interfaces, user-defined search and display parameters, and multiple methods of visualization. All software will continue to be open source and engineered toward compatibility and will be complementary with other database and software development efforts. The BioGRID will provide interaction data and software tools to model organism databases and other interested parties without restriction. The BioGRID resource will enable the biomedical research community to access validated biological interaction datasets across model organisms and humans for hypothesis generation and network analysis, and thereby further the general mission of the NIH. Narrative The BioGRID database provides an extensive collection of protein and genetic interaction data for the major model organism species and humans, with user-oriented tools to explore this information. The BioGRID facilitates better understanding of human disease by enabling inference of gene and protein function through network context and the computational comparison of these gene and protein networks in human health and disease to analogous networks mapped in model organisms. The vast amounts of data in the BioGRID are freely provided to many other databases and biomedical researchers, thus enabling both fundamental and translational research.",BioGRID: An open resource for biological interactions and network analysis,10299336,R01OD010929,"['Algorithms', 'Alleles', 'Animal Model', 'Architecture', 'Archives', 'Area', 'Back', 'Behavior', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'COVID-19', 'CRISPR screen', 'Cells', 'Chemical Agents', 'Chemicals', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Drug Interactions', 'Engineering', 'Funding', 'Future', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Genome', 'Health', 'Human', 'Human Development', 'International', 'Intuition', 'Knowledge', 'Literature', 'Malignant Neoplasms', 'Maps', 'Methods', 'Mission', 'Molecular', 'Organism', 'Orthologous Gene', 'Pathway Analysis', 'Phenotype', 'Post-Translational Protein Processing', 'Process', 'Property', 'Protein Structure Initiative', 'Proteins', 'Proteome', 'Publications', 'Records', 'Research', 'Research Personnel', 'Resources', 'Services', 'Software Tools', 'Source', 'System', 'Technology', 'Tissues', 'Translating', 'Translational Research', 'Ubiquitin', 'United States National Institutes of Health', 'Visualization', 'base', 'biological systems', 'data pipeline', 'data tools', 'experimental study', 'functional genomics', 'fundamental research', 'gene function', 'genome-wide', 'human disease', 'improved', 'interest', 'knowledge graph', 'large datasets', 'model organisms databases', 'multicatalytic endopeptidase complex', 'new therapeutic target', 'novel', 'open source', 'pathogen', 'protein complex', 'protein function', 'repository', 'software development', 'statistics', 'technological innovation', 'text searching', 'tool', 'web site']",OD,SINAI HEALTH SYSTEM,R01,2021,942594
"Privacy-preserving genomic medicine at scale 1 Project Summary  2  3 High-throughput sequencing, biomedical imaging, and electronic health record technologies are 4 generating health-related datasets of unprecedented scale. Integrative analysis of these  5 resources promises to reveal new biology and drive personal and precision medicine. Yet, the  6 sensitive nature of these data often requires that they be kept in isolated silos, limiting their 7 usefulness to science. The goal of this project is to develop innovative privacy-preserving  8 algorithms to enable data sharing and drive genomic medicine. Crucially, we will draw upon our  9 past success in secure genome analysis and algorithmic expertise in computational biology to 10 address the imminent need to perform complex integrative analyses securely and at scale. 11 Current privacy-preserving tools are prohibitively too costly to perform the complex 12 calculations required in genomic analysis. We previously leveraged the highly structured nature 13 of biological data and novel optimization strategies to implement efficient pipelines for secure 14 genome-wide association studies (GWAS) and drug interaction predictions which scaled to 15 millions of samples. In this project, we will further exploit the unique properties of biomedical data 16 to: (i) develop secure integrative analysis methods for genomic medicine; (ii) develop an easy-to- 17 use programming environment with advanced automated optimizations to facilitate the adoption 18 of privacy-preserving analyses; and (iii) promote the use of our privacy techniques to gain novel 19 biological insights through large-scale collaborative genetic studies of multi-ethnic cohorts. 20 With co-I’s Amarasinghe (MIT) and Cho (Broad Institute), we aim to apply these tools to 21 realize the first multi-institution, multi-national secure genetic studies with our partners at the 22 Swiss Personalized Health Network, UK Biobank, Finnish FinnGen, All of Us, NIH NCBI, Broad 23 and Barcelona Supercomputing Center (Letters of Support). We will also use our privacy- 24 preserving approaches to study genomic origins of polygenic traits for disease as well as 25 neuroimaging and other clinical phenotypes. We will continue to actively integrate our methods 26 into community standards (MPEG-G, GA4GH). 27 Successful completion of these aims will result in computational methods and open-source, 28 easy-to-use, production-grade implementations that open the door to secure integration and 29 analysis of massive sets of sensitive genomic and clinical data. With input from our collaborations, 30 we will build these tools and apply them to better understand the molecular causes of human 31 health and its translation to the clinic. Project Narrative Combining genomic and health-related data from millions of patients will empower the development of clinically relevant measures of human health and disease risks. However, this task requires securely sharing sensitive data at an immense scale beyond what existing cryptographic platforms can achieve. Here we develop novel computational methods to enable biomedical data integration, analysis, and interpretation in a privacy-preserving and highly scalable manner.",Privacy-preserving genomic medicine at scale,10266081,R01HG010959,"['Address', 'Adoption', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biological', 'Biology', 'Clinic', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Pooling', 'Data Security', 'Data Set', 'Disease', 'Drug Interactions', 'Electronic Health Record', 'Engineering', 'Environment', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Institutes', 'Institution', 'Knowledge', 'Letters', 'Machine Learning', 'Mainstreaming', 'Measures', 'Medical Imaging', 'Medical Records', 'Medicine', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Patients', 'Performance', 'Pharmacology', 'Polygenic Traits', 'Privacy', 'Process', 'Production', 'Property', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Science', 'Secure', 'Security', 'Software Engineering', 'Software Tools', 'Standardization', 'Stream', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Time', 'Translations', 'United States National Institutes of Health', 'Work', 'analysis pipeline', 'base', 'biobank', 'bioimaging', 'clinical development', 'clinical phenotype', 'clinically relevant', 'cohort', 'computer framework', 'cost', 'cryptography', 'data analysis pipeline', 'data handling', 'data integration', 'data repository', 'data sharing', 'disorder risk', 'epidemiology study', 'experimental study', 'genome analysis', 'genome wide association study', 'genomic data', 'health data', 'innovation', 'insight', 'monomethoxypolyethylene glycol', 'multi-ethnic', 'neuroimaging', 'novel', 'open source', 'polygenic risk score', 'precision medicine', 'preservation', 'privacy preservation', 'statistics', 'success', 'task analysis', 'theories', 'tool']",NHGRI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,674882
"Center for Integrated Cellular Analysis Abstract While rapid advances in single-cell RNA-sequencing are yielding comprehensive taxonomies of cell states in the human body, understanding the complex molecular and environmental factors that regulate cell behavior remains a central challenge. New methods for simultaneous measurement of multiple molecular modalities, spatial context, and lineage relationships are needed to address this goal, but are currently outside the scope of present technologies which largely focus on a single data type. We propose to create a Center for Integrated Cellular Analysis, with a mission to develop a comprehensive suite of technologies and analytical methods to measure and integrate the molecular and environmental determinants of cellular identity. To achieve these goals, we propose the following series of synergistic Aims that will be developed in parallel: 1) Develop massively- parallel assays to simultaneously profile multiple molecular components across millions of cells; 2) Identify the spatial and environmental determinants of cellular state in complex interacting populations; 3) Develop scalable platforms to profile inherited molecular components, and determine the role of cell lineage in establishing molecular and phenotypic differences across cells; and 4) Develop methods to harmonize single- cell profiles across distinct modalities, enabling the inference of cellular identity. Our Center will address critical challenges in data integration, and produce software and protocols that will be applicable to diverse biological systems. We will share these resources broadly with the community, alongside a broader educational focus to encourage New York City students from under-represented backgrounds to pursue academic training in Genomics and Systems Biology. Project Narrative Understanding how the molecular components, inherited lineage, and spatial milieu of single cells dictate function in health and disease remains a key outstanding challenge in genomics. The overarching goal of our Center for Integrated Cellular Analysis is to develop methods to simultaneously assess these multimodal cellular properties, develop tools to harmonize them to allow inferential assessment of cell identity based on partial phenotyping, and share these developments with the broad scientific community while encouraging community engagement through education and outreach. Success in our strategy will facilitate deep, multi-omic phenotyping of single cells for basic research and clinical applications.",Center for Integrated Cellular Analysis,10176553,RM1HG011014,"['Academic Training', 'Address', 'Anatomy', 'Atlases', 'Awareness', 'Basic Science', 'Biological', 'Biological Assay', 'Cell Communication', 'Cell Lineage', 'Cells', 'Cellular Indexing of Transcriptomes and Epitopes by Sequencing', 'Chromatin', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Disease', 'Education and Outreach', 'Ensure', 'Environmental Risk Factor', 'Epitopes', 'Genes', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Health', 'Heritability', 'Human body', 'Immunofluorescence Immunologic', 'In Situ', 'Individual', 'Inherited', 'Joints', 'Learning', 'Measurement', 'Measures', 'Membrane Proteins', 'Messenger RNA', 'Methods', 'Mission', 'Modality', 'Molecular', 'New York City', 'Output', 'Phenotype', 'Play', 'Population', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Proteome', 'Protocols documentation', 'Recording of previous events', 'Resolution', 'Resource Sharing', 'Role', 'Series', 'Signal Transduction', 'Source', 'Students', 'Systems Biology', 'Taxonomy', 'Technology', 'Time', 'Variant', 'analytical method', 'base', 'biological systems', 'cell behavior', 'clinical application', 'combinatorial', 'community engagement', 'cost', 'data integration', 'deep learning', 'epigenome', 'experimental study', 'extracellular', 'indexing', 'innovation', 'insight', 'molecular phenotype', 'multimodality', 'multiple omics', 'novel strategies', 'outreach', 'reconstruction', 'single cell sequencing', 'single-cell RNA sequencing', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,RM1,2021,2935850
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),10147746,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'efficacy evaluation', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2021,162000
"A next-generation morbid map of the human genome PROJECT SUMMARY/ABSTRACT The impact of next-generation sequencing (NGS) on gene discovery and molecular diagnostics for Mendelian conditions (MCs) is hard to overstate. However, to provide affected individuals with precise natural history, recurrence risk, and prognosis in clinical settings, identification of pathogenic variant(s)/genotypes alone is often insufficient. This is a challenge most notably for genes that cause more than one MC or ~25% of all genes that underlie MCs. In such an instance, even with a known genotype a patient's phenotype has to be compared to that of all MCs caused by variants in a gene to determine which MC, if any, is the likely diagnosis or whether patient instead has a novel condition. This comparison is increasingly difficult because delineation of the ~5,100 MCs currently known has typically been based on subjective grouping of affected individuals by phenotypic similarity. We propose to develop a quantitative framework for assessing overlap among the distributions of phenotypes due to pathogenic genotypes the same gene and apply this framework genome-wide. NGS has enabled identification of causal genotypes in hundreds of thousands of individuals with MCs, providing a sufficiently large dataset that it is now feasible to use machine learning to quantitatively and systematically identify “clusters” of co-occurring genotypes and phenotypic features for each known gene. We will refine and validate our approach by comparing differences between conventionally-delineated and quantitatively-delineated MCs and by assessing the similarity of individuals with well-studied atypical phenotypes/genotypes to quantitatively-delineated MCs. We will then apply the optimal strategy across the genome to generate a “next- generation morbid map” based on quantitatively-delineated MCs. We will also apply machine learning approaches to identify genomic properties associated with the propensity for each gene to underlie multiple MCs (i.e., the numeric contribution of each gene to the morbid map or phenotropy). This will enable a more precise and complete understanding of the genotypic and phenotypic spectrum of each MC, enable more objective diagnosis of individuals with atypical phenotypes, and more robustly identify the existence of multiple MCs among individuals with non-specific “class” phenotypes (e.g., developmental delay, autism, hearing impairment). We will make all newly developed methods publicly available via interactive and programmatic web-based tools to facilitate extension of this work to other human and model organism datasets. PROJECT NARRATIVE The major goals of this project are to develop a quantitative framework that enables objective delineation of Mendelian conditions, apply the framework to systematically delineate conditions across all genes known to underlie a Mendelian condition, and predict the number of conditions due to each gene. This framework will provide a fuller, unbiased characterization of the genotypic/phenotypic spectrum for all Mendelian conditions, enable more precise diagnoses and counseling of individuals with difficult to diagnose phenotypes, and accelerate the detection of new Mendelian conditions.",A next-generation morbid map of the human genome,10251153,R35HG011297,"['Affect', 'Animal Model', 'Clinical', 'Counseling', 'Data Set', 'Detection', 'Developmental Delay Disorders', 'Diagnosis', 'Genes', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Human', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Methods', 'Natural History', 'Pathogenicity', 'Patients', 'Phenotype', 'Prognosis', 'Property', 'Recurrence', 'Risk', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'gene discovery', 'genome-wide', 'hearing impairment', 'large datasets', 'molecular diagnostics', 'next generation', 'next generation sequencing', 'novel', 'web-based tool']",NHGRI,UNIVERSITY OF WASHINGTON,R35,2021,454043
"Scaling up computational genomics with tree sequences Project Summary/Abstract Increasing sample size is a tremendously important factor in building our understanding of the genetics of human disease. As we discover that more and more diseases have a complex web of genetic causation, we need larger and larger genetic datasets to disentangle them, and to ultimately produce successful therapies. Driven in part by this need, the community is now assembling vast collections of human genome sequences, and millions of samples will soon be commonplace. Nonhuman datasets, with applications in epidemiology, ecology, and evolution, will not be far behind. There is a profound problem, however: our computational methods for storing, processing, simulating, and analyzing genomic data are lagging far behind our ability to collect such data. The algorithms and data structures underlying today's computational methods were designed for thousands of samples, not millions, and we are in danger of being overwhelmed by the impending tsunami of data. Without a fundamental change in how we store and process genomic data, we will either not fully tap the potential of the data we collect, or the computational costs will be astronomical – or both.  Our proposal addresses this critical need by focusing on a new data structure: the succinct tree sequence. This data structure (the “tree sequence”, for brevity) encodes genetic variation data using the population ge- netics processes that produced the data itself – by representing variation among contemporary samples via mutations on the branches of the underlying genealogical trees. This yields extraordinary levels of data com- pression, with ﬁle sizes hundreds of times smaller than current community standards. Since the tree sequence was introduced in 2016 it has led to performance increases of 2–4 orders of magnitude in the diverse applica- tions of genome simulation, calculation of statistics, and ancestry inference. Such sudden leaps in computa- tional performance are vanishingly rare, and only possible through deep algorithmic advances.  Our research plan builds on the extraordinary successes of tree sequence methods so far, scaling up three crucial layers of computational genomics: analysis, simulation, and inference. First, we will continue our development of highly efﬁcient tree-sequence-based methods for fundamental operations in statistical and population genetics. Second, we will scale up genome simulations by integrating tree sequence methods into complex forward-time simulations, utilizing modern, multicore processors. Third, we will combine efﬁcient genome simulations with cutting-edge deep-learning methods to improve existing inference methods, both of tree sequences from genomic data, and of population parameters from novel tree-sequence encodings of genotype data. Together, we aim to revolutionize the way we work with population genetic variation data, and how we use it to understand human health and evolutionary processes.  Our experienced, interdisciplinary team is committed to producing rigorously tested and validated software and accessible, interoperable, and reusable data formats through inclusive and open development. Narrative We are collecting genetic data at an ever-increasing rate, driven largely by our success in understanding both rare and common diseases using today's vast genomic datasets. Our computational methods are lagging far behind, however, and without fundamental improvements in how we store and process genomic data, we may never fully realize the potential health beneﬁts of the data we are gathering. Our project applies the revolutionary “succinct tree sequence” data structure – which has yielded orders-of-magnitude gains in decades-old problems since its recent introduction – to produce further major gains in fundamental genomics algorithms, genome simulation, and inference from genomic data.",Scaling up computational genomics with tree sequences,10471496,R56HG011395,"['Address', 'Affect', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Base Sequence', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Compression', 'Data Set', 'Development', 'Disease', 'Ecology', 'Ensure', 'Epidemiology', 'Etiology', 'Evolution', 'Genealogical Tree', 'Genealogy', 'Generations', 'Genetic', 'Genetic Processes', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Haplotypes', 'Health', 'Health Benefit', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Internet', 'Libraries', 'Maps', 'Methods', 'Modeling', 'Modernization', 'Mutation', 'Performance', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Positioning Attribute', 'Process', 'Production', 'Recording of previous events', 'Records', 'Research', 'Running', 'Sample Size', 'Sampling', 'Statistical Data Interpretation', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Tsunami', 'Validation', 'Variant', 'Work', 'algorithm development', 'base', 'computer framework', 'cost', 'data format', 'data reuse', 'data structure', 'deep learning', 'design', 'experience', 'frontier', 'genome-wide', 'genomic data', 'human disease', 'improved', 'interoperability', 'learning strategy', 'member', 'multicore processor', 'next generation', 'novel', 'novel strategies', 'open source', 'operation', 'scale up', 'sequence learning', 'simulation', 'statistics', 'structural genomics', 'success', 'supervised learning', 'whole genome']",NHGRI,UNIVERSITY OF OREGON,R56,2021,556834
"Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles PROJECT SUMMARY Genomic and other “omic” profiles hold immense potential for advancing personalize/precision medicine by enabling the accurate prediction of disease phenotypes or outcomes for individual patients, which can be used by a clinician to design an appropriate plan of care. However, despite this potential, the actual impact of these omic profiles on disease phenotype prediction may be limited by the fact that even large cohorts collecting these data do not cover large enough numbers of individuals. In contrast, a variety of clinical data types, such as laboratory tests and physician notes, are routinely collected and studied for a much larger number of patients undergoing treatment for such diseases at medical centers. The abundance of these clinical data, and their complementarity with multi-omic data, offer an opportunity to advance personalized medicine by integrating these disparate types of data. However, this disparity in data formats, namely several omic profiles being structured, and several clinical data types, such as physician notes, being unstructured, poses challenges for this integration. An associated challenge due to this disparity is that different classes of computational methods are likely to be the most effective for predicting disease phenotypes from these clinical and omics datasets. These challenges pose barriers for current data integration methods to address this problem. Here, we propose an innovative approach to this integration by assimilating diverse base phenotype predictors inferred from individual clinical and omics datasets into heterogeneous ensembles. These ensembles, which have shown promise for several other computational genomics problems, can aggregate an unrestricted number and variety of base predictors, which is ideal for this integration problem. Specifically, we describe how existing heterogeneous ensemble methods for single datasets can be transformed and advanced to address the multiple clinical and omic dataset integration problem. In particular, we detail novel algorithms for improving these integrative ensembles by modeling and incorporating the inherent patient and dataset heterogeneity in these datasets. We also propose novel algorithms for leveraging the inherent complementarity among clinical and omic datasets, as well as an innovative approach for handling expected missing data, both with the goal of making ensemble phenotype predictors more accurate and applicable to patient cohorts. To assess the performance of this novel suite of data integration-oriented heterogeneous ensembles, we will validate their effectiveness for predicting asthma and Inflammatory Bowel Disease phenotypes in substantial patient cohorts with diverse omics and clinical datasets. We will publicly release efficient software implementations of the methods developed in this project to enable others to carry out similar analyses with other diverse data collections. Successful accomplishment of the proposed work will contribute to the advancement of personalized medicine through accurate individualized prediction of disease phenotypes. Predictive modeling is expected to become a cornerstone on the path to achieving precision/personalized medicine, as one of the key tasks here will be making individualized predictions of disease characteristics/phenotypes like subtype and risk of progression and/or recurrence. We propose several innovative computational algorithms for developing accurate predictive models that integrate diverse clinical and omic data, as well as several rigorous validation exercises that will demonstrate the capabilities of these models. Successful accomplishment of the proposed work will contribute to the advancement of personalized/precision medicine through more accurate individualized prediction of disease characteristics.",Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles,10218766,R01HG011407,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Disease', 'Disease Outcome', 'Docking', 'Effectiveness', 'Electronic Health Record', 'Encapsulated', 'Exercise', 'Genomics', 'Goals', 'Health', 'Individual', 'Inflammatory Bowel Diseases', 'Institution', 'Laboratories', 'Learning', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Patients', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Recurrence', 'Research Personnel', 'Risk', 'Sampling', 'Structure', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Validation', 'Variant', 'Work', 'advanced disease', 'base', 'clinical phenotype', 'cohort', 'data format', 'data integration', 'deep learning', 'design', 'disease phenotype', 'diverse data', 'feature selection', 'flexibility', 'genomic data', 'heterogenous data', 'improved', 'individual patient', 'innovation', 'insight', 'member', 'multiple datasets', 'multiple omics', 'multitask', 'novel', 'novel strategies', 'outreach', 'patient population', 'personalized medicine', 'personalized predictions', 'precision medicine', 'predictive modeling', 'programs', 'rapid growth', 'repository', 'scale up', 'transcriptomics', 'vector']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,539951
"Genome Informatics For Biobank-scale Data Genetic data of biobank scales offer a wealth of information that is not obvious in traditional smaller cohorts. We will develop and evaluate efficient and accurate algorithms and tools for the analysis of such data to reveal such information. In particular, we will develop methods for three main tasks: haplotype phasing refinement, genotype imputation, and relatedness inference. Although mature methods are available for these tasks in traditional smaller data sets, there is still a lack of scalable efficient and accurate methods and tools for handling genomic big data of that scale. Our main observation is that biobank-scale genetic data offer dense connections between individual data points. Unlike traditional methods based on the Li and Stephens hidden Markov models (HMMs), we models each individual using the individual-specific cohort, i.e., all the other individuals that are connected to the individual. We leverage the efficient positional Burrows-Wheeler transformation (PBWT), a foundational data structure for modeling haplotype matching. We were the first to develop a PBWT-based method for identifying IBD segments in biobank-scale cohorts, RaPID. We are also enriched the traditional PBWT data structure and algorithms to efficient haplotype search and allowing dynamic updates. In this application, we leverage our algorithm development expertise and develop an IBD-based algorithm for refining haplotype phasing of very large panels. We will also develop IBD-based algorithms for improving efficiency and cost-effectiveness of genotype imputation using a very large reference panel. In addition, we will develop RaPID-Affin algorithms for efficient and accurate inference of genetic relatedness. Finally, we will benchmark the methods and develop free software for the community. This project will empower modern genetic research by developing efficient informatics tools for very large genotyped cohorts. While large biobank-scale cohort offer new opportunities for genetics research, they also created daunting informatics challenges. We will develop new informatics methods and tools that substantially improve the efficiency and accuracy of the state-of-the-art on haplotype phasing, genotype imputation, and relatedness inference. This project will empower modern genetic research on genetic association studies and population genetics.",Genome Informatics For Biobank-scale Data,10471476,R56HG011509,"['Algorithmic Software', 'Algorithms', 'Benchmarking', 'Big Data', 'Communities', 'Computer software', 'Data', 'Data Set', 'Detection', 'Foundations', 'Genetic', 'Genetic Research', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Individual', 'Informatics', 'Length', 'Measures', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Phase', 'Population', 'Population Genetics', 'Resort', 'Sampling', 'Scheme', 'Special Population', 'Statistical Methods', 'Structural Models', 'Sum', 'Testing', 'Time', 'Update', 'Voting', 'algorithm development', 'base', 'biobank', 'cohort', 'cost', 'cost effectiveness', 'data structure', 'experience', 'genetic association', 'identity by descent', 'improved', 'indexing', 'informatics tool', 'information model', 'innovation', 'machine learning method', 'markov model', 'rare variant', 'software development', 'statistical and machine learning', 'tool']",NHGRI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R56,2021,616069
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"Identifying novel targets for cardioprotection with non-traditional animal models Project Summary/Abstract:  Low-cost sequencing has ushered in a new era of drug discovery that can that utilize genomic information from hundreds of thousands of people. However, humans are a limited resource for identifying novel drug targets, and attempts at therapeutic development often rely on an already well-known set of genes and pathways. Greater potential for discovery exists if we broaden our search throughout the animal kingdom. In particular, animal adaptations for disease resistance have great potential to unearth novel biological pathways to counteract human diseases. Hibernating mammals are an especially rich resource to inspire novel therapeutics as they exhibit numerous transient phenotypes that mirror critical human health problems such as ischemia-reperfusion injury, Alzheimer’s disease, osteoporosis, muscle atrophy, and obesity/diabetes, yet they are able to avoid or reverse pathologies. A systematic understanding of the gene networks utilized to generate the protective and healing phenotypes of hibernators has great potential to reveal novel therapeutic avenues; however, targets that reproduce across independent datasets, including associating with the same phenotype across multiple species have higher likelihood of translating to humans. In this proposal, specifically, we propose to (1) obtain high-throughput phenotypic data to test our platform (2) create a better model for identifying targets based on machine learning and (3) grow our approach into new disease areas. Our long-term vision is to develop a genomics discovery platform centered on hibernating animals for all of the diseases discussed above. We believe that our approach will identify novel therapeutic targets that will translate to humans, and we will advance our discoveries through strategic pharmaceutical partnerships. Project Narrative: Genomic drug discovery leverages data from hundreds of thousands of people, but humans are a limited resource for identifying novel drug targets, and drug developers focus too often on well-known genes and pathways. Animal adaptations for disease resistance, particularly in hibernating mammals, have great potential to unearth novel biological pathways to counteract human diseases as they exhibit phenotypes that mirror diseases such as Alzheimer’s disease, ischemia-reperfusion injury, osteoporosis, muscle atrophy, and obesity/diabetes but are able to avoid or reverse these pathologies. Here we propose to obtain high-throughput phenotypic data to test our platform in order to create a better model for identifying targets based on machine learning and grow our approach into new disease areas.",Identifying novel targets for cardioprotection with non-traditional animal models,10406111,R41HG011577,"['Acute Liver Failure', 'Age', 'Aloral', 'Alzheimer&apos', 's Disease', 'Animal Disease Models', 'Animal Model', 'Animals', 'Apoptosis', 'Area', 'BCL9 gene', 'Biological', 'Biology', 'Brain', 'Categories', 'Collagen', 'Data', 'Data Set', 'Decision Trees', 'Diabetes Mellitus', 'Disease', 'Disease Resistance', 'Etiology', 'Event', 'Exhibits', 'Fibrosis', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Grant', 'Health', 'Hibernation', 'Human', 'Human Genome', 'Hydrogen Peroxide', 'In Vitro', 'Ischemia', 'Lead', 'Liver', 'Liver Failure', 'Logistic Regressions', 'Machine Learning', 'Mammals', 'Medical', 'Methods', 'Modeling', 'Muscle', 'Muscular Atrophy', 'Myocardial Ischemia', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Obesity', 'Osteoporosis', 'Output', 'Paralysed', 'Pathology', 'Pathway interactions', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'RNA Interference', 'Reperfusion Injury', 'Reperfusion Therapy', 'Resistance', 'Resources', 'Sampling', 'Sequence Analysis', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'Spermophilus', 'Testing', 'Time', 'Training', 'Transforming Growth Factor beta', 'Translating', 'Validation', 'Vision', 'Work', 'animal data', 'base', 'cardioprotection', 'cost', 'drug discovery', 'experience', 'genome wide association study', 'genomic data', 'healing', 'heart damage', 'human data', 'human disease', 'hyperphosphorylated tau', 'improved', 'in vitro Model', 'in vivo', 'liver ischemia', 'new therapeutic target', 'novel', 'novel therapeutic intervention', 'novel therapeutics', 'phenotypic data', 'repaired', 'screening', 'tau phosphorylation', 'therapeutic development', 'therapeutic target', 'transcriptome sequencing']",NHGRI,FAUNA BIO INCORPORATED,R41,2021,177278
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10267774,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2021,2075409
"Use of a Machine Learning Approach to Impute Gene Expression in African Americans PROJECT SUMMARY Multi-omics data has been invaluable in understanding the potential mechanisms behind SNP associations. Using paired genomic and transcriptomic data allows investigators to determine the tissue specific effects of non-coding variation. However, most of this type of data exists for mostly European ancestry populations. Linear models have been developed which that can impute gene expression from genotype data  mostly created from the GTEx resource. This resource contains paired genotype and gene expression data on 44 human tissues. Unfortunately, these models are built mostly on European data; they do not perform as well on African American (AA) cohorts. To alleviate this disparity in both knowledge and data we are proposing to use both or own African American paired data as well as public African American data to create linear and machine learning models to impute gene expression. We will then assess the utility of these models in predicting the risk on venous thromboembolism in our ACCOuNT cohort. By building on our current knowledge of transcriptome imputation, we will be advancing these methods to understudies admixed populations. NARRATIVE Paired genomic and transcriptomic data has previously been used to create gene expression imputation models. However, the majority of the data used to create these models were from European Ancestry individuals. We will create both linear and machine learning models using African American data to improve the imputation of gene expression in this understudied population and test the utility of these model to predict venous thromboembolism.",Use of a Machine Learning Approach to Impute Gene Expression in African Americans,10199406,R21HG011695,"['Address', 'African', 'African American', 'Alleles', 'Benchmarking', 'Clinical', 'Clinical assessments', 'Complex', 'Data', 'Data Set', 'European', 'Evaluation', 'Funding', 'Gene Expression', 'Gene Expression Profile', 'Gene Frequency', 'Genes', 'Genetic Variation', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Hepatocyte', 'Hispanics', 'Image', 'Individual', 'Inheritance Patterns', 'Inherited', 'Knowledge', 'Linear Models', 'Linkage Disequilibrium', 'Liver', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mosaicism', 'Multiomic Data', 'Neural Network Simulation', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Heterogeneity', 'Research Personnel', 'Resources', 'Risk', 'Statistical Methods', 'Testing', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'base', 'cohort', 'convolutional neural network', 'deep learning', 'disease phenotype', 'genomic data', 'human model', 'human tissue', 'improved', 'innovation', 'learning strategy', 'monocyte', 'novel', 'novel strategies', 'recruit', 'response', 'tool', 'transcriptome', 'transcriptomics', 'venous thromboembolism', 'whole genome']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2021,239250
"A Data and Administrative Coordinating Center for the Impact of Genomic Variation on Function Consortium Project Summary/Abstract The goals of the IGVF Data Administrative and Coordinating Center (DACC) are to support the IGVF Consortium by defining and establishing a strategy that connects all participants to the project’s science. By creating avenues of access that distribute these data to the greater biological research community, the DACC provides a critical connection between scientific producers and consumers. The IGVF Consortium brings together laboratories that generate complex data types via novel experimental assays, often focusing at the single-cell level of gene expression. This work is extended and regularized by laboratories that integrate these unique data using computational analyses to discover the associations and networks between human variation, chromosomal elements and molecular phenotypes for the purpose of elucidating their complex relationship in human cells and tissues. The DACC’s participation enhances the data created by the consortium through the creation of structured procedures for the verification and validation of all submitted data and providing processes for the documentation of metadata that describe each biological sample and assay method. To facilitate access to all the data created, the DACC will construct a state of the art data warehouse, design and develop robust software to enable data submission, and harden unified data processing pipelines. All experimental and computational results will be made available via the IGVF Portal, developed by the DACC. The Portal will integrate these data resources and provide enhanced search and browsing capabilities, along with powerful web services. The DACC will develop tools for semantically-enhanced graph-based searches of experiment metadata, individual genomic elements, variation and phenotype, and will implement methods to distribute these results in matrices suitable for machine learning. Beyond computational infrastructure to house and distribute consortium data, the DACC will also function as the administrative hub of the IGVF. Consortium science thrives on clear and forthright communication between its component parts, and it is the DACC’s responsibility to manage this relationship. This effort will be facilitated by management of consortium working groups, organization of scientific results and publications, and providing regular reporting and feedback to the Steering committee. To fully support the community, the DACC will act as a service organization, allowing biomedical research to take full advantage of the results from the IGVF. To this end, the DACC will organize and host consortium- focused and user-focused meetings, and will provide documentation via many media including written documentation, video tutorials, webinars, and meeting presentations. The various component projects of the IGVF (DACC, mapping, systematic characterization, genetic network regulation, modeling of genomic variation centers and groups) will be tightly woven together to create the IGVF Consortium. Relevance to Public Health, Project Narrative Through this project we will create a Data Administration and Coordinating Center (DACC) for the NHGRI Impact of Genomic Variation and Function (IGVF), which promises to transform our understanding of the associations between genetic variation and phenotype. Our proposed DACC will serve as the primary administration, communication, outreach and data center for IGVF awardees and provide leadership for standards and processing pipeline implementation, and facilitate FAIR databases and software. Due to our cross-cutting and unparalleled technical expertise in data management, genomics, informatics, network analysis, and privacy-preserving application as well as our role leading a large data coordination center, managing, coordinating data and metadata, as well as creating gold standard knowledgebases, Stanford is in a strong position to serve as the IGVF DACC.",A Data and Administrative Coordinating Center for the Impact of Genomic Variation on Function Consortium,10296944,U24HG012012,"['Biological', 'Biological Assay', 'Biomedical Research', 'Catalogs', 'Cells', 'Cellular Assay', 'Communication', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Coordinating Center', 'Data Set', 'Data Sources', 'Databases', 'Documentation', 'Electronic Mail', 'Elements', 'FAIR principles', 'Feedback', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Graph', 'Human', 'Human Resources', 'Individual', 'Informatics', 'Laboratories', 'Leadership', 'Life', 'Machine Learning', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'National Human Genome Research Institute', 'Ontology', 'Participant', 'Pathway Analysis', 'Phenotype', 'Policies', 'Positioning Attribute', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Role', 'Sampling', 'Science', 'Selection Criteria', 'Semantics', 'Services', 'Software Tools', 'Standardization', 'Structure', 'Students', 'Technical Expertise', 'Techniques', 'Tissues', 'To specify', 'Update', 'Variant', 'Work', 'analysis pipeline', 'base', 'biological research', 'cloud storage', 'complex data', 'computer infrastructure', 'data analysis pipeline', 'data centers', 'data harmonization', 'data management', 'data modeling', 'data resource', 'data submission', 'data warehouse', 'design', 'distributed data', 'expectation', 'experimental study', 'functional genomics', 'genomic variation', 'implementation facilitation', 'improved', 'innovation', 'knowledge base', 'meetings', 'molecular phenotype', 'novel', 'online resource', 'outreach', 'predictive modeling', 'privacy preservation', 'scientific organization', 'service organization', 'social media', 'tool', 'verification and validation', 'web services', 'webinar', 'working group']",NHGRI,STANFORD UNIVERSITY,U24,2021,2739389
"Probabilistic modeling of observational clinical data for high-throughput inference of disease phenotypes PROJECT SUMMARY/ABSTRACT  Today's healthcare infrastructure supports the production and storage of clinical data on a massive scale. A central goal in clinical informatics is to leverage these data to improve our understanding of health and disease. However, a major challenge is the paucity of reliable disease labels in observational data. Disease phenotypes address this issue by summarizing the characteristics of specific diseases in terms of commonly observed clinical variables. Classically, disease phenotypes are engineered via a manual expert-driven approach which fails to scale to large numbers of diseases. Data-driven methods for disease phenotyping aim to obtain large numbers of disease phenotypes by directly modeling large-scale observational clinical data. Such high-throughput methods may scale, but generally cannot guarantee identifiability; that is, inferred phenotypes are not guaranteed to map to specific diseases. In addition, data-driven disease phenotyping methods generally model phenotypes independently with no effort to capture relationships among diseases which would be consistent with our understanding of comorbidities, disease progression trends, and disease type/subtype relationships.  The long-term goal of the proposed research is to support large-scale analysis of observational clinical data by introducing a family of closely related models for high-throughput disease phenotyping which resolve the issue of identifiability and model relationships among diseases. My work is inspired by an unsupervised probabilistic graphical model for high-throughput phenotyping, UPhenome. My objective is to derive, implement, validate, and disseminate UPhenome-based models which will 1) process both biomedical knowledge and clinical data to yield identifiable phenotypes and 2) model co-occurrence, temporal, and hierarchical relationships among inferred phenotypes. My central hypothesis is that UPhenome-based models can support large-scale clinical data analysis by inferring phenotypes that effectively represent the clinical characteristics of specific diseases while also capturing common comorbidities (co- occurrence model), patterns of disease progression (temporal model), and organizing diseases into types and subtypes (hierarchical model). To test this hypothesis, I propose the following aims. Aim 1: I describe Guided UPhenome, a model which process biomedical knowledge and clinical data to yield identifiable phenotypes. The model's capacity for capturing disease-specific traits is evaluated qualitatively by clinical experts, and quantitatively in disease-specific cohort selection tasks versus a gold-standard and a competing algorithm. Aim 2: I detail extensions to UPhenome which allow for modeling of disease relationships. The meaningfulness of these relationships is evaluated qualitatively using a series of custom “intrusion tasks” inspired by the topic modeling literature. Aim 3: I will disseminate UPhenome-based models by ensuring their compatibility with the Observational Medical Outcomes Partnership (OMOP) common data model, and promoting their adoption within the Observational Health Data Sciences and Informatics (OHDSI) community. PROJECT NARRATIVE The high-throughput phenotyping methods I describe in this proposal will serve as powerful tools for exploring disease comorbidities, patterns of disease progression, and resolution of disease subtypes from observational clinical data. When adopted and applied broadly across a network of clinical institutions, such as the Observational Health Data Sciences and Informatics (OHDSI) collaborative, these methods could potentially power disease-oriented analysis on a massive population spanning the breadth of the nation. Such large-scale analysis would no doubt yield critical insights as to patterns of disease which would be of use in the study and understanding of public health.",Probabilistic modeling of observational clinical data for high-throughput inference of disease phenotypes,10181074,F31LM012894,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Biological Process', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communities', 'Consumption', 'Custom', 'Data', 'Data Analyses', 'Data Science', 'Disease', 'Disease Progression', 'Disease model', 'Electronic Health Record', 'Engineering', 'Ensure', 'Family', 'Goals', 'Gold', 'Health', 'Healthcare', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Knowledge', 'Label', 'Literature', 'Manuals', 'Maps', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pattern', 'Phenotype', 'Population', 'Process', 'Production', 'Public Health', 'Research', 'Resolution', 'Running', 'Series', 'Statistical Models', 'System', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'cohort', 'comorbidity', 'data modeling', 'design', 'disease phenotype', 'disorder subtype', 'health data', 'improved', 'insight', 'knowledge base', 'public health research', 'repository', 'tool', 'trait', 'trend']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,F31,2021,51036
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,10168611,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,315727
"Efficient nonparametric estimation of heterogeneous treatment effects in causal inference PROJECT SUMMARY In nearly all studies of comparative effectiveness, the investigators seek to estimate how an in- tervention changes outcomes on average. That is, are outcomes for treated subjects better on average than for untreated subjects? While the average treatment effect (ATE) is a useful sum- mary of the treatment effect, the treatment effect may vary from patient to patient. The ATE is a low-dimensional summary of a treatment effect, since it summarizes the overall effect of the treatment using a single quantitative measure and ignores possible effect heterogeneity. Many in- vestigators seek to go beyond low-dimensional summaries by estimating heterogenous treatment effects (HTEs). The most common approach to the estimation of HTEs relies on simple statistical methods. Specifically, regression models are widely used but may be biased due to the linear functional form especially where HTEs that are nonlinear or based on complex combinations of patient subgroups. Currently, there is considerable interest in developing more flexible methods for the estimation of the HTEs. In this project, we will use the the doubly robust machine learning (DRML) framework to develop improved methods for a variety of HTEs. The DRML framework is a combination of semiparametric theory, machine learning (ML) methods, and doubly robust estimators. The key advantage of the DRML framework is that it allows one to reduce bias using ML estimation methods, while retaining the efficiency of parametric models. PROJECT NARRATIVE Our project will develop methods for the nonparametric estimation of heterogenous treatment effects (HTEs). We will (1) develop methods for HTEs that vary with baseline variables, (2) develop HTE methods for IV designs, and for time-varying effects, and (3) we will apply the methods to three original applications.",Efficient nonparametric estimation of heterogeneous treatment effects in causal inference,10297407,R01LM013361,"['Abdomen', 'Age', 'Benchmarking', 'Caring', 'Clinical', 'Clinical Research', 'Comparative Effectiveness Research', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Development', 'Dimensions', 'Educational workshop', 'Effectiveness', 'Emergency Situation', 'Endometrial Carcinoma', 'Ensure', 'Healthcare', 'Heterogeneity', 'Hospital Nursing', 'Intervention', 'Machine Learning', 'Masks', 'Measures', 'Methods', 'Modeling', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Property', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Variant', 'Work', 'base', 'care outcomes', 'comparative effectiveness study', 'design', 'dosage', 'experience', 'flexibility', 'high dimensionality', 'improved', 'individualized medicine', 'innovation', 'interest', 'machine learning method', 'non-compliance', 'novel', 'patient population', 'patient subsets', 'randomized trial', 'semiparametric', 'simulation', 'software development', 'study population', 'theories', 'tool', 'treatment effect', 'treatment strategy']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2021,364126
"Guiding humans to create better labeled datasets for machine learning in biomedical research PROJECT SUMMARY / ABSTRACT Machine learning (ML) has seen tremendous advances in the past decade, fueled by growth in computing and the availability of large labeled datasets. While the impact of these advances on clinical and biomedical research are potentially significant, these applications face unique challenges due to the difficulty in acquiring labels from biomedical experts. Furthermore, ML algorithms often fail to generalize across institutions or datasets due to measurement biases (e.g. MR scanners) or intrinsic demographic or biological differences between cohorts / datasets which limits their impact in biomedical science. This proposal will develop new methodology and open-source software that biomedical data scientists can use with their applications to 1. Improve data labeling by identifying the best samples for labeling that provide the most benefit for training ML algorithms; 2. Improve generalization of ML models across institutes; and 3. Perform this work on scalable cloud platforms. We will first explore how to improve upon methods known as active learning that interactively construct labeled datasets by having an algorithm select samples that address its weaknesses and present these samples to an expert for labeling. We will then investigate how these samples can be selected to improve the performance of ML algorithms across multiple institutions by learning robust patterns that are not specific to any one site. Finally, we will develop an extendable software framework that developers can integrate into their own applications to take advantage of these methods, and that can operate on cloud platforms to support scalable analysis of large datasets. This work will be developed through a combination of simulation studies using a unique repository of over 280,000 human markups of digital pathology images at multiple institutions, and also user studies of the developed software frameworks focused on applications in perinatal pathology and the human placenta. The software tools will impact a broad variety of biomedical applications beyond pathology where data labeling and multi-institutional studies remain challenging. PROJECT NARRATIVE / PUBLIC HEALTH RELEVANCE Machine learning tools can help biomedical researchers to understand their data or to make predictions. Acquiring labeled examples from biomedical experts is a significant limitation in developing machine learning tools. These tools also often fail to generalize beyond the datasets used for tool development. Improving the efficiency of data labeling and generalization would increase the impact of these tools in biomedical research.",Guiding humans to create better labeled datasets for machine learning in biomedical research,10298684,R01LM013523,"['Active Learning', 'Address', 'Algorithms', 'Bayesian neural network', 'Biological', 'Biomedical Research', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Computer Systems', 'Computer software', 'Data', 'Data Scientist', 'Data Set', 'Databases', 'Environment', 'Face', 'Fetal health', 'Funding', 'Growth', 'High Performance Computing', 'Histologic', 'Human', 'Image', 'Institutes', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Machine Learning', 'Maternal Health', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathologist', 'Pathology', 'Pattern', 'Performance', 'Perinatal', 'Placenta', 'Process', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Software Framework', 'Software Tools', 'Source', 'Structure', 'Tissue imaging', 'Training', 'Work', 'algorithm training', 'base', 'cloud platform', 'cohort', 'computing resources', 'deep learning', 'deep learning algorithm', 'digital pathology', 'experience', 'feature extraction', 'hands-on learning', 'human-in-the-loop', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'malignant breast neoplasm', 'multidimensional data', 'novel strategies', 'open source', 'pathology imaging', 'public health relevance', 'repository', 'simulation', 'software development', 'tool', 'tool development', 'unsupervised learning', 'whole slide imaging']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,430928
"Rule-based machine learning to address heterogeneity in high-dimensional survival data Project Summary In the post-genomic era, researchers are met with an abundance of data to analyze and interpret. Genome- wide association analyses (GWAS) often boast millions of single-nucleotide polymorphisms (SNPs), alongside increasingly large epigenomic, transcriptomic, proteomic (multi-omic) and other data sets. While the current standard in genetic epidemiology emphasizes increased sample sizes, we propose that substantial progress can be made by developing improved methods to analyze the vast amount of multi-omic data that currently exists. A number of methodological challenges including dimensionality and the multiple testing burden have limited the success of many approaches thus far. Furthermore, only considering simple, linear associations leaves out the more likely scenario of complex genetic and multi-omic relationships driving risk and outcomes in common diseases. Heterogeneity is just one of the complex mechanisms that underlies disease risk and outcomes, but is arguably among the most difficult to model and detect. This project tackles this and other challenges in glioma, a highly heterogeneous cancer type. Improving upon available treatment strategies in cancer and glioma specifically will undoubtedly require a full characterization of genetic heterogeneity and epigenetic mechanisms. In addition to confronting the dimensionality of genetic and epigenetic data using a feature selection strategy that can detect both main effects and interaction and preserve heterogeneity, we will modify an existing method for detecting heterogeneity to accommodate censored survival data. First, in Aim 1, we will use simulated genetic survival data to establish the utility of a Relief-based feature selection algorithm in capturing complex genetic architectures (i.e., main effects, heterogeneity, and epistasis). We will compare it against standard approaches for high-dimensional feature selection of survival data. Aim 2 updates a learning classifier system (LCS), a type of rule-based machine learning that uses IF/THEN rules to model complex and heterogeneous problem spaces. To our knowledge, no LCS that handles censored survival data has been developed to date. After testing our survival LCS on simulated data and comparing it to standard survival methods, in Aim 3 we will implement it using somatic mutation and methylation data from the TCGA glioma dataset. Finally, as part of Aim 3, we will perform a pathway analysis using the LCS output in an effort to identify common biological pathways underlying heterogeneous associations. We will also utilize a network visualization tool to better understand interactions between features and provide a visual interpretation of the results. Findings from this project will lay the foundation for precision care and treatment of glioma. Our innovative approach to high-dimensional, heterogeneous survival data will be both generalizable and interpretable, qualities that are missing from current machine learning approaches. This project and the accompanying training plan undeniably provide an ideal setting to develop the skills and experience necessary to become and independent investigator at the forefront of genetic epidemiology and informatics. Project Narrative Current approaches to analyzing genetic and other large data sets fail to suitably model heterogeneity – a phenomenon where different mechanisms give rise to the same disease; these methods similarly struggle with capturing interactions and other complex patterns of association. A full characterization of this complexity is necessary to fully understand and predict risk and outcomes in common diseases. Using both simulated and publicly available survival data, this proposal will develop and evaluate a machine learning method for identifying important variables and making predictions in the context of complex associations.",Rule-based machine learning to address heterogeneity in high-dimensional survival data,10141575,F31LM013583,"['Address', 'Adult', 'Age', 'Algorithms', 'Alkylating Agents', 'Architecture', 'Automobile Driving', 'Biological', 'Brain Neoplasms', 'Cancer Prognosis', 'Cells', 'Clinical', 'Complex', 'Cox Models', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Integration', 'DNA Methylation', 'DNA Sequence', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Disease Outcome', 'Drug Targeting', 'Elements', 'Epigenetic Process', 'Foundations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Heterogeneity', 'Genetic Models', 'Genetic Transcription', 'Genomics', 'Glioma', 'Head', 'Heritability', 'Heterogeneity', 'Histones', 'Hypermethylation', 'Incidence', 'Informatics', 'Intervention', 'MGMT gene', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Methylation', 'MicroRNAs', 'Modeling', 'Modification', 'Molecular', 'Multiomic Data', 'Outcome', 'Output', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Performance', 'Persons', 'Pharmacology', 'Phenotype', 'Play', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Primary Brain Neoplasms', 'Prognosis', 'Promoter Regions', 'Proteomics', 'RNA', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'Single Nucleotide Polymorphism', 'Somatic Mutation', 'System', 'Testing', 'The Cancer Genome Atlas', 'Training', 'Treatment Efficacy', 'Update', 'Validation', 'Visual', 'Visualization', 'Visualization software', 'base', 'cancer heterogeneity', 'cancer risk', 'cancer type', 'data modeling', 'deep learning', 'disorder risk', 'epigenomics', 'experience', 'feature selection', 'forest', 'genetic analysis', 'genetic architecture', 'genetic epidemiology', 'genome wide association study', 'genome wide methylation', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'large datasets', 'learning classifier', 'machine learning method', 'multidimensional data', 'multiple omics', 'novel', 'personalized approach', 'personalized care', 'potential biomarker', 'preservation', 'promoter', 'skills', 'success', 'survival prediction', 'temozolomide', 'therapeutic target', 'therapy resistant', 'tool', 'transcriptomics', 'treatment response', 'treatment strategy', 'tumor', 'tumor progression']",NLM,UNIVERSITY OF PENNSYLVANIA,F31,2021,46036
"Machine learning algorithms to analyze large medical image datasets Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. Our overall objective for this research is to dramatically reduce the burden of creating high quality reference labels by requiring only a small set of such labels from experts. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. This will enable us to apply ML techniques to generate high quality labels of the large amounts of unlabeled data that are already available, which in turn will facilitate the assessment of potential quantitative imaging biomarkers. We will develop, extend and evaluate novel algorithms that represent three distinct strategies for reducing labelling cost. These three strategies are learning from unlabelled data incorporating a novel strategy for characterizing uncertainty, optimizing sample selection for expert quality labelling with a novel form of Active Learning especially suited for deep learning, and reducing the cost of achieving quality labeling by replacing or augmenting an expert with a crowd of inexperts. We will then implement and distribute these novel algorithms, facilitating the replication of our experiments. Finally, we will demonstrate the practical efficacy of these three strategies by applying them to the important challenge of identifying quantitative imaging biomarkers that best capture alterations in brain structure that are associated with characteristics of ASD. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes. Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes.",Machine learning algorithms to analyze large medical image datasets,10182522,R01LM013608,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'Benchmarking', 'Brain', 'Characteristics', 'Child', 'Clinical', 'Collection', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Fatigue', 'Image', 'Image Analysis', 'Informatics', 'Interruption', 'Label', 'Learning', 'Life', 'Machine Learning', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Noise', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Reference Standards', 'Research', 'Sampling', 'Speed', 'Structure', 'Techniques', 'Training', 'Uncertainty', 'Update', 'autism spectrum disorder', 'base', 'clinical decision-making', 'cost', 'crowdsourcing', 'deep learning', 'design', 'experimental study', 'imaging Segmentation', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'novel', 'novel strategies', 'prevent', 'quantitative imaging', 'radiologist', 'success', 'supervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,369580
SCH: Enabling Data Outsourcing and Sharing for AI-powered Parkinson's Research RELEVANCE (See instructions): n/a,SCH: Enabling Data Outsourcing and Sharing for AI-powered Parkinson's Research,10435804,R01LM014027,"['Artificial Intelligence', 'Biomedical Research', 'Classification', 'Cloud Computing', 'Complex', 'Consumption', 'Data', 'Data Set', 'Disease', 'Foundations', 'Institutes', 'Instruction', 'Joint Prosthesis', 'Laws', 'Lead', 'Machine Learning', 'Masks', 'Mathematics', 'Medical', 'Methods', 'Modeling', 'Modernization', 'Neural Network Simulation', 'Non-linear Models', 'Outcome', 'Outsourcing', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patients', 'Performance', 'Privacy', 'Quality of life', 'Regulation', 'Research', 'Series', 'Source', 'Technology', 'Theoretical Studies', 'Time', 'Training', 'University Hospitals', 'Work', 'accurate diagnosis', 'artificial neural network', 'base', 'biomedical informatics', 'cloud based', 'cloud storage', 'cost', 'data privacy', 'deep learning', 'deep neural network', 'digital', 'distributed data', 'encryption', 'experimental study', 'imaging genetics', 'improved', 'individualized medicine', 'mobile computing', 'novel', 'operation', 'privacy preservation', 'privacy protection', 'theories']",NLM,UNIVERSITY OF FLORIDA,R01,2021,298653
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Improving Hypertension Treatment in African Americans Using Computational Modeling and Predictive Analytics ABSTRACT As compared to whites, African Americans (AA) develop hypertension (HTN) at an earlier age, have a greater frequency and severity of HTN, poorer control of blood pressure (BP), and have twice the mortality rate from HTN. For 47 years our department has been developing computer simulations of integrative physiology for research purposes. The current model, HumMod, is comprised of 14 organ systems, and includes neural, endocrine, circulatory, and renal physiology. We have created tools that generate and analyze large cohorts of computer-generated (virtual) patients. With these techniques HumMod has been used for hypothesis generation and for understanding underlying physiological mechanisms that are not able to be determined in either whole animal or human experiments. This proposed work will use these tools and this mathematical model of human physiology to develop a realistic AA virtual population for studying antihypertensive therapies that have well-known (diuretic or salt reduction), variable (angiotensin converting enzyme, or ACE inhibition), or unclear (renal denervation (RDX), and baroreflex activation therapy (BAT) therapeutic efficacies in AA. Published data from our laboratory show that our model is robust and can realistically simulate salt sensitivity, multiple types of HTN, and device-based antihypertensive therapy. As shown in our preliminary data, we have successfully created a virtual population that was similar to the clinical data (AA population with resistant HTN) in 5-dimensions (blood pressure, heart rate, glomerular filtration rate, cardiac output, and peripheral resistance) and have conducted in silico trials for new device-based therapy currently being evaluated for the treatment of resistant HTN—namely RDX, BAT, and arteriovenous fistula. Based on these preliminary data, we hypothesize that these techniques will allow us to investigate the physiological mechanisms responsible for the variation in response to therapy in a wide range of AA patient types and predict the likelihood of success for a particular treatment. Aim 1 of the proposal will test the hypothesis that a virtual AA population with resistant HTN can be successfully calibrated and validated. Aim 2 of the proposal will test the hypothesis that in silico trials using the calibrated populations from the first Aim can be used for testing and predicting mechanisms of nonresponse to device-based antihypertensive therapies. Aim 3 will test the hypothesis that our predictive analytic techniques can be used to identify mechanisms and proxy markers of therapeutic resistance in hypertensive AA. These proposed studies have clinical relevance because they address a leading cause of morbidity and mortality as well as potential mechanisms of therapeutic resistance in an underserved and understudied minority. Furthermore, these applications and the potential insights gleaned from our physiological model and predictive analytic tools may have broad implications for BP control in other resistant hypertensive populations. PROJECT NARRATIVE African Americans develop hypertension and its co-morbidities at an earlier age, have a greater frequency and severity of hypertension, have poorer control of blood pressure, and die disproportionately (2-fold) more from hypertension as compared to whites. Despite these known disparities, there has been little attention or advancement in the management of blood pressure in the African American population. Our laboratory’s advanced physiological model paired with novel analytic tools may mechanistically predict the types of patients that should respond to therapy, ultimately improving patient drug regimens and their success rate in this underserved and understudied population.",Improving Hypertension Treatment in African Americans Using Computational Modeling and Predictive Analytics,10268976,K99MD014738,"['Address', 'African American', 'Age', 'Aldosterone Antagonists', 'Angiotensin II', 'Animals', 'Antihypertensive Agents', 'Arterial Disorder', 'Arteriovenous fistula', 'Attention', 'Baroreflex', 'Blood Pressure', 'Calcium Channel', 'Cardiac Output', 'Clinical', 'Clinical Data', 'Clinical Treatment', 'Complex', 'Computer Models', 'Computer Simulation', 'Controlled Study', 'Data', 'Denervation', 'Development', 'Devices', 'Dimensions', 'Disease', 'Diuretics', 'Endocrine', 'Feedback', 'Frequencies', 'Generations', 'Genomics', 'Glean', 'Glomerular Filtration Rate', 'Heart Rate', 'High Prevalence', 'Hormonal', 'Human', 'Hypertension', 'Jackson Heart Study', 'Kidney', 'Laboratories', 'Literature', 'Machine Learning', 'Mentors', 'Minority', 'Modeling', 'Morbidity - disease rate', 'Obesity', 'Patients', 'Pattern', 'Peptidyl-Dipeptidase A', 'Peripheral Resistance', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Physiological', 'Physiology', 'Population', 'Predictive Analytics', 'Prevalence', 'Probability', 'Process', 'Proxy', 'Publishing', 'Regimen', 'Research', 'Resistance', 'Resistant Hypertension', 'Severities', 'Socioeconomic Factors', 'Sodium Chloride', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Efficacy', 'Variant', 'Work', 'analytical tool', 'base', 'blood pressure regulation', 'body system', 'clinically relevant', 'cohort', 'comorbidity', 'computer generated', 'data warehouse', 'experimental study', 'genetic epidemiology', 'human model', 'hypertension control', 'hypertension treatment', 'improved', 'in silico', 'insight', 'machine learning algorithm', 'mathematical model', 'mortality', 'novel', 'patient population', 'patient response', 'physiologic model', 'relating to nervous system', 'resistance mechanism', 'response', 'simulation', 'success', 'therapeutic biomarker', 'therapy resistant', 'tool', 'virtual', 'virtual model', 'virtual patient']",NIMHD,UNIVERSITY OF MISSISSIPPI MED CTR,K99,2021,101117
"Enhancing Diversity through IHSAN (Interdisciplinary Health disparities and data Science trAiNing) PROJECT SUMMARY/ABSTRACT To address the gap in expertise in data science in some RCMI U54 Centers, we propose developing a coordinated RCMI Data Science Initiative with two goals: (1) Upskilling RCMI investigators in data science, including tools, methods, and best practices with a focus on reproducible data analysis and effective knowledge mobilization around health disparities and (2) Incentivizing collaborations at the nexus of data science and health disparities between investigators within and outside of the RCMI consortium. Our specific aims are: 1. To enhance the data science capacity of RCMI investigators across the RCMI consortium by collaboratively developing a project-based curriculum and organizing workshops introducing data science fundamentals and tools as well as NIH-funded resources and datasets relevant to minority health disparities. Investigators will learn how to access data from the All of Us research workbench, link it to community-level datasets available on Google’s Cloud Platform, create visualizations, build and evaluate machine learning models, and upload replication files into a repository using R, SQL, and Git. 2. To stimulate data science collaborations across U54 centers as well as between U54 and non-RCMI institutions by organizing Data Science and Health Disparities Demo Days and launching Enrichment awards to support development of collaborative research projects. Our goal is to provide financial support to develop promising research collaborations into proposals for pilot funding. Our long term goal is to leverage existing partnerships with the Atlanta University Center (AUC) Data Science Initiative, the Georgia CTSA, and the National Research Mentoring Network (NRMN) to build a well-coordinated infrastructure to support collaboration between RCMI and non RCMI investigators, and train the next generation of diverse investigators leveraging advances in data science and machine learning to address minority health and health disparities in the 21st century. PROJECT NARRATIVE The RCMI Coordinating Center Data Science Initiative will leverage existing partnerships with the Atlanta University Center (AUC) Data Science Initiative, the Georgia CTSA, and the National Research Mentoring Network (NRMN) to build a well-coordinated infrastructure to support collaboration between RCMI and non RCMI investigators, and train the next generation of diverse investigators.",Enhancing Diversity through IHSAN (Interdisciplinary Health disparities and data Science trAiNing),10452040,U24MD015970,"['Address', 'Award', 'Behavioral', 'Biomedical Research', 'Biometry', 'Collaborations', 'Communities', 'Coupled', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Set', 'Development', 'Diagnosis', 'Discipline', 'Economic Factors', 'Educational workshop', 'Environmental Risk Factor', 'Evaluation', 'Financial Support', 'Fostering', 'Funding', 'Gap Junctions', 'Goals', 'Hispanics', 'Incentives', 'Indigenous', 'Informatics', 'Infrastructure', 'Institution', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Mentors', 'Methods', 'Minority-Serving Institution', 'Modeling', 'Needs Assessment', 'Pathway interactions', 'Positioning Attribute', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Sharing', 'Resources', 'Respondent', 'Scientist', 'Talents', 'Training', 'Underrepresented Populations', 'United States National Institutes of Health', 'Universities', 'Visualization', 'biomedical data science', 'cloud platform', 'community engagement', 'data access', 'disparity reduction', 'faculty mentor', 'health data', 'health disparity', 'health equity promotion', 'improved', 'innovation', 'inter-institutional', 'investigator training', 'learning progression', 'minority health', 'next generation', 'programs', 'project-based learning', 'repository', 'skills', 'social factors', 'student participation', 'student training', 'technological innovation', 'tool', 'underserved community']",NIMHD,MOREHOUSE SCHOOL OF MEDICINE,U24,2021,355000
"Machine learning-enabled Comparative Transcriptomic Profiling to Validate NanoScript-induced Inner Ear Hair Cells PROJECT SUMMARY  Hearing loss during early childhood significantly affects learning and acquisition of social skills, while hearing loss in adults can often result in social isolation and the inability to perform many routine social functions. A leading cause of sensorineural hearing loss is the loss of sensory hair cells of the inner ear. A lifetime exposure to aminoglycoside and loud sounds will result in an estimated 15% of adult Americans (~36 million) having some form of hearing loss. A promising approach to mitigate hearing loss and deafness is a cell replacement therapy by transdifferentiating supporting cells into hair cells. Unfortunately, current approaches for transdifferentiation rely on viral delivery may be unsafe and impractical for clinical translation. Therefore, there is a critical need to develop alternative platforms for regulating gene expression and inducing transdifferentiation in an efficient, non- viral manner that is suitable for restoration of hearing.  To this end, our long-term goal is to develop NanoScript, an innovative, tunable nanoparticle-based artificial transcription factor platform capable of effectively regulating gene expression in a non-viral manner. Using NanoScript, we will transdifferentiate supporting cells into functional hair cells. NanoScript consists of a nanoparticle functionalized with specific small molecules and peptides that are designed to mimic the individual domains of natural transcription factor (TF) proteins. TFs are endogenous, multi-domain proteins that orchestrate many cellular functions, including differentiation. Since NanoScript is a functional replica of TF proteins, it can replace virally-delivered TFs for regenerative medicine-based applications. The overall objective of this proposal is to design three NanoScripts that mimic three TFs essential for hair cell differentiation (Gfi1, Pou4f3, and Atoh1; GPA). We will test whether GPA-NanoScript binds to the same DNA sequence and activate gene expression in vitro. Next, we will determine if the addition of epigenetic modulators to GPA-NanoScript will bind to the same targets as the TF proteins, locally alter the chromatin structure and enhance gene expression. Finally, we will use cochlear explants to determine whether GPA-NanoScript promotes transdifferentiation of supporting cells into hair cells by single-cell transcriptome analysis. Generation of nascent hair cells using an ex vivo model will serve as a springboard to test NanoScript technology for regenerative medicine. It will also establish NanoScript as an effective and non-viral tool for researchers to generate functional cells via direct reprogramming. PROJECT NARRATIVE This is an application for an administrative artificial intelligence and machine learning (AI/ML) supplement [PA- 20-272 and NOT-OD-21-094] to parent award 5R01DC016612, Lee, KiBum (PI). To address the challenges associated with studying a complex inner hair cells (IHCs) environment with only a limited number of observations, such as induced measurement bias and irreproducibility of experimental results, we propose to develop a conditional adversarial network to recapitulate the transcriptomes of inner and outer hair cells to supplement downstream analysis. Then, we will validate our AI/ML experiments by comparing the transcriptomes of differentiated iMOP cells to the generated transcriptomes by examining the Pearson correlation between marker genes and sequencing experiments.",Machine learning-enabled Comparative Transcriptomic Profiling to Validate NanoScript-induced Inner Ear Hair Cells,10412274,R01DC016612,"['Address', 'Adult', 'Affect', 'American', 'Aminoglycosides', 'Artificial Intelligence', 'Award', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Biomimetics', 'Cartilage', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Characteristics', 'Chromatin Structure', 'Cochlea', 'Complex', 'DNA Sequence', 'Data', 'Data Files', 'Data Set', 'Development', 'Eating', 'Elements', 'Endogenous Factors', 'Ensure', 'Environment', 'Epigenetic Process', 'Exposure to', 'GFI1 gene', 'Gene Expression', 'Generations', 'Genes', 'Genotype', 'Goals', 'Grant', 'Hair Cells', 'Human', 'In Vitro', 'Individual', 'Inner Hair Cells', 'Labyrinth', 'Learning', 'Loudness', 'Machine Learning', 'Measurement', 'Modeling', 'Mus', 'Muscle', 'Nerve Degeneration', 'Neurons', 'Outer Hair Cells', 'Parents', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Performance', 'Phenotype', 'Proteins', 'Publications', 'Regenerative Medicine', 'Research Personnel', 'Sample Size', 'Sampling', 'Sensorineural Hearing Loss', 'Sensory Hair', 'Social Functioning', 'Social isolation', 'Source', 'Supporting Cell', 'Technology', 'Tertiary Protein Structure', 'Testing', 'United States National Institutes of Health', 'Viral', 'afferent nerve', 'base', 'bone', 'bony labyrinth', 'cell replacement therapy', 'cell type', 'clinical translation', 'comparative', 'deafness', 'design', 'differential expression', 'early childhood', 'experimental study', 'hearing impairment', 'hearing restoration', 'in silico', 'innovation', 'mRNA Differential Displays', 'machine learning method', 'membranous labyrinth', 'nanoparticle', 'nerve damage', 'overexpression', 'postnatal', 'single-cell RNA sequencing', 'small molecule', 'social skills', 'sound', 'stem cell differentiation', 'supplemental instruction', 'tool', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'transdifferentiation', 'web site']",NIDCD,"RUTGERS, THE STATE UNIV OF N.J.",R01,2021,311115
"The development and validation of a novel tool for the assessment of bulbar dysfunction in ALS Project Summary  The overall aim of our “parent” grant proposal is to develop and validate a clinician-administered bulbar dysfunction assessment tool for Amyotrophic Lateral Sclerosis (ALS), called ALS-Index of Bulbar Dysfunction (ALS-IBD). Interrupted by the SARS-CoV-2 pandemic, clinical practices as well as clinical research have been forced to pivot, simultaneously providing an unprecedented opportunity for the development of new and expansion of existing remote assessment platforms, which can serve clinical and research assessment needs. As part of this pivoting effort, we recently created VirtualSLP, a software tool to support remote, online multi- modal - high quality video/kinematic and audio/acoustic – data collection, using a multi-platform compatible, web-browser based audio and video recordings. In parallel, we have designed a tool for automatic extraction of kinematic and acoustic metrics of neurological diseases, which provides clinically interpretable features/ measures that have been identified as important for detecting and tracking the onset and progression of oro- motor and speech (aka bulbar) impairments in neurological diseases. The next step in the progression of our technology development efforts is to incorporate the automatic metrics extraction software within VirtualSLP, creating a user-friendly and intuitive cloud-based platform for research and clinical assessment of bulbar dysfunction. To achieve rapid development and deployment of VirtualSLP, we will use modern engineering methodology and user-centered design to iterate through a number of steps in the software development cycle. The cycle will begin with the engagement of end users (e.g., researchers, clinicians and patients) in design sessions to document users' current and anticipated end-to-end experiences with the software, while performing the baseline analysis of the existing software components and determining and implementing necessary changes. The necessary components will be incorporated to create VirtualSLP on the Amazon Web Services (AWS) platform, to enhance its usability, interoperability, scalability, and security, as part of the NIH STRIDES initiative. Usability testing of Virtual SLP with end users will be performed throughout the development process and at the end of the development cycle. When completed, the work will result in an enhanced software tool for collection of audio and video data and corresponding AI-based analytics to be used in the context of clinical research. VirtualSLP will propel our specific work on developing a clinician- administered tool for bulbar ALS assessment and monitoring (ALS-IBD-Remote) by providing a novel cloud- based platform for its clinical validation. This work aims to exemplify the intent of the current funding opportunity by supporting collaborations between clinical speech scientists, data scientists, and software engineers to enhance the design, implementation, and ""cloud-readiness"" of research software. Project Narrative  The current proposal focuses on the development of VirtualSLP, a software tool for video and audio data collection and automatic AI-based analytics to be used in the context of clinical research. VirtualSLP will propel our specific work on developing a clinician-administered tool for the assessment and monitoring of bulbar ALS, as well as other neurological diseases, by providing a novel cloud-based platform for validation of remote assessment. The development of VirtualSLP will follow the best practices of software engineering using the enterprise architecture framework and agile methodology, with focus on inclusive, user-centered design.",The development and validation of a novel tool for the assessment of bulbar dysfunction in ALS,10405152,R01DC017291,"['Acoustics', 'Affect', 'Amyotrophic Lateral Sclerosis', 'Applications Grants', 'Architecture', 'Artificial Intelligence', 'Aspiration Pneumonia', 'Assessment tool', 'Back', 'COVID-19 pandemic', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Collaborations', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analytics', 'Data Collection', 'Data Scientist', 'Deglutition', 'Dehydration', 'Development', 'Dysarthria', 'Engineering', 'Evaluation', 'Event', 'Face', 'Functional disorder', 'Funding Opportunities', 'Goals', 'Guidelines', 'Impairment', 'Internet', 'Interruption', 'Intuition', 'Length', 'Malnutrition', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modernization', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Myography', 'Needs Assessment', 'Neurologic', 'Outcome Measure', 'Parkinson Disease', 'Patients', 'Performance', 'Persons', 'Process', 'Quality of life', 'Readiness', 'Research', 'Research Personnel', 'Scientist', 'Security', 'Signal Transduction', 'Software Design', 'Software Engineering', 'Software Tools', 'Speech', 'Standardization', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Validation', 'Video Recording', 'Work', 'base', 'clinical examination', 'clinical practice', 'cloud based', 'cloud platform', 'data management', 'data sharing', 'design', 'electric impedance', 'experience', 'indexing', 'interoperability', 'kinematics', 'motor disorder', 'movement analysis', 'multimodality', 'nervous system disorder', 'novel', 'orofacial', 'pandemic disease', 'parent grant', 'post stroke', 'social', 'software development', 'technology development', 'telehealth', 'tool', 'usability', 'user centered design', 'user-friendly', 'virtual', 'web services']",NIDCD,SUNNYBROOK RESEARCH INSTITUTE,R01,2021,186859
"Characterizing the primary olfactory subregions of the human amygdala Several subregions of the human amygdala receive direct projections from the olfactory bulb, yet the functional and anatomical properties of these olfactory projections are not well understood. Rodent studies have begun to shed light on the functions of some of these olfactory amygdala subregions in mediating olfactory-guided social and approach/avoid behaviors. However, there are significant differences in the projections from the olfactory bulb to the amygdala between species. For example, in rodents, the medial amygdala receives highly dense fibers from the accessory olfactory bulb. In stark contrast, humans lack an accessory olfactory system entirely. There are also other apparent differences in the specific amygdalar targets of main olfactory bulb projections between species, although these targets have not been well-characterized in humans, further highlighting the need for human studies in this area. The goal of this proposal is to characterize the anatomical and functional properties of the olfactory projections into the human amygdala. We will take a multifaceted approach, combining functional neuroimaging, electrophysiology and stimulation, which will strengthen the reproducibility and rigor of our findings. The goal of Aim 1 is to anatomically and functionally localize the primary olfactory cortical regions of the human amygdala. At the structural level, we will use a novel new multi- shot diffusion-weighted imaging sequence to localize olfactory projections into amygdala subregions. At the functional level, we will use resting fMRI combined with k-means clustering algorithms to parcellate amygdalar subregions based on distinct whole-brain functional connectivity profiles, and event-related fMRI to functionally localize odor-responsive subregions of the amygdala. The goal of Aim 2 is to shed light on the roles of distinct amygdala subregions in olfactory perception. We will use event-related fMRI to acquire high-resolution multivariate signals from the amygdala during olfactory perceptual tasks. The goal of Aim 3 is to assess the necessity of the amygdala subregions in olfactory perception. We will use intracranial EEG techniques to measure different olfactory perceptual decisions during clinician-delivered, clinically prescribed, disruptive electrical stimulation directly into the human amygdala. The proposed studies will provide a detailed characterization of the functional and anatomical properties of an under-studied group of amygdala subregions, including the medial nucleus of the amygdala, the cortical amygdala and the periamygdaloid cortex. Recent studies suggest these anterior and medial amygdala areas may play a role in sudden unexpected death in epilepsy (SUDEP), which is the leading cause of death in patients with temporal lobe epilepsy and has no known cause or treatment. Furthering our understanding of the functional and structural properties of these brain regions has strong clinical importance for these patients. The amygdala is considered a hub for emotional processing in the brain, and a large body of clinical research implicates it in anxiety disorders, PTSD, other disorders involving emotional dysfunction, and newer research suggests it even plays a key role in sudden unexpected death in epilepsy (SUDEP), the leading cause of death in patients with temporal lobe epilepsy. The amygdala is a heterogeneous structure, though the majority of human amygdala studies do not analyze data from its many subregions separately, limiting our understanding of the specific roles that these subregions play in clinical diseases that affect the amygdala. We plan to conduct a thorough characterization of the anatomical and functional properties of the subregions of the human amygdala, with a special focus on those receiving direct projections from the olfactory bulb, areas which have been implicated in SUDEP, ultimately providing some of the first detailed explorations of human amygdala subregions that are implicated in this disease.",Characterizing the primary olfactory subregions of the human amygdala,10120995,R01DC018539,"['Accessory Olfactory Bulbs', 'Address', 'Affect', 'Algorithms', 'Amygdaloid structure', 'Anatomy', 'Anterior', 'Anxiety Disorders', 'Area', 'Behavior', 'Brain', 'Brain region', 'Cause of Death', 'Cell Nucleus', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Data', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electric Stimulation', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Event', 'Exhibits', 'Fiber', 'Food', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Human', 'Light', 'Measures', 'Medial', 'Mediating', 'Methods', 'Odors', 'Olfactory Cortex', 'Olfactory Pathways', 'Olfactory tract', 'Patients', 'Pattern', 'Play', 'Post-Traumatic Stress Disorders', 'Property', 'Psychophysics', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Rodent', 'Role', 'Series', 'Signal Transduction', 'Smell Perception', 'Structure', 'Techniques', 'Temporal Lobe Epilepsy', 'Testing', 'Time', 'base', 'experimental study', 'neuroimaging', 'novel', 'olfactory bulb', 'relating to nervous system', 'social', 'sudden unexpected death in epilepsy']",NIDCD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,480569
"The Influence of Morphosyntactic Network Complexity on Typical and Atypical Language Learning Project Summary The proposed project details an innovative line of research that draws on advanced tools from the field of network science to elucidate typical and atypical language learning mechanisms in adults. Network analysis of natural language has revealed a number of global structural patterns emerging from relationships (used to construct network edges) between words (used as network nodes). Informed by the naturally-occurring network architecture of real-world languages, we will construct miniature artificial languages that display emergent properties of existing language systems and measure the extent to which these languages are learned by adults with typical development (TD) and those with developmental language disorder (DLD) (Aim 1). Given that DLD is often associated with deficits in processing and producing complex morphosyntax, we will concentrate on networks in which edges between words represent either their co-occurrence in a sentence or overlap in morphological family (e.g., eater, eating). In Aim 2, we will examine whether language learning deficits in adults with DLD might be recast as a hyperfocus on local-level information (i.e., “oddball” structures or individual word frequency) at the expense of the broader architecture of the language learning environment. To strengthen links between deficits in language learning and expressive language, Aim 3 calls for the network analysis of elicited speech samples to reveal whether individuals less sensitive to complexity in learning might also display reduced complexity in their language output. Of individuals diagnosed with receptive and expressive language disorder in childhood, the vast majority continue to struggle with language impairment in adulthood. Despite a pressing need for expansion of adult-oriented language interventions, characterization of the full scope of deficits in individuals with DLD, in addition to their language learning mechanisms beyond childhood, is an understudied area. Project Narrative The proposed project will apply cutting-edge methods from network science to investigate mechanisms of typical and atypical language learning. With a focus on complex grammatical patterns, our work compares learning in young adults with typical development to learning in young adults with expressive and receptive language impairment that has persisted since childhood (Developmental Language Disorder; DLD). A formal characterization of complex pattern sensitivity will inform our understanding of basic mechanisms of language acquisition and may lead to the development of therapeutic interventions tailored to the specific needs of adults with DLD.",The Influence of Morphosyntactic Network Complexity on Typical and Atypical Language Learning,10218819,R21DC018948,"['2 year old', 'Address', 'Adult', 'Architecture', 'Area', 'Blueberries', 'Child', 'Child Language', 'Childhood', 'Complex', 'Dependence', 'Development', 'Diagnosis', 'Eating', 'Employment', 'Environment', 'Exhibits', 'Exposure to', 'Family', 'Frequencies', 'Human', 'Impairment', 'Individual', 'Instinct', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Link', 'Measures', 'Methods', 'Morphology', 'Natural Language Processing', 'Output', 'Participant', 'Pathway Analysis', 'Pattern', 'Population', 'Prevalence', 'Process', 'Production', 'Property', 'Raspberries', 'Records', 'Research', 'Role', 'Sampling', 'Science', 'Semantics', 'Series', 'Signal Transduction', 'Speech', 'Strawberries', 'Structure', 'System', 'Testing', 'Therapeutic Intervention', 'Toddler', 'Work', 'aged', 'classical conditioning', 'design', 'early childhood', 'educational atmosphere', 'experimental study', 'flexibility', 'indexing', 'innovation', 'kindergarten', 'language impairment', 'natural language', 'network architecture', 'phrases', 'statistics', 'syntax', 'therapeutic development', 'tool', 'young adult']",NIDCD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R21,2021,240750
"Genetic Modulators of Glaucoma Glaucoma is the leading cause of irreversible blindness in the world. While elevated intraocular pressure (IOP) is a major risk factor, damage and death of retinal ganglion cells (RGCs) underlies visual field loss. However, a thorough understanding of this disease is a major challenge because its genetic basis is heterogeneous and it represents a family of age-related disorders resulting from intersecting gene-regulated pathophysiologic networks. We propose to continue to use the BXD (C57BL/6 x DBA/2J) family of recombinant inbred (RI) lines of mice as a genetic reference panel (GRP) and to combine our work with human genome wide association studies (GWAS), to uncover and clarify the genetic heterogeneity that underlies optic nerve (ON) damage. We have had recent success using this combined approach in the regulation of intraocular pressure (IOP). We are very well positioned to take the next step and apply this approach to define cellular targets of RGC damage and death. We propose to uncover phenotypic diversities of glaucoma-related ON damage and uncover common underlying mechanisms that are shared with IOP modulation. Our long-term research goal is to identify disease mechanisms and develop neuroprotective therapies to preserve retinal health in patients at risk for glaucoma. Our overall objective is to identify novel gene products and related mechanisms that lead to glaucomatous endophenotypes using multi-dimensional genetic analyses, cross-species comparisons (mouse, rat and human) and validation using novel murine glaucoma models. Our central hypothesis is that molecular processes leading to glaucoma associated-endophenotypes, such as elevated IOP and ON damage, are shared across species, and that species comparisons can uncover common underlying mechanisms, and efficient testing of targeted glaucoma therapeutics. In the current investigation, we perform a systematic analysis of ON damage, and an additional species—rat. We will mine the extensive databases of IOP and ON damage that we are generating for more than 70 BXD strains across five age cohorts with the goal of defining new models of glaucoma. An overall strength of this proposal is the combination of cutting-edge systems genetics methods, species comparisons of glaucoma phenotypes, and a strong interdisciplinary team that includes investigators with extensive experience in systems genetics, glaucoma, GWAS in human and rats, and advanced computational methods. To test our hypothesis, we will perform the following thress studies: 1) Identify the candidate gene on chromosome 12 that modulates ON damage; 2) Determine if modulation of IOP and/or ON damage is shared across rodent species; and 3) Identify novel spontaneous glaucoma models through a comprehensive analysis of our enlarged BXD GRP of 100 or more BXD strains. The outcomes of these studies will define novel genes and molecular networks that underlie glaucoma-associated phenotypes and also provide unique glaucoma models for future analysis. These results are expected to fundamentally advance the field of glaucoma disease mechanisms and enable targeted therapeutic development. Glaucoma is the leading cause of irreversible blindness in the world and a thorough understanding of this disease is a major challenge because its genetic basis is heterogeneous, and it likely represents a family of disorders resulting from intersecting gene-regulated pathophysiologic pathways. Our goals are to: identify candidate gene(s) that modulate optic nerve damage; determine if regulation of intraocular pressure and/or optic nerve damage are shared across species; and identify novel spontaneous glaucoma models. These outcomes will fundamentally advance the field of glaucoma disease mechanisms and enable targeted therapeutic development.",Genetic Modulators of Glaucoma,10090598,R01EY021200,"['Age', 'Axon', 'Blindness', 'Candidate Disease Gene', 'Cell Death', 'Cellular Assay', 'Cessation of life', 'Chromosome 12', 'Clinical', 'Computing Methodologies', 'Data', 'Databases', 'Disease', 'Family', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Heterogeneity', 'Genomics', 'Glaucoma', 'Goals', 'Health', 'Human', 'Human Genome', 'Inbred Strains Rats', 'Inbreeding', 'Investigation', 'Laboratories', 'Lead', 'Methods', 'Modeling', 'Molecular', 'Mus', 'Ocular Hypertension', 'Optic Nerve', 'Outcome', 'Outcome Study', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiologic Intraocular Pressure', 'Population', 'Positioning Attribute', 'Process', 'Publications', 'Quantitative Trait Loci', 'Rattus', 'Recombinants', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Ganglion Cells', 'Risk', 'Risk Factors', 'Rodent', 'System', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Visual Fields', 'Work', 'age related', 'cell injury', 'cellular targeting', 'clinical subtypes', 'cohort', 'deep neural network', 'density', 'endophenotype', 'experience', 'gene product', 'genetic analysis', 'genome wide association study', 'human data', 'human model', 'lead candidate', 'nerve damage', 'novel', 'novel therapeutics', 'preservation', 'success', 'targeted treatment', 'therapeutic development', 'treatment strategy']",NEI,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2021,371486
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Prognosis', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"Design Optimization of Reduced-Diameter Implants in Simulated and Cadaver Bone Project Summary Reduced-diameter dental implants have an outer diameter less than 3.75 mm. They are useful for replacing teeth that have small cervical diameters, especially in anterior locations. In the anterior, the width of the alveolar ridge is often insufficient to place a standard-diameter implant, so reduced-diameter implants avoid the need for bone augmentation surgery and thus avoid the additional cost and six-month wait prior to implant placement. However, reduced-diameter implants suffer from a much greater incidence of mechanical complications compared with standard-diameter implants. These complications include loosening and/or fracture of the implant-abutment connector screw. Fortunately, our preliminary data suggest that the design of the implant-abutment connection in reduced-diameter implants can be optimized to increase their lifetime. We previously conducted a five-year project on more efficient methods of evaluating the mechanical reliability of dental implants by (1) validating the accuracy of implant lifetime prediction performed using finite element stress analysis combined with fatigue post-processing software and (2) validating the accelerated lifetime testing of physical specimens performed using a combination of overstress acceleration and usage rate acceleration. We accomplished those aims, which provided us with a powerful set of tools for addressing the design optimization of reduced-diameter dental implants. In the currently proposed project, we will use finite element modeling to screen 25 implant design parameters to determine which parameters should be used as experimental factors in design optimization of reduced- diameter dental implants. The candidate parameters were identified by fatigue testing of four types of reduced- diameter dental implants and testing design parameters for significant association with fatigue lifetime. Second, we will identify the optimal combination of design parameters that corresponds to the maximum predicted fatigue lifetime for reduced-diameter dental implants. We will use Artificial Neural Networks that have been trained using the results of our finite element analyses to perform design optimization and will compare that method with Response Surface Methodology. Third, we will validate the virtual models by using accelerated lifetime testing (ALT) of physical specimens to compare the performance of our optimized implant with a commercially available benchmark in simulated bone. Fourth, we will also test our optimized prototype in cadaver bone to validate our novel simulated bone holder material for future implant fatigue studies. Project Narrative An oral surgeon sometimes must insert metallic screws into a patient’s jawbone. The screws currently available for use near the lips break too frequently. We will design a more durable type of screw.",Design Optimization of Reduced-Diameter Implants in Simulated and Cadaver Bone,10134802,R01DE026144,"['Acceleration', 'Address', 'Alveolar ridge', 'Anterior', 'Benchmarking', 'Cadaver', 'Caliber', 'Cervical', 'Computer software', 'Confidence Intervals', 'Data', 'Dental Implants', 'Elements', 'Equipment', 'Fatigue', 'Finite Element Analysis', 'Fracture', 'Future', 'Goals', 'Implant', 'Implantation procedure', 'Incidence', 'Incisor', 'Lateral', 'Linear Regressions', 'Lip structure', 'Location', 'Maxilla', 'Measures', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Oral Surgeon', 'Patients', 'Performance', 'Research Personnel', 'Resistance', 'Site', 'Specimen', 'Stress', 'Surface', 'System', 'Testing', 'Tooth structure', 'Training', 'Variant', 'Width', 'artificial neural network', 'bone', 'cost', 'design', 'experience', 'healing', 'implant design', 'member', 'metallicity', 'novel', 'prototype', 'response', 'tool', 'virtual model']",NIDCR,UNIVERSITY OF MISSISSIPPI MED CTR,R01,2021,362936
"Using CRISPR technology to study the function of paralogous genes Gene annotations in model organisms such as Drosophila are important contributors to our understanding of the functions of human genes, including human disease-associated genes. Paralogs, which share a common ancestor, present a challenging case for identification of gene function in model organisms as in some cases, loss of function of one paralog is masked by compensatory function of the other(s), such that only when both are disrupted will informative phenotypes be observed. In other cases, redundancy is partial, such that knockout of one paralog has a subset of the phenotypes observed when more than one member of the group is disrupted simultaneously. Recent advances in CRISPR technology by our group and others makes it now possible to systematically knockout paralog pairs in Drosophila, including in a stage- and tissue-specific manner. We will use our existing infrastructure for bioinformatics-based identification of orthologs and paralogs, efficient large-scale production of fly stocks, and fly stock and data sharing to develop a resource useful for double-knockdown of paralogs. Our initial characterization of the genes with regards to signal transduction and neurodegeneration, as well as in-depth analyses by the community, will uncover function for paralogous genes, helping to close the ‘phenotype gap’ (lack of associated loss-of-function phenotypes) that currently exists for nearly half of all genes in this important genetic model system. The result will be a fly stock resource for further study by Drosophila experts, a bioinformatics pipeline and methods that can be applied to other model systems, and a data resource that will inform annotation of fly and human genes Genetic analysis is a powerful tool for uncovering conserved gene functions but paralogs can have full or partial overlap in function, preventing discovery in single-gene studies. The issue will be solved using state-of- the-art CRISPR technology to generate a resource that will allow gene function to be uncovered through simultaneous disruption of paralogs.",Using CRISPR technology to study the function of paralogous genes,10202779,R24OD026435,"['Address', 'Animal Model', 'Area', 'Biological Assay', 'Biological Models', 'Biology', 'CRISPR/Cas technology', 'Clone Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collection', 'Communities', 'Complex', 'Controlled Study', 'Databases', 'Development', 'Disease', 'Drosophila genome', 'Drosophila genus', 'Fluorescence', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Models', 'Genome', 'Human', 'Human Genome', 'Infrastructure', 'Knock-out', 'Knowledge', 'Maps', 'Masks', 'Methods', 'Modeling', 'Mosaicism', 'Nerve Degeneration', 'Orthologous Gene', 'Phenotype', 'Production', 'Proteins', 'Reiterated Genes', 'Research', 'Resources', 'Role', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'System', 'Technology', 'Testing', 'Tissues', 'Transgenic Organisms', 'base', 'bioinformatics infrastructure', 'bioinformatics pipeline', 'cell type', 'data mining', 'data resource', 'data sharing', 'fly', 'gene function', 'genetic analysis', 'genetic approach', 'human disease', 'insight', 'knock-down', 'knockout gene', 'large scale production', 'loss of function', 'member', 'mutant', 'neuronal cell body', 'paralogous gene', 'pleiotropism', 'prevent', 'text searching', 'tool', 'vector']",OD,HARVARD MEDICAL SCHOOL,R24,2021,629871
"MICRORNA BIOMARKERS FOR OROPHARYNGEAL CANCER Project Summary Head and neck cancer is the fifth most common cancer in the United States, with an overall survival rate of around 50%. Compared to other subsites of head and neck cancer, the incidence of oropharyngeal cancer is increasing and has been intimately linked to human papillomavirus (HPV). Most oropharyngeal cancer patients receive standard therapy. However, clinical outcomes vary significantly and are difficult to predict. Thus, more robust prognostic biomarkers are needed to accurately stratify patients for the risk of treatment failures.  The long-term goal of this research is to develop clinical prognostic assays and therapeutic agents for individualized oropharyngeal cancer treatment by focusing on microRNAs. MicroRNAs (miRNAs) are a family of small non-coding RNA molecules that collectively control the expression of thousands of protein-coding genes. miRNAs are extensively involved in tumorigenesis and they have deregulated expression in human cancers. Recent studies indicate that miRNAs are promising biomarkers and play critical regulatory roles in many types of cancer. However, the prognostic and therapeutic values of miRNAs in oropharyngeal cancer are poorly characterized to date. Our preliminary analysis has identified six miRNAs that are predictive of oropharyngeal cancer outcome. Here, we propose to significantly expand our preliminary study to identify new miRNA biomarkers by analyzing all oropharynx-related miRNAs in a large number of oropharyngeal tumors. These miRNA biomarkers will then be combined to build a robust model for significantly improved prognosis of oropharyngeal cancer. Further, the therapeutic potential of selected prognostic miRNAs will be evaluated by characterizing the roles of these miRNAs in cancer progression and treatment response. RELEVANCE Although the overall incidence of head and neck cancer has decreased steadily in the past decades, the number of reported oropharyngeal cancer cases has increased significantly. The long-term goal of this research is to develop clinical prognostic assays for individualized oropharyngeal cancer treatment by focusing on microRNAs, which are a class of small non-coding RNAs that play important regulatory roles in tumorigenesis.",MICRORNA BIOMARKERS FOR OROPHARYNGEAL CANCER,10238766,R01DE026471,"['Automobile Driving', 'Biological Assay', 'Biological Markers', 'Cancer Patient', 'Cancer Prognosis', 'Cells', 'Clinical', 'Code', 'Data', 'Family', 'Gene Targeting', 'Genes', 'Goals', 'Head and Neck Cancer', 'Human', 'Human Papillomavirus', 'Incidence', 'Institution', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'MicroRNAs', 'Modeling', 'Oncogenic', 'Oropharyngeal', 'Oropharyngeal Neoplasms', 'Outcome', 'Patients', 'Play', 'Prognosis', 'Prognostic Marker', 'Proteins', 'Reporting', 'Research', 'Risk', 'Role', 'Sampling', 'Survival Rate', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Treatment Failure', 'United States', 'Untranslated RNA', 'Validation', 'base', 'cancer therapy', 'cancer type', 'high risk', 'improved', 'malignant oropharynx neoplasm', 'miRNA expression profiling', 'microRNA biomarkers', 'outcome prediction', 'patient biomarkers', 'patient stratification', 'patient subsets', 'predictive modeling', 'prognostic', 'prognostic assays', 'prognostic model', 'prospective', 'screening', 'treatment response', 'treatment risk', 'tumor', 'tumor progression', 'tumorigenesis']",NIDCR,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2021,378722
"Development of Accurate and Interpretable Machine Learning Algorithms for their application in Medicine Project Summary  The objective of this proposal is to provide a robust course of training for Gilmer Valdes, PhD, DABR, a candidate with an excellent foundation in clinical and machine learning research, to enable him to become an independent investigator. The proposed research aims to address a tradeoff between interpretability and accuracy of modern machine learning algorithms which limits their use in clinical practice. The candidate’s central hypothesis is that the current tradeoff is not a law of nature but rather a limitation of current interpretable machine learning algorithms. Towards proving this hypothesis, the candidate, leading a multidisciplinary team, have developed unique mathematical frameworks (MediBoost and the Conditional Interpretable Super Learner) to build interpretable and accurate models. The proposed research will I) implement and extensively benchmark these frameworks and II) use the algorithms develop to solve three clinical problems where potentially suboptimal models are currently used to make clinical decisions: 1) predicting mortality in the Intensive Care Unit, 2) predicting risk of Hospital Acquired Venous Thromboembolism, 3) predicting which prostate cancer patients benefit the most from adjuvant radiotherapy. The candidate’s training and research plan, multidisciplinary by nature, takes advantage of the proximity of UC San Francisco, Stanford and UC Berkeley and proposes a training plan that cannot be easily replicated elsewhere. Recognizing the multidisciplinary nature of the work proposed, the author will be mentored and work closely with a stellar committee from three institutions and different scientific areas (Machine Learning, Biostatistics, Statistics, Hospital Medicine, Cancer Research and Quality Assurance in Medicine): Jerome H. Friedman PhD (Stanford Statistics Department), Mark Van der Laan PhD (Berkeley Biostatistics and Statistics Department), Mark Segal (UCSF Epidimiology and Biostatistics Deparments), Andrew Auerbach MD (UCSF Medicine Department), Felix Y. Feng MD (UCSF Radiation Oncology),and Timothy D. Solberg PhD (UCSF Radiation Oncology). This committee will be coordinated by Dr Solberg. The candidate also counts with a strong a multidisciplinary team of collaborators. Successful completion of the proposed research will develop the next generation of accurate and interpretable Machine Learning algorithms and solve three important clinical problems where linear models are currently used in clinical settings. This proposal has wide-ranging implications across the healthcare spectrum. The intermediate-term goal is for the candidate to acquire the knowledge, technical skills and expertise necessary to submit a successful R01 proposal. PROJECT NARRATIVE Current state of the art machine learning algorithms have a marked tradeoff between accuracy and interpretability. In medicine, where errors can have a dire consequence and knowledge representation and validation is as relevant as accuracy, the development of accurate and interpretable algorithms is of paramount importance. My research project will address a critical public health need by developing machine learning algorithms that are both accurate and interpretable, and apply them to solve specific clinical problems.",Development of Accurate and Interpretable Machine Learning Algorithms for their application in Medicine,10241965,K08EB026500,"['Address', 'Adjuvant Radiotherapy', 'Algorithms', 'Area', 'Benchmarking', 'Biometry', 'Cancer Patient', 'Classification', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Decision Trees', 'Development', 'Doctor of Philosophy', 'Foundations', 'Goals', 'Healthcare', 'Hospitals', 'Institution', 'Intensive Care Units', 'Knowledge', 'Label', 'Laws', 'Libraries', 'Limb structure', 'Linear Models', 'Machine Learning', 'Malignant neoplasm of prostate', 'Mathematics', 'Mediating', 'Medical', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Patient Triage', 'Patients', 'Performance', 'Physicians', 'Pneumonia', 'Polynomial Models', 'Public Health', 'Radiation Oncology', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'San Francisco', 'Survival Analysis', 'Technical Expertise', 'Testing', 'Training', 'Trees', 'Validation', 'Work', 'anticancer research', 'artificial neural network', 'asthmatic patient', 'classification trees', 'clinical decision-making', 'clinical practice', 'design', 'improved', 'information organization', 'machine learning algorithm', 'medical specialties', 'mortality', 'multidisciplinary', 'neural network', 'next generation', 'novel', 'quality assurance', 'random forest', 'regression trees', 'standard care', 'statistics', 'structured data', 'task analysis', 'theories', 'venous thromboembolism']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K08,2021,172512
"Multidimensional in vivo Assessments of Engineered Nanomaterials and Biological Interactions Abstract We propose an integrative modeling approach to synthesize data generated across labs of the Nanotechnology Health Implications Research (NHIR) consortium. Our goal is to leverage these diverse data toward developing principles for sustainable design and synthesis of engineered nanomaterials (ENM). Our approach advances this goal by (1) Creation of a flexible data structure that permits analysis across ENM attributes and assay results, (2) Sophisticated machine learning modeling of integrated data, and (3) Facilitating dissemination of results via Cancer Nanotechnology Laboratory (CaNanoLab). This proposal can advance overarching NHIR goals by allowing for the discovery of robust patterns in complex, integrated data that could not be gleaned from single data sources alone. Project Narrative Not Applicable",Multidimensional in vivo Assessments of Engineered Nanomaterials and Biological Interactions,10381394,U01ES027294,"['Biological', 'Biological Assay', 'Complex', 'Data', 'Data Sources', 'Engineering', 'Glean', 'Goals', 'Health', 'Information Dissemination', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Nanotechnology', 'Pattern', 'Research', 'data structure', 'design', 'diverse data', 'flexibility', 'in vivo', 'nanomaterials']",NIEHS,OREGON STATE UNIVERSITY,U01,2021,104918
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",10063870,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'large datasets', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2021,178370
"The influence of ocular remodeling on glaucoma Abstract Glaucoma is a leading cause of blindness worldwide, yet the reason for retinal ganglion cell damage within the optic nerve head (ONH) is not fully understood. Elevated intraocular pressure (IOP) is considered the primary cause of glaucoma, but epidemiologic studies identify moderate or high myopia as an independent risk factor. Currently, the connection between these two diseases is unknown. We propose that there is a biomechanical basis underlying this interaction. Our central hypothesis is that scleral and ONH remodeling that leads to high myopia is one of many factors increasing the risk for subsequent pathologic ONH remodeling and glaucoma later in life. With myopia reaching epidemic proportions in portions of the world, and the prevalence of glaucoma continuing to increase, understanding the basic mechanisms underlying these disease processes is critical. We will leverage our unique tree shrew model of experimental myopia and glaucoma, a combination of in vivo and ex vivo experiments, and in silico multiscale simulation tools to examine the biomechanical basis for the link between myopia and glaucoma. The grant will focus on three primary areas of interest: 1) We will examine the ocular biomechanical changes that occur within the sclera and ONH during high myopia development in tree shrews. 2) We will determine whether scleral remodeling that leads to high myopia predisposes an animal to accelerated pathologic ONH remodeling and increased axon loss in experimental glaucoma. And, 3) We will use multiscale modeling to elucidate the interacting biomechanical mechanisms underlying glaucoma and high myopia. This knowledge will be used to develop novel targets for future glaucoma therapies. Project Narrative Glaucoma is one of the leading causes of blindness worldwide, yet we are still trying to develop a fundamental understanding of the mechanisms that cause this disease. While we know that increased eye pressure is a risk factor for glaucoma, recent evidence also indicates moderate to high myopia is an independent risk factor. The research described in this application is aimed at investigating the link between myopia and glaucoma with the goal of identifying novel treatment options for patients with glaucoma.",The influence of ocular remodeling on glaucoma,10375895,R01EY027759,"['3-Dimensional', 'Age', 'Anatomy', 'Animal Experiments', 'Animals', 'Anterior', 'Area', 'Artificial Intelligence', 'Axon', 'Biomechanics', 'Blindness', 'Caliber', 'Calibration', 'Characteristics', 'Communities', 'Computer software', 'Connective Tissue', 'Custom', 'Data', 'Data Set', 'Development', 'Devices', 'Disease', 'Engineering', 'Epidemic', 'Experimental Models', 'Eye', 'Financial compensation', 'Funding', 'Future', 'Glass', 'Glaucoma', 'Goals', 'Grant', 'Head', 'Image', 'Image Analysis', 'Implant', 'Knowledge', 'Length', 'Life', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Morphology', 'Myopia', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'POU2F2 gene', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Physiologic Intraocular Pressure', 'Play', 'Positioning Attribute', 'Prevalence', 'Problem Solving', 'Process', 'Protocols documentation', 'Reading', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Risk', 'Risk Factors', 'Role', 'Scanning', 'Sclera', 'Severities', 'Source', 'Structure of retinal pigment epithelium', 'System', 'Time', 'Tissues', 'Training', 'Tupaiidae', 'Validation', 'Wages', 'arm', 'automated analysis', 'automated segmentation', 'base', 'cell injury', 'deep learning algorithm', 'epidemiology study', 'exhaustion', 'experimental study', 'imaging modality', 'implantation', 'in silico', 'in vivo', 'interest', 'multi-scale modeling', 'non-linear transformation', 'novel', 'preclinical study', 'pressure', 'reconstruction', 'serial imaging', 'simulation', 'tool']",NEI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,94161
"A fully automated PET radiomics framework Summary The overall goal of this proposal is to develop a fully automated PET radiomics framework and evaluate the efficacy of PET radiomic features (RFs) derived from this framework in predicting therapy response in patients with stage III non-small cell lung cancer (NSCLC). Radiomics is showing exciting promise in deriving biomarkers for several diseases. The potential to measure and evaluate the efficacy of radiomic features derived from PET for early prediction of therapy response is highly impactful since PET probes the functional characteristics of the tumor, where changes are manifested sooner in comparison to anatomical changes. However, PET images have high noise and limited resolution, which leads to inaccurate and imprecise RF measurements that then have limited clinical value. Previously we have developed techniques to optimize quantitative imaging methods and shown that these can help estimate more reliable quantitative metrics leading to better predictive ability with these metrics. Building on these past studies and by combining concepts from imaging physics, statistical inference theory, deep learning, we propose to develop methods that accurately and precisely estimate RFs from PET. These methods will include a fully automated PET segmentation method that will enable reliable delineation of tumor boundaries using a practical approach. Next, a no-gold-standard (NGS) evaluation technique will be developed to optimize RF quantification protocols. This technique will provide a mechanism for precise measurement of RFs from PET images without access to the ground truth RF value. The methods will be rigorously validated in the context of measuring radiomics features in patients with NSCLC using a combination of realistic simulations, physical phantom studies and existing patient data. Select RFs will then be retrospectively evaluated on predicting therapy response using existing data the ACRIN 6697 longitudinal clinical trial in patients with stage III NSCLC. A strong multidisciplinary team has been assembled for this project, consisting of an imaging scientist, clinical nuclear-medicine radiologists, medical oncologist with expertise in biomarker development for thoracic malignancies and biology of NSCLC, biostatistician, and a medical physicist. The proposed methods are poised to have a strong impact on PET radiomics by enabling measurement of precise and accurate RFs, and by facilitating the clinical translation of PET radiomics. The impact is strengthened as we investigate the predictive ability of the PET RFs in patients with stage III NSCLC, a leading cause of death with low overall survival, and with an important and timely need for improved personalized therapy regimens. Further, the methods developed in this project are general and potentially impact precision-medicine approaches for other cancers as well as other diseases where PET imaging has a clinical role. Project Narrative There is an important need to develop biomarkers for early prediction of therapy response for personalizing treatments. The proposed project will develop and validate methods to compute radiomic features from PET and retrospectively evaluate their ability to predict therapy response in patients with non-small cell lung cancer. The developed methods are general and also applicable to other diseases where PET has a role.",A fully automated PET radiomics framework,10458241,R56EB028287,"['Address', 'Affect', 'American College of Radiology Imaging Network', 'Anatomy', 'Biological Markers', 'Biology', 'Cause of Death', 'Characteristics', 'Clinical', 'Clinical Trials', 'Computer software', 'Data', 'Data Set', 'Discipline of Nuclear Medicine', 'Disease', 'Engineering', 'Evaluation', 'Goals', 'Gold', 'Heterogeneity', 'Image', 'Knowledge', 'Lead', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Oncologist', 'Metabolic', 'Methods', 'Molecular', 'Multicenter Trials', 'Noise', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Procedures', 'Process', 'Progression-Free Survivals', 'Property', 'Protocols documentation', 'Quality of life', 'Radiation Therapy Oncology Group', 'Reader', 'Regimen', 'Reproducibility', 'Resolution', 'Retrospective Studies', 'Role', 'Smoking History', 'Techniques', 'Time', 'Toxic effect', 'Training', 'Translating', 'Treatment Cost', 'base', 'biomarker development', 'biomarker discovery', 'cancer imaging', 'chemoradiation', 'clinical application', 'clinical translation', 'deep learning', 'early detection biomarkers', 'efficacy evaluation', 'fluorodeoxyglucose positron emission tomography', 'imaging modality', 'imaging scientist', 'improved', 'in vivo', 'mortality', 'multidisciplinary', 'novel', 'optimal treatments', 'patient oriented', 'personalized medicine', 'precision medicine', 'prognostic value', 'quantitative imaging', 'radiologist', 'radiomics', 'reconstruction', 'response', 'simulation', 'theories', 'tumor']",NIBIB,WASHINGTON UNIVERSITY,R56,2021,492943
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",10129958,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury to Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'statistical learning', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,350335
"Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties ABSTRACT Mesenchymal stem cells (MSCs) have broad-based potential in regenerative medicine cell therapies and can be isolated from a variety of different tissues. Though MSCs from different tissues are phenotypically similar, a barrier to their clinical use is the high variability of their trophic and regenerative properties. This variability suggests that inherent differences exist in the molecular machinery guiding MSC properties between different MSC populations, yet, to date, these differences are ill-defined. To this end, we have preliminary evidence that MSC phenotypes correlate to their regenerative outcomes. In this study, we aim to elucidate how the molecular and cellular properties of distinct MSC populations determine their regenerative properties. Our hypothesis is that MSCs from different tissues have different regenerative properties which correlate to specific molecular profiles defined by gene expression and transcriptional activity. To test this hypothesis, the project proposed has three Specific Aims (SAs). In SA1, we will determine how tissue-specificity dictates gene expression and dynamic transcription factor activity of distinct MSCs. SA2 will determine how differences in the cellular and molecular properties of MSCs correlate to MSC phenotype. Finally, in SA3, we will determine how the molecular profiles and cellular activities of MSCs dictate their regenerative properties. Findings of the proposed study will provide novel insights about how the distinct molecular profiles of MSCs dictate their biological and physiological properties. In a therapeutic context, this would enable the development of innovative screening technologies for MSC therapies to identify and enrich for the most appropriate MSC for the specific therapeutic application. PROPOSAL NARRATIVE Stem cell therapies are emerging as a new treatment approach to regenerate lost tissues, treat ischemic disorders, and treat chronic inflammatory conditions. Many of these approaches use stem cells from adults which are present in various regions throughout the body. Our research team is working to better understand how and why these adult stem cells behave the way they do so that we can better determine how to use them in different therapies to treat debilitating health conditions.",Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties,10231011,R01DE028657,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Angiogenic Factor', 'Automobile Driving', 'Biological', 'Biological Process', 'Bone Marrow', 'Bone Regeneration', 'Bone Tissue', 'Cell Culture Techniques', 'Cell Separation', 'Cell Therapy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Computer Models', 'Data', 'Dental', 'Dental Pulp', 'Development', 'Disease', 'ENG gene', 'Emerging Technologies', 'Fatty acid glycerol esters', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Profile', 'Genetic Transcription', 'Gingiva', 'Health', 'Immunophenotyping', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Maintenance', 'Mesenchymal Stem Cells', 'Methods', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Muscle', 'Natural regeneration', 'Operative Surgical Procedures', 'Oral', 'Osteogenesis', 'Outcome', 'Pathway interactions', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Population Heterogeneity', 'Production', 'Property', 'Regenerative Medicine', 'Regulation', 'Reporting', 'Research', 'Rodent Model', 'Role', 'Signal Pathway', 'Sorting - Cell Movement', 'Specificity', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Tooth structure', 'United States National Institutes of Health', 'Work', 'adult stem cell', 'alveolar bone', 'angiogenesis', 'base', 'bone', 'clinical translation', 'healthy volunteer', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'molecular phenotype', 'next generation sequencing', 'novel', 'oral tissue', 'osteogenic', 'population based', 'regeneration model', 'regenerative', 'regenerative cell', 'regenerative therapy', 'screening', 'stem cell differentiation', 'stem cell population', 'stem cell self renewal', 'stem cell therapy', 'stem cells', 'stemness', 'transcription factor', 'transcriptome']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,421957
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,10171859,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'detection sensitivity', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2021,381543
"Accelerating collaborative, cumulative, and open intervention science with an e-intervention authoring platform Background. Research has identified a wide range of evidence-based interventions for key behavioral health risks such as poor diet, smoking, unhealthy alcohol use, or a sedentary lifestyle. However, to be truly successful, behavioral intervention science should fulfill at least three key criteria: (1) demonstration of cumulative increases in intervention efficacy; (2) provision of interventions that reach a high proportion of those in need; and (3) demonstration of a meaningful population impact/reduction in disease burden. It currently meets none of these. Some reasons for this include (1) over-reliance on an imprecise delivery mechanism (people; usually therapists or coaches of some kind) that is difficult to train to fidelity on a large scale, and that cannot be manipulated with precision; (2) use of sample sizes that may be far below what is needed to accurately characterize heterogeneity of response; and (3) cross-study variability in therapist characteristics, sample characteristics, and measurement strategy. All of this combines to create a science that lacks evidence of cumulative improvements upon prior benchmarks. Proposed solution. Mobile technology shows significant promise as an intervention delivery mechanism that is replicable, transparent, modular, and precise. However, progress in the development and implementation of mobile interventions has been slowed by factors such as the tremendous time and money needed to develop an intervention; limitations in cross-platform compatibility and interoperability; and lack of a consistent system around which to collaborate. To address these needs, the PI developed the Computerized Intervention Authoring System (CIAS), which facilitates behavioral intervention science by allowing investigators to directly develop sophisticated and interactive mobile applications without programming. CIAS is already being used by investigators outside of the PI’s own lab, a process that has revealed significant interest in this software from a wide range of NIH-funded investigators, as well as significant limitations. Current aims. The proposed application will address these limitations, making CIAS into a significant, open-source, and virtually unique non-commercial research resource. In Aim 1, we will engage in sustained user experience testing designed to make the tool far more intuitive to use. This process is expected to result in a dramatic reorganization of the investigator interface, as well as in a complete set of evidence-based user training and support materials. In Aim 2, we will add a range of features and capabilities to make CIAS more powerful, flexible, and interoperable (e.g., by building to SMART Health IT standards, as well as FHIR open specifications to facilitate integration with Electronic Health Records). In Aim 3, we will engage in focused efforts to promote the use of CIAS as part of multi-lab collaborations using open science practices (e.g., via integration with the Open Science Framework). Importantly, we will engage in all of the above with the assistance of a highly accomplished panel of advisors who will help ensure that the final product is broadly relevant, future-facing, and usable to a broad range of behavioral scientists. Project Narrative Technology-delivered interventions are showing great potential to help people modify unhealthy behaviors like substance use, poor diet, and poor medication adherence. However, designing these interventions is time- consuming and expensive, which is slowing down research in this area as well as the rate at which such technology can help people. This project will develop a new version of existing software so it can allow scientists to easily and quickly collaborate to develop powerful interventions for mobile devices.","Accelerating collaborative, cumulative, and open intervention science with an e-intervention authoring platform",10271571,U24EB028990,"['Address', 'Adult', 'Apple', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Benchmarking', 'Budgets', 'Cessation of life', 'Characteristics', 'Code', 'Collaborations', 'Computer software', 'Computers', 'Consumption', 'Development', 'Documentation', 'Eating', 'Ecosystem', 'Electronic Health Record', 'Elements', 'Ensure', 'Evaluation', 'Evidence based intervention', 'Fast Healthcare Interoperability Resources', 'Funding', 'Future', 'Health behavior', 'Heterogeneity', 'Human', 'Intervention', 'Intervention Studies', 'Interview', 'Intuition', 'Investments', 'Language', 'Machine Learning', 'Measurement', 'Methods', 'Modification', 'National Institute of Biomedical Imaging and Bioengineering', 'Operating System', 'Outcome', 'Persons', 'Population', 'Process', 'Public Health Informatics', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Risk', 'SMART health', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Smoking', 'Support System', 'System', 'Technology', 'Testing', 'Text Messaging', 'Time', 'Training', 'Training Support', 'Translations', 'Treatment Efficacy', 'Unhealthy Diet', 'United States National Institutes of Health', 'Work', 'alcohol misuse', 'base', 'behavioral health', 'brief intervention', 'burden of illness', 'comparison intervention', 'computerized', 'cost', 'design', 'diet and exercise', 'evidence base', 'experience', 'flexibility', 'good diet', 'handheld mobile device', 'healthy weight', 'interest', 'interoperability', 'intervention effect', 'mHealth', 'medication compliance', 'mobile application', 'mobile computing', 'open data', 'open source', 'prevent', 'reduced substance use', 'repository', 'response', 'sedentary lifestyle', 'software development', 'substance use', 'symposium', 'therapy design', 'therapy development', 'tool', 'user centered design', 'virtual', 'web site']",NIBIB,MICHIGAN STATE UNIVERSITY,U24,2021,377490
"Identifying treatment responders in medication trials for AUD using machine learning approaches ABSTRACT Alcohol use disorder (AUD), as defined in DSM-5, represents a highly prevalent, costly, and often untreated condition in the United States. Pharmacotherapy offers a promising avenue for treating AUD and for improving clinical outcomes for this debilitating disorder. While developing novel medications to treat AUD remains a high priority research area, there remain major opportunities to further elucidate clinical response in completed medication trials. To that end, a key question in randomized clinical trials (RCTs) is which patients respond to a given pharmacotherapy. Identifying treatment responders provides major opportunities to advance clinical care for AUD by personalizing medication practices on the bases of variables/predictors of good clinical response. For example, while the effect size for medications such as naltrexone is deemed small-to-moderate, a host of studies over the past decade have shown that its effect size may be considerably larger for certain subgroups of patients. Towards advancing precision medicine for AUD and leveraging data from a host of carefully conducted RCTs for AUD, this R03 application seeks to conduct secondary data analysis. Specifically, we propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG). These state-of-the-art RCTs for AUD have tested the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. In this R03 application, we propose to use a machine learning approach to identify treatment responders in the NCIG RCTs. Machine learning represents a highly promising and underutilized data analytic strategy in the field of AUD treatment response. Machine learning models prioritize the ability to predict future outcomes over creating perfectly fitting models for the data at hand. This results in models which are more generalizable to future observations, which fits well with our goal of identifying responders in RCTs. Leveraging data from these pivotal RCTs through secondary data analysis and using novel analytic methods, namely machine learning, provides a cost-effective approach to identifying AUD pharmacotherapy responders. PROJECT NARRATIVE In this R03 application, we propose to use a machine learning approach to identify treatment responders in pivotal clinical trials for AUD. We propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG), testing the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. Leveraging resources through secondary data analysis and using novel analytic methods provides a cost- effective approach to identifying AUD pharmacotherapy responders.",Identifying treatment responders in medication trials for AUD using machine learning approaches,10195465,R03AA029244,"['Age', 'Age of Onset', 'Alcohols', 'Anxiety', 'Area', 'Chantix', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Conduct Clinical Trials', 'DSM-V', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Ethnic Origin', 'Faculty', 'Future', 'Goals', 'Hand', 'Heavy Drinking', 'Human', 'Keppra', 'Laboratories', 'Levetiracetam', 'Machine Learning', 'Manuscripts', 'Marital Status', 'Mental Depression', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Modeling', 'Motivation', 'Naltrexone', 'National Institute on Alcohol Abuse and Alcoholism', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Policies', 'Psychologist', 'Psychology', 'Randomized Clinical Trials', 'Recommendation', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Scientist', 'Secondary to', 'Self Administration', 'Severities', 'Sum', 'Symptoms', 'Technical Expertise', 'Testing', 'United States', 'Withdrawal', 'Work', 'alcohol use disorder', 'analytical method', 'base', 'cigarette smoking', 'clinical care', 'clinical investigation', 'clinically relevant', 'cost', 'cost effective', 'cost effectiveness', 'craving', 'data sharing', 'drinking', 'gabapentin', 'improved', 'insight', 'machine learning method', 'material transfer agreement', 'novel', 'patient subsets', 'precision medicine', 'quetiapine', 'random forest', 'response', 'secondary analysis', 'sex', 'success', 'tenure track', 'treatment responders', 'treatment response', 'varenicline']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R03,2021,74776
"Develop a large-scale library of comprehensive deformable image registration (DIR) benchmark datasets and an integrated framework for quantifying accuracy of patient-specific DIR results Summary  Deformable image registration (DIR) between different image sets acquired from the same patient is a key enabling technology for many important diagnostic and therapeutic tasks, e.g. tumor diagnosis, evaluation of tumor response to treatment, and image-guided surgery. DIR algorithms compute tissue deformation by maximizing intensity and/or structural similarity between moving and target images, and regularity of deformation. DIR accuracy, which is the voxel-level positional correspondence between the two images, is not guaranteed, often inadequate, unpredictable and patient specific. DIR accuracy is largely dependent on anatomical site, image modality and quality, algorithm designs and implementations, operator skills and workflow selections. Inaccurate DIRs can have significant deleterious impact clinical decisions, treatment quality and patient safety. Lack of confidence in current registration tools has significantly limited the broader use of DIR in automating clinical decision-making tasks and improving diagnostic and therapeutic outcomes.  We posit that lack of accurate or robust performance arises from the fact that current DIR algorithms are based upon overly simplistic models of tissue deformation and failure to accommodate the reality of CT image quality. Currently, no method exists for quantitatively and automatically evaluating patient- specific DIR accuracy. We are therefore motivated to conduct two studies: 1) Build a large and comprehensive library of DIR benchmark datasets to support DIR algorithm validation in challenging settings. Each new DIR benchmark dataset will consist of automatically and  precisely detected landmark pairs, small blood vessel section pairs, and segmentation of organs and  large blood vessels. Currently no such DIR benchmark dataset exist. These datasets will spur  development of new and advanced DIR algorithms able to support complex, patient-specific tissue  deformation. These datasets will be immensely valuable for applications beyond DIR such as  semantic segmentation and vessels extraction, etc. 2) Develop integrated methods for quantitative verification of patient-specific DIRs. The automatic DIR  verification procedure will use multiple novel deep-learning models for automatic organ  segmentation, vessel bifurcation detection and direct prediction of 3D vector field of TREs (target  registration error). These to-be-developed deep-learning-based image processing procedures are  robust with respect to image noise and intensity variations, and will naturally support many  anatomical sites. This DIR verification procedure will provide quality assurance for patient-specific  DIRs for supporting clinical applications. Project Narrative  Inaccurate deformable image registration (DIR) can have significant deleterious impacts on clinical decisions. In this proposal, we will develop 1) a large-scale library of comprehensive DIR benchmark datasets to facilitate DIR research by objective, comprehensive, and quantitative performance assessment of new and advanced DIR methods designed to better model tissue deformation in challenging settings; and 2) a novel integrated process for automatically and quantitatively evaluating patient-specific DIRs, enabling physicians to confidently use such registrations to improve targeting accuracy of image-guided interventions and clinical decision-making tasks.",Develop a large-scale library of comprehensive deformable image registration (DIR) benchmark datasets and an integrated framework for quantifying accuracy of patient-specific DIR results,10121241,R01EB029431,"['3-Dimensional', 'Abdomen', 'Address', 'Advanced Development', 'Affect', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Benchmarking', 'Blood Vessels', 'Chest', 'Clinical', 'Code', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Ensure', 'Evaluation', 'Excision', 'Exhibits', 'Failure', 'Goals', 'Head', 'Head and neck structure', 'Image', 'Image-Guided Surgery', 'Libraries', 'Liver', 'Location', 'Lung', 'Manuals', 'Methods', 'Modeling', 'Motion', 'Noise', 'Organ', 'Patients', 'Pelvis', 'Performance', 'Physicians', 'Procedures', 'Process', 'Radiation therapy', 'Reporting', 'Research', 'Resolution', 'Risk', 'Role', 'Scanning', 'Semantics', 'Site', 'Slide', 'Software Tools', 'Structure', 'Structure of parenchyma of lung', 'Technology', 'Therapeutic', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical decision-making', 'clinical imaging', 'clinical practice', 'clinically relevant', 'contrast enhanced', 'deep learning', 'design', 'diagnosis evaluation', 'image guided', 'image guided intervention', 'image processing', 'image registration', 'imaging modality', 'improved', 'novel', 'patient safety', 'quality assurance', 'response', 'skills', 'targeted imaging', 'therapy outcome', 'tool', 'treatment response', 'tumor', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R01,2021,1685767
"Development of quantitative tools to predict patients with difficult intubation to minimize treatment related complications ABSTRACT Endotracheal mouth/nose breathing need 10% this to performing subjective poorly standard Unfortunately, these airway examination systems in clinical practice perform only modestly, with sensitivities of 20-62%, specificities of 82-97%, and very low positive predictive values, generally less than 30%, unless very liberal definitions of difficulty are used. There are likely a number of reasons for this poor performance, including the relative rarity of difficult intubation, the multifactorial etiology and varying definition of difficult intubation, inter-observer variability in test results, failure to validate potential systems in patients independent of those used to derive the test, and the inadequacy of the tests themselves. intubation (EI) is a common medical procedure in which a plastic tube is introduced via the into the trachea, to provide respiratory support during general anesthesia or to ameliorate difficulty in cases of respiratory failure, cardiac arrest, or other forms of critical illness. The global for EI is likely at least 150 million based on the WHO estimate of surgical need worldwide. Approximately  of EI attempts are difficult, and approximately 1/2000 are deemed impossible. The clinica l significance of “can't intubate, can't ventilate” scenario is extremely important: 25% of anesthetic related deaths are due airway mishaps. Patients are typically assessed for anatomic features that might predict difficulty in EI prior to the procedure. In practice, anesthesiologists and other airway experts likely weigh other factors in anticipating a difficult airway, including habitus, facial appearance, and perhaps other understood hunches. The use of this examination to predict difficult intubation is considered the of care in modern anesthesiology practice. When personnel Conversely, not learning and intubation. identify accuracy (Mallampati anesthesiologists reduce mobilization difficulty the airway is anticipated, more advanced techniques may be employed, additional may be recruited for assistance, surgical airway expertise (i.e., tracheostomy) may be on standby these techniques are expensive, time consuming, and uncomfortable to patients, so they should be overused. We hypothesize that anesthesiologists' visual assessment can be modeled through deep to identify patients with difficult intubation with high accuracy. Through innovative use of deep learning sophisticated image analysis, this research will identify facial features tha accurately predict difficult The research will utilize frontal as well as profile facial photographs to build a generative model to difficult intubation patients. The developed model will be subjected to rigorous statistical analysis for and reproducibility . In a clinical trial, the proposed model will be compared against the bedside tests + thryomental distance). The project will 1) result in innovative software tools to facilitate and 2) substantially reduce unnecessary healthcare expenses. We expect that this model will the probability of an unexpected difficult intubation and allow anesthesiologists to better prepare by of alternative techniques, equipment, or operators. with . t The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality, reducing inter-observer variability that will ultimately improve patient care. Thus, the proposed research is relevant to the part of NIH's mission that pertains to the application of novel strategies that may improve human health.",Development of quantitative tools to predict patients with difficult intubation to minimize treatment related complications,10126231,R21EB029493,"['Accident and Emergency department', 'Anatomy', 'Anesthesia procedures', 'Anesthesiology', 'Anesthetics', 'Appearance', 'Bedside Testings', 'Breathing', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Comprehension', 'Computer-Assisted Image Analysis', 'Consumption', 'Critical Illness', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Equipment', 'Etiology', 'Face', 'Failure', 'Floor', 'General Anesthesia', 'Health', 'Healthcare', 'Heart Arrest', 'Human', 'Human Resources', 'Image', 'Image Analysis', 'Imaging technology', 'Intensive Care Units', 'Interobserver Variability', 'Intubation', 'Medical', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Nose', 'Operative Surgical Procedures', 'Oral cavity', 'Patient Care', 'Patient imaging', 'Patients', 'Performance', 'Perioperative', 'Pre-hospital setting', 'Predictive Value', 'Probability', 'Procedures', 'Public Health', 'Reproducibility', 'Research', 'Respiratory Failure', 'Scientist', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Systems Analysis', 'Techniques', 'Test Result', 'Testing', 'Time', 'Trachea', 'Tracheostomy procedure', 'Training', 'Tube', 'United States National Institutes of Health', 'Visual', 'Work', 'autoencoder', 'automated image analysis', 'base', 'clinical care', 'clinical practice', 'deep learning', 'design', 'disorder risk', 'endotracheal', 'experience', 'improved', 'indexing', 'innovation', 'mortality', 'novel strategies', 'patient safety', 'recruit', 'respiratory', 'response', 'risk stratification', 'standard of care', 'tool']",NIBIB,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R21,2021,193750
"Computational Methods for Enhancing Privacy in Biomedical Data Sharing Project Summary Data sharing is essential to modern biomedical data science. Access to a large amount of genomic and clinical data can help us better understand human genetics and its impact on health and disease. However, the sensitive nature of biomedical information presents a key bottleneck in data sharing and collection efforts, limiting the utility of these data for science. The goal of this project is to leverage cutting-edge advances in cryptography and information theory to develop innovative computational frameworks for privacy-preserving sharing and analysis of biomedical data. We will draw upon our recent success in developing secure pipelines for collaborative biomedical analyses to address the imminent need to share sensitive data securely and at scale.  Practical adoption of existing privacy-preserving techniques in biomedicine has thus far been largely limited due to two major pitfalls, which this project overcomes with novel technical advances. First, emerging cryptographic data sharing frameworks, which promise to enable collaborative analysis pipelines that securely combine data across multiple institutions with theoretical privacy guarantees, are too costly to support complex and large-scale computations required in biomedical analyses. In this project, we will build upon recent advances in cryptography (e.g., secure distributed computation, pseudorandom correlation, zero-knowledge proofs) to significantly enhance the scalability and security of cryptographic biomedical data sharing pipelines. Second, existing approaches that locally transform data to protect sensitive information before sharing (e.g. de-identification techniques) either offer insufficient levels of protection or require excessive perturbation in order to ensure privacy. We will draw upon recent tools from information theory to develop effective local privacy protection methods that achieve superior utility-privacy tradeoffs on a range of biomedical data including genomes, transcriptomes, and medical images by directly exploiting the latent correlation structure of the data.  To promote the use of our privacy techniques, we will create production-grade software of our tools and publicly release them. We will also actively participate in international standard-setting organizations in genomics, e.g. GA4GH and ICDA, to incorporate our insights into community guidelines for biomedical privacy. Successful completion of these aims will result in computational methods and software tools that open the door to secure sharing and analysis of massive sets of sensitive genomic and clinical data. Our long-term goal is to broadly enable data sharing and collaboration efforts in biomedicine, thus empowering researchers to better understand the molecular basis of human health and to drive translation of new biological insights to the clinic. Project Narrative Rapidly-growing volume of biomedical datasets around the world promises to enable unprecedented insights into human health and disease. However, increasing concerns for individual privacy severely limited the extent of data sharing in the field. This project draws upon cutting-edge tools from cryptography and information theory to develop effective privacy- preserving methods for collecting, sharing, and analyzing sensitive biomedical data to empower advances in genomics and medicine.",Computational Methods for Enhancing Privacy in Biomedical Data Sharing,10260457,DP5OD029574,"['Address', 'Adoption', 'Biological', 'Biology', 'Biomedical Research', 'Brain', 'Clinic', 'Clinical Data', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Disease', 'Electronic Health Record', 'Engineering', 'Enhancement Technology', 'Ensure', 'Foundations', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Genetics', 'Image', 'Individual', 'Information Theory', 'Institutes', 'Institution', 'Interdisciplinary Study', 'International', 'Knowledge', 'Letters', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Mathematics', 'Medical Genetics', 'Medical Imaging', 'Mentorship', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Pattern', 'Pharmacology', 'Policies', 'Polynomial Models', 'Preservation Technique', 'Privacy', 'Privatization', 'Production', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Science', 'Secure', 'Security', 'Software Tools', 'Structure', 'Techniques', 'Technology', 'Translations', 'Vision', 'Work', 'analysis pipeline', 'base', 'biomedical data science', 'computer framework', 'computing resources', 'cost', 'cryptography', 'data sharing', 'design', 'empowered', 'experience', 'experimental study', 'genetic analysis', 'genome wide association study', 'genomic data', 'infancy', 'innovation', 'insight', 'novel', 'privacy preservation', 'privacy protection', 'software development', 'statistics', 'success', 'task analysis', 'tool', 'transcriptome', 'transcriptomics', 'web server']",OD,"BROAD INSTITUTE, INC.",DP5,2021,392799
"A Dental implant registry of treatment outcomes of implant therapy by practitioners in the National Dental Practice Based Research Network There is a substantial body of literature to support that biological and prosthetic complications occur which may interfere with the health of the peri-implant tissues, the function and esthetics of the implant restoration. Peri-implant diseases are classified into peri-implant mucositis, inflammation restricted to the peri-implant mucosa, and peri-implantitis, characterized by peri-implant bone loss. The limitations of the current body of literature of biologic and prosthetic complications are based on many small studies and in large part conducted in an academic and specialty setting. We propose to create an implant registry within the National Dental Practice Based Research Network (NDPBRN) that will record the setting and implant therapy, the implants used, the prosthetic therapy provided and the rate of complications. The registry will create an opportunity for subsequent, additional targeted studies on specific complications available from the registry data and will lead to diagnosis driven therapy strategies. The target enrollment is a total of 2000 implants with prosthesis across the whole network. The one year UG3 Phase will be used to create a strategy to be able to meet the recruitment and enrollment objectives and to develop the protocol for data collection to facilitate the data gathering of the practitioners for the subjects they enroll. The data collection model we propose will be designed to be validated, concise, and easy to use for practitioners. We will develop a web based decision tree that will guide the practitioner through the data collection. The UH3 phase will recruit practitioners with representation of all 6 regions of the network that will enroll subjects with 2000 implants. Data collection will be detailed and comprehensive and will include surgical, prosthetic, and biologic aspects of implant therapy and radiographs for bone level assessments for a period of 3 years. The data will present clinically meaningful information about the prevalence of the various implant therapies, the incidence of prosthetic and biologic implant complications, risk factors for implant complications and evidence-based implant therapy strategies in every dental practices. We expect that the results from this study will significantly impact the clinical practice of implant dentistry and the quality of care provided for the patients. We propose to create an Implant Registry capturing implant therapy that is provided by practitioners within the NDPBRN. The aim is to determine the therapies associated with the greatest amount of success and the least amount of complications. With the data generated through this registry, we will add to the generalizable knowledge about implant therapy, the complications and therapies associated with implant success at the fixture level and the patient level.",A Dental implant registry of treatment outcomes of implant therapy by practitioners in the National Dental Practice Based Research Network,10101988,UG3DE030090,"['Biological', 'Biological Factors', 'Biometry', 'Budgets', 'Client satisfaction', 'Clinical', 'Complication', 'Data', 'Data Collection', 'Decision Trees', 'Dental General Practice', 'Dental Implants', 'Dentistry', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Enrollment', 'Esthetics', 'Goals', 'Health', 'Image', 'Implant', 'Incidence', 'Inflammation', 'Knowledge', 'Literature', 'Measures', 'Modeling', 'Mucositis', 'Mucous Membrane', 'National Institute of Dental and Craniofacial Research', 'Online Systems', 'Operative Surgical Procedures', 'Oral health', 'Patients', 'Phase', 'Predictive Factor', 'Prevalence', 'Private Practice', 'Prosthesis', 'Protocols documentation', 'Quality of Care', 'Registries', 'Resources', 'Risk Factors', 'System', 'Tissues', 'Training', 'Treatment outcome', 'adjudicate', 'base', 'bone', 'clinical practice', 'data registry', 'design', 'evidence base', 'health related quality of life', 'medical specialties', 'peri-implant bone loss', 'peri-implantitis', 'personalized therapeutic', 'practice setting', 'practice-based research network', 'recruit', 'restoration', 'success', 'tool']",NIDCR,UNIVERSITY OF ALABAMA AT BIRMINGHAM,UG3,2021,202410
"Single-Cell Transcriptomic Analysis of Human Retina PROJECT SUMMARY Vision, the most important of the human senses, occupies 25% of the brain function. It requires an orchestrated coordination between all parts of the eye. Of all the parts, the retina is the most vital for normal perception of an image. It is a precisely layered structure lining the surface of the back of the eye, comprising many millions of cells packed together in a tightly knit network. The optic nerve connects the retina with the brain. The retina not only receives light, but also processes it, and transmits downstream signals to the midbrain and the thalamus. When the retina becomes diseased, the unfortunate result is blindness, which is the most feared disability. Diseases that affect the retina are complex because of the diverse number of cell types and total number of cells involved. It remains challenging to assess if pathological phenotypes affect diverse cell populations versus highly specific cell types. While advances in retinal disease diagnostics have progressed rapidly, treatments for retinal diseases directed at primary genetic defects have progressed slowly. Despite major successes in genetics, the vision community is lagging behind the advances in precision medicine occurring in other specialties. Modest progress is due in part to an incomplete understanding of human retinal biology. Anatomical differences between humans and commonly used animal models have severely hindered the translation of results from laboratory to human health. Therefore, there is an urgent need to collect and analyze retinal cells from human eyes to advance our understanding of human retinal diseases and assess the cell type conservation between mouse and human. Recent technologic breakthroughs in single-cell RNA-seq (scRNA-seq) have made it possible to measure gene expression in single cells, paving the way for exploring cellular heterogeneity. Collaborating with the Alabama Eye Bank, we will deeply sample human retinal cells, fully characterize cell diversity, and elucidate the functional roles of findings from genome- wide association studies for retinal diseases. We propose the following aims. Aim 1 will generate scRNA-seq data from eyes of 20 healthy adult human donors, and produce de-noised gene expression data for downstream analyses. Aim 2 will characterize cell diversity in human retina and supporting tissues, and validate novel cell type-specific marker genes by immunohistochemistry. Aim 3 will infer cell type compositions and allele-specific gene expression in each cell type by integrating scRNA-seq and bulk RNA-seq data from normal human eyes. These pioneering studies leverage novel methods and interdisciplinary expertise to characterize cell type-specific gene expression in human retina and supporting tissues. By detailed characterization of the cell atlases in four geographical areas in human eye, our study will provide novel insights into cell-type specific functions that can power precision therapeutic targeting of retinal diseases. PROJECT NARRATIVE The retina is the most vital for normal perception of an image in the eye. Diseases that affect the retina are complex, and it remains challenging to assess if pathological phenotypes originate in diverse cell populations or highly specific cell types. This application will address the urgent need to collect and analyze retinal cells from postmortem human eyes to advance our understanding of human retinal diseases.",Single-Cell Transcriptomic Analysis of Human Retina,10159930,R01EY030192,"['Address', 'Adult', 'Affect', 'Age related macular degeneration', 'Alabama', 'Alleles', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Atlases', 'Automobile Driving', 'Autopsy', 'Back', 'Biology', 'Blindness', 'Brain', 'Cell physiology', 'Cells', 'Cellular Morphology', 'Choroid', 'Communities', 'Complex', 'Computer software', 'Data', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Eye', 'Eye Banks', 'Eye diseases', 'Fright', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genomics', 'Geographic Locations', 'Health', 'Heterogeneity', 'Hour', 'Human', 'Human Genetics', 'Image', 'Immunohistochemistry', 'Laboratories', 'Light', 'Measures', 'Methods', 'Microglia', 'Midbrain structure', 'Mus', 'Mutation', 'Optic Nerve', 'Pathologic', 'Pattern', 'Perception', 'Phenotype', 'Population', 'Precision therapeutics', 'Process', 'Recovery', 'Retina', 'Retinal Diseases', 'Role', 'Sampling', 'Signal Transduction', 'Stains', 'Structure', 'Structure of retinal pigment epithelium', 'Surface', 'Testing', 'Thalamic structure', 'Thick', 'Thinness', 'Tissues', 'Translations', 'Vision', 'Visualization', 'cell type', 'computerized tools', 'deep learning', 'denoising', 'disability', 'genome wide association study', 'improved', 'insight', 'learning strategy', 'macula', 'medical specialties', 'millimeter', 'novel', 'open source', 'precision medicine', 'protein expression', 'single-cell RNA sequencing', 'success', 'therapeutic target', 'transcriptome sequencing', 'transcriptomics', 'user-friendly', 'web app', 'web site']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2021,534903
"Model-guided design of next-generation bacterial therapeutics to treat cardiovascular disease PROJECT SUMMARY/ABSTRACT It is becoming increasingly evident that the composition and metabolites produced by the human gut microbiome influence the progression of cardiovascular diseases. While we are continuing to discover important associations between the gut microbiome and human physiology and diseases, we lack the tools and methodology to precisely manipulate gut microbiota to benefit human health. We propose to develop computational models and optimization frameworks to predict community dynamics and functions and design interventions to shift the gut microbiome to desired states. We will design novel bacterial therapeutics that operate autonomously in the mammalian gastrointestinal tract to steer the microbiome towards healthy states. These next-generation bacterial therapeutics will sense important gut microbiome metabolites, process information, and deliver species- specific antimicrobial proteins to reshape the dynamics and functions of this ecosystem. The performance of these bacterial therapeutics will be characterized in vitro using synthetic human gut microbiome communities and in gnotobiotic mouse models of cardiovascular disease. Model-guided microbiome engineering has the potential to transform human medicine and is becoming increasingly important as scientists continue to discover connections between the microbiome and human health and disease. PROJECT NARRATIVE Recent studies have shown close connections between the human gut microbiome and cardiovascular diseases (CVDs), which are the leading cause of death worldwide. While engineering of the gut microbiome holds tremendous potential as a novel therapeutic strategy for CVD, we currently lack the tools and methodology required to design interventions that precisely shift the structure and function of the gut microbiome. The major goals of our project are to (1) develop computational modeling techniques to design perturbations that can steer the microbiome to desired states and (2) design next-generation bacterial therapeutics that sense major gut microbiome-produced metabolites and deliver selective antimicrobials to shift microbiome states to ameliorate CVD.",Model-guided design of next-generation bacterial therapeutics to treat cardiovascular disease,10249177,R01EB030340,"['Address', 'Bacteriophages', 'Bacteroides', 'Behavior', 'Biosensor', 'Butyrates', 'Cardiovascular Diseases', 'Cause of Death', 'Communities', 'Complex', 'Computer Models', 'Data', 'Development', 'Disease', 'Ecosystem', 'Engineering', 'Equilibrium', 'Escherichia coli', 'Feedback', 'Gastrointestinal tract structure', 'Genetic Transcription', 'Germ-Free', 'Gnotobiotic', 'Goals', 'Health', 'Human', 'In Vitro', 'Intervention', 'Intestines', 'Lead', 'Machine Learning', 'Mediating', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Organism', 'Performance', 'Phenotype', 'Physiology', 'Probiotics', 'Process', 'Production', 'Protein Engineering', 'Proteins', 'Scientist', 'Stimulus', 'Structure', 'System', 'Techniques', 'Therapeutic', 'Time', 'Work', 'antimicrobial', 'computer framework', 'design', 'dynamic system', 'gut microbiome', 'gut microbiota', 'human disease', 'lysin', 'member', 'microbial', 'microbial community', 'microbiome', 'microbiome alteration', 'mouse model', 'next generation', 'novel', 'novel therapeutic intervention', 'personalized medicine', 'predictive modeling', 'prototype', 'real time monitoring', 'response', 'sensor', 'therapy design', 'tool', 'trimethylamine']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,667219
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10225620,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'risk stratification', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,707970
"A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC) Project Summary/Abstract: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will include datasets produced locally at Washington University: The Connectome Coordination Facility (CCF) (which itself includes the Human Connectome Project (HCP) Young Adult study, The Lifespan related projects, the Disease related projects, and assorted HCP-related projects), The Knight Alzheimer Disease Research Center (ADRC), the Adolescent Brain Cognitive Development (ABCD) Study, The Comprehensive Neuro-Oncology Data Repository (CONDR), and the clinically-based PACS image repository. In addition, copies of external data collections such as the UK Biobank, The Alzheimer's Disease Neuroimaging Initiative (ADNI), and The Cancer Image Archive (TCIA) will be maintained. The RIR includes a data management software solution that will introduce many novel features (such as `data tagging' to enrich datasets, and advanced search features) and will allow us to leverage existing storage including the Center for High Performance Computing's (CHPC) 1.4PB of BeeGFS `scratch' storage, solid-state NVMe drives integrated into the compute nodes, and 10PB of ZFS-based storage. All storage will be presented to the user as a single file-system, while data will be migrated to different performance tiers based on the storage requirements of the datasets or processing algorithms. The RIR will be integrated into the CHPC for data processing. The proposal also includes two NVIDIA DGX A100 GPU servers providing state-of-the-art GPU- based processing power. The combination of high-quality, diverse sets of biomedical imaging data with next- generation computing power will have a transformative effect on biomedical imaging processing pipelines and nowhere will the effects be more profound than in the emerging field of Deep Learning for image processing. Project Narrative: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will be integrated into Washington University in St. Louis's Center for High Performance Computing (CHPC) to process the data and will leverage over 11PB of existing storage.",A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC),10177147,S10OD030477,"['Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Clinical', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Disease', 'High Performance Computing', 'Human', 'Longevity', 'Performance', 'Research', 'System', 'The Cancer Imaging Archive', 'Universities', 'Washington', 'base', 'biobank', 'bioimaging', 'cognitive development', 'computerized data processing', 'connectome', 'data management', 'data repository', 'deep field survey', 'deep learning', 'image archival system', 'image processing', 'neuro-oncology', 'neuroimaging', 'next generation', 'novel', 'solid state', 'young adult']",OD,WASHINGTON UNIVERSITY,S10,2021,1927344
"Epidemiology of Biomarkers of AMD Progression Project Abstract There are currently no effective treatments for atrophic age-related macular degeneration (AMD), in part because we may be intervening too late in the disease course after geographic atrophy (GA) has developed. A far preferable strategy would be to intervene at an earlier phase of the disease, but there is uncertainty with regards to disease biomarkers to select the most appropriate patients as well as endpoints which could be used to conduct an interventional trial in a clinically-practical time-frame. This is in large part because of the lack of a sufficiently granular staging system describing the progression from early to late stage AMD. The best currently available data comes from studies such as the Age-Related Eye Diseases Study and the Beaver Dam Eye Study, but these studies were largely based on color fundus photographs with AMD disease features assessed using historical protocols developed in the film-based imaging era. The AMD disease severity scales and staging systems built from these studies are insufficiently granular and fail to take advantage of modern, pervasive digital imaging technologies such as optical coherence tomography (OCT) and OCT angiography (OCT-A) which readily lend themselves to quantification. Extensive research over the past decade has identified a number of structural OCT features of AMD, such as intraretinal hyper-reflective foci and subretinal drusenoid deposits, which appear to increase the risk for developing late AMD (atrophy and/or neovascularization). More recently, choriocapillaris (CC) flow deficits have been shown to increase with age and in AMD. The relationship between CC flow deficits and the onset and stage of AMD still remains to be defined. In addition, although a number of genetic risk factors for AMD have been identified, the genetics of AMD progression are not yet elucidated. This research application proposes to address these critical knowledge gaps by evaluating elderly subjects with AMD who have previously been recruited as part of the NEI-funded Amish Eye Study. The Amish represent a homogenous population with regards to environmental and social exposures which reduces variability and makes this group ideally suited for epidemiologic studies of AMD progression. Through that previous study, baseline (and some 2-year follow up) clinical, multimodal imaging (including OCT), and genetic data have already been collected. However, long-term (7 year) data, which will be a focus of our proposed research, is critical to actually establish which individuals go on to progress to late AMD, which is vital in order to determine which baseline features are associated with a higher risk of progression, and to develop a granular and quantitative staging system for AMD. The development of this novel AMD staging system will provide points of intervention and outcome assessment to enable early intervention clinical trials and provide new insights into the genetics and pathophysiology of AMD. Project Narrative Despite effective treatments for choroidal neovascularization, age-related macular degeneration (AMD) remains the leading cause of blindness in the US due to the eventual development of atrophy in the long-term. As current attempts to develop therapies to slow the progression of atrophy have met with limited success, earlier intervention would be desirable, and could be possible if endpoints and biomarkers to assess progression early in the disease were available. By studying the epidemiology of AMD progression over 7 years, the proposed research will identify these critical biomarkers and develop a staging system for AMD which is essential to enable early intervention clinical trials for AMD.",Epidemiology of Biomarkers of AMD Progression,10233694,R01EY030614,"['Address', 'Age', 'Age related macular degeneration', 'Age-Years', 'Amish', 'Angiogenesis Inhibitors', 'Angiography', 'Atrophic', 'Background Diabetic Retinopathy', 'Beavers', 'Biological Markers', 'Blindness', 'Calibration', 'Categories', 'Choroid', 'Choroidal Neovascularization', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Color', 'Data', 'Deposition', 'Development', 'Diabetic Retinopathy', 'Disease', 'Drusen', 'Early Intervention', 'Elderly', 'Epidemiology', 'Evolution', 'Eye', 'Eye diseases', 'Film', 'Functional disorder', 'Funding', 'Fundus', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Image', 'Imaging technology', 'Individual', 'Intervention', 'Intervention Trial', 'Knowledge', 'Methods', 'Modeling', 'Modernization', 'Multimodal Imaging', 'Nonexudative age-related macular degeneration', 'Optical Coherence Tomography', 'Outcome Assessment', 'Patients', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Principal Component Analysis', 'Probability', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Retina', 'Risk', 'Risk Factors', 'Series', 'Severities', 'Severity of illness', 'Staging', 'Staging System', 'Structure', 'Supervision', 'System', 'Techniques', 'Testing', 'Therapeutic Trials', 'Time', 'Uncertainty', 'United States', 'Validation', 'Visit', 'age related', 'base', 'clinical practice', 'cohort', 'cost', 'deep learning', 'design', 'digital imaging', 'effective therapy', 'effectiveness evaluation', 'epidemiology study', 'follow-up', 'genetic risk factor', 'geographic atrophy', 'high risk', 'improved', 'insight', 'learning algorithm', 'macula', 'neovascularization', 'novel', 'population based', 'prevent', 'recruit', 'risk variant', 'social', 'statistical learning', 'success', 'therapy development', 'three-dimensional visualization']",NEI,DOHENY EYE INSTITUTE,R01,2021,640560
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Personalized 3D avatar tool development for measurement of body perception across gender identities Abstract Public awareness of the diversity of experiences of gender identities has climbed sharply. The specific issues of those with gender dysphoria (GD) related to self-identity, body image, and medical interventions are challenges for the 21st century, particularly given the high risk of suicide. Gender identity is tightly linked to one’s bodily features, particularly readily observable sexual characteristics. For transgender and nonbinary individuals with GD, the incongruence between their body associated with their birth-assigned sex – what they see in the mirror before any treatment – and the internalized representation of their gender-identified body is a key defining part of their experience and contributes to their dysphoria. Currently, no clinical or research tool exists to capture and quantify the diverse experiences of one’s current body and one’s gender-identified body (which may be distinct from their current body), across a range of gender identities. Measuring the internalized representation of one’s body could be facilitated by technology to visually represent this on a three-dimensional avatar. The technology needed to scan and analyze the human figure is now available and cost efficient. It is now possible to scan individuals to create personalized 3D visualizations, or “avatars,” with which they can interact on mobile and desktop devices to represent internal representation of their bodies. This can allow individuals to see and manipulate their own 3D avatar with a high degree of flexibility. The goal of this project is to create a novel, visually based digital tool to measure, understand, and quantify individuals’ experiences of their bodies. We will develop, validate, and test in transgender, nonbinary, and cisgender adults a personalized avatar tool to represent internalized gender-identified bodies in order to quantify incongruence between this and one’s current body. This tool – “GD Somatomap” – will be an advancement over existing self-report questionnaires to capture visual representations of internalized body image, cross-sectionally and dynamically over time. It will be flexible enough to characterize the heterogenous experiences of a range of gender identities including binary transgender, gender fluid, nonbinary, and cisgender. It can be used in clinical and clinical research applications to track outcomes of cross-hormone and gender-affirming surgical treatments. It can potentially improve clinical outcomes by identifying specific sets of body parts as targets for treatments to improve body congruence. Further, it will provide a unique means to measure own-body perceptual accuracy; understanding differences in perceptual accuracy and what potentially modifiable factors contribute to this may have prognostic significance for treatments to address body incongruence. It could also be used in future studies to investigate functional and structural neurobiological correlates of body perception and internal body representation, and at what point in neurodevelopment these emerge for those with different gender identities. PROJECT NARRATIVE The internalized, conscious experience of one’s body is not easily communicated, much less measured and quantified. This is especially relevant for those with gender dysphoria, whose internal, gender-identified body representation is incongruent with their current body. We will develop and test an innovative technological solution, making use of 3D image reconstruction and advanced 3D modeling, to create personalized avatars to measure body incongruence for research and clinical applications in those with gender dysphoria.",Personalized 3D avatar tool development for measurement of body perception across gender identities,10480133,R21EB030851,"['3-Dimensional', 'Address', 'Adult', 'Area', 'Awareness', 'Birth', 'Body Image', 'Body measure procedure', 'Body part', 'Breast', 'Characteristics', 'Clinical', 'Clinical Research', 'Computer software', 'Conscious', 'Data', 'Development', 'Devices', 'Discriminant Analysis', 'Distress', 'Future', 'Gender', 'Gender Identity', 'Goals', 'Gonadal Steroid Hormones', 'Grouping', 'Hormonal', 'Hormones', 'Human body', 'Individual', 'Intervention', 'Least-Squares Analysis', 'Link', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Neurobiology', 'Operative Surgical Procedures', 'Outcome', 'Patient Self-Report', 'Physical shape', 'Problem Solving', 'Questionnaires', 'Reporting', 'Research', 'Scanning', 'Sex Characteristics', 'Shapes', 'Specific qualifier value', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Time', 'Validation', 'Visual', 'Waist-Hip Ratio', 'base', 'body dissatisfaction', 'cisgender', 'clinical application', 'cost efficient', 'digital', 'dysphoria', 'experience', 'flexibility', 'follow-up', 'gender dysphoria', 'gender fluid', 'high risk', 'image reconstruction', 'improved', 'innovation', 'neurodevelopment', 'novel', 'prognostic significance', 'sex', 'suicidal risk', 'three-dimensional modeling', 'three-dimensional visualization', 'tool', 'tool development', 'transgender', 'unsupervised learning']",NIBIB,CENTRE FOR ADDICTION AND MENTAL HEALTH,R21,2021,167495
"Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy Abstract Socket augmentation after tooth extraction by placing either allograft or xenograft bone particulates in the socket is frequently applied to reduce jawbone volume shrinkage for subsequent implant placement. Socket healing after the augmentation varies largely, ranging from uneventful healing to infection, failure of bone graft integration and severe bone loss due to bacterial infection and/or local/systemic conditions. The healing duration, which dictates the timing of implant placement, is widely different as well. Currently, an arbitrary waiting time of 6 months after socket augmentation is adopted, when a 2-dimensional (2D) or 3D radiograph, along with a visual examination is performed to assess hard- and soft-tissue healing to determine the readiness and strategy for the subsequent implant surgery. However, 3D radiographs are not recommended for longitudinal use to monitor socket healing due to radiation concerns. They have lower image resolution (250-500 µm), which limits their ability to evaluate bone surface healing, and inferior soft tissue contrast. A non-radiation and point-of-care method that can evaluate both hard- and soft-tissue longitudinally is much needed for a definitive, accurate, and timely diagnosis of socket healing pathologies. A high-frequency and miniature-sized intraoral ultrasound probe that can operate on an off-the-shelf scanner has been manufactured in collaboration with industry (see support letter) by our research team. Research conducted by our group demonstrated accuracy of this probe in measuring various oral and dental structures. The central hypothesis is to develop ultrasound-based imaging to characterize and grade socket healing lesions in determining the extent and severity of disease. To test this hypothesis, two aims are proposed: Aim 1. Evaluate the diagnostic value of ultrasonic images for bone grafting procedures of dental extraction sockets in a longitudinal clinical study (from -2 months to +6 months of graft placement). We will compare other imaging and clinical diagnostic tools for assessing hard- and soft tissue, anatomical and physiological status throughout the longitudinal study time-course. Aim 2. Develop an extended-view scan-mode for acquiring large field- of-view jawbone images and determine buccal (facial) to lingual tissue morphology. We will engage the manufacturer (see support letter) to modify the existing scanner for this dental specific application. Design goals will include the creation of an extended, large angle, field-of-view to visualize the buccal to lingual jaw bone surface and to create machine learning based measurement tools, including soft- and hard-tissue thickness and surface analysis. Successful execution of the proposed aims will result in an imaging-based tool for longitudinal socket augmentation evaluation that is based on soft- and hard-tissue features and will allow the care provider to choose deviation from current clinical procedures where indicated. This would be investigated subsequently in a specifically designed clinical trial. Narrative The goals of this investigation are to follow dental patients that require bone grafts before their dental implant is placed and to demonstrate the diagnostic opportunities that ultrasound adds to the current standard of clinical dental care. 3",Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy,10427073,R56DE030872,"['3-Dimensional', 'Adopted', 'Allografting', 'Anatomy', 'Atrophic', 'Bacterial Infections', 'Blood', 'Blood flow', 'Bone Surface', 'Bone Transplantation', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials Design', 'Collaborations', 'Dental', 'Dental Care', 'Dental Implants', 'Dental caries', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Face', 'Failure', 'Frequencies', 'Goals', 'Gold', 'Image', 'Implant', 'Implantation procedure', 'Industry', 'Infection', 'Inferior', 'Inflammation', 'Investigation', 'Ionizing radiation', 'Jaw', 'Lateral', 'Lesion', 'Letters', 'Longitudinal Studies', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Miniaturization', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Oral', 'Oral cavity', 'Organ Transplantation', 'Outcome', 'Particulate', 'Pathology', 'Patients', 'Perfusion', 'Physiological', 'Procedures', 'Process', 'Quality of life', 'Radiation', 'Readiness', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Severities', 'Severity of illness', 'Site', 'Structure', 'Surface', 'Testing', 'Thick', 'Time', 'Time Study', 'Tissues', 'Tooth Extraction', 'Ultrasonography', 'United States', 'Visual', 'Wait Time', 'base', 'bone', 'bone healing', 'bone loss', 'bone xenograft', 'care providers', 'clinical diagnostics', 'cone-beam computed tomography', 'dental structure', 'design', 'experience', 'graft failure', 'graft healing', 'healing', 'improved', 'oral care', 'point of care', 'soft tissue', 'targeted treatment', 'tool', 'two-dimensional']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R56,2021,642438
"Metal-nutrient mixtures in epidemiologic and toxicologic studies of cardiovascular disease Abstract This proposal is designed to extend and complement our R01-funded case-cohort study of cadmium (Cd) and acute myocardial infarction (AMI). Herein we will add arsenic (As), calcium (Ca), and magnesium (Mg) to our case-cohort study and include epidemiologic and toxicologic mixtures analyses. The four elements we have selected are compelling for their independent role in cardiovascular disease (CVD) and as a mixture. As increases plaque formation and adhesion to endothelium and Cd also induces endothelial dysfunction and atherosclerosis; yet it is not clear if the effects of As and Cd are synergistic or competing. To potentially counteract these processes, Mg is important for modulating endothelial function. While Ca’s role is equivocal, its role in calcification of the arteries is undeniable, making it important to consider as well. Our efficient case-cohort study design includes 810 cases of AMI and a comparison subcohort of 600 men and 600 women selected randomly from never smokers at risk of AMI at the start of follow-up, leveraging the prospective population-based Danish Diet Cancer and Health Cohort. We are already funded to measure Cd, creatinine, osmolality, and cotinine in baseline urine samples. We now propose to additionally analyze As species, Mg, and Ca in urine among ~2000 participants selected into this case-cohort study, along with pre-existing food frequency questionnaire data on Mg and Ca. In Aim 1 we will evaluate the association between each of As, Ca, and Mg, and incidence of AMI. This will be one of the largest prospective studies of these elements in relation to AMI. In Aim 2 we will apply mixtures methods (Bayesian kernel machine regression, weighted quantile sum regression, random forests) to evaluate the interactive and joint effects of Cd, As, Ca, and Mg in relation to AMI risk. In Aim 3 we will apply in vitro and in vivo approaches to study combined effects of exposure to these elements to investigate the toxicologic mechanisms and pathways of activity. Each Aim is independently compelling and will provide important scientific contributions but together the complementary approaches have the potential to provide evidence of consistency in findings across the distinct approaches. Triangulating data across in vitro, in vivo and epidemiologic analyses represents a translational bridge as depicted in the NIEHS translational research framework. The scope of this virtual consortium will enrich our understanding of the relationships between Cd, As, Mg, Ca, and CVD. Other innovative features of our study include leveraging an existing efficient case-cohort design, large sample size, a large number of incident AMI events, controlling for tobacco smoking, in vitro assays of pro-atherogenic mechanisms, and in vivo studies of atherosclerosis. Sources of exposure to these elements are well known, therefore the identification of mixtures of these elements as cardiovascular risk/protective factors can have major implications for the prevention and control of CVD. Public Health Relevance Mechanistic and epidemiologic studies suggest a mixture of elements including cadmium, arsenic, magnesium, and calcium may play an important role in cardiovascular disease as risk and protective factors. We propose to create a virtual consortium to study chemical mixtures of these elements in relation to risk of cardiovascular disease using state-of-the-art techniques in exposure science, epidemiology, biostatistics, and cardio-toxicology. Sources of exposure to these elements are well known, therefore the identification of mixtures of these elements as cardiovascular risk/protective factors can have major implications for the prevention and control of cardiovascular disease.",Metal-nutrient mixtures in epidemiologic and toxicologic studies of cardiovascular disease,10254343,R01ES030938,"['Acute myocardial infarction', 'Adhesions', 'Apolipoprotein E', 'Arsenic', 'Arteries', 'Atherosclerosis', 'Behavioral', 'Biological Markers', 'Biometry', 'Cadmium', 'Calcium', 'Cardiovascular Diseases', 'Cell Adhesion', 'Chemicals', 'Cholesterol', 'Clinical Data', 'Cohort Studies', 'Collection', 'Complement', 'Cotinine', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Elements', 'Endothelial Cells', 'Endothelium', 'Epidemiology', 'Event', 'Exposure to', 'Food', 'Frequencies', 'Funding', 'Generations', 'Health', 'Hypertension', 'In Vitro', 'Incidence', 'Joints', 'Knockout Mice', 'Lipids', 'Magnesium', 'Measures', 'Metals', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Institute of Environmental Health Sciences', 'Nutrient', 'Osmolalities', 'Participant', 'Pathway interactions', 'Physical activity', 'Play', 'Population', 'Prevention', 'Process', 'Prospective Studies', 'Prospective cohort', 'Questionnaires', 'Reactive Oxygen Species', 'Regression Analysis', 'Reporting', 'Research Design', 'Risk', 'Risk Factors', 'Role', 'Sample Size', 'Sampling', 'Science', 'Side', 'Smoking', 'Source', 'Spottings', 'Sum', 'Techniques', 'Tobacco smoking behavior', 'Toxicology', 'Translational Research', 'Urine', 'Woman', 'calcification', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'cohort', 'design', 'diet and cancer', 'endothelial dysfunction', 'epidemiology study', 'follow-up', 'hazard', 'in vitro Assay', 'in vivo', 'innovation', 'macrophage', 'men', 'mortality', 'mouse model', 'never smoker', 'novel', 'population based', 'prospective', 'protective factors', 'public health relevance', 'random forest', 'recruit', 'urinary', 'virtual']",NIEHS,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2021,601096
"Development of Nanomembrane Electronics and Machine-Learning Algorithms for Quantitative Screening of Dysphagia Therapeutics Project Summary Dysphagia is an impairment of the swallow reflex's neurological and muscular functions that causes a debilitating and potentially deadly condition such as choking, malnutrition, dehydration or pneumonia during swallowing. Dysphagia afflicts almost 15 million Americans, particularly individuals 50-60 years or older with up to a 20% chance of dysphagia. However, regardless of the cause of dysphagia, currently there are no available therapeutic treatments. Limitation of preclinical tools and methods to study dysphagia is one of the biggest reasons for the lack of therapeutic treatment for dysphagia. Video-fluoroscopic swallowing study (VFSS) has been used to diagnose dysphagia in a clinical study as well as research with animal models for drug development. However, the VFSS method in clinical study relies on the active cooperation of a human subject, such as ingestion of food with barium (oral contrast agent) and movement immobilization during X-ray imaging. The VFSS tool shows the severe issue in an animal study due to uncontrollable target, which results in poor image quality and unreliable drug development. Overall, none of the existing commercial systems can offer a portable, real-time, continuous monitoring of swallowing with either humans or animals. Here, this project will develop a novel, nanomembrane electronic system that offers a continuous, quantitative assessment of swallowing activities in a non-invasive way on the skin of rat models, which will help to develop potential dysphagia drugs. Specifically, we will develop soft, ultrathin, lightweight, miniaturized wearable electronics to monitor time-dependent changes of swallowing muscle functions via wireless, real-time recording of electromyograms on swallowing muscles of a dysphagia rat model. In this project, our initial study in the evaluation of dysphagia therapeutics will focus on ALS-related dysphagia since there are well-established animal models (transgenic superoxide dismutase; SODG93A) with severe dysphagia at a young age. SODG93A animal models have been widely used to screen potential therapeutic compounds, including two FDA-approved ALS drugs: edaravone and riluzole. Collectively, if successful, the newly developed nanomembrane electronics will be a game-changer in the therapeutic evaluation of candidate drugs for ALS-related dysphagia as well as other diseases- related dysphagia. The research outcome is expected to provide a new drug for an effective treatment of dysphagia, which will eventually reduce mortality and improve the quality of life of dysphagia patients. Project Narrative Dysphagia afflicts almost 15 million Americans, particularly individuals 50-60 years or older with up to a 20% chance of dysphagia. However, there is no available therapeutic treatment for dysphagia. Although ongoing research is focusing on the development of new drugs, none of the existing systems provides a quantitative, continuous evaluation of drug efficacy with animal models and human subjects. Here, we aim to develop a novel, nanomembrane electronic system that offers a continuous, quantitative assessment of swallowing activities in a non- invasive way with rat models, which will help to develop new dysphagia drugs.",Development of Nanomembrane Electronics and Machine-Learning Algorithms for Quantitative Screening of Dysphagia Therapeutics,10373326,R21EB031535,"['Age', 'American', 'Animal Model', 'Animals', 'Barium', 'Choking', 'Clinical Research', 'Contrast Media', 'Coughing', 'Data', 'Deglutition', 'Deglutition Disorders', 'Dehydration', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Drug Evaluation', 'Electronics', 'Evaluation', 'Experimental Designs', 'FDA approved', 'Food', 'Guidelines', 'Human', 'Image', 'Immobilization', 'Impairment', 'Individual', 'Ingestion', 'Malnutrition', 'Mastication', 'Measurement', 'Mechanics', 'Methods', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'Muscle function', 'Neurologic', 'Oral', 'Outcomes Research', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pneumonia', 'Quality of life', 'Rattus', 'Reflex action', 'Research', 'Riluzole', 'Signal Transduction', 'Skin', 'Stretching', 'Superoxide Dismutase', 'System', 'Systems Integration', 'Testing', 'Therapeutic', 'Time', 'Transgenic Organisms', 'Wireless Technology', 'base', 'classification algorithm', 'computerized data processing', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'drug candidate', 'drug classification', 'drug development', 'drug efficacy', 'effective therapy', 'efficacy evaluation', 'flexibility', 'human subject', 'improved', 'in vivo', 'light weight', 'machine learning algorithm', 'miniaturize', 'mortality', 'nanomembrane', 'novel', 'novel therapeutics', 'phenylmethylpyrazolone', 'portability', 'pre-clinical', 'screening', 'signal processing', 'therapeutic evaluation', 'tool', 'wearable device', 'wearable sensor technology']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R21,2021,211947
"FluoRender: Rapid Quantitative Analysis and Adaptive Workflows for Fluorescence Microscopy Data in Fundamental Biomedical Research Summary FluoRender is a software package for interactive visualization and analysis of multichannel and multidimensional fluorescence microscopy data. This project will serve the pressing needs of biologists utilizing fluorescence microscopy for flexible and reliable data analysis and address the problems in fundamental biomedical research that demands rapid measurements and workflow prototyping. Specific Aim 1: Interactive and collaborative measurement and analysis of large multidimensional microscopy data. We will add rapid measurement tools specifically designed for three pilot studies of our close collaborators at the University of Utah. FluoRender will take full advantage of latest graphics processing unit (GPU) computing techniques and streamed processing to handle large data at interactive speed, ensuring the success of the collaborative projects. Specific Aim 2: Applying machine learning to user workflows and data analysis. We will support diverse data analysis needs from FluoRender users and provide automatic workflow assembly using machine learning. We will incorporate user interactions in a human-in-the-loop approach to address the problem of insufficient training examples and enhance interpretability in machine learning. Specific Aim 3: Interoperability between FluoRender and other popular open-source image analysis software. We will support invoking ImageJ/Fiji modules from FluoRender user interface. Users will be able to apply familiar ImageJ/Fiji functions combined with FluoRender interactive tools. Frequently accessed external functions will be converted to native FluoRender implementations to improve efficiency and accuracy. Specific Aim 4: Immersive volumetric data presentation. We will support the augmented reality (AR) headsets and holographic displays for immersive data analysis. These emerging display technologies will have more natural user interactions than the virtual reality (VR) devices and be advantageous for analyzing 3D data in scientific research. Narrative The proposed research will enhance software tools for understanding fundamental biology and will contribute to the knowledge about the nature of living systems. Biological processes in fundamental research can be imaged with microscopy and FluoRender, the proposed analysis tool, will aid biologists to understand these processes.",FluoRender: Rapid Quantitative Analysis and Adaptive Workflows for Fluorescence Microscopy Data in Fundamental Biomedical Research,10276704,R01EB031872,"['3-Dimensional', 'Acceleration', 'Address', 'Adopted', 'Augmented Reality', 'Behavior', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Code', 'Collaborations', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Development', 'Devices', 'Elements', 'Ensure', 'Feedback', 'Fiji', 'Fluorescence Microscopy', 'Hybrids', 'Image', 'Image Analysis', 'Immersion', 'International', 'Java', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Microscopy', 'Modeling', 'Modernization', 'Molecular Conformation', 'Morphology', 'Nature', 'Organism', 'Pilot Projects', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Software Tools', 'Source', 'Speed', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Visualization', 'Work', 'analysis pipeline', 'augmented reality headset', 'base', 'computerized data processing', 'design', 'diverse data', 'flexibility', 'fundamental research', 'head mounted display', 'human-in-the-loop', 'image processing', 'improved', 'interactive tool', 'interoperability', 'novel', 'open source', 'prototype', 'response', 'statistics', 'success', 'tool', 'two-dimensional', 'usability', 'virtual reality', 'virtual reality headset']",NIBIB,UNIVERSITY OF UTAH,R01,2021,1143750
"Focal nerve fiber layer reflectance analysis for glaucoma evaluation PROJECT SUMMARY Glaucoma is a leading cause of blindness, and effective glaucoma management requires early detection. Nerve fiber layer (NFL) thickness measurement by optical coherence tomography (OCT) is useful for confirming the diagnosis of glaucoma, but its diagnostic sensitivity is not sufficient to be used alone for population-based screening.  NFL reflectivity is reduced in glaucoma subjects, presumably due to loss of axons and axonal microtubule content. But its diagnostic value is diminished by its dependence on the incident angle of the OCT beam, which is highly variable in routine clinical imaging. We hypothesize that the diagnostic accuracy can be boosted by reducing incidence angle effects with azimuthal filtering of NFL reflectance profile, and by analysis of focal rather than average reflectance changes. The preliminary result, bases on 100 normal and glaucoma eyes, showed that the diagnostic sensitivity was significantly improved from 71% for average NFL thickness to 97% for focal NFL reflectance loss in PG eyes, at a 99% specificity cutoff. We propose to validate this result in the large Advanced Imaging for Glaucoma (AIG) study dataset that comprises 249 perimetric glaucoma (PG), 252 pre-perimetric glaucoma (PPG), and 145 normal participants. The AIG study has an average follow-up of more than 4 years, which also allows assessment of the accuracy in predicting glaucoma progression. 1. Reproduce the high diagnostic accuracy of focal NFL reflectance loss analysis using the large AIG  dataset. If we could again demonstrate high diagnostic accuracy in the AIG dataset, especially in the PPG  and early PG subgroups, this could bring OCT glaucoma evaluation into the realm of population screening.  The primary performance metric will be the diagnostic sensitivity at a fixed 99% specificity cut point. 2. Use focal NFL reflectance loss to predict visual field (VF) conversion and progression. In the AIG  study, focal thinning of the macular ganglion cell complex (GCC) and peripapillary nerve fiber layer (NFL)  were found to be the best predictors of VF conversion (development of glaucomatous VF abnormality in an  eye with normal baseline VF) and progression (significant worsening of VF). We hypothesize that focal  NFL reflectance loss would have even better predictive accuracy. Predictive accuracy will be assessed  using the area under the receiver operating curve (AROC) and logistic regression (odds ratio). 3. Combine OCT reflectance and structural maps using machine learning to improve glaucoma  diagnostic accuracy. A combination of disc, peripapillary, and macular thickness parameters had  previously been shown to be synergistic, producing higher AROC than any single parameter. We  hypothesize that the addition of the novel NFL reflectance loss map to the set of input parameters will  further enhance the diagnostic accuracy of a machine learning algorithm. PROJECT NARRATIVE Nerve fiber layer (NFL) thickness using OCT is widely used in clinic for glaucoma diagnosis, but the diagnostic sensitivity is limited. Combination of NFL reflectivity and other structural OCT information promises to improve the diagnostic accuracy to a level where population-based screening would be feasible.",Focal nerve fiber layer reflectance analysis for glaucoma evaluation,10108277,R21EY032146,"['Algorithms', 'Area', 'Axon', 'Blindness', 'Clinic', 'Clinical Management', 'Complex', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Diagnostic Specificity', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Glaucoma', 'Image', 'Incidence', 'Logistic Regressions', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Nerve Fibers', 'Odds Ratio', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Performance', 'Population', 'Retina', 'Sampling', 'Scanning', 'Specificity', 'Structure', 'Subgroup', 'System', 'Thick', 'Thinness', 'Visual Fields', 'base', 'clinical imaging', 'cost', 'diagnostic accuracy', 'disorder risk', 'follow-up', 'ganglion cell', 'improved', 'machine learning algorithm', 'macula', 'novel', 'population based', 'screening']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,192500
"Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises Project summary: Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems. This leads to at least 16 million cases of acute gastroenteritis directly linked to pollution at community water systems, with tens of millions more directly impacted by chemical and organic pollutants. Impacts are further exacerbated in locations dealing with water scarcity, in under-served populations, and within other vulnerable populations already suffering from health disparities. Many of these water problems are the direct result of managerial negligence, inconsistent monitoring, and a lack of the ability to anticipate where problems may arise next. While the reasons for drinking water problems are complex, if we could anticipate where health-based drinking water problems were to occur in the future, it could have an immediate and positive impact on tens of millions of Americans annually. Interestingly, extensive data about water quality and the performance of municipal water systems already exists in large, disparate databases. These databases are largely ignored and, when used, are typically used only anecdotally and retroactively. Preliminary evidence suggests that these existing databases, which contain histories of administrative violations and sub-threshold water-quality results, can be mined to accurately predict future drinking water crises. The Superior Statistical Research R&D team is an internationally recognized group of water experts with cross-cutting expertise in statistics/data analysis/modelling/computing, water-quality monitoring of biological and chemical contaminants, and the ability to clearly and compellingly translate water-quality and health information to actionable steps for individuals, organizations and communities. In this Phase I project, we will show that it is possible to predict water-related, health-based problem areas utilizing already collected, historical data on water quality and municipal water system performance. We will begin by harmonizing the disparate water quality and municipal water system performance in two different states (Michigan and Iowa). We will then utilize machine-learning techniques to predict health-based violation histories and will evaluate our methods by comparing predicted violations to actual health-based violations in the previous 5 years. Finally, we will identify at least 10 municipalities determined by our algorithm to be at the highest risk for future health- based water problems and will do systematic sampling to confirm our model-based predictions. We will then demonstrate how making these predictions can be leveraged to profitability by exploring how our model-based predictions can be presented to customers in an economical, usable form. Proof of our concept and profitability models in two states (Phase I) will set us up for widespread (multi-state) database harmonization and improvement of the proposed machine-learning/modelling effort in Phase II. With multi-state harmonized datasets, identification of key data gaps in particular states/areas, and proven financial models, our technology will ultimately lead to dramatic reductions in the number of health-based drinking water problems annually. Project Narrative Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems, but predicting where and when these health-based drinking water problems will occur remains a large and complex obstacle. Current approaches focus on a reactive approach to health-based water-quality violations in community water systems, rather than a proactive one that seeks to anticipate where problems will occur in the future. The overall goal of this project is to leverage large and disparate historical datasets of water quality to accurately predict locations of future health-based water-quality violations, validate the predictions, and commercialize our proprietary predictions as a practical and cost-saving approach to anticipating and heading off future health-based water problems.",Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises,10253600,R43ES033134,"['Acute', 'Address', 'Algorithms', 'American', 'Area', 'Biological Monitoring', 'Chemicals', 'Cities', 'Coal', 'Communities', 'Community Surveys', 'Complex', 'Cost Savings', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ensure', 'Exposure to', 'Filtration', 'Focus Groups', 'Future', 'Gastroenteritis', 'Goals', 'Government', 'Health', 'Human', 'Individual', 'International', 'Iowa', 'Lead', 'Lead levels', 'Link', 'Location', 'Machine Learning', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Municipalities', 'Negligence', 'Pathway interactions', 'Performance', 'Persons', 'Phase', 'Pollution', 'Price', 'Provider', 'Public Health', 'ROC Curve', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Sampling', 'Serinus', 'Site', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Trust', 'Underserved Population', 'Vulnerable Populations', 'Water', 'advocacy organizations', 'base', 'commercialization', 'data harmonization', 'data integration', 'drinking water', 'economic impact', 'health disparity', 'high risk', 'improved', 'inner city', 'innovation', 'large scale data', 'member', 'pollutant', 'predictive modeling', 'research and development', 'rural area', 'statistics', 'water quality', 'water sampling', 'water testing', 'willingness to pay']",NIEHS,"SUPERIOR STATISTICAL RESEARCH, LLC",R43,2021,256579
"Transcriptional Co-Regulators in Epidermis ABSTRACT Our long-term goal is to understand the transcriptional regulation of interfollicular epidermal (IFE) differentiation. The IFE is maintained by proliferating basal layer stem cells that self-renew, but also divide asymmetrically to generate postmitotic progeny deposited into the suprababasal compartment. As these progeny cells move toward the skin's surface they form successively the spinous, granular and cornified layers. The distinct morphology of each epidermal layer, combined with matching sharp boundaries in the expression of landmark genes, has established a stepwise differentiation model for the IFE. We have focused on the later IFE differentiation stages and their control by Grhl3, an evolutionarily conserved transcriptional regulator of epidermal barrier formation. Grhl3 also promotes keratinocyte migration where it activates a gene expression program distinct from that in differentiation. In this renewal application, we propose to employ emerging single cell approaches to define in vivo transcriptional regulation of IFE differentiation and collective keratinocyte migration- -at a scale and resolution not heretofore possible. In Aim 1, we will re-define IFE differentiation based on single cell RNA-seq (scRNA-seq) analysis. Our recent scRNA-seq experiments suggest that many gene batteries with distinct functions have expression patterns that cross different IFE layers, and that there is a large population of transition cells between the basal layer and the first spinous layer. Our hypothesis is that rather than a stepwise process, IFE differentiation is better understood as a continuous process where every cell in the IFE is at a distinct differentiation stage. We will use a new hybridization-based single cell method, to match our scRNA-seq data with landmarks in the IFE. We will also use ATAC-seq, to correlate chromatin accessibility with single cell mRNA expression. In Aim 2, we will understand how Grhl3 and other IFE regulators act in vivo. Unexpectedly, Grhl3 loss leads to an accumulation of an abnormal IFE cell population with progenitor characteristics. We will test the hypotheses that in addition to its well described role in activating terminal differentiation genes, Grhl3 suppresses the formation of this abnormal progenitor cell population. In Aim 3, we will define cellular heterogeneity in the migrating epithelial wound front. We will test the hypotheses that different regions of the migrating wound front contain groups of keratinocytes which can be classified based on their transcriptome and chromatin state; that there are cell signals within and between different keratinocyte populations of the wound front; that Grhl3 regulates adhesion properties of follower cells; and that cell heterogeneity, cell-cell signaling, and role of Grhl3 change as wound healing progresses. These experiments are significant and innovative because they will be the first to comprehensively characterize in an unbiased way the in vivo transcriptome heterogeneity of the IFE in differentiation and migration--relevant to many skin diseases. The premise is strong, based on extensive literature, published work on the role of Grhl3, and our recent scRNA-seq data. PROJECT NARRATIVE Defective epidermal differentiation and barrier formation contributes to a number of skin diseases including ichthyosis, atopic dermatitis, psoriasis and skin cancer. Defective migration of keratinocytes contributes to delayed wound healing. Understanding the control of epidermal differentiation and migration will ultimately contribute to our understanding of these skin diseases.",Transcriptional Co-Regulators in Epidermis,10103776,R01AR044882,"['ATAC-seq', 'Abbreviations', 'Address', 'Adhesions', 'Appearance', 'Atopic Dermatitis', 'Biological Assay', 'Cells', 'Characteristics', 'Chromatin', 'Color', 'Data', 'Deposition', 'Development', 'Differentiated Gene', 'Enhancers', 'Epidermis', 'Epigenetic Process', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Glean', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Human', 'Impaired wound healing', 'Impairment', 'In Situ', 'In Vitro', 'Knowledge', 'Left', 'Literature', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Morphology', 'Mus', 'Nature', 'PF4 Gene', 'Pattern', 'Pharmaceutical Preparations', 'Play', 'Population', 'Principal Component Analysis', 'Process', 'Proliferating', 'Property', 'Psoriasis', 'Publishing', 'Regulation', 'Resolution', 'Role', 'Signal Transduction', 'Skin', 'Skin Cancer', 'Stratum Basale', 'Surface', 'System', 'Technology', 'Testing', 'Transcription Coactivator', 'Transcriptional Regulation', 'Transitional Cell', 'Transposase', 'Work', 'base', 'blind', 'cell motility', 'cell type', 'cohesion', 'epithelial wound', 'experimental study', 'in vivo', 'innovation', 'insight', 'intercellular communication', 'keratinocyte', 'mRNA Expression', 'migration', 'progenitor', 'programs', 'promoter', 'prototype', 'self renewing cell', 'single cell analysis', 'single-cell RNA sequencing', 'skin barrier', 'skin disorder', 'stem cells', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'wound', 'wound healing']",NIAMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2021,426601
"Stalled capillary flow: a novel mechanism for hypoperfusion in Alzheimer disease Project Summary / Abstract We seek to investigate the agent-based participation of machine learning (ML) models in an existing crowdsourcing system, which could substantially speed up biomedical image analysis without loss of data quality for Aims 2-4 in our R01 research. We encountered an analytic bottleneck in our prior R01-supported work, which seeks to reveal mechanisms that underlie capillary stalling in the brain and requires quantifying stall rates from 2PEF (2-photon excited fluorescence) image stacks. To address this, we partnered with the Human Computation Institute (HCI) to crowdsource the analysis using the online citizen science platform Stall Catchers, which has reduced the time to analyze a typical dataset from many months to just a few weeks. Beyond enabling several published results, 35,000 Stall Catchers volunteers have produced over 1.4 million high-quality “crowd” annotations, which served as a rich training set in a recent machine learning competition that led to the creation of fifty distinct ML models exhibiting a broad distribution of sensitivity and bias. None of these models, by itself, meets our stringent analytic requirements. However, if we could endow these models with sufficient agency to participate as bonafide Stall Catchers players, then we could test the hypothesis that hybrid (human/machine) ensembles will achieve the same data quality as human-only ensembles when answers are combined using our existing “wisdom of the crowd” algorithm. Developing an open source toolkit for transforming ML models into citizen science “bots” would enable a direct pathway for effectively integrating even substandard ML models into an existing crowd-powered analytic pipeline without requiring intensive re-engineering. Accelerating biomedical data analysis in this way could allow other biomedical researchers to derive immediate value from smaller training sets and investigate more hypotheses using less time and resources. This project could enable a low-overhead pathway for semi-automation using imperfect ML models, which could leverage ML sooner while reducing reliance on human cognitive resources, and provide a pathway for achieving fully automated analyses as improved ML models are added to the crowd as CitSci bots. Success in this pursuit would allow us to incorporate full-time CitSci bots into Stall Catchers, which could double the number of capillary stalling studies we can conduct in a given year toward elucidating a more complete mechanistic model of capillary stalling. This would speed up our ability to identify a targeted intervention with reduced side effects that could alleviate cognitive impairments in implicated dementias, such as Alzheimer’s disease while contributing to the advancement of hybrid intelligence methods with broad utility for biomedical data analysis. Narrative Due to an analytic bottleneck that couldn’t be solved using automation, we used citizen science to crowdsource the analysis of capillary stalling in direct support of aims in our R01-supported Alzheimer’s research. Having collected 1.4 million crowd-generated labels we recently ran a machine learning (ML) competition, resulting in 50 new ML models, which perform well but do not meet our data quality standards. We now propose to investigate a new mode of human/machine collaboration, which would allow these models to participate directly as autonomous agents alongside humans in our crowdsourcing systems, which could speed up our data analysis, reduce reliance on human annotators, and improve data quality, while providing a proof of concept and open source tools to reduce barriers and increase opportunities for using ML for biomedical data analysis.",Stalled capillary flow: a novel mechanism for hypoperfusion in Alzheimer disease,10412670,RF1AG049952,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Automation', 'Blood capillaries', 'Blood flow', 'Brain', 'Classification', 'Cognitive', 'Collaborations', 'Computer software', 'Crowding', 'Data', 'Data Analyses', 'Data Compromising', 'Data Set', 'Dementia', 'Engineering', 'Exhibits', 'Future', 'Goals', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Impaired cognition', 'Individual', 'Institutes', 'Intelligence', 'Intervention', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Participant', 'Pathway interactions', 'Performance', 'Process', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Speed', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'automated analysis', 'base', 'bioimaging', 'citizen science', 'crowdsourcing', 'data quality', 'design', 'experience', 'fluorescence imaging', 'hypoperfusion', 'improved', 'member', 'novel', 'open source', 'open source tool', 'prevent', 'prototype', 'side effect', 'success', 'two-photon', 'volunteer']",NIA,CORNELL UNIVERSITY,RF1,2021,220000
"Multi-Study Integer Programming Methods for Human Voltammery Project Summary/Abstract  The development of treatments for addiction requires the characterization of neural mechanisms underlying reward. Studying reward in humans requires assays that can detect changes in neurotransmitter levels with high chemical specificity. Recently, fast-scan cyclic voltammetry (FSCV) has been implemented in humans to measure dopamine with high temporal and spatial resolution. This technological achievement was enabled in large part through the novel application of machine learning methods. FSCV relies on statistical tools since FSCV records an electrochemical response which must be converted into concentration estimates via a statistical model. The validity of the scientific conclusions from human FSCV studies therefore depends heavily on the reliability of these statistical models to generate accurate dopamine concentration estimates.  In human FSCV, models are fit on in vitro training sets as making in vivo training sets in humans is infeasible. Producing accurate estimates thus requires that models trained on in vitro training sets generalize to in vivo brain recordings. Combining data from multiple training sets is the standard approach human FSCV researchers have employed to improve model generalizability. This proposal extends work that shows that multi-study machine learning methods improve dopamine concentration estimates by combining training sets from different electrodes such that the resulting average signal (“cyclic voltammogram” or CV) is similar to the average CV of the electrode used in the brain. However, this approach relies on random resampling. This is problematic because the randomness limits the extent to which estimate accuracy can be improved and the slow speed of the resampling approach precludes the generation of estimates during data collection, which is critical to experiment success.  This proposal details the development of methods that leverage mixed integer programming to optimally generate training sets that combine data from multiple electrodes. By generating training sets that are specifically tailored to the electrode used for brain measurements, one can vastly improve dopamine concentration estimate accuracy. The speed of the integer programming methods will enable the use of this approach during data collection. This work will include validation of the methods on in vitro data as well as on data from published in vivo and slice experiments in rodents. By applying methods to published optogenetic experiments, one can compare estimates from the proposed methods and from standard methods. The asymptotic properties of the proposed methods will be characterized analytically assuming a linear mixed effects model and empirically through application of the methods to data simulated under this model.  This work will be conducted at the highly collaborative and innovative Harvard School of Public Health. The fellowship will support growth in statistical, computing and collaborative skills, and prepare the trainee for a productive career as a biostatistics professor who develops methods for neuroscience and addiction research. Project Narrative  Fast-scan cyclic voltammetry in humans offers an invaluable tool to study the neural mechanisms underlying reward by allowing for sub-second detection of dopamine during cognitive-behavioral tasks. However, conducting voltammetry in humans presents distinct statistical challenges that must be overcome to ensure optimal dopamine concentration estimates. We propose novel statistical methods that use mixed integer optimization and extend preliminary work that shows multi-study machine learning methods substantially improve dopamine concentration estimate accuracy.",Multi-Study Integer Programming Methods for Human Voltammery,10212321,F31DA052153,"['Achievement', 'Address', 'Algorithms', 'Behavioral', 'Biological Assay', 'Biometry', 'Brain', 'Cells', 'Chemicals', 'Cognitive', 'Complex Mixtures', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Dopamine', 'Electrodes', 'Ensure', 'Fellowship', 'Generations', 'Goals', 'Grant', 'Growth', 'Human', 'In Vitro', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Neurosciences', 'Neurotransmitters', 'Nucleus Accumbens', 'Performance', 'Periodicity', 'Property', 'Public Health Schools', 'Publications', 'Publishing', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Rewards', 'Rodent', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Specificity', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Statistical Models', 'Techniques', 'Training', 'Validation', 'Work', 'addiction', 'algorithm training', 'career', 'effective therapy', 'experimental study', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning method', 'method development', 'multiple data sources', 'neuromechanism', 'novel', 'optogenetics', 'predictive modeling', 'professor', 'relating to nervous system', 'response', 'skills', 'success', 'therapy development', 'tool']",NIDA,HARVARD SCHOOL OF PUBLIC HEALTH,F31,2021,37751
"Integrating primate-rodent cell types and epigenomics to identify conservation in substance addiction Project Summary/Abstract Substance use disorders (SUD) of many highly addictive drugs affect more than 100 million people worldwide. Genetic variations associated with complex neuro-behavioral traits, such as drug addiction, are likely to impact enhancers which have a high degree of cell type-specificity and can be conserved across species. Furthermore, variation in addiction behavior has been linked to genetic variation in both human and rodents. Thus, it follows that genetic mechanisms driving addiction behavior, specifically at cell type-specific enhancers, might also be conserved between primates and rodents. I hypothesize that risk variants for some SUDs may lie in enhancers of distinct cell types in the reward areas and not others, providing insight into the cell types that are critical to SUDs. This project proposes to identify the gene markers and putative enhancers of cell types that are conserved or clade-specific to primates and rodents and of these, which are enriched for SUD human genetic risk variants. The proposal comprises of the following aims: Aim 1: identify the primate-rodent conserved cell types and marker gene profiles enriched for human SUD risk variants. Aim 2: identify the primate-rodent conserved putative enhancer profiles to test whether mouse substance use behavior risk loci disrupt similar putative conserved enhancers to human SUD risk loci. Together, these experiments could reveal primate-rodent gene and enhancer atlas of conserved and species-specific cell types of the reward system by integrating single-nuclei genomics data across multiple mammalian species. This information is critically important because better understanding of how an individual’s genetic makeup could affect the cells of the reward circuit will inform future work to craft personalized, targeted SUD therapy. Thus, this work integrates closely with my clinical interests in addiction medicine. This proposal outlines a combination of rigorous mentored research training, longitudinal clinical experiences, coursework, and professional and leadership development activities. The intellectual, technical, and professional skills refined during this fellowship training period will be instrumental in my development as an aspiring physician scientist in the clinical field of addiction medicine. Project Narrative Substance use disorders affect more than 100 million people worldwide and are influenced by the genetic makeup of the individual, in humans as well as rodent models. In this proposal, I will investigate how genetic differences in humans and mice could influence sets of brain cell types shared across human, monkey, and rodents. These results will provide a foundation to link the power of rodent models to specific features of SUDs in humans.",Integrating primate-rodent cell types and epigenomics to identify conservation in substance addiction,10143371,F30DA053020,"['Affect', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Atlases', 'Automobile Driving', 'Autopsy', 'Behavior', 'Biological Assay', 'Brain', 'Brain region', 'Cell Nucleus', 'Cells', 'Chromatin', 'Clinical', 'Clinical Research', 'Collaborations', 'Communities', 'Comparative Genomic Analysis', 'Complex', 'Corpus striatum structure', 'Data', 'Development', 'Dopamine D1 Receptor', 'Dorsal', 'Drug Addiction', 'Enhancers', 'Epigenetic Process', 'Fellowship', 'Foundations', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Heritability', 'Human', 'Human Genetics', 'Individual', 'Lead', 'Letters', 'Link', 'Macaca', 'Machine Learning', 'Maps', 'Medicine', 'Mentors', 'Modeling', 'Molecular', 'Monkeys', 'Mus', 'Neurons', 'Nicotine', 'Nucleus Accumbens', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Predisposition', 'Primates', 'Quantitative Trait Loci', 'Rattus', 'Research', 'Research Training', 'Resolution', 'Rewards', 'Risk', 'Risk Behaviors', 'Rodent', 'Rodent Model', 'Scientist', 'Small Nuclear RNA', 'Specificity', 'Speed', 'Substance Addiction', 'Substance Use Disorder', 'System', 'Testing', 'Training', 'Transposase', 'Variant', 'Work', 'addiction', 'base', 'brain cell', 'brain tissue', 'cell type', 'comparative genomics', 'epigenomics', 'experience', 'experimental study', 'genetic makeup', 'genome wide association study', 'genomic data', 'human disease', 'insight', 'interest', 'leadership development', 'machine learning algorithm', 'mammalian genome', 'mouse genetics', 'neural circuit', 'neurobehavioral', 'neuropsychiatry', 'nonhuman primate', 'novel', 'personalized medicine', 'pre-clinical research', 'prevent', 'programs', 'risk variant', 'skills', 'substance use', 'trait', 'transcriptome sequencing', 'transcriptomics']",NIDA,CARNEGIE-MELLON UNIVERSITY,F30,2021,51036
"Clear Volume Imaging with Machine Learning: a novel tool to identify brain-wide neuronal ensembles of opioid relapse in rat models This project is in response to PA-18-437 “Cutting-Edge Basic Research Awards (CEBRA)”. Over the two past decades, there has been a large increase in the abuse of prescription and illegal opioids; this increase coincides with increases in opioid-related deaths. A critical challenge is the occurrence of relapse in treated patients, especially given that relapse episodes carry a risk of overdose. There is a need to improve our understanding of the brain mechanisms of opioid relapse, which hopefully will result in the identification of targeted circuitry-based treatments. We propose to develop a high-throughput computation system termed Clear Volume Analysis with Machine Learning (CVA-ML). We will combine CVA-ML with a rat-optimized version of the whole brain immunostaining and clearing method iDISCO+ and a new rat model of opioid relapse after voluntary abstinence to identify brain- wide neuronal ensembles of opioid relapse. We recently adapted the iDISCO+ method to intact rat brains and developed experimental methods for Fos immunostaining, brain clearing, and light sheet fluorescence microscopy imaging. However, incorporation of the iDISCO+ method to large scale rat studies is currently limited by (1) lack of ABA-CCF-comparable high-resolution 3D rat brain atlas that allows for high-resolution registration of the activity signal in the 3D space, and (2) lack of an automated data analysis pipeline. In Aim 1, we propose to develop a data analysis pipeline that will take light sheet fluorescence microscopy- generated rat brain images and automatically register them into a custom-made 3D rat brain atlas encompassing a converted Paxinos and Watson rat’s brain atlas. As part of Aim 1, we also propose to develop machine-learning methods to identify and analyze the whole brain Fos signals in 3D space. In Aim 2, we propose to use the methods we developed in Aim 1 to identify brain-wide patterns of neuronal activity (‘neural ensembles’) that encode opioid relapse after voluntary abstinence induced by imposing adverse consequences (electric barrier) that results in long-term cessation of opioid (oxycodone) self-administration. Our proposal addresses the goal of PA-18-437: “to develop, and/or adapt, revolutionary techniques or methods for addiction research.” The anticipated outcomes of our proposal are an open-source software package to automatically analyze iDISCO+ data of rat brains, and a rat whole brain activity map for opioid relapse, assessed using a new rat model. The publicly available software will be easy to modify and can be used by investigators to identify brain-wide neuronal ensembles underlying drug relapse and other motivated behaviors in rats. Project Narrative This project seeks to develop a high-throughput computation system and combine it with the whole brain clearing method iDisco+ and a novel rat model of relapse after voluntary abstinence opioid relapse model to identify brain-wide neuronal ensembles of opioid relapse. The proposed computational framework can identify neuronal ensembles controlling drug relapse and other motivated behaviors in rats.",Clear Volume Imaging with Machine Learning: a novel tool to identify brain-wide neuronal ensembles of opioid relapse in rat models,10241671,UG3DA053802,"['3-Dimensional', 'Abstinence', 'Address', 'Atlases', 'Award', 'Basic Science', 'Brain', 'Brain imaging', 'Buprenorphine', 'Cell Count', 'Cells', 'Computer software', 'Custom', 'Data', 'Data Set', 'FDA approved', 'Fluorescence Microscopy', 'Goals', 'Image', 'Immediate-Early Genes', 'Immunohistochemistry', 'Label', 'Light', 'Machine Learning', 'Maps', 'Methadone', 'Methods', 'Modeling', 'Mus', 'Naltrexone', 'Neurons', 'Opioid', 'Outcome', 'Oxycodone', 'Patients', 'Positioning Attribute', 'Procedures', 'Rattus', 'Relapse', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Self Administration', 'Signal Transduction', 'System', 'Systems Analysis', 'Techniques', 'Transcranial magnetic stimulation', 'activity marker', 'addiction', 'adverse outcome', 'analytical method', 'base', 'bioimaging', 'brain tissue', 'computer framework', 'data analysis pipeline', 'drug relapse', 'experience', 'experimental group', 'graphical user interface', 'high throughput analysis', 'improved', 'machine learning method', 'microscopic imaging', 'motivated behavior', 'neuroimaging', 'neuronal patterning', 'novel', 'open data', 'open source', 'opioid epidemic', 'opioid mortality', 'opioid user', 'overdose risk', 'programs', 'relating to nervous system', 'response', 'tool', 'usability']",NIDA,UNIVERSITY OF MARYLAND BALTIMORE,UG3,2021,229734
"From diverse dynamics to diverse computation via neural cell types Project Summary A prominent feature of biological neuronal networks is the astonishing diversity of their cell types. Major, nationally coordinated experimental efforts, including the BRAIN Initiative’s Cell Census Network (BICCN) and the Allen Institute Cell Types programs, are currently revealing this cellular diversity at new and very high levels of resolution. For example, just across two areas of mouse cortex 133 cell types have been characterized, with many types shared across areas! Similar cell classes have been observed across species. These types show marked differences not only gene expression and connectivity, but also membrane, spiking, and synaptic dynamics. This is in sharp contrast to most computational and theoretical models of learning in neural networks, which generally make use of only one or a small number of cell types. The goal of this project is to produce new computational and theoretical tools to help close this gap. This will enable us, and the broader community, to test a hypothesis for the functional role of cell-type specific, heterogeneous cellular and synaptic dynamics: that they can be harnessed to generate complex network dynamics which allows faster or more accurate learning of tasks which themselves have inputs or objectives which have complex dynamics. Such tasks abound in natural environments. Testing this hypothesis requires new high-throughput computational tools to train neural networks with biologically realistic dynamics and connectivity to solve tasks, new theoretical tools to understand how diverse cellular dynamics contribute to network computation, and new application to large-scale, cellular data-driven models. First, with the expertise of a grant-supported scientific software engineer, will build, test, and disseminate a software package that flexibly implements heterogeneous dynamics of single cells and short-term synaptic dynamics. We plan to use a very popular, freely available and open source software framework for machine learning (Pytorch). Next, we will establish metrics of network dynamics that help to mechanistically explain what does -- and does not -- matter about cellular and synaptic heterogeneity in impacting learning performance. Finally, we will integrate these tools with a prior cell-type specific computational model of the mouse primary visual cortex, based on large scale Allen Institute databases, to test the hypothesis stated above. Specifically, we will newly determine whether experimentally observed levels of heterogeneity in cellular and synaptic dynamics contribute to the ability of visual microcircuits to perform visual computation. Project Narrative The brain is composed of a large number of cell types, each with diverse dynamical properties that vary robustly from type to type. We propose to study the role of this diversity in how circuits in the brain compute, by building new tools that will enable the community to simulate and analyze learning in neural networks with complex cellular components.",From diverse dynamics to diverse computation via neural cell types,10263658,RF1DA055669,"['Area', 'BRAIN initiative', 'Biological', 'Brain', 'Cells', 'Censuses', 'Code', 'Communities', 'Complex', 'Computer Models', 'Computer software', 'Data', 'Databases', 'Development', 'Environment', 'Feedback', 'Fire - disasters', 'Gene Expression', 'Goals', 'Grant', 'Heterogeneity', 'Institutes', 'Learning', 'Machine Learning', 'Membrane', 'Modeling', 'Mus', 'Nature', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Pathway Analysis', 'Performance', 'Property', 'Research', 'Resolution', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Synapses', 'System', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Visual Cortex', 'Visual system structure', 'Weight', 'area striata', 'base', 'cell type', 'computational basis', 'computerized tools', 'flexibility', 'large-scale database', 'member', 'mouse model', 'network models', 'neural network', 'open source', 'programs', 'relating to nervous system', 'tool']",NIDA,ALLEN INSTITUTE,RF1,2021,1115283
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,10223179,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2021,1186500
"Role of extracellular matrix in age-related declines of muscle regeneration PROJECT SUMMARY  The capacity for muscle regeneration decreases markedly with aging. While regeneration is led by muscle stem cells (MuSC), complex age-related changes in the skeletal muscle extracellular matrix (ECM) provide potent signals that drive aberrant lineage specification. The complexity of the interactions between aging MuSC and their environmental niche defined by biomechanical, architectural, and dynamic changes in the ECM suggests a data-driven analysis can elucidate underlying mechanisms, increase our fundamental understanding of aging and stem cell biology, and point to novel therapeutic strategies. In this research, -omics data (i.e., single cell RNA-seq and imaging flow cytometry assessments of myogenic markers) obtained from cells cultured onto substrates of varying elasticity and cell-adhesion will be used to probe signaling pathways including mitochondrial/metabolic signaling pathways in cultured MuSCs. We propose that the implementation of machine learning/artificial intelligence (ML/AI) paradigms represents a critical next step for integrating multi- layer -omics datasets and building predictive models that will more comprehensively elucidate stem cell responses to the extrinsic biophysical environment.  The overarching goal of this Supplement is to test the central hypothesis that Biological data and domain knowledge relating to muscle aging can be embedded in a framework of Bayesian optimization will allow for elucidating mechanisms and accurately predicting regenerative responses. This central hypothesis will be tested by conducting three specific aims: Specific Aim 1. To prepare -omics data for ML models: Curate datasets, identify and impute missing data, compile metadata, and pre-process data to quantify descriptors used in model building. Adopt data management protocols associated with best practices. Specific Aim 2. To perform benchmark ML modeling with Bayesian optimization: Identify environmental variables (ECM stiffness and composition, signaling molecules) and cellular characteristics (age, expression markers) that correlate with epigenetic signatures and myogenicity, then develop mechanistic ML models and estimate posterior distributions. Specific Aim 3. To broaden approaches to ML modeling and broaden researcher engagement in the biology of aging: CMU will host a hackathon with teams that combine students and researchers from regional universities and HBCU partners. PROJECT NARRATIVE For elderly individuals, muscle injury often results in dramatic functional declines, with these declines being largely a result of an impaired regenerative response. The focus of the parent grant is to investigate how age- related changes in the biophysical skeletal muscle microenvironment contribute to an impaired muscle stem cell function and defective healing after an acute injury. In this Administrative Supplement, we will extend the aims of this project by developing machine learning/artificial intelligence models that estimate biological age of muscle stem cells and predict regenerative potential.",Role of extracellular matrix in age-related declines of muscle regeneration,10410777,R01AG061005,"['Acute', 'Administrative Supplement', 'Adopted', 'Age', 'Aging', 'Architecture', 'Artificial Intelligence', 'Bayesian Modeling', 'Benchmarking', 'Biological', 'Biology of Aging', 'Biomechanics', 'Biophysics', 'Cell Adhesion', 'Characteristics', 'Complex', 'Cultured Cells', 'Data', 'Data Set', 'Descriptor', 'Elasticity', 'Elderly', 'Environment', 'Epigenetic Process', 'Extracellular Matrix', 'Flow Cytometry', 'Goals', 'Image', 'Impairment', 'Individual', 'Injury', 'Knowledge', 'Machine Learning', 'Metabolic', 'Metadata', 'Mitochondria', 'Modeling', 'Muscle', 'Muscle satellite cell', 'Natural regeneration', 'Process', 'Protocols documentation', 'Regenerative response', 'Research', 'Research Personnel', 'Role', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Skeletal Muscle', 'Students', 'Testing', 'Universities', 'age related', 'age-related muscle loss', 'data management', 'functional decline', 'hackathon', 'healing', 'model building', 'muscle aging', 'muscle regeneration', 'novel therapeutic intervention', 'parent grant', 'predictive modeling', 'regeneration potential', 'response', 'single-cell RNA sequencing', 'stem cell biology', 'stem cell function', 'stem cells']",NIA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,281359
"Genetic and Genomic Dissection of Psoriatic Arthritis Psoriatic arthritis (PsA) is distinctive amongst the inflammatory/autoimmune joint diseases in that its onset is commonly preceded by cutaneous psoriasis (PsC). This provides an unparalleled opportunity for the identification of predictive biomarkers to determine which of the approximately 25% of psoriasis vulgaris (PsV) patients will develop PsA. Over the past decade, we have expanded our genetic study of PsV to focus on PsA, resulting in the collection of 1,279 PsA patients at Michigan, 743 of whom have already been subjected to GWAS. Initiated in 2007, the International Psoriatic Arthritis Research Team (IPART) has accumulated 1,919 Canadian PsA patients, of whom 1,370 have already been subjected to GWAS. In 2015, we completed a meta- GWAS of PsC and PsA involving a discovery cohort of 1,430 PsA cases and 1,417 controls, with 9,293 additional PsV replication samples (3,061 PsA, 3,110 PsC) and 13,670 controls. We detected 10 associations for PsA and 11 for PsC, as well as a new association for PsV. Utilizing an innovative core exome array to genotype additional cases and controls, we carried out the largest meta-GWAS of PsV to date (~40,000 subjects) and found 16 more susceptibility regions, highlighting the roles of interferon signaling and the NFB cascade, and demonstrating strong enrichment for psoriasis genetic signals in T-cell regulatory elements. Using machine learning to model ~200 genetic variants in our PsA vs. PsC GWAS, we achieved 82% area under receiver operator curve for distinguishing PsA vs PsC, with 98% accuracy among the top 10% of patients with the highest genetic load. We also carried out RNA-seq on mRNA and miRNA from 65 pairs of pre- and post-conversion samples from PsC patients who developed PsA. Suggestive of a shift from skin- focused to systemic autoimmunity, we found significant post-conversion enrichment for central memory CD4+ T-cell (CD4-Tcm) transcripts among the up-regulated genes. We also observed highly correlated pre- and post- conversion behaviors of 54 differentially-expressed miRNAs and their mRNA targets, as well as multiple serum miRNAs that are significantly differentially expressed in PsA vs. PsC. A metabolomic study of 50 paired converter sera revealed 293 biochemicals with significant alterations, 275 of which were increased. Finally, we identified noncoding eQTLs for IL23R that correlate strikingly with a region of selective PsA association.  Based on these results, we hypothesize that PsA and PsC have pathogenetic mechanisms that are T-cell, osteoblast and osteoclast-driven and progress from skin to systemic during transition to PsA. We propose that this paradigm can be used to develop a useful test to predict PsA in PsC patients, while increasing our basic understanding of PsA. To test this hypothesis, we propose four aims: (1) to maintain and grow our longitudinal clinical resource; (2) To identify biomarkers for the development of PsA in PsC patients; (3) To integrate the biomarkers identified in Aim 2 into a clinically-useful tool for PsA identification using machine learning ; and (4) to explore the mechanisms by which the IL23R gene contributes to PsA pathogenesis. PROJECT NARRATIVE: Psoriatic Arthritis (PsA) is a major health problem in the United States and around the world. The mechanisms that predispose patients with psoriasis to develop PsA are unknown. The proposed research will utilize the power of genome-wide association studies, transcriptome analysis, metabolomics, and the largest longitudinal resource of PsA in the world to develop a clinically-relevant tool for PsA prediction and to address a major gap in our mechanistic understanding of the causes of PsA. The results of this research are also likely to be relevant to other autoimmune diseases.",Genetic and Genomic Dissection of Psoriatic Arthritis,10208711,R01AR063611,"['Address', 'Alleles', 'Area', 'Autoimmune', 'Autoimmune Diseases', 'Behavior', 'Biochemical', 'Biological Markers', 'Blood', 'Blood Banks', 'Blood specimen', 'CD8B1 gene', 'Cardiovascular Diseases', 'Cellular Assay', 'Chronic small plaque psoriasis', 'Clinic', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'Collection', 'Cutaneous', 'DNA', 'Data', 'Dermatology', 'Dissection', 'Elements', 'Exhibits', 'Genes', 'Genetic', 'Genetic Load', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'HLA-C Antigens', 'Health', 'Hospitals', 'Immunity', 'In Vitro', 'Individual', 'Inflammatory', 'Interferons', 'International', 'Life', 'Longitudinal cohort', 'Machine Learning', 'Memory', 'Messenger RNA', 'Meta-Analysis', 'Michigan', 'MicroRNAs', 'Modeling', 'Mutagenesis', 'Osteoblasts', 'Osteoclasts', 'Pathogenesis', 'Patients', 'Predisposition', 'Proteins', 'Psoriasis', 'Psoriatic Arthritis', 'RNA', 'Regulatory Element', 'Regulatory T-Lymphocyte', 'Research', 'Resources', 'Rheumatology', 'Risk', 'Role', 'STAT3 gene', 'Sampling', 'Serum', 'Signal Transduction', 'Site', 'Skin', 'Small Interfering RNA', 'Suggestion', 'T-Lymphocyte', 'TNFSF15 gene', 'TYK2', 'Testing', 'Transcript', 'United States', 'Untranslated RNA', 'Variant', 'arthropathies', 'base', 'biomarker development', 'case control', 'causal variant', 'clinically relevant', 'cohort', 'comorbidity', 'differential expression', 'exome', 'follow-up', 'genetic variant', 'genome wide association study', 'high risk', 'innovation', 'insight', 'memory CD4 T lymphocyte', 'metabolome', 'metabolomics', 'novel', 'osteoblast differentiation', 'predictive marker', 'rare variant', 'recruit', 'systemic autoimmunity', 'tool', 'tool development', 'transcriptome', 'transcriptome sequencing']",NIAMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,608486
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"Functional Determinants in G-Protein-Coupled Receptors FUNCTIONAL DETERMINANTS OF G PROTEIN-COUPLED RECEPTORS PROJECT SUMMARY/ABSTRACT The long-term goal of this work is to rationally manipulate G protein-coupled receptor (GPCRs) activation with the hope to develop novel therapeutic approaches in this major family of transmembrane receptors and drug targets. Our hypothesis is that evolutionary divergence patterns can reveal the roles that GPCR sequence positions play, individually or together, in order to mediate ligand binding, allosteric conformational switching, and finally ligand-biased activation of efferent signaling pathways, which can be G protein-dependent or independent. In the past funding period, computational analysis of such evolutionary patterns revealed: Intramolecular allosteric communication in the transmembrane domain of dopamine D2R receptor; Modular components of an allosteric switch controlling B2AR functional selectivity; A new non-canonical cAMP- independent signaling pathway in that same receptor; and Ligand specificity determinants in the extracellular domain of metabotropic glutamate receptors (MGluR). Technical progress led to: increased accuracy to assess the impact of coding mutations in proteins through a first-principle equation for the evolutionary variations of genotype and phenotype; The generalization of our analyses of evolutionary divergence to consider co-varying residues; and new methods to unravel complex simultaneous assay readouts to stratify drug effects on GPCRs. Together these and other data support new aims that combine biological and algorithmic goals: 1. To titrate mutationally the signaling bias of bioamine receptors. 2. To uncover allosteric mediators in metabotropic glutamate receptors. 3. To identify a systematic role of GPCR mutations in cancer. The outcome should reveal new aspects of the molecular basis of signaling in an important family of pharmaceutical targets. It will also link sequence and structure genomics databases to the molecular basis of function and to the rational re- design of protein function–key steps towards manipulating cellular pathways. FUNCTIONAL DETERMINANTS OF G PROTEIN-COUPLED RECEPTORS Narrative of the project G protein-coupled receptors account for nearly half of all current medications, yet so far relatively few have been successfully targeted by drugs. One of the difficulties is that we have limited knowledge of their mechanisms at a detailed level. This proposal attempts to uncover the mechanisms of these proteins so that in the longer term we can design new drugs that block their role in diseases, including in cancer.",Functional Determinants in G-Protein-Coupled Receptors,10240656,R01GM066099,"['ADRB2 gene', 'Adrenergic Receptor', 'Affect', 'Algorithms', 'Amino Acid Sequence', 'Arrestins', 'Biological', 'Biological Assay', 'Calcium', 'Cancer Family', 'Cancer Patient', 'Code', 'Communication', 'Complex', 'Computer Analysis', 'Coupled', 'Coupling', 'Cyclic AMP', 'Data', 'Data Set', 'Databases', 'Disease', 'Distant', 'Dopamine', 'Dopamine D2 Receptor', 'Dopamine Receptor', 'Drug Targeting', 'Equation', 'Extracellular Domain', 'Family', 'Funding', 'G Protein-Coupled Receptor Signaling', 'G-Protein-Coupled Receptors', 'GTP-Binding Protein alpha Subunits, Gs', 'GTP-Binding Proteins', 'Genotype', 'Glutamate Receptor', 'Goals', 'Individual', 'Knowledge', 'Ligand Binding', 'Ligand Binding Domain', 'Ligands', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manipulative Therapies', 'Maps', 'Mediating', 'Mediator of activation protein', 'Metabotropic Glutamate Receptors', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Mus', 'Mutate', 'Mutation', 'Neoplastic Cell Transformation', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacologic Substance', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Point Mutation', 'Positioning Attribute', 'Protein Engineering', 'Proteins', 'Proteome', 'Receptor Activation', 'Receptor Signaling', 'Recording of previous events', 'Role', 'Serotonin', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Stretching', 'Structure', 'Testing', 'Titrations', 'Transmembrane Domain', 'Variant', 'Venus Flytrap', 'Work', 'beta-arrestin', 'cancer cell', 'design', 'experimental study', 'fitness', 'interest', 'metabotropic glutamate receptor 4', 'novel marker', 'novel therapeutic intervention', 'novel therapeutics', 'patient stratification', 'protein function', 'protein structure prediction', 'prototype', 'receptor', 'receptor function', 'response', 'structural genomics', 'tumor', 'web server']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,472000
"Empower treatment effects evaluation of randomized clinical trials for elderly patients with integrated real-world data PROJECT SUMMARY/ABSTRACT  Randomized clinical trials (RCTs) are the gold-standard method of evaluating cancer treatment, which has immense health and economic burdens worldwide. However, practical considerations that allow an RCT to be conducted typically require a relatively small sample size and restricted eligibility criteria such that the study has inadequate power to generalize treatment effects to elderly patients or other under-represented patient pop- ulations. On the other hand, massive real-world data (RWD) are increasingly captured by population-based databases and registries, such as Surveillance, Epidemiology, and End Results (SEER), SEER-Medicare, and National Cancer Database (NCDB), that have much broader demographic and clinical diversity compared to RCT cohorts. Treatment evaluation using causal inference methods and RWD that were not collected purely for re- search purposes is now frequently performed but fraught with limitations such as confounding due to lack of randomization. In fact, the agreement between RCT and RWD ﬁndings is often low in the analysis of matched RCT and RWD studies with the same treatment comparisons. Although several national organizations and reg- ulatory agencies have advocated using RWD to complement RCTs, methods that integrate these two potentially complementary data sources and achieve better treatment evaluation over the use of a single data source alone have yet to be developed.  This proposal is motivated by the PIs' collaborative work to study the safety and efﬁcacy of treatment strategies for elderly non-small cell lung cancer (NSCLC) and esophageal cancer patients by integrating data from multiple sources: RCTs from NCI cooperative groups and the real-world databases (e.g. SEER, SEER-Medicare, and NCDB). The objective of this project is to develop new statistical methods for integrative analyses of RCTs and RWD that can improve the generalizability and increase estimation efﬁciency of RCT ﬁndings to more diverse ""real-world"" patients as well as under-studied populations while avoiding confounding bias inherent in RWD. In Aim 1, we develop methods for statistical analysis of RCT data to compare chemoradiotherapy patterns for the real-world and elderly NSCLC patients by leveraging the baseline covariates of comparable patients from SEER, for whom the temporal information of chemotherapy and radiation and the outcome are both missing. Aims 2 and 3 focus on the settings when both RCT and RWD provide comparable covariates, treatment, and outcome information. In Aim 2, we develop improved analysis of RCT data to evaluate trimodality therapy versus surgery alone for the real-world and elderly esophageal cancer patients by exploiting the large sample size and predictive power offered by the NCDB/SEER-Medicare. In Aim 3, we develop new efﬁcient and data-adaptive methods to estimate individualized treatment effects of adjuvant chemotherapy versus observation, possibly modiﬁed by age and tumor size, for stage IB resected NSCLC patients by integrating RCT and NCDB data. PROJECT NARRATIVE  The proposed research is closely in line with the 21st Century Cures Act, passed in 2016, which placed additional focus on the use of big real-world data to support decision making and precision medicine. The availability of multiple data sources, namely randomized clinical trials (RCTs) and real-world databases, presents unique and novel opportunities for medical research, because the knowledge that can be acquired from integrative analyses would not be possible from any single-source analysis alone. Our effort is important to bridge RCTs and vast real-world databases and registries arising from clinical practices in order to better understand how treatment works for the real-world and under-studied patient populations outside relatively narrow RCT eligibility criteria and provide accurate and reliable evidence for patient-centered care.",Empower treatment effects evaluation of randomized clinical trials for elderly patients with integrated real-world data,10149900,R01AG066883,"['Address', 'Adjuvant Chemotherapy', 'Advocate', 'Age', 'Agreement', 'Area', 'Calibration', 'Cancer Patient', 'Characteristics', 'Chemotherapy and/or radiation', 'Clinical', 'Clinical Trials', 'Complement', 'Data', 'Data Analyses', 'Data Collection', 'Data Sources', 'Databases', 'Decision Making', 'Disease', 'Economic Burden', 'Elderly', 'Electronic Health Record', 'Eligibility Determination', 'Ensure', 'Equilibrium', 'Evaluation', 'Evidence Based Medicine', 'Exclusion Criteria', 'Gold', 'Heterogeneity', 'Knowledge', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Medical Research', 'Medicare', 'Methods', 'Modeling', 'Non-Small-Cell Lung Carcinoma', 'Operative Surgical Procedures', 'Outcome', 'Patient Recruitments', 'Patient-Centered Care', 'Patients', 'Pattern', 'Population', 'Randomized', 'Randomized Clinical Trials', 'Registries', 'Research', 'Research Personnel', 'Resected', 'SEER Program', 'Sample Size', 'Sampling', 'Sampling Studies', 'Source', 'Statistical Data Interpretation', 'Statistical Methods', 'Target Populations', 'Therapy trial', 'Treatment Efficacy', 'Treatment outcome', 'Weight', 'Work', 'anticancer research', 'base', 'cancer therapy', 'chemoradiation', 'clinical practice', 'clinical trial analysis', 'cohort', 'disease registry', 'esophageal cancer patient', 'health economics', 'improved', 'inclusion criteria', 'individualized medicine', 'learning strategy', 'machine learning method', 'multiple data sources', 'novel', 'older patient', 'patient population', 'population based', 'precision medicine', 'safety study', 'study population', 'treatment comparison', 'treatment effect', 'treatment group', 'treatment response', 'treatment strategy', 'tumor']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2021,391243
"Software development for Stan to improve survey statistics for non-probability samples 1 Project Summary This proposal is a supplement to our NIH grant R01 AG067149-01: Improving Representativeness in Non-probability Surveys and Causal Inference with Regularized Regression and Poststrati cation. That project involves developing certain Bayesian methods for sampling adjustment in a general,  exible, and reliable way that can be used for a wide range of problems in public health research. The project requires extensive use of the Stan probabilistic programming platform, both as part of the research e ort and as part of resulting methods.  This NOSI is synergistic with that grant. It will support new software engineering initiatives to improve the core Stan platform in three ways: (1) Providing the option for JSON format outputs will improve interoperability and facilitate incorporating Bayesian methods into machine learning pipelines; (2) Extending and refactoring the core Stan inference algorithms for greater memory eciency and increased parallel processing will improve the overall speed and scalability of infer- ence, allowing for Bayesian methods to be used with increasingly complex models. This will allow researchers to compare a greater number and wider range of models in order to nd those with optimal behaviors. (3) The addition of a standard logging framework will bene t both the Stan user community and the developer community.  The parent grant's research agenda is threefold. Firstly, it is directed to addressing the unique challenges posed by public health datasets and questions by investigating adaptations to state-of- the art modelling techniques. Secondly, it strives to improve causal inferences for demographic subgroups. Thirdly, and more broadly, it seeks to improve current methodology by developing work ows to test and validate models with non-representative data in order to obtain better and more trustworthy population based estimates.  The work in the NOSI is relevant in two ways. First, it will directly support the research in the main project. During our research, computational challenges arise. The progress in research reveals areas where the computational infrastructure needs to be improved; thus, the NOSI will enable us to do our NIH-funded research more e ectively. Second, it's important for the results of our research to be used by others. The computing work in the NOSI will make it easier for applied practitioners to make use of the research we have been developing. Furthermore, the addition of a common data format for inputs and outputs, greater processing speed and eciency, and standardized logging will make it easier to use Stan in complex processing pipelines, therefore improving overall cloud-readiness. Project Narrative The computational developments in this supplement will enable more effective fitting of statistical models for adjusting data from non-probability surveys to be representative of populations of interest. Being able to fit these models more reliably will enable more efficient and reliable survey research for the purpose of estimating population characteristics and average causal effects in a wide range of problems in public health, with examples including longitudinal surveys of health and wellbeing, surveys of hard-- to-reach populations, and effects of experimental interventions. This research will contribute to the advancement of knowledge by filling in the gap between surveys or experimental data and real-world populations and implementations.",Software development for Stan to improve survey statistics for non-probability samples,10405924,R01AG067149,"['Address', 'Algorithms', 'Architecture', 'Area', 'Bayesian Analysis', 'Bayesian Method', 'Behavior', 'Callback', 'Cations', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Documentation', 'Failure', 'Funding', 'Grant', 'Health Surveys', 'Human', 'Industrialization', 'Intervention', 'Knowledge', 'Libraries', 'Longitudinal Surveys', 'Machine Learning', 'Memory', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Monte Carlo Method', 'Output', 'Personal Satisfaction', 'Population', 'Population Characteristics', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Published Comment', 'Readability', 'Readiness', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Running', 'Sampling', 'Schedule', 'Software Engineering', 'Speed', 'Standardization', 'Statistical Models', 'Stream', 'Subgroup', 'Surveys', 'Techniques', 'Testing', 'Text', 'United States National Institutes of Health', 'Work', 'Writing', 'computer infrastructure', 'data format', 'data interoperability', 'data sharing', 'design', 'falls', 'improved', 'innovation', 'interest', 'interoperability', 'large datasets', 'man', 'parallel processing', 'parallelization', 'parent grant', 'population based', 'processing speed', 'programs', 'public health research', 'software development', 'statistics', 'structured data', 'tool', 'trustworthiness', 'usability']",NIA,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2021,233137
"Hematopoietic Stem Cell And Cord Blood Transplantation PROJECT SUMMARY/ABSTRACT Hematopoietic cell transplantation from unrelated donors, haploidentical related donors and cord blood units can cure life-threatening blood disorders; however, graft-versus-host disease (GVHD), relapse and survivorship disparities across different ancestries remain the major obstacles. When matched donors are not available, the properties of HLA mismatches that govern (non)-permissivity are not well-defined. Furthermore, the role of KIR/HLA interactions in modulating relapse remain to be clarified. These deficiencies have important implications for a large fraction of patients who lack HLA-matched donors, and for all patients at risk for disease relapse. We have demonstrated that HLA class I leader peptides, HLA-DP expression, and HLA/KIR interactions each contribute to GVHD, relapse and mortality. The unmet needs are to understand the mechanisms through which HLA and KIR genes modulate transplant risks, and a means to apply the research findings to clinical care. We propose to define the underlying mechanisms through which HLA and KIR genes and proteins function in transplantation, and develop tools for using HLA and KIR in the selection of the optimal transplant donor and cord blood unit. The specific aims are to: define the role of HLA-DP expression and peptide-binding groove pocket in GVHD; define NKG2/HLA-E interactions and HLA-G in GVHD and relapse; define the role for KIR and HLA interaction in relapse after HCT for acute leukemia, and design tools to evaluate gene features in clinical practice. The goals will be achieved through systemic analysis of individual gene variation, haplotypes of genes, and receptor/ligand recognition in large ethnically diverse transplant populations with complete clinical data. This proposal will fill the knowledge gap in the immunobiological basis of GVHD, relapse and survivorship disparities in transplantation. The information will increase the safety, efficacy and availability of transplantation for all patients in need of this life-saving therapy. Project Narrative We will study how immune system genes affect the success of transplantation for patients of diverse ancestries. This information will help to lower risks through individualized treatment options for future patients.",Hematopoietic Stem Cell And Cord Blood Transplantation,10214464,U01AI069197,"['Acute Graft Versus Host Disease', 'Acute leukemia', 'Affect', 'Affinity', 'African', 'Alleles', 'Artificial Intelligence', 'Asians', 'Binding', 'Biology', 'Caucasians', 'Clinical', 'Clinical Data', 'Data', 'Donor person', 'Ensure', 'Failure', 'Frequencies', 'Funding', 'Future', 'GEM gene', 'Genes', 'Genetic Polymorphism', 'Genotype', 'Goals', 'HLA G antigen', 'HLA-A gene', 'HLA-B Antigens', 'HLA-C Antigens', 'HLA-DP Antigens', 'HLA-DPB1 gene', 'Haplotypes', 'Health', 'Hematological Disease', 'Hematopoietic stem cells', 'Hispanics', 'Histocompatibility', 'Immune system', 'Individual', 'International', 'Knowledge', 'Life', 'Ligands', 'Linkage Disequilibrium', 'Malignant Neoplasms', 'Measures', 'Methods', 'Natural Killer Cells', 'Nature', 'Outcome', 'Patients', 'Peptide Leader Sequences', 'Peptides', 'Phenotype', 'Population', 'Population Group', 'Property', 'Recurrent disease', 'Regimen', 'Registries', 'Relapse', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Role', 'Safety', 'Savings', 'Selection Criteria', 'Sentinel', 'Shapes', 'Survival Rate', 'Testing', 'Translating', 'Transplant Recipients', 'Transplantation', 'Umbilical Cord Blood', 'Umbilical Cord Blood Transplantation', 'Validation', 'Variant', 'Work', 'base', 'clinical care', 'clinical decision-making', 'clinical practice', 'design', 'disorder risk', 'ethnic diversity', 'gene function', 'graft vs host disease', 'hematopoietic cell transplantation', 'high risk', 'improved outcome', 'individual patient', 'individualized medicine', 'leukemia', 'leukemia relapse', 'mortality', 'novel', 'personalized medicine', 'personalized strategies', 'prognostic', 'protein function', 'receptor', 'success', 'survivorship', 'tool', 'tumor', 'working group']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,U01,2021,200000
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10263268,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'dietary', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,317579
"Integrative Biology Approach to Identify and Characterize Roles of lncRNAs Associated with Psoriasis Pathology PROJECT SUMMARY/ABSTRACT Candidate After the completion of my Ph.D. in Bioinformatics, I joined the Center for Statistical Genetics at the University of Michigan (U-M) as research fellow and acquired extensive training in analysis on high- dimensional biological data. I uncovered a strong interest in studying the genetics and genomics of psoriasis when working with Dr. James Elder at the U-M, and I developed a fascination in understanding the functional roles of long non-coding RNAs (lncRNAs) in cutaneous diseases. I joined the Department of Dermatology at the U-M as a faculty in summer of 2015, with secondary appointments in the Department of Computational Medicine & Bioinformatics and the Department of Biostatistics. In addition, I direct the new Center for Cutaneous Bioinformatics within the Department of Dermatology, and serve to supervise and implement an analysis pipeline for studies investigating the immunological mechanisms for different skin diseases. Career Development Plan I aim to become a future leader in combining in silico discovery and bench experiments to advance biomedical research in autoimmune skin disorders. My objective in seeking a Mentored Research Scientist Development Award is to acquire the additional knowledge, training, and experience necessary for me to become an independent scholar in developing novel systems biology approaches to decipher the pathology and mechanisms of cutaneous diseases. The five year training proposed will provide knowledge and experience in aspects that are critical to my success, and they are: i) To develop knowledge and experimental skills in cutaneous biology --- achieved by guidance from Dr. Elder (investigative dermatology), intense research meetings/conferences, and practical laboratory experience in cutaneous research; ii) To develop knowledge and skills to study immunological systems of autoimmune skin diseases --- achieved by supervision from Dr. Johann Gudjonsson (skin immunology), attending formal Immunology courses and seminars, and earning laboratory experience from immunology experiments; iii) To advance skills in developing statistical and computational approaches --- accomplished by mentoring from Dr. Goncalo Abecasis (computational biologist), research meetings, and conducting research projects requiring advanced skills and knowledge in quantitative science; iv) To cultivate my professional development through enhancing scientific connections, grantsmanship skills, and educator portfolio --- achieved by establishing connections with colleagues during meetings, visiting King’s College London as scholar, attending a grantsmanship workshop and bootcamp, and learning mentoring skills through teaching formal classes and mentoring research students. Through the intensive and comprehensive training, I will be well grounded in conducting basic science experiments and also be able to capitalize my advanced knowledge in quantitative science to model mechanisms in cutaneous diseases. Research Project The research project will use psoriasis as a disease model to study the roles of lncRNAs in complex cutaneous disorders. I will test the hypotheses that (i): some lncRNAs are key causal elements and potentiate pathogenic inflammatory reactions in psoriasis development and (ii) by combining in silico predictions and in vitro validations we are able to provide comprehensive characterization of skin-expressing lncRNAs in keratinocytes and lymphocytes to infer their pathological implications for psoriasis. This work will demonstrate how we can take advantages of the genomic data to develop an integrative biology framework to provide novel biological insights and understand pathological roles of lncRNAs. Significance Psoriasis is a chronic immune-mediated skin disease with complex genetic architecture. It is estimated that over 4 million Americans and 100 million people worldwide suffer from this disease. While genetic association studies have revealed the disease loci are highly enriched in non-coding regions, it is very challenging to translate genetic signals to biologic effects. In fact, most of the causal genes have not yet been identified. Our preliminary results showed that lncRNA is a class of gene that has largely been understudied for their roles in psoriasis, and both genetic and transcriptomic data suggested they can play important functions in psoriasis pathogenesis. By combining in silico analysis and in vitro validation we can expand our knowledge of lncRNAs in skin biology, and generate important hypotheses for future experiments. The results of this project can also identify novel biomarkers, and ultimately assist in the therapeutic drug discovery. PROJECT NARRATIVE Psoriasis is a chronic immune-mediated skin disease with complex genetic architecture, and affects over 4 million Americans and 100 million people worldwide. Long non-coding RNAs (lncRNAs) is a class of gene that has largely been understudied, and recent studies suggested their potential roles in autoimmune diseases. This project aims to expand our knowledge of lncRNAs in skin biology, and advance identification of lncRNAs that play functional roles in psoriasis pathogenesis.",Integrative Biology Approach to Identify and Characterize Roles of lncRNAs Associated with Psoriasis Pathology,10246892,K01AR072129,"['Affect', 'American', 'Appointment', 'Autoimmune', 'Autoimmune Diseases', 'Basic Science', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Biometry', 'Catalogs', 'Cellular Structures', 'Chromatin', 'Chronic', 'Complex', 'Coronary Arteriosclerosis', 'Cutaneous', 'Data', 'Dermatology', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Disease susceptibility', 'Doctor of Philosophy', 'Economic Burden', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Enzyme-Linked Immunosorbent Assay', 'Enzymes', 'Epigenetic Process', 'Faculty', 'Flow Cytometry', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Genomics', 'Genotype', 'Homing', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunologics', 'Immunology', 'In Vitro', 'Inflammatory', 'Inflammatory Response', 'Knowledge', 'Learning', 'London', 'Lymphocyte', 'Mediating', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Michigan', 'Modeling', 'Molecular', 'Pathogenesis', 'Pathogenicity', 'Pathologic', 'Pathology', 'Patients', 'Play', 'Process', 'Production', 'Proteins', 'Psoriasis', 'Public Health', 'Quality of life', 'Quantitative Reverse Transcriptase PCR', 'Reaction', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Science', 'Signal Transduction', 'Skin', 'Societies', 'Statistical Methods', 'Students', 'Supervision', 'Susceptibility Gene', 'Systems Biology', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Transcript', 'Translating', 'United States', 'Universities', 'Untranslated RNA', 'Validation', 'Visit', 'Work', 'analysis pipeline', 'base', 'candidate identification', 'career development', 'causal variant', 'cell type', 'cohort', 'college', 'comorbidity', 'cytokine', 'drug discovery', 'experience', 'experimental study', 'fascinate', 'genetic architecture', 'genetic association', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'immunoregulation', 'in silico', 'insight', 'interest', 'keratinocyte', 'knock-down', 'laboratory experience', 'machine learning method', 'meetings', 'novel', 'novel marker', 'recruit', 'scaffold', 'skills', 'skin disorder', 'small hairpin RNA', 'statistical center', 'success', 'symposium', 'tool', 'transcriptome sequencing', 'transcriptomics']",NIAMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2021,98982
"Systems Analysis of cell type differentiation in Xenopus development Summary The pathways involved in embryonic development have been a rich resource for understanding disease in adults, as well as being critically important in tracing the effects of genetic lesions and environmental poisons in the fetus. Frog embryos have been particularly useful due to the large size of the frog egg and embryo. New tools we developed for measuring the expression of RNA at a single-cell level, and advances in protein and phosphopeptide measurement technologies, offer hope for dramatic progress in understanding how signals involved in the maturation of the embryo direct individual cells to adopt specific fates. Our first goal is to define cell types using single-cell transcriptomics, and to define the lineages that result in specific cell types using high resolution temporal mappings. Targeted transcriptomics and proteomics of important molecules involved in specifying cell fate, such as transcription factors, will provide an index of the levels of signaling activity in each individual cell. This will result in an unprecedentedly detailed molecular picture of the factors involved in producing the phenotypes, and their interconversions from the early cleavage stage to the middle of organogenesis. The Xenopus model system allows us to dissect out portions of the early embryo that differentiate to ectoderm if not disturbed, called the animal cap. In the context of the embryo the cells in the animal cap receive a number of developmental signals, including Nodal, BMP, and Wnt. Combinations of these three signals (in different proportions) are capable of generating many of the major tissues. We will expose animal caps to a matrix of these three signals and trace the differentiation pathways that result, using single-cell RNA sequencing. This study of the molecular roots of differentiation decisions will be used to develop a mathematical approach, based on machine learning, to predicting the results of an attempted perturbation of the development of Xenopus. We will ask whether cell types are carefully specified by tightly controlled combinations of ligands or whether there are default states that are hard to escape from (""basins of attraction""), that therefore form the majority of embryonic cell types. The answer to this question is central to our understanding of how the Xenopus embryo reliably develops into a frog, and will accelerate efforts to create computational methods to predict the behavior of other biological pathways such as those involved in cancer. Narrative The complexity of biology makes it hard to predict what effect a mutation or a drug will have. We will use new tools to measure when genes are expressed at the individual cell level throughout the course of development of a vertebrate embryo. This will give us new information on the cell types involved in tissue and organ formation, and will provide an unprecedentedly detailed dataset that we will use to develop a mathematical model of how the decision to become a specific cell type is made.",Systems Analysis of cell type differentiation in Xenopus development,10174971,R01HD073104,"['Activins', 'Address', 'Adopted', 'Adult', 'Animal Cap', 'Bayesian Method', 'Behavior', 'Biochemical Pathway', 'Biological', 'Biological Models', 'Biology', 'Catalogs', 'Cell Lineage', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Ectoderm', 'Embryo', 'Embryonic Development', 'Event', 'Evolution', 'Exposure to', 'Fetus', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Goals', 'Grant', 'Individual', 'Internet', 'Investments', 'Knowledge', 'Lateral', 'Lead', 'Lesion', 'Ligands', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mesoderm Cell', 'Messenger RNA', 'Methods', 'Modeling', 'Molecular', 'Muscle', 'Mutation', 'Nodal', 'Organ', 'Organogenesis', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphopeptides', 'Phosphorylated Peptide', 'Phosphorylation', 'Plant Roots', 'Poison', 'Proteins', 'Proteomics', 'RNA', 'RNA library', 'Rana', 'Regulator Genes', 'Regulatory Pathway', 'Resolution', 'Resources', 'Series', 'Signal Transduction', 'Signaling Molecule', 'Specific qualifier value', 'Spectrometry', 'Statistical Models', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Xenopus', 'Xenopus laevis', 'base', 'blastomere structure', 'cell type', 'cluster computing', 'course development', 'egg', 'embryo cell', 'experimental study', 'hatching', 'indexing', 'innovation', 'knock-down', 'mathematical methods', 'mathematical model', 'notochord', 'novel', 'phosphoproteomics', 'predictive modeling', 'response', 'single cell proteins', 'single-cell RNA sequencing', 'temporal measurement', 'tool', 'transcription factor', 'transcriptomics', 'vertebrate embryos', 'xenopus development']",NICHD,HARVARD MEDICAL SCHOOL,R01,2021,614763
"Driver Genes for Engineered Rotator Cuff Development Rotator cuff tears affect over 15% of Americans and impair shoulder joint biomechanics and function. Following repair of symptomatic tears, functional deficits frequently persist and re-tears are common, due to the complex anatomy and high functional demands on the rotator cuff tendons. Rotator cuff tendon tissue engineering research is focused on devices to improve immediate mechanical support to the repair and to stimulate early and rapid tendon regeneration rather than scarring and fibrosis, particularly for the supraspinatus tendon (SST), the most commonly torn tendon in the rotator cuff. Aligned electrospun scaffolds that mimic both the highly aligned medial region of the SST, and bi-axially aligned electrospun scaffolds that mimic the multi-axially aligned isotropic anterior region of the SST have been evaluated with promising results when seeded with adipose- derived stem cells (ASCs). However, progress in this area of rotator cuff tendon engineering and in other areas of tendon research is hindered by the lack of definitive markers for SST or for its regional heterogeneity, the lack of understanding to what extent ASCs are tenogenic and can assume the identity of tendon fibroblasts, the lack of specific markers for tendon fibroblast identity and tenogenic differentiation, and by a lack of markers for tendon maturation and response to mechanical loading in engineered tendon. Therefore, is it difficult to assess how successful current tendon tissue engineering approaches really are, or to predict how well tendon tissue engineered approaches will function in translation when autologous or allogeneic ASCs from diverse human populations are used to enhance rotator cuff repair via augmentation or interposition with engineered tendon devices. These studies will evaluate the epigenome (methylome), transcriptome, proteome, lipidome, metabolome and phenome (phenotype) of native human SST and donor-matched tissue engineered tendon produced from SST fibroblasts and ASCs. Bioinformatics approaches will be used to integrate the data to an integrated multiome, which will then be used with machine learning approaches to extract key causal ‘driver’ genes, or tendon specific genes or molecules responsible for: 1) SST heterogeneity between medial and anterior regions. 2) Tendon cell identity and the extent of tenogenesis by ASCs on electrospun scaffolds. 3) The heterogenetic response by ASCs on uni- vs. bi-axially aligned electrospun scaffolds that mimic the native heterogeneity of the SST. 4) The response of engineered tendon to dynamic loading. Identified driver genes or molecules will be validated though over-expression or silencing approaches, thus providing therapeutic targets for manipulation to enhance tenogenesis, and engineered tendon development and maturation. Together these innovative studies will provide a template for improved external validity of benchtop tendon tissue engineering and pre-clinical studies towards successful translation in diverse patient populations. In addition, the bioinformatics and multiomics toolboxes and assays that result from this work will be invaluable to not only the tendon research community, but also to the wider musculoskeletal and regenerative medicine fields. A small number of driver genes in other medical fields are responsible for changes in expression and protein levels in hundreds of other genes, and subsequent tissue metabolism. The process of tissue engineered rotator cuff tendon development and formation as it relates to adult tendon after surgical repair is not well understood, despite rotator cuff tears being an important clinical problem and representing almost one third of orthopedic injuries. Evaluating changes in the ability of genes to be translated to proteins at the DNA, RNA, small metabolite, and protein level of tissue engineered tendon formation under different loading conditions compared to normal adult tendon will identify driver genes and potential new ways to improve currently available options for rotator cuff repair.",Driver Genes for Engineered Rotator Cuff Development,10098302,R01AR073882,"['Address', 'Adipose tissue', 'Adult', 'Affect', 'Allogenic', 'American', 'Anatomy', 'Anterior', 'Area', 'Autologous', 'Biochemical', 'Biocompatible Materials', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cadaver', 'Cells', 'Cicatrix', 'Clinical', 'Communities', 'Complex', 'Computational Technique', 'Cues', 'DNA', 'Data', 'Data Set', 'Development', 'Devices', 'Engineered Gene', 'Engineering', 'Evaluation', 'Extracellular Matrix', 'Fibroblasts', 'Fibrosis', 'Genes', 'Genetic', 'Harvest', 'Head', 'Heterogeneity', 'Human', 'Impairment', 'In Vitro', 'Injury', 'Investigation', 'Joint structure of shoulder region', 'Knowledge', 'Machine Learning', 'Measures', 'Mechanical Stimulation', 'Mechanics', 'Medial', 'Medical', 'Mesenchymal Stem Cells', 'Metabolism', 'Methylation', 'Modeling', 'Modification', 'Molecular', 'Musculoskeletal', 'Natural regeneration', 'Operative Surgical Procedures', 'Orthopedics', 'Outcome', 'Phenotype', 'Population', 'Process', 'Property', 'Proteins', 'Proteome', 'RNA', 'Regenerative Medicine', 'Research', 'Resources', 'Rotator Cuff', 'Seeds', 'Techniques', 'Tendon structure', 'Testing', 'Tissue Engineering', 'Tissues', 'Translating', 'Translations', 'Work', 'design', 'epigenome', 'improved', 'innovation', 'interest', 'lipidome', 'mechanical load', 'mechanical properties', 'metabolome', 'methylome', 'multiple omics', 'overexpression', 'patient population', 'phenome', 'phenomics', 'preclinical study', 'regenerative', 'repaired', 'response', 'rotator cuff tear', 'scaffold', 'spatial relationship', 'stem cells', 'supraspinatus muscle', 'tendon development', 'therapeutic target', 'transcriptome', 'translation to humans']",NIAMS,PURDUE UNIVERSITY,R01,2021,479770
"Employing the gut microbiome to accelerate effective initiation of rheumatoid arthritis therapy Title: Employing the gut microbiome to accelerate effective initiation of rheumatoid arthritis therapy ABSTRACT Rheumatoid arthritis (RA) is a complex, multifactorial, autoimmune disorder that affects ~1% of the worldwide population (~2 million adults in the US alone). It is characterized by chronic synovitis that, when left untreated, can result in irreversible joint destruction and deformity, leading to increased morbidity and all-cause mortality. The last three decades have witnessed impressive advances in the understanding of disease pathogenesis and therapeutic outcomes. In fact, the use of methotrexate first, and the subsequent incorporation of anti-TNF (TNFi) and other “biologics” have led to substantial improvements in RA clinical outcomes, enhancing the quality of life for millions of patients with inflammatory arthritis. Despite this progress, however, a significant question still remains unanswered: why do over 50% of RA patients with moderate to severe arthritis fail to respond appropriately to these agents? Pharmacomicrobiomics – an emerging field of study that investigates the effect of variations within the human gut microbiome on drugs – promises to overcome these barriers and facilitate precision medicine approaches in autoimmune disease.  Methotrexate (MTX), a dihydrofolate (DHF) reductase inhibitor, remains the anchor drug for the treatment of RA and is used widely throughout the world. While quite effective, oral MTX achieves significant results in less than 50% of patients and remission in only a quarter of them. It is well established that the inter-individual bioavailability of MTX is extremely variable, ranging from 10 to 80%. The reasons for this are presumably multifactorial. However, the intestinal microbiome and its enzymatic machinery are likely to play a significant role, based on our Preliminary Results and given that animals treated with antibiotics or kept under germ-free conditions show significant differences in MTX metabolism relative to control animals.  Our multidisciplinary team composed of rheumatologists, bioinformaticians, pharmacologists and microbiome researchers will address our overarching goal to study: a) if baseline intestinal microbiome, its genes, and associated metabolites can be used to predict the immunomodulatory responses to MTX in treatment-naïve, new-onset RA (NORA) patients; and b) if the gut microbiomes of MTX non-responders can be manipulated to modulate MTX metabolism and bioavailability. We believe that the results of our highly translational, innovative studies will directly influence therapeutic approaches for the treatment of RA and offer a more personalized approach in which the clinical efficacy response would be predicted early (and potentially improved by microbiome-targeted adjuvant therapies) in any given patient about to initiate MTX, limiting or preventing disease progression and ultimately avoiding wasteful health expenditures (estimated as ~$50,000/year/patient in direct costs). Importantly, we anticipate that our studies will establish generalizable approaches in rheumatology and autoimmunity that could be more broadly applied to the study and clinical maximization of other similar small molecules (e.g., JAK inhibitors) or even biologic agents (e.g., anti-TNF mAbs). NARRATIVE Rheumatoid arthritis (RA) is a chronic, autoimmune disease characterized by widespread musculoskeletal inflammation affecting 1% of the world’s population (including ~2 million adults in the US alone). While the use of methotrexate (MTX) has significantly improved the lives of many people with RA, over 50% of patients do not respond adequately to this drug. Successful completion of our proposed studies will provide key insights into the effects of the gut bacteria on MTX and the implications for prediction of clinical response, ultimately identifying patients that are either likely to improve even before this treatment is prescribed, or those that would benefit from microbiome-targeted interventions to improve MTX absorption and efficacy.",Employing the gut microbiome to accelerate effective initiation of rheumatoid arthritis therapy,10240299,R01AR074500,"['Address', 'Adherence', 'Adjuvant Therapy', 'Adult', 'Affect', 'Animals', 'Antibiotics', 'Arthritis', 'Autoimmune Diseases', 'Autoimmunity', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Availability', 'Biological Markers', 'Biological Products', 'Biological Response Modifier Therapy', 'Biometry', 'Cells', 'Chronic', 'Clinical', 'Complex', 'Control Animal', 'Coupled', 'Data', 'Deformity', 'Diagnosis', 'Dihydrofolate Reductase Inhibitor', 'Direct Costs', 'Disease', 'Disease Progression', 'Disease remission', 'Drug Kinetics', 'Engraftment', 'Excess Mortality', 'Exposure to', 'Foundations', 'Genes', 'Genetic Polymorphism', 'Genotype', 'Germ-Free', 'Goals', 'Health Expenditures', 'Human', 'Human Microbiome', 'Immunophenotyping', 'Individual', 'Individual Differences', 'Inflammation', 'Inflammatory Arthritis', 'Intervention', 'Intervention Studies', 'Knowledge', 'Lead', 'Left', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Metabolism', 'Metagenomics', 'Methotrexate', 'Modeling', 'Monitor', 'Monoclonal Antibodies', 'Morbidity - disease rate', 'Mus', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Oral', 'Outcome', 'Pathogenesis', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Play', 'Population', 'Positioning Attribute', 'Prediction of Response to Therapy', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Quality of life', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Series', 'Structure', 'Symptoms', 'Synovitis', 'TNF gene', 'Techniques', 'Therapeutic', 'Transplantation', 'Validation', 'Variant', 'absorption', 'arthritis therapy', 'bacterial community', 'base', 'biomarker identification', 'chronic autoimmune disease', 'clinical efficacy', 'clinical practice', 'cohort', 'cost', 'cost effective', 'disability', 'drug disposition', 'drug metabolism', 'effective therapy', 'experience', 'experimental study', 'field study', 'follow-up', 'germ free condition', 'gut bacteria', 'gut microbiome', 'gut microbiota', 'immunoregulation', 'improved', 'inhibitor/antagonist', 'innovation', 'insight', 'inter-individual variation', 'joint destruction', 'joint injury', 'metabolomics', 'microbial', 'microbiome', 'microbiome components', 'mortality', 'multidisciplinary', 'multiple omics', 'novel', 'personalized approach', 'personalized medicine', 'polyglutamates', 'pre-clinical', 'precision medicine', 'prevent', 'rRNA Genes', 'recruit', 'response', 'response biomarker', 'rheumatologist', 'sample collection', 'small molecule', 'therapy outcome']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,647865
"Application of advanced methodology to osteoarthritis phenotyping Osteoarthritis (OA) is highly prevalent, contributes to substantial morbidity in the population, and lacks effective interventions to prevent onset and progression. Importantly, and like many other chronic conditions, OA is not a single disease but rather a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying pathophysiological mechanisms. It is becoming increasingly clear that consideration of specific OA phenotypes in clinical studies and trials is critically needed to move the field forward. The overall goal of this line of work is to identify and understand potential phenotypes of knee osteoarthritis (KOA) to better inform future research efforts and treatments; this exploratory R21 project using OA Initiative (OAI) data will investigate novel methodology to support phenotyping in KOA. Successful treatments for OA will need to be targeted to, and tested in, specifically chosen OA phenotypes. Our hypothesis is that an understanding of KOA phenotypes, a key step toward Precision Medicine in OA, will lead to more successful clinical studies in the long-term. To approach this important clinical problem, we propose a project in which we will apply innovative machine learning methods and validation strategies to data from the large, publicly available OAI cohort. We will leverage this large dataset, along with local expertise in statistics, biostatistics and machine learning methodology, to tackle the problem of phenotyping this heterogeneous disease. In Aim 1, we will utilize a data-driven, unsupervised learning approach, to cluster features that best define and discriminate among phenotypes of KOA in the OAI dataset, using biclustering and a novel significance test (SigClust) developed by co-I Marron. For Aim 2, we will test specific hypotheses of relevance to OA outcomes, such as differences between those with and without OA, or those who do or do not develop new or worsening disease, using another set of machine learning methods (Direction-projection-permutation [DiProPerm] hypothesis testing, and Distance-Weighted Discrimination [DWD]), also developed by co-I Marron, in the full cohort and in any identified clusters from Aim 1. In order to address these aims, this proposal involves interdisciplinary collaborations among experts in statistics, biostatistics, computer science, rheumatology, and epidemiology. This work will significantly impact the field by fulfilling a critical need to accurately define OA phenotypes, discover the key features associated with these phenotypes, link phenotype subgroups to underlying mechanisms and use this information to inform and focus future clinical studies. In the long term, we expect that this strategy will lead to more personalized and successful management of the millions of people affected by OA. Project narrative Osteoarthritis is an enormous and increasing public health problem, and like many other chronic conditions it is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. The lack of appreciation of this heterogeneity has contributed to the failure of all attempts to date to develop disease-modifying osteoarthritis drugs; future trials will need to target specific OA phenotypes. There is a critical need to define and understand phenotypes in OA and link these to outcomes, leading to more personalized and successful management of this common and debilitating disease.",Application of advanced methodology to osteoarthritis phenotyping,10083187,R21AR074685,"['Address', 'Affect', 'Age-Years', 'Arthritis', 'Biomechanics', 'Biometry', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Discrimination', 'Disease', 'Epidemiology', 'Etiology', 'Failure', 'Fibrinogen', 'Future', 'General Population', 'Goals', 'Heterogeneity', 'Individual', 'Inflammation', 'Injury', 'Intervention', 'Joints', 'Knee Injuries', 'Knee Osteoarthritis', 'Link', 'Machine Learning', 'Meniscus structure of joint', 'Methodology', 'Morbidity - disease rate', 'Non obese', 'Obesity', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Progressive Disease', 'Public Health', 'Randomized', 'Research Methodology', 'Resources', 'Rheumatology', 'Risk Factors', 'Structure', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Visit', 'Work', 'base', 'bone', 'cohort', 'common treatment', 'computer science', 'demographics', 'design', 'disability', 'drug development', 'effective intervention', 'experience', 'improved', 'injured', 'innovation', 'interdisciplinary collaboration', 'joint destruction', 'large datasets', 'loss of function', 'machine learning method', 'novel', 'precision medicine', 'prevent', 'statistics', 'unsupervised learning']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2021,160567
"Macrophage Phenotype Transition as the Biological Mechanism of Chronic Wound Healing Treated with Non-Thermal, Non-Cavitational Therapeutic Ultrasound PROJECT SUMMARY/ ABSTRACT Chronic wounds affect approximately 6.5 million patients in the United States. Current standard protocols for wound management do not guarantee healing and focus on maintaining a wound environment that is conducive to passive self-healing. Hence, there is a need to develop alternative treatments that promote active healing and shorten healing time leading to reduced costs. We have previously reported that treatment with low-frequency (20-100 kHz), low-intensity (50-150 mW/cm2) ultrasound (LFLI US) significantly (p<0.03) reduces venous ulcer size in vivo as compared to wounds treated with a sham device. This proposal aims at determining the biological mechanisms by which LFLI US promotes chronic wound healing in vitro. There is evidence that the cause of impaired healing is the dysregulation of macrophage phenotype, especially the defective transition from pro- inflammatory (M1) to pro-healing (M2) macrophages. Our characterization of tissue debrided from chronic wounds has shown that healing chronic wounds contain higher proportions of M1-like than M2- like macrophages. Additionally, the signaling protein Rac2, downstream of integrin and focal adhesion kinase activation, is a key regulator of mechanotransduction in macrophages and facilitates the transition of macrophages from the M1 to M2 phenotype. The proposed study will systematically examine the effects of LFLI ultrasound on macrophage phenotype, using macrophages cultured in three-dimensional (3D) scaffolds. We hypothesize that LFLI US directly and indirectly stimulates the transition of pro-inflammatory M1 macrophages to pro-healing M2 macrophages via Rac2. This project will enhance our understanding of chronic wound healing and the potential of therapeutic ultrasound to accelerate healing. Aim 1 will elucidate the direct effects of LFLI US on macrophage function and phenotype by treating inflammatory macrophages directly with LFLI US and characterizing functional changes (proliferation, migration, and phagocytosis), protein/cytokine secretion, and gene expression. Concurrently, we will validate Rac2 as the potential mechanotransduction pathway which promotes M1 to M2 macrophages transition by analyzing integrins, focal adhesion kinases, and Rac2 via confocal microscopy and RNA characterization. [Aim 2 will validate the in vitro findings from Aim 1 using our previously developed diagnostic M1/M2 score on debrided tissue from chronic wound patients treated with LFLI US.] Aim 3 will elucidate the indirect effects of LFLI US on macrophage function and phenotype via a 3D macrophage fibroblast co-culture. The results of this study will inform the optimal design of LFLI ultrasound therapy protocols, lead to a personalized, active treatment for chronic wounds, accelerate chronic wound healing, and contribute to reduced annual wound care costs. Project Narrative Chronic wounds currently affect approximately 6.5 million patients in the United States and an excess of 25 billion dollars is spent annually on treatment. Current standards of care for chronic wounds, including months of weekly re-dressings and debridement, fails to guarantee active wound healing or closure. To address this issue, we propose to determine the biological mechanism responsible for therapeutic ultrasound mediated healing, low-intensity (<100mW/cm2), low-frequency (20kHz) ultrasound that has been shown to accelerate chronic wound closure in pilot clinical studies.","Macrophage Phenotype Transition as the Biological Mechanism of Chronic Wound Healing Treated with Non-Thermal, Non-Cavitational Therapeutic Ultrasound",10137782,F31AR074847,"['3-Dimensional', 'Address', 'Adhesions', 'Affect', 'Biological', 'Cells', 'Chronic', 'Chronic Care', 'Clinical Research', 'Clinical Trials', 'Coculture Techniques', 'Confocal Microscopy', 'Debridement', 'Devices', 'Diagnostic', 'Enzyme-Linked Immunosorbent Assay', 'Exhibits', 'Extracellular Matrix', 'Fibroblasts', 'Focal Adhesion Kinase 1', 'Frequencies', 'Gene Expression', 'Genes', 'Goals', 'Human', 'Impaired healing', 'In Vitro', 'Inflammation', 'Inflammatory', 'Integrins', 'Lead', 'Mechanics', 'Mediating', 'Pathway interactions', 'Patients', 'Phagocytosis', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Play', 'Process', 'Proteins', 'Protocols documentation', 'Prunella vulgaris', 'RNA', 'RNA analysis', 'Reporting', 'Role', 'Signaling Protein', 'Source', 'Sterile coverings', 'Stimulus', 'Therapeutic', 'Time', 'Tissues', 'Ultrasonic Therapy', 'Ultrasonography', 'United States', 'Varicose Ulcer', 'active method', 'alternative treatment', 'angiogenesis', 'behavioral phenotyping', 'care costs', 'cell type', 'chronic wound', 'cost', 'cytokine', 'design', 'diabetic ulcer', 'healing', 'human tissue', 'in vivo', 'knock-down', 'machine learning algorithm', 'macrophage', 'mechanotransduction', 'migration', 'rac2 GTP-binding protein', 'scaffold', 'three dimensional cell culture', 'wound', 'wound care', 'wound closure', 'wound environment', 'wound healing', 'wound treatment']",NIAMS,DREXEL UNIVERSITY,F31,2021,46036
"Acid-Base Status as a Novel Risk Factor for Fractures Project Summary/Abstract  Fractures are a major public health burden with its associated disability, cost, morbidity and mortality. In recent years, hip fracture rates are higher than expected and the incidence of vertebral fracture appears to be rising dramatically, especially after age 75 years. A growing body of research suggests that acidosis, even when subclinical, directly affects bone and can have detrimental effects on bone metabolism and health. Acidosis can inhibit osteoblast function and bone formation while promoting bone resorption and breakdown, thus impairing the bone’s ability to repair microdamage that occurs with daily wear and tear and accumulates with aging, and potentially contributing to higher fracture risk. The Nurses’ Health Studies (NHS) I and II and the Health Professionals Follow-up Study (HPFS) are ongoing large-scale cohort studies with decades of follow-up and rich dietary and lifestyle data, and archived biosamples. Integrating metabolomics technology into population-based studies is emerging as a valuable research tool which could provide novel insights into cellular processes that affect fracture risk. Therefore, this proposal’s goal is to prospectively study the association between acid-base status, assessed through dietary acid load, plasma bicarbonate level and plasma metabolites, and risk of incident fracture. We hypothesize that perturbations in acid-base status through diet-dependent and independent mechanisms resulting in increased acidosis will be associated with higher fracture risk. We will prospectively examine the association of dietary acid load with risk of incident hip and vertebral fracture in NHS I and II and HPFS (Aim 1). We will use a nested case-control study of hip fracture cases (n=650) and matched controls (n=650) within these three cohorts to study the association between plasma bicarbonate level (Aim 2), plasma metabolites (Aim 3) and risk of incident hip fracture in women and men. Archived plasma samples collected pre-hip fracture diagnosis will be measured for metabolites using state-of-the art, high-throughput liquid or gas chromatography followed by mass spectrometry (LC/MS/MS and GC/MS) platforms. Using advanced computational and biostatistical methods in metabolomics and high-dimensional data analyses, we will use a targeted metabolomics approach as well as an agnostic approach to build distinct metabolite signatures using all of the available plasma metabolite data to distinguish hip fracture cases from controls. Ultimately, we expect these studies to produce new insights into the development of fractures that may lead to new approaches to their prevention and treatment. Project Narrative  Osteoporosis and fractures are a major public health burden and a growing body of research suggests that acidosis, even when subclinical, can have detrimental effects on bone metabolism and health. This proposal’s goal is to prospectively study the association between acid-base status and risk of fractures. We expect these studies to produce novel insights into the development of fractures that may lead to new approaches to their prevention and treatment.",Acid-Base Status as a Novel Risk Factor for Fractures,9906852,R01AR075117,"['Acidosis', 'Acids', 'Adult', 'Affect', 'Age', 'Aging', 'Alkalies', 'Amino Acids', 'Anions', 'Archives', 'Attention', 'Automobile Driving', 'Bicarbonates', 'Biological Assay', 'Biostatistical Methods', 'Bone Density', 'Bone Regeneration', 'Bone Resorption', 'Bone remodeling', 'Buffers', 'Cell physiology', 'Citrates', 'Clinical', 'Cohort Studies', 'Computing Methodologies', 'Cross-Sectional Studies', 'Cysteine', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diet', 'Epidemic', 'Equilibrium', 'Excretory function', 'Follow-Up Studies', 'Fracture', 'Gas Chromatography', 'Generations', 'Glutamine', 'Goals', 'Health Professional', 'Hip Fractures', 'Impairment', 'Incidence', 'Investigation', 'Kidney', 'Lead', 'Liquid Chromatography', 'Liver', 'Longitudinal Studies', 'Malates', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Measures', 'Metabolic acidosis', 'Methionine', 'Morbidity - disease rate', 'Nested Case-Control Study', 'Nurses&apos', ' Health Study', 'Osteoblasts', 'Osteogenesis', 'Osteoporosis', 'Plasma', 'Population Study', 'Potassium', 'Prevalence', 'Prevention', 'Principal Component Analysis', 'Production', 'Prospective Studies', 'Public Health', 'Research', 'Risk', 'Risk Factors', 'Salts', 'Sampling', 'Sex Differences', 'Site', 'Skeleton', 'Spinal Fractures', 'Statistical Methods', 'Sulfur', 'Sulfuric Acids', 'Technology', 'Testing', 'Time', 'Urine', 'Woman', 'base', 'biological specimen archives', 'bone', 'bone health', 'bone metabolism', 'case control', 'clinically significant', 'cohort', 'cost', 'dietary', 'disability', 'extracellular', 'follow-up', 'fracture risk', 'insight', 'lifestyle data', 'lifetime risk', 'liquid chromatography mass spectrometry', 'men', 'metabolomics', 'mortality', 'multidimensional data', 'novel', 'novel strategies', 'prospective', 'repaired', 'secondary analysis', 'tool', 'western diet', 'wrist fracture']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,761948
"Multiscale models of fibrous interface mechanics PROJECT SUMMARY Interfaces between tissues either transfer load (requiring toughness) or provide a smooth surface (requiring low friction). Fibrous interfaces are very effective at transferring load between tissues, e.g., at connective tissue-bone interfaces (“entheses”), peritoneal-mesentery interfaces, interfaces between layers of the vasculature, and the pia mater. These interfaces require toughness to resist high stresses associated with material mismatches. Surgical repair can lead to smooth interfaces becoming fibrous, (e.g., following hernia surgery) or to tough interfaces becoming weak (e.g., following tendon- and ligament-to-bone repair). In older patients with large rotator cuff repairs, for example, where the desired attachment is not reformed, up to 94% of surgical repairs fail. These challenges arise in part because the features that endow fibrous interfaces with toughness are not known. We therefore propose to develop a comprehensive modeling and experimental approach for studying the factors underlying the transition from tough to weak in a fibrous interface. Our previous work motivates the hypothesis that disorder is a key toughening feature of fibrous attachments. We will focus initially on the example of tendon attaching to bone, in which microscale disorder underlies the ordered macroscale, graded transition between the two tissues, as a foundation for studying the general problem of adhesion throughout the body. We predict that disorder enhances energy absorption by distributing failure processes and energy absorption over larger volumes of tissue. We propose this as a fundamental mechanism by which fibrous interfaces in the body transfer load effectively. We will test these ideas through two aims: (1) Identify and model the mechanisms of fibrous attachment toughening ex vivo. We will model and experimentally validate how disorder across length scales toughens the tendon-to-bone attachment. Hierarchical molecular dynamics-to- continuum models, enriched by machine learning, will be validated in vitro, in systems with nanoscale control of mineral distributions, and ex vivo, in tissue samples of fibrous attachments. (2) Identify and model the loss of fibrous attachment toughness due to pathologic settings in vivo using murine rotator cuff tendinopathy models. In both aims, nano- through milli-scale characterization will be performed to define the mechanisms driving mechanical behavior. We will test the hypothesis that pathology- induced changes at multiple length scales will predict changes in failure mode. These models and experiments will test the global hypothesis that energy absorption across hierarchies is a fundamental toughening mechanism by which fibrous interfaces resist injury level loads. Taken together, we believe that these new models of fibrous attachment will enable an understanding of how the order and complexity of fibrous attachments leads to effective attachment of tissues. PROJECT NARRATIVE Tough fibrous interfaces between tissues are a common location of injury and source of pathology, pain and disability. Surgical repairs of interfaces that are desirable proceed in the absence of knowledge of the mechanisms that endow fibrous interfaces with toughness, and unsurprisingly have very high failure rates of up to a nearly unbelievable 94%. By developing and testing the first mathematical models for the toughness of this class of interfaces, we hope to identify the mechanisms of toughening definitively, and more broadly to provide technology that enables design of improved surgical procedures.",Multiscale models of fibrous interface mechanics,10222575,R01AR077793,"['Adhesions', 'Adhesives', 'Animal Model', 'Automobile Driving', 'Behavior', 'Biological Models', 'Bone Regeneration', 'Bone Tissue', 'Botulinum Toxin Type A', 'Brain', 'Characteristics', 'Collagen', 'Collagen Diseases', 'Collagen Fiber', 'Connective Tissue', 'Disease', 'Environment', 'Failure', 'Fiber', 'Foundations', 'Friction', 'Hernia', 'In Vitro', 'Injury', 'Intra-abdominal', 'Knowledge', 'Laparotomy', 'Lead', 'Length', 'Ligaments', 'Location', 'Machine Learning', 'Mechanics', 'Meniscus structure of joint', 'Mesentery', 'Minerals', 'Modeling', 'Modification', 'Mus', 'Musculoskeletal', 'Nature', 'Nervous system structure', 'Operative Surgical Procedures', 'Pain', 'Paralysed', 'Pathologic', 'Pathology', 'Patients', 'Peritoneal', 'Physiological', 'Pia Mater', 'Process', 'Rotator Cuff', 'Running', 'Skin', 'Slide', 'Source', 'Specimen', 'Stress', 'Structure', 'Surface', 'System', 'Technology', 'Tendinopathy', 'Tendon structure', 'Testing', 'Tissue Sample', 'Tissues', 'Work', 'absorption', 'bone', 'cranium', 'crosslink', 'design', 'disability', 'experimental study', 'improved', 'in vivo', 'mathematical model', 'mechanical behavior', 'millimeter', 'molecular dynamics', 'multi-scale modeling', 'nano', 'nanocrystal', 'nanoscale', 'older patient', 'repaired', 'treadmill']",NIAMS,WASHINGTON UNIVERSITY,R01,2021,474719
"Understanding the mechanisms by which weight change affects progression of knee osteoarthritis in obese and overweight individuals: An analysis of the Osteoarthritis Initiative Dataset Project Summary Osteoarthritis (OA) is a degenerative joint disease which affects more than 27 million people in the US and is the single most common cause of disability in older adults. The number of people affected with symptomatic OA will increase due to the aging of the population and the growing number of people with obesity, which represents an established risk factor for OA. Obesity has become a US “epidemic,” and projections have suggested that 86.3% of adults in the United States will be overweight or obese by 2030. Obesity is a modifiable risk factor for OA with weight loss offering a potential non-invasive therapy for disease prevention in obese and overweight individuals. Research has shown that weight loss slows OA progression and weight gain exacerbates progression. However, these studies did not specifically assess factors or pathways which would be responsible for improved or worse outcomes, such as associated inflammation, local body composition and sarcopenia. In the current proposal, we will comprehensibly examine the mechanisms associated with mechanical loading (weight loss and gain) that are responsible for driving knee joint degenerative changes including cartilage loss, namely concurrent changes in inflammation, local body composition (periarticular fat), and muscle morphology and strength. Identifying which mechanism(s) are most beneficial for slowing OA progression during weight loss will lead to targeted therapies for effective and optimized treatment of OA at early stages of disease during which progression may be prevented. Through pathway analysis, mediation analysis, and machine learning, we will identify potential preventive measures (such as muscle strengthening and anti-inflammatory measures) that could amplify the positive effects of reduced mechanical loading on OA. Thus, the clinical impact of our project is development of a subject-specific prediction model for clinicians to individually-tailor treatment plans that slow joint breakdown, and decrease probability for invasive and costly surgeries such as total knee arthroplasty. Three specific aims are proposed: Specific Aim 1: We will characterize the associations between changes in weight with changes in knee joint inflammation, local body composition, muscle cross-sectional area (CSA), fat infiltration and muscle strength, and investigate the associations between these parameters and progression of knee degenerative changes. Specific Aim 2: Using a path analysis we will explore the mechanisms by which weight change impacts OA progression, and quantify the degree to which these factors mediate this relationship. Specific Aim 3: Finally, we will develop a prediction model using machine learning to determine which demographic, clinical, and MRI features (including changes in local body composition, inflammation, muscle) can predict progression of OA over 8 years. Project Narrative (Public Health Relevance) While obesity is a modifiable risk factor for osteoarthritis (OA), studies analyzing the impact of weight loss in overweight and obese people have found inconsistent results on structural progression of knee OA. One potential explanation for these findings, and at the same time a major gap of knowledge in previous research, is that studies have not specifically assessed factors or pathways which, together with mechanical load, are responsible for improved or worse outcomes, such as associated inflammation, local body composition and sarcopenia. The overall goal of our proposal is to elucidate which mechanisms are responsible for slowing progression during weight loss, and which are most beneficial to develop individualized treatment plans targeting specific pathways that will enhance the positive effects of weight loss on slowing OA progression.",Understanding the mechanisms by which weight change affects progression of knee osteoarthritis in obese and overweight individuals: An analysis of the Osteoarthritis Initiative Dataset,10180705,R01AR078917,"['Adult', 'Affect', 'Aging', 'Anti-Inflammatory Agents', 'Area', 'Automobile Driving', 'Biochemistry', 'Biomechanics', 'Body Composition', 'Body Weight Changes', 'Body Weight decreased', 'Cartilage', 'Characteristics', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Disease', 'Elderly', 'Epidemic', 'Fatty acid glycerol esters', 'Goals', 'Individual', 'Infiltration', 'Inflammation', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Morphology', 'Muscle', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Outcome Measure', 'Overweight', 'Pathway Analysis', 'Pathway interactions', 'Persons', 'Population', 'Preventive measure', 'Probability', 'Research', 'Risk Factors', 'Role', 'Stress', 'Structural defect', 'Structure', 'Thick', 'Time', 'Tissues', 'United States', 'Weight', 'Weight Gain', 'base', 'cost', 'disability', 'disorder prevention', 'improved', 'individualized medicine', 'joint destruction', 'joint inflammation', 'knee replacement arthroplasty', 'mechanical load', 'modifiable risk', 'muscle form', 'muscle strength', 'novel', 'obese person', 'personalized risk prediction', 'predictive modeling', 'prevent', 'public health relevance', 'risk prediction model', 'sarcopenia', 'strength training', 'targeted treatment', 'treatment optimization', 'treatment planning']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,714433
"HIV-1 Tat genetic variation impacts NeuroAIDS Project Abstract/Summary The viral load can be controlled in the periphery of HIV-1-infected patients through consistent use of antiretroviral therapy (ART). Despite this, over 50% of HIV-infected patients are predicted to suffer from HIV-associated neurocognitive impairment (NCI). Although the pathogenesis of NCI is incompletely understood, HIV-1 transactivator of transcription (Tat) has been shown to be capable of being secreted from infected cells, and once extracellular within the central nervous system (CNS) it will induce neuronal dysregulation. Early in the infection, HIV-1 has been shown to establish a reservoir in the brain, either by entering as infected perivascular macrophages or infecting resident microglia, prior to the patient receiving ART. ART does not affect the production of Tat, which is continually made in these cells, leading to quantifiable levels of Tat in the absence of detectable viral load. Tat sequence composition varies within and between individuals due to HIV-1’s error-prone reverse transcriptase and host factors such as APOBEC3G. In the previous 5 years, we have shown that this variation is associated with NCI, as shown by our studies comparing the HIV-1 Tat protein sequence composition from impaired and non-impaired patients within the Drexel Medicine CNS AIDS Research and Eradication Study (CARES) Cohort. Residues associated with NCI included 59P, 74H, and 12K, while 36V, 40T, 63E, and 23T were associated with non-impairment. Effects of Tat variation can be further exemplified by Tat’s interaction with the NMDA receptor (NMDAR). This interaction can be weakened when Tat undergoes a C31S mutation, as shown in HIV-1 subtype C infections. Our preliminary data has shown that Tat genetic variants within the CARES Cohort have different predicted interaction profiles with GRIN2A, a subunit of NMDAR. Although the Tat-NMDAR interaction has been shown to be an established driver of HAND, it may not be the only factor involved in NCI in neuroHIV. Given this, we hypothesize that HIV-1 Tat genetic variation may cause differential secretion of Tat and/or affect Tat’s binding to molecular targets leading to neuronal dysfunction that underlies NCI in neuroHIV. To investigate this, we propose three Aims. Aim 1 will determine if amino acid variations in Tat associated with NCI via peripheral blood sampling correlates to that found in the CNS and/or intact provirus. Aim 2 will explore the impact of HIV-1 Tat genetic variation on protein-protein interactions that contribute to HAND pathogenesis. Aim 3 will assess the contribution of HIV-1 Tat variants to NCI using an in vivo model of Tat-induced neuropathogenesis. Overall, these studies will contribute to defining the mechanism of how HIV-1 Tat polymorphisms alter interactions with neurons and ultimately affect CNS function. Successful completion of the proposed project will result in a better understanding of the etiology of HAND, potential development of diagnostic assay for HAND, and identification of novel Tat-mediated targets for treating NCI. Project Narrative This proposal will build upon data from the previous funding period to understand how genetic variation in the viral accessory protein Tat affects its function and hence neuroHIV. Using complimentary in silico, in vitro, in vivo and ex vivo assays, we propose to delineate the mechanism by which Tat promotes neurotoxicity and neurocognitive impairment. Successful completion of the proposal will have implications in developing novel therapeutics to treat neurocognitive impairment and genetic diagnostic assays.",HIV-1 Tat genetic variation impacts NeuroAIDS,10075989,R01NS089435,"['APOCEC3G gene', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Amino Acid Sequence', 'Amino Acids', 'Architecture', 'Astrocytes', 'Behavior', 'Behavioral', 'Binding', 'Biological Assay', 'Blood specimen', 'Brain', 'Cells', 'Cohort Studies', 'Consensus', 'Custom', 'Data', 'Defective Viruses', 'Development', 'Dose', 'Etiology', 'Frequencies', 'Funding', 'Generations', 'Genetic', 'Genetic Polymorphism', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'HIV', 'HIV-1', 'HIV-associated neurocognitive disorder', 'Histology', 'Impaired cognition', 'Impairment', 'In Vitro', 'Individual', 'Infection', 'Integration Host Factors', 'Lead', 'Mediating', 'Medicine', 'Microglia', 'Midbrain structure', 'Modeling', 'Molecular Target', 'Mutation', 'N-Methyl-D-Aspartate Receptors', 'National NeuroAids Tissue Consortium', 'Nervous System Physiology', 'Network-based', 'Neuraxis', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuronal Dysfunction', 'Neurons', 'Neuropathogenesis', 'Neuropsychology', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Pharmacology', 'Positioning Attribute', 'Prefrontal Cortex', 'Production', 'Proteins', 'Proviruses', 'RNA-Directed DNA Polymerase', 'Rattus', 'Receptor Inhibition', 'Recovery', 'Research', 'Rodent Model', 'Scoring Method', 'Surface', 'Surface Plasmon Resonance', 'T-Lymphocyte', 'Testing', 'Tissues', 'Trans-Activators', 'Transactivation', 'Transfection', 'Variant', 'Viral', 'Viral Load result', 'Virus', 'antiretroviral therapy', 'behavioral outcome', 'brain tissue', 'cell type', 'convolutional neural network', 'design', 'diagnostic assay', 'experimental study', 'extracellular', 'fetal', 'genetic variant', 'in silico', 'in vivo', 'in vivo Model', 'macrophage', 'molecular modeling', 'monocyte', 'neuroAIDS', 'neurotoxicity', 'novel', 'novel therapeutics', 'peripheral blood', 'prevent', 'protein protein interaction', 'receptor', 'response', 'tat Genes']",NINDS,DREXEL UNIVERSITY,R01,2021,603073
"Symmetry Breaking and Collective Cell Growth in Drosophila Oogenesis PROJECT SUMMARY In many studied animal species, including mammals, the future oocyte develops within a cluster of cells that exchange molecules and organelles through a network of cytoplasmic bridges, which are formed by stabilized and reinforced cytokinetic furrows. While the formation and structure of this interesting class of multicellular systems has been extensively studied, their dynamics is poorly understood, leaving many critical questions about oocyte determination and development unanswered. I will investigate two of these questions in Drosophila, an experimental model that continues to provide valuable insights into general mechanisms of animal oogenesis. Using experimental, modeling, and computational approaches, I will investigate how one cell within the germline cell cluster is chosen to be the future oocyte and how the germline cell cluster comprising the oocyte and supporting nurse cells grows during development. Specifically, Aim 1 is designed to evaluate the differential contributions of the prepatterning and self-organizing mechanisms of oocyte determination. Focusing on the fusome, a membranous structure that is essential for intercellular communication in early oogenesis, and on a recently discovered positive feedback loop involving mRNA localization and translation, I will establish data- driven mathematical models for oocyte selection. In parallel, Aim 2 will investigate growth of the oocyte and supporting cells, using the germline cluster as a tractable system for exploring how the scaling laws established by studies of single cell growth are altered when cells grow together. In particular, I will focus on size regulation of nuclei and nucleoli, aiming to understand how their sizes adjust to rapidly increasing cell volumes within the germline cell cluster. The completion of these proposed studies, which are supported by strong preliminary results, including a machine learning approach for 3D image reconstructions and morphometric analysis, should provide new insights into some of the first steps of animal oogenesis. PROJECT NARRATIVE The proposed work will establish new quantitative approaches for studies of oocyte specification and collective cell size regulation during Drosophila oogenesis, an experimental system that continues to reveal highly conserved mechanisms of female germline development and provides unique opportunities for the integration of genetic, imaging, and computational techniques.",Symmetry Breaking and Collective Cell Growth in Drosophila Oogenesis,10285981,F31HD098835,"['Address', 'Animal Model', 'Animals', 'Cell Nucleus', 'Cell Volumes', 'Cells', 'Computational Technique', 'Consumption', 'Cyst', 'Data', 'Data Set', 'Development', 'Drosophila genus', 'Experimental Models', 'Feedback', 'Female', 'Future', 'Genetic Techniques', 'Growth', 'Image', 'Imaging Techniques', 'Insecta', 'Laws', 'Machine Learning', 'Mammals', 'Manuals', 'Messenger RNA', 'Nurses', 'Oocytes', 'Oogenesis', 'Organelles', 'Organism', 'Regulation', 'Regulation of Cell Size', 'Statistical Data Interpretation', 'Structure', 'Study models', 'Supporting Cell', 'System', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Work', 'base', 'cell growth', 'design', 'egg', 'experimental study', 'image reconstruction', 'imaging study', 'improved', 'insight', 'intercellular communication', 'mathematical model', 'quantitative imaging', 'reconstruction', 'supervised learning', 'tool']",NICHD,PRINCETON UNIVERSITY,F31,2021,39636
"Center for Critical Assessment of Structure Prediction (CASP) PROJECT SUMMARY  Experimental determination of protein structure often provides atomic accuracy models, but is inherently time- consuming, often costly, and not always possible. Computational modeling is currently less accurate, but offers an alternative approach when experimental results are not available. The goal of CASP (Critical Assessment of Structure Prediction) is to advance the protein structure modeling field by conducting community-wide experiments that objectively determine the strengths and weaknesses of current methods and so foster progress. Approximately 100 research groups world-wide participate. In the most recent experiment (2018), there were 57,000 submissions in nine modeling categories, including over 35,000 tertiary structure models. The Center provides the infrastructure for CASP and Aim 1 is the continued development and operation of this resource. Principal tasks include registration and communication with participants; solicitation, characterization, and management of modeling targets; collection and validation of models; and extensive numerical analysis of submissions. These operations are supported by a secure and robust data infrastructure. The Center also develops evaluation, analysis, and display software, and provides access to models and evaluation results. CASP relies on independent assessors, experts in modeling or a related experimental field, to interpret the results. The Center coordinates this process, providing evaluation data and, when necessary, implementing new evaluation methods.  Recent CASPs have shown dramatic improvements in model accuracy, especially for the most difficult cases where homology modeling cannot be used. A major factor driving progress is the use of new machine learning approaches, particularly convolutional neural networks. These and related methods appear poised to make further major advances in a number of key modeling areas. The plan for the next period of the project is designed to capitalize on these and other opportunities for progress. Greater success with modeling small proteins and domains dictates a shift in emphasis to the still challenging area of large multi-domain proteins and complexes (Aim 2), where progress is expected both from the machine learning developments and from the incorporation of sparse experimental data. Although accuracy of models has improved, it is still seldom competitive with experiment. Aim 3 is to pursue strategies that will make models more accurate and useful, by nurturing further progress in refining initial models, better methods for estimating model accuracy, and assessment of the utility of models. Aim 4 introduces new ways of strengthening interactions between CASP and the broader research community, providing models that directly address contemporary problems (for example, for CoV-2 protein structures) and boosting communications through meetings, webinars, publications and other means. PROJECT NARRATIVE Knowledge of macromolecular structure plays a crucial role in biology and medicine, allowing for detailed studies and understanding of biological processes and disease mechanisms. Yet, relatively few structures are obtained experimentally - the rest must be modeled. The Critical Assessment of Structure Prediction program (CASP), provides the primary means of evaluating performance of the methods dedicated to this task.",Center for Critical Assessment of Structure Prediction (CASP),10220601,R01GM100482,"['2019-nCoV', 'Address', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Process', 'Biology', 'Categories', 'Chemicals', 'Collaborations', 'Collection', 'Communication', 'Communities', 'Community Developments', 'Computer Models', 'Computer software', 'Consumption', 'Cryoelectron Microscopy', 'Crystallography', 'Data', 'Data Set', 'Development', 'Disease', 'Double-Blind Method', 'Drug Design', 'Epitopes', 'Evaluation', 'Fostering', 'Future', 'Goals', 'Gold', 'Homology Modeling', 'Information Dissemination', 'Infrastructure', 'International', 'Journals', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Medicine', 'Methods', 'Modeling', 'Molecular Biology', 'Molecular Structure', 'Paper', 'Participant', 'Performance', 'Play', 'Procedures', 'Process', 'Proteins', 'Provider', 'Publications', 'Reporting', 'Research', 'Resources', 'Rest', 'Role', 'Sampling', 'Seasons', 'Secure', 'Sequence Alignment', 'Series', 'Structural Models', 'Structure', 'Techniques', 'Tertiary Protein Structure', 'Time', 'Validation', 'Visualization', 'Work', 'base', 'biological research', 'convolutional neural network', 'cost', 'crosslink', 'data acquisition', 'data handling', 'data infrastructure', 'deep learning', 'design', 'experimental study', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'online resource', 'operation', 'programs', 'protein complex', 'protein structure', 'structural biology', 'success', 'symposium', 'vaccine development', 'webinar']",NIGMS,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2021,638990
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),10145009,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2021,1210147
"Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases The placenta is essential for fetal development and growth, maternal homeostasis, and broadly, pregnancy health. Yet, our ability to non-invasively probe placental health during human pregnancy is hampered by its deep intrauterine location and its highly vascular composition, rendering the placenta largely inaccessibly for safe and dynamic investigation. Whereas placental research has been advanced by cell culture, ex vivo systems, animal models, and postpartum analyses, these indirect approaches provide ex post facto information about placental health. Placental imaging has revolutionized the field of placental medicine, but resolution at the molecular, cellular, or metabolic level remains limited. To address these challenges, we and others have focused on the release of extracellular vesicles (EVs) from placental trophoblasts, which, in humans, are directly bathed in maternal blood. We focused on exosomes (now termed small EVs or sEVs), microvesicles, and apoptotic blebs, which are continuously and abundantly released from trophoblasts into the maternal circulation and are accessible throughout pregnancy by peripheral blood tests. Among these EVs, we focus mainly on placental sEVs, which harbor messages that are seldom expressed by any other cell types and execute unique placental biological functions, such as an antiviral response. While informative, recent data indicate that sEVs are not a uniform population of vesicles, but comprise several subgroups, defined as large sEVs, small sEVs, and exomeres. In addition to their size, these sEV subtypes are characterized by distinctive cargo. Although the recent discovery of sEV subpopulations has excited researchers due to their potential to revolutionize the field of non-invasive diagnostics, sEV subpopulations have yet to be utilized in clinical settings. This is largely due to the difficulties associated with separation and isolation the nano-sized sEV subpopulations. Our group has now developed advanced acoustofluidic technologies designed to effectively, reproducibly, and rapidly isolate sEVs from blood. We show that we can separate placental sEVs into their specific subpopulations, which has not been previously accomplished. Our proposed investigation therefore focuses on the production of human placental sEV subpopulations, along with their RNA and proteome cargo. We posit that, by profiling these analytes from sEV subpopulations, we can illuminate a unique landscape of bioactive molecules that are relevant to placental health. To reduce data complexity, we propose a machine learning pipeline that will be used to probe the sub-sEV spectra during normal and pathological pregnancies. Further, we will improve our ability to purify sEV subpopulations from lipoproteins, and generate a single, integrated device that can reliably separate vesicles in real time across human gestation. We believe that our automated acoustofluidic approach to separating sEV subpopulations in a high-yield, biocompatible manner is critical to unlocking the clinical utility of sEVs. Insights gained from our investigation will improve non-invasive diagnostics during pregnancy and may uncover new targets for personalized placental therapeutics. Our proposal centers on the discovery and analysis of previously unrecognized nanovesicle subpopulations that are produced by placental cells and are released to the maternal-fetal circulation. By studying these nanovesicle subpopulations in health and diseases of human pregnancy and by innovating new technologies to efficiently, rapidly, and reproducibly purify these nanovesicles from the blood and other biological media, we enable pioneering tools to interrogate the placenta in real time and improve clinical care during pregnancy.",Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases,10099051,R01HD103727,"['Address', 'Animal Model', 'Antiviral Response', 'Apoptotic', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Circulation', 'Blood Tests', 'Blood Vessels', 'Bulla', 'Cell Culture Techniques', 'Cells', 'Clinical', 'Communication', 'Culture Media', 'Data', 'Devices', 'Diagnostic', 'Dimensions', 'Discipline of obstetrics', 'Disease', 'Fetal Development', 'Fetal Growth Retardation', 'Field Flow Fractionation', 'Functional disorder', 'Funding', 'Genomics', 'Glean', 'Grant', 'Growth Factor', 'Growth and Development function', 'Health', 'Health Status', 'Homeostasis', 'Hormones', 'Human', 'Image', 'Inherited', 'Injury', 'Investigation', 'Lipoproteins', 'Location', 'MLLT2 gene', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuscripts', 'Maternal-Fetal Exchange', 'Medicine', 'Metabolic', 'MicroRNAs', 'Modification', 'Molecular', 'National Institute of Child Health and Human Development', 'Nature', 'Pathologic', 'Pathway interactions', 'Physiological', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Population', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Pregnancy', 'Production', 'Proteins', 'Proteome', 'Proteomics', 'RNA', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Subgroup', 'Surface', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Ultrasonography', 'Uterus', 'Vesicle', 'Woman', 'bioinformatics tool', 'biomaterial compatibility', 'cell type', 'clinical care', 'clinically relevant', 'data complexity', 'design', 'differential expression', 'epigenomics', 'exosome', 'extracellular vesicles', 'fetal', 'first responder', 'human disease', 'improved', 'in vivo', 'innovation', 'insight', 'liquid biopsy', 'microvesicles', 'molecular diagnostics', 'nanosized', 'nanovesicle', 'new technology', 'noninvasive diagnosis', 'novel', 'peripheral blood', 'pregnancy health', 'response', 'tool', 'trait', 'transcriptome', 'transcriptomics', 'trophoblast', 'vesicular release']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2021,542123
"Trio Analysis of Recurrent Pregnancy Loss Integrated Bioinformatics Genomics Study (TRIOS) PROJECT SUMMARY Recurrent pregnancy loss (RPL) affects up to 5% of couples, yet nearly half of cases remain unexplained by current testing recommendations. Euploid pregnancy loss, in the setting of unexplained RPL, is particularly frustrating for patients and providers because there is no clear explanation or any proven therapies to mitigate risk of subsequent miscarriages. As clinical presentation and subsequent pregnancy outcomes vary widely, this complex disorder will ultimately require a precision health approach. While more than 3000 human genes are conserved and likely essential for early development, remarkably little is known about their contribution to RPL and current genetic databases are essentially devoid of RPL entries. Moreover, there is currently no database that annotates phenotypes and genotypes of these essential genes. This proposal aims to define genetic determinants of RPL through clinical and molecular phenotyping and genomic sequencing of a large RPL cohort, combined with novel bioinformatics and machine learning approaches to derive predictive risk algorithms. A comprehensive approach to identify genomic markers of pregnancy loss by whole genome sequencing of well- characterized RPL trios (mother-father-pregnancy loss) will be undertaken in Aim 1. These genetics efforts will be paired in Aim 2 with metabolomic, lipidomic and single cell transcriptomic profiling preconception and in early pregnancy. Leveraged with innovative machine learning strategies in Aim 3, this approach will significantly advance understanding of the genetic underpinnings of unexplained RPL. A clinical ‘intolerome’ database will be constructed in Aim 4 to facilitate worldwide collaboration and curation of genotypes and associated phenotypes, making the genetics and omics data and results available to the public as well as other funded teams. This multidisciplinary team includes leaders in RPL, genetics, genomics, prenatal diagnosis, bioinformatics and machine learning at Stanford, UCSF and OHSU. Combined we have a substantial cohort of RPL patients that will serve as a robust recruitment source, along with a collaboration with the unique UK Pregnancy Baby BioBank of existing trios to accomplish project goals. The proposed study is anticipated to have significant clinical and research impact by identifying the genomic contribution to RPL in a large and well phenotyped cohort and building improved risk predictions based on machine learning incorporating clinical, genetic, and molecular data. This work will lay the foundation for precision medicine-based interventions for RPL couples who are difficult to diagnose and have few proven treatments. PROJECT NARRATIVE Given that there are very few proven treatments for unexplained recurrent pregnancy loss, uncovering genetic mechanisms is crucial for identifying individuals at risk and initiating targeted, patient-centered treatments. The proposed work will provide unprecedented machine learning analysis to define the spectrum of genomic and clinical indicators for recurrent pregnancy loss, unparalleled molecular phenotyping through metabolomics and single cell RNA sequencing, and development of a publicly-available “intolerome” database which will provide the foundation for a future prenatal OMIM.",Trio Analysis of Recurrent Pregnancy Loss Integrated Bioinformatics Genomics Study (TRIOS),10225966,R01HD105256,"['Affect', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Blood Circulation', 'Catalogs', 'Cells', 'Clinical', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Couples', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Essential Genes', 'Etiology', 'Fathers', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Databases', 'Genetic Determinism', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Heritability', 'Human', 'Immune', 'Individual', 'Intervention', 'Machine Learning', 'Medical Genetics', 'Molecular', 'Molecular Profiling', 'Mothers', 'Multiomic Data', 'Online Mendelian Inheritance In Man', 'Parents', 'Pathway interactions', 'Patients', 'Phenotype', 'Precision Health', 'Pregnancy', 'Pregnancy Outcome', 'Pregnancy loss', 'Prenatal Diagnosis', 'Provider', 'Recommendation', 'Recurrence', 'Regulator Genes', 'Risk', 'Seminal', 'Source', 'Spontaneous abortion', 'Structural Congenital Anomalies', 'Systems Biology', 'Testing', 'Work', 'adverse pregnancy outcome', 'base', 'biobank', 'clinical phenotype', 'cohort', 'data repository', 'early pregnancy', 'epidemiology study', 'exome sequencing', 'experience', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic biomarker', 'genomic locus', 'improved', 'innovation', 'insight', 'learning strategy', 'lipidomics', 'metabolomics', 'molecular marker', 'molecular phenotype', 'multidisciplinary', 'multiple omics', 'novel', 'patient oriented', 'phenotypic data', 'precision medicine', 'predictive modeling', 'prenatal', 'protein protein interaction', 'recruit', 'reproductive', 'reproductive system disorder', 'risk prediction', 'risk variant', 'single-cell RNA sequencing', 'transcriptomics', 'treatment center', 'whole genome']",NICHD,STANFORD UNIVERSITY,R01,2021,1465292
"Neurophysiologically-informed Design of Flexible, 2-learner Brain-Machine Interfaces for Robust and Skillful Performance PROJECT SUMMARY This proposal aims to elucidate the computational and neural basis of neuroprosthetic skill learning by leveraging recent advances in the science and engineering of closed-loop brain-machine interfacing. The outcome of the proposed work has the potential to guide the development of the next generation of neurophysiologically-informed, cortically-controlled neuroprosthetic systems for patients with neurological disorders. State-of-the-art brain-machine interfaces (BMIs) leverage machine learning to rapidly calibrate to the neural activity of individuals, but performance also benefits from subjects learning to reliably produce desired neural activity patterns. The basic science and engineering principles of designing such a “2-learner BMI” in which the brain and machine synergistically learn are not well understood. Hence, this proposal aims to investigate how the brain learns when the machine undergoes different degrees of learning, how different degrees of brain learning affect long-term BMI performance, robustness, and generalization, and how these principles can guide the design of a 2-learner BMI system which facilitates brain learning. The proposal is structured in three aims: 1) To study the impact of decoder adaptation on the development of neural encoding models underlying neuroprosthetic skill; 2) To Study how decoder adaptation and resultant neural encoding model influences BMI performance with perturbations (robustness) and BMI performance on unpracticed tasks (generalization); and 3) Design and validation of the next-generation Flexible 2-Learner Decoder architecture. The analyses and experiments proposed in these aims will leverage the fundamental knowledge gained about how the brain learns and acquires neuroprosthetic skills into the neurophysiologically-informed design of robust and high-performance closed-loop motor neuroprosthetics that generalize to new tasks. PROJECT NARRATIVE The proposed work will advance our understanding of the computational and neural basis of neuroprosthetic skill learning by leveraging recent advances in the science and engineering of closed-loop brain-machine interfacing. The outcome of the proposed work has the potential to guide the development of the next generation of neurophysiologically-informed, cortically-controlled neuroprosthetic systems for patients with neurological disorders.","Neurophysiologically-informed Design of Flexible, 2-learner Brain-Machine Interfaces for Robust and Skillful Performance",10113682,R01NS106094,"['Affect', 'Animal Model', 'Architecture', 'Automobile Driving', 'Basic Science', 'Brain', 'Chronic', 'Data Set', 'Development', 'Engineering', 'Feedback', 'Future', 'Goals', 'Implant', 'Individual', 'Knowledge', 'Learning', 'Learning Skill', 'Location', 'Macaca', 'Machine Learning', 'Microelectrodes', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Population', 'Privatization', 'Protocols documentation', 'Resistance', 'Science', 'Series', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Update', 'Validation', 'Work', 'brain machine interface', 'clinical development', 'computational basis', 'denoising', 'design', 'experimental study', 'flexibility', 'improved', 'indexing', 'insight', 'learning strategy', 'movement practice', 'nervous system disorder', 'neural patterning', 'neurodevelopment', 'neurophysiology', 'neuroprosthesis', 'next generation', 'nonhuman primate', 'relating to nervous system', 'skills']",NINDS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2021,343378
"DaTscan-based Disease Progression Models for Early-stage Parkinson’s Disease Project Summary Parkinson's disease (PD) is heterogeneous: it has many subtypes and the disease progresses at different rates in different subtypes. Disease progression in early-stage PD is observed as signal changes in SPECT imaging with 123I-FP-CIT, which is called DaTscan imaging, or simply DaTscan. The goal of the research proposed here is to create accurate models of heterogeneous PD progression using DaTscan images. Such models will not only provide additional insight into PD, but they are also critically important in assessing the effect of neuro-protective therapy. A new set of models called mixtures of linear dynamical systems (MLDS) are proposed to model early-state PD progression as it manifests in DaTscans. MLDS models combine machine-learning methods with linear dynamical system theory. They capture many features of early-stage PD progression: laterality, non-linear progression, as well as PD heterogeneity. Preliminary results show that, MLDS is accurate, finds progression subtypes, relates well to clinical data (MDS-UPDRS motor scores), and gives genuinely new insights about PD progression. The proposed research aims to develop the MLDS methodology in region-of-interest as well as voxel-based frameworks. A detailed discussion of the MLDS theory, model fitting, and the relation to clinical data is included. Longitudinal DaTscan images as well as MDS-UPDRS motor scores are available for over 440 subjects from the Parkinson's Progression Markers Initiative (PPMI), and this data set will be used along with MLDS to create the PD progression models. Project Narrative How Parkinson's disease (PD) progresses is poorly understood. This research proposes to develop precise disease progression models for PD using machine-learning. These models will give greater insight into PD progression and also help assess PD therapy.",DaTscan-based Disease Progression Models for Early-stage Parkinson’s Disease,10149422,R01NS107328,"['Algorithms', 'Anterior', 'Bilateral', 'Biological Models', 'Clinical', 'Clinical Data', 'Corpus striatum structure', 'Coupled', 'Coupling', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Disease Progression', 'Enrollment', 'Exhibits', 'Glean', 'Globus Pallidus', 'Goals', 'Handedness', 'Image', 'Joints', 'Left', 'Machine Learning', 'Mathematics', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Movement Disorder Society Unified Parkinson&apos', 's Disease Rating Scale', 'National Institute of Neurological Disorders and Stroke', 'Parkinson Disease', 'Pattern', 'Recommendation', 'Research', 'Research Design', 'Signal Transduction', 'Systems Theory', 'Work', 'base', 'disease heterogeneity', 'dopamine transporter', 'dynamic system', 'expectation', 'insight', 'interest', 'machine learning method', 'model design', 'neuron loss', 'presynaptic', 'progression marker', 'putamen', 'research clinical testing', 'single photon emission computed tomography', 'uptake']",NINDS,YALE UNIVERSITY,R01,2021,352779
"Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers Project Summary/Abstract:  The diagnosis of multiple sclerosis (MS) remains challenging due to its clinical heterogeneity and lengthy differential diagnosis. The incorrect assignment of a diagnosis of MS occurs in approximately 9% of newly evaluated patients and is associated with considerable clinically important, and avoidable, medical risk, morbidity, and healthcare costs. At the same time studies have demonstrated that many patients encounter a significant diagnostic delay prior to confirmation of a correct diagnosis of MS. In such patients early and accurate diagnosis of MS can result in prompt initiation of disease modifying therapy and consequent preventable disability. MS remains a clinical diagnosis and diagnostic criteria for MS are revised periodically, including most recently in 2017. Since implementation of the 2017 criteria, like all prior revisions, will continue to rely on subjective clinical and radiological assessments for its fulfillment, misdiagnosis will remain a risk.  New objective, automated, and clinically applicable approaches to MS diagnosis are needed. Recent preliminary data from cross-sectional pilot studies in patients with established diagnoses have shown promise for three new radiographic and three new laboratory methods to differentiate MS from other disorders. The present study will evaluate these six methods for the first time in a prospective cohort of 125 patients undergoing an initial evaluation for MS at an academic MS subspecialty center. The specificity and sensitivity of each method will be compared to fulfillment of 2017 MS diagnostic criteria at the time of initial clinical evaluation. Using diagnostic thresholds developed from this analysis, a two year post-enrollment analysis will also be performed in participants who did not meet 2017 criteria initially but did so during the subsequent two year interval to determine if the study methods could have predicted a diagnosis of MS earlier in such patients. The use of a multimodal and machine-learning approach to evaluate the integration of each of these six new methods which represent different aspects of MS neuroinflammatory and neurodegenerative processes will also be performed during each analysis, and such a combination of radiographic and laboratory methodology may provide superior diagnostic accuracy compared to any given method alone.  Planned collaborative career development, mentoring, and advising activities will facilitate acquisition of specific advanced quantitative and qualitative research skills necessary to develop and coordinate collection of data for this large prospective cohort study to rigorously evaluate new diagnostic methods for MS and incorporate machine learning analyses. Successful completion of this study will provide experience and skills necessary to move the field of MS diagnosis forward through a planned prospective multicenter NIH R01 funded study. Project Narrative: A highly specific, sensitive, objective and automated novel diagnostic approach to multiple sclerosis (MS) is needed maximize early benefits of disease modifying therapy in patients with MS and to prevent the frequent problem of MS misdiagnosis. This project assesses three novel MRI techniques and three novel blood tests for the diagnosis of MS in a large prospective cohort undergoing a new clinical evaluation for suspect MS. While each method may show promise alone, utilization of machine learning methodology combining these approaches that represent different aspects of MS pathophysiology may demonstrate a highly accurate and clinically applicable methodology for MS diagnosis.",Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers,10070136,K02NS109340,"['Algorithms', 'Appearance', 'Atrophic', 'Binding', 'Biological Assay', 'Biological Markers', 'Blood Tests', 'C-Peptide', 'Central Vein', 'Clinical', 'Clinical/Radiologic', 'Computer Models', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Differential Diagnosis', 'Disease', 'Early Diagnosis', 'Enrollment', 'Erythrocytes', 'Evaluation', 'Evolution', 'Functional disorder', 'Funding', 'Gene Expression', 'Goals', 'Gold', 'Health Care Costs', 'Image', 'Inflammatory', 'Laboratories', 'Lesion', 'Light', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Participant', 'Pathogenesis', 'Patients', 'Peptides', 'Pilot Projects', 'Process', 'Prospective cohort', 'Prospective cohort study', 'Qualitative Research', 'RNA', 'Rare Diseases', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Specificity', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Training', 'United States National Institutes of Health', 'Untranslated RNA', 'Whole Blood', 'accurate diagnosis', 'career development', 'clinical Diagnosis', 'clinical application', 'clinical diagnostics', 'clinical heterogeneity', 'clinical phenotype', 'clinical practice', 'cohort', 'diagnostic accuracy', 'disability', 'disease heterogeneity', 'experience', 'gray matter', 'improved', 'machine learning method', 'multimodality', 'multiple sclerosis patient', 'neurofilament', 'neuroinflammation', 'novel', 'novel diagnostics', 'novel imaging technique', 'prevent', 'prospective', 'recruit', 'research clinical testing', 'skills', 'specific biomarkers', 'support vector machine', 'white matter']",NINDS,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,K02,2021,192792
"The Nature and Function of Genomic Imprinting in Monoaminergic Neurons Mental illnesses are complex, affected by stressors and metabolic factors and involve changes to multiple behavioral components and decision-making processes. Thousands of genetic variants with small effects are typically involved. Thus, we lack a coherent genetic, cellular and evolutionary model for understanding and modifying important behavioral components affecting decision-making, activity and stress. If such a fundamental model of control could be uncovered for conserved, naturalistic behavior, our capabilities for understanding and therapeutically modifying behavioral disorders would be improved. Foraging has been studied for decades to uncover the basic principles and mechanisms of decision-making. Studies typically use simplified binary choice tests. However, we recently published a naturalistic foraging assay and unsupervised machine-learning methods to study complex, naturalistic decision patterns in mice. We discovered that foraging is composed of reproducible, genetically controlled behavioral sequences that we call “modules”. Using these methods, we investigated roles for maternally and paternally imprinted genes in controlling naturalistic decision patterns in males and females. Canonical imprinting involves complete silencing of one parent’s allele; however, we previously described genes with “noncanonical imprinting effects” that involve parental allele expression biases at the tissue level. We now have evidence that noncanonical imprinting effects at the tissue level involve allele silencing in subpopulations of cells. Moreover, we uncovered important roles for noncanonical imprinting effects in controlling naturalistic foraging and risk-reward-effort decision patterns. Currently, we do not fully understand the behavioral roles for different noncanonical imprinted genes. MEGs (maternally expressed genes) and PEGs (paternally expressed genes) are postulated to have opposing functional roles, suggesting an enticing genetic and evolutionary model of mammalian decision control. Imprinting effects in different cell populations could regulate the form, expression, timing and/or sequential order of different behavioral components of foraging. Therefore, our proposed study tests the hypothesis that noncanonical MEGs and PEGs have opposing effects on discrete behavioral components of naturalistic foraging and their cell-type specific imprinting effects reveal cell populations controlling discrete behaviors. In Aim 1, we will determine how MEGs and PEGs co-expressed with Th (tyrosine hydroxylase) and Ddc (dopa decarboxylase) in monoaminergic brain cells affect naturalistic decisions. In Aim 2, we will define functional links between discrete cell populations with imprinting effects for particular genes and discrete behavioral components of naturalistic foraging and decision patterns. Our proposed study is significant because it will help define an important genetic, cellular and evolutionary model of behavioral and decision control. Our long-term objective is to define a new conserved mechanistic model of control over decision patterns that helps delineate targets for therapeutically modifying human behavior. PROJECT NARRATIVE This study will make a substantial contribution towards improving our understanding of the expression and function of imprinted genes in the brain and the genetic and cellular mechanisms controlling complex behavior. The proposed research is relevant to public health because it could lead to improvements in our ability to evaluate genetic risk factors for mental illness according to whether mutations are maternally or paternally derived and uncover therapeutic strategies to help improve behavioral pathologies.",The Nature and Function of Genomic Imprinting in Monoaminergic Neurons,10367506,R01MH109577,"['Adrenal Glands', 'Adrenal Medulla', 'Affect', 'Alleles', 'Behavior', 'Behavior Control', 'Behavior Disorders', 'Behavioral', 'Behavioral Model', 'Biological Assay', 'Brain', 'Brain region', 'Catecholamines', 'Cells', 'Complex', 'DOPA decarboxylase', 'Decision Making', 'Dependovirus', 'Enzymes', 'Epigenetic Process', 'Epinephrine', 'Exhibits', 'Fasting', 'Female', 'Genes', 'Genetic', 'Genetic Models', 'Genomic Imprinting', 'Goals', 'Heritability', 'Heterozygote', 'Human', 'Hydrocortisone', 'Hypothalamic structure', 'Lead', 'Length', 'Link', 'Mammals', 'Mental disorders', 'Metabolic', 'Methods', 'Modeling', 'Mus', 'Mutant Strains Mice', 'Mutation', 'Nature', 'Neurons', 'Parents', 'Pathology', 'Pattern', 'Population', 'Process', 'Public Health', 'Publishing', 'Reporter', 'Reproducibility', 'Research', 'Resources', 'Rewards', 'Risk', 'Role', 'Serotonin', 'Stress', 'Testing', 'Therapeutic', 'Tissues', 'Tyrosine 3-Monooxygenase', 'behavior test', 'behavioral phenotyping', 'behavioral response', 'brain cell', 'cell type', 'genetic risk factor', 'genetic variant', 'hypothalamic-pituitary-adrenal axis', 'imprint', 'improved', 'machine learning method', 'male', 'maternal imprint', 'monoamine', 'novel', 'offspring', 'parental involvement', 'paternal imprint', 'sex', 'stressor', 'targeted treatment', 'unsupervised learning']",NIMH,UNIVERSITY OF UTAH,R01,2021,762322
"Decoding Astrocyte Signaling in Neural Circuitry with Novel Computational Modeling and Analytical Tools Astrocyte is the most abundant glia cell and significantly outnumbers neuron in the human brain. Long thought to be primarily passive cell, astrocyte has been increasingly recognized as essential player with active regulatory role in neural circuitry and pathology. Since a single astrocyte interacts with thousands of synapses, other glial cells and blood vessels, it is well positioned to link neuronal information in different spatial-temporal dimensions to achieve higher level brain integration. Indeed, neuron-astrocyte communication at synapses regulates breathing, memory formation, motor function, and sleep, and are implicated in many neuropsychiatric disorders. All these results provide strong rationale for modeling and analyzing astrocyte function, which will provide unprecedented insights to our understanding how astrocytes function to regulate and protect brain and how these functions can be exploited for astrocyte-based therapeutic targets. Recent advances in the modern microscopy and ultrasensitive genetic encoded calcium indicators (GECI) have enabled optical recording of astrocytic calcium dynamics – the excitatory state and functional readout of astrocytes – in vitro, ex vivo and in vivo. Compared to the great experimental capability of generating tremendous volumes of astrocyte functional data, the development of computational tools to analyze and interpret the complex and big data is lagged far behind, which has severely jeopardized a deeper understanding of the functional roles of astrocytes. To address the pressing need, we thus propose to develop sophisticated computational tools for interpreting the complex calcium dynamics data, through judicious application of advanced machine learning and systems theories. We have the following three specific aim. Aim1). Developing computational tools to analyze the cellular properties of calcium signaling in a single astrocyte. Aim2). Developing computational tools to analyze the network properties of calcium signaling in a population of astrocytes. Aim3). Validating experimentally the computational tools, developing optimal experiment protocol and disseminating the software packages. Our preliminary studies on both synthetic and real datasets demonstrate the feasibility of our plans and highlight the potential of analyzing astrocyte functional activity to understand neuronal circuitry and pathology, including for the first time the surprising discovery of hyper-activity in Down’s syndrome astrocytes compared to the normal astrocytes. This proposal is built on pre-established collaboration between two groups with the much needed complementary expertise for accomplishing this project, (1) computational scientists (Yu lab at Virginia Tech) and (2) experimental neuroscientists (Tian lab at UC Davis). The pre-established working relationships, developed channels of communication and mechanisms for resource sharing will help insure that the work will proceed in an efficient and effective manner. Project Narrative Although astrocytes, the most abundant glia cells in the brain, have been proposed to play important roles in the neural circuitry, our understanding of the physiological roles of astrocyte in neural circuitry is very limited partially due to the lack of sophisticated computational tools to analyze the complex astrocyte calcium data. We thus propose to apply advanced machine learning and systems theories to address the pressing need. Deep understanding of the functional roles of astrocytes in health and disease will translate into identifying novel therapeutic avenues for treatment of brain disorders.",Decoding Astrocyte Signaling in Neural Circuitry with Novel Computational Modeling and Analytical Tools,10102648,R01MH110504,"['Address', 'Astrocytes', 'Big Data', 'Biological', 'Biology', 'Blood - brain barrier anatomy', 'Blood Vessels', 'Brain', 'Brain Diseases', 'Breathing', 'Calcium', 'Calcium Signaling', 'Cells', 'Characteristics', 'Collaborations', 'Communication', 'Complex', 'Computer Models', 'Computer software', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Down Syndrome', 'Ensure', 'Epilepsy', 'Event', 'Feedback', 'Genetic', 'Goals', 'Graph', 'Health', 'Human', 'Hyperactivity', 'In Vitro', 'Joints', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Memory', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Motor', 'Mus', 'Nature', 'Neuroglia', 'Neurons', 'Optics', 'Paper', 'Pathology', 'Pathway Analysis', 'Peer Review', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Property', 'Protocols documentation', 'Psychological Techniques', 'Publishing', 'Research', 'Resource Sharing', 'Rodent', 'Role', 'Scientist', 'Signal Transduction', 'Sleep', 'Software Engineering', 'Statistical Models', 'Structure', 'Synapses', 'System', 'Systems Theory', 'Techniques', 'Testing', 'Time', 'Translating', 'Transplantation', 'Virginia', 'Work', 'analytical tool', 'autism spectrum disorder', 'base', 'calcium indicator', 'complex data', 'computerized tools', 'experience', 'experimental study', 'flexibility', 'in vivo', 'insight', 'interest', 'laboratory experiment', 'multidisciplinary', 'myelination', 'neural circuit', 'neuroimmunology', 'neuronal circuitry', 'neuropsychiatric disorder', 'novel', 'novel therapeutics', 'open source', 'signal processing', 'statistics', 'synaptogenesis', 'theories', 'therapeutic target', 'tool', 'user-friendly']",NIMH,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2021,488894
"Sensitive and Quantitative MS-bases Glycomic Mapping Platform Glycosylation is one of the most complex protein modifications; more than 50% of mammalian proteins are glycosylated. The fact that there are 100,000 proteoforms coded by only ~20,300 genes identified in the human genome emphasizes the importance of posttranslational modifications (PTMs) like glycosylation. Aberrant protein glycosylation has been implicated in many diseases, such as Alzheimer’s disease, congenital/metabolic disorders, diabetes, inflammation, Parkinson’s disease, bacterial/viral infectious diseases, and various cancers. More recently, glycans have been associated with coronavirus spike glycoproteins, including the SARS- CoV-2 virion. The diverse biological roles of glycans and their implications in diseases have created a demand for reliable qualitative and quantitative glycomic approaches, which facilitates sensitive investigation of glycan changes in different biological and biomedical samples. Mass spectrometry (MS) is the most efficient technique in glycomics due to its high sensitivity and capacity for acquiring structural information. However, glycomic research remains a challenge because of the microheterogeneity of glycan compositions in complex biological samples; the relatively low abundance in nature and low ionization efficiency in MS analysis; and the existence of variant positional and linkage isomers caused by the biosynthesis process. To overcome these challenges, several separation methods have been coupled to MS. Despite the development of these separation techniques, isomeric separation of glycans remains insufficient. There is an increasing demand for more efficient isomeric separation approaches since glycan isomers have been related to different diseases.  The main aim of this proposal is to provide easily accessible, adaptable, and affordable strategies for better separation and characterization of glycans and glycan isomers derived from different glycoconjugates. Aim 1 is focused on finding a replacement for porous craphitic carbon columns that sufferes from low reprodcubility and loss of resolution and efficiency with time. The in-house mesoporous graphitic carbon (MGC)-LC-MS will be investigated for both permethylated (Aim 1a) and native (Aim 2b) isomeric separation of N- and O-glycans, glycolipid glycans, and free oligosaccharides. Other alternatives (also part of Aim 1a), such as 50 cm and 200 cm micro pillar array columns (μPAC)-C18-LC-MS, and a 50 cm long capillary nanoC18-LC-MS, will also be evaluated to achieve an improved isomeric separation of glycan isomers. Subsequently, GUI will be utilized to improve the identification of glycan isomers. A GUI libraries for the separation strategies developed in Aim 1 will be established to normalize the possible retention time shift among different runs (Aim 2). LC-M based glycomics quantitative strategies will be developed and assessed in Aim 3. The combination of permethylation and TMT will capitalize on the advantages of both techniques, providing enhanced sensitivity and accuracy in glycan quantitation (Aim 3a). Additionally, the combination of 8-plex isotopic permethylation and 6-plex TMT will facilitate a reliable 48-plex, thus significantly increasing the throughput of analysis (Aim 3b). Furthermore, with the improved separation and identification (Aim 1 and 2), PRM will be employed to assist the better quantitation of glycans and the differentiation of glycan isomers. A library containing the fragments fingerprint of each glycan isomer will be created to aid the glycan isomeric identification (Aim 3c). The development of automated software for easy, fast, and accurate glycomic data processing is the main focus of Aim 4. Finally, the aforementioned strategies and tools will be applied to clinical samples to address a variety of biological and biomedical issues such as COVID-19, breast cancer brain metastasis, liver cancer vs. cirrhosis, kidney diseases, algae development, and others (Aim 5). The development of the proposed methods and algorithms will help us and our collaborators to better understand the attributes and biomedical significance of glycan isomers in the development and progression of esophageal, breast, and liver cancer. Furthermore, we expect the analytical tools and algorithms proposed here to benefit researchers and scientists who are interested in understanding the biological attributes of glycan isomers in other systems. The proposed research will enable the development of tools for the characterization of protein carbohydrate structures at a sensitivity, throughput, and level of detail not previously possible. The implementation of these tools will enable researchers to better understand the attributes and biomedical significance of glycans in the development and progression of a wide array of diseases. Examples of future benefits for public health include the identification of disease and cancer biomarkers for medical diagnostics and the monitoring of recombinant protein therapeutics, which will lead to better targeted drugs that are more bioactive with fewer side effects.",Sensitive and Quantitative MS-bases Glycomic Mapping Platform,10318016,R01GM112490,"['2019-nCoV', 'Address', 'Adhesions', 'Algae', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anabolism', 'Area', 'Bacterial Infections', 'Bioinformatics', 'Biological', 'Biological Process', 'Blood capillaries', 'COVID-19', 'Carbon', 'Cell Differentiation process', 'Cells', 'Cirrhosis', 'Clinical', 'Code', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Coronavirus', 'Coronavirus spike protein', 'Coupled', 'Cystic Fibrosis', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug Targeting', 'Fingerprint', 'Future', 'Gangliosides', 'Genes', 'Glucose', 'Glycoconjugates', 'Glycolipids', 'Glycoproteins', 'Goals', 'High temperature of physical object', 'Human Genome', 'Immune response', 'Inflammation', 'Investigation', 'Ions', 'Isomerism', 'Isotopes', 'Kidney Diseases', 'Label', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Malignant neoplasm of liver', 'Mass Spectrum Analysis', 'Medical', 'Metabolic Diseases', 'Metastatic malignant neoplasm to brain', 'Methods', 'Monitor', 'Natural graphite', 'Nature', 'Oligosaccharides', 'Outcome', 'Parkinson Disease', 'Pattern', 'Polysaccharides', 'Post-Translational Protein Processing', 'Process', 'Protein Glycosylation', 'Proteins', 'Public Health', 'Reaction', 'Recombinant Proteins', 'Research', 'Research Activity', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Sampling', 'Scientist', 'Software Tools', 'Structure', 'Symbiosis', 'System', 'Techniques', 'Time', 'Traumatic Brain Injury', 'Variant', 'Viral', 'Virion', 'Virus Diseases', 'analytical tool', 'base', 'bioinformatics tool', 'cancer biomarkers', 'carbohydrate structure', 'computerized data processing', 'drug development', 'glycosylation', 'implementation tool', 'improved', 'indexing', 'interest', 'ionization', 'malignant breast neoplasm', 'nano', 'pathogen', 'predictive modeling', 'predictive signature', 'protein complex', 'side effect', 'software development', 'tandem mass spectrometry', 'therapeutic protein', 'tool', 'tool development']",NIGMS,TEXAS TECH UNIVERSITY,R01,2021,316105
"Dissecting the role of the direct and indirect pathways in moment-to-moment action selection. Brains transform sensory information into decisions and decisions into behaviors, which ultimately determine fitness. Behavior can be broken down into a set of discrete chunks of movement, called actions. The basal ganglia (BG) and in particular the input nucleus of the BG, the striatum, is critical for the proper sequencing and selection of actions. At a cellular level, the striatum is comprised of spiny projection neurons (SPNs) that constitute the direct pathway (dSPNs) and indirect pathway (iSPNs). Under the center-surround model of action selection, dSPNs are thought to facilitate the expression of an action while iSPNs are thought to inhibit the expression of other actions. However, it is not clear how each pathway contributes to action selection due to methodological constraints in acquiring an objectively quantitative description of behavior. Our lab has recently developed a pipeline, known as MoSeq, that acquires high-resolution behavioral data and uses an unsupervised algorithm to model stereotyped pose dynamics (actions or “syllables”). Here I propose to combine this state-of- the-art behavioral acquisition and detection technology with both cellular-resolution imaging and optogenetic perturbation to study the population dynamics underlying action selection in the striatum. I hypothesize that SPNs exhibit syllable-specific tuning, where dSPNs are tightly tuned to facilitate the expression of related syllables, while iSPNs are more broadly tuned to suppress the simultaneous expression of other syllables. I will dissect these two processes by recording and manipulating each SPN class during specific syllable expression. In aim 1, I will perform cellular-resolution recordings of the direct or indirect pathway using genetically encoded calcium indicators and miniaturized microendoscopy in the striatum. I will examine the differential roles of the direct and indirect pathways in the context of behavioral tuning. My preliminary data suggest that dSPNs are more sparsely tuned than iSPNs. In aim 2, I will functionally test the center-surround model via direct and indirect pathway inhibition. I will use the inhibitory anion-conducting rhodopsin, ACR2. Using a system capable of detecting syllable expression in real-time, I will perturb each pathway triggered upon the expression of specific syllables to compare the same selection context across many trials. In summary, the experiments proposed here will contribute to a mechanistic understanding of how the BG performs action selection on a moment-to-moment timescale. This proposal is the first to test the predictions made by the center- surround model and will advance our understanding of how the BG encodes actions. Behavior is constructed from actions that are placed into sequences that enable animals to achieve ethologically relevant goals. The striatum, the input nucleus of the basal ganglia, is critical for the proper selection and expression of actions. My work aims to understand how striatal circuits perform action selection on a moment- to-moment timescale.",Dissecting the role of the direct and indirect pathways in moment-to-moment action selection.,10238135,F31NS113385,"['Address', 'Algorithms', 'Animals', 'Anions', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Cell Nucleus', 'Corpus striatum structure', 'Data', 'Detection', 'Endoscopes', 'Environment', 'Exhibits', 'Goals', 'Human', 'Image', 'Individual', 'Methodology', 'Modeling', 'Motion', 'Movement', 'Neurons', 'Organism', 'Output', 'Pathway interactions', 'Pattern', 'Play', 'Population', 'Population Dynamics', 'Postural adjustments', 'Process', 'Property', 'Resolution', 'Rhodopsin', 'Rodent', 'Role', 'Sensory', 'Series', 'Stereotyping', 'Substantia nigra structure', 'System', 'Technology', 'Testing', 'Time', 'Work', 'calcium indicator', 'complement pathway', 'experimental study', 'fitness', 'indexing', 'microendoscopy', 'miniaturize', 'optogenetics', 'tool', 'unsupervised learning']",NINDS,HARVARD MEDICAL SCHOOL,F31,2021,33868
"Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index Project Summary  Delayed cerebral ischemia (DCI) is the most devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. Only after medical management fails, is endovascular treatment (EVT) including intraarterial vasodilator infusion and/or intracranial angioplasty initiated. This reactive practice does not account for early predictors of DCI and may miss the optimal EVT window at an early stage of DCI development before symptoms or severe deviations from normal hemodynamics. The goal of this project is to develop algorithms to predict DCI and related targets at an early stage in their development. An accurate prediction of DCI will enable a more proactive strategy to prevent and treat the underlying cause of DCI.  The following three aims will be pursued towards the goal of the project: 1) Develop aSAH-specific intracranial pressure (ICP) pulse-based cerebral arterial state index; 2) Develop and validate predictive models of targets related to delayed cerebral ischemia after aSAH; 3) Conduct a prospective institution- specific adaption and validation of the developed models.  Our DCI predictive algorithms only need data available in current clinical practice hence they can be readily adopted. If validated, these algorithms will enable clinicians to monitor risk of DCI continuously and to proactively deliver appropriate treatment. The proposed prospective study of algorithm implementation and adaptation will well prepare future clinical trials to test the efficacy of algorithm-informed interventions. Project Narrative  Delayed cerebral ischemia (DCI) is a devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. The goal of this project is to develop algorithms to predict DCI and other related targets at an early stage in their development to enable a more proactive strategy to prevent and treat the underlying cause of DCI.",Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index,10251348,R01NS113541,"['Acute', 'Adopted', 'Algorithms', 'Aneurysmal Subarachnoid Hemorrhages', 'Angioplasty', 'Appearance', 'Area', 'Blood Flow Velocity', 'Cerebral Ischemia', 'Cerebral perfusion pressure', 'Cerebrovascular Circulation', 'Cerebrum', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Complication', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Diagnosis', 'Dilatation - action', 'Distal', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Future', 'Goals', 'Hydrocephalus', 'Incidence', 'Individual', 'Infusion procedures', 'Injury', 'Institution', 'Intervention', 'Intracranial Pressure', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Neurologic', 'Neurological status', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Procedures', 'Process', 'Prospective Studies', 'Pulse Pressure', 'Recurrence', 'Reproducibility', 'Research', 'Risk', 'Shapes', 'Signal Transduction', 'Source', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcranial Doppler Ultrasonography', 'Validation', 'Vasodilator Agents', 'base', 'clinical practice', 'constriction', 'data streams', 'diagnostic accuracy', 'efficacy testing', 'electronic data', 'hemodynamics', 'improved', 'indexing', 'machine learning algorithm', 'novel', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'recurrent neural network', 'relating to nervous system', 'temporal measurement', 'vector']",NINDS,DUKE UNIVERSITY,R01,2021,582524
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,10124433,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2021,199800
"Computational Imaging of Renal Structures for Diagnosing Diabetic Nephropathy Project Summary At the current rate, one in three U.S. adults will be diabetic by 2050. A disease secondary to diabetes is diabetic nephropathy (DN), which causes end-stage renal disease (ESRD) for >225K U.S. patients (50% of all ESRD cases), accounting for >$19K in yearly Medicare costs for each patient. Measurement of minute urinary albumin (microalbuminuria) is the most common non-invasive clinical biomarker of DN. In order to conclusively define DN severity, pathologists conduct qualitative manual estimation of glomerular structural damage in renal biopsies. However, renal glomerular structure in DN biopsies does not often correlate with less invasive clinical biometrics (e.g., estimated glomerular filtration rate, urine protein, serum creatinine and glucose levels). This traditional diagnostic method is approximate, subjected to user bias, time-consuming, and has low diagnostic precision in early disease stages; further, manual hand identified features may not always accurately predict disease progression. Computational image analysis offers the opportunity to project clinical biometrics onto glomerular histological structures. This method provides finer precision in identifying structural changes that lead to physiological changes, which in turn reduces the required clinical resources and time for diagnosis, and provides clinicians with greater feedback to improve early intervention. We have developed computational tools to quantify renal structures in human DN biopsies. Our tools quantify glomerular features in histological renal tissue images more efficiently than manual methods. We have also derived a quantitative progression risk score (PRS) describing DN progression risk estimated off only a single biopsy point. Here, we will rigorously analyze the performance of these methods to predict disease progression using histological images of human DN renal biopsies. We will computationally quantify morphologically diverse DN-indicative intra-glomerular features. We will analytically integrate computationally derived glomerular features with clinical biometrics in order to develop patient-specific PRS to identify patients at risk of renal failure. Since human renal DN data is sparse, we will also use murine data, which can be generated in large amounts in a controlled fashion, to initially train the computational models. We will then refine the model for clinical use by fine-tuning the parameters using human data. The innovation is in the novel integration of traditional clinical detection methods with traditional diagnostic methods, under a computational schema for enhanced precision. This integration will lead to computational disease predicting biomarkers of the earliest measurable renal DN dysfunction. We will study the predictive power of these markers to foretell future clinical endpoints from earlier time points. These methods support the development of quantifiable prognostic and predictive information, which is dynamic over the disease course, easily discriminated, and is highly informative for modeling disease progression or response to therapy. This study will 1) enable earlier clinical predictions, thus extending windows for interventions of evolving DN; and 2) work as a pilot platform for future studies to computationally derive renal biomarkers predictive of other diseases. Narrative Diabetic nephropathy (DN) causes end-stage renal disease (ESRD) for >225K U.S. patients (50% of all ESRD cases), accounting for >$19K in yearly Medicare costs per patient. Renal glomerular structure in DN biopsies, however, does not often correlate with less invasive clinical biometrics (e.g., estimated glomerular filtration rate, urine protein, and serum creatinine and glucose levels). Our research will transform diagnostic methods and treatment of DN by combining traditional clinical detection methods with traditional diagnostic methods under a computational schema to precisely identify the earliest measurable glomerular structural changes, as well as identify patients at risk of renal failure, thus opening new windows to precision therapy.",Computational Imaging of Renal Structures for Diagnosing Diabetic Nephropathy,10208865,R01DK114485,"['Accounting', 'Adult', 'Albumins', 'Albuminuria', 'Architecture', 'Biological Markers', 'Biometry', 'Biopsy', 'Characteristics', 'Classification', 'Classification Scheme', 'Clinical', 'Clinical Data', 'Communities', 'Computer Models', 'Computing Methodologies', 'Consumption', 'Cost Savings', 'Creatinine', 'Data', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Nephropathy', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Early Intervention', 'Elements', 'End stage renal failure', 'Eye', 'Feedback', 'Functional disorder', 'Future', 'Glomerular Filtration Rate', 'Glucose', 'Goals', 'Hand', 'Histologic', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Intervention', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Lead', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Medicare', 'Methods', 'Microalbuminuria', 'Microscopic', 'Modeling', 'Morphology', 'Mus', 'Neural Network Simulation', 'Outcome', 'Pathologic', 'Pathologist', 'Patients', 'Performance', 'Physiological', 'Precision therapeutics', 'Proteins', 'Refractory', 'Renal Tissue', 'Research', 'Resources', 'Risk', 'Risk Estimate', 'Secondary to', 'Serum', 'Severities', 'Staging', 'Stains', 'Standardization', 'Streptozocin', 'Structural Models', 'Structure', 'Therapeutic Intervention', 'Thinness', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Urine', 'Variant', 'Visual', 'Work', 'autoencoder', 'base', 'clinical biomarkers', 'clinically relevant', 'computer studies', 'computerized tools', 'convolutional neural network', 'cost', 'detection method', 'diabetic', 'digital', 'follow-up', 'histological image', 'human data', 'human imaging', 'improved', 'information model', 'innovation', 'kidney biopsy', 'mouse model', 'network models', 'novel', 'personalized diagnostics', 'predictive marker', 'prognostic', 'protein biomarkers', 'response', 'statistics', 'tool', 'urinary']",NIDDK,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2021,296893
"Niche signals in HSC genesis PROJECT SUMMARY Hematopoietic stem cells (HSC) have well established clinical applications in the treatment of heritable and acquired blood disorders. However, their therapeutic potential could be significantly broadened by engineering novel methods to generate HSC de novo from pluripotent stem cells or from directly reprogrammed adult cells. Toward this goal, we have established endothelial cell (EC) niche based culture methods that provide the necessary conditions to support the specification and self-renewal of HSC from embryonic hemogenic precursors, and more recently, from adult ECs using transcription factor (TF)-mediated conversion that bypasses a pluripotent intermediate. We hypothesize that recreating the signals necessary and sufficient to develop a clinically meaningful system for HSC generation in vitro will necessitate a comprehensive, systems approach to deconstruct the niche provided signals required for HSC specification and self-renewal. Thus, the overall goal of this grant is to leverage unique expertise of the collaborating laboratories to elucidate the signaling interactions regulating HSC specification and self-renewal from embryonic hemogenic precursors or TF-reprogrammed adult EC in the context of the EC niche. Our approach consists of three overlapping aims. The first aim will identify EC niche-provided signals necessary for embryonic HSC specification and self-renewal. The second aim will identify the unique HSC programs induced by these signals that regulate the transition from embryonic hemogenic precursor to bone fide repopulating HSC. The third will identify comparable programs that regulate the transition from adult EC to HSC during TF-mediated reprogramming in the EC niche. Key to these studies will be innovative functional assays, transcriptional profiling methods, and computational approaches that will enable us to resolve cellular complexity of niche cells and their interactions with developing embryonic or reprogrammed HSC at the single cell level. The role of identified signal factors in stage-specific support of HSC specification will be validated and further refined in vitro by gain and loss of function studies in the context of niche EC. Furthermore, to extend these studies to stromal cell-free systems as a step toward clinical translation, we will also test the contribution of identified signal factors in HSC specification and self-renewal in the context of stage-specific modulation of Notch activation using engineered Notch agonists. To achieve the goals of this proposal, we have developed a multidisciplinary collaboration involving unique expertise in each of our laboratories, including basic HSC and EC niche cell biology, direct TF based cellular conversion, clinical HSC transplantation, genome wide assessment of rare stem cell populations at single cell resolution, and innovative computational approaches to deconstruct core signal pathways regulating developmental transitions. Altogether, we expect the proposed studies will ultimately guide the design of novel strategies for deriving and expanding HSC in vitro for therapeutic applications. NARRATIVE Hematopoietic stem cells are currently used in the treatment and cure of a variety of blood disorders. Methods to generate new or greater numbers of hematopoietic stem cells in the laboratory could expand the availability and therapeutic applications of these valuable cells, but currently such methods are lacking. The goal of this proposal is to use lessons from endothelial cells, which provide critical signals to support hematopoietic stem cells, to engineer novel systems for the development and expansion of hematopoietic stem cells in culture. !",Niche signals in HSC genesis,10224676,RC2DK114777,"['Address', 'Adult', 'Agonist', 'Aorta', 'Biological Assay', 'Blood Vessels', 'Bypass', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cell-Free System', 'Cells', 'Cellular biology', 'Clinical', 'Coculture Techniques', 'Development', 'Embryo', 'Embryonic Development', 'Endothelial Cells', 'Engineering', 'Gene Expression Profiling', 'Generations', 'Goals', 'Gonadal structure', 'Grant', 'Hematological Disease', 'Hematopoietic Stem Cell Specification', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic stem cells', 'Heritability', 'Human', 'In Vitro', 'Interdisciplinary Study', 'Laboratories', 'Mediating', 'Mesonephric structure', 'Methods', 'Molecular', 'Molecular Analysis', 'Pathway interactions', 'Physiological Processes', 'Pluripotent Stem Cells', 'Population Heterogeneity', 'Resolution', 'Role', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Sorting - Cell Movement', 'Source', 'Stem Cell Development', 'Stromal Cells', 'System', 'Systems Development', 'Testing', 'Therapeutic', 'Transplantation', 'base', 'blastomere structure', 'bone', 'clinical application', 'clinical translation', 'design', 'embryonic stem cell', 'genome-wide', 'hematopoietic stem cell expansion', 'hematopoietic stem cell self-renewal', 'in vivo', 'indexing', 'innovation', 'insight', 'loss of function', 'machine learning algorithm', 'notch protein', 'novel', 'novel strategies', 'programs', 'receptor', 'self-renewal', 'single-cell RNA sequencing', 'stem', 'stem cell population', 'transcription factor']",NIDDK,FRED HUTCHINSON CANCER RESEARCH CENTER,RC2,2021,650976
"Genetic neuroscience: How human genes and alleles shape neuronal phenotypes Genetic studies have identified many specific loci with significant associations to psychiatric disorders. However, unless we can develop useful approaches for systematically turning genetic information into neurobiological insights about brain disorders, there is a danger that costly and hard-won genetic findings will not be exploitable to understand pathophysiology and generate important therapeutic hypotheses. The goal of our collaborative, interdisciplinary effort is to develop powerful, generalizable approaches for discovering how risk variants for psychiatric disorders shape neurobiological processes at multiple levels of analysis, and to identify the processes whose dysregulation underlies disease. To do this, we propose to develop new experimental and inferential systems to bridge a longstanding gap between human genetics and experimental biology. We aim to identify biological causes and effects that span the genetic, molecular, and cellular levels of the nervous system. Our interdisciplinary team will develop new experimental systems that measure genetic influences across levels of analysis (RNA, proteins, and cellular function including physiology) in precise, scalable, well- controlled ways. We will make use of emerging cellular systems including three-dimensional cortical spheroids and organoids, and radically novel “population in a dish” experimental systems that collect data on cells from hundreds of donors in a shared environment, inferring donor identity at the time of phenotypic readout. The analysis of such systems in turn requires sophisticated inferential strategies and new ideas from computer science. We propose to develop and widely share experimental and computational resources, including cell lines, methods, datasets, and analytic tools. The successful completion of this work will identify key neurobiological processes for multiple psychiatric disorders, and fortify many other scientists in making such connections in their own work. We hope in so doing to create a new kind of interdisciplinary science that – by combining the strengths of data-driven, unbiased human genetics with the power of emerging experimental systems – transforms the rate at which human- genetic leads lead to insights about disease mechanisms. To better understand common, severe psychiatric illnesses and develop improved treatments for them, we need to understand what specific aspects of brain biology give rise to each disorder. Here a team of scientists with diverse areas of expertise – from neuroscience to computer science to psychiatry to human genetics to stem cell biology – come together to develop a set of next-generation scientific approaches to this important problem, and to generate new methods and data sets that we will widely share. Our team will work to understand how aspects of brain biology at many levels – genes, molecules, and cells – act upon one another to create vulnerability to psychiatric illness.",Genetic neuroscience: How human genes and alleles shape neuronal phenotypes,10223999,U01MH115727,"['3-Dimensional', 'Affect', 'Alleles', 'Architecture', 'Area', 'Awareness', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Brain Diseases', 'California', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Computer Analysis', 'Data', 'Data Science', 'Data Set', 'Disease', 'Engineering', 'Environment', 'Experimental Models', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Investments', 'Ion Channel', 'Lead', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microglia', 'Molecular', 'Molecular Biology', 'Mutation', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Organoids', 'Penetrance', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Process', 'Property', 'Proteins', 'Psychiatry', 'RNA', 'Regenerative Medicine', 'Resources', 'Risk', 'Sampling', 'Science', 'Scientist', 'Shapes', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'analytical tool', 'cell type', 'computer science', 'computing resources', 'cost', 'cytokine', 'excitatory neuron', 'experimental study', 'genetic information', 'human data', 'improved', 'induced pluripotent stem cell', 'inhibitory neuron', 'innovation', 'insight', 'loss of function mutation', 'multidimensional data', 'neurophysiology', 'next generation', 'novel', 'protein expression', 'protein function', 'rare variant', 'response', 'risk variant', 'stem cell biology', 'translational neuroscience', 'whole genome']",NIMH,"BROAD INSTITUTE, INC.",U01,2021,4026586
"Biosynthesis of antifungal nucleoside antibiotics Project Summary/Abstract Peptidyl nucleosides (PNs) are naturally occurring antifungal agents active against multiple pathogenic fungi such as the causal agent of “Valley Fever”. They also exhibit potent synergistic effects with clinically approved antifungal drugs. Our long-term goal is to provide a comprehensive understanding of both the biosynthesis of PNs and their mode of action. The current application focuses on the biosynthesis of PNs. Understanding PN biosynthetic pathways will provide a basis for creating structurally diverse PN analogs through engineered biosynthesis, semi synthesis and genome mining. In the previous funding cycle, we found that PNs are biosynthesized through cryptic phosphorylation and carbohydrate tailoring by oxidative C-C bond cleavage. On the basis of these findings, in this application, we will perform functional and mechanistic characterization of the biosynthetic enzymes to provide the foundation for genome mining discovery of novel nucleoside natural products and chemoenzymatic synthesis of unnatural PNs. In Aim 1, the mechanism of removal of cryptic phosphorylation and the generality of cryptic phosphorylation in other nucleoside biosynthesis pathways will be investigated. In Aim 2, the radical mediated divergent biosynthesis of nucleoside natural products will be investigated by studying the mechanism of oxidative C-C bond cleavage and genome mining characterization of homologous enzymes. In Aim 3, the mechanism of amide ligation by NikS/PolG enzymes will be characterized, and their potentials for use in the chemoenzymatic preparation of PNs will be investigated. The proposed research is significant because it will provide a basis for the future biosynthetic and chemoenzymatic generation of novel therapeutic PNs as well as genome mining discovery of novel antifungal nucleoside natural products. Project Narrative The proposed research is relevant to public health because peptidyl nucleosides exhibit potent in vivo antifungal activities against fungi pathogenic to humans. Understanding their biosynthesis is an important step for their successful development into clinically useful molecules. Therefore, the proposed research will contribute to developing fundamental knowledge that will help to combat fungal infectious diseases.",Biosynthesis of antifungal nucleoside antibiotics,10264167,R01GM115729,"['Acids', 'Amides', 'Anabolism', 'Antibiotics', 'Antifungal Agents', 'Bacteria', 'Carbohydrates', 'Cell Wall', 'Cellular Structures', 'Chemicals', 'Chitin', 'Clinical', 'Communicable Diseases', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Enzymatic Biochemistry', 'Enzymes', 'Excision', 'Exhibits', 'Foundations', 'Funding', 'Fungal Components', 'Future', 'Gene Cluster', 'Gene Combinations', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth', 'Human', 'Immunocompromised Host', 'Knowledge', 'Ligase', 'Ligation', 'Mediating', 'Mining', 'Mycoses', 'Natural Products', 'Nucleosides', 'Oxygenases', 'Pathway interactions', 'Phosphorylation', 'Phosphotransferases', 'Physiological', 'Polysaccharides', 'Preparation', 'Protein Dephosphorylation', 'Public Health', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Specificity', 'Streptomyces', 'Structure', 'Structure-Activity Relationship', 'Substrate Specificity', 'Testing', 'Toxic effect', 'Travel', 'alpha ketoglutarate', 'analog', 'base', 'carbohydrate structure', 'clinical development', 'combat', 'desert fever', 'experimental study', 'fungus', 'guided inquiry', 'in vivo', 'inorganic phosphate', 'nikkomycin', 'novel', 'novel therapeutics', 'nucleoside analog', 'nucleoside triphosphatase', 'pathogenic fungus', 'reconstitution', 'sugar', 'text searching']",NIGMS,DUKE UNIVERSITY,R01,2021,328626
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,10086862,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2021,171720
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychoses', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835
"Increasing NF1 Expression as a Treatment for NF1 Haploinsufficiency Project Abstract Haploinsufficiency plays a crucial role in Neurofibromatosis (NF1), an autosomal dominant genetic disorder impacting over 120,000 individuals in the United States. Current therapeutic approaches focus on specific components of NF1 signaling, for example inhibiting MEK signaling pathways in tumors, thus failing to address the broad range of signaling and symptoms associated with NF1. Given that NF1 is characterized by both autosomal dominance and haploinsufficiency (lack of normal protein), upregulating protein expression of the remaining wild-type NF1 allele has the ability to compensate for loss of function from the mutant allele, thus alleviating a broad range of NF1 symptoms and overall disease progression. Infixion proposes to build a luciferase reporting assay to evaluate NF1 expression against known drugs, including 50+ compounds, across six drug classes, already identified by Infixion to correlate with increased NF1 expression. By confirming that these candidate drugs activate NF1 transcription, increase NF1 protein expression, and normalize Ras pathway signaling in NF1 +/- Schwann cells, and by further screening libraries of known drugs for increased NF1 expression, we propose a novel path of NF1 drug discovery that will impact a broad range of NF1 patients and symptoms, in a preventative manner, and without regard to the wide spectrum of NF1 genetic mutations. Research Background. Increasing NF1 expression via transfection reverses abnormal Ras activation resulting from NF1 loss (Wallis, et al. 2018). Transcriptional activation in other genetic conditions such as Willams-Beuren Syndrome, and Supravalvular Aortic Stenosis compensates for haploinsufficiency (Giordano, et al. 2012). Lastly, overcoming haploinsufficiency in another autosomal dominant condition (Sim1 induced obesity; mouse model) was recently shown using a Crispr/dCas9 transcriptional activator (Ahituv, et al. 2019). Specific Aims. 1) Construct a luciferase reporter assay engineered into the endogenous NF1 gene of a well characterized, publically available, immortalized NF1 +/- Schwann cell line (Wallace et al. 2016; data published at Synapse.org). Validate assay using a viral transcription factor developed by Infixion using Crispr/dCas9 to upregulate NF1. 2) Deploy this NF1 luciferase reporter assay to screen 50+ known drugs shown by Infixion to correlate with increased NF1 expression across various cell/tissue types. Next, use this validated luciferase reporter to screen a 13,000+ compound repurposing library of known drugs available from Scripps Research Institute (known as ReFrame). 3) The top hits from Aim 2 screens will be evaluated, utilizing both immortalized and iPSC derived NF1+/- Schwann cells, for the following: a) ability to induce NF1 mRNA and protein expression, using qPCR and Westerns, b) the impact on Ras signaling (pERK, ELK-1, AKT, etc.) utilizing a targeted quantitative mass spec proteomics assay, c) their broader impact on gene expression in Schwann cells utilizing RNAseq, d) impact on cell proliferation, and e) their safety profile based on published data from previous trials. The goal is to prioritize not more than 3-5 candidates to take forward into a Phase 2 evaluation. Project Narrative Neurofibromatosis Type 1 (NF1) is an autosomal dominant genetic disorder that impacts an estimated 1 in 3000 people worldwide, and one that is characterized by a complex set of symptoms shown to be dependent on haploinsufficiency (i.e., the lack of normal protein). By upregulating NF1 protein expression from the normal allele by two-fold, and thus restoring normal levels of functional NF1 protein in tissues important in NF1, we target a range of NF1 symptoms by eliminating the haploinsufficient environment. We propose to develop and utilize NF1-specific luciferase reporter and proteomic assays, along with standard small molecule evaluation tools, to characterize a small molecule library of repurposed drugs for their ability to upregulate NF1 transcription, and to further evaluate the resulting impact of “hits” on NF1 protein expression, cell proliferation, gene expression specificity, as well as downstream pathways (such as Ras, MEK, mTOR) known to be dysregulated by mutations in the NF1 gene.",Increasing NF1 Expression as a Treatment for NF1 Haploinsufficiency,10145101,R43NS117234,"['Address', 'Alleles', 'Animals', 'Biological Assay', 'Cell Line', 'Cell Proliferation', 'Cells', 'Clinical', 'Complex', 'Cutaneous', 'DNA Sequence', 'DNA Sequence Alteration', 'Data', 'Databases', 'Development', 'Disease Progression', 'Dominant Genetic Conditions', 'Drug Screening', 'ELK1 gene', 'Engineering', 'Environment', 'Evaluation', 'FRAP1 gene', 'Gene Expression', 'Genetic Diseases', 'Genetic Transcription', 'Genomics', 'Genotype', 'Goals', 'Heterozygote', 'Human', 'In Vitro', 'Individual', 'Institutes', 'Libraries', 'Link', 'Luciferases', 'MEKs', 'Machine Learning', 'Messenger RNA', 'Modification', 'Mutate', 'Mutation', 'NF1 gene', 'Neurofibromatoses', 'Neurofibromatosis 1', 'Obese Mice', 'Orphan Drugs', 'Other Genetics', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Preventive treatment', 'Proteins', 'Proteomics', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'Rare Diseases', 'Reagent', 'Regimen', 'Reporter', 'Reporting', 'Research', 'Research Institute', 'Risk', 'Role', 'Safety', 'Schwann Cells', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Structure of thyroid parafollicular cell', 'Supravalvular aortic stenosis', 'Symptoms', 'Synapses', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Transcend', 'Transcription Coactivator', 'Transcriptional Activation', 'Transfection', 'United States', 'Up-Regulation', 'Validation', 'Viral', 'Williams Syndrome', 'associated symptom', 'base', 'brain pathway', 'commercialization', 'design', 'drug candidate', 'drug discovery', 'drug repurposing', 'gene expression database', 'gene therapy', 'genomic variation', 'high throughput screening', 'in vivo Model', 'induced pluripotent stem cell', 'innovation', 'loss of function', 'mRNA Expression', 'mouse model', 'mutant', 'neurofibroma', 'novel', 'phase 2 testing', 'programs', 'protein expression', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool', 'transcription factor', 'transcriptome sequencing', 'tumor', 'tumor progression']",NINDS,"INFIXION BIOSCIENCE, INC.",R43,2021,150794
"Prediction of risk of disability worsening and inflammatory disease activity in MS utilizing multimodal prediction algorithms Project Summary:  Multiple sclerosis (MS) exhibits a markedly heterogeneous and unpredictable course, with a clinical spectrum ranging from very mild forms of the disease in some patients (often termed “benign MS”) to an aggressive disease course with rapid accumulation of disability in others. Furthermore, there appears to be significant inter-individual variability in the responses to the many available disease-modifying therapies (DMT). A variety of factors have been proposed to be associated with the disease course in MS, including demographics, lifestyle factors, clinical characteristics, MRI-derived measures, and elevated serum neurofilament light chain (NfL), among others. It remains unclear though if these factors are complementary or redundant in their predictive value. Moreover, there is a lack of validated tools to accurately predict, at an individual level, future inflammatory disease activity or disability worsening. This is largely due to the lack of datasets with sufficient size, breadth and representativeness. The use of electronic medical records (EMR) has dramatically increased in recent years, enabling the capture of a wide variety of data measures from large numbers of individuals. Furthermore, the development and refinement of statistical machine learning methods has revolutionized the approach to analysis of such high-dimensional datasets. This background provides a unique opportunity to leverage and analyze “big data” in order to develop clinical risk prediction algorithms and personalized medicine tools in MS.  Multiple Sclerosis Partners Advancing Technology and Health Solutions (MS PATHS) is a network of 10 MS centers that have standardized elements of their clinical practice to implement a centralized health information exchange architecture. MS PATHS was designed around the concept of a learning health system (LHS), merging research with ongoing patient care by collecting standardized clinical and imaging data during routine medical visits. As of August, 2019, >15,000 patients have opted to participate in MS PATHS. Thus, the MS PATHS network is an ideal, deeply phenotyped, “real-world”, large population of people with MS, in which clinically relevant predictive algorithms may be developed and validated.  The goal of the current project is to develop and validate multi-modal predictive algorithms of clinically relevant disease outcomes in MS. We hypothesize that integrating a wide variety of potential predictors, including demographics, clinical characteristics (including current/historical DMT use), comorbidities/lifestyle factors, MRI- derived measures and laboratory data (including serum NfL) will lead to the development and validation of algorithms that may accurately predict future clinical disability worsening and inflammatory disease activity. Furthermore, this approach will allow the assessment of the individual contribution of specific predictors to the developed predictive algorithms, and may aid with the identification of novel risk factors of disease severity in MS. Project Narrative Successful completion of this project will lead to the development and dissemination of clinically relevant predictive algorithms to enable personalized risk assessment and therapeutic decision-making in MS, provide the means to optimize selection/stratification of participants in clinical trials, and will also provide insight regarding the interactions and relative importance of putative prognostic factors in MS.",Prediction of risk of disability worsening and inflammatory disease activity in MS utilizing multimodal prediction algorithms,10224357,K23NS117883,"['Algorithms', 'Architecture', 'Award', 'Benign', 'Big Data', 'Biological Markers', 'Biostatistical Methods', 'Blood specimen', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Computerized Medical Record', 'Counseling', 'Data', 'Data Set', 'Decision Making', 'Demographic Factors', 'Development', 'Devices', 'Digit structure', 'Disease', 'Disease Outcome', 'Elements', 'Enhancing Lesion', 'Enrollment', 'Exhibits', 'Future', 'Goals', 'Hand', 'Health', 'Health system', 'Image', 'Individual', 'Inflammatory', 'Laboratories', 'Learning', 'Lesion', 'Light', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medical', 'Modality', 'Modeling', 'Monitor', 'Multiple Sclerosis', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predictive Value', 'Prognostic Factor', 'Recording of previous events', 'Relapse', 'Reporting', 'Research', 'Research Personnel', 'Risk Assessment', 'Risk Factors', 'Serum', 'Severity of illness', 'Standardization', 'Stratification', 'Structure', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Universities', 'Validation', 'Visit', 'Walking', 'base', 'biobank', 'career', 'clinical practice', 'clinical predictors', 'clinical risk', 'clinically relevant', 'comorbidity', 'demographics', 'design', 'dexterity', 'disability', 'disability risk', 'follow-up', 'foot', 'gray matter', 'high dimensionality', 'insight', 'inter-individual variation', 'lifestyle factors', 'machine learning method', 'multimodality', 'neurofilament', 'neuroimaging', 'novel', 'novel diagnostics', 'performance tests', 'personalized medicine', 'prediction algorithm', 'processing speed', 'prognostic', 'response', 'risk prediction', 'statistical and machine learning', 'tool', 'walking speed']",NINDS,JOHNS HOPKINS UNIVERSITY,K23,2021,170094
"Interplay of inherent promiscuity and specificity in protein biochemical function with applications to drug discovery and exome analysis PROJECT SUMMARY Although the past two decades witnessed the large-scale analyses of cellular components, e.g. exomes, their impact on drug discovery and precision medicine has been modest. For example, 6/7 drug candidates failed safety and 3/4 failed efficacy in recent FDA clinical trials. These unsolved, but related issues, safety and efficacy, reflect significant gaps in understanding of the triangular interrelationship between diseases, molecular function, and drug treatments. A key conceptual limitation of contemporary drug discovery is the often implicitly assumed single drug for a single protein target disease model. In reality, most diseases are caused by multiple malfunctioning molecules. Whether it be disease treatment or precision medicine diagnostics, there is often an inability to identify disease-associated mode of action (MOA) proteins. To begin to address these issues, in the current MIRA proposal, we developed a promising protein structure and network-based Artificial Intelligence (AI) approach, MEDICASCY, to predict disease-associated MOA proteins, drug indications, side effects and efficacy; however, much more needs to be done. Here, we propose to build on our successes and develop an integrated AI-based approach, MEDICASCY-X, that addresses the following: The first step in determining a drug’s MOA and off-target interactions is to identity its protein targets. This requires the structures of all human proteins and their complexes. While we predicted suitable models for at least one domain in 97% of human proteins, using deep learning, we will predict the structures of the missing domains, domain-domain orientations and protein- protein complexes. We will extend small molecule virtual ligand screening (VLS) to predict binding affinities based on the insight that interacting ring-protein subpocket geometries and chemistry are conserved across protein families, are often privileged chemical structures and are likely low free energy complexes. Cryptic protein pockets, recently recognized as important drug targets, will be predicted and included in our VLS approach. Antibody-based immunotherapies are powerful but have similar safety and efficacy issues as small-molecules; thus, their safety and efficacy will be predicted by MEDICASCY-X. While MEDICASCY works on an “averaged human”, MEDICASCY-X will consider individual genetic and epigenetic profiles to make it a true precision medicine tool. We will predict which MOA proteins should be targeted and if a protein’s MOA is due to a loss or gain of function. The same framework will predict synergistic drug-drug interactions. Another way to prioritize MOA proteins is by disease comorbidity: proteins occurring in multiple diseases are likely important. If disease comorbidity can be predicted, we will construct the “Phylogenetic” Tree(s) of Diseases that would facilitate a deeper understanding of disease interrelationships. As proof of principle of the effectiveness of the algorithms being developed, novel preclinical treatments for a variety of intractable diseases will be developed. Thus, this project could enhance the success rates of drug discovery and precision medicine while reducing time and cost. PROJECT NARRATIVE Despite the explosion of biological knowledge that has occurred since the turn of the century, the impact on drug discovery and precision medicine has been modest. To address the key issues limiting this success, this project will develop an AI-driven, integrated protein structure and interaction network-based approach, MEDICASCY-X, that will predict disease associated proteins, identify the most effective protein targets to treat the disease and suggest effective, de-risked therapeutic strategies. MEDICASCY-X will be applied to improve drug discovery and precision medicine and will be validated by developing novel preclinical treatments for a variety of intractable diseases.",Interplay of inherent promiscuity and specificity in protein biochemical function with applications to drug discovery and exome analysis,10149528,R35GM118039,"['Address', 'Affinity', 'Algorithms', 'Antibodies', 'Artificial Intelligence', 'Binding', 'Biochemical', 'Biological', 'Chemical Structure', 'Chemistry', 'Clinical Trials', 'Complex', 'Diagnostic', 'Disease', 'Disease model', 'Drug Interactions', 'Drug Targeting', 'Effectiveness', 'Epigenetic Process', 'Explosion', 'Free Energy', 'Genetic', 'Geometry', 'Human', 'Immunotherapy', 'Individual', 'Knowledge', 'Ligands', 'Modeling', 'Molecular', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phylogenetic Analysis', 'Protein Family', 'Proteins', 'Risk', 'Safety', 'Specificity', 'Structure', 'Therapeutic', 'Time', 'Trees', 'Work', 'base', 'comorbidity', 'cost', 'cryptic protein', 'deep learning', 'drug candidate', 'drug discovery', 'exome', 'gain of function', 'improved', 'insight', 'novel', 'pre-clinical', 'precision medicine', 'protein complex', 'protein structure', 'screening', 'side effect', 'small molecule', 'success', 'tool', 'virtual']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R35,2021,490958
"Multi-tissue high-throughput proteomic and genomic study in Parkinson's Disease Project Summary/Abstract Parkinson's disease (PD) is the most common neurodegenerative movement disorder, affecting more than 6 million people worldwide, with the prevalence projected to double in the next few decades. Despite the improvements in high-throughput genomics and proteomics that have significantly facilitated the advancement of biomarker discovery in other neurodegenerative diseases, there are no reliable biomarkers for PD. Currently, the PD diagnosis relies almost entirely on clinical examination. There are several reasons for the lack of reliable biomarkers in PD including most studies have been focused on single molecules in one tissue, small samples sizes and a lack of independent replication cohorts. To overcome these limitations, we propose leveraging a unique resource that includes quantitative proteomic analysis of ~1,300 proteins from CSF and plasma of clinically diagnosed PD patients coupled with validation in brain samples from autopsy-confirmed PD cases. We will pair the proteomic data with novel and powerful unbiased (hypothesis-free) genomic approaches to select the most plausible candidates for targeted replication studies. This large-scale screening of ~3,110 samples could identify biomarkers of known molecular pathways involving PD or with a clear genetic connection to PD risk. To achieve these goals, we propose three aims: Specific Aim 1: To identify proteins differentially expressed in PD patients in plasma, CSF or brain tissue. We plan to carry out a quantitative proteomic analysis using Somalogic SOMAscan® assay of plasma (n=600) and CSF (n=200) from clinically diagnosed PD patients and of brain tissue (n=200) from autopsy-confirmed PD patients. We will also evaluate CSF (n=740), plasma (n=410) and brain tissue (n=114) from an independent cohort of healthy individuals and CSF (n=275), plasma (n=234) and brain tissue (n=345) from AD patients. We expect to obtain precise and accurate levels of a large number of proteins across multiple tissues in the analyzed samples. Specific Aim 2: To prioritize candidate biomarkers based on an integrative analysis of proteomic and genome-wide genotyping data using Mendelian Randomization (MR). We plan to integrate proteomic and GWAS data to identify protein quantitative loci (pQTLs) and apply MR approaches to determine proteins involved in the causal pathway of PD. Using this approach, we will be able to select reliable PD biomarker candidates for validation. Specific Aim 3: To determine whether genetic and proteomic data improves biomarker specificity. We will ascertain whether combining proteomic and genomic data could increase biomarker accuracy. We expect to uncover a genome-proteome network that may provide a basis for novel approaches to diagnostic and pharmacotherapeutic applications in PD. Narrative Parkinson's disease (PD) is the second most common neurodegenerative disorders in humans. Currently, there are no reliable, sensitive and specific biomarkers identified in PD to date. We expect to uncover a genome- proteome network that may provide a basis for novel approaches to pharmaceutical and diagnostic applications in PD.",Multi-tissue high-throughput proteomic and genomic study in Parkinson's Disease,10266770,R01NS118146,"['Affect', 'Age', 'Alzheimer&apos', 's disease patient', 'Amyloid beta-Protein', 'Atlases', 'Autophagocytosis', 'Autopsy', 'Basic Science', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biology', 'Brain', 'CISH gene', 'CTSB gene', 'Cerebrospinal Fluid', 'Cerebrospinal Fluid Proteins', 'Clinical', 'Coupled', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Freezing', 'Galactose Binding Lectin', 'Genes', 'Genetic', 'Genome', 'Genomic approach', 'Genomics', 'Genotype', 'Goals', 'Human', 'Individual', 'LRRK2 gene', 'Lead', 'Link', 'Logistic Regressions', 'Lysosomes', 'Machine Learning', 'Measures', 'Mendelian randomization', 'Metabolic', 'Mitochondria', 'Molecular', 'Movement Disorders', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Oxidative Stress', 'Parkinson Disease', 'Parkinson&apos', 's Disease Pathway', 'Participant', 'Pathway interactions', 'Patients', 'Pharmacologic Substance', 'Plasma', 'Prevalence', 'Prevention', 'Process', 'Protein Isoforms', 'Proteins', 'Proteome', 'Proteomics', 'Reproducibility', 'Research', 'Resources', 'Saints', 'Sample Size', 'Sampling', 'Signal Transduction', 'Source', 'Specificity', 'Synapses', 'Technology', 'Therapeutic', 'Therapeutic Intervention', 'Tissues', 'Translational Research', 'UCHL1 gene', 'Universities', 'Validation', 'Variant', 'Washington', 'alpha synuclein', 'base', 'biobank', 'biomarker discovery', 'brain tissue', 'candidate marker', 'candidate validation', 'clinical Diagnosis', 'clinical examination', 'cohort', 'cost effective', 'differential expression', 'disease diagnosis', 'disorder risk', 'drug discovery', 'genetic analysis', 'genetic association', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'innovation', 'molecular marker', 'molecular phenotype', 'neuroinflammation', 'novel', 'novel marker', 'novel strategies', 'polygenic risk score', 'potential biomarker', 'protein expression', 'proteogenomics', 'screening', 'single molecule', 'specific biomarkers', 'statistics', 'targeted treatment', 'tau Proteins', 'tau-1', 'therapeutic target', 'tool', 'vascular injury']",NINDS,WASHINGTON UNIVERSITY,R01,2021,614921
"Improving Outcomes Assessment in Chronic Graft versus Host Disease PROJECT SUMMARY Allogeneic hematopoietic cell transplantation (HCT) can cure many hematologic cancers and other life- threatening hematologic diseases but 20-50% of survivors develop chronic graft-versus-host disease (cGVHD), the leading cause of morbidity and mortality in transplant survivors. Chronic GVHD is an iatrogenic complication that can affect multiple organs, leading to clinical manifestations similar to autoimmune diseases such as systemic sclerosis, systemic lupus erythematosus, Sjogren’s syndrome, and lichen planus. Chronic GVHD requires prolonged treatment with potent immunosuppressive agents and is associated with high symptom burden and poor quality of life. The precise pathophysiology is unclear in humans. There are data supporting involvement of T and B cells, macrophages, dendritic cells, fibroblasts, endothelial cells, cytokines, chemokines and other proteins. However, information is derived from studies with few patients having heterogeneous clinical manifestations. This renewal application will address key gaps in our understanding: Can we identify biologically relevant cGVHD subgroups by studying large numbers of patients and using sophisticated analytic techniques to identify “clusters” of similar patients? Is personalized medicine possible based on knowledge of underlying pathophysiology and the likelihood of response? To address these questions, we will use our extensive biorepository to test whether plasma proteins and peripheral blood cellular populations cluster with clinical manifestations. While these studies are ongoing, a new cohort will be enrolled to prospectively test the cluster findings and to investigate early biomarkers for treatment response. Participants will be enrolled prior to starting a new systemic initial or second-line cGVHD treatment, then followed at 1, 3 and 6 months later to assess clinical response. Successful completion of these aims will advance our understanding of the biologic underpinnings of the different forms of human cGVHD and guide therapeutic approaches, in order to decrease the morbidity and mortality of this common transplant complication. PROJECT NARRATIVE Chronic graft-versus-host disease (cGVHD) is the leading cause of morbidity and non-relapse mortality in survivors of allogeneic transplantation. Our understanding of the biologic abnormalities associated with different clinical phenotypes is lacking, preventing our ability to rationally choose cGVHD treatments. The proposed studies will bring together clinical, laboratory and statistical collaborators to address these knowledge gaps.",Improving Outcomes Assessment in Chronic Graft versus Host Disease,10146301,R01CA118953,"['Address', 'Adrenal Cortex Hormones', 'Affect', 'Allogenic', 'Autoimmune Diseases', 'B-Lymphocytes', 'Biological', 'Cells', 'Characteristics', 'Clinical', 'Clinical Data', 'Collaborations', 'Complication', 'Consensus', 'Cryopreservation', 'Data', 'Data Scientist', 'Dendritic Cells', 'Disease Management', 'Endothelial Cells', 'Enrollment', 'Fibroblasts', 'Flow Cytometry', 'Functional disorder', 'Funding', 'Goals', 'Hematologic Neoplasms', 'Hematological Disease', 'Homologous Transplantation', 'Human', 'Iatrogenesis', 'Immunosuppression', 'Immunosuppressive Agents', 'Knowledge', 'Laboratories', 'Laboratory Markers', 'Lichen Planus', 'Life', 'Logistic Regressions', 'Machine Learning', 'Morbidity - disease rate', 'Observational Study', 'Organ', 'Outcome', 'Outcome Assessment', 'Participant', 'Pathway interactions', 'Patients', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Plasma Proteins', 'Population', 'Prediction of Response to Therapy', 'Proteins', 'Quality of life', 'Refractory Disease', 'Reporting', 'Sampling', 'Sjogren&apos', 's Syndrome', 'Steroids', 'Survivors', 'Symptoms', 'Syndrome', 'Systemic Lupus Erythematosus', 'Systemic Scleroderma', 'Systemic disease', 'T-Lymphocyte', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Studies', 'Time', 'Transplantation', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'biobank', 'chemokine', 'chronic graft versus host disease', 'clinical phenotype', 'clinically relevant', 'cohort', 'cytokine', 'disorder subtype', 'early detection biomarkers', 'financial toxicity', 'hematopoietic cell transplantation', 'improved outcome', 'individual patient', 'macrophage', 'mortality', 'novel', 'patient subsets', 'peripheral blood', 'personalized medicine', 'phenotypic data', 'predicting response', 'prevent', 'prospective', 'prospective test', 'response', 'response biomarker', 'side effect', 'statistical and machine learning', 'statistical learning', 'success', 'survival prediction', 'therapeutic target', 'translational scientist', 'transplant survivor', 'treatment duration', 'treatment response', 'unsupervised learning']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,202856
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10183329,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2021,797476
"Biomarker Signatures for Delayed Cerebral Ischemia and Outcome Following Subarachnoid Hemorrhage Abstract Subarachnoid hemorrhage (SAH) accounts for 5% of all strokes, has a high mortality and the cost to society is similar to ischemic stroke since subjects are much younger. Though SAH fatality has decreased ~50% in the last 25 years due to immediate repair of aneurysms, improved medical management and nimodipine, nearly 1/3 of SAH patients develop delayed cerebral ischemia (DCI) often with cerebral infarction which is associated with poor outcomes. Though this was thought to be due delayed cerebral vasospasm, recent studies have shown that decreasing or preventing vasospasm does not improve outcomes. This has led to alternative hypotheses that combined effects of microvessel thrombosis and vasospasm combined with cortical spreading ischemia and peripheral and central inflammation may cause DCI. Thus, there is a great unmet need to assess potential treatment targets that contribute to DCI following SAH in humans and that could be used to predict DCI to begin early treatment and to predict outcome to better allocate resources. The premise of the proposal is based upon the findings that we have shown that gene expression in blood can predict SAH patients who develop vasospasm. This led us to Hypothesize that clotting and inflammatory molecules in blood interact with the brain microvasculature and other factors to cause Delayed Cerebral Ischemia (DCI) and delayed cerebral infarction following SAH which lead to poor outcomes. We propose that gene profiles in blood will predict DCI and predict outcomes using the modified Rankin Scale (mRS).  R61 Phase. Specific Aim #1a: Perform RNA sequencing (RNAseq) on whole blood of a training cohort of patients 1, 2 and 3 days after a SAH but prior to DCI compared to matched vascular risk factor controls. Specific Aim #1b. Identify the most significantly regulated genes and pathways in blood at 1, 2 or 3d that distinguish SAH patients who develop DCI at 4-14 days from SAH patients who do not develop DCI. Specific Aim #1c: Use WGCNA to identify key hub genes and upstream genes expressed at 1, 2 or 3d after SAH and which are associated with developing DCI at 4-14d and might be causative. Specific Aim #1d. Use Support Vector Machine (SVM) learning to identify the least number of genes at 1, 2 or 3d from Aim #1b that best predict (1) SAH patients who develop DCI at 4-14 days (2) and predict mRS of 0, 1-3, 4-5, and 6 at 3 months. Specific Aim #1e. Confirm RNAseq with qRT-PCR and assess qRT-PCR accuracy and precision. R33 Phase. Specific Aim #2. In a separate validation cohort of SAH patients perform qRT-PCR on their peripheral blood to measure expression of genes derived in Aim #1 to predict using Support Vector Machine (SVM) on day 1, 2 and/or day 3 which patients will develop DCI at 4-14 days and which patients will have mRS=0 (no deficit), 1-2, 3-5 and mRS=6 (dead) at 3 months.  Contexts of Use. The molecules/pathways that predict DCI and mRS could serve as future treatment or prevention targets of DCI. Predicting who will develop DCI would make it possible to treat DCI earlier. In addition, future clinical trials to prevent DCI following SAH would enroll just those patients predicted to develop DCI after SAH. Predicting mRS outcomes could be used to stratify patients in future DCI trials. Narrative  This proposal will perform RNAseq on blood of a derivation cohort of subarachnoid hemorrhage (SAH) patients to determine those genes that best predict Delayed Cerebral Ischemia (DCI) between 4 and 14 days and that predict median Rankin Scores (mRS) outcomes at 90 days using cross-correlation. These genes are then measured in an independent validation cohort of SAH patients to predict who develops DCI by 14d, and to predict their mRS at 90 days after SAH. The studies will direct early treatment for DCI, identify treatment targets for DCI, and help stratify patients for future DCI treatment trials.",Biomarker Signatures for Delayed Cerebral Ischemia and Outcome Following Subarachnoid Hemorrhage,10105072,R61NS119345,"['3-Dimensional', 'Affect', 'Age', 'Aneurysm', 'Aneurysmal Subarachnoid Hemorrhages', 'Angiography', 'Arteries', 'Blood', 'Blood - brain barrier anatomy', 'Catheters', 'Cerebral Infarction', 'Cerebral Ischemia', 'Cerebral hemisphere hemorrhage', 'Cerebrovascular Spasm', 'Cerebrum', 'Clinical', 'Clinical Trials', 'Coagulation Process', 'Cognitive', 'Complication', 'Derivation procedure', 'Diagnosis', 'Early treatment', 'Endothelin Receptor Antagonist', 'Enrollment', 'FDA approved', 'Future', 'Gene Expression', 'Genes', 'Hemorrhage', 'Human', 'Image', 'Inflammation', 'Inflammatory', 'Ischemia', 'Ischemic Stroke', 'Lead', 'Machine Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Modeling', 'Morbidity - disease rate', 'Myocardial dysfunction', 'Neurologic', 'Nimodipine', 'Outcome', 'Pathway interactions', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Placebos', 'Prevention', 'Pulmonary Edema', 'Quantitative Reverse Transcriptase PCR', 'Randomized Clinical Trials', 'Resources', 'Sensitivity and Specificity', 'Societies', 'Stroke', 'Subarachnoid Hemorrhage', 'Survivors', 'Systemic Inflammatory Response Syndrome', 'Thrombosis', 'Training', 'Validation', 'Vasospasm', 'Whole Blood', 'Work', 'base', 'biomarker signature', 'care costs', 'cerebral microvasculature', 'cohort', 'cost', 'improved', 'improved outcome', 'mortality', 'outcome prediction', 'patient stratification', 'peripheral blood', 'prevent', 'repaired', 'spreading depression', 'stroke patient', 'support vector machine', 'transcriptome', 'transcriptome sequencing', 'treatment trial', 'vascular risk factor', 'whole genome']",NINDS,UNIVERSITY OF CALIFORNIA AT DAVIS,R61,2021,681385
"Advancing personalized medicine in PD using harmonized multi-site clinical data Project Summary Among neurological disorders, the fastest growing is now Parkinson's disease (PD), surpassing Alzheimer's dis- ease. PD manifests as a heterogeneous clinical syndrome and this variability in the clinical phenotype highlights the need to tailor the type and/or the dosage of treatment to the speciﬁc and changing needs of individuals living with PD. The main goal of individualized, or precision, medicine is to use patient characteristics to determine an individualized treatment strategy (ITS) to promote wellness. Due to the complex nature of PD coupled with phenotypic heterogeneity, formulating successful individualized approaches to medical care is a complex prob- lem that may beneﬁt from a more data-driven approach. One of the challenges in developing reliable ITSs is that the analyses require studies with fairly large sample sizes and longitudinal assessment of subjects over a relatively long period of time. The data set must also include various prescribing patterns to allow the analytic method to learn the effects of different treatment sequences (strategies). These important requirements preclude investigators from using data from a single clinical study to construct data-driven ITSs. Existing guidelines for symptomatic drug therapy for PD can best be described as ""permissive"". The relative lack of comparative evidence for different classes of drugs has created challenges in devising recommendations to follow any speciﬁc therapeutic strategy. We ﬁll this important gap by proposing a two phase study. The ﬁrst phase (R61) focuses on creating a harmonized and curated dataset by integrating data from six clinical trials and the PPMI observational study that, in aggregate, involved 4,705 patients followed from 23.5 to 96 months. To the best of our knowledge, such comprehensive data harmonization has not been done before in PD and it can provide an excellent source of information for future studies as well. In the second phase (R33), we will leverage the harmonized data set to develop high quality ITSs for PD with respect to several clinical outcomes including UPDRS score, quality of life, and Schwab and England (SE) ADL measured at 24 and 48 months of follow-up. Speciﬁcally, the goals of the R33 phase are to (Aim 1) compare commonly used sequences of drug classes for PD; (Aim 2) identify the best individualized treatment strategies to inform optimal sequences of drug classes for PD. In pursuit of these aims, we will propose robust, rigorous and computationally efﬁcient statistical machine learning methods for constructing data-driven optimal ITSs for PD. The proposal expands the scope of existing methods in developing ITSs by relaxing certain unrealistic assumptions and through the use of ﬂexible modeling techniques (e.g., machine learning methods) while maintaining valid statistical inference. These new methods will be integrated into easy-to-use, publicly available software in the R language (Aim 3). This will maximize the adoption of the proposed methodology by other investigators and allow researchers to analyze other PD datasets with a goal of constructing an ITS for PD. Furthermore, because the methods are not disease-speciﬁc, our methods and software will enable similar exploration for other diseases. Project Narrative Constructing reliable individualized treatment strategies requires studies with fairly large sample sizes with longi- tudinal assessment of subjects over a relatively long period of time. To this end, we will create a harmonized and curated dataset by integrating data from seven long-term observational and randomized studies in Parkinson's disease. Using this harmonized data, we will develop and apply robust, rigorous and computationally efﬁcient methods for estimating an optimal individualized treatment strategy for Parkinson's disease with respect to var- ious outcomes (e.g., Uniﬁed Parkinson's Disease Rating Scale, quality of life, and Schwab and England ADL score). We will also leverage statistical machine learning approaches to improve the quality of the constructed optimal individualized treatment strategy while providing valid statistical inference.",Advancing personalized medicine in PD using harmonized multi-site clinical data,10266825,R61NS120240,"['Adoption', 'Alzheimer&apos', 's Disease', 'Behavior', 'Benefits and Risks', 'Caring', 'Characteristics', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Decision Trees', 'Disease', 'England', 'Future', 'Goals', 'Guidelines', 'Health', 'Heterogeneity', 'Individual', 'Journals', 'Language', 'Lead', 'Learning', 'Longterm Follow-up', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Movement Disorder Society Unified Parkinson&apos', 's Disease Rating Scale', 'Nature', 'Observational Study', 'Outcome', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Quality of life', 'Randomized', 'Recommendation', 'Recording of previous events', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Software Tools', 'Source', 'Syndrome', 'Target Populations', 'Techniques', 'Therapeutic', 'Time', 'analytical method', 'base', 'care providers', 'clinical care', 'clinical decision-making', 'clinical phenotype', 'clinical research site', 'comparative', 'comparative effectiveness study', 'data harmonization', 'data management', 'demographics', 'dosage', 'flexibility', 'follow-up', 'improved', 'individualized medicine', 'longitudinal dataset', 'machine learning method', 'nervous system disorder', 'open source', 'overtreatment', 'patient response', 'personalized approach', 'personalized medicine', 'precision medicine', 'progression marker', 'repository', 'response', 'software development', 'statistical and machine learning', 'tool', 'treatment planning', 'treatment response', 'treatment strategy']",NINDS,UNIVERSITY OF ROCHESTER,R61,2021,631099
"Combining Voice and Genetic Information to Detect Heterogeneity in Major Depressive Disorder PROJECT SUMMARY This application aims to advance our understanding of major depressive disorder (MDD) by combining genetic information and analyzing speech patterns of those with MDD to identify subtypes. MDD is the leading cause of disability throughout the world, yet, relative to other common disorders, less is known about its origins. There are less effective treatments and much less is spent on trying to understand how it arises and how to cure it. Current treatments are relatively ineffective, with up 50% of patients refractory and many suffering severe recurrence. Understanding the mechanisms underlying MDD has been recognized as a grand challenge in global mental health. Thus, developing new treatments for MDD is a major priority for public health. A major challenge for MDD research is the presence of heterogeneity. The existence of multiple subtypes of MDD has been suspected for a long time, and likely confounds the ability to treat the disorder appropriately with existing treatments, as well as making it hard to identify the causes of MDD as a prelude to developing new treatments. However finding subtypes has been hard. Given that the way people talk can reflect alterations in mood, we expect voice to be able to predict mood, and hence potentially be used as biomarker to recognize heterogeneity. In preliminary data show that in combination with genetic data high-dimensional vocal features extracted from recordings can be used to identify subtypes. Furthermore, the use of genetic data allows us to impute voice features into large biobanks where no recordings exist, making it possible to explore the relationship between vocal features and a rich array of clinically important indicators. We explore the power of voice to make a diagnosis of MDD, to predict severity and other clinical features. Applying our approach to will inform clinical management, improving diagnosis, refine treatment and aid the development of new treatments PROJECT NARRATIVE The research proposed here will contribute to an understanding of major depressive disorder, the commonest psychiatric disorder and a leading cause of disability throughout the world. The proposal will combine information from voice recordings and genetics to identify subtypes of depression and develop robust predictors of mood, severity of illness and other clinical indicators. Our research will thereby provide new insights into disease, and well enable the more effective targeting of therapy to those who will most benefit at the appropriate time.",Combining Voice and Genetic Information to Detect Heterogeneity in Major Depressive Disorder,10238767,R01MH122569,"['Affect', 'Alleles', 'Anxiety', 'Behavioral Genetics', 'Biological Markers', 'Biology', 'Case-Control Studies', 'China', 'Chinese People', 'Classification', 'Clinical', 'Clinical Management', 'Collection', 'Data', 'Data Set', 'Depressed mood', 'Development', 'Diagnosis', 'Disease', 'Disease remission', 'Drug Prescriptions', 'Engineering', 'Ensure', 'Far East', 'Frequencies', 'Genetic', 'Genetic study', 'Genomics', 'Genotype', 'Heritability', 'Heterogeneity', 'Interview', 'Investigation', 'Linkage Disequilibrium', 'Major Depressive Disorder', 'Manuals', 'Maps', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'Morphologic artifacts', 'Neurobiology', 'Participant', 'Patients', 'Pattern', 'Pharmacological Treatment', 'Phenotype', 'Population', 'Psychiatry', 'Psychological Transfer', 'Recurrence', 'Refractory', 'Research', 'Resources', 'Sampling', 'Scheme', 'Severities', 'Severity of illness', 'Signal Transduction', 'Specificity', 'Speech', 'Suicide', 'System', 'Testing', 'Time', 'Ursidae Family', 'Voice', 'Voice Quality', 'Woman', 'accurate diagnosis', 'base', 'biobank', 'clinical application', 'clinical phenotype', 'comorbidity', 'computer science', 'data sharing', 'deep neural network', 'disability', 'disorder subtype', 'effective therapy', 'efficacy evaluation', 'flexibility', 'genetic analysis', 'genetic architecture', 'genetic information', 'genetic predictors', 'improved', 'innovation', 'insight', 'long short term memory', 'multidimensional data', 'neuroimaging', 'preservation', 'psychogenetics', 'public health priorities', 'statistics', 'targeted treatment', 'trait', 'treatment response', 'vector']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,667757
"Next-generation, pathway-specific, polygenic risk scores PROJECT SUMMARY The key appeal of polygenic risk scores (PRS) is the provision of individual-level estimates of genetic liability to complex disease. These proxies of genetic liability enable a raft of applications across clinical and basic research settings. However, while PRS are set to play a pivotal role in the future of biomedical research, their present formulation is suboptimal since it fails to directly account for substructure in genetic disease risk. The overarching goal of our proposal is to introduce a new generation of pathway-specific PRS, informed by biological function. Rather a single genome-wide PRS for each individual, they will have a set of k PRS over k pathways. Pathways will be defined according to multiscale integration of ‘omics data, exploiting co-expression networks, the transcriptome and the epigenome. The key deliverable from this project will be the production of a powerful and comprehensive pathway-specific PRS computational tool, PRSet, informed by biological function. The rationale is that PRS calculated for individuals by aggregating the effects of all risk variants genome-wide, results in a loss of vital individual-level information. Providing pathway-specific estimates of genetic liability, computed in a scalable, statistically rigorous way, informed by latest multi-omic data, could enable researchers to better decompose heterogenous complex disease, identify key pathways that explain overlap or differences among disorders, and explain problems of portability of PRS between and within populations. Applying our pathway-specific PRS tool, we seek to stratify patients into more homogenous subgroups by their liability over key pathways. We will use PRSet for stratification in three ways: (i) stratifying within SCZ/BiP, testing if liability over different pathways forms multiple routes to disease, (ii) differentiating between SCZ and BiP, testing if key pathways differentiate these highly overlapping disorders, (iii) testing whether variation in treatment response can be explained by pathway liability. Such stratification could help explain past successes, failures and adverse-effects in clinical trials, and provide new therapeutic targets tailored to subsets of patients. Our proposal is significant because the burgeoning application of PRS means that any advance in the PRS approach will have immediate, high impact across psychiatric research. Pathway-specific PRS could open-up routes to hypotheses that cannot be answered by genome-wide PRS. If PRSet reveals that genetic liability is more stratified than presently modelled, then this would call for a focus on pathways and their multi-omic integration, paving a new path towards precision medicine. Our proposal is innovative because we develop the first pathway-specific, function-informed, PRS tool, we propose that disease risk may be influenced by multiple genetic liabilities, and we stratify patients according to pathway-specific genetic risk for the first time. In conclusion, our proposal delivers a tool for the field to perform powerful pathway PRS analyses, better understand genetic liability to disease, and which may offer a more direct route to precision medicine. PROJECT NARRATIVE Polygenic risk scores (PRS) are set to play a key role in advancing our understanding of the etiology and treatment of disease. While the application of genome-wide PRS is burgeoning across biomedical research, we propose that pathway-specific PRS have even greater potential to provide etiological insights and will help pave the way to precision medicine. Here we introduce a new generation of pathway-specific polygenic risk scores, informed by biological function, and deliver a comprehensive computational tool for their analysis, applying it to perform patient stratification in schizophrenia and bipolar disorders.","Next-generation, pathway-specific, polygenic risk scores",10136725,R01MH122866,"['Address', 'Adverse effects', 'Basic Science', 'Biochemical', 'Biochemical Pathway', 'Biological', 'Biological Process', 'Biomedical Research', 'Bipolar Disorder', 'Body mass index', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Computer software', 'Custom', 'Data', 'Diagnostic', 'Disease', 'Disease susceptibility', 'Environment', 'Epigenetic Process', 'Etiology', 'Failure', 'Formulation', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Gold', 'Human', 'In Vitro', 'Individual', 'Intuition', 'Lead', 'Link', 'Location', 'Mental disorders', 'Modeling', 'Multiomic Data', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Prevention', 'Production', 'Proxy', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Route', 'Running', 'Sampling', 'Schizophrenia', 'Stratification', 'Subgroup', 'Symptoms', 'Testing', 'Time', 'Variant', 'base', 'computerized tools', 'disorder risk', 'epigenome', 'functional genomics', 'genome wide association study', 'genome-wide', 'high risk', 'individualized prevention', 'innovation', 'insight', 'multiple omics', 'new therapeutic target', 'next generation', 'novel strategies', 'patient stratification', 'patient subsets', 'personalized medicine', 'personalized therapeutic', 'polygenic risk score', 'portability', 'precision medicine', 'prototype', 'rare variant', 'risk variant', 'statistical and machine learning', 'success', 'tool', 'trait', 'transcriptome', 'treatment response', 'user-friendly']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,635256
"Computational Methods to Integrate and Interpret the Transcriptome from Single Cell and Tissue Level Data In the past decade, substantial progress has been made in discovery of genetic variants and genes associated with risk for psychiatric disorders. Altered gene expression in the brain, particularly at the cell-type-specific level, is believed to be a driving factor in conferring risk through these genetic variants. To link altered transcription to psychopathology, an immense amount of transcriptomic data is being accumulated, including single-cell and tissue level transcriptomes. Some of these samples cover critical developmental periods. An outstanding challenge is how to integrate single cell and tissue level transcriptomic data and how genetic variation alters transcription in specific cells to produce psychopathology. In this high dimensional ‘omics setting, we need powerful statistical and machine learning tools to produce integrative analyses and mesh those results with large psychiatric genetic datasets to achieve new insights. We propose to use our expertise in high dimensional statistical inference to tackle this challenge. We go beyond machine learning models that specialize in prediction, focusing instead on providing interpretable statistical inferences. We identify gene communities, defined in terms of cell type and spatiotemporal window, driving risk. With vast amounts of data comes great risk of spurious inferences based on non-rigorous analyses. On the other hand, reliable, but naïve tools can sacrifice power by not fully integrating all available information. Our overall objective to produce analytic tools that yield reliable and powerful inferences relating cell-type-specific gene expression with genetic risk factors. With these analytical tools made available to the research community, our longer-term goal is to hasten discoveries in the field and thus build the foundation from which therapeutic targets for psychiatric disorders emerge. Our objectives will be accomplished with the following Specific aims: 1) statistically rigorous methods to select cell-type markers and to estimate cell-type-specific (CTS) expression, which will facilitate downstream analyses, including CTS eQTLs from tissue; 2) modeling dynamic gene communities throughout development of cell lineages or tissue and relating them to community-based-score statistics to gain insight into the impact of genetic risk factors on psychiatric disorders; and 3) novel methods for estimating gene co-expression networks from single cell RNA-seq. This contribution is significant because it will make many transcriptomic resources more valuable and enable downstream analyses, such as detection of CTS eQTLs in larger sample sets with higher power. Dynamic network analysis tools enhance our ability to identify gene communities that vary over developmental epochs and this variation facilitates inferences that relate cell type and developmental period with risk factors. The research proposed is innovative, in our opinion, because it uses novel statistical methods for integrative analysis of data from multiple sources, and cutting edge results to represent high dimensional data in a meaningful way that lends itself to clustering and network analysis. The statistical tools and results arising from the proposed research are relevant to public health because they will generate a deeper understanding of the etiology of psychiatric disorders. Moreover, the refined methods and new results provided by our research will be directly useful for the research community as they hunt for ways to prevent or treat mental disorders.",Computational Methods to Integrate and Interpret the Transcriptome from Single Cell and Tissue Level Data,10144504,R01MH123184,"['Algorithms', 'Automobile Driving', 'Brain', 'Brain region', 'Cell Lineage', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Elements', 'Etiology', 'Foundations', 'Gene Cluster', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic Transcription', 'Genetic Variation', 'Goals', 'Graph', 'Heritability', 'Heterogeneity', 'Human', 'Link', 'Literature', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Molecular', 'Neurons', 'Noise', 'Organ', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Procedures', 'Psychopathology', 'Public Health', 'Publishing', 'Quantitative Trait Loci', 'RNA', 'Regulator Genes', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Statistical Methods', 'Structure', 'Synapses', 'System', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Untranslated RNA', 'Variant', 'Vertebral column', 'Work', 'analytical tool', 'base', 'brain cell', 'case control', 'cell type', 'critical developmental period', 'gene discovery', 'genetic analysis', 'genetic predictors', 'genetic risk factor', 'genetic variant', 'high dimensionality', 'improved', 'innovation', 'insight', 'machine learning method', 'multidimensional data', 'multiple data sources', 'novel', 'prevent', 'psychogenetics', 'single-cell RNA sequencing', 'spatiotemporal', 'statistical and machine learning', 'statistics', 'stem', 'therapeutic target', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'user friendly software']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2021,505168
"Map Manager: Longitudinal image analysis with online editing and sharing. The increasing availability and ease of use of confocal, two-photon, and light-sheet microscopes coupled with rapid developments in fluorescent protein reporters have made 3D and functional imaging and its analysis a central component of modern Neuroscience research. Yet, the ease of acquiring 3D and functional images is creating progressively larger datasets, prompting the need for high-throughput image analysis algorithms and software that can be both rapid and accurate. Although software to analyze single time-point images has received substantial attention, tools to analyze multiple time-point longitudinal imaging datasets is currently lacking. This lack of longitudinal image analysis tools is a major barrier to scientific inquiry with individual labs devising their own analysis strategies creating a situation where it is difficult for others to verify and reproduce this analysis. What is needed is a community agreed upon longitudinal image analysis standard that promotes sharing.  Here, we propose to develop software to create and curate annotations in longitudinal imaging datasets. This software will solve a major problem by providing the needed rigor and reproducibility while making it easy for researchers to distribute their data and analysis. Making these important datasets findable, accessible, interoperable, and reusable. To achieve these goals, we propose to build intuitive web-browser and desktop graphical-user-interfaces (GUIs) that will work with cloud based data and analysis. These GUIs will be driven by a Python advanced-programming-interface (API) that is scriptable. For online editing and sharing we will work with the BRAIN funded Brain Image Library (BIL), and for interoperability with Neurodata Without Borders (NWB) and Neuroscience Data Interface. We will utilize the BRAIN Initiative NeuroMorpho.Org and Defining Our Research Methodology (DORY), to ensure our annotations of morphology, connectivity, and physiological signatures include accepted meta-data nomenclatures and vocabularies.  We will work closely with a group of ""seed"" BRAIN funded labs to obtain feedback and make rapid improvements in the functionality and usability of the front-end GUIs and the back-end API. This will be achieved by online forums, site visits, and a hack-a-thon hosted at UC Davis. During the Covid pandemic we have learned that these events work extremely well when done virtually and are prepared to continue this model. We are committed to providing thorough documentation for the web-browser, desktop GUIs, and Python API as well as constantly refined and simple to follow recipes with interactive web-based use cases. To ensure community adoption and use, this proposal also includes working with a number of ""seed"" labs to run their data through the entire pipeline from analysis to online sharing.  The long range goal is to have Map Manager act as a catalyst for data analysis, exploration, and sharing. Effectively creating a community based approach, akin to other disciplines such as astronomy, where data is widely and publicly shared allowing effective data mining and model building to advance new discoveries. A major bottleneck in the interpretation of longitudinal imaging data is the availability of useful analysis software tools. The purpose of this proposal is to develop a rigorous and easy to use software ecosystem for the annotation, curation, and sharing of longitudinal imaging datasets. We will provide cloud-based editors and viewers that allow collaboration and dissemination of this critical data.",Map Manager: Longitudinal image analysis with online editing and sharing.,10365810,RF1MH123206,"['3-Dimensional', '4D Imaging', 'Adoption', 'Algorithmic Software', 'Astronomy', 'Attention', 'Axon', 'BRAIN initiative', 'Back', 'Brain imaging', 'COVID-19 pandemic', 'Cells', 'Client', 'Collaborations', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Development', 'Discipline', 'Documentation', 'Ecosystem', 'Encapsulated', 'Ensure', 'Environment', 'Event', 'Evolution', 'FAIR principles', 'Feedback', 'Fostering', 'Foundations', 'Functional Imaging', 'Funding', 'Goals', 'Image', 'Image Analysis', 'Individual', 'Internet', 'Intuition', 'Kinetics', 'Libraries', 'Light', 'Link', 'Machine Learning', 'Maps', 'Metadata', 'Microscope', 'Modeling', 'Modernization', 'Morphology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Nomenclature', 'Online Systems', 'Parents', 'Physiological', 'Proteins', 'Publishing', 'Pythons', 'Recipe', 'Reporter', 'Reproducibility', 'Research Methodology', 'Research Personnel', 'Running', 'Schedule', 'Scientific Inquiry', 'Seeds', 'Series', 'Site Visit', 'Software Design', 'Software Tools', 'Structure', 'System', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Vertebral column', 'Visual', 'Visualization', 'Vocabulary', 'Work', 'analysis pipeline', 'automated algorithm', 'base', 'catalyst', 'cell type', 'cloud based', 'data mining', 'data modeling', 'data sharing', 'density', 'design', 'file format', 'flexibility', 'graphical user interface', 'high resolution imaging', 'image archival system', 'interest', 'interoperability', 'large datasets', 'longitudinal analysis', 'longitudinal design', 'model building', 'online repository', 'programs', 'serial imaging', 'software development', 'tool', 'two-photon', 'usability', 'virtual', 'web interface']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,RF1,2021,1158500
"Heritability and cognitive implications of structural-functional connectome coupling The human brain is an unimaginably complicated system of interconnected neurons that is capable of complex thought, emotion and behavior. Macroscale white matter connections quantified via the structural connectome (SC) act as the backbone for the flow of functional activation, which can be represented via the functional con- nectome (FC). Our group and others have shown that quantifying properties of the brain’s structural and func- tional connectomes and their relationship can inform understanding of brain-behavior associations and disease mechanisms4-9. However, models that describe SC-FC relationships have only achieved moderate agreement with observations and have not been used to fully explore the heritability and cognitive implications of structure- function coupling in adult and developing populations. If we do not accurately understand how the brain’s anat- omy and physiology are linked across the human lifespan, then we will not be able to quantify the impact of disease or pathological developmental trajectories. Our long-term goal is to create computational tools for stud- ying the brain’s structure and function, particularly in the context of disease. The overarching objective of this project is to create a model that accurately {and interpretably} quantifies the coupling between the structural and functional connectomes in both sexes, which will in turn allow us to investigate the heritability and cognitive implications of SC-FC coupling across developing and adult populations. Our central hypothesis is that a {hybrid approach to predicting FC from SC, combining both biophysical modeling and deep learning,} will be more ac- curate than existing techniques. Based on the prior literature and our preliminary data, we hypothesize that SC- FC coupling will vary with sex, be heritable, associated with development, and explain inter-subject variability in cognition. Our hypothesis is supported by preliminary data from our group and others that show SC-FC relation- ships are heritable and vary with sex and cognition in patients7,18. The rationale for this work is that having an accurate model of the SC-FC relationship in healthy populations, which currently does not exist, will further our understanding of the complex relationship between anatomy, physiology, sex, genetics and cognition. We will test the central hypothesis via three specific aims: 1) identify the most accurate model for predicting FC from SC, 2) quantify the heritability of SC-FC coupling and its association with cognitive performance and 3) characterize the SC-FC coupling trajectory and its cognitive implications throughout development. We will use neuroimaging, genetic and cognitive data from the Human Connectome Project, including young adult (~1000 individuals, 22- 37 years) and developing populations (~650 individuals, 5-21 years). The approach is innovative, as it proposes to use model-driven, data-driven and hybrid approaches to model SC-FC relationships and that it poses to ex- plore sex effects, heritability, cognitive and developmental implications of SC-FC relationships. The proposed research is significant in that understanding structure-function relationships across typical development will allow quantification of the impact of disease and reveal avenues for novel treatments in various neurological diseases. The proposed research is relevant to public health because understanding the relationship between brain anatomy, physiology, genetics and cognition throughout human development is paramount to understanding of how it can break down in disease. Thus, the proposed work is relevant to the NICHD's mission in that it seeks to understand human development and optimize abilities for all.",Heritability and cognitive implications of structural-functional connectome coupling,10189014,RF1MH123232,"['Adult', 'Age', 'Agreement', 'Anatomy', 'Architecture', 'Behavior', 'Brain', 'Brain region', 'Cognition', 'Cognitive', 'Complex', 'Coupling', 'Data', 'Data Set', 'Development', 'Diffusion', 'Disease', 'Dissociation', 'Early Diagnosis', 'Emotions', 'Evolution', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Health', 'Heritability', 'Human', 'Human Development', 'Hybrids', 'Individual', 'Link', 'Literature', 'Longevity', 'Maps', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurons', 'Pathologic', 'Pathology', 'Pathway interactions', 'Patients', 'Physiology', 'Population', 'Prognosis', 'Property', 'Public Health', 'Publishing', 'Research', 'Rest', 'Sex Differences', 'Ships', 'Signal Transduction', 'Structural Models', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Testing', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'base', 'biophysical model', 'brain behavior', 'cognitive performance', 'cohort', 'computerized tools', 'connectome', 'deep learning', 'deep neural network', 'genome-wide', 'human data', 'imaging modality', 'innovation', 'insight', 'nervous system disorder', 'neuroimaging', 'novel', 'predictive modeling', 'relating to nervous system', 'sex', 'white matter', 'young adult']",NIMH,WEILL MEDICAL COLL OF CORNELL UNIV,RF1,2021,1292521
"A Pragmatic Latent Variable Learning Approach Aligned with Clinical Practice Abstract With growing interest in personalized medicine and the rise of machine learning, constructing good risk prediction and prognostic models has been drawing renewed attention. In this development, much effort is concentrated in identifying good predictors of patient outcomes, although the same level of rigor is often absent in improving the outcome side of prediction. The majority of popular supervised techniques (e.g., regularized logistic regression and its variations), which can be readily applied in risk model development, assumes that the prediction target is a clear single outcome measured at a single time point. In clinical reality, patient outcomes are often complex, multivariate, and measured with errors. Even when a target is a relatively clear univariate outcome (e.g., death, cancer, diabetes, etc), the process that leads to this ultimate outcome often involves complex intermediate outcomes, where predicting and understanding this intermediate process can be crucial in providing effective care and preventing negative ultimate outcomes. The situation calls for a ﬂexible learning framework that can easily incorporate this important but neglected aspect in model development - better characterizing and constructing prediction targets before building prediction models.  Focusing on risk labels as prediction targets, we propose a pragmatic 3-stage learning approach, where we sequentially 1) generate latent labels, 2) validate them using explicit validators, and 3) go on with supervised learning with labeled data. Latent variable (LV) strategies used in Satge 1 have great potentials in handling complex outcome information. The unsupervised nature of LV strategies makes highly ﬂexible data synthesis and organization possible. The same nature, however, can also be seen as esoteric and subjective, which is not desirable in situations where transparency and reproducibility are of great concern such as in risk prediction. As a practical solution to this problem, we propose the use of explicit clinical validators, which not only makes LV-based labels closely aligned with contemporary science and clinical practice, but also makes it possible to automatically validate and narrow a large pool of candidate labels. With the goal of developing a practical and transparent system of learning and inference for clinical research and practice, we formed a highly interdisciplinary team of researchers with expertise in latent variable modeling, machine learning, psychometrics and causal inference along with clinical/substantive expertise. Our streamlined learning framework focuses on direct and transparent validation of latent variable solutions to ensure clear communication across risk model developers, clinical researchers and practitioners. The project ultimately aims to improve personalized treatment and care by improving risk prediction. Narrative This project intends to develop a pragmatic learning and risk predction framework that will facilitate utilization of multivariate data collected from research and health care services, which otherwise is underutilized in developing methods to improve personalized care of future patients. The project ultimately aims to improve personalized treatment and care by improving risk prediction, and therefore will have positive impact on public health.",A Pragmatic Latent Variable Learning Approach Aligned with Clinical Practice,10212944,R01MH123443,"['Address', 'Anxiety', 'Anxiety Disorders', 'Attention', 'Attention deficit hyperactivity disorder', 'Brain', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'Data', 'Decision Making', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Ensure', 'Future', 'Goals', 'Health', 'Heart', 'Hybrids', 'Hyperglycemia', 'Intention', 'Label', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Manic', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motivation', 'Nature', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Process', 'Psychometrics', 'Public Health', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Science', 'Side', 'Structure', 'Supervision', 'Symptoms', 'System', 'Techniques', 'Time', 'Validation', 'Variant', 'acceptability and feasibility', 'base', 'clinical practice', 'clinical risk', 'comorbidity', 'data exploration', 'flexibility', 'health care service', 'high dimensionality', 'improved', 'improved outcome', 'interest', 'model development', 'neglect', 'personalized care', 'personalized medicine', 'predictive modeling', 'prevent', 'prognostic', 'prognostic model', 'risk prediction', 'risk prediction model', 'simulation', 'supervised learning', 'tool', 'treatment planning', 'unsupervised learning']",NIMH,STANFORD UNIVERSITY,R01,2021,558490
"A Unified High Performance Web Service for Systems Genetics and Precision Medicine High-throughput technologies have transformed biology by enabling deep phenotyping of living organisms. Deep phenotyping in genetically randomized populations provides a powerful resource for understanding cause and effect – this is the promise of systems genetics and precision medicine. Despite the advances in data collection and the availability of genetic and genomic resources, generation of actionable knowledge from these data presents computational and statistical challenges. The goal of the GeneNetwork project is to provide a platform of innovation to make the best use of the data and computational tools for systems genetics. The proposed project will focus on broadening the impact of the web service by broadening community participation in the web service and strengthening computational engine powering the web service. We will enhance our database by providing automated tools for data entry and curation (Aim 1); we will improve tools for genetic analysis of high-throughput traits (Aim 2); enable bidirectional information sharing between animal model and human genetic studies (Aim 3); and provide a platform for toolset prototying and testing by the computational community (Aim 4). The goal of the GeneNetwork project is to provide a platform of innovation to make the best use of the data and computational tools for systems genetics. We will focus on broadening the impact of the web service by broadening research community participation in the web service and strengthening computational engine powering the web service. We will enhance our database by providing automated tools for data entry and curation (Aim 1); we will improve tools for genetic analysis of high-throughput traits (Aim 2); enable bidirectional information sharing between animal model and human genetic studies (Aim 3); and provide a platform for toolset prototyping and testing by the computational community (Aim 4).",A Unified High Performance Web Service for Systems Genetics and Precision Medicine,10210974,R01GM123489,"['Animal Model', 'Area', 'Bioinformatics', 'Biological Models', 'Biology', 'Caenorhabditis elegans', 'Candidate Disease Gene', 'Code', 'Communities', 'Community Participation', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Scientist', 'Data Set', 'Databases', 'Drosophila genus', 'Equilibrium', 'Experimental Genetics', 'FAIR principles', 'Foundations', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Medicine', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Internet', 'Joints', 'Knowledge', 'Linear Models', 'Link', 'Machine Learning', 'Medical Genetics', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Motivation', 'Multiomic Data', 'Mus', 'National Institute of General Medical Sciences', 'Online Systems', 'Ontology', 'Organism', 'Pathway Analysis', 'Performance', 'Phenotype', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Programming Languages', 'Pythons', 'Quality Control', 'Randomized', 'Rattus', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sample Size', 'Science', 'Secure', 'Ships', 'Site', 'Solid', 'Structure', 'Synteny', 'System', 'Testing', 'Time', 'Tissues', 'Translations', 'Trust', 'United States National Institutes of Health', 'Variant', 'addiction', 'causal model', 'cohort', 'computerized tools', 'data curation', 'data reuse', 'data sharing', 'data tools', 'data visualization', 'disorder risk', 'experimental study', 'genetic analysis', 'genome wide association study', 'genomic data', 'high throughput analysis', 'high throughput technology', 'improved', 'innovation', 'insight', 'pan-genome', 'precision medicine', 'prototype', 'simulation', 'skills', 'statistics', 'tool', 'trait', 'translational genetics', 'web services']",NIGMS,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2021,453683
"Steroselectivity of Synthetically Valuable Enzyme Catalysts Project Abstract This research program develops and applies state-of-the-art computational methods to understand stereoselectivities of enzyme catalysts for reactions of high synthetic value. The control of stereoselectivity is an essential feature of efficient synthesis, and this program provides explanations of the origins of these selectivities and builds on these to predict new enzyme catalysts for stereoselective reactions. Collaborators test these predictions. These are critical elements in the synthesis of effective pharmaceutical agents. Project Narrative The goal of this research program is to develop and apply state-of-the-art computational methods to understand stereoselectivities of enzyme catalysts for synthetically valuable transformations, to aid in the design of new stereoselective reagents and catalysts, and to demonstrate efficient computational methods that all chemists can use to study such problems. Collaborations with prominent biosynthetic laboratories have provided challenging goals and will provide experimental testing of predictions.",Steroselectivity of Synthetically Valuable Enzyme Catalysts,10104515,R01GM124480,"['Acids', 'Active Sites', 'Alcohols', 'Aldehydes', 'Amines', 'Amino Acid Sequence', 'Antibiotics', 'Beta Carbolines', 'Biochemical Reaction', 'Biology', 'Chemicals', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Diels Alder reaction', 'Distal', 'Elements', 'Engineering', 'Enzymes', 'Filtration', 'Free Energy', 'Goals', 'Hot Spot', 'Industrialization', 'Intuition', 'Ketones', 'Kinetics', 'Laboratories', 'Location', 'Methods', 'Mutation', 'Oxides', 'Pathway interactions', 'Pharmacologic Substance', 'Physical condensation', 'Principal Component Analysis', 'Process', 'Production', 'Protein Engineering', 'Protocols documentation', 'Reaction', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Sequence Alignment', 'Strictosidine synthase', 'System', 'Testing', 'Transaminases', 'analog', 'base', 'catalyst', 'combinatorial', 'comparative', 'cycloaddition', 'decalin', 'design', 'flexibility', 'improved', 'molecular dynamics', 'mutant', 'novel', 'programs', 'protein folding', 'pyridine']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,292995
"Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center The “clinical high risk” (CHR) for psychosis syndrome is an antecedent period characterized by attenuated psychotic symptoms that are marked by subtle deviations from normal development in thinking, motivation, affect, behavior, and a decline in functioning. Early intervention in this CHR population is critical to prevent psychosis onset as well as other adverse outcomes. However, the presentation of symptoms and subsequent course is highly variable, and there is a paucity of biomarkers to guide treatment development. Thus, to improve predictive models that are clinically relevant, several issues need to be addressed: 1) focusing on outcomes beyond psychosis; 2) taking into account heterogeneity in samples and outcomes; and 3) integrating data sets with a broad array of variables using innovative algorithms to overcome variability across studies. To address these challenges, the proposed “Psychosis Risk Evaluation Data Integration and Computational Technologies: Data Processing, Analysis, and Coordination Center” (PREDICT-DPACC) brings together a multidisciplinary team of highly experienced researchers with proven capabilities in all aspects of large-scale studies, CHR studies, as well as computational expertise. The ultimate goal is to identify new CHR biomarkers, and CHR subtypes that will enhance future clinical trials. To do so, the PREDICT-DPACC will 1) aggregate extant CHR- related data sets from legacy datasets; 2) provide collaborative management, direction, data processing and coordination for new U01 multisite network(s); and 3) develop and apply advanced algorithms to identify biomarkers that predict outcomes, and to stratify CHR into subtypes based on outcome trajectories, first from the extant data and then refined and applied to the new data. The PREDICT-DPACC team has the broad, comprehensive, and robust infrastructure that is sufficiently flexible to accommodate the inclusion of multiple data types and to optimally address the needs of the CHR U01 network(s). Carefully selected extant data will be rapidly obtained, processed, and uploaded to the NIMH Data Archive (NDA). Proposed analysis methods are powerful and robust, leveraging the expertise and experience of computer scientist developers, and experienced clinical researchers. The U01 network(s) will be coordinated by a team that is experienced in managing large studies, familiar with the needs of such studies, flexible, and is knowledgeable in all aspects of CHR studies, including measures, outcomes, biomarkers, and cohorts. Upon meeting the goals of this U24, and the supported U01 network(s), the expected outcomes of the PREDICT-DPACC will be new predictive biomarkers for CHR outcomes, new definitions of CHR subtypes that are clinically useful, and new curated and comprehensive CHR datasets (extant and new) as well as processing tools and prediction algorithms that are shared with the research community through the NIMH Data Archive. NARRATIVE The “Clinical High Risk” (CHR) for psychosis syndrome in young people represents an opportune window for early intervention to prevent the onset of psychosis and other disorders, and to forestall disability; however, clinical heterogeneity and the paucity of biomarkers have hampered the development of effective intervention. To address these challenges, working with NIMH and key stakeholders, we will harmonize and aggregate existing “legacy” CHR data, and guide and coordinate the collection of new data across a network of sites, to develop biomarker algorithms that can predict individual trajectories for diverse outcomes. This proposal leverages a multidisciplinary team with broad and CHR-specific experience in large-scale multisite and multimodal studies (including clinical trials), along with expertise in data type-specific processing, coordination, analysis, and computational analyses (e.g., machine and deep learning tools from artificial intelligence, and advanced statistical approaches), ethics, community outreach, and data dissemination, all of which will ensure the success of this project.","Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center",10256796,U24MH124629,"['Address', 'Adolescent', 'Affect', 'Algorithms', 'Anxiety Disorders', 'Artificial Intelligence', 'Attenuated', 'Behavior', 'Big Data', 'Biological Markers', 'Child', 'Clinical', 'Clinical Trials', 'Collection', 'Common Data Element', 'Communities', 'Community Outreach', 'Computer Analysis', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease remission', 'Early Intervention', 'Early identification', 'Enrollment', 'Ensure', 'Ethics', 'Evaluation', 'FAIR principles', 'Follow-Up Studies', 'Funding', 'Future', 'Goals', 'Heterogeneity', 'Human Resources', 'Impaired cognition', 'Individual', 'Informatics', 'Infrastructure', 'Instruction', 'Intervention', 'Lead', 'Leadership', 'Longterm Follow-up', 'Machine Learning', 'Measures', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Monitor', 'Moods', 'Motivation', 'National Institute of Mental Health', 'Online Systems', 'Outcome', 'Output', 'Perception', 'Procedures', 'Process', 'Protocols documentation', 'Psychoses', 'Quality Control', 'Recovery', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sampling', 'Scientist', 'Secure', 'Site', 'Social Functioning', 'Standardization', 'Substance Use Disorder', 'Suggestion', 'Symptoms', 'Technology', 'Thinking', 'Time', 'Training', 'Transact', 'United States', 'Validation', 'Visualization software', 'adverse outcome', 'analytical tool', 'attenuated psychosis syndrome', 'base', 'bioinformatics infrastructure', 'candidate marker', 'clinical heterogeneity', 'clinical risk', 'clinical subtypes', 'clinically relevant', 'cloud based', 'cohort', 'computerized data processing', 'data acquisition', 'data archive', 'data dictionary', 'data dissemination', 'data harmonization', 'data infrastructure', 'data integration', 'data tools', 'deep learning', 'demographics', 'design', 'disability', 'effective intervention', 'experience', 'flexibility', 'functional decline', 'functional disability', 'high risk', 'high risk population', 'improved', 'inclusion criteria', 'innovation', 'meetings', 'member', 'multidisciplinary', 'multimodal data', 'multimodality', 'multiple data types', 'outcome prediction', 'persistent symptom', 'prediction algorithm', 'predictive marker', 'predictive modeling', 'prevent', 'prospective', 'psychotic symptoms', 'quality assurance', 'recruit', 'research study', 'resilience', 'response', 'risk prediction', 'risk stratification', 'success', 'therapy development', 'tool', 'working group']",NIMH,BRIGHAM AND WOMEN'S HOSPITAL,U24,2021,3917810
"Diversity Supplement Project Summary The goal of this Diversity Supplement Application is to provide an in-depth research experience and strengthen the scientific background of Paola Marquez-Gomez to enable her to access and thrive at a graduate program or medical school. Toward this goal, Paola will work on an extension project of the paneer award engineering an orthogonal Gαs-coupled Designer G protein-couple receptor activated by designer drug (DREADD) to enable the multiplex activation of GPCR signaling pathways in mammalian cells. This work is significant because multiplex activation of GPCR signaling in mammalian cells would allow the study of GPCR signaling crosstalk and its effect on cellular phenotype, and, in the future, animal behavior. This work is innovative because it leverages experimental and chemoinformatics data to train a machine learning algorithm to engineer the substrate specificity of GPCRs for which no crystal structure is available. Project Narrative G protein coupled receptors (GPCRs) are targeted by 30% of all approved drugs, and a full understanding of how they activate intracellular signaling pathways and their effect on complex behavior is key to the development of new and safer therapeutics. We propose engineering the substrate specificity of a GPCR such that it can be activated independently of other GPCRs naturally presented on the cell surface. Such a GPCR could be used to study how GPCR signaling pathways interact with one another with implications for understanding complex cell signaling and animal behavior.",Diversity Supplement,10443343,R35GM124871,"['Animal Behavior', 'Area', 'Award', 'Behavior', 'Cell Therapy', 'Cell surface', 'Cells', 'Chemical Engineering', 'Chemicals', 'Clozapine', 'Complex', 'Coupled', 'Coupling', 'Crystallization', 'Data', 'Designer Drugs', 'Development', 'Docking', 'Doctor of Philosophy', 'Engineering', 'Future', 'G Protein-Coupled Receptor Signaling', 'G-Protein-Coupled Receptors', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene Expression', 'Goals', 'Laboratories', 'Latina', 'Libraries', 'Ligands', 'Link', 'Logic', 'Luciferases', 'Machine Learning', 'Mammalian Cell', 'Mentors', 'Muscarinics', 'Mutation', 'Orphan', 'Oxides', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Receptor Signaling', 'Reporter Genes', 'Research', 'STEM field', 'Science', 'Serotonin', 'Signal Pathway', 'Signal Transduction', 'Structure', 'Substrate Specificity', 'Therapeutic', 'Training', 'Underrepresented Minority', 'Woman', 'Work', 'Yeasts', 'base', 'beta-arrestin', 'combinatorial', 'desensitization', 'designer receptors exclusively activated by designer drugs', 'experience', 'high throughput screening', 'improved', 'in vivo', 'innovation', 'kappa opioid receptors', 'machine learning algorithm', 'medical schools', 'member', 'mutant', 'olfactory receptor', 'physical science', 'programs', 'receptor', 'response', 'screening', 'sensor technology', 'serotonin receptor', 'small molecule libraries', 'tool']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R35,2021,72562
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,10239056,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'statistical and machine learning', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2021,332952
"Intestinal Homeostasis Induced by Commensals ABSTRACT While multidrug-resistance transporters including P-gp and MRP2 are generally studied for their role in exporting drugs and foreign compounds from the cell, our studies indicate that these efflux pumps expressed at the apical surface of intestinal epithelial cells provide a critical link in communication between sentinel functions of mucosal barriers and the immune system. Understanding how this P-gp/eCB anti-inflammatory arm is regulated will provide crucial insight into how dysfunction may promote intestinal inflammation and help identify potential new therapeutic targets. Because the resident microbiota is known to contribute to tolerance and homeostasis in the healthy intestine, the central hypothesis we aim to test is whether the normal microbiota actively drives the P-gp/eCB axis to prevent unnecessary inflammation. Our pilot studies indicate that the microbiota does influence P-gp expression and function, providing a unique foundation for further cause-effect studies. No data have previously demonstrated a link between the microbiota and eCBs or any other epithelial lipid signals, and may well provide great insight into a novel system. Bridging this gap could help explain how commensal bacteria can stabilize a state of tolerance and how genetic modification of specific pathway elements might predispose individuals to conditions of inflammatory bowel disease (IBD). To begin addressing these questions, in Aim 1 of this application will combine in vitro (including human colonoids) and in vivo murine model systems, as well as use healthy and UC patient stool, to more deeply understand the microbial consortia that collectively maximize P-gp expression and function. Aim 2 is designed to identify the microbial metabolites that drive activation of P-gp expression and eCB secretion to maintain an anti-inflammatory tone in the intestinal epithelium. Thus, transcriptomics and metabolite analyses will be performed to provide new information regarding microbial genes, gene clusters, and their metabolic products implicated in maintaining an anti- inflammatory tone in the intestinal epithelium through regulation of the P-gp/eCB axis. In Aim 3 we will employ novel computational methods will to uncover the inter-microbial network responses and the ecological structure of a stable community that is able to induce P-gp expression. Collectively, knowledge of the pathways that coordinate the maintenance of the P-gp/eCB axis will require a comprehensive understanding of distinct signals regulating intestinal homeostasis, how multiple signals are integrated in the complex intestinal environment, and pathways that modulate host-microbe interactions. Consequently, this proposal will directly advance novel biological principles with guidance of new therapeutic intervention strategies. Public Health Narrative Regulated recruitment and migration of acute inflammatory cells termed neutrophils (PMN) into the intestine and across the specialized epithelium that lines it is critical for host defense, yet dysregulation of this process is associated with disease. Because the resident microbiota is known to contribute to tolerance and homeostasis in the healthy intestine, the goal of this proposal will examine whether the normal microbiota actively drives the P-gp/eCB axis to maintain a homeostatic anti-inflammatory tone in the intestinal epithelium. Understanding this process could help explain how commensal bacteria can stabilize a state of tolerance and how genetic modification of specific pathway elements might predispose individuals to conditions of inflammatory bowel disease (IBD).",Intestinal Homeostasis Induced by Commensals,10212384,R01DK125407,"['ABCB1 gene', 'Acute', 'Address', 'Anti-Inflammatory Agents', 'Apical', 'Bile Acids', 'Biological', 'Biological Models', 'Cells', 'Colitis', 'Communication', 'Communities', 'Complex', 'Computing Methodologies', 'Cues', 'Data', 'Disease', 'Elements', 'Endocannabinoids', 'Environment', 'Epithelial', 'Epithelial Cells', 'Equilibrium', 'Ethanolamines', 'Eubacterium', 'Feces', 'Foundations', 'Functional disorder', 'Gene Cluster', 'Genes', 'Genetic', 'Genetic Transcription', 'Goals', 'Homeostasis', 'Host Defense', 'Human', 'Immune system', 'In Vitro', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Inflammatory Response', 'Injury', 'Intervention', 'Intestinal Mucosa', 'Intestines', 'Invaded', 'Knowledge', 'Lactobacillus', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Mediating', 'Metabolic', 'Modeling', 'Modification', 'Molecular', 'Mucous Membrane', 'Multi-Drug Resistance', 'Mus', 'Outcome', 'Output', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Play', 'Process', 'Public Health', 'Pump', 'Regulation', 'Research', 'Resolution', 'Role', 'Sentinel', 'Severities', 'Signal Transduction', 'Structure', 'Submucosa', 'Surface', 'System', 'Testing', 'Time', 'Toxin', 'Work', 'Xenobiotic Metabolism', 'arm', 'bacterial community', 'base', 'commensal bacteria', 'design', 'efflux pump', 'first responder', 'healing', 'host colonization', 'host-microbe interactions', 'in vivo', 'inflammatory disease of the intestine', 'innate immune mechanisms', 'insight', 'intestinal epithelium', 'intestinal homeostasis', 'mathematical model', 'microbial', 'microbiome', 'microbiota', 'microorganism', 'migration', 'mouse model', 'neutrophil', 'new therapeutic target', 'normal microbiota', 'novel', 'novel therapeutic intervention', 'nuclear factor 1', 'prevent', 'recruit', 'response', 'theories', 'transcriptomics']",NIDDK,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,560048
"Methodological and data-driven approach to infer durable behavior change from mHealth data Abstract Poor cancers, lengthy, achieve diet and physical activity (PA) behaviors, the most prevalent risk factors for cardiometabolic diseases and can be treated to prevent disease. However, most diet, PA, and weight loss interventions are costly, and burdensome. Theseinterventions could be more cost-efficient if we could tell when people a sustainable pattern of health behavior change so that treatment could be tapered and then stopped without behavioral relapse. Theories of habit formation might be assumed to address this problem, but they have not proved actionable to guide treatment decisions because they do not specify measurable criteria to reliably detect acquisition of a durable behavior pattern. Hence, we propose to identify behavior patterns that precede and predict maintenance of target-level behavioral improvement that persist after an intervention ends. The measurements needed to tell whether an intervention has durably entrained behavioral improvement are collected as part of diet, PA, and weight loss interventions. Specifically, participants continuously self-monitor their behavior digitally while assessments are relayed back to inform them about progress toward goals. We will analyze self-monitoring measures collected in 6 mHealth trials, conducted over 14 years among over 1,600 participants and more than 147,000 daily observations, to assess when an intervention has durably entrained targeted behaviors, as validated by their reliable persistence post- intervention. We will use location scale modeling to quantify change not only in the absolute level (location) of a behavior but also in its within-person variability (scale). We posit that the induction of durable behavior change requires both improvement in location (increases for healthy behaviors; decreases for unhealthy ones) and decrease in scale (i.e., increased behavioral consistency). Aim 1 will apply existing location scale methods to test the hypothesis that effective interventions will improve the location and reduce the scale of targeted behaviors across all trials. Because existing methods only measure scale at the group level and cannot measure the change in an individual's behavioral consistency that we need to personalize treatment adaptation, Aim 2 will extend location scale methods to enable individual estimation of the rate of change in behavioral consistency. Estimates derived from the new method will be analyzed to learn which parameters of behavior change during intervention are most associated with maintenance post-treatment. Finally, Aim 3 will apply machine learning to estimates from the extended location-scale mixed models to establish ranges and behavioral patterns that predict behavioral maintenance post-treatment. These resultswill inform behaviorinterventionscience and improve treatment efficiency by guiding real-timedecisions about the needed dosage and duration of behavioral treatments. Project Narrative Health promotion could be more cost-efficient if we could tell when people have established a durable behavioral change so that their treatment could be tapered with low risk of relapse. The project introduces a new method of quantifying improvement in both the absolute level and the day-to-day consistency of targeted behaviors to learn when healthy changes are likely to persist.",Methodological and data-driven approach to infer durable behavior change from mHealth data,10218158,R01DK125414,"['Address', 'Aftercare', 'Algorithms', 'Back', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Body Weight Changes', 'Body Weight decreased', 'Cardiometabolic Disease', 'Chronic Disease', 'Clinical', 'Computer software', 'Confusion', 'Consumption', 'Data', 'Decision Making', 'Diet', 'Diet Monitoring', 'Disease', 'Dose', 'Feedback', 'Frequencies', 'Goals', 'Habits', 'Health Promotion', 'Health Promotion Sciences', 'Health behavior', 'Health behavior change', 'Individual', 'Intercept', 'Intervention', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Measurable', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Participant', 'Pattern', 'Persons', 'Physical activity', 'Process', 'Psychological Theory', 'Relapse', 'Research', 'Risk Behaviors', 'Risk Factors', 'Running', 'Science', 'Statistical Data Interpretation', 'Statistical Models', 'Techniques', 'Terminology', 'Testing', 'Time', 'Vegetables', 'analytical tool', 'base', 'behavior change', 'behavioral phenotyping', 'cancer risk', 'control theory', 'cost', 'cost effective', 'cost efficient', 'digital', 'dosage', 'effective intervention', 'exercise intervention', 'improved', 'individual variation', 'interest', 'intervention cost', 'mHealth', 'personalized medicine', 'post intervention', 'predictive modeling', 'prevent', 'rate of change', 'relapse risk', 'theories', 'treatment duration', 'weight loss intervention']",NIDDK,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,510240
"Adapting machine learning methods to detect genetic loci specific to strictly defined MDD Abstract  This project seeks to further our understanding of the genetic influences on Major Depressive Disorder (MDD). One approach to increasing sample sizes for molecular genetic studies of MDD and thereby increasing power to detect genetic loci is to assess individuals using surveys that are shorter and more efficient than full clinical assessments. This `minimal phenotyping' leads to identification of risk loci that may not be specific to strictly defined MDD and can be associated with a variety of psychiatric phenotypes. While these discoveries are important to understand the overall biology of complex mental and psychiatric outcomes, they offer little direct and actionable insight into the biological underpinning of strictly defined MDD which shows increased severity, impairment, and recurrence risk and accounts for a disproportionate impact on disability and morbidity in comparison to liberally defined MDD. Recently, large biobanks surveying tens to hundreds of thousands of subjects across hundreds to thousands of variables and EHR records have been become available to the scientific community. Combining rich phenotype data with genome-wide genotyping or sequencing offers an unprecedented opportunity to leverage these resources to advance discovery and understanding of the genetic influences on MDD. One major challenge is the lack of uniform measures that allow assessment of strictly defined MDD, impairment, severity, and recurrence risk. This lack of `deep phenotyping' while pragmatic in allowing the assembly of large samples, creates challenges in accurate determinations of controls, non-specific mild cases, and strictly defined cases. We have previously shown how machine learning (ML) analysis methods can leverage this type of heterogeneous, broad, but light collection of information to predict and quantify risk in subjects not deeply assessed. While there is significant room for improvement in these predictions, the resulting effective sample size and power to detect specific liability loci increased dramatically when this method was applied. In Aim 1, we plan to evaluate 2 families of ML methods that can be used to predict unmeasured and specific strictly defined MDD risk. In Aim 2, we propose to use these predictions of risk in genetic association analyses to detect common genetic variation that influences risk specific to strictly defined MDD. Finally, we will make our biobank adapted ML method pipeline available to the broader psychiatric genetics research community which is expected to improve power and loci detection for other psychiatric disorders.   NARRATIVE  Major Depressive Disorder (MDD) is common psychiatric disorder, a leading cause of disability worldwide, and partially influenced by genetics. Rigorous clinical assessments are generally needed for studies to distinguish between genetic loci influencing mild versus debilitating manifestations of the disorder. We propose to evaluate and adapt machine learning methods to estimate risk to strictly defined MDD in large-scale biobanks samples that measure many variables but may not contain rigorous clinical assessments and use these predictions to discover additional genetic variation specifically influencing MDD.",Adapting machine learning methods to detect genetic loci specific to strictly defined MDD,10196078,R21MH126358,"['Address', 'Biological', 'Biology', 'Body mass index', 'Characteristics', 'Clinical', 'Clinical assessments', 'Collection', 'Communities', 'Complex', 'Data', 'Data Set', 'Detection', 'Disease', 'Family', 'Foundations', 'Genetic', 'Genetic Research', 'Genetic Variation', 'Genetic study', 'Genotype', 'Heritability', 'Impairment', 'Individual', 'Lead', 'Light', 'Machine Learning', 'Major Depressive Disorder', 'Measures', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Molecular Genetics', 'Morbidity - disease rate', 'Neurotic Disorders', 'Nucleotides', 'Outcome', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Probability', 'Process', 'Psyche structure', 'Records', 'Recurrence', 'Resources', 'Risk', 'Risk Estimate', 'Sample Size', 'Sampling', 'Severities', 'Smoking Behavior', 'Solid', 'Structure', 'Surveys', 'Techniques', 'Training', 'Variant', 'Weight', 'biobank', 'disability', 'disorder risk', 'genetic analysis', 'genetic association', 'genome wide association study', 'genome-wide', 'genomic locus', 'improved', 'indexing', 'insight', 'interest', 'large datasets', 'lifetime risk', 'machine learning method', 'novel', 'phenotypic data', 'psychogenetics', 'risk prediction', 'risk variant', 'sample collection', 'statistical and machine learning', 'supervised learning', 'theories', 'trait', 'vector']",NIMH,RESEARCH TRIANGLE INSTITUTE,R21,2021,208389
"Profiling the Functional Genetics of Health and Disease using BrainGENIE: The Brain Gene Expression and Network Imputation Engine Abstract The pathophysiology of brain disorders remains unknown because we cannot study the relevant tissue in living human subjects. Postmortem brain tissue is useful, but expensive, rare, and critically confounded by antemortem and agonal factors. These two facts have inspired the search for alternative strategies, such as the use of surrogate markers like blood-based gene expression. To improve the rigor of this widely used approach, we developed a novel computational method called the Brain Gene Expression and Network Imputation Engine (BrainGENIE) that leverages biological comparability between blood and brain gene expression to predict transcriptome profiles for brain tissue based on blood gene-expression profiles. BrainGENIE is fundamentally different from other transcriptome-imputation methods, and captures a much larger proportion of the variance in—and larger fraction of—the brain transcriptome. BrainGENIE is capable of predicting approximately 9–57% of the brain transcriptome, which yields an approximate 1.8-fold increase in coverage relative to the “gold standard” method PrediXcan, and which greatly improves our statistical power to detect genes and pathways associated with disease. Our proposal contains three Specific Aims to improve our method and shed light on biological pathways underlying neuropsychiatric disorders. Aim 1: Refine BrainGENIE to capture additional genes that are not currently well predicted by our method. Aim 2: Apply BrainGENIE to our collection of publicly available and in-house data to predict brain-region-specific gene expression profiles for over 8,000 living persons, and discover region-specific gene-expression patterns associated with neuropsychiatric disorders and neurodegenerative diseases. Aim 3: Disseminate BrainGENIE as stand-alone software for other researchers to use freely. Guided by recent genetic and genomic studies, we hypothesize that comparable patterns of gene dysregulation will be found across neuropsychiatric disorders among pathways involving innate immunity, chromatin remodeling, neurodevelopment, and neurotransmission. Inclusion of neurodegenerative disorders in our analysis will allow us to determine whether gene expression patterns are shared across a broader range of brain disorders. We also expect to identify disorder-specific and brain-region-specific transcriptomic associations. Our project will enable new lines of inquiry into biological changes that emerge in the brains of living persons, and create opportunities to improve diagnostics, intervention, and treatment. Project Narrative There is a critical need for a method that would allow us to safely study the living human brain so that we can answer centuries-old questions about mental illness, and accelerate progress to improve diagnostics, treatments, and interventions. To accomplish this, we developed a new prediction tool called BrainGENIE that uses correlations between blood and brain tissue to allow us to approximate gene expression levels in the living human brain, and identify molecular mechanisms underlying mental illness. We propose to apply our method to generate brain- region-specific gene expression profiles in over 8,000 individuals (the largest dataset of its kind) and discover genes and biological pathways associated with neuropsychiatric disorders, which will deepen our understanding of pathophysiology.",Profiling the Functional Genetics of Health and Disease using BrainGENIE: The Brain Gene Expression and Network Imputation Engine,10235574,R21MH126494,"['Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Attention', 'Autopsy', 'Bayesian Modeling', 'Biological', 'Bipolar Disorder', 'Blood', 'Blood specimen', 'Brain', 'Brain Diseases', 'Brain region', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Etiology', 'Fostering', 'Functional disorder', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Goals', 'Gold', 'Health', 'Heritability', 'Human', 'Individual', 'Intervention', 'Knowledge', 'Light', 'Major Depressive Disorder', 'Maps', 'Mental disorders', 'Methods', 'Modeling', 'Molecular', 'Natural Immunity', 'Neural Network Simulation', 'Neurodegenerative Disorders', 'Parkinson Disease', 'Participant', 'Pathway interactions', 'Pattern', 'Persons', 'Post-Traumatic Stress Disorders', 'Quantitative Trait Loci', 'Regression Analysis', 'Research Personnel', 'Sampling', 'Schizophrenia', 'Source Code', 'Statistical Methods', 'Surrogate Markers', 'Testing', 'Tissues', 'Training', 'Validation', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'brain tissue', 'cell type', 'chromatin remodeling', 'deep learning', 'deep neural network', 'gene discovery', 'genome wide association study', 'human subject', 'improved', 'mild cognitive impairment', 'neural network', 'neurodevelopment', 'neuropsychiatric disorder', 'neurotransmission', 'novel', 'peripheral blood', 'public repository', 'tool', 'trait', 'transcriptome', 'transcriptomics']",NIMH,UPSTATE MEDICAL UNIVERSITY,R21,2021,243000
"Big-Data Electron-microscopy for Novel Community Hypotheses: Measuring And Retrieving Knowledge (BENCHMARK) Project Summary In an effort to better understand structural organization and anatomy of nervous systems at unprecedented spatial resolution, recent efforts, including BRAIN Initiative funded projects, have collected increasingly larger datasets using Electron Microscopy (EM) and X-Ray Microtomography (XRM). We can now image neural tissue across a range of different scales, potentially forming the basis for the next generation of brain atlases at submicron and nanometer resolution. However, there is huge variability in data collection approaches, as well as ongoing research into evolving imaging technology, experimental protocols, data storage, and post- processing methods. Different resolutions, contrasts, staining, image corrections, data compression, machine learning algorithms, and metadata are all being developed. To enable comparison, meta-analysis, and registration with other datasets and imaging modalities, new standards for EM and XRM data are required, similar to those pursued in light microscopy, magnetic resonance imaging, and other domains. In this time period of growth in EM and XRM imaging, and its increased adoption and utilization for neuroscientific investigations, it is a critical time to implement standards that ensure interoperability, sustainability, and availability of these expensive datasets. This will be critical to enable openness, sharing between laboratories, and reproducible results on these large and expensive datasets. This proposal aims to develop standards for large scale EM and XRM structural data, as well as standards for annotations and links to complementary data sources. This will enable validation, sharing, and replication, greatly amplifying investment in other BRAIN initiative projects in this community. Our team will bring together a community of researchers into two complementary Working Groups (WGs) for Image and Experimental Metadata Standards and Annotation Standards. This community of interest will collaboratively develop standards and disseminate results in conjunction with BRAIN initiative projects and archives. Finally, this project will build tools to query and retrieve image and annotation data, including motif discovery, through a community portal and open source tools. This will allow scientists to reproducibly analyze data, test hypotheses, and share data products and results with the community. We will emphasize collaboration with existing standards across communities and the development and integration of software tools supporting the standards to ensure adoption. Project Narrative We propose the development of imaging and annotations data standards for the Electron Microscopy and X-ray Microtomography research communities. These standards will enable analysis and discovery on a new generation of large-scale nano- and micro-scale neuroanatomical and connectomics datasets. The team will build these standards collaboratively with the broader scientific community, develop and release software tools that utilize these standards, and build a community portal to ensure adoption and maximize impact.",Big-Data Electron-microscopy for Novel Community Hypotheses: Measuring And Retrieving Knowledge (BENCHMARK),10252257,R01MH126684,"['Academia', 'Adoption', 'Anatomy', 'Archives', 'Atlases', 'BRAIN initiative', 'Big Data', 'Brain', 'Brain region', 'Collaborations', 'Communities', 'Community Developments', 'Computer software', 'Data', 'Data Collection', 'Data Compression', 'Data Provenance', 'Data Scientist', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Data Store', 'Development', 'Electron Microscopy', 'Ensure', 'Exposure to', 'Funding', 'Generations', 'Genomics', 'Government', 'Graph', 'Growth', 'Image', 'Imaging technology', 'Informatics', 'Ingestion', 'Institutes', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Link', 'Magnetic Resonance Imaging', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Nervous system structure', 'Pattern', 'Phase', 'Privatization', 'Protocols documentation', 'Reporting', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Resolution', 'Retrieval', 'Scientist', 'Software Tools', 'Stains', 'Standardization', 'Structure', 'Testing', 'Time', 'Tissues', 'Validation', 'computerized data processing', 'data sharing', 'data standards', 'experience', 'flexibility', 'imaging modality', 'insight', 'interest', 'interoperability', 'large datasets', 'light microscopy', 'machine learning algorithm', 'metadata standards', 'microCT', 'multimodal data', 'nanometer resolution', 'nanoscale', 'neural circuit', 'next generation', 'novel', 'open data', 'open source tool', 'organizational structure', 'recruit', 'relating to nervous system', 'submicron', 'support tools', 'tool', 'working group']",NIMH,JOHNS HOPKINS UNIVERSITY,R01,2021,637869
"Interpretable and extendable deep learning model for biological sequence analysis and prediction SUMMARY Single-cell sequencing technologies provide great opportunities for studying biology and medicine, but computational analyses are often the bottlenecks to reveal biological insights and define cellular heterogeneity underlying the data. The applications of machine learning (ML), especially deep learning hold great promises to address the challenges. While ML studies from various labs, including the PI’s lab, have made significant progress along this line, the involvement of the ML community in single-cell data analysis is limited due to the barriers of technology complexity and biology knowledge. To attract more ML experts into this field, the PI proposes to make large-scale single-cell sequencing data ML-ready and provide an ML-friendly development environment. Specific aims include: (1) Collect, process, and manage diverse single-cell sequencing data to make them ML-ready. We will collect single-cell sequencing data from public sources and convert them into formats efficient for storage and handling. The data will be processed with multiple options, such as imputation, normalization, and dimension reduction using a pipeline to be developed. (2) Configure the data into benchmarks. We will use the collected data to build benchmarks, gather public benchmarks, and encourage the community to submit their benchmarks. The data will be divided into training, validation, and test sets in multiple settings, including a minimum viable benchmark to assist efficient method development and a comprehensive benchmark for full evaluations. We will develop utilities to evaluate results based on a set of assessment measures, and generate detailed reports. We will select a set of public tools to run them on the benchmarks as baselines for others to compare with. (3) Provide an integrated development environment (IDE) to support partial method development. We will build an IDE for single-cell sequencing analysis method development with plug-and-play features at the code level and web interface for ML researchers to contribute and test any minimum new ideas. A report will be provided containing evaluation metrics and usage of computer resources, comparisons with some public tools, and downstream visualization and interpretation. The newly formatted data, the benchmarks, and the method development and assessment environment will be available at GitHub and the in-house single-cell data analysis web portal DeepMAPS. The proposed research is a natural extension of the parent grant (R35-GM126985), which aims to develop deep- learning algorithms, tools, web resources for analyses and predictions of biological sequences, including (1) developing general unsupervised representations and making deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (2) applying deep-learning models to a wide range of bioinformatics problems, and (3) making the data, models, and tools freely accessible to the research community. Thanks to the flexibility of the R35 mechanism, the PI’s lab extended these methods to single-cell data analyses, which well-prepared the lab for the proposed tasks. Project Narrative: Relevance to Public Health Single-cell sequencing is becoming one of the most powerful biotechnologies in studying diseases, such as cancers and Alzheimer’s disease. Machine learning can play a prominent role to better utilize single-cell sequencing data, but the involvement from the machine learning community is limited due to various technical barriers related to data complexity and development environment. Hence, in this project, we will collect and process hundreds of single-cell sequencing data sets, form benchmarks, and provide an integrated development environment to help more machine learning researchers develop methods for single-cell sequencing data analyses.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,10409152,R35GM126985,"['ATAC-seq', 'Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Attention', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biotechnology', 'Cell Communication', 'Cells', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex Analysis', 'Computer Analysis', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Environment', 'Evaluation', 'Formulation', 'Genes', 'Genomics', 'Graph', 'Head', 'Heterogeneity', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Multiomic Data', 'Nature', 'Ohio', 'Performance', 'Play', 'Problem Formulations', 'Process', 'Public Health', 'Publishing', 'Regulator Genes', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sequence Analysis', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Validation', 'Visualization', 'Work', 'analysis pipeline', 'base', 'cell type', 'data complexity', 'data format', 'data integration', 'deep learning', 'deep learning algorithm', 'experience', 'flexibility', 'improved', 'innovation', 'insight', 'learning community', 'learning strategy', 'method development', 'neural network', 'novel', 'online resource', 'parent grant', 'single cell sequencing', 'single cell technology', 'single-cell RNA sequencing', 'tool', 'tool development', 'transcriptomics', 'web interface', 'web portal', 'web site']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2021,234750
"Establishment of Active Chromatin Domains RESEARCH SUMMARY: Understanding the mechanisms which drive coordinate gene activation will provide critical biological insights into development and disease. This supplement aims to enable AI/ML methods to integrate diverse datasets to help achieve that goal. Specifically, we plan to computationally model the spatiotemporal regulation of genes in Drosophila by combining ChIP-Seq, Hi-C/ Micro-C, and mRNA-Seq datasets. Moreover, we will obtaining and model single-cell measurements (scRNA-Seq and scATAC-Seq) across early embryonic developmental stages when domains of coordinate gene activation are established. Therefore, we propose three tasks to produce AI/ML-ready datasets for the community. (1) Development of robust preprocessing pipelines for easy access and input to graph-based neural networks for integrating datasets. (2) Application of sub-graph selection methods to extract informative interactions from large and noisy graphs generated from chromatin capture technologies. (3) Integrating single-cell measurements and providing these combinations for data modeling and analysis purposes. The proposed methods will assist the goals of accurately capturing the underlying biological information when using various machine learning approaches. Furthermore, we will provide processed datasets and scripts to the community to enable methodological innovations. Dr. Larschan will collaborate with machine learning expert Dr. Singh and we have collaborated on several projects based on the proposed topic with joint students and publications. This supplement will be essential to allowing us to continue collaborating and generating new methods and data sets which will provide key insight into coordinate gene activation. Project Narrative Because AI/ML approaches are a key tool to understanding gene regulation, we will apply these key approaches to understand how domains of coordinated gene regulation are established. This supplement will fund a joint graduate student, Jeremy Bigness, who is co- advised with machine learning expert, Dr. Ritambhara Singh. Jeremy will implement machine learning approaches on our three-dimensional and time course data sets.",Establishment of Active Chromatin Domains,10410617,R35GM126994,"['3-Dimensional', 'Biological', 'Cells', 'ChIP-seq', 'Chromatin', 'Communities', 'Computer Models', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drosophila genus', 'Embryo', 'Funding', 'Gene Activation', 'Gene Expression Regulation', 'Goals', 'Graph', 'Hi-C', 'Joints', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Process', 'Publications', 'Research', 'Students', 'Technology', 'Time', 'base', 'data modeling', 'graduate student', 'innovation', 'insight', 'mRNA sequencing', 'neural network', 'single-cell RNA sequencing', 'spatiotemporal', 'tool']",NIGMS,BROWN UNIVERSITY,R35,2021,74191
"Determinants of inception of inflammation in inflammatory bowel diseases Project Summary Crohn’s disease (CD) and ulcerative colitis (UC) affect over 2 million individuals in the United States and are associated with considerable morbidity. Existing treatments achieve remission in fewer than 50% of patients. Further, despite achieving endoscopic remission, up to 30% of patients with CD or UC will relapse over the subsequent three years. Pathophysiologic mechanisms leading to relapse have not been well established. The central premise of our proposal is that despite endoscopic, there exists a local pro-inflammatory microbial milieu and transcriptional profile that favors disease relapse. We hypothesize that current clinical tools do not have sufficient resolution to capture this state. Existing cohorts, by recruiting patients in a heterogeneous state of active inflammation, cannot be used to infer mechanisms of loss of remission and inception of inflammation. A targeted effort that comprehensively and longitudinally profiles a homogeneous cohort of patients in deep remission is essential to define the dynamic relationship between microbial alterations, metabolomic, transcriptional, and proteomic perturbations, and onset of inflammation. Identifying deficient components favoring relapse also allows the development of intervention to replace these deficiencies, thereby extending remission. They will also provide clues and serve as starting points for development of novel therapies. In the first aim, we will recruit 300 patients with IBD in clinical and endoscopic remission and prospectively, systematically follow them for 3 years. We will comprehensively characterize such patients through serial sampling of mucosal and fecal microbiome, serum and fecal metabolome, and proteome in addition to detailed environmental exposure assessment and measurement of drug pharmacokinetics. We will determine the dynamic predictive utility of each of these parameters in defining future relapse from a state of quiescence. In the second aim, we will define the role of pro-inflammatory changes at the cellular level by performing single cell transcriptomic analysis from colonic and ileal biopsies in patients with quiescent CD and UC recruited as above. This will provide important insights into loss of control of inflammation at the tissue level that determines future clinical activity. The final study aim will train and validate a machine-learning predictive model to define the contribution of each additional biologic layer to inception of inflammation and to identify more robust biomarkers of a state of sustained remission. Defining the molecular basis of future relapse in patients in deep remission will provide insights into the ‘pre-disease’ state, allowing for identification of immune pathways of relevance in preventing disease. Defining the fundamental mechanisms through which disease inception occurs from quiescence is critically important to inform key steps in the pathogenesis of these complex diseases, which in turn, will offer opportunities for targeted mechanism-driven interventions to aid durable maintenance of remission and health. The approaches and analyses outlined also have broad applicability to other autoimmune diseases. Project Narrative Despite achieving remission, up to 30% of patients with Crohn’s disease (CD) or ulcerative colitis (UC) will relapse over the subsequent 3 years. The mechanisms of sustained remission have not been defined. We propose a targeted effort that comprehensively and longitudinally profiles a homogeneous cohort of patients in deep remission to define the dynamic perturbations resulting in the inception of inflammation in quiescent disease.",Determinants of inception of inflammation in inflammatory bowel diseases,10297457,R01DK127171,"['Affect', 'Autoimmune Diseases', 'Bacteroides', 'Biological', 'Biological Markers', 'Biopsy', 'Blood specimen', 'Carnitine', 'Cells', 'Characteristics', 'Clinical', 'Colon', 'Complex', 'Consumption', 'Crohn&apos', 's disease', 'Data', 'Development', 'Diet', 'Direct Costs', 'Disease', 'Disease remission', 'Drug Kinetics', 'Environment', 'Environmental Exposure', 'Feces', 'Food', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Health', 'Immune', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Influentials', 'Intake', 'Interleukin-10', 'Intervention', 'Machine Learning', 'Maintenance', 'Measurement', 'Mediating', 'Metagenomics', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Mucous Membrane', 'Neural Network Simulation', 'Pathogenesis', 'Pathway interactions', 'Patient Recruitments', 'Patients', 'Pharmaceutical Preparations', 'Physical activity', 'Pilot Projects', 'Proteome', 'Proteomics', 'Recurrent disease', 'Registries', 'Relapse', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Serum', 'Smoking', 'Sphingolipids', 'Stress', 'Technology', 'Time', 'Tissues', 'Training', 'Ulcerative Colitis', 'United States', 'Up-Regulation', 'Work', 'cohort', 'deep learning', 'deep learning algorithm', 'defined contribution', 'disorder prevention', 'dysbiosis', 'fecal metabolome', 'fecal microbiome', 'follow-up', 'gut microbiome', 'healthy volunteer', 'insight', 'learning strategy', 'metabolome', 'metabolomics', 'microbial', 'microbiome', 'novel therapeutics', 'outcome prediction', 'predicting response', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'recurrent neural network', 'relapse prediction', 'relapse risk', 'soluble fiber', 'targeted treatment', 'therapeutic target', 'therapy development', 'tool', 'transcriptome', 'transcriptomics', 'treatment optimization']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,1129731
"Biomarking IBD patient-specific disease features using the epithelial antigenic peptidome Project Summary/Abstract  In immune-mediated diseases such as type1 diabetes, target-cell autoantibodies have emerged as important clinical biomarkers of pre-clinical disease progression and mechanistic disease subsets. However, with the focus on genetics, inflammatory effectors, and microbiome, there has not been a modern search for such antibody biomarkers and the potential contribution of anti-epithelial autoimmunity in IBD. This project tests the hypothesis that ulcerative colitis phenotypes are distinguished by autoantibodies to mucosal epithelial proteins, addressed in two aims.  In the first aim, we apply the innovative peptide expression display (PED) technology to display and analyze the antigenic epithelial peptidome. This includes bioinformatically determining a comprehensive tabulation of human proteins with high likelihood for antigenicity and ileal-colonic epithelial expression; and, representing these proteins as tiled peptide epitopes with linked cognate oligonucleotides suitable for NGS-based identification and quantitation.  In the second aim, we will assess archival sera of 654 well-characterized colonic IBD patients and non-IBD controls to quantitate individual profiles of epithelial protein binding in relation to two outcomes of ulcerative colitis (UC). The significance of the project has been endorsed by the IBD Genetics Consortium (IBDGC), which made the UC colectomy cohort a research priority, and will collaborate with this R21 via archival serum samples and associated genetics and clinical metadata from the consortium UC patients and controls. Our primary study will compare 300 UC subjects, equally divided into severe and mild phenotypes of outcome based on time to colectomy. Our secondary study will compare 154 UC post-colectomy pouch patients, divided into severe and absent pouchitis phenotypes. We will also study two age-matched reference populations. Bioinformatic analyses will test for shared peptide specificities associated with disease state (UC vs. non-IBD controls) and each of the two extreme phenotypes (severe vs. mild UC; chronic pouchitis vs. late non-pouchitis). We also will perform exploratory tests for the role of IBD predictive risk scores and select genetic loci on autoantibody specificities.  If successful, this project will establish feasibility for the hypothesis, and foundational targets to pursue mechanistic and clinical biomarker studies that may validate and refine its implications for IBD pathogenesis and clinical applications. Project narrative In immune-mediated diseases such as type-1 diabetes, target-cell autoantibodies have emerged as important clinical biomarkers of pre-clinical disease progression and mechanistic disease subsets. Here we propose the first modern search for autoantibody biomarkers in ulcerative colitis, and a test of the hypothesis that anti-epithelial autoimmunity is a contributor to extreme phenotypes in this disease. If successful, this project will establish feasibility for the hypothesis, and foundational targets to pursue mechanistic and clinical biomarker studies that may validate and refine its implications for IBD pathogenesis and clinical applications.",Biomarking IBD patient-specific disease features using the epithelial antigenic peptidome,10261547,R21DK127189,"['Address', 'Age', 'Algorithms', 'Antibodies', 'Archives', 'Autoantibodies', 'Autoimmune Process', 'Autoimmunity', 'Base Sequence', 'Binding Proteins', 'Bioinformatics', 'Biological Markers', 'Cells', 'Chronic', 'Clinical', 'Colectomy', 'Complementary DNA', 'Crohn&apos', 's disease', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Effectiveness', 'Environmental Exposure', 'Epithelial', 'Epitopes', 'Foundations', 'Genetic', 'Genetic Diseases', 'Genomics', 'Goals', 'Human', 'Immune', 'Immunologics', 'Incidence', 'Individual', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Injury', 'Insulin-Dependent Diabetes Mellitus', 'Libraries', 'Link', 'Mediating', 'Metadata', 'Modernization', 'Mucous Membrane', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Oligonucleotides', 'Outcome', 'Pathogenesis', 'Pathogenicity', 'Patients', 'Peptides', 'Phenotype', 'Population', 'Pouchitis', 'Prognosis', 'Prognostic Marker', 'Proteins', 'Research Priority', 'Risk', 'Role', 'Sampling', 'Serum', 'Specificity', 'Subgroup', 'Technology', 'Testing', 'Time', 'Ulcerative Colitis', 'base', 'clinical application', 'clinical biomarkers', 'cohort', 'disease phenotype', 'disorder control', 'genomic locus', 'host microbiome', 'innovation', 'microbiome', 'patient subsets', 'pre-clinical', 'study population', 'technological innovation', 'therapeutic target', 'unsupervised learning']",NIDDK,CEDARS-SINAI MEDICAL CENTER,R21,2021,208750
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10224845,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'machine learning method', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2021,388750
"A web-based framework for multi-modal visualization and annotation of neuroanatomical data PROJECT SUMMARY/ABSTRACT Modern experimental approaches allow researchers to collect a variety of whole-brain data from the same animal via different anatomical labels, including tracers, genetic markers, and fiducial marks from recording electrodes. Unfortunately, viewing and analysis methods have not kept pace with the complexity of these datasets, which can be as large as several terabytes. This limitation makes it time- and resource-intensive to view and manipulate light-microscopy data or to share these datasets with distant laboratories. Currently available software solves some aspects of this problem, but no existing program provides a user-friendly way to visualize, annotate, and compare large neuroanatomical datasets across research sites, with minimal investment of computational resources. We propose to develop a web-based tool, named BrainSharer, to allow researchers to access, visualize, align, share, and semi-automatically annotate brain-wide data within a common framework. The foundation for this tool will be provided by Neuroglancer, a generic web-based volumetric viewer first developed at Google and then adapted for use in electron microscopy laboratories. While some of its current features are useful across applications, existing versions of Neuroglancer are not optimized for light-microscopy data. In particular, they do not realize the potential for sharing, viewing, and editing data across multi-laboratory collaborations, such as U19 projects. To enable BrainSharer to serve data rapidly and to save and restore sessions, we will add a modular distributed database to synchronize metadata across laboratories. In addition, we will tailor BrainSharer for light microscopy by displaying data in formats independent of the imaging modality, adding semiautomatic means to segment cell bodies and processes, adding tools for annotation (with special attention to defining cytological boundaries in three dimensions and tracing projection pathways), and adding ways to incorporate auxiliary data such as electrode tracks. In addition, we will integrate alignment tools into BrainSharer, so that separate datasets can be co-registered, visualized, and annotated in the same framework, along with established and emerging atlases. As test beds for development of BrainSharer, we will use three types of datasets from our U19 projects: whole-brain disynaptic and polysynaptic tracing, activity-based staining with c-fos, and neurovascular data. All software, training datasets, and video tutorials for BrainSharer will be made freely available to the community, hosted on our website, along with a slice histology dataset and an electrophysiology dataset with probes implanted throughout the brain. To orient new users, we will also provide a Jupyter notebook for converting raw, intermediate, and registered light-sheet data, along with detected cells and brain atlases, to precomputed format, so they can be loaded into BrainSharer. When complete, BrainSharer will make it straightforward for researchers to use their laptops to combine and compare large datasets from different anatomical labels for viewing and analysis relative to reference atlases, and to share this information across performance sites, thus increasing the ease of use and interoperability of big data in neuroscience. PROJECT NARRATIVE A critical step in understanding brain function is to determine how specific neurons and regions interact via their connections, many of which project between regions. However, three-dimensional neuroanatomical data currently requires massive computational resources to view, analyze, or share with other researchers. The proposed software package will enable distant scientists to collaboratively analyze complex anatomical datasets via a cloud-based viewer on their laptops, allowing them to take full advantage of available data to learn about healthy and disordered brains.",A web-based framework for multi-modal visualization and annotation of neuroanatomical data,10365435,RF1MH128776,"['3-Dimensional', 'Anatomy', 'Animal Experiments', 'Animal Model', 'Animals', 'Atlases', 'Attention', 'BRAIN initiative', 'Beds', 'Big Data', 'Brain', 'Brain Diseases', 'Cell physiology', 'Cells', 'Cerebrovascular system', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cytology', 'Data', 'Data Display', 'Data Set', 'Databases', 'Development', 'Distant', 'Distributed Databases', 'Documentation', 'Electrodes', 'Electron Microscopy', 'Electrophysiology (science)', 'Ensure', 'Evaluation', 'FOS gene', 'Feedback', 'Foundations', 'Functional Imaging', 'Genetic Markers', 'Goals', 'Guidelines', 'Histology', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Instruction', 'Investments', 'Label', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Light', 'Machine Learning', 'Metadata', 'Methods', 'Microscopy', 'Midbrain structure', 'Modernization', 'Modification', 'Molecular', 'Names', 'Neurons', 'Neurosciences', 'Online Systems', 'Pathway interactions', 'Physiological', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Scientist', 'Site', 'Slice', 'Software Tools', 'Specificity', 'Stains', 'Standardization', 'Stress Tests', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tracer', 'Training', 'United States National Institutes of Health', 'Viral', 'Visualization', 'annotation  system', 'automated segmentation', 'base', 'cloud based', 'cognitive system', 'computing resources', 'density', 'imaging modality', 'interest', 'interoperability', 'laptop', 'large datasets', 'light microscopy', 'multimodality', 'neurovascular', 'performance site', 'programs', 'reconstruction', 'relating to nervous system', 'skills', 'software development', 'terabyte', 'three-dimensional visualization', 'tool', 'two-photon', 'user-friendly', 'web site', 'web-based tool']",NIMH,PRINCETON UNIVERSITY,RF1,2021,1634528
"Linking genetics to cellular behavior and disease via multimodal data integration Project Summary / Abstract Studies of mechanisms underlying genetic associations with disease have primarily focused on gene regulatory mechanisms. In contrast, the impact of genetic variation on cellular phenotypes such as morphology and behavior is poorly understood, despite their importance in disease progression. This poor understanding is in part because measurement of some cellular phenotypes such as electrophysiological response patterns require skilled manual labor and is performed cell by cell, and is thus low throughput. Furthermore, some cellular phenotype assays require live cells, which for cell types such as neurons are prohibitively challenging to obtain from humans. The goal of this proposal is to develop deep learning-based frameworks for characterizing how molecular and cellular phenotypes covary using multimodal datasets, then to predict how these cellular behaviors mediate the effect of genetic variation on the risk of illnesses such as psychiatric and neurodevelopmental disorders. We will achieve this overall goal through the development of three frameworks. Multimodal models linking molecular and cellular phenotypes of cells. By linking gene regulation with cellular phenotypes such as neuron electrophysiology and morphology, we can then understand how changes at the molecular level propagate to cellular phenotypes and vice versa. Furthermore, we can use these models to impute cellular phenotypes when they cannot be measured experimentally. Identification of cellular phenotypes that mediate genetic risk of mental disorders. We will jointly model genotype, gene expression, cellular phenotypes and disease risk to generate mechanistic hypotheses about the mediation of genetic effects on disease risk through cellular phenotypes. Prediction of cellular phenotypes associated with disease progression. We will develop a prediction framework for exploring which cellular phenotypes change significantly with disease progression. By applying our imputation framework developed above, we will predict changes in neuron electrophysiological response and morphology associated with a range of psychiatric and neurodevelopmental disorders. We expect completion of this project to yield generalizable computational frameworks for linking genetics to molecular and cellular phenotypes for diverse cell types and organs. Project Narrative A large number of gene mutations that are associated with disease risk have been identified for diverse diseases. Hypotheses about how these mutations confer disease risk and their effects on cells and tissues are needed in order to prioritize therapeutic targets for intervention. This study proposes computational frameworks for identifying gene mutations that affect cellular behaviors of individual human cells, therefore enabling prioritization of therapeutic targets.",Linking genetics to cellular behavior and disease via multimodal data integration,10246113,DP2MH129987,"['Affect', 'Behavior', 'Biological Assay', 'Cells', 'Development', 'Disease', 'Disease Progression', 'Electrophysiology (science)', 'Gene Expression', 'Gene Expression Regulation', 'Gene Mutation', 'Genetic', 'Genetic Risk', 'Genetic Variation', 'Genotype', 'Goals', 'Human', 'Individual', 'Intervention', 'Link', 'Manuals', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mental disorders', 'Modeling', 'Molecular', 'Morphology', 'Mutation', 'Neurodevelopmental Disorder', 'Neurons', 'Organ', 'Pattern', 'Phenotype', 'Regulator Genes', 'Risk', 'Tissues', 'base', 'cell behavior', 'cell type', 'computer framework', 'data integration', 'deep learning', 'disorder risk', 'genetic association', 'multimodal data', 'multimodality', 'response', 'therapeutic target']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,DP2,2021,1431500
"Computational methods for optimized biologics formulation Project Summary: Protein-based biologics – therapeutics whose active ingredient is a protein and most commonly a monoclonal antibody (mAb) – make up a $200 billion/year market that is expected to double in size by 2025. A critical component in the safety and efficacy of biologics is the need to maintain the active protein during long-term storage and subsequent injection/infusion. The selection of excipients and buffers toward this end is termed “formulation.” Proper formulation of a protein-based drug is essential to stabilize the active protein from unfolding and to block sites on the folded protein that may pose an aggregation risk and lead to elevated viscosity due to undesirable protein-protein interactions (PPI). Importantly, formulation can be done without altering the sequence of (i.e. re-engineering) the protein and is thus an independent tool for bringing a biologic therapeutic to market. Current approaches to choosing an optimized formulation are either low-throughput experiments or computational methods that do not take into account the molecular details of excipient-protein interactions. The established Site Identification by Ligand Competitive Saturation (SILCS) computational platform technology maps the affinity pattern of the complete 3D surface of a protein for a wide diversity of chemical functional groups. The functional group affinity pattern is then used to determine excipients that can bind to and stabilize the active, folded conformation of a protein and bind to regions of the protein that may participate in PPI, thereby inhibiting aggregation and decreasing viscosity. The broad goal of the proposal is the continued development and validation of SILCS-Biologics as an industry-ready workflow and a graphical user interface to manage and apply the extensive information generated by SILCS excipient screening and PPI analysis. In the proposed studies experimental efforts will be undertaken to generate data for model training and validation across a variety of proteins and commonly used excipients. That data will be then combined with computed SILCS metrics including excipient binding locations and affinities and potential regions that can participate in PPI across the complete protein surface, including the impact of pH and the unique properties of Arginine as an excipient. This information will then be applied in the context of machine learning to develop models that will predict excipients that will block PPI thereby lowering viscosity and slowing aggregation as well as stabilize the folded, biologically active state of the protein. The proposed models will be validated at the University of Maryland, Baltimore and with industrial and government partners against established experimental methods on a range of proteins with various therapeutic indications. Upon successful completion of the project new offerings will be added to the existing SILCS software suite that will minimize the time and costs requirements for the formulation of biologics as well as lead to improved formulations thereby improving clinical outcomes. These capabilities will be implemented in the context of industry-ready workflows for direct sale to pharmaceutical companies and for use in contract research for the optimized formulation of biologics. Project Narrative: Biopharmaceuticals, including monoclonal antibodies, represent a growing and important area of new therapeutic agent development, but the formulation of biopharmaceuticals remains a bottleneck. Proposed is the continuation of a successful Phase 1 effort to use a rational formulation design technology using computational methods to allow screening of a large number of excipient/buffer combinations that will result in accelerated and improved biopharmaceutical development thereby facilitating bringing these agents to market as well as improving clinical outcomes.",Computational methods for optimized biologics formulation,10257518,R44GM130198,"['3-Dimensional', 'Address', 'Adoption', 'Affinity', 'Area', 'Arginine', 'Baltimore', 'Behavior', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological', 'Biological Products', 'Biological Response Modifier Therapy', 'Buffers', 'Chemicals', 'Clinical', 'Code', 'Collaborations', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Engineering', 'Excipients', 'FDA approved', 'Failure', 'Formulation', 'Goals', 'Government', 'Growth', 'Human', 'Industrialization', 'Industry', 'Insulin', 'Lead', 'Letters', 'Ligands', 'Location', 'Lysine', 'Machine Learning', 'Maps', 'Maryland', 'Membrane Proteins', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Monoclonal Antibodies', 'Outcome', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Probability', 'Property', 'Protein Engineering', 'Protein Region', 'Proteins', 'Recombinants', 'Research Contracts', 'Risk', 'Role', 'Safety', 'Sales', 'Site', 'Structure', 'Surface', 'Technology', 'Therapeutic', 'Time', 'Training', 'Universities', 'Validation', 'Viscosity', 'Work', 'base', 'commercialization', 'computational platform', 'cost', 'design', 'experimental study', 'flexibility', 'functional group', 'graphical user interface', 'improved', 'injection/infusion', 'insight', 'novel therapeutics', 'phase 1 study', 'prevent', 'protein folding', 'protein protein interaction', 'protein structure', 'screening', 'success', 'therapeutic development', 'three dimensional structure', 'tool', 'trend', 'usability']",NIGMS,"SILCSBIO, LLC",R44,2021,885774
"Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics The human microbiota plays an important role in health and disease, and its therapeutic manipulation is being actively investigated for a wide range of diseases that span every NIH institute. Our microbiota are inherently dynamic, and analyzing these time-dependent properties is key to robustly linking the microbiota to disease, and predicting the effects of therapies targeting the microbiota; indeed, longitudinal microbiome data is being acquired with increasing frequency, and is a major component of many NIH-funded projects. However, there is currently a dearth of computational tools for analyzing microbiome time-series data, which presents several special challenges including high measurement noise, irregular and sparse temporal sampling, and complex dependencies between variables. The objective of this proposal is to introduce new capabilities, improve on, and provide state-of-the-art implementations of tools for analyzing dynamics, or patterns of change in microbiome time-series data. The tools we develop will use Bayesian machine learning methods, which are well-recognized for their strong conceptual and practical advantages, particularly in biomedical domains. Tools will be rigorously tested and validated on synthetic and real human microbiome data, including publicly available datasets and those from collaborators providing 16S rRNA sequencing, metagenomic, and metabolomics data. We propose three specific aims. For Aim 1, we will develop integrated Bayesian machine learning tools for predicting population dynamics of the microbiome and its responses to perturbations. These tools will include a new model that simultaneously learns groups of microbes with similar interaction structure and predicts their behavior over time, and that incorporates prior phylogenetic information. The model will be further improved by incorporating stochastic microbial dynamics and errors in measurements throughout the model. For Aim 2, we will develop Bayesian machine learning tools to predict host status from microbiome dynamics. The tools will learn easily interpretable, human-readable rules that predict host status from microbiome time-series data, and will be further extended to handle a variety of longitudinal study designs. For Aim 3, we will engineer our microbiome dynamics analysis software tools for optimal performance, ease-of- use, maintainability, extensibility, and dissemination to the community. In total, the proposed work will yield a suite of contemporary software tools for analyzing microbiome dynamics, with expected broad use and major impact. The software will allow investigators to answer important scientific and translational questions about the microbiome, including discovering which microbial taxa or their metagenomes are affected over time by perturbations such as changes in diet or invasion by pathogens; predicting the effects of these perturbations over time, including changes in composition or stability of the gut microbiota; and finding temporal signatures in multi-‘omic microbiome data that predict disease risk in the human host. The human microbiota, or collection of micro-organisms living on and within us, plays an important role in health, and when disrupted or abnormal, may contribute to many types of diseases including infections, kidney diseases, bowel diseases, diabetes, heart diseases, arthritis, allergies, brain diseases, and cancer. Sophisticated computer-based tools are needed to make sense of human microbiota data, particularly time- series data, which can yield important insights into how our microbiomes change over time. This work will develop new and improved computer-based tools for analyzing microbiota time-series data, which will be made freely available and will enable scientists to increase our fundamental knowledge about how our microbiota affect us and ultimately to apply this knowledge to prevent and treat human illnesses.",Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics,10245080,R01GM130777,"['16S ribosomal RNA sequencing', 'Affect', 'Algorithms', 'Antibiotics', 'Arthritis', 'Autoimmunity', 'Bayesian learning', 'Behavior', 'Biological Markers', 'Biological Models', 'Brain Diseases', 'Cardiovascular Diseases', 'Childhood', 'Clostridium difficile', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Dependence', 'Diabetes Mellitus', 'Diet', 'Disease', 'Engineering', 'Environmental Exposure', 'Frequencies', 'Funding', 'Health', 'Heart Diseases', 'Human', 'Human Microbiome', 'Hypersensitivity', 'Infection', 'Institutes', 'Intervention', 'Intestines', 'Investigation', 'Kidney Diseases', 'Knowledge', 'Learning', 'Link', 'Longitudinal Studies', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Metagenomics', 'Microbe', 'Modeling', 'Names', 'Noise', 'Oligosaccharides', 'Outcome', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Play', 'Population Dynamics', 'Property', 'Pythons', 'Readability', 'Research Design', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Series', 'Shotguns', 'Software Engineering', 'Software Tools', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Work', 'base', 'computerized tools', 'design', 'dietary', 'disorder risk', 'dynamic system', 'gut microbiota', 'human data', 'human microbiota', 'human subject', 'implementation tool', 'improved', 'insight', 'learning algorithm', 'machine learning method', 'man', 'metabolomics', 'metagenome', 'microbial', 'microbiome', 'microbiome analysis', 'microbiome sequencing', 'microbiota', 'microorganism', 'nervous system disorder', 'novel', 'open source', 'pathogen', 'predictive tools', 'prevent', 'recurrent infection', 'response', 'software development', 'targeted treatment', 'tool']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,312939
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227
"A computational modeling framework for COVID-19 vaccination Project Summary/Abstract Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), remains a global pandemic at present. Quantitative research is urgently needed to clarify the impacts of the current vaccination campaign on the pandemic evolution and economic growth, and to guide future policy development. The overall objective of this proposal is to establish a new computational modeling framework for an investigation of the COVID-19 vaccination campaign in the US, and to incorporate real data to assess the impacts of COVID-19 vaccination on public health and the economy. To achieve this objective, the team will pursue three specific aims: (1) Modeling the transmission and spread of COVID-19 under the impact of vaccination; (2) Modeling the economic impact of COVID-19 vaccination; (3) Conducting a case study for the Chattanooga region in the state of Tennessee. The proposed research is significant because it will incorporate detailed characteristics and potential limitations of the current vaccination campaign (such as the vaccine efficacy, phased allocation schemes, public resistance to vaccination, and vaccine breakthrough due to new variants of SARS- CoV-2) into a sophisticated modeling framework, which will enable us to make more accurate forecasts on the progression and long-term evolution of the pandemic. As such, the project is expected to advance the current understanding of COVID-19 transmission and to quantify the interaction between epidemic spreading, economic growth, and disease prevention and intervention under the impact of COVID-19 vaccination, all of which are important for the control and management of the pandemic. The approach is innovative in the development of a computational framework that integrates novel mechanistic and machine learning models and that connects the epidemic and economic aspects of COVID-19. The innovation of this project is also reflected by the integration of sophisticated computational modeling, rigorous mathematical analysis, intensive numerical simulation, and detailed data validation. The project represents an interdisciplinary collaboration among an applied and computational mathematician with long-term interest in infectious disease modeling (Wang), an epidemiologist with extensive working experiences at CDC and a current member of the regional COVID-19 task force (Heath), a business and management professor with a background in public heath (Mullen), and a statistician with expertise in machine learning and biomedical data analytics (Ma). The success of this project will not only build a solid knowledge base for the complex transmission dynamics of SARS-CoV-2 and the health and economic impacts of COVID-19 vaccination, but also provide important guidelines for the government agencies and public health administrations in pandemic management and policy development. Project Narrative The proposed project is relevant to public health because a deep understanding of the COVID-19 vaccination campaign and its health and economic impacts will help to inform the pandemic management and improve the current practice in disease prevention and intervention. The mathematical and machine learning models developed in this project will improve such understanding and make new knowledge discovery. This research effort aligns with part of NIH's mission to reduce public health burdens of infectious diseases.",A computational modeling framework for COVID-19 vaccination,10376956,R15GM131315,"['2019-nCoV', 'Address', 'Advisory Committees', 'Attention', 'Businesses', 'COVID-19', 'COVID-19 vaccination', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical Research', 'Collaborations', 'Communicable Diseases', 'Complement', 'Complex', 'Computer Models', 'Computer Simulation', 'Country', 'County', 'Coupled', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Differential Equation', 'Economic Factors', 'Economic Models', 'Economics', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evolution', 'Foundations', 'Future', 'Goals', 'Government Agencies', 'Growth', 'Guidelines', 'Health', 'Immunization Programs', 'Intervention', 'Investigation', 'Joints', 'Knowledge Discovery', 'Machine Learning', 'Mathematics', 'Mission', 'Modeling', 'Persons', 'Phase', 'Policy Developments', 'Public Health', 'Public Health Administration', 'Research', 'Resistance', 'Route', 'SARS-CoV-2 transmission', 'SARS-CoV-2 variant', 'Scheme', 'Schools', 'Science', 'Solid', 'Techniques', 'Tennessee', 'Theoretical Studies', 'Unemployment', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'computer framework', 'disorder prevention', 'dynamic system', 'economic impact', 'economic indicator', 'experience', 'experimental study', 'health economics', 'improved', 'infectious disease model', 'innovation', 'interdisciplinary collaboration', 'interest', 'knowledge base', 'mathematical analysis', 'mathematical learning', 'mathematical model', 'member', 'novel', 'pandemic disease', 'professor', 'simulation', 'success', 'transmission process', 'vaccine efficacy']",NIGMS,UNIVERSITY OF TENNESSEE CHATTANOOGA,R15,2021,122580
"Continuous Probing of Nanoconstruct-Cell Interactions at Biologically Relevant Time Scales PROJECT SUMMARY  This proposal aims to develop live-cell, multi-channel imaging tools that can visualize—continuously, and in real time—nanoparticle interactions with cellular components. We will focus on several different time windows, where early time periods will monitor nanoparticle-cell membrane binding and uptake and later times will track endosomal accumulation and escape. The ability to resolve temporally and spatially how particle size/shape and ligand density affects interactions in 3D is critical for determining structure-activity-relationships and mechanism of action in live cells. To characterize interactions of functional nanoparticles with different cellular structures at physiologically relevant times, we propose to design a multi-channel optical microscope integrated with an opto- splitter and custom live-cell imaging chamber. Simultaneous images can be acquired in different channels of the fluorescence of dye-labeled organelles and dye-labeled ligands on the particles as well as differential interference contrast (DIC) signals of whole cells, cellular components, and nanoparticle cores. Correlation of structural and functional images provides a powerful window into how local nanoconstruct interactions can mediate a biological response. For model systems, we will compare gold nanoconstructs with oligonucleotide ligand shells of both targeting (DNA aptamers) or non-targeting (siRNA) properties. Nanoparticle shape enables a unique handle to probe rotation and orientation of intracellular particle interactions. This work can bridge a gap in understanding the behavior of nanoconstructs intracellularly and how the integrity and presentation of oligonucleotides in ligand shells affects targeting and other processes such as endosomal escape, which is critical to assess therapeutic efficacy. RELEVANCE TO PUBLIC HEALTH  This proposal aims to design tools that can visualize nanoparticle interactions with cells at distinct time points with biological relevance. Our ultimate goal is to evaluate how nanoconstructs interact with cellular membranes and sub-cellular components. Such results may impact how nanoparticle shape and ligand density can inform design of particle-based drug delivery agents.",Continuous Probing of Nanoconstruct-Cell Interactions at Biologically Relevant Time Scales,10245134,R01GM131421,"['3-Dimensional', 'Affect', 'Behavior', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Cell Communication', 'Cell membrane', 'Cells', 'Cellular Membrane', 'Cellular Structures', 'Chemicals', 'Chemistry', 'Clinical Trials', 'Complex', 'Custom', 'DNA', 'Diagnostic', 'Drug Delivery Systems', 'Dyes', 'Endosomes', 'Environment', 'Eukaryotic Cell', 'Event', 'FDA approved', 'Fluorescence', 'Functional Imaging', 'Glioblastoma', 'Goals', 'Gold', 'Image', 'Imaging Device', 'Immune response', 'Label', 'Ligands', 'Lipid Bilayers', 'Mediating', 'Membrane', 'Membrane Proteins', 'Microscope', 'Microscopy', 'Molecular', 'Monitor', 'Multimodal Imaging', 'Multiple Partners', 'Nomarski Interference Contrast Microscopy', 'Nucleic Acids', 'Oligonucleotides', 'Optics', 'Organelles', 'Particle Size', 'Physiological', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Public Health', 'Raman Spectrum Analysis', 'Role', 'Rotation', 'Shapes', 'Signal Transduction', 'Small Interfering RNA', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'aptamer', 'base', 'density', 'design', 'experimental study', 'in vivo', 'insight', 'interest', 'live cell imaging', 'machine learning algorithm', 'multimodality', 'nanoparticle', 'nanoparticle drug', 'nanoprobe', 'nanoscale', 'optical imaging', 'particle', 'plasmonics', 'programs', 'response', 'simulation', 'tool', 'trafficking', 'tumor', 'uptake']",NIGMS,NORTHWESTERN UNIVERSITY,R01,2021,197807
"EFFICIENT METHODS FOR CALIBRATION, CLUSTERING, VISUALIZATION AND IMPUTATION OF LARGE scRNA-seq DATA Single cell RNA-seq (scRNA-seq) profiling provides an unprecedented opportunity to conduct detailed cellular analysis of cell subpopulations. Fulfilling the promise of scRNA-seq for biomedical studies and biomarker discovery requires robust computational approaches to support detection of rare phenotypes and unanticipated cellular responses. Current approaches for imputation, calibration, clustering and visualizing of scRNA-seq data suffer from challenges such as erroneous imputing of non-expressed genes, limitation of linear assumptions in removal of multivariate batch effects, and inefficiencies of clustering and dimensional reduction methods of very large datasets. We have developed spectral, neural network, and Fast Multipole Methods (FMM) prototypes suitable for addressing these issues in the context of scRNA-seq and other high throughput data contexts and propose to further develop and adapt these methods to scRNA-seq data analysis. Our team of experts on data analytics and computational biology is currently funded through the NIH BD2K initiative to develop novel big data tools and methods that have broad applicability to biomedical science. This effort proved the feasibility of extremely efficient scalable prototypes of neural network, spectral, and harmonic analysis techniques suitable for calibrating, reducing the dimensionality and visualizing high dimensional data, finding intrinsic state-probability densities, and co-organizing cells, markers and samples. We propose substantial advances over existing analytical procedures used in single cell RNA-seq studies including matrix recovery approaches for the sparse and noisy scRNA-seq data by combining matrix completion and statistical techniques (Aim 1A), and calibration based on our unsupervised MMD-ResNet neural network prototype and optimal transport theory (Aim 1B). We will develop a variant of the FMM approach to speed up the calculation of the repulsion term of the t-distributed stochastic neighbor embedding (t-SNE) visualization technique, which will improve our current fastest t-SNE FFT-based FIt-SNE prototype, and develop new reliable approximate nearest neighbors approaches to speed up the computation of the attraction term of t-SNE and other clustering algorithms (Aim 2A). Our additional variants of t-SNE will be further developed to allow better separation between clusters of cell subpopulations (late exaggeration) and better visualization using 1D t-SNE for heatmap gene-cell representation (Aim 2A). We will adapt SpectralNet, our efficient neural network approach, for computing graph Laplacian eigenvectors for large datasets. This will enable computation of spectral clustering, diffusion maps and manifold learning that are utilized in many scRNA studies but are currently limited to a moderate number of single cells (Aim 2B). Finally, we will develop a kernel based differential abundance algorithm to characterize differences between biological conditions (Aim 2C). We will adopt appropriate sampling approaches to significantly improve current methods. This research plan aims at developing scalable spectral computational and neural network tools suitable for analyzing very large single cell RNA sequencing datasets. Specifically, our team which is led by a computational biologist, two prominent applied mathematicians and two prominent biologists will develop and validate scalable and novel techniques for: (i) completing missing values prevalent in these measurements, (ii) removing batch effect, (iii) reducing dimensionality and visualizing very large single cell RNA sequencing datasets and enabling detection of rare cell populations as well as detecting minute changes of cell populations between biological conditions. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page","EFFICIENT METHODS FOR CALIBRATION, CLUSTERING, VISUALIZATION AND IMPUTATION OF LARGE scRNA-seq DATA",10126872,R01GM131642,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Attenuated', 'Benchmarking', 'Big Data Methods', 'Big Data to Knowledge', 'Biological', 'Biology', 'Calibration', 'Cells', 'Computational Biology', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Detection', 'Diffusion', 'Dimensions', 'Dropout', 'Emerging Technologies', 'Excision', 'Funding', 'Generations', 'Genes', 'Genomic approach', 'Graph', 'Immune', 'Laplacian', 'Learning', 'Maps', 'Measurement', 'Methods', 'Modality', 'Neurons', 'Noise', 'Pathogenesis', 'Phenotype', 'Population', 'Probability', 'Procedures', 'Recovery', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Series', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visualization', 'analytical method', 'artificial neural network', 'base', 'biomarker discovery', 'cell type', 'computerized tools', 'deep learning', 'deep neural network', 'density', 'experimental study', 'hematopoietic differentiation', 'human disease', 'improved', 'insight', 'kernel methods', 'large datasets', 'learning network', 'multidimensional data', 'neural network', 'novel', 'prototype', 'response', 'single cell analysis', 'single-cell RNA sequencing', 'theories', 'tool', 'transcriptome sequencing']",NIGMS,YALE UNIVERSITY,R01,2021,400846
"Antibody repertoire characterization in the context of coronaviruses Project Summary. SARS-CoV-2, or the 2019 novel coronavirus, is a significant pandemic threat that has resulted in hundreds of thousands of diagnosed cases and tens of thousands of mortalities as of March 2020. The development of preventive and therapeutic measures that can counteract the ongoing, and any future, coronavirus pandemics is therefore of utmost significance for public health worldwide. The S protein is the immunodominant region of coronaviruses (CoV) recognized by the immune system and serves as the target for a number of neutralizing antibodies. Passive transfer of neutralizing antibodies has been shown to prevent coronavirus infection in animal models. Further, engineered prefusion-stabilized S protein immunogens have been shown to elicit high titers of coronavirus-neutralizing antibodies in animal models, in the context of MERS. Together, this prior work establishes a strong premise for targeting the identification and characterization of neutralizing antibodies in the context of SARS-CoV-2. More generally, a better understanding of the human antibody response to the S protein of SARS-CoV-2 as well as other related CoV members can help inform therapeutic antibody optimization and accelerate vaccine design efforts.  Our laboratory recently developed the LIBRA-seq technology (LInking B-cell Receptor to Antigen specificity through sequencing) for antibody discovery and characterization of antigen-specific antibody repertoires. Unlike other B cell approaches, LIBRA-seq is the first to enable the simultaneous determination of BCR sequence and antigen specificity for a large number of B cells against a theoretically unlimited number of diverse antigens, at the single-cell level. LIBRA-seq therefore provides a unique opportunity for characterizing the types and specificities of antibodies that can recognize the S protein from SARS-CoV-2, as well as other CoV viruses.  Here, we propose to utilize the LIBRA-seq technology in the context of SARS-CoV-2, with two major goals: (1) To identify cross-reactive antibodies that recognize multiple antigen variants associated with human coronavirus infection, including SARS-CoV-2, SARS-CoV-1, and MERS-CoV, and (2) To evaluate the ability of current lead CoV vaccine candidates to engage with antibody repertoires from healthy individuals.  Taken together, the efforts proposed in this application will be of high potential translational/clinical impact for SARS-CoV-2 and other CoV pathogens of biomedical significance. The types of antibody repertoire characterization that we propose to develop here will also be readily generalizable to other pathogens, and as such, will have a broad and lasting impact on the development of countermeasures for established and emerging infectious diseases. Project Narrative  The development of preventive and therapeutic measures that can counteract the ongoing, and any future, coronavirus pandemics is of utmost significance for public health worldwide. Here, we propose to focus on the identification of coronavirus-specific antibodies as potential countermeasures against coronaviruses, by utilizing a powerful antibody discovery technology recently developed by our group. Our efforts will be readily generalizable to other pathogens, and as such, will have a broad and lasting impact on the development of countermeasures for established and emerging infectious diseases.",Antibody repertoire characterization in the context of coronaviruses,10266227,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,673335
"Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes Project summary In contract to sexual organisms, the mechanisms of population genetics in bacteria are far less understood. Two fundamental aspects of bacterial population genetics remain sorely understudied: i) the impact of DNA exchange on the evolution of bacterial genomes and populations is largely unknown. ii) the prominence of adaptive evolution has not been comprehensively assessed in bacteria. Determining how recombination and adaptive evolution impact bacteria is key to understand the biology of these organisms and to develop relevant models of their evolution. Although bacteria reproduce clonally, there is increasing evidence that the vast majority of these organisms are capable of homologous recombination by exchanging pieces of DNA in a process similar to gene conversion in animals and plants. This process enhances microbial capacity to adapt to stresses or changing environments and the exchange of DNA between bacterial strains is a major concern for human health as exemplified by the transfer of virulence and antibiotic resistance genes. Despite the central role of this process, the rates and patterns of recombination remain unresolved in bacteria. The extent of recombination often varies greatly from one study to another and, as a result, the same bacterial species can be perceived as clonal in one study and highly recombining in another. In this project, we propose to re-evaluate the landscape of recombination rates and patterns along the genomes of hundreds of bacterial species. Using new methodological frameworks based on Approximate Bayesian Computation and Deep Learning, we will identify the factors shaping the variation in recombination rate across bacteria. We will also uncover recombination rate variation across bacterial chromosomes (i.e. hot spots and cold spots). Our rate estimates will also allow us to study how recombination drives the evolution of genomic architecture of bacteria, including turnover in gene content. Finally, we will quantify the impact of adaptive evolution in bacteria, which may be substantially larger than in other organisms due to large bacterial effective population sizes. We will also investigate the relationship between adaptation and recombination, and identify the genes/pathways responsible for adaptation. In summary, this study will evaluate the rates and patterns of recombination across hundreds of species, determine the factors driving the evolution of the recombination process, reveal the role of adaptive evolution in bacteria, and the interplay between recombination and adaptation. Project narrative Homologous recombination and adaptive evolution are key mechanisms driving bacterial adaptation to new environments and new treatments. The proposed study aims to apply new approaches to determine the rates and patterns of recombination across genomic data in order to identify the factors shaping the rates and landscapes of recombination as well as the impact of adaptive evolution on bacteria. Upon completion, this project will provide a global view of the interplay between recombination and adaptative evolution across hundreds of bacterial species.",Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes,10135120,R01GM132137,"['Address', 'Affect', 'Animals', 'Antibiotic Resistance', 'Architecture', 'Automobile Driving', 'Bacteria', 'Bacterial Chromosomes', 'Bacterial Genome', 'Bacterial Infections', 'Bayesian Analysis', 'Biology', 'Chromosomes', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Contracts', 'DNA', 'Data Set', 'Ecology', 'Elements', 'Environment', 'Epidemic', 'Evolution', 'Fibrinogen', 'Frequencies', 'Gene Conversion', 'Genes', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomics', 'Health', 'Hot Spot', 'Human', 'Individual', 'Knowledge', 'Laboratories', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Organism', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Prokaryotic Cells', 'Recombinants', 'Role', 'Sampling', 'Shapes', 'Spottings', 'Stress', 'Structure', 'Testing', 'Time', 'Variant', 'Virulence', 'Virulent', 'Work', 'base', 'deep learning', 'gene function', 'genome analysis', 'genomic data', 'high throughput screening', 'homologous recombination', 'innovation', 'large datasets', 'microbial', 'novel strategies', 'resistance gene', 'tool', 'trait']",NIGMS,UNIVERSITY OF NORTH CAROLINA GREENSBORO,R01,2021,289206
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,10231149,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2021,287379
"Machine learning approaches for improved accuracy and speed in sequence annotation: supplement for software enhancement Summary The goal of this parent grant for this supplement request is to develop Machine Learning approaches to improve both accuracy and speed of highly-sensitive sequence database search and alignment. We have developed three software tools associated with this effort of correctly annotating genomes: (i) ULTRA, which labels repetitive sequence, (ii) PolyA which integrates such labels with other sequence annotations in a probabilistic framework, computing uncertainty and improving accuracy, and (iii) SODA, which aids in visualization of annotations and supporting evidence. Here, we describe a plan to refactor these software tools and their documentation to improve robustness and reliability, and to improve their availability through package management systems and incorporation into cloud-based analysis frameworks. Narrative This proposal describes a plan to improve the quality of existing software from the Wheeler lab that supports accurate annotation of biological sequences (ULTRA and PolyA), and visualization of such annotation (SODA). The emphasis of this effort is on software engineering, documentation, and package management, with a specific plan to prepare the tools for use in the cloud.",Machine learning approaches for improved accuracy and speed in sequence annotation: supplement for software enhancement,10406630,R01GM132600,"['Address', 'Biological', 'Centromere', 'Classification', 'Cloud Computing', 'Complex', 'Computer software', 'Consensus', 'DNA Transposable Elements', 'Data', 'Development', 'Documentation', 'Elements', 'Error Sources', 'Galaxy', 'Genetic Recombination', 'Genome', 'Goals', 'Human', 'Label', 'Libraries', 'Machine Learning', 'Maintenance', 'Methods', 'Modernization', 'Molecular Biology', 'Output', 'Parents', 'Pathway interactions', 'Pattern', 'Process', 'Repetitive Sequence', 'Reporting', 'Sequence Alignment', 'Sequence Analysis', 'Software Engineering', 'Software Tools', 'Source', 'Speed', 'Structure', 'System', 'Testing', 'Uncertainty', 'Visualization', 'adjudicate', 'base', 'cloud based', 'genome annotation', 'improved', 'molecular sequence database', 'parent grant', 'searchable database', 'software development', 'support tools', 'telomere', 'tool', 'web server']",NIGMS,UNIVERSITY OF MONTANA,R01,2021,221904
"Determining the scope of prenylatable protein sequences PROJECT SUMMARY This study investigates the specificity of farnesyl transferase (FTase) that isoprenylates CaaX proteins. Studies probing the in vivo activity of the FTase have historically used reporters (e.g. Ras GTPases) that undergo complex multi-step post-translational modification (PTM), involving initial farnesylation followed by CaaX proteolysis and carboxyl methylation. This study takes advantage of Hsp40 Ydj1, a farnesylation-only reporter for which we have developed a range of methods to monitor its PTM status. Its use reveals that farnesylation is not necessarily coupled to subsequent PTMs as has been generally accepted for CaaX proteins, and that FTase specificity is significantly more promiscuous than anticipated. These findings challenge the conventional paradigm for how farnesylated proteins are modified and which proteins are targeted by FTase. We will extend our studies to fully resolve the specificity of FTase using a combination of genetic, biochemical, bioinformatic, and biophysical studies. We bring to bear on our investigations an exceptionally strong set of preliminary findings, the complementary expertise of several research groups, and a comprehensive molecular toolbox for the study of farnesylated proteins and other enzymes associated with this post-translational modification pathway. PROJECT NARRATIVE Farnesylated proteins are intimately involved in disease. This project investigates the target specificity of the farnesyl transferase that mediates protein farnesylation. Our results are expected to help shape ongoing efforts aimed at targeting the farnesyl transferase for therapeutic benefit in a variety of diseases.",Determining the scope of prenylatable protein sequences,10218213,R01GM132606,"['Address', 'Amino Acid Sequence', 'Amino Acids', 'Belief', 'Biochemical', 'Bioinformatics', 'Biological', 'Biology', 'CENP-E protein', 'Charge', 'Complex', 'Consensus', 'Coupled', 'Cysteine', 'Data', 'Disease', 'Enzymes', 'Frequencies', 'Genetic', 'Guanosine Triphosphate Phosphohydrolases', 'Human', 'In Vitro', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Mediating', 'Membrane', 'Methods', 'Methylation', 'Modification', 'Molecular', 'Molecular Chaperones', 'Monitor', 'Nuclear Lamin', 'Online Systems', 'Partner in relationship', 'Pathway interactions', 'Phenotype', 'Pheromone', 'Phosphotransferases', 'Positioning Attribute', 'Post Translational Modification Analysis', 'Post-Translational Protein Processing', 'Prevalence', 'Property', 'Protein Farnesylation', 'Proteins', 'Proteolysis', 'Reporter', 'Reporting', 'Research', 'Shapes', 'Specificity', 'Testing', 'Therapeutic', 'Ursidae Family', 'Yeasts', 'base', 'biophysical analysis', 'farnesylation', 'genetic selection', 'in vivo', 'isoprenylation', 'next generation sequencing', 'prediction algorithm', 'prevent', 'protein farnesyltransferase', 'protein function', 'protein geranylgeranyltransferase', 'protein protein interaction', 'ras-Related G-Proteins']",NIGMS,UNIVERSITY OF GEORGIA,R01,2021,388631
"Novel Statistical Inference for Biomedical Big Data Project Summary This project develops novel statistical inference procedures for biomedical big data (BBD), including data from diverse omics platforms, various medical imaging technologies and electronic health records. Statistical inference, i.e., assess- ing uncertainty, statistical signiﬁcance and conﬁdence, is a key step in computational pipelines that aim to discover new disease mechanisms and develop effective treatments using BBD. However, the development of statistical inference procedures for BBD has lagged behind technological advances. In fact, while point estimation and variable selection procedures for BBD have matured over the past two decades, existing inference procedures are either limited to simple methods for marginal inference and/or lack the ability to integrate biomedical data across multiple studies and plat- forms. This paucity is, in large part, due to the challenges of statistical inference in high-dimensional models, where the number of features is considerably larger than the number of subjects in the study. Motivated by our team's extensive and complementary expertise in analyzing multi-omics data from heterogenous studies, including the TOPMed project on which multiple team members currently collaborate, the current proposal aims to address these challenges. The ﬁrst aim of the project develops a novel inference procedure for conditional parameters in high-dimensional models based on dimension reduction, which facilitates seamless integration of external biological information, as well as biomedical data across multiple studies and platforms. To expand the application of this method to very high-dimensional models that arise in BBD applications, the second aim develops a data-adaptive screening procedure for selecting an optimal subset of relevant variables. The third aim develops a novel inference procedure for high-dimensional mixed linear models. This method expands the application domain of high-dimensional inference procedures to studies with longitu- dinal data and repeated measures, which arise commonly in biomedical applications. The fourth aim develops a novel data-driven procedure for controlling the false discovery rate (FDR), which facilitates the integration of evidence from multiple BBD sources, while minimizing the false negative rate (FNR) for optimal discovery. Upon evaluation using ex- tensive simulation experiments and application to multi-omics data from the TOPMed project, the last aim implements the proposed methods into easy-to-use open-source software tools leveraging the R programming language and the capabilities of the Galaxy workﬂow system, thus providing an expandable platform for further developments for BBD methods and tools. Public Health Relevance Biomedical big data (BBD), including large collections of omics data, medical imaging data, and electronic health records, offer unprecedented opportunities for discovering disease mechanisms and developing effective treatments. However, despite their tremendous potential, discovery using BBD has been hindered by computational challenges, including limited advances in statistical inference procedures that allow biomedical researchers to investigate uncon- founded associations among biomarkers of interest and various biological phenotypes, while integrating data from multiple BBD sources. The current proposal bridges this gap by developing novel statistical machine learning methods and easy-to-use open-source software for statistical inference in BBD, which are designed to facilitate the integration of data from multiple studies and platforms.",Novel Statistical Inference for Biomedical Big Data,10252023,R01GM133848,"['Address', 'Adoption', 'Behavioral', 'Big Data Methods', 'Biological', 'Biological Assay', 'Biological Markers', 'Code', 'Collection', 'Communities', 'Computer software', 'Data', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Galaxy', 'Genetic study', 'Goals', 'Heart', 'Imaging technology', 'Individual', 'Linear Models', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Outcome', 'Phenotype', 'Procedures', 'R programming language', 'Research Personnel', 'Sample Size', 'Scientist', 'Screening procedure', 'Software Tools', 'Structure', 'System', 'Testing', 'Trans-Omics for Precision Medicine', 'Uncertainty', 'Work', 'base', 'big biomedical data', 'computational pipelines', 'data integration', 'design', 'diverse data', 'effective therapy', 'experimental study', 'heterogenous data', 'high dimensionality', 'interest', 'machine learning method', 'member', 'novel', 'open source', 'public health relevance', 'screening', 'simulation', 'statistical and machine learning', 'structured data', 'tool', 'treatment strategy', 'user friendly software']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2021,414994
"Methods for determination of glycoprotein glycosylation similarities among disease states Abstract This application addresses NIGMS PAR-17-045 “Focused Technology Research and Development (R01)”. This initiative supports projects that focus solely on development of technologies with the potential to enable biomedical research. Dysregulation of the cellular microenvironment occurs in cancers, neurodevelopmental and neuropsychiatric diseases. Known as the matrisome, the set of extracellular matrix and cell surface molecules control the availability of growth factors to cellular receptors and the mechanical-physical properties of the cell microenvironment. Currently, the limited understanding of regulation of matrisome glycosylation hinders understanding of the roles of glycosylation-dependent matrisome networks in the basic mechanisms necessary for targeted intervention of many diseases. Matrisome function depends on networks of interaction among glycosylated proteins and glycan-binding lectins. It is not possible using present proteomics and glycoproteomics methods to compare using rigorous statistics similarities of glycoproteins that differ by disease-related changes in site-specific glycosylation. We propose to develop technologies to meet this need. Present proteomics methods quantify proteins using a few representative peptides per gene product; sequence coverage for most proteins is low. Such low sequence coverage does not suffice to reconstruct the predominant glycosylated proteoforms active in a biological context. We propose to develop technologies to compare glycoprotein similarities among biological sample sets. To do this, we will develop MS acquisition and bioinformatics methods for rapid, sensitive and reproducible mapping of glycoprotein glycosylation to enable statistically rigorous comparison of glycoprotein similarities. By making these technologies available, we will enable a new level of understanding of the roles of matrisome networks in human diseases. Project narrative The matrisome consists of glycosylated extracellular matrix and cell surface proteins that surround cells and support normal physiological activity. While it is known that glycosylation changes during disease processes, it has not been possible to quantitatively compare glycoprotein structure among biological samples. We aim to develop technologies to meet this need.",Methods for determination of glycoprotein glycosylation similarities among disease states,10194553,R01GM133963,"['Address', 'Algorithms', 'Atherosclerosis', 'Autoimmune Diseases', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Brain', 'Brain region', 'CSPG3 gene', 'Cell Surface Proteins', 'Cell surface', 'Cells', 'Chondroitin Sulfate Proteoglycan', 'Collagen', 'Complex', 'Core Protein', 'Data', 'Data Set', 'Disease', 'Dissociation', 'Electron Transport', 'Environment', 'Enzymes', 'Extracellular Matrix', 'Family', 'Functional disorder', 'Genes', 'Glycopeptides', 'Glycoproteins', 'Growth Factor', 'Growth Factor Receptors', 'Heart', 'Heparitin Sulfate', 'Intelligence', 'Intervention', 'Ions', 'Knowledge', 'Lectin', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Neurodegenerative Disorders', 'Pathway interactions', 'Peptides', 'Physiological', 'Polysaccharides', 'Process', 'Protein Glycosylation', 'Proteins', 'Proteoglycan', 'Proteomics', 'Receptor Protein-Tyrosine Kinases', 'Regulation', 'Reproducibility', 'Role', 'Sampling', 'Signal Pathway', 'Site', 'Structure', 'Technology', 'Tissues', 'aggrecan', 'bioinformatics tool', 'brevican', 'cell growth', 'data acquisition', 'data to knowledge', 'extracellular', 'gene product', 'glycoprotein structure', 'glycoproteomics', 'glycosylation', 'human disease', 'hydrophilicity', 'neuropsychiatric disorder', 'pathogen', 'physical property', 'rapid technique', 'receptor', 'statistics', 'technology development', 'technology research and development', 'versican']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2021,420750
"Repurpose open data to discover therapeutics for understudied diseases Project Summary/Abstract Many diseases are understudied because they are rare or of little public interest. The effect of each understudied disease may be limited, but the cumulative effects of all these diseases could be profound. One common research challenge for these diseases is that the resources allocated to each is often limited. For instance, large- scale screening of drugs is often challenging, if not possible, in small labs. The decreasing costs of next generation sequencing make possible the generation of gene expression profiles of understudied disease samples. Integrating these expression profiles with other open data provides tremendous opportunities to gain insights into disease mechanisms and identify new therapeutics for understudied diseases. We have utilized a systems-based approach that employs gene expression profiles of disease samples and drug-induced gene expression profiles from cancer cell lines to predict new therapeutic candidates for hepatocellular carcinoma, Ewing sarcoma and basal cell carcinoma. All these candidates were successfully validated in preclinical models. The success of this approach relies on multiscale procedures, such as quality control of disease samples, selection of appropriate reference tissues, evaluation of disease signatures, and weighting cell lines. There is a plethora of relevant datasets and analysis modules that are publicly available, yet are isolated in distinct silos, making it tedious to implement this approach in translational research. A centralized informatics system that allows prediction of therapeutics for further experimental validation is thus of great interest to researchers working on understudied diseases. Accordingly, we propose four specific aims: 1) developing novel deep learning methods to select precise reference normal tissues for disease signature creation, 2) developing computational methods to reuse drug profiles from other disease models for drug prediction, 3) integrating open efficacy data to identify new targets from the systems-based approach, and 4) developing a centralized platform and promoting the platform in the scientific community. This proposal will reuse several big open databases (e.g., TCGA, TARGET, GTEx, GEO, LINCS, CTRP, GDSC) and employ cutting-edge informatics methods (e.g., deep learning). To demonstrate the scalability of the system, we will investigate three representative understudied diseases: multiple organ dysfunction syndrome (Aim 1), diffuse intrinsic pontine glioma (Aim 2) and hepatocellular carcinoma (Aim 3). Successful implementation of the systems-based approach can be used as a model for using other large open omics (proteins, metabolites) to discover therapeutics for diseases with unmet needs. This proposal will bring together experts in informatics, statistics, computer science, and physicians from Michigan State University, Stanford University, UC Berkeley and Spectrum Health. All data and code will be released to the public for continuing development. The system will be deployed to our OCTAD portal (http://octad.org), an open workplace for therapeutic discovery. Project Narrative About 25 million people are living with understudied diseases in the U.S. Although there are voluminous high dimensional molecular datasets that could be leveraged for research, individual labs have limited computational capacity to translate these molecular features into therapeutic hits. We propose to build a centralized information system that allows individual labs to easily harness open gene expression datasets and generate new therapeutic targets or drug candidates for further experimental validation.",Repurpose open data to discover therapeutics for understudied diseases,10231115,R01GM134307,"['Address', 'Adult', 'Affect', 'Asia', 'Basal Cell', 'Basal cell carcinoma', 'Cancer cell line', 'Case Study', 'Cell Line', 'Code', 'Communities', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diffuse intrinsic pontine glioma', 'Disease', 'Disease model', 'Drug Modelings', 'Drug Screening', 'Drug Targeting', 'Evaluation', 'Ewings sarcoma', 'Gene Expression', 'Gene Expression Profile', 'Generations', 'Genes', 'Genotype', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Heterogeneity', 'Individual', 'Informatics', 'Information Systems', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Methods', 'Michigan', 'Modeling', 'Molecular', 'Multiple Organ Failure', 'Normal tissue morphology', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physicians', 'Pre-Clinical Model', 'Primary carcinoma of the liver cells', 'Procedures', 'Quality Control', 'Ramp', 'Rare Diseases', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scientist', 'System', 'The Cancer Genome Atlas', 'Therapeutic', 'Therapeutic Agents', 'Tissues', 'Translating', 'Translational Research', 'Universities', 'Validation', 'Weight', 'Workplace', 'base', 'cancer gene expression', 'clinically relevant', 'computer science', 'cost', 'data modeling', 'deep learning', 'disease classification', 'disorder control', 'drug candidate', 'drug mechanism', 'high dimensionality', 'improved', 'insight', 'interest', 'large scale data', 'learning strategy', 'model development', 'mouse model', 'new therapeutic target', 'next generation sequencing', 'novel', 'novel therapeutics', 'open data', 'overexpression', 'pill', 'protein metabolite', 'statistics', 'success', 'therapeutic candidate', 'therapeutic target', 'transcriptome sequencing']",NIGMS,MICHIGAN STATE UNIVERSITY,R01,2021,416266
"Automating mosquito microdissection for a malaria PfSPZ vaccine ABSTRACT Despite annual investments of >$3 billion for intensive control measures, in 2018, the 228 million cases of malaria were an increase of ~16 million cases over 2015, and no decrease in number of deaths. The impact of available malaria control measure has plateaued. Moreover, WHO estimates deaths from malaria could double across sub-Saharan Africa this year due to disruptions in access to control measures due to the current global COVID-19 pandemic malaria. New tools, especially a vaccine, are needed. Only broad deployment of an effective vaccine holds the promise of true elimination or eradication, especially in the face of sudden developments like COVID-19. More than 98% of all deaths from malaria are caused by Plasmodium falciparum (Pf). Thus, a vaccine against Pf malaria is the priority. Sanaria is moving in 2021 to Phase 3 clinical trials of its Pf sporozoite (SPZ), PfSPZ Vaccine, and is planning for marketing authorization (licensure) from FDA and EMA in 2022/2023. Over the next 5-10 years we aim to decrease the cost of goods (COGs) and efficiency of production of PfSPZ vaccines so they can be used most effectively and economically by individuals who suffer the most from malaria. Microdissection of mosquitoes is a crucial step in extraction of PfSPZ vaccine products, and ensures a 10,000-fold purification away from irrelevant mosquito parts as the starting material for downstream purification procedures that then achieve a final product purity of 99.9%. To-date, mosquito salivary gland PfSPZ have demonstrated in vivo infectivity/potency superior to those extracted from whole mosquitoes, or grown outside a mosquito. However, extraction of mosquito salivary glands is a rate-limiting, labor-intensive, expensive step in production of PfSPZ-based vaccines. The overarching aim of this proposal is to enable implementation of an interim semi-automated dissection device in cGMP production of PfSPZ-based vaccines against malaria, and develop an integrated dissection system incorporating multiple automation steps downstream of mosquito orientation, for commercial-scale manufacturing. The unique application of robotic technology, state-of-the art computer vision and machine learning algorithms, and software systems to production-scale processing of very small insects in cleanrooms not only advances manufacturing capabilities, but also represents a spectrum of milestone innovations in automation. Success in this project involving a highly-skilled multi-disciplinary team of investigators, manufacturing and quality experts will decidedly lead to further streamlining and process optimization during the key step of isolating mosquito salivary glands for manufacture of our highly effective PfSPZ-based vaccines. The breakthroughs that initially defined a vaccine that is far superior to competing technologies in both safety and protective efficacy, will continue, as we advance in the proposed studies to make vaccine extraction more cost-effective due to greater efficiencies, mitigation of human error and operator fatigue, reduced timeframes, greatly reduced training periods, and increased product purity, towards deployment of a highly-impactful tool in the fight against malaria. Malaria claims upwards of 600,000 human lives each year, with more than 1,000 children succumbing every day. Sanaria’s Plasmodium falciparum (Pf) sporozoite (SPZ)-based vaccines against malaria have demonstrated outstanding safety and efficacy in numerous clinical trials. The manufacturing procedure for PfSPZ-based crucially involves a currently labor-intensive process of mosquito salivary gland extraction entirely by manual dissection. Our aim in this proposal is to first introduce an interim semi-automated dissection fixture for this process. In parallel efforts, incorporating automation in key steps of mosquito decapitation, and extraction of glands will lead to greater efficiencies, reduce timeframes, greatly reduce training times, mitigate human error and operator fatigue while maintaining product purity and quality that is thought to underlie an incredible safety record of Sanaria’s PfSPZ vaccines. These outcomes will accelerate Sanaria’s march to licensure and production of commercial-scale volumes required to meet demand for post-licensure distribution to populations with greatest need, world- wide.",Automating mosquito microdissection for a malaria PfSPZ vaccine,10258416,R44AI134500,"['Africa South of the Sahara', 'Authorization documentation', 'Automation', 'Body part', 'COVID-19', 'COVID-19 pandemic', 'Cessation of life', 'Characteristics', 'Chest', 'Child', 'Clinical Trials', 'Collection', 'Comb animal structure', 'Computer Vision Systems', 'Culicidae', 'Cyclic GMP', 'Decapitation', 'Development', 'Devices', 'Dissection', 'Ensure', 'Environment', 'Equipment', 'Falciparum Malaria', 'Fatigue', 'Feasibility Studies', 'Geometry', 'Gland', 'Goals', 'Head', 'Hour', 'Human', 'Human Resources', 'Individual', 'Injections', 'Insecta', 'Investments', 'Lead', 'Licensure', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Marketing', 'Measures', 'Methodology', 'Methods', 'Microdissection', 'Microscope', 'Modeling', 'Modification', 'Molds', 'Needles', 'Outcome', 'Output', 'Phase', 'Phase III Clinical Trials', 'Plasmodium falciparum', 'Plasmodium falciparum vaccine', 'Population', 'Procedures', 'Process', 'Production', 'Research Personnel', 'Robotics', 'Running', 'Safety', 'Salivary Glands', 'Scheme', 'Sporozoites', 'Stainless Steel', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Vaccines', 'Vision', 'base', 'cGMP production', 'commercialization', 'cost', 'cost effective', 'design', 'experience', 'feeding', 'fight against', 'human error', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning algorithm', 'manufacturing scale-up', 'multidisciplinary', 'operation', 'process optimization', 'protective efficacy', 'prototype', 'robotic system', 'software systems', 'success', 'tool']",NIAID,"SANARIA, INC.",R44,2021,1000000
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,10246414,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'interest', 'machine learning method', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'statistical and machine learning', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2021,70458
"Developing novel technologies that ensure privacy and security in biomedical data science research Data science holds the promise of enabling new pathways to discovery and can improve the understanding, prevention and treatment of complex disorders such as cancer, diabetes, substance abuse, etc., which are significantly on the rise. The promise of data science can be fully realized only when collected data can be collaboratively shared and analyzed. However, the widespread increases in healthcare data breaches due to inappropriate access as well as the increasing number of novel privacy attacks restrict institutions from sharing data. Indeed, in some cases, the results of the analysis can themselves lead to significant privacy harm. The success of the data commons depends on ensuring the maximal access to data, subject to all of the patient privacy requirements including those mandated by legislation, and all of the constraints of the organization collecting the data itself. While there are existing solutions that can solve parts of the problem, there are significant challenges in truly incorporating these into comprehensive working solutions that are usable by the biomedical research community, and new challenges brought on by modern techniques such as deep learning. The long-term goal of this research is to develop technologies that can holistically enable data sharing while respecting privacy and security considerations and to ensure that they are implemented in existing platforms that have widespread acceptance in the research community. Towards this, the objective of this project is to develop complementary solutions for risk inference, distributed learning, and access control that can enable different modalities of data sharing. The problems studied are general in nature and will evolve depending on research successes and new impediments that arise. The proposed program of research is significant since lack of access to biomedical data can lead to fragmentation of care, resulting in higher economic and social costs, and is a significant impediment to biomedical research. The project will result in open-source, freely available software tools that will be integrated into widely used data collection, cohort identification, and distributed analytics platforms. There are several ongoing collaborations that will serve as initial pilot customers to provide use cases, identify the requirements, evaluate results, and in general validate the developed solutions. Project Narrative Statement of Relevance to Public Health Being able to ensure privacy and security while enabling data sharing and analysis is critical to pave the way forward for public health research and improve our understanding of diseases. The proposed work will address the challenges that impede the use of data across all of the different modalities of data sharing. The integration into existing platforms will ensure that the developed models, tools, and solutions directly impact the research community and improve public health interventions.",Developing novel technologies that ensure privacy and security in biomedical data science research,10077318,R35GM134927,"['Address', 'Biomedical Research', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Science', 'Diabetes Mellitus', 'Disease', 'Economics', 'Ensure', 'Goals', 'Healthcare', 'Institution', 'Lead', 'Learning', 'Malignant Neoplasms', 'Modality', 'Modeling', 'Modernization', 'Nature', 'Pathway interactions', 'Prevention', 'Privacy', 'Public Health', 'Research', 'Risk', 'Security', 'Software Tools', 'Statutes and Laws', 'Substance abuse problem', 'Techniques', 'Technology', 'Work', 'biomedical data science', 'care fragmentation', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'new technology', 'novel', 'open source', 'patient privacy', 'programs', 'public health intervention', 'public health research', 'social', 'success', 'tool']",NIGMS,RUTGERS THE STATE UNIV OF NJ NEWARK,R35,2021,383279
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,10061631,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'community engagement', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2021,1261742
"Endothelial-to-mesenchymal transition and atherosclerosis Project Summary/Abstract This competitive renewal is based on work demonstrating that a subpopulation of endothelial cells (ECs) in atherosclerotic plaques undergo a transition to a mesenchymal cell fate that involves loss of barrier function, expression of inflammatory genes and remodeling of the extracellular matrix. This transition is initiated by inflammatory signaling that sensitizes cells to TGFβ, which then drives the mesenchymal fate transition. A key consequence of the mesenchymal phenotype is production of a fibronectin-rich extracellular matrix that amplifies inflammatory signaling, recruiting leukocytes and production of cytokines. This sequence of events thus creates positive feedback, a key feature of disease progression and resistance to therapy. Our work during the past grant cycle has provided evidence that fate switching is driven by a minor subset of pre-existing, susceptible ECs that drive vessel wall remodeling. Our work has also elucidated novel pathways by which matrix remodeling alters integrin signaling to enhance inflammatory pathways and promotes disease progression. The overall goal of the current application is to understand the EC subpopulations and factors that drive fate switching, and the positive feedback mechanisms that drive disease. Aim 1 will elucidate endothelial heterogeneity in mice and in patients with atherosclerosis. Aim 2 will characterize disease-prone subset of normal endothelial cells. Aim 3 will elucidate the role of pro-inflammatory integrin signaling in evolution of EC populations in the atherosclerotic plaque and the downstream pathways that mediate plaque progression. Project Narrative Atherosclerosis is an inflammatory/metabolic disease in which cells of the artery wall remodel to form a plaque that can narrow vessel lumens or rupture and block blood flow. This grant aims to understand the changes in endothelial cell fate that govern vessel remodeling and the pathways by which these changes promote disease. We will identify spatial and gene expression characteristics of susceptible EC subpopulations that mediate these transitions and elucidate the cellular positive feedback loops that mediate disease progression.",Endothelial-to-mesenchymal transition and atherosclerosis,9973898,R01HL135582,"['Appearance', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Attention', 'Binding', 'Blood Vessels', 'Blood flow', 'Cell Proliferation', 'Cells', 'Characteristics', 'Cytometry', 'Data', 'Deposition', 'Development', 'Disease', 'Disease Progression', 'Disease Resistance', 'Endothelial Cells', 'Endothelium', 'Event', 'Evolution', 'Extracellular Matrix', 'Feedback', 'Fibronectins', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Goals', 'Grant', 'Growth', 'Health', 'Heterogeneity', 'Human', 'Image', 'Inflammation', 'Inflammatory', 'Integrin alpha5beta1', 'Integrins', 'Leukocytes', 'Life Style', 'Link', 'Machine Learning', 'Mediating', 'Mesenchymal', 'Metabolic Diseases', 'Minor', 'Molecular', 'Molecular Profiling', 'Mus', 'Paint', 'Pathogenesis', 'Pathogenicity', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Process', 'Production', 'Proteomics', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Smooth Muscle Myocytes', 'Stimulus', 'Techniques', 'Therapeutic', 'Time', 'Transforming Growth Factor beta', 'Up-Regulation', 'Vascular Permeabilities', 'Work', 'advanced disease', 'base', 'cerebral cavernous malformations', 'cytokine', 'human tissue', 'immunocytochemistry', 'macrophage', 'mouse model', 'novel', 'programs', 'recruit', 'repaired', 'response', 'single-cell RNA sequencing', 'therapeutic target', 'therapy resistant', 'tool', 'vascular inflammation']",NHLBI,YALE UNIVERSITY,R01,2021,835601
"Integration of Evolution to Avoid Resistance in Structure Based Drug Design Integration of Evolution to Avoid Resistance in Structure Based Drug Design Many of the most deadly diseases that plague our society evolve quickly, challenging our therapeutic strategies. Drug resistance occurs as a result of this evolution when drug pressure changes the balance of molecular recognition events, selectively weakening inhibitor binding while maintaining the biological function of the therapeutic target. Disrupting the therapeutic target’s activity is necessary but not sufficient to avoid resistance. We hypothesize that the multi-dimensional landscape of resistance evolution can be elucidated through integration of experimental and computational data to reveal the key pathways and coupled molecular mechanisms to resistance. Furthermore, we hypothesize that this strategy can be incorporated into structure-based drug design to evaluate novel inhibitors.  Resistance occurs under gradual and persistent drug pressure, and interestingly the mutations are not limited to the active site of a drug target, but can occur throughout the enzyme to confer high levels of resistance. The molecular mechanism by which this resistance occurs is not clear. Our aim is to exploit the rich and versatile experimental data, integrating inhibitor potency and crystallographic structures with ensemble dynamics in an internally consistent manner using machine learning to elucidate both the molecular mechanisms of drug resistance and generate predictive models of inhibitor potency. Integration of Evolution to Avoid Resistance in Structure Based Drug Design Many of the most deadly diseases that plague our society evolve quickly, challenging our therapeutic strategies. Drug resistance occurs as a result of this evolution when drug pressure changes the balance of molecular recognition events, selectively weakening inhibitor binding while maintaining the biological function of the therapeutic target. We hypothesize that the multi- dimensional landscape of resistance evolution can be elucidated through integration of experimental and computational data to reveal the key pathways and coupled molecular mechanisms to resistance and thereby advance drug design.",Integration of Evolution to Avoid Resistance in Structure Based Drug Design,10256048,R01GM135919,"['Active Sites', 'Amino Acid Sequence', 'Binding', 'Binding Sites', 'Biological Models', 'Biological Process', 'Chemicals', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Dihydrofolate Reductase', 'Disease', 'Distal', 'Drug Design', 'Drug Targeting', 'Drug resistance', 'Enzyme Inhibitor Drugs', 'Enzymes', 'Epidermal Growth Factor Receptor', 'Equilibrium', 'Event', 'Evolution', 'HIV', 'HIV-1 protease', 'Human', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Modification', 'Molecular', 'Mutation', 'Oncology', 'Pathogenicity', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Plague', 'Protease Inhibitor', 'Protein Dynamics', 'Protein Tyrosine Kinase', 'Research', 'Resistance', 'Resistance profile', 'Site', 'Societies', 'Structure', 'Supervision', 'System', 'Testing', 'Therapeutic', 'Variant', 'Viral', 'Virus', 'base', 'bcr-abl Fusion Proteins', 'design', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'machine learning method', 'molecular dynamics', 'molecular recognition', 'novel', 'predictive modeling', 'pressure', 'resistance mechanism', 'resistance mutation', 'supervised learning', 'therapeutic target', 'tool']",NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,599223
"Integration of Evolution to Avoid Resistance in Structure Based Drug Design Integration of Evolution to Avoid Resistance in Structure Based Drug Design Many of the most deadly diseases that plague our society evolve quickly, challenging our therapeutic strategies. Drug resistance occurs as a result of this evolution when drug pressure changes the balance of molecular recognition events, selectively weakening inhibitor binding while maintaining the biological function of the therapeutic target. Disrupting the therapeutic target’s activity is necessary but not sufficient to avoid resistance. We hypothesize that the multi-dimensional landscape of resistance evolution can be elucidated through integration of experimental and computational data to reveal the key pathways and coupled molecular mechanisms to resistance. Furthermore, we hypothesize that this strategy can be incorporated into structure-based drug design to evaluate novel inhibitors.  Resistance occurs under gradual and persistent drug pressure, and interestingly the mutations are not limited to the active site of a drug target, but can occur throughout the enzyme to confer high levels of resistance. The molecular mechanism by which this resistance occurs is not clear. Our aim is to exploit the rich and versatile experimental data, integrating inhibitor potency and crystallographic structures with ensemble dynamics in an internally consistent manner using machine learning to elucidate both the molecular mechanisms of drug resistance and generate predictive models of inhibitor potency. Integration of Evolution to Avoid Resistance in Structure Based Drug Design Many of the most deadly diseases that plague our society evolve quickly, challenging our therapeutic strategies. Drug resistance occurs as a result of this evolution when drug pressure changes the balance of molecular recognition events, selectively weakening inhibitor binding while maintaining the biological function of the therapeutic target. We hypothesize that the multi- dimensional landscape of resistance evolution can be elucidated through integration of experimental and computational data to reveal the key pathways and coupled molecular mechanisms to resistance and thereby advance drug design.",Integration of Evolution to Avoid Resistance in Structure Based Drug Design,10388034,R01GM135919,"['Active Sites', 'Amino Acid Sequence', 'Binding', 'Binding Sites', 'Biological Models', 'Biological Process', 'Chemicals', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Dihydrofolate Reductase', 'Disease', 'Distal', 'Drug Design', 'Drug Targeting', 'Drug resistance', 'Enzyme Inhibitor Drugs', 'Enzymes', 'Epidermal Growth Factor Receptor', 'Equilibrium', 'Event', 'Evolution', 'HIV', 'HIV-1 protease', 'Human', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Modification', 'Molecular', 'Mutation', 'Oncology', 'Pathogenicity', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Plague', 'Protease Inhibitor', 'Protein Dynamics', 'Protein Tyrosine Kinase', 'Research', 'Resistance', 'Resistance profile', 'Site', 'Societies', 'Structure', 'Supervision', 'System', 'Testing', 'Therapeutic', 'Variant', 'Viral', 'Virus', 'base', 'bcr-abl Fusion Proteins', 'design', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'machine learning method', 'molecular dynamics', 'molecular recognition', 'novel', 'predictive modeling', 'pressure', 'resistance mechanism', 'resistance mutation', 'supervised learning', 'therapeutic target', 'tool']",NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,67000
"Finding emergent structure in multi-sample biological data with the dual geometry of cells and features    A fundamental question in biomedical data analysis is how to capture biological heterogeneity and characterize the complex spectrum of health states (or disease conditions) in patient cohorts. Indeed, much effort has been invested in developing new technologies that provide groundbreaking collections of genomic information at a single cell resolution, unlocking numerous potential advances in understanding the progression and driving forces of biological states. However, these new biomedical technologies produce large volumes of data, quantified by numerous measurements, and often collected in many batches or samples (e.g., from different patients, locations, or times). Exploration and understanding of such data are challenging tasks, but the potential for new discoveries at a level previously not possible justifies the considerable effort required to overcome these difficulties.  In this project we focus on multi-sample single-cell data, e.g., from a multi-patient cohort, where data points represent cells, data features represent gene expressions or protein abundances, and samples (e.g., considered as separate batches or datasets) represent patients. We consider a duality or interaction between constructing an intrinsic geometry of cells (e.g., with manifold learning techniques) and processing data features as signals over it (e.g., with graph signal processing techniques). We propose the utilization of this duality for several data exploration tasks, including data denoising, identifying noise-invariant phenomena, cluster characterization, and aligning cellular features over multiple datasets. Furthermore, we expect the dual multiresolution organization of data points and features to allow us to compute aggregated signatures that represent patients, and then provide a novel data embedding that reveals multiscale structure from the cellular level to the patient level.  The proposed research combines recent advances in several fields at the forefront of data science, including geometric deep learning, manifold learning, and harmonic analysis. The methods developed in this project will provide novel advances in each of these fields, while also establishing new relations between them. Furthermore, the challenges addressed by these methods are a foundational prerequisite for new advances in genomic research, and more generally in empirical data analysis where data is collected in varying experimental environments. The developed algorithms and methods in this project will be validated in several biomedical settings, including characterizing Zika immunity in Dengue patients, tracking progress of Lyme disease, and predicting the effectiveness of immunotherapy. In this project we will develop new algorithms for biomedical data analysis that will characterize the complex spectrum of health states across various patient populations. These algorithms will leverage the large volumes of data collected by new biomedical technologies, focusing on single-cell data. Specific analysis will be carried out for characterizing Zika immunity in Dengue patients, tracking progress of Lyme disease, and predicting the effectiveness of immunotherapy.",Finding emergent structure in multi-sample biological data with the dual geometry of cells and features   ,10236365,R01GM135929,"['Address', 'Algorithms', 'Biological', 'Biomedical Technology', 'Cells', 'Cellular Structures', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Dengue', 'Disease', 'Effectiveness', 'Environment', 'Foundations', 'Gene Expression', 'Gene Proteins', 'Genomics', 'Geometry', 'Graph', 'Health', 'Immunity', 'Immunotherapy', 'Learning', 'Location', 'Lyme Disease', 'Measurement', 'Methods', 'Noise', 'Patients', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Structure', 'Techniques', 'Time', 'ZIKA', 'algorithmic methodologies', 'biological heterogeneity', 'cohort', 'computerized data processing', 'data exploration', 'deep learning', 'denoising', 'driving force', 'multiple datasets', 'new technology', 'novel', 'patient population', 'signal processing']",NIGMS,MICHIGAN STATE UNIVERSITY,R01,2021,353150
"Novel computational approaches to predict drug response and combination effects Summary Tailoring the most desired therapy to each individual patient is the primary goal of precision medicine. A reliable and robust predictive model of drug effectiveness based on patients' unique genomic background is the key. For decades, communities have been trying to establish the relationship between molecular characteristics and drug response in complex diseases. Over the last decade, a large amount of genomic and epigenomic data together with pharmacogenomics data and response to perturbations data has been generated for many human cell lines through collaborations in the research community. These projects have led to significant therapeutic discoveries and have provided unprecedented opportunities to predict drug response using molecular fingerprints. However, even with great interest and effort in developing computational methods for predicting drug response, the prediction accuracies are at best only moderate. A related but distinct question is to understand the mechanisms of action (MOA) of drugs. Understanding drug MOAs enables characterization of drug side effects and identification of old drugs for new uses (i.e. drug repositioning). The traditional experimental assays to identify MOAs of drugs are expensive and time- consuming. There are three key questions to be addressed in the study. 1. Can novel computational approaches largely improve prediction accuracy of response to single drugs using comprehensive genomic and chemical information? 2. Can computational approaches provide a systematic way to mine genomics and drug response data to generate biological insights into the mechanisms of actions of various drugs? 3. Is it possible to develop an interpretable and accurate computation model to predict drug combination effects using pharmacogenomics data? Inherent features make it very challenging to predict drug response accurately: High-dimensionality of input data, the complex relationship between input features and response data; and heterogeneous drug/compound response patterns across different genetic lineages. Recently, artificial intelligence (AI) has been making remarkable strides in various applications owing to the rapid progress of “deep learning. In Aim 1 of this study, we will develop novel AI-based approaches to address the computational challenges of improving the prediction accuracy of drug response. In Aim 2 of the study, we will develop a novel computation framework to study of MOA of drugs. In Aim 3, we will develop an interpretable deep-learning based computational framework to predict drug combination effects. In addition, we will develop a user-friendly web portal as an integrated research platform to share the methodology, algorithms and data generated from this proposed study to the research community. Project Narrative Tailoring the most desired therapy to each individual patient is the primary goal of precision medicine. The proposed study aims to develop novel computational approaches to predict drug response and drug combination effects accurately.",Novel computational approaches to predict drug response and combination effects,10133094,R35GM136375,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological', 'Biological Assay', 'Characteristics', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer Models', 'Computing Methodologies', 'Consumption', 'Data', 'Disease', 'Drug Combinations', 'Drug Compounding', 'Drug Modelings', 'Drug Side Effects', 'Drug usage', 'Effectiveness', 'Genetic', 'Genomics', 'Goals', 'Human Cell Line', 'Methodology', 'Molecular', 'Molecular Profiling', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Research', 'Therapeutic', 'Time', 'base', 'computer framework', 'deep learning', 'drug action', 'drug mechanism', 'drug response prediction', 'epigenomics', 'high dimensionality', 'improved', 'individual patient', 'insight', 'interest', 'novel', 'precision medicine', 'predictive modeling', 'response', 'user-friendly', 'web portal']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R35,2021,409479
"Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease PROJECT SUMMARY/ABSTRACT Chronic obstructive pulmonary disease (COPD) is the leading cause of respiratory mortality in the United States. COPD is a highly heterogeneous disease and some COPD therapies are only applied to specific clinically defined subtypes. With the advent of multiple high-throughput biological assays and machine learning approaches, data-driven subtypes are increasingly being recognized. We hypothesize that such subtypes exist in COPD and that they can be identified using an integrative, multi-'omic approach. To accomplish this goal, we first propose to complement existing RNA and whole genome sequencing data in the well-phenotyped COPDGene study with peripheral blood microRNA sequencing. We will study the relationship of microRNA to genetic variation and gene expression in COPD. Next, we will apply a patient-based network similarity method to these three data types to identify COPD molecular subtypes. Finally, we will associate these subtypes with important clinical phenotypes and outcomes, and validate these subtypes in an independent subset of subjects. Our analysis targets a key clinical problem in COPD management, and will allow the mentee to become an independent investigator, applying bioinformatic and machine learning methods to genomic data in respiratory diseases. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is a leading cause of death in the United States. Patients with COPD may have very similar lung function but differ in many other characteristics. We propose to use multiple types of biologic data to identify different COPD subtypes, which may be important for disease prognosis and treatment.",Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease,10205150,K08HL136928,"['Affect', 'Bioinformatics', 'Biological', 'Biological Assay', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complement', 'Complex', 'Data', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Expert Opinion', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Diseases', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Goals', 'Impairment', 'Individual', 'Lung', 'Lung diseases', 'Lung volume reduction surgery', 'Machine Learning', 'Measures', 'Methods', 'MicroRNAs', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Muscular Atrophy', 'Network-based', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Investigator', 'Prognosis', 'Pulmonary Emphysema', 'RNA', 'Research Personnel', 'SNP array', 'Severities', 'Spirometry', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'United States', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'disorder subtype', 'exome', 'genome sequencing', 'genome wide association study', 'genomic data', 'machine learning method', 'miRNA expression profiling', 'molecular subtypes', 'mortality', 'multiple omics', 'next generation sequencing', 'novel', 'patient subsets', 'peripheral blood', 'personalized approach', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'risk variant', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,172800
"Identifying individuals at risk of progression to active tuberculosis Project Summary Almost 2 billion people are infected with Mycobacterium tuberculosis (Mtb), the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no clinical test to distinguish those that will progress to active TB disease, from those that will not. If we are to realize the World Health Organization's (WHO) goal of a world free of TB by 2035, the massive reservoir of TB infection must be addressed with a cost-effective, ethical therapy for preventing progression, based on treating only those most likely to progress. A diagnostic test that can accurately predict the risk of progression is critical for treating these high-risk individuals and the eradication of TB. Our goal is to develop such an assay. Our central hypothesis is that five independent host immune biomarkers, combined into a single multimetric signature will predict progression from latent to active TB with at least 90% sensitivity and specificity. We will test this hypothesis and achieve our goal by implementing the following specific aims: Aim 1: Compile a comprehensive dataset of biomarkers in a prospective cohort of individuals who are at risk of progressing to active TB. Working with the Moldova Ministry of Health's National TB Program, we will enroll 3,685 close contacts of active TB cases. All participants will be followed for two years to determine who progresses to active TB. We expect to identify ≥ 140 progressors. We will assess three previously established blood-based predictors of active TB progression, and two novel assays. We will verify the performance of previously published biomarkers in this population to discriminate progressors from non-progressors and identify new candidate biomarkers using RNA-Seq of antigen stimulated PBMC and detection of Mtb-peptides by NanoDisk MS. Aim 2: Use a discovery set of samples to develop predictive models of progression to active TB. Using data from 140 progressors and 140 non-progressors from Aim 1 we will (1) Verify the performance of existing biomarkers, (2) Use a cross-validation to identify new candidate biomarkers, and (3) derive predictive models using logistic regression and machine learning methods to identify optimal biomarker signatures that best predict progression to active TB within 12 months. Aim 3: Verify the ability of the model to predict progression to active TB disease. Using the same approach as Aim 1, we will enroll a new set of 1,340 household contacts of active TB and identify at least 60 progressors and 60 matched non-progressors and verify clinically the sensitivity/specificity of our models and biosignatures (Aim 2) to predict progression to active disease. A combined host biomarker signature that can predict TB progression from a small blood volume will have significant impact on the WHO End TB Program. PROJECT NARRATIVE Almost 2 billion people are infected with Mycobacterium tuberculosis, the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no test to distinguish those that will progress from those that will not. We propose to develop a multimetric signature of host biomarkers that together will have a sensitivity and specificity of ≥ 90% for predicting progression to active TB in one year, a critical first step to developing cost-effective and ethical treatment plans in order to reach the World Health Organization goal of Ending TB by 2035.",Identifying individuals at risk of progression to active tuberculosis,10092079,R01AI137681,"['Address', 'Antigens', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Volume', 'Cells', 'Characteristics', 'Child', 'Clinical', 'Clinical Sensitivity', 'Data', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Enrollment', 'Ethics', 'Event', 'Filtration', 'Flow Cytometry', 'Foundations', 'Freezing', 'Frequencies', 'Gender', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Goals', 'Health', 'Household', 'Immune', 'Immune response', 'Immunologic Markers', 'Individual', 'Interferons', 'Logistic Regressions', 'Lymphocyte', 'Modeling', 'Moldova', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'National Health Programs', 'Organizational Objectives', 'Outcomes Research', 'Participant', 'Patients', 'Peptide Fragments', 'Peptides', 'Performance', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Procedures', 'Production', 'Prospective cohort', 'Proteins', 'Publications', 'Publishing', 'RNA', 'Research Personnel', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'T cell response', 'T-Lymphocyte', 'Testing', 'Tuberculosis', 'Validation', 'World Health Organization', 'age group', 'base', 'biobank', 'biomarker performance', 'biomarker signature', 'biosignature', 'blood-based biomarker', 'candidate marker', 'classification algorithm', 'clinical Diagnosis', 'cohort', 'cost effective', 'deep neural network', 'enzyme linked immunospot assay', 'falls', 'follow-up', 'high risk', 'indexing', 'innovation', 'machine learning method', 'monocyte', 'nanodisk', 'novel', 'novel diagnostics', 'predictive modeling', 'predictive test', 'prevent', 'programs', 'progression marker', 'random forest', 'research clinical testing', 'support vector machine', 'transcriptome sequencing', 'transmission process', 'treatment planning']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,728879
"Understanding the control mechanisms of 3D cell migration from new dimensions Cell migration in 3D tissue space is of fundamental importance for human biology. However, predicting and programming 3D cell motility remain as major challenges despite of a firm picture of the molecular machineries involved. To fill the knowledge gap between the overwhelming subcellular details such as protein-protein interactions, and the fascinating dynamic patterns exhibited by different cell types in tissue spaces, I will focus on the mesoscale cellular dynamics, namely the migration mode transitions of cells in 3D extracellular matrix (ECM). My lab has developed deep-learning based image postprocessing to track the migration modes of cells. We also developed techniques to manipulate and measure the micromechanics of ECM at cellular scale. Based on these preliminary results, I will systematically study the intrinsic and extrinsic control mechanisms of 3D cell migration mode transitions in collagen ECM. The results will pave the way for my long-term goals to understand the organizing principle that lead molecules to life, and to program cell motility for applications in tissue engineering and cancer treatment. To this end, I will dedicate my lab to the following research thrusts. Thrust 1 aims to determine how cell migration mode transitions are regulated by external cues, as well as intrinsic states of cells during the Epithelial-Mesenchymal Transition (EMT). I will test three hypotheses that elucidate the roles of ECM micromechanical stiffness, anisotropy, plasticity, synergy of mechanical and chemical guidance, as well as EMT stage in modulating the cell migration mode transitions. I will employ sophisticated ECM engineering and characterization techniques developed in my lab. I will also use genetically engineered cells whose EMT transcription factors are fluorescent labeled and can be specifically activated. Completion of thrust 1 will establish 3D cell migration as a hidden Markov process where the mesoscale dynamics, namely the migration mode transitions, provides a unifying framework to explain diverse dynamic patterns of 3D cell migration observed in vivo. Thrust 2 aims to devise strategies to program cell migration via nonstationary mechanical cues. In subproject 1, I will employ techniques developed in my lab to control 3D contact guidance cues in space and in real time. By measuring the migration mode transitions under step-increasing contact guidance, I will obtain the energy barriers that separate different modes. Then under periodic mechanical stimuli I will measure and computationally model the nonequilibrium mode transition flux, a statistical physics quantity that inform the efficiency and energy dissipation of cell motility responses. These mesoscale quantities shed light to the underlying molecular organizing principles. In subproject 2 I will develop collagen ECM which exhibits digital response to stresses using DNA-grafted nanoparticles as crosslinkers. I will design the DNA sequence to control the yield strength of crosslinkers, thereby programing cell migration mode both for single cell and for collective organoid migration. Completion of thrust 2 will expands the design space of engineered ECM, laying a foundation for the mechanical programing of 3D cell motility. 3D cell migration is of fundamental importance for both normal physiological processes such as in development, and disease progression such as cancer metastasis. Understanding the regulation and control mechanisms not only will advance our basic understanding of how cells mechanically interact with their environment, but will also lead to powerful strategies to facilitate therapeutic strategies in areas such as tissue regeneration, immune disorder and cancer.",Understanding the control mechanisms of 3D cell migration from new dimensions,10197977,R35GM138179,"['3-Dimensional', 'Anisotropy', 'Area', 'Cells', 'Chemicals', 'Collagen', 'Computer Models', 'Crosslinker', 'Cues', 'DNA', 'DNA Sequence', 'Development', 'Dimensions', 'Disease Progression', 'Engineering', 'Environment', 'Epithelial', 'Exhibits', 'Extracellular Matrix', 'Foundations', 'Goals', 'Human Biology', 'Image', 'Immune System Diseases', 'Knowledge', 'Label', 'Lead', 'Life', 'Light', 'Malignant Neoplasms', 'Markov Chains', 'Measures', 'Mechanics', 'Mesenchymal', 'Molecular', 'Neoplasm Metastasis', 'Organoids', 'Pattern', 'Periodicity', 'Physics', 'Physiological Processes', 'Regulation', 'Research', 'Role', 'Stimulus', 'Stress', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissue Engineering', 'Tissues', 'base', 'cancer therapy', 'cell motility', 'cell type', 'deep learning', 'design', 'digital', 'fascinate', 'genetically modified cells', 'in vivo', 'migration', 'nanoparticle', 'programs', 'protein protein interaction', 'response', 'synergism', 'tissue regeneration', 'transcription factor']",NIGMS,OREGON STATE UNIVERSITY,R35,2021,352506
"Functional annotation of new genes aided by deep learning New genes (NGs) are generated by multiple mechanisms and their end-piece sequences are identified as the chimeric transcript sequence from multiple human sources including healthy and disease tissues. Therefore, NGs have been recognized as important biomarkers and therapeutic targets for precision medicine. Many efforts have been made to study individual NG function and to identify relevant drug targets. However, the current in-depth research and achievements are mainly concentrated on several driver NGs, and classical cancer drugs have been directly used to target the NG domains, such as the kinase domain of BCR-ABL1 fusion protein in leukemia. Some of the fusion proteins with retaining DNA-binding domains such as transcription factors can directly bind their target genes, such as the EWSR1-FLI fusion actively recruiting BAF complex. Recently, the downstream effectors of driver FGs have emerged as therapeutic targets. For example, targeting the downstream CCND2 inhibited RUNX1/ETO-driven leukemic expansion in vitro and in vivo and inhibition of STAT5, the downstream factor of NUP214-ABL1 led to the induction of leukemia cell death. However, the functions of most identified FGs have not been systematically investigated. This is mainly due to the limitations of traditional tools and the high cost of experimental procedures. Therefore, there is an urgent need to develop new tools for analyzing NG breakpoint-specific features systemically in the human genome and predict their originating and regulatory mechanisms, such as upstream and downstream effectors. In-depth annotation based on NG structure is important for understanding the cellular mechanisms of NGs. Effective use of systematic bioinformatics tools for functional annotation can provide a deeper insight into the role of NGs in the development and progression of diseases such as cancers to find direct and indirect therapeutic targets. In this study, we will develop five bioinformatics tools for the functional annotation and feature analysis of NGs, a predictive pipeline for automatic analysis of downstream effects of NGs, and a predictive method for tracing the origin of NGs. This project will be a substantial contribution to public health by systematicallydeep annotating thefunction of new genes (NGs) in cancer and neurodegenerative diseases such as Alzheimer's disease. These systematic annotation results will be performed through ChimerAnno (a tool for functional annotation of human chimeric genes), FGviewer (a tool for visualizing multi-tiered functional features of fusion genes), NGeffector with DeepChIP (a tool for predicting NG downstream effectors with enhanced transcription factor binding site prediction with deep learning), DeepCLIP (a tool for providing evidence of origin of NGs for trans-splicing mechanism) and hBPAI (a tool for feature extraction of human new genes' breakpoint (BP)). The application of these approaches on all kinds of human BPs of new genes will be integrated into NewGeneDB, New Gene annotation Database. This study will advance our knowledge in NG regulatory mechanisms in diseases and open up the possibility of novel treatments of cancer tools and platforms for analyzing NGs. and other diseases in the future by providing powerful",Functional annotation of new genes aided by deep learning,10241506,R35GM138184,"['ABL1 gene', 'Achievement', 'Alzheimer&apos', 's Disease', 'Antineoplastic Agents', 'Binding', 'Binding Sites', 'Biological Markers', 'CCND2 gene', 'Cell Death', 'Chimeric Proteins', 'Complex', 'DNA Binding Domain', 'Databases', 'Development', 'Disease', 'Disease Progression', 'Drug Targeting', 'EWSR1 gene', 'Future', 'Gene Structure', 'Genes', 'Human', 'Human Genome', 'In Vitro', 'Individual', 'Knowledge', 'Leukemic Cell', 'Malignant Neoplasms', 'Methods', 'NUP214 gene', 'Neurodegenerative Disorders', 'Phosphotransferases', 'Procedures', 'Public Health', 'RUNX1 gene', 'Recruitment Activity', 'Regulator Genes', 'Research', 'Role', 'Source', 'Stat5 protein', 'Tissues', 'Trans-Splicing', 'Transcript', 'base', 'bioinformatics tool', 'cancer therapy', 'chimeric gene', 'cost', 'deep learning', 'feature extraction', 'fusion gene', 'gene function', 'in vivo', 'insight', 'leukemia', 'novel', 'precision medicine', 'predictive tools', 'therapeutic target', 'tool', 'transcription factor']",NIGMS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R35,2021,323658
"Dissecting host-pathogen interactions through the lens of genomics Summary: Dissecting host-pathogen interactions through the lens of genomics Current investigation of mechanisms underlying many diseases relies on the acquisition of multi-dimensional genomics data. The utility of these data is, however, offset by the lag in development of tools and models to fully interrogate them. In the context of infectious diseases, such data contains molecular information including gene transcription, regulation, and variations from both the infecting pathogen and the host cell, providing a snapshot of the host and pathogen interactions (HPIs). These HPIs determine infection outcomes. For instance, when a pathogen evades, or evolves resistance to defensive host immunity via a multifaceted HPI, it can result in persisting infection, chronic inflammation, malignant transformation, and/or elevated mortality. Recent successes in overcoming immune-evasion of infected tumor cells with checkpoint inhibitors exemplifies the clinical gains that can be made by identifying and specifically targeting essential mechanisms of HPIs. Hence, precisely identifying new mode(s) of HPIs is critical for development of effective and personalized interventions. The molecular mechanisms of HPIs underpinning disease can be identified from genomics data. For example, information on whether a transcription factor (TF) regulates genes from either host or pathogen, or both, can be captured by chromatin immunoprecipitation (ChIP) sequencing of infected host cells. This means that integrative analysis of genome-scale data can provide a platform for large-scale and unbiased detection of often multi- dimensional and novel facets of HPIs in host cells. However, there is a lack of data mining tools and models to extract such information. More importantly, the available analysis tools typically focus on data from either the host or the pathogen and not on the interactions occurring between the two, excluding us from investigating the full HPI spectrum. Thus, novel methods to determine HPIs by simultaneously modeling both host and pathogen data are critical for understanding key cellular mechanisms and developing treatment strategies. My lab specializes in developing computational models to construct HPI maps and to experimentally validate them. As proof-of-principle, we produced a comprehensive HPI map from sequencing samples from large numbers of tumors caused by Epstein–Barr virus. This map delivered unprecedented insights, identifying novel viral integrations, mutations linked to viral reactivation and providing molecular classification of tumors expected to yield individualized cancer therapy. Therefore, my lab is uniquely positioned to uncover mechanistic insights from HPIs. Our program seeks to develop new models and machine learning tools to construct HPI maps in several diseases by focusing on the following major questions: 1) how do expression, integration, and mutational landscapes of host and pathogen affect pathogenesis of disease?; 2) what is the nature of physical HPIs and cross-regulation by major host and pathogen factors that modulate gene expression, such as TFs and RNA binding proteins?; 3) how do HPIs define molecular subtypes to guide personalized treatments? We expect to identify novel HPIs and provide systems-level understanding of mechanisms critical to cell biology. Narrative Understanding how host cells and pathogens interact is key to developing new and individualized therapeutics. Here, we will develop novel computational tools and models to analyze existing and newly generated high throughput data and construct multi-dimensional host pathogen interaction maps. These maps will provide detailed mechanisms underpinning multi-faceted interactions occurring between host and pathogen and will delineate molecular subtypes that can be utilized for novel and personalized treatment options.",Dissecting host-pathogen interactions through the lens of genomics,10241946,R35GM138283,"['Affect', 'Cells', 'Cellular biology', 'ChIP-seq', 'Chronic', 'Clinical', 'Communicable Diseases', 'Computer Models', 'Data', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Human Herpesvirus 4', 'Immune Evasion', 'Immune checkpoint inhibitor', 'Immunity', 'Infection', 'Inflammation', 'Investigation', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Classification of Tumors', 'Mutation', 'Nature', 'Outcome', 'Pathogenesis', 'Positioning Attribute', 'RNA-Binding Proteins', 'Regulation', 'Resistance', 'Sampling', 'System', 'Therapeutic', 'Transcriptional Regulation', 'Variant', 'Viral', 'Virus Integration', 'computerized tools', 'data mining', 'effective intervention', 'genome analysis', 'genome-wide', 'genomic data', 'insight', 'lens', 'molecular subtypes', 'mortality', 'neoplastic cell', 'novel', 'pathogen', 'personalized cancer therapy', 'personalized intervention', 'personalized medicine', 'programs', 'success', 'tool', 'tool development', 'transcription factor', 'treatment strategy', 'tumor']",NIGMS,PURDUE UNIVERSITY,R35,2021,381824
"Joint submission for administrative supplement proposal: HIPAA aligned storage and computing solution Summary: Dissecting host-pathogen interactions through the lens of genomics Current investigation of mechanisms underlying many diseases relies on the acquisition of multi-dimensional genomics data. The utility of these data is, however, offset by the lag in development of tools and models to fully interrogate them. In the context of infectious diseases, such data contains molecular information including gene transcription, regulation, and variations from both the infecting pathogen and the host cell, providing a snapshot of the host and pathogen interactions (HPIs). These HPIs determine infection outcomes. For instance, when a pathogen evades, or evolves resistance to defensive host immunity via a multifaceted HPI, it can result in persisting infection, chronic inflammation, malignant transformation, and/or elevated mortality. Recent successes in overcoming immune-evasion of infected tumor cells with checkpoint inhibitors exemplifies the clinical gains that can be made by identifying and specifically targeting essential mechanisms of HPIs. Hence, precisely identifying new mode(s) of HPIs is critical for development of effective and personalized interventions. The molecular mechanisms of HPIs underpinning disease can be identified from genomics data. For example, information on whether a transcription factor (TF) regulates genes from either host or pathogen, or both, can be captured by chromatin immunoprecipitation (ChIP) sequencing of infected host cells. This means that integrative analysis of genome-scale data can provide a platform for large-scale and unbiased detection of often multi- dimensional and novel facets of HPIs in host cells. However, there is a lack of data mining tools and models to extract such information. More importantly, the available analysis tools typically focus on data from either the host or the pathogen and not on the interactions occurring between the two, excluding us from investigating the full HPI spectrum. Thus, novel methods to determine HPIs by simultaneously modeling both host and pathogen data are critical for understanding key cellular mechanisms and developing treatment strategies. My lab specializes in developing computational models to construct HPI maps and to experimentally validate them. As proof-of-principle, we produced a comprehensive HPI map from sequencing samples from large numbers of tumors caused by Epstein–Barr virus. This map delivered unprecedented insights, identifying novel viral integrations, mutations linked to viral reactivation and providing molecular classification of tumors expected to yield individualized cancer therapy. Therefore, my lab is uniquely positioned to uncover mechanistic insights from HPIs. Our program seeks to develop new models and machine learning tools to construct HPI maps in several diseases by focusing on the following major questions: 1) how do expression, integration, and mutational landscapes of host and pathogen affect pathogenesis of disease?; 2) what is the nature of physical HPIs and cross-regulation by major host and pathogen factors that modulate gene expression, such as TFs and RNA binding proteins?; 3) how do HPIs define molecular subtypes to guide personalized treatments? We expect to identify novel HPIs and provide systems-level understanding of mechanisms critical to cell biology. 091221!345""6""""'""""$""""'$&&""'#""""%""",Joint submission for administrative supplement proposal: HIPAA aligned storage and computing solution,10388739,R35GM138283,"['Administrative Supplement', 'Affect', 'Cells', 'Cellular biology', 'ChIP-seq', 'Chronic', 'Clinical', 'Communicable Diseases', 'Computer Models', 'Data', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Health Insurance Portability and Accountability Act', 'Human Herpesvirus 4', 'Immune Evasion', 'Immune checkpoint inhibitor', 'Immunity', 'Infection', 'Inflammation', 'Investigation', 'Joints', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Classification of Tumors', 'Mutation', 'Nature', 'Outcome', 'Pathogenesis', 'Positioning Attribute', 'RNA-Binding Proteins', 'Regulation', 'Resistance', 'Sampling', 'System', 'Transcriptional Regulation', 'Variant', 'Viral', 'Virus Integration', 'data mining', 'effective intervention', 'genome analysis', 'genome-wide', 'genomic data', 'insight', 'lens', 'molecular subtypes', 'mortality', 'neoplastic cell', 'novel', 'pathogen', 'personalized cancer therapy', 'personalized intervention', 'personalized medicine', 'programs', 'success', 'tool', 'tool development', 'transcription factor', 'treatment strategy', 'tumor']",NIGMS,PURDUE UNIVERSITY,R35,2021,100000
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10207692,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,382894
"Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS Network models are used to investigate the spread of HIV/AIDS, but rather than assuming that the members of a population of interest are fully mixed, the network approach enables individual-level specification of contact patterns by considering the structure of connections among the members of the population. By representing individuals as nodes and contacts between pairs of individuals as edges, this network depiction enables identification of individuals who drive the epidemic, allows for accurate assessment of study power in cluster- randomized trials, and makes it possible to evaluate the impact of interventions on the individuals themselves, their partners, and the broader network. There are currently two major mathematical paradigms to the modeling of networks: the statistical approach and the mechanistic approach. In the statistical approach, one specifies a model that states the likelihood of observing a given network, whereas in the mechanistic approach one specifies a set of domain-specific mechanistic rules at the level of individual nodes, the actors in the network, that are used to evolve the network over time. Given that mechanistic models directly model individual-level behaviors – modification of which is the foundation of most prevention measures – they are a natural fit for infectious diseases. Another attractive feature of mechanistic models is their scalability as they can be implemented for networks consisting of thousands or even millions of nodes, making it possible to simulate population-wide implementation of interventions. Lack of statistical methods for calibrating these models to empirical data has however impeded their use in real-world settings, a limitation that stems from the fact that there are typically no closed-form likelihood functions available for these models due the exponential increase in the number of ways, as a function of network size, of arriving at a given observed network. We propose to overcome this gap by advancing inferential and model selection methods for mechanistic network models, and by developing a framework for investigating their similarities with statistical network models. We base our approach on approximate Bayesian computation (ABC), a family of methods developed specifically for settings where likelihood functions are intractable or unavailable. Our specific aims are the following. Aim 1: To develop a statistically principled framework for estimating parameter values and their uncertainty for mechanistic network models. Aim 2: To develop a statistically principled method for model choice between two competing mechanistic network models and estimating the uncertainty surrounding this choice. Aim 3: To establish a framework for mapping mechanistic network models to statistical models. We also propose to implement these methods in open source software, using a combination of Python and C/C++, to facilitate their dissemination and adoption. We believe that the research proposed here can help harness mechanistic network models – and with that leverage some of the insights developed in the network science community over the past decade and more – to help eradicate this disease. PROJECT NARRATIVE Network models are used to gain a more precise understanding of human behavioral factors associated with the spread of HIV/AIDS in order to develop more effective interventions to halt the epidemic. There are two main mathematical paradigms for modeling networks, the statistical approach and the mechanistic approach, and given that the latter directly models individual-level behaviors – modification of which is the foundation of most prevention measures – mechanistic models are a natural fit for infectious diseases. Lack of statistical methods for calibrating these models to empirical data has so far impeded their use in real-world settings, and we therefore propose to develop parameter inference and model selection methods for mechanistic network models in order to endow the biomedical community with these powerful tools.",Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS,10179312,R01AI138901,"['AIDS prevention', 'AIDS/HIV problem', 'Adoption', 'Automobile Driving', 'Bayesian Analysis', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Biological', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Epidemic', 'Ethics', 'Evaluation', 'Evolution', 'Family', 'Foundations', 'Goals', 'HIV', 'Health Sciences', 'Human', 'Individual', 'Infection', 'Intervention', 'Learning', 'Likelihood Functions', 'Logistics', 'Machine Learning', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Physics', 'Population', 'Prevention Measures', 'Prevention strategy', 'Probability', 'Process', 'Property', 'Public Health', 'Pythons', 'Research', 'Research Personnel', 'SET Domain', 'Science', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Structure', 'Time', 'Uncertainty', 'base', 'effective intervention', 'high dimensionality', 'implementation intervention', 'indexing', 'innovation', 'insight', 'interest', 'member', 'network models', 'open source', 'pandemic disease', 'pathogen', 'pre-exposure prophylaxis', 'simulation', 'statistics', 'stem', 'tool', 'treatment adherence', 'treatment strategy']",NIAID,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2021,554331
"Inverted Spectroscopic Infrared Microscope (ISIM) for High Throughput Multi-Dimensional Cell Assays Abstract The goal of this research is to develop a novel spectroscopic cellular assay that will enable us to measure the real-time intra-cellular response of a cell to various extra-cellular stimuli. The uniqueness of our approach relies on several innovations. We will construct an Inverted Spectral Infrared Microscope (ISIM) based on Fourier- transform infrared (FTIR) spectroscopy and combining it with a novel biosensor based on plasmonic nanostructures (metasurfaces). The biosensor will be integrated with multi-well plates to enable high- throughput. The proposed assay will detect biochemical and morphological changes of the cell, with the emphasis on the reorganization of the cellular membrane and its cytoskeleton. The multi-dimensional nature of the spectroscopic data will enable the application of machine learning techniques and improve its sensitivity in comparison with traditional one-dimensional real-time assays. To our knowledge, this will be the first real-time cellular assay that satisfies all of the four requirements below: (i) high throughput, (ii) multi-dimensionality of the collected time-dependent data, (iii) specific focus on biochemical changes of the cell, and (iv) focus on the changes occurring in close proximity of the cellular membrane. The assay will be validated using very common external stimuli of the cell, such as small-molecule compounds acting on G-protein coupled receptors. Relevance Statement: The goal of our program is to develop a novel multi-dimensional real-time cell assay. This will be accomplished by constructing an FTIR-based inverted spectral infrared microscope (ISIM) and combining it with a novel biosensor. The biosensor is based on the integration of plasmonic metasurface fabricated on an infrared-transparent glass with multi-well microtiter plates. The proposed geometry will enable high throughput while the metasurface will dramatically enhance the signal-to-noise ratio and reduce the penetration depth of the infrared light into the cell. These innovations will enable us to quantify the effects of extra-cellular signaling on the excitation of intra-cellular signaling pathways. The multi-dimensional nature of the spectroscopic data will enable the application of machine learning techniques and improve the sensitivity in comparison with traditional one-dimensional real-time assays.",Inverted Spectroscopic Infrared Microscope (ISIM) for High Throughput Multi-Dimensional Cell Assays,10218929,R21GM138947,"['Adherence', 'Adhesions', 'Agonist', 'Apoptosis', 'Bar Codes', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Testing', 'Biosensor', 'Cell Adhesion', 'Cell Culture Techniques', 'Cell-Matrix Junction', 'Cells', 'Cellular Assay', 'Cellular Membrane', 'Cessation of life', 'Chemicals', 'Cholesterol', 'Clinical', 'Concentration measurement', 'Coupled', 'Cyclic AMP', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Detection', 'Development', 'Dimensions', 'Dopamine', 'Ensure', 'Extracellular Matrix', 'Fingerprint', 'Focal Adhesions', 'Fourier Transform', 'G-Protein-Coupled Receptors', 'Geometry', 'Glass', 'Go Alpha Subunit', 'Goals', 'Homeostasis', 'Image', 'Label', 'Lasers', 'Lateral', 'Ligands', 'Light', 'Lighting', 'Machine Learning', 'Measures', 'Mechanics', 'Membrane', 'Microscope', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Morphology', 'Nanostructures', 'Nature', 'Noise', 'Optics', 'Pathologic', 'Penetration', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiology', 'Process', 'Proteins', 'Publishing', 'Radiation', 'Research', 'Resolution', 'Side', 'Signal Pathway', 'Signal Transduction', 'Slide', 'Source', 'Specificity', 'Spectroscopy, Fourier Transform Infrared', 'Spectrum Analysis', 'Stimulus', 'Surface Plasmon Resonance', 'Techniques', 'Technology', 'Testing', 'Time', 'Trypsin', 'Validation', 'Visible Radiation', 'Water', 'absorption', 'base', 'biological systems', 'data standards', 'design', 'detector', 'electric impedance', 'extracellular', 'improved', 'indexing', 'innovation', 'light transmission', 'novel', 'plasmonics', 'programs', 'receptor', 'response', 'sensor', 'small molecule', 'spectroscopic data', 'temporal measurement', 'tomography', 'tool', 'vibration']",NIGMS,CORNELL UNIVERSITY,R21,2021,233752
"A single cell view of the spatiotemporal nitrogen response in roots Project Summary/Abstract: This proposal seeks to investigate the mechanisms that mediate nutrient control of lateral root (LR) development by exploiting new single-cell expression data. The ultimate goal is to develop plants with enhanced nitrogen (N)-uptake and N-use-efficiency (NUE). This would help ameliorate the application of excess N-fertilizer - a main cause of water and air pollution that negatively impacts human health. Plant roots can sense levels of nitrate in the soil, which induces LR foraging for nutrients. LRs initiate post-embryonically from differentiated cells in the pericycle layer of the root, which de-differentiate to form “founder cells” that give rise to the post-embryonic LRs meristems. Thus, LRs are vital for root developmental plasticity and nutrient acquisition. Previous studies using GFP-marked cell lines, found that N-responses in roots are cell-type specific. However, those studies lacked the single-cell resolution and time-component necessary to identify the N- regulation of transitional states of cell-types (i.e. pericycle-to-founder cell). This proposal aims to: i) use single- cell N-response time-series data to create developmental trajectories that model the transition from pericycle-to- founder cells and ii) identify/validate TFs that regulate LR initiation in response to N-sensing. To do this, single- cell N-response transcriptome data will be analyzed from N-treated Arabidopsis thaliana roots (Aim 1). To determine the TFàtarget gene relationships in this dataset, cell-specific N-response data will be used to learn gene regulatory networks (GRNs) using a time-based machine learning algorithm called OutPredict. Next, the predicted TFàtarget gene interactions in the GRN will be validated using TARGET, a root cell-based TF perturbation assay (Aim 2). Finally, the function of candidate TFs in N-regulation of LR development and N- uptake will be validated in planta using TF mutants in phenotyping assays (Aim 3). In a preliminary in silico analysis of the outlined approach applied to existing single-cell data from Arabidopsis roots, intersected with N- responsive transcriptome data from whole roots identified: 1. A founder cell pseudotime trajectory and N- responsive TFs (Aim 1), 2. A founder cell N-response GRN that predicts TFàtarget gene interactions, and 3. A preliminary list of N-response TFs from founder cell trajectories (Table 2). These preliminary TFs will be phenotyped for their role in N-responsive LR development and 15N-uptake (Aim 3). This proposal will be the first to collect single-cell N-response data in planta and model LR development using developmental trajectory approaches. This proposal also provides new computational training in single cell-data analysis and machine learning methods for GRN to the PI, which will complement her experimental skills-set in plant molecular biology, and provide her with a multi-faceted research foundation for a career as an independent researcher. This project will also benefit from a sponsor environment with proven success for providing new training to the PI, as well as, the ideal laboratory and collaborator environment for the for the proposed single-cell and network modeling experiments. Project Narrative: The developmental plasticity of plants is enabled by their ability to change their root architecture post- embryonically, to acquire water and nutrients in a changing soil environment. This study specifically aims to identify the mechanisms by which nitrogen initiates the development of post-embryonic meristems in lateral roots. These studies will be used to guide strategies for generating crops that have enhanced lateral root growth and are more efficient at taking up nitrogen in the soil, to reduce the excess application of nitrogen-based fertilizes that negatively impact the environment and human health.",A single cell view of the spatiotemporal nitrogen response in roots,10235451,F32GM139299,"['Air Pollution', 'Arabidopsis', 'Architecture', 'Auxins', 'Biological Assay', 'Cell Differentiation process', 'Cell Line', 'Cell division', 'Cells', 'Complement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Embryo', 'Environment', 'Fertilizers', 'Foundations', 'Generations', 'Genes', 'Goals', 'Growth', 'Hazardous Chemicals', 'Health', 'Human', 'Knowledge', 'Laboratories', 'Lateral', 'Learning', 'Length', 'Mediating', 'Meristem', 'Methods', 'Modeling', 'Molecular Biology', 'Mouse-ear Cress', 'Nitrates', 'Nitrogen', 'Nutrient', 'Pathway Analysis', 'Phenotype', 'Plant Growth Regulators', 'Plant Roots', 'Plants', 'Reaction Time', 'Regulation', 'Regulator Genes', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Soil', 'Time', 'Training', 'Water', 'Water Pollution', 'base', 'career', 'cell type', 'comparative', 'developmental plasticity', 'experimental study', 'gene interaction', 'improved', 'in silico', 'insight', 'machine learning algorithm', 'machine learning method', 'mutant', 'network models', 'overexpression', 'overtreatment', 'response', 'single cell analysis', 'single-cell RNA sequencing', 'skills', 'spatiotemporal', 'success', 'time use', 'transcriptome', 'uptake']",NIGMS,NEW YORK UNIVERSITY,F32,2021,68562
"Nuclear Organization and Function PROJECT SUMMARY. Proper regulation of gene expression is essential for cell differentiation and homeostasis. Most of our understanding of the mechanisms that control the transcription process comes from studies of the one-dimensional genome i.e. the 10 nm chromatin fiber. However, the genome is folded in the three-dimensional (3D) nuclear space, and the relationship between this organization and gene expression is poorly understood. Using Drosophila as a model system, where it is feasible to obtain 250 bp resolution Hi-C data, we have found that the genome is folded into only one type of domain, which we call compartmental domains. These domains precisely correlate with the transcriptional state of their sequences. Compartmental domains are also found in other lower eukaryotes. Based on this, we propose that compartmental domains represent an evolutionarily conserved principle of genome 3D organization. Drosophila and lower eukaryotes either lack CTCF or this protein is unable to stop cohesin extrusion. However, CTCF can interfere with the progression of cohesin extrusion in vertebrates, which in turn affects other types of interactions in the genome. Here we suggest extending concepts learned from the analysis of 3D organization in Drosophila to mammals by proposing an ambitious and substantive multi-disciplinary approach combining genetics, epigenomics, computational biology, and differentiation of human embryonic stem cells (hESC) into disease-relevant tissues. The hypothesis underlying the proposed experiments is based on the idea that, rather than the prevalent view of large compartments containing smaller TADs, the mammalian genome is organized by conserved principles into relatively small compartmental domains. Cohesin extrusion operates on top of the compartmental domain scaffold and affects its organization. To test this novel hypothesis, we will deplete specific proteins present in complexes required for various aspects of the transcription process. We will also deplete protein complexes responsible for H3K27me3- and H3K9me3-dependent silencing. We will then use Micro-C XL to obtain very high-resolution interaction data and examine effects of protein depletion on the formation of self-interacting domains and in the interactions between these domains. These effects will be examined in the presence and absence of cohesin in order to understand the contribution of loop extrusion to enhancer-promoter interaction frequency. We will examine the predictability of 3D genome organization from one-dimensional epigenetic information using machine learning computational tools. We will study the logic of CTCF loop formation by analyzing the local chromatin environment around CTCF sites able or unable to form loops of different strengths using a new computational tool we have developed. Principles learned from these experiments will be tested by analyzing changes in 3D organization and their relationship to gene expression during the differentiation of hESCs into pancreatic cells. Results from this work will fill critical gaps in our understanding of the relationship between 3D chromatin organization and transcription, and its possible role in human disease. PROJECT NARRATIVE This study will analyze the mechanisms by which the three-dimensional organization of the genetic material in the nucleus is established and maintained. This organization is critical for the regulation of gene expression, and the results will be important to understand how transcription is controlled during stem cell differentiation or during reprograming of somatic cells. This knowledge will be essential to understand the basic biology of the cell nucleus and the origin of human genetic disease or cancer and could help guide the use of stem cell therapy to treat human diseases.",Nuclear Organization and Function,10083368,R35GM139408,"['3-Dimensional', 'Affect', 'Biological Models', 'Cell Differentiation process', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Chromatin', 'Chromatin Fiber', 'Complex', 'Computational Biology', 'Data', 'Dimensions', 'Disease', 'Drosophila genus', 'Enhancers', 'Environment', 'Epigenetic Process', 'Eukaryota', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genetic', 'Genetic Diseases', 'Genetic Materials', 'Genetic Transcription', 'Genome', 'Hi-C', 'Homeostasis', 'Human Genetics', 'Knowledge', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Nuclear', 'Pancreas', 'Proteins', 'Resolution', 'Role', 'Site', 'Somatic Cell', 'Testing', 'Three-dimensional analysis', 'Tissues', 'Transcription Process', 'Transcriptional Regulation', 'Vertebrates', 'Work', 'base', 'cohesin', 'computerized tools', 'epigenomics', 'experimental study', 'human disease', 'human embryonic stem cell', 'interdisciplinary approach', 'mammalian genome', 'novel', 'promoter', 'protein complex', 'scaffold', 'stem cell differentiation', 'stem cell therapy']",NIGMS,EMORY UNIVERSITY,R35,2021,431097
"CGMP Compliant Closed Cell Culture System for Reproducible De-differentiation of human somatic cells into iPSCs CGMP Compliant Closed Cell Culture System for Reproducible De-differentiation of human somatic cells into iPSCs Abstract The advancement of iPSC-based personalized cell therapies is currently hindered by the challenges in the biomanufacturing of therapeutic cells. Despite approaches that have made the derivation, growth and differentiation of iPSCs more efficient, there remains significant variability in reprogramming efficacy, genomic integrity and developmental potential of iPSCs derived from patient tissue samples. These variabilities include lot-dependent or technician-dependent differentiation efficiency, bacterial or fungal contamination risks, CO2 or O2 concentration level stresses during cell maintenance, high costs or cross- contamination risks with centralized biomanufacturing facility and requirement of cGMP criteria or regulatory compliance. The difference of iPSCs derived from the same sample in their in-vitro growth characteristics and their inability to re-differentiate into the desired tissue type will cause serious problems in therapy. The further advance of iPSC-based personalized medicine is currently limited by the difficulty to generate iPSCs for large populations and at an affordable cost. Therefore Biopico Systems Inc will solve such challenges by developing an automated cGMP Compliant Closed Cell Culture System for reproducible de-differentiation of human somatic cells into iPSCs. To commercialize Biopico's “CellsMX” system, optimization of closed media exchange system and integration of customized mRNA/ media formulation front-end for reprogramming will be performed in this Phase II research. The CellsMX system will provide quality assurance to the customers for mass production under cGMP guidelines, as operating license are issued to biological entities along with how cells are produced, tested, and released for therapeutic use. Further, even, if a large number of patients need iPSC-based personalized cell therapies, under CellsMX closed system, patient cells are not cross-contaminated and the system can be deployed at the point of care avoiding high costs and risks associated with the transportation, logistics, tracking, and recording. While patient-specific iPSC strategy's reduction of immunologic stimulus will drive the initial market segment for the CellsMX system, Biopico will develop a suite of products for several of such therapeutic culture processes. Narrative The stem cells can address diseases such as cancer or damaged or dysfunctional organs using tissues or cell therapies. The enormous transplant waiting lists results in many people die awaiting transplants. Further, to provide stem cells as a viable source of replacement cells to treat diseases, the manufacturing costs are presently not affordable keeping public expectations unrealistic. Biopico's CellsMX reprogramming platform can address these issues to generate large number of iPSC and supply cells for stem cell banking or stem cell therapy applications.",CGMP Compliant Closed Cell Culture System for Reproducible De-differentiation of human somatic cells into iPSCs,10239244,R44GM139413,"['Address', 'Air', 'Algorithms', 'Alleles', 'Antibodies', 'Automation', 'Biological', 'Biomanufacturing', 'Biotechnology', 'Carbon Dioxide', 'Cell Culture System', 'Cell Culture Techniques', 'Cell Maintenance', 'Cell Therapy', 'Cells', 'Cellular Morphology', 'Characteristics', 'Custom', 'Cyclic GMP', 'Derivation procedure', 'Development', 'Differentiation and Growth', 'Disease', 'Environment', 'Equilibrium', 'Feasibility Studies', 'Fibroblasts', 'Film', 'Formulation', 'Freezing', 'Gene Expression', 'Goals', 'Growth', 'Guidelines', 'Human', 'Image', 'Immunologics', 'In Vitro', 'Individual', 'Legal patent', 'Licensing', 'Liquid substance', 'Logistics', 'Malignant Neoplasms', 'Manuals', 'Messenger RNA', 'Microscope', 'Monitor', 'Motor', 'Organ', 'Patients', 'Performance', 'Periodicity', 'Phase', 'Population', 'Process', 'Production', 'Protocols documentation', 'Pump', 'Reagent', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Somatic Cell', 'Source', 'Stains', 'Stimulus', 'Stress', 'Syringes', 'System', 'Systems Integration', 'Technology', 'Temperature', 'Testing', 'Therapeutic', 'Therapeutic Uses', 'Time', 'Tissue Sample', 'Tissue Therapy', 'Tissues', 'Transfection', 'Transplantation', 'Transportation', 'Vial device', 'Waiting Lists', 'base', 'cost', 'deep learning algorithm', 'design', 'dosage', 'expectation', 'flasks', 'genome integrity', 'improved', 'induced pluripotent stem cell', 'meter', 'novel', 'operation', 'personalized medicine', 'point of care', 'pressure', 'pressure sensor', 'quality assurance', 'stem cell therapy', 'stem cells', 'stressor', 'success', 'wasting']",NIGMS,BIOPICO,R44,2021,617592
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Integrated proteomic and metabolomics analysis of thrombotic myocardial infarction Project Summary / Abstract: Acute myocardial infarction (MI) is defined as myocardial ischemia, the inadequate supply of blood to heart muscle, followed by myocardial cell death. Multiple causes of acute MI are widely recognized and can be categorized as thrombotic, non-thrombotic, and acute MI secondary to coronary procedures. The mechanistic cause of a thrombotic MI is the rupture or erosion of an atherosclerotic plaque that results in the formation of a thrombus, or blood clot, which occludes the flow of blood. In contrast, non-thrombotic MI occurs secondary to mechanisms which create an oxygen supply and demand imbalance, but are not associated with atherosclerotic plaque rupture or disruption. Given that myocardial cell death is the pathological characteristic that is common to all acute MI, non-invasive diagnostics for acute MI are based on the detection of myocardial cell death. Currently non-invasive diagnostics for differentiating thrombotic MI from non-thrombotic MI do not exist which results in sub-optimal treatment and diminished patient safety. Further, it is not known how the impacts on metabolism and biological processes differ between thrombotic and non-thrombotic MI. In this project, we will address both of these problems. We will develop a diagnostic method for the non-invasive differentiation of thrombotic MI versus non-thrombotic MI that will enable earlier, safer, and more precise targeting of therapeutics to patients suffering from acute MI. We will determine biological processes that differ between thrombotic and non-thrombotic MI, which will suggest targets for therapeutic intervention that are specific to the underlying cause of an acute MI. In Aim 1 we will utilize high resolution mass spectrometry to determine the absolute concentration of over 500 proteins in previously collected plasma samples from human subjects who were experiencing an acute MI for which the cause (thrombotic versus non-thrombotic) was determined. This will enable us to determine which proteins report on the cause of the acute MI as opposed to the presence of myocardial cell death. A critical advantage of our study design is that we have repeated measures from the same human subjects: at the time of presentation, 6 hours post-presentation, and at a stable event-free follow-up timepoint 3 months after the acute MI. In Aim 2 we will integrate this data with our existing data on the abundances of metabolites and lipids generated from the same human subject samples. This integrated data will facilitate an in-depth analysis of the differences between thrombotic and non-thrombotic MI in the activities of metabolic pathways, receptor-ligand binding events, and other biochemical reactions. Further we will conduct data- dependent systems biology analyses that will highlight proteins, metabolites, and lipids that are co-abundant in plasma and will evaluate how the topology of these related entities differs between thrombotic and non- thrombotic MI. In Aim 3 we will develop a statistical classifier for the determination of the underlying cause of an acute MI. We will conduct a blinded evaluation of the performance of this classifier in a second cohort. Project Narrative: Acute myocardial infarction (heart attack) is one of the leading causes of death in the United States and globally. Currently a non-invasive method of determining the underlying cause of an acute myocardial infarction does not exist, and it is unknown how different causes of acute myocardial infarction affect or alter metabolic processes. This project will use previously collected blood plasma from humans experiencing an acute myocardial infarction to develop a diagnostic method for determining the underlying cause of the event and how the different causes alter metabolic processes.",Integrated proteomic and metabolomics analysis of thrombotic myocardial infarction,10087409,SC1GM139730,"['Acute myocardial infarction', 'Address', 'Affect', 'Arterial Fatty Streak', 'Biochemical Reaction', 'Biological', 'Biological Markers', 'Biological Process', 'Blinded', 'Blood coagulation', 'Blood flow', 'Cardiac Myocytes', 'Cause of Death', 'Cell Death', 'Cell-Cell Adhesion', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Coagulation Process', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Ensure', 'Etiology', 'Evaluation', 'Event', 'Fibrinolysis', 'Guidelines', 'Hour', 'Human', 'Infarction', 'International', 'Investigation', 'Knowledge', 'Ligand Binding', 'Ligands', 'Lipids', 'Mass Spectrum Analysis', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardium', 'Necrosis', 'Oxygen', 'Pathologic', 'Patients', 'Performance', 'Plasma', 'Plasma Proteins', 'Platelet Activation', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Reaction', 'Reporting', 'Research Design', 'Resolution', 'Rupture', 'Sampling', 'Secondary to', 'Statistical Models', 'System', 'Systems Biology', 'Therapeutic Intervention', 'Thrombosis', 'Thrombus', 'Time', 'United States', 'Vascular blood supply', 'Work', 'atherosclerotic plaque rupture', 'base', 'cohort', 'design', 'differential expression', 'experience', 'feature selection', 'follow-up', 'genome-wide', 'human subject', 'improved', 'insight', 'lipid metabolism', 'lipidomics', 'liquid chromatography mass spectrometry', 'metabolome', 'metabolomics', 'mortality', 'multiple omics', 'new therapeutic target', 'noninvasive diagnosis', 'novel diagnostics', 'optimal treatments', 'patient safety', 'protein metabolite', 'proteomic signature', 'receptor', 'safety outcomes', 'statistical and machine learning', 'targeted treatment', 'thrombotic', 'treatment strategy']",NIGMS,NEW MEXICO STATE UNIVERSITY LAS CRUCES,SC1,2021,222000
"Functional and transcriptional analysis of embryonic hematopoietic stem cell development at the single cell level PROJECT SUMMARY/ABSTRACT The therapeutic potential of hematopoietic stem cells (HSC) could be significantly enhanced by methods to generate HSC de novo from pluripotent stem cells (PSC) or reprogrammed adult cells. Thus, there has been great interest in understanding the embryologic origin of HSC and the signal pathways that guide HSC development and self-renewal, such that the process of HSC genesis can be recapitulated in vitro, a goal which has yet to be realized. Given the heterogeneity and developmental asynchrony in hemogenic precursors during their emergence in the embryo, to achieve this it will be necessary to develop better strategies to isolate and characterize the rare precursors capable of giving rise to HSC and to understand the signals that drive their development to functional, engrafting HSC. To this end, I have established that endothelial cells (EC) derived from the aorta-gonad-mesonephros region (AGM), the niche in which the first HSC emerge, can promote the in vitro specification and self-renewal of engrafting HSC from hemogenic precursors, including recent studies at the single cell level. Furthermore, I have shown that the Notch pathway functions in both specification and self-renewal of HSC in the EC niche, and that use of immobilized Notch ligands to activate the Notch pathway, along with hematopoietic cytokines, is sufficient to induce expansion of embryonic HSC. Building upon this work, the goals of this proposal are to utilize this novel in vitro AGM-EC system to elucidate the phenotypic, molecular, and functional properties of HSC precursors as they transition to functional HSC capable of long-term, multilineage engraftment. This will require isolation and functional characterization of HSC precursors across different stages of their development at the single cell level (Aim 1), followed by single cell transcriptional analysis to determine the gene regulatory networks and molecular signals promoting their development to functional HSC (Aim 2A). In studies working toward the engineering of stromal cell-free systems for HSC generation, agonists of identified signaling pathways will be functionally tested for their capacity to support HSC development in conjunction with the known requirement for Notch signaling activation (Aim 2B). Altogether, these studies will provide novel insight into the unique properties of HSC precursors, as well at the signaling mechanisms governing their maturation to functional HSC, which will have important implications in advancing our ability to generate HSC from PSC. To accomplish these aims, I will leverage the wealth of resources available in the mentoring laboratory of Dr. Bernstein, as well as key resources available at the Fred Hutchinson Cancer Research Center, the University of Washington, and Seattle Children’s Hospital, and opportunities for co-mentorship from Dr. Shahin Rafii at the Ansary Stem Cell Institute at Weill Cornell Medical College. A key aspect of my career development plan is to also acquire new skills that will facilitate my research objectives, including techniques in single cell RNA-seq and bioinformatics analysis which will be performed in collaboration with and under the co-mentorship of Dr. Cole Trapnell in Genome Sciences at the University of Washington. This type of interdisciplinary training will provide me with the tools necessary to apply innovative technologies in unravelling the complexity of niche- stem cell interactions that instruct HSC fates. My research experience studying hematopoietic stem cell development has provided me with a strong background to facilitate success in the proposed research goals. My clinical experience in caring for children undergoing hematopoietic stem cell transplantation has cemented a strong passion to expand scientific knowledge of HSC and translate this knowledge to improve therapies for children with hematologic, immunologic, and oncologic diseases. Success in my research and career development goals outlined in this proposal will enable me to establish an independent academic career as a physician-scientist with the skills to lead a diverse research team and collaborate broadly to address essential questions in stem cell biology. Ultimately, my long-term goal is to develop a laboratory-based career with focus on taking fundamental principles discovered through basic research in developmental HSC biology toward clinical applications in hematopoietic stem cell therapeutics. PROJECT NARRATIVE The research in this proposal will improve scientific knowledge about the signals which support development of hematopoietic stem cells. This knowledge which will enable new technologies to improve the use of hematopoietic stem cell transplantation for cure of hematologic, immunologic, and oncologic diseases.",Functional and transcriptional analysis of embryonic hematopoietic stem cell development at the single cell level,10080103,K08HL140143,"['Address', 'Adult', 'Agonist', 'Aorta', 'Basic Science', 'Bioinformatics', 'Biological Assay', 'Cell Communication', 'Cell-Free System', 'Cells', 'Child', 'Child Care', 'Clinical', 'Coculture Techniques', 'Collaborations', 'Development', 'Development Plans', 'Disease', 'Embryo', 'Embryonic Development', 'Endothelial Cells', 'Engineering', 'Engraftment', 'Fred Hutchinson Cancer Research Center', 'Gene Expression Profile', 'Gene Expression Profiling', 'Generations', 'Genetic Transcription', 'Goals', 'Gonadal structure', 'Hematological Disease', 'Hematology', 'Hematopoietic', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic stem cells', 'Heterogeneity', 'IL3 Gene', 'Immobilization', 'Immune System Diseases', 'Immunologics', 'In Vitro', 'Individual', 'Inherited', 'Institutes', 'Knowledge', 'Laboratories', 'Lead', 'Ligands', 'Mediating', 'Mentors', 'Mentorship', 'Mesonephric structure', 'Methods', 'Molecular', 'Molecular Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Phenotype', 'Physicians', 'Pluripotent Stem Cells', 'Population', 'Process', 'Property', 'Regulator Genes', 'Research', 'Resources', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Site', 'Sorting - Cell Movement', 'Stem Cell Development', 'Stem cell transplant', 'Stromal Cells', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Translating', 'Transplantation', 'Universities', 'Washington', 'Work', 'base', 'blastomere structure', 'career', 'career development', 'clinical application', 'experience', 'gene therapy', 'genome sciences', 'genome-wide', 'hematopoietic stem cell fate', 'hematopoietic stem cell self-renewal', 'hemogenic endothelium', 'improved', 'in vivo', 'indexing', 'innovative technologies', 'insight', 'interest', 'machine learning algorithm', 'medical schools', 'new technology', 'notch protein', 'novel', 'precursor cell', 'research and development', 'self-renewal', 'single-cell RNA sequencing', 'skills', 'stem cell biology', 'stem cell niche', 'stem cell therapy', 'stem cells', 'success', 'tool', 'transcriptome']",NHLBI,FRED HUTCHINSON CANCER RESEARCH CENTER,K08,2021,92910
"Carbohydrate enzyme gene clusters in human gut microbiome PROJECT SUMMARY Carbohydrate enzyme gene clusters in human gut microbiome Hippocrates said ~2,400 years ago: “Let food be thy medicine and medicine be thy food”. It is now well known that this is largely due to the “diet-microbiota-host” interactions that happen in the human gut. In particular, microbial degradation of carbohydrates can produce a variety of metabolites, which have a profound impact on human health. As a bioinformatics researcher in the Nebraska Food for Health Center, the long-term interests of the PI include: (i) develop specialized computational tools for better functional annotation of food-digesting microbial genomes and metagenomes, and (ii) characterize enzymes and other genetic elements that connect microbes, diets, and human health. The objective of this R01 project is to develop a suite of bioinformatics tools for functional annotation of carbohydrate active enzyme (CAZyme) and CAZyme gene clusters (CGCs) in human gut microbiome. The PI has over 10 years of experience in CAZyme bioinformatics tool development, and maintains a well-recognized CAZyme annotation database and web server called dbCAN (http://bcb.unl.edu/dbCAN2). This project aims to further dbCAN development to address fundamental personalized nutrition questions: (i) is a gut microbe able to utilize a specific type of glycan? (ii) can a person carrying certain gut microbes respond to an individualized diet (e.g., prebiotics: dietary compounds that are beneficial to human health)? To address these questions, new CAZyme annotation tools must have the ability to predict the carbohydrate substrates of CAZymes. Recent research has found that different CAZyme encoding genes are often co-localized with each other and with other genes (e.g., those encoding sugar transporters, regulators, and signaling proteins) in bacterial genomes to form CGCs (also known as polysaccharide utilization loci or PULs). Thus, the foundation of the new tool development is that the gene membership (or functional domain composition) of a CGC can be used to predict its carbohydrate substrates (e.g., xylans, pectins, glucans, etc.). The innovation is that machine learning approaches will be used to analyze a large number of experimentally characterized PULs curated from literature, and the extracted sequence features will be used to build effective classifiers to predict and classify CGCs in new genomes/metagenomes. The expected outcome will be novel and user-friendly open source computer programs, databases, and web servers that allow automated CGCs identification and substrate predictions. The significance is that the new tools will facilitate the experimental characterization of more PULs and their carbohydrate substrates in human gut microbiome (also in other carbohydrate rich environments). Therefore, this project will contribute computational solutions to the research of personalized nutrition, e.g., analyze a person's gut microbiome to predict if this person can respond to diets containing certain prebiotic glycans. PROJECT NARRATIVE Human gut microbes primarily feed on carbohydrate substrates derived from diet and host, and produce important metabolites that significantly influence host physiology and health. The functional annotation of the carbohydrate metabolic enzyme repertoire of gut microbes is poorly defined for most bacterial phyla, resulting in gaps in understanding of how microbial communities utilize these carbohydrates to influence human health. Creating new bioinformatics tools for predicting carbohydrate utilization will contribute to the arising microbiome-based personalized nutrition practice and aid in the development of therapeutic options to prevent/treat human metabolic disorders.",Carbohydrate enzyme gene clusters in human gut microbiome,10099567,R01GM140370,"['Address', 'Algorithms', 'Bacterial Genome', 'Bacteroidetes', 'Bioinformatics', 'Carbohydrates', 'Data', 'Databases', 'Development', 'Diet', 'Dietary Fiber', 'Environment', 'Enzymes', 'Family', 'Firmicutes', 'Food', 'Foundations', 'Gene Cluster', 'Genes', 'Genome', 'Genomics', 'Glucans', 'Glycosides', 'Health', 'Health Food', 'Human', 'Human Microbiome', 'Link', 'Literature', 'Machine Learning', 'Mannans', 'Medicine', 'Metabolic', 'Metabolic Diseases', 'Microbe', 'Nebraska', 'Other Genetics', 'Outcome', 'Pectins', 'Persons', 'Physiology', 'Polysaccharides', 'Proteins', 'Proteobacteria', 'Publishing', 'Research', 'Research Personnel', 'Sampling', 'Signaling Protein', 'Starch', 'System', 'Testing', 'Training', 'Work', 'Xylans', 'annotation  system', 'base', 'bioinformatics tool', 'computer program', 'computerized tools', 'contig', 'dietary', 'experience', 'genetic element', 'gut metagenome', 'gut microbes', 'gut microbiome', 'host microbiota', 'innovation', 'interest', 'machine learning method', 'metagenome', 'metatranscriptome', 'microbial', 'microbial community', 'microbial genome', 'microbiome', 'microbiome sequencing', 'novel', 'nutrition', 'open source', 'prebiotics', 'predictive tools', 'prevent', 'programs', 'sugar', 'supervised learning', 'therapeutic development', 'tool', 'tool development', 'user-friendly', 'web server']",NIGMS,UNIVERSITY OF NEBRASKA LINCOLN,R01,2021,302120
"Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine A fundamental challenge in precision medicine is to understand the patterns of differentiation between individuals. To address this challenge, we propose to go beyond the traditional `one disease--one model' view of bioinformatics and pursue a new view built upon personalized patient models that facilitates precision medicine by leveraging both commonalities within a patient cohort as well as signatures unique to every individual patient. With the emergence of large-scale databases such as The Cancer Genome Atlas (TCGA), the International Cancer Genome Consortium (ICGC), and the Gene Expression Omnibus (GEO), which collect multi-omic data on many different diseases, a new “pan-omics” and “pan-disease” paradigm has emerged to jointly analyze all patients in a disease cohort while accounting for patient-specific effects. An example of this is the recently released Pan-Cancer Atlas. At the same time, next generation statistical tools to accurately and rigorously draw the necessary inferences are lacking. In this project we propose a series of mathematically rigorous, statistically sound, and computationally feasible approaches to infer sample-specific models, providing a more complete view of heterogeneous datasets. By bringing together ideas from the machine learning, statistics, and mathematical optimization communities, we provide a rigorous framework for precision medicine via sample-specific statistical models. Crucially, we propose to analyze this framework and prove strong theoretical guarantees under weak assumptions--this dramatically distinguishes our framework from much of the existing literature. Towards these goals, we propose the following aims: Aim 1: Discovery of new molecular profiles with sample-specific statistical models. We propose a general framework for inferring sample-specific models with low-rank structure based on the novel concept of distance-matching. This allows us to infer statistical models at the level of a single patient without overfitting, and is general enough to be applied for prediction, classification, and network inference as well as a variety of diseases and phenotypes. Aim 2: Multimodal approaches to personalized diagnosis--contextually interpretable models for actionable clinical decision support. In order to translate these models into practice, we propose a novel interpretable predictive model that supports complex, multimodal data types such as images and text combined with high-level interpretable features such as SNP data, gender, age, etc. This framework simultaneously boosts the accuracy of clinical predictions by exploiting sample heterogeneity while providing human-digestable explanations for the predictions being made. Aim 3: Next-generation precision medicine--algorithms and software for personalized estimation. To put our models into practical use, we will develop new algorithms for interpretable prediction of personalized clinical outcomes and visualization of personalized statistical models. All of our tools will be combined into a user-friendly software package called PrecisionX that will be freely available to researchers and clinicians everywhere. RELEVANCE (See instructions): Personalization with data is a critical challenge whenever decisions must be made at scale, and has applications that go beyond precision medicine; businesses, educational institutions, and financial institutions are among the many players that have acknowledged a stake in this complex problem. We expect the proposed work to provide a rigorous foundation for personalization with large and high-dimensional datasets, finding use throughout the broader scientific community as well as with industry and educational institutions. Alongside our collaboration with Pitt/UPMC, we will work with physicians and data scientists for practical feedback as well as provide training in the methods developed. n/a",Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine,10236547,R01GM140467,"['Accounting', 'Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Atlases', 'Bioinformatics', 'Businesses', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Scientist', 'Data Set', 'Disease', 'Feedback', 'Foundations', 'Gender', 'Gene Expression', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Industry', 'Institution', 'Instruction', 'International', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Outcome', 'Patients', 'Pattern', 'Physicians', 'Portraits', 'Research Personnel', 'Sampling', 'Series', 'Statistical Models', 'Structure', 'Text', 'The Cancer Genome Atlas', 'Time', 'Training', 'Translating', 'Visualization', 'Work', 'base', 'cancer genome', 'clinical decision support', 'clinically actionable', 'cohort', 'disease phenotype', 'heterogenous data', 'high dimensionality', 'individual patient', 'large-scale database', 'molecular modeling', 'multimodal data', 'multimodality', 'next generation', 'novel', 'personalized diagnostics', 'personalized predictions', 'precision medicine', 'predictive modeling', 'sound', 'statistics', 'tool', 'user friendly software']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,304146
"Feeding Machine Learning Algorithms with Mechanistic Data to Predict Outcomes of Copper-Catalyzed Couplings PROJECT SUMMARY Cross-coupling reactions that combine aryl halides with oxygen and nitrogen nucleophiles to form C-N and C-O bonds are vital tools for the synthesis of medicinally-relevant molecules. These reactions are often catalyzed by complexes of transition metals, such as palladium or copper. Copper-catalyzed cross-coupling reactions have several advantages over their palladium-mediated counterparts, but the disadvantages associated with copper catalysis often outweigh these benefits. Most Cu-catalyzed cross-coupling methods require high loadings of catalyst and high temperatures, and copper catalysts are often unable to effect cross-coupling of aryl chlorides. To address these issues, ligands that increase activity of copper catalysts for C-N and C-O cross-couplings have been sought, and oxalamide ligands have been shown to generate some of the most active catalysts. A series of publications by Ma have shown that such catalysts can, in some cases, react with 10,000 turnovers, and can cross-couple aryl chlorides, albeit at high temperature (120 °C) and loading of catalyst (5-10 mol %). However, identifying reaction conditions to promote cross-coupling of a given pair of substrates can be difficult – 12 different oxalamide ligands have been used to achieve couplings of different combinations of substrates in high yield. Herein, we propose to use mechanistic research, together with machine learning (ML), to facilitate the identification of reaction conditions for C-O cross-coupling reactions mediated by Cu salts with oxalamide ligands and to facilitate the development of improved ligands and methods. We hypothesize that mechanistic understanding can be used to build improved ML models that can use data sets on the order of 100-1000 points to predict reaction yield effectively. Once built, an ML model capable of predicting yield can be used to evaluate in-silico the potential of a ligand to generate a catalyst for the cross-coupling of aryl chlorides, or to predict reaction conditions to achieve high yield for a new combination of coupling partners. Our research strategy is as follows. First, we will elucidate the mechanism of C-O cross-coupling reactions catalyzed by copper salts with oxalamide ligands, and determine how ligand structure influences the reaction mechanism. The mechanistic insights gained will be used to identify or develop input for a machine learning model (features). We will use high-throughput experimentation tools to carry out 960 C-O coupling reactions with a variety of aryl halides, nucleophiles, and oxalamide ligands. The data set will be used to compare our hand- selected features with features selected by a ML algorithm by their ability to predict C-O coupling yield. The comparison will be made across three different ML optimization tasks. Our mechanistic studies will establish for the first time the mechanism of a C-O cross-coupling reaction catalyzed by Cu salts with oxalamide ligands, laying the foundation for the investigation of other C-O and C-N cross-coupling reactions using the same catalyst system. Our ML studies will establish methods that enable reasonably small datasets to predict reaction yield. PROJECT NARRATIVE The use of machine learning tools to predict the yield of chemical reactions is challenging, and often requires large quantities of training data. Herein, we propose to conduct mechanistic studies on C-O cross-coupling reactions promoted by Cu salts/oxalamide ligands, and to use the mechanistic information to design machine learning models that use small (100-1000 reactions) quantities of data to accurately predict reaction yield. Both the mechanistic data and the developed models will facilitate the identification of productive reaction conditions as well as the development of improved ligands and methods.",Feeding Machine Learning Algorithms with Mechanistic Data to Predict Outcomes of Copper-Catalyzed Couplings,10314079,F32GM140550,"['Address', 'Adoption', 'Affinity', 'Air', 'Area', 'Binding', 'Bromides', 'Catalysis', 'Chlorides', 'Communities', 'Complex', 'Copper', 'Coupling', 'Data', 'Data Set', 'Development', 'Disadvantaged', 'Equation', 'Fostering', 'Foundations', 'Generations', 'Hand', 'High temperature of physical object', 'Informatics', 'Investigation', 'Iodides', 'Ligands', 'Machine Learning', 'Mediating', 'Methods', 'Modeling', 'Nitrogen', 'Organic Chemistry', 'Oxygen', 'Palladium', 'Phosphines', 'Price', 'Publications', 'Reaction', 'Research', 'Rest', 'Salts', 'Series', 'Structure', 'System', 'Temperature', 'Testing', 'Time', 'Training', 'Transition Elements', 'Validation', 'Work', 'aryl halide', 'catalyst', 'chemical reaction', 'cost', 'design', 'feeding', 'improved', 'in silico', 'insight', 'large datasets', 'machine learning algorithm', 'outcome prediction', 'predictive modeling', 'reaction rate', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,F32,2021,65994
"Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics PROJECT SUMMARY When an outbreak of an established or emerging infectious disease occurs we ask a standard set of questions that are critical to a lifesaving public health response: Where will future incidence occur? How many cases will there be? And where can we most effectively intervene? The proposed research is motivated by real world instances where answering these questions was critical to making practical public health decisions, and current methods came up short: from deciding if and where to build additional Ebola Treatment Units in the 2014-15 West African Ebola epidemic, to identifying priority districts where oral cholera vaccine should be used in the 2016-17 cholera outbreak in Yemen, to picking locations where sufficient cases might occur to selecting and prioritizing interventions to slow the spread of COVID-19 worldwide. Forecasts informing such decisions are typically generated either using an epidemic model that relies on knowledge of the disease transmission mechanism and epidemic theory or using a statistical model to project the expected number of cases based on the relationship between covariates and observed counts. However, both approaches are subject to limitations, particularly early in an epidemic when few cases are observed. This project is based on the overarching scientific premise that inferences that combine the strengths of mechanistic epidemic models and statistical covariate models will substantially outperform either approach alone in forecasting and making decisions to confront emerging infectious disease threats. Specifically, this project aims to (1) Develop a framework to forecast incidence in ongoing outbreaks that merges mechanistic and machine learning approaches; (2) Validate the framework using retrospective data and apply the framework to inform decision making in emerging epidemics; (3) Integrate this inferential forecasting framework into causal decision theory to optimize critical actions in the public health response to emerging epidemics; and (4) Develop accessible and extensible tools for forecasting and decision analysis in infectious disease epidemics. We will validate these approaches using rigorous simulation studies and by applying the proposed approaches to retrospective data from important recent epidemics (e.g., Ebola, Cholera and COVID-19, as mentioned above). We will prospectively apply our approach to inform the response to emerging disease threats that occur during the project period, including the ongoing COVID-19 pandemic. To ensure that the tools developed are useful, efficient, and user friendly, we will work with international humanitarian organizations responding to epidemics. Successful completion of these aims will provide a flexible and validated framework for forecasting and decision making during ongoing epidemics, while allowing for innovation in mechanistic and statistical approaches. In doing so it will provide tools to optimize responses and reduce morbidity and mortality during public health crises. PROJECT NARRATIVE The purpose of the proposed project is to improve inference, forecasting and decision making in response to emerging infectious diseases by developing a framework to integrate mechanistic and statistical approaches to epidemic modeling and causal inference. Approaches developed will be validated using simulations and retrospective data and applied prospectively to reduce morbidity and mortality in emerging public health crises. Further, they will be incorporated into publically available tools for use in epidemic response.",Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics,10142638,R01GM140564,"['African', 'Algorithms', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Cholera', 'Cholera Vaccine', 'Communicable Diseases', 'Community Health', 'Cost utility', 'Data', 'Data Set', 'Decision Analysis', 'Decision Making', 'Decision Theory', 'Disease', 'Disease Outbreaks', 'Ebola', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Evaluation', 'Fogs', 'Future', 'Geographic Locations', 'Incidence', 'International', 'Intervention', 'Knowledge', 'Liberia', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Online Systems', 'Oral', 'Policies', 'Public Health', 'Research', 'Research Personnel', 'Series', 'Shapes', 'Statistical Algorithm', 'Statistical Methods', 'Statistical Models', 'System', 'Time', 'Translating', 'Update', 'War', 'Work', 'Yemen', 'base', 'case-based', 'curve fitting', 'dashboard', 'disease transmission', 'experience', 'flexibility', 'improved', 'innovation', 'mortality', 'multidimensional data', 'programs', 'prospective', 'response', 'simulation', 'sound', 'surveillance data', 'theories', 'tool', 'transmission process', 'user-friendly']",NIGMS,JOHNS HOPKINS UNIVERSITY,R01,2021,429701
"Differential Scanning Fluorimetry (DSF) Methods for Studying Protein Stability Abstract. There is great interest in technologies that measure protein stability, because many devastating diseases (e.g. cystic fibrosis, Alzheimer’s disease) are linked to protein misfolding and instability. One especially promising way to treat these diseases is to use small molecules, termed “correctors” that bind to the damaged protein and partially restore its folding. Multiple correctors have received FDA approval (e.g. ivacaftor, tafamadis, migalastat), but there are hundreds of additional misfolding diseases. What are the hurdles to the rapid discovery of additional correctors? One important barrier is that previous correctors have been uncovered through prolonged searches, using specialized (i.e. target-specific) technologies that are not versatile enough for use across many proteins-of-interest (POIs). Here, we propose next-generation Differential Scanning Fluorimetry (DSF) to fill this gap. In a typical DSF experiment, a POI is heated in a qPCR instrument and its un-folding is monitored by its binding to a solvatochromatic dye (e.g. Sypro Orange, SO). The resulting temperature vs. fluorescence curves are then used to estimate the melting transition (Tm), with putative correctors identified by their effect on this value (DTm). DSF is versatile because it does not require protein labeling or structural knowledge. Moreover, unlike comparable platforms, such as circular dichroism (CD) or differential scanning calorimetry (DSC), DSF is amenable to 384-well plate format, facilitating large-scale chemical screens. While DSF has the potential to transform corrector discovery, there are major hurdles to overcome. For example, DSF often fails because SO does not bind the target protein or it binds to hydrophobic patches on the native state, obscuring the Tm. Further, for some POIs, the temperature-fluorescence curves are complex, with multiple transitions, and therefore not readily analyzed or fit using standard equations. Based on our preliminary screens of ~50 different proteins, these issues cause DSF to fail in more than 60% of cases. We propose to solve these issues through disruptive innovations: (SA1) Design and synthesis of next-generation dye libraries that significantly expand the scope of DSF and (SA2) Theory- and experiment-driven, dramatic improvements in data analysis, enabled by machine learning and made publicly available through a web portal (DSFWorld). Encouraged by preliminary success, we also propose to: (SA3) Expand the scope of DSF applications by pioneering studies of multi-protein complexes and conformational changes. Importantly, we will benchmark each of these innovations against current state-of-the-art approaches, with a focus on a critical understanding of strengths and weaknesses. Together, these studies are expected to dramatically expand the scope of DSF technology. PROJECT NARRATIVE. Protein instability is the cause of many devastating and untreatable human diseases. We propose to build an exciting new technology for rapidly measuring protein stability, enabling screens for new therapeutics that correct these defects.",Differential Scanning Fluorimetry (DSF) Methods for Studying Protein Stability,10184149,R01GM141299,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Benchmarking', 'Binding', 'Binding Proteins', 'CD69 antigen', 'Chemicals', 'Chemistry', 'Chromatin Remodeling Factor', 'Circular Dichroism', 'Clinical', 'Collaborations', 'Complex', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Databases', 'Defect', 'Differential Scanning Calorimetry', 'Disease', 'Drug Targeting', 'Dyes', 'Equation', 'Failure', 'Fluorescence', 'Goals', 'Gold', 'Hydrophobicity', 'Individual', 'Kinetics', 'Knowledge', 'Label', 'Libraries', 'Ligand Binding', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Membrane', 'Methods', 'Modality', 'Molecular Conformation', 'Monitor', 'Multiprotein Complexes', 'Neurodegenerative Disorders', 'Nucleic Acid Binding', 'Oranges', 'Pharmaceutical Chemistry', 'Pilot Projects', 'Process', 'Property', 'Proteins', 'Reporting', 'Research', 'Role', 'Scanning', 'Series', 'Specificity', 'Structure', 'Structure-Activity Relationship', 'System', 'Technology', 'Temperature', 'Testing', 'Therapeutic', 'Time', 'Work', 'aerobic respiration control protein', 'base', 'cheminformatics', 'conformational conversion', 'design', 'enzyme activity', 'experimental study', 'high throughput screening', 'high throughput technology', 'human disease', 'improved', 'innovation', 'instrument', 'interest', 'large datasets', 'melting', 'metalloenzyme', 'new technology', 'next generation', 'novel therapeutics', 'protein complex', 'protein folding', 'protein misfolding', 'reconstitution', 'simulation', 'small molecule', 'success', 'tau Proteins', 'theories', 'web portal']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,390539
"Synthetic biology and organelle genomics: A rubisco library as a case study in evolutionary landscapes and organellar engineering Food security is a critical issue facing human health in the 21st century as the global population  approaches 10 billion and climate change threatens the food supply. Photosynthetic engineering has  been successful in improving crop yields but the central enzyme of carbon fixation, rubisco, has  remained intractable as a target of molecular evolution. The few plants tested with heterologous  rubiscos grow uniformly slower than their wild-type counterparts. The goal of this proposal is to  generate a chloroplast genome library in plants to explore the limits of rubisco function and  organellar genome organization. In Aim 1 of this proposal I will explore the sequence-function landscape of a model, homodimeric  rubisco enzyme and a novel, linked variant I have generated. I have generated a deep-mutational  scan (OMS: all possible point-mutants) library and will assay their function in a uniquely suited  rubisco-dependent E. coli strain. I have shown that these linked rubiscos function in vivo and in  vitro and have already constructed the mutant library; in the K99 phase of this project I will  perform selections on this library and analyze the data with a machine learning model. In the R00  phase I will generate further libraries to explore regions of the sequence landscape predicted to  be rich in improved rubiscos with the goal of testing them in plants. In Aim 2 I will improve chloroplast transformation technology in order to enable the generation of  chloroplast genome libraries of unprecedented size in the chloroplast-editing model plant N.  tabacum. To do this I will generate sequence-specific TALEN nucleases that will be expressed from  the nuclear genome and trafficked to the chloroplast where they will cut and disrupt the genome,  preferencing homologous recombination of transgenic donor ONA. After demonstrating TALEN-cutting in  the K99 phase I will develop this technology into an intracellular gene drive which will accelerate  chloroplast genome editing. In Aim 3, with the technology developed in Aim 2 and the rubisco variants discovered in Aim 1, I  will generate libraries of plants with altered rubisco genes and promoters in order to demonstrate  the potential of rubisco engineering to improve plant growth. In addition, in the R00 phase, I will  produce a comprehensive chloroplast gene knockout library in order to answer fundamental questions  about the evolutionary flow of genes from organellar genomes to nuclear genomes. My goal as an independent investigator is to study organellar biology in model plants in order to  explore the limits of engineering in individual proteins and metabolic pathways. My training in  organellar transformation, protein library generation and laboratory management during the K99  phase will prepare me well for the R00 phase. The Innovative Genomics Institute at UC Berkeley and  the laboratories of Ors. Oavid Savage and Brian Staskawicz in particular are the ideal environment  for my career transition, combining precisely the necessary mixture of expertise - protein  evolution and plant transformation, respectively. The goal of this proposal is to overcome the fundamental limits of the carbon-fixing enzyme rubisco  and to translate that knowledge into improvements in carbon fixation efficiencies in transgenic  plants. By studying a wider array of genes, gene variants and expression levels, the chloroplast  transformation technologies proposed here have the potential to reshape our understanding of the  limits of photosynthetic yield in plants. Insights from this work will advance basic and applied  biology fields including metabolic control, protein evolution, biochemistry, organellar genome  organization and genome editing.",Synthetic biology and organelle genomics: A rubisco library as a case study in evolutionary landscapes and organellar engineering,10191932,K99GM141455,"['Address', 'Basic Science', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Models', 'Biology', 'Carbon', 'Career Mobility', 'Case Study', 'Chloroplasts', 'Data', 'Engineering', 'Environment', 'Enzymes', 'Escherichia coli', 'Evolution', 'Food Supply', 'Future', 'Gene Expression', 'Gene Library', 'Gene Mutation', 'Generations', 'Genes', 'Genome', 'Genomic Library', 'Genomics', 'Goals', 'Growth', 'Health', 'Human', 'In Vitro', 'Individual', 'Institutes', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic Control', 'Metabolic Pathway', 'Modeling', 'Molecular Evolution', 'Molecular Target', 'Mutate', 'Nuclear', 'Nutritional', 'Organelles', 'Outcome', 'Phase', 'Photosynthesis', 'Plant Model', 'Plants', 'Population', 'Process', 'Protein Isoforms', 'Proteins', 'Research Personnel', 'Ribulose-Bisphosphate Carboxylase', 'Science', 'Series', 'Technology', 'Testing', 'Tobacco', 'Training', 'Transgenic Organisms', 'Transgenic Plants', 'Translating', 'Variant', 'Work', 'carbon fixation', 'career', 'climate change', 'design', 'experimental study', 'food security', 'genetic selection', 'genetic variant', 'genome editing', 'homologous recombination', 'improved', 'in vivo', 'innovation', 'insight', 'knockout gene', 'metabolic engineering', 'mutant', 'mutation screening', 'novel', 'nuclease', 'plant growth/development', 'preference', 'promoter', 'synthetic biology', 'technology development', 'transcription activator-like effector nucleases']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,K99,2021,93852
"Clinical significance and genetic determinants of novel imaging measures of emphysema distribution in 9,743 smokers PROJECT SUMMARY/ABSTRACT Candidate: Dr. Adel El Boueiz is a pulmonary and critical care physician-scientist completing a period of T32- funded support at the Channing Division of Network Medicine (CDNM) and Harvard Medical School (HMS). He received a Master's of Medical Science in Biomedical Informatics from HMS in May 2016. He will be promoted to Instructor of Medicine at the CDNM and HMS on July 1, 2017. His principal research interests are the genetic epidemiology of chronic obstructive pulmonary disease (COPD) and the translation of genomic discoveries into clinical practice and public health. His long-term goal is to be an independent investigator with expertise in imaging phenotyping, genomics, and predictive analytics of the regional heterogeneity of the various aspects of COPD (emphysema, airway disease, and pulmonary vascular remodeling). Environment: Dr. El Boueiz will continue to pursue his research and career development in the rich and multidisciplinary environment of the CDNM and the Brigham and Women's Hospital Applied Chest Imaging Lab (ACIL). He will be mentored by Drs. Edwin K. Silverman, Peter J. Castaldi, and Raúl San José Estépar, leaders in the field of COPD quantitative imaging, genetic epidemiology, and predictive analytics with excellent track records of mentoring young investigators towards independent research careers. His career development will also be overseen by an advisory committee with expertise related to key areas of his proposal. Research: COPD is a major cause of morbidity and mortality that is of increasing public health importance. COPD is a heterogeneous disease and this heterogeneity complicates the identification of the predictors of disease progression and consequently, the development of effective therapies. Emphysema distribution is an important COPD-related phenotype that emerged as a strong predictor of the response to lung volume reduction procedures. Despite the availability of advanced texture-based CT quantification methods, global threshold-based quantitative metrics have to date been the cornerstone for the radiological characterization of emphysema distribution with inability to differentiate centrilobular, panlobular, and paraseptal emphysema patterns. In this project, we will apply a texture-based CT quantification method to discover novel imaging biomarkers of the regional heterogeneity of centrilobular, panlobular, and paraseptal emphysema in a large cohort of well-characterized smokers and identify their genetic determinants using whole genome sequencing and integrative genomics analyses. The results will be considered for inclusion along with other rich phenotypic and imaging data in COPD disease progression machine learning predictive models. Relevance: Through improved radiographic phenotyping of emphysema distribution, better understanding of disease pathobiology, and more accurate prediction of disease progression, the proposed work will open new avenues of investigation for the development of personalized and improved COPD therapeutic strategies. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is a common disease that affects up to 24 million people in the United States, is associated with considerable and increasing morbidity and mortality, and for which there is no available disease-modifying therapy. COPD is associated with significant variation in radiographic, symptomatic and physiologic presentation and exhibits variability in progression. Currently, there is no satisfactory method for progression prediction. This project will identify novel imaging biomarkers of the regional distribution of centrilobular, panlobular, and paraseptal emphysema with particular emphasis on their associations with clinical relevant COPD-related outcomes, their genetic determinants, and their ability to improve prediction of COPD disease progression, above and beyond that provided by the traditional clinical, radiographic, and genetic features. This is an important area of research as predicting those patients who will remain stable from those who will have rapid disease progression is critical in defining prognosis and selecting patients for specific therapeutic interventions.","Clinical significance and genetic determinants of novel imaging measures of emphysema distribution in 9,743 smokers",10208938,K08HL141601,"['ACVR1B gene', 'Accounting', 'Advisory Committees', 'Affect', 'Airway Disease', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological Process', 'Chest', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Clinical/Radiologic', 'Cohort Studies', 'Collection', 'Complex', 'Computing Methodologies', 'Critical Care', 'Data', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Dyspnea', 'Environment', 'Evaluation', 'Exhibits', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Polymorphism', 'Genomic approach', 'Genomics', 'Goals', 'Heterogeneity', 'Hospitals', 'Image', 'Investigation', 'Lobar', 'Lobe', 'Lung', 'Lung Volume Reductions', 'Lung diseases', 'Machine Learning', 'Measures', 'Medical', 'Medical Genetics', 'Medical Research', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Outcome', 'Pathologic', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Physiological', 'Positioning Attribute', 'Predictive Analytics', 'Procedures', 'Prognosis', 'Public Health', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quantitative Trait Loci', 'Radiology Specialty', 'Records', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Smoker', 'Structure of parenchyma of lung', 'Subgroup', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Intervention', 'Tissues', 'Translations', 'United States', 'Variant', 'Vascular remodeling', 'Visual', 'Walking', 'Woman', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'biomedical informatics', 'career', 'career development', 'clinical practice', 'clinically relevant', 'clinically significant', 'cohort', 'comorbidity', 'data mining', 'disease heterogeneity', 'disease phenotype', 'disorder risk', 'disorder subtype', 'effective therapy', 'genetic architecture', 'genetic association', 'genetic epidemiology', 'genetic predictors', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic predictors', 'imaging biomarker', 'imaging genetics', 'improved', 'instructor', 'interest', 'machine learning method', 'medical schools', 'mortality', 'multidisciplinary', 'novel', 'personalized care', 'predicting response', 'predictive modeling', 'prognostic', 'pulmonary function', 'quantitative imaging', 'rare variant', 'research and development', 'respiratory', 'whole genome']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,170639
"Accelerated discovery of synthetic polymers for ribonucleoprotein delivery through the integration of active learning, machine learning, and polymer science PROJECT SUMMARY/ABSTRACT Gene editing systems such as CRISPR/Cas9 have rapidly grown in popularity as research tools and hold the potential to cure a diverse set of genetic disorders. However, effective, safe, and effective delivery remains a significant challenge for therapeutic translation and for application to cell types that are difficult to culture ex vivo. Ideally, intact Cas9 protein would be delivered with its guide RNA (sgRNA) as a purified ribonucleoprotein (RNP), as opposed to Cas9-encoding mRNA or plasmids, to minimize off-target effects. Viral vectors (e.g., AAVs) cannot deliver such large cargo due to their limited capsid size, which exhibit additional challenges with respect to immunogenicity, cost, and manufacturability. Fortunately, synthetic polymers--widely studied in the context of nucleic acid delivery and as biomaterials--have recently shown promise as vehicles for in vivo delivery of sgRNA- Cas9 RNPs. However, there are no consistent design principles by which novel synthetic polymers with improved delivery efficiency, tissue specificity, and safety can be developed. There are far too many polymer structures to test exhaustively or through ad hoc experimentation, so a systematic approach to polymer design, synthesis, and evaluation is required to identify promising candidates. This proposal presents a framework for the discovery of functional polymers through Bayesian experimental design. Machine learning models trained on experimental outcomes will serve as surrogates for experimentation in order to virtually screen a massive library of potential polymer candidates. Polymer candidates will be selected algorithmically through Bayesian Optimization to balance exploration of unknown chemical space and exploitation of structures known to effectively deliver RNPs. Aim 1 will involve (a) the synthesis of a diverse library of biodegradable poly(ester urea amines) (PEUAs), (b) the evaluation of their functional performance using a model fluorescent reporter knock-in/knock-out assay, a cell viability assay, and a metabolic activity assay, and (c) the development and validation of a machine learning model to learn a quantitative relationship between polymer structure/composition and these multiple performance metrics. Aim 2 will involve (a) the enumeration of the chemical space of synthetically accessible PEUAs, and (b) the development and application of a Bayesian Optimization framework leveraging the machine learning model from Aim 1 to guide the selection of candidate polymers from the enumerated space through iterative rounds of experimentation. The outcome of the proposed work will be an integrated tool combining machine learning and polymer science for the unbiased exploration of a broad biomaterial design space, validated through the development of effective and safe RNP delivery vehicles for gene editing that outperform existing commercial polymeric vehicle solutions. NARRATIVE Gene editing is a powerful technology with the potential to cure a wide variety of genetic disorders, but methods for delivering gene editing systems into live cells exhibit significant limitations. The current proposal combines concepts in active learning, machine learning, and polymer science to discover new synthetic polymers with improved delivery performance. Such a platform will lead to safer, cheaper, and more effective delivery of gene therapies and will be broadly applicable to the discovery of polymers for other biomedical applications.","Accelerated discovery of synthetic polymers for ribonucleoprotein delivery through the integration of active learning, machine learning, and polymer science",10195432,R21GM141616,"['Active Learning', 'Algorithms', 'Amines', 'Architecture', 'Biocompatible Materials', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Capsid', 'Cell Survival', 'Cell model', 'Cells', 'Chemicals', 'Clinical Trials', 'Complex', 'DNA', 'Data', 'Development', 'Equilibrium', 'Esters', 'Evaluation', 'Exhibits', 'Experimental Designs', 'Gene Delivery', 'Genes', 'Genetic Diseases', 'Guide RNA', 'Human', 'Knock-in', 'Knock-out', 'Learning', 'Length', 'Libraries', 'Lipids', 'Machine Learning', 'Maps', 'Mediating', 'Messenger RNA', 'Metabolic', 'Methods', 'Modeling', 'Outcome', 'Performance', 'Plasmids', 'Polymer Chemistry', 'Polymers', 'Property', 'Proteins', 'RNA', 'RNA delivery', 'Reporter', 'Research', 'Ribonucleoproteins', 'Ribonucleotides', 'Safety', 'Science', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Translations', 'Urea', 'Validation', 'Viral Vector', 'Work', 'base', 'biomaterial compatibility', 'candidate selection', 'cell type', 'cheminformatics', 'cost', 'cytotoxicity', 'design', 'exhaustion', 'experimental study', 'gene therapy', 'immunogenicity', 'improved', 'in silico', 'in vivo', 'manufacturability', 'manufacturing process', 'novel', 'nucleic acid delivery', 'polypeptide', 'relating to nervous system', 'tool', 'virtual', 'virtual screening']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2021,197622
"Manifold representations and active learning for 21 st century biology Project Summary With the rise of high-throughput sequencing and multiplexed biotechnologies enabling single-cell multi-omics and massively parallel CRISPR experiments, the biomedical community is generating a monumental amount of data. These data promise to reveal new biology and drive personal and precision medicine. However, the sheer volume of genomic data is overwhelming current computational resources, requiring prohibitively high compute time, memory usage, and storage. My lab has been at the forefront of solving big data challenges in genomics, designing novel algorithms that enable efficient and secure analyses that were previously computationally infeasible, and that reveal novel structural, cellular, and systems biology. Drawing upon our expertise in developing scalable and insightful algorithms for analyzing genomic, transcriptomic, and proteomic data, we aim to tackle two key data-driven challenges facing the biological community: 1) efficient, accurate, and robust characterization of tissues at the single-cell level, and 2) translating high-throughput datasets into biological discoveries via machine learning-based prediction. To solve the first challenge, we will leverage our discovery that seemingly high-dimensional sequencing data often lies on low-dimensional manifolds that capture the underlying biological state of interest. We will design algorithms that generate these compact, meaningful manifold representations of single-cell omics datasets. This will enable a number of key applications including characterizing co-expression and gene-modules that define healthy and pathologic cell states; integrating multi-modal single-cell omics datasets to more richly characterize cellular diversity; and investigating the mechanisms underlying transcriptomic diversity across tissues and developmental states. To solve the second challenge, we will take a two-pronged approach. First, we will design novel machine learning frameworks that provide a measure of confidence when predicting in unfamiliar biological states, enabling prediction that is robust to “out-of-distribution” (unobserved) examples. We will then work with our experimental collaborators and CROs to rapidly perform experimental validation of model-based predictions. Finally, we will return the experimental results to the model to further improve performance. This will enable an “active learning” feedback loop to efficiently explore a complex biological space for outcomes of interest. We will use this uncertainty-powered active learning approach to explore several pressing biological concerns such as the identification of small molecule compounds with enzymatic or whole-cell growth inhibitory properties, efficient design of spatial- transcriptomic experiments, computationally guided CRISPR perturbation experiments, and identification of functional non-coding mutations. This project will result in 1) numerous software tools with wide utility that efficiently analyze massive biological datasets and guide complex experimentation, and 2) reveal biological insights, especially into biomolecular interactions and cellular heterogeneity. Project Narrative The rise of high-throughput genomic profiling of individual cells and efficient, targeted manipulation of cellular phenotypes (including CRISPR-based genetic perturbations) promise to revolutionize our understanding of cellular biology and disease. However, realizing this revolution will require new computing paradigms that can integrate and analyze these massive datasets and suggest new biological hypotheses and experimental designs. Here we develop novel computational algorithms and software for tackling these challenges to characterize cellular diversity and improve our ability to manipulate cells to understand and treat disease.",Manifold representations and active learning for 21 st century biology,10207091,R35GM141861,"['Active Learning', 'Algorithm Design', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Big Data', 'Biological', 'Biology', 'Biotechnology', 'Cells', 'Cellular biology', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complex', 'Computational algorithm', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Experimental Designs', 'Feedback', 'Genes', 'Genetic', 'Genomics', 'Heterogeneity', 'High-Throughput Nucleotide Sequencing', 'Individual', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Mutation', 'Outcome', 'Pathologic', 'Performance', 'Phenotype', 'Property', 'Proteomics', 'Secure', 'Software Tools', 'Spatial Design', 'State Interests', 'Systems Biology', 'Time', 'Tissues', 'Translating', 'Uncertainty', 'Untranslated RNA', 'Validation', 'Work', 'base', 'cell growth', 'computing resources', 'design', 'experimental study', 'genomic data', 'high dimensionality', 'improved', 'insight', 'interest', 'multimodality', 'multiple omics', 'novel', 'precision medicine', 'small molecule', 'structural biology', 'transcriptomics']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R35,2021,478341
"Systems Metabolomics for Biomarker Discovery PROJECT SUMMARY Metabolomics offers a comprehensive analysis of thousands of small molecules in biological samples. It can play an indispensable role in the growing systems biology approaches to unravel the relationships between metabolites and diseases. Liquid chromatography coupled to mass spectrometry (LC-MS) and gas chromatography coupled to mass spectrometry (GC-MS) have been used for high-throughput analysis of thousands of metabolites. However, the potential values of many disease-associated metabolites discovered by using these platforms have been inadequately explored in systems biology approaches for biomarker discovery due to lack of computational tools and resources to: (1) accurately determine the identity of most of the metabolites; (2) investigate the rewiring interactions among the metabolites due to diseases; and (3) integrate metabolite profiles with those from other omics studies to evaluate the relationships between the metabolites and the diseases at the systems level. Partly due to these limitations, poor generalizability of previously identified metabolite biomarker candidates has been observed, especially when they are evaluated through independent platforms and validation sets. Therefore, new methods are sought to find more generalizable metabolite biomarker candidates. The goal of this research program is to fill the gaps in metabolite identification and multi- omics integration by using systems metabolomics approaches that will enhance the role of metabolomics in systems biology approaches for biomarker discovery. Specifically, the proposed research program will utilize multiple resources (biological databases, spectral libraries, etc.) and innovative statistical, machine learning, and network-based methods for: (1) developing a comprehensive workflow for ranking putative metabolite IDs; (2) differential analysis of metabolite profiles based on changes in the levels of individual metabolites and pairwise interactions in disease vs. control groups; and (3) integration of metabolomics data with genomics, transcriptomics, proteomics, and glycoproteomics data to identify highly promising metabolite biomarker candidates. Our recent progress has led to acquisition of multi-omics data and development of computational tools for metabolite identification and integrative analysis. The performance of the proposed metabolite identification workflow in ranking putative metabolite IDs will be evaluated through experimental methods using reference compounds. The differential and integrative analysis methods will be used for selection of candidate biomarkers via multi-omics data acquired in biomarker discovery studies. The selected candidates will be evaluated by targeted quantitation using independent samples and platforms compared to those used for discovery. The outcomes of these experimental evaluations will be used not only to help refine the computational methods but also to identify promising biomarker candidates. In summary, the proposed research program seeks to capitalize on the power of network modeling, machine learning, and multi-omics data integration to improve the ability to find disease biomarkers that are likely to succeed in future large-scale biomarker validation studies. PROJECT NARRATIVE The goal of this research program is to develop computational methods that enhance the role of metabolomics in systems biology approaches for biomarker discovery. Specifically, statistical, network-based, and machine learning methods will be developed for ranking putative metabolite IDs and selection of metabolite biomarker candidates. The performance of the proposed methods for metabolite identification and biomarker selection will be evaluated through experimental methods including: (1) comparing the fragmentation patterns of unknown analytes against those from reference compounds; and (2) targeted quantitative analysis of selected metabolites. 2",Systems Metabolomics for Biomarker Discovery,10206465,R35GM141944,"['Biological', 'Biological Markers', 'Biological databases', 'Computing Methodologies', 'Control Groups', 'Coupled', 'Data', 'Development', 'Disease', 'Evaluation', 'Future', 'Gas Chromatography', 'Genomics', 'Goals', 'Individual', 'Libraries', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Multiomic Data', 'Network-based', 'Outcome', 'Pattern', 'Performance', 'Play', 'Proteomics', 'Research', 'Resources', 'Role', 'Sampling', 'System', 'Systems Biology', 'Validation', 'base', 'biomarker discovery', 'biomarker selection', 'biomarker validation', 'candidate marker', 'candidate selection', 'computerized tools', 'computing resources', 'data integration', 'glycoproteomics', 'high throughput analysis', 'improved', 'innovation', 'machine learning method', 'metabolomics', 'multiple omics', 'network models', 'platform-independent', 'programs', 'small molecule', 'statistical and machine learning', 'transcriptomics', 'validation studies']",NIGMS,GEORGETOWN UNIVERSITY,R35,2021,390000
"Development of a pipeline for parallel elucidation of protein structures Advances in biophysical technologies have accelerated our ability to probe the mechanisms of even the most complex cellular systems, and such studies have enabled researchers to design modifications to known protein structures and design completely new proteins. This “protein design” technology has given rise to an ability to manipulate protein structures as a means of improving on or introducing new medical diagnostics and therapeutics. The bases of these studies rely on computational modeling of protein candidates, although the accuracy of protein structure prediction, protein de novo design, and single-mutation effects prediction remain below the threshold for many use cases, such as structure-guided drug design and rational enzyme engineering. Thus, success of a protein engineering effort relies on high-resolution structure determination, which involves laborious screening and optimization in order to obtain stable proteins or active enzyme variants. However, our ability to observe protein structure using common structure determination strategies (X-ray crystallography, NMR, and cryo-electron microscopy (cryo-EM)) lags far behind our ability to design and produce new sequences, creating a knowledge gap that prevents biochemists from accessing the range of protein functions seen in nature. While current technologies enable rapid synthesis of hundreds of proteins with varied sequences, there do not exist technologies for rapid structural characterization of these generated proteins. The ability to obtain high- resolution structural information for hundreds of sequences in parallel would provide invaluable insights in protein engineering methods. Importantly, rapid structure determination would enable structural characterization of genetic variation in the human genome underlying disease by enabling the structural and mechanistic interpretation of rare and de novo disease-related variants. Cryo-EM enables numerous high-resolution structures to be determined from a small amount of sample without requiring homogeneity, an aspect of this method that we plan to exploit for parallel elucidation of protein structures. We will establish the feasibility of this technique for rapidly investigate the structures of engineered protein libraries, where the molecular weight range is near or below the lower detection limit of cryo-EM. We will also probe the limits of our ability to identify the location and structural impact of tested mutations at limited structural locations, such as active sites. We will explore the feasibility of our parallel structure determination approach in two aims: Aim 1 will identify the limit of current single-particle analysis methods to discriminate between structurally similar protein complexes. Aim 2 will implement machine learning algorithms to push the current limits of classification using a combination of synthetic and real data. These exploratory studies will pave the way to rapid structure determination of multiple protein complexes from a single cryo-EM experiment, providing the ability to rapidly obtain high-resolution structures for many engineered proteins, thereby enabling unprecedented design and testing feedback cycles to help treat human disease. Narrative Our understanding of structure-function relationships has matured to the point that we can now manipulate the composition of proteins as a means of producing diagnostics or therapeutics for human disease. However, in order to fully elucidate the biochemical mechanisms of function that drive these protein design studies, structures of the designed proteins must be determined. However, structure determination is a massive bottleneck, which we plan to overcome by establishing a platform for massively parallelized structure determination of protein targets that is commensurate with the rate of protein production involved in protein design studies.",Development of a pipeline for parallel elucidation of protein structures,10231713,R21GM142196,"['Active Sites', 'Amino Acid Sequence', 'Biochemical', 'Biochemical Process', 'Biological', 'Biological Assay', 'Biophysics', 'Biotechnology', 'Classification', 'Clinic', 'Complex', 'Computer Models', 'Cryoelectron Microscopy', 'Crystallography', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Drug Design', 'Engineering', 'Enzymes', 'Feedback', 'Foundations', 'Genetic Variation', 'Heart', 'Human Genome', 'Image', 'Knowledge', 'Lead', 'Libraries', 'Location', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Conformation', 'Molecular Weight', 'Mutation', 'Names', 'Nature', 'Performance', 'Preparation', 'Production', 'Property', 'Protein Biochemistry', 'Protein Engineering', 'Proteins', 'Proteomics', 'Research Design', 'Research Personnel', 'Resolution', 'Sampling', 'Shapes', 'Statistical Methods', 'Structural Models', 'Structural Protein', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'classification algorithm', 'de novo mutation', 'deep learning', 'design', 'detection limit', 'experimental study', 'genome sequencing', 'human disease', 'image processing', 'improved', 'in silico', 'insight', 'knowledge base', 'machine learning algorithm', 'particle', 'prevent', 'programs', 'protein complex', 'protein folding', 'protein function', 'protein structure', 'protein structure prediction', 'rapid technique', 'screening', 'success', 'therapeutic development', 'tool', 'variant of unknown significance']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R21,2021,221875
"Learning about the evolution of structural variations from genomic and transcriptomic data PROJECT SUMMARY Structural variations are key drivers of both evolutionary adaptation and human disease. My group develops and applies computational and statistical approaches for understanding the evolution of structural variations from patterns in their genomic and transcriptomic data. During the past few years, our studies have focused primarily on gene duplication, which represents the most common type of structural variation observed in nature. In particular, we investigated the origins of evolutionary innovation after gene duplication, a problem of long- standing interest in the evolutionary genomics community. To answer this question, we designed the first method for classifying evolutionary outcomes of duplicate genes from phylogenetic comparisons of their gene expression profiles. By applying this decision tree method to multi-tissue gene expression data, we were able to classify evolutionary outcomes of duplicate genes in Drosophila, mammals, and grasses. These studies revealed frequent tissue-specific expression divergence after duplication, as well as sequence and expression differences within and among taxa that are consistent with natural selection. In a follow-up population-genomic analysis, we demonstrated that natural selection indeed plays an important role in the evolutionary outcomes of young duplicate genes in Drosophila. Later, we developed analogous decision tree classifiers for two additional types of structural variations: gene deletion and translocation. Applications of our methods to sequence and expression data from multiple tissues and developmental stages in Drosophila uncovered rapid divergence concordant with adaptation, suggesting that natural selection shapes the evolutionary trajectories of structural variations generated by deletion and translocation as well. However, our recent analyses revealed that there are many limitations of these decision tree methods, including sensitivity to gene expression stochasticity, lack of statistical support, and inability to predict parameters driving the evolution of structural variations. Thus, during the next five years, my group will develop a suite of tailored model-based statistical and machine learning approaches for classifying the evolutionary outcomes and predicting the evolutionary parameters of structural variations arising from duplication, deletion, inversion, and translocation events. Our preliminary studies indicate that these techniques will be much more powerful and accurate than previous approaches, and will therefore compose major advancements in evolutionary investigations of structural variations. In addition to implementing our methods in open source software packages, we will apply them to assay the evolutionary implications of different types of structural variations in humans and several other animal and plant taxa. Comparisons will be made among different types of structural variations, their evolutionary outcomes, and taxonomic groups. The major goal of these studies will be to ascertain the general rules by which different types of structural variation contribute to evolutionary innovation. Together, these studies will shed light on how gene duplication, deletion, inversion, and translocation work in concert to generate a diversity of complex adaptations across the tree of life. PROJECT NARRATIVE Just like a population of organisms, genome size and composition can change over time via births, deaths, and migrations of large DNA segments. These mutation events result in genomic structural variations among individuals that underlie many important human adaptations, such as color vision, and diseases, such as cancer. The work proposed here seeks to develop and apply powerful new computational and statistical techniques for investigating the outcomes of structural variations in humans and other species, thereby both enhancing our understanding of past evolutionary history and advancing future biomedical research.",Learning about the evolution of structural variations from genomic and transcriptomic data,10270302,R35GM142438,"['Animals', 'Automobile Driving', 'Biological Assay', 'Biomedical Research', 'Birth', 'Cessation of life', 'Color Visions', 'Communities', 'Complex', 'Computer software', 'DNA', 'Data', 'Decision Trees', 'Development', 'Disease', 'Drosophila genus', 'Event', 'Evolution', 'Future', 'Gene Deletion', 'Gene Duplication', 'Gene Expression', 'Genome', 'Genomics', 'Goals', 'Human', 'Individual', 'Investigation', 'Investigative Techniques', 'Learning', 'Life', 'Light', 'Malignant Neoplasms', 'Mammals', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Nature', 'Organism', 'Outcome', 'Pattern', 'Phylogenetic Analysis', 'Plants', 'Play', 'Poaceae', 'Population', 'Recording of previous events', 'Role', 'Shapes', 'Structure', 'Taxonomy', 'Techniques', 'Time', 'Tissues', 'Trees', 'Variant', 'Work', 'base', 'design', 'follow-up', 'gene translocation', 'genomic variation', 'human disease', 'innovation', 'interest', 'migration', 'open source', 'statistical and machine learning', 'structural genomics', 'transcriptomics']",NIGMS,FLORIDA ATLANTIC UNIVERSITY,R35,2021,370065
"Evolution-guided machine learning for inferring natural selection Project Summary/Abstract A fundamental question in genomics is to understand natural selection on coding and noncoding sequences. Signatures of natural selection encoded in polymorphism and divergence data not only elucidate the patterns of evolution but also pinpoint deleterious genetic variants responsible for genetic disorders. While numerous com- putational methods have been developed to infer sequences under various types of natural selection, the existing methods suffer from two critical limitations. First, most of the methods for inferring natural selection focus on an- alyzing individual loci. Due to the intrinsic sparsity of polymorphism and divergence data, the single-locus-based approaches are often underpowered. Second, when multiple genomic features are correlated with signatures of natural selection, the existing methods are incapable of distinguishing causal genomic features from corre- lated confounders. Due to these limitations, we still lack powerful computational frameworks to identify loci and genomic features responsible for natural selection. During the next ﬁve years, l will address the limitations of exist- ing methods by combining evolutionary models and ﬂexible machine learning techniques. Speciﬁcally, I formulate the inference of natural selection as a special regression problem in which genomic features are input covariates whereas polymorphism and divergence data are response variables. Based on this idea, my lab will develop a suite of evolution-guided machine learning models to infer negative, positive, and lineage-speciﬁc selection. These customized machine learning models will boost the statistical power of selection inference by pooling data across large numbers of loci, and will be able to distinguish genomic determinants from confounders. These new models will be applied to investigate various types of natural selection in the human genome. In addition, a genome-wide map of deleterious variants under strong negative selection will be developed for accurate variant prioritization. The proposed research builds on my recent work for predicting functional noncoding sequences, inferring selection coefﬁcients of coding variants, and unifying variant-level and gene-level prioritization methods. It will illustrate new insights into genomic determinants of functional sequences and human adaptive evolution, and will provide powerful computational tools for identifying disease mutations. It could also serve as a basis for the emerging paradigm of combining classical evolutionary theory and machine learning methods to address a variety of questions in evolutionary biology. Project Narrative Natural selection is a fundamental force of evolution and a hallmark of functional sequences. However, it is challenging to identify loci and genomic features responsible for natural selection due to the intrinsic sparsity of polymorphism and divergence data at a single locus. By combining evolutionary models and machine learning techniques, we can infer loci under natural selection at an unprecedented resolution, distinguish genomic deter- minants of natural selection from confounders, and accurately identify pathogenic variants from the footprints of negative selection.",Evolution-guided machine learning for inferring natural selection,10273742,R35GM142560,"['Address', 'Biology', 'Code', 'Computing Methodologies', 'Custom', 'Data', 'Data Pooling', 'Disease', 'Evolution', 'Genes', 'Genetic Diseases', 'Genetic Polymorphism', 'Genomics', 'Human', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Pathogenicity', 'Pattern', 'Research', 'Resolution', 'Techniques', 'Untranslated RNA', 'Variant', 'Work', 'base', 'computer framework', 'computerized tools', 'flexibility', 'genetic variant', 'genome-wide', 'insight', 'machine learning method', 'response', 'theories']",NIGMS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R35,2021,373274
"Statistical and Machine Learning Methods to Address Biomedical Challenges for Integrating Multi-view Data Project Summary Many diseases are complex, heterogeneous, conditions that affect multiple organs in the body and depend on the interplay between several factors that include genetic, cellular, molecular, and environmental factors. It is therefore not surprising that the pathogenesis of many complex diseases remain elusive, and therapeutic targets are lacking. The traditional approach that focus on a small number of molecules (e.g., genes or metabolites) or a single type of data (e.g., clinical or genetic) cannot address this complexity and heterogeneity. Integrative or systems biology approaches and network analysis can be used to leverage the strengths of data from multiple sources (e.g., genomics, metabolomics, epidemiology, clinical data) to achieve new insights into the pathobiology of complex diseases. Recent technological advances have enabled the production of vast amounts of diverse but related data with rich information that offer remarkable opportunities to understand biological processes involved in complex diseases and to transform medicine, yet at the same time present signiﬁcant analytical challenges including how to effectively synthesize information from the tens of thousands of data points to identify important biomarkers with potential to serve as therapeutic targets. To alleviate this, we will develop and apply a suite of novel, robust, and powerful statistical and machine learning methods for the integration and interpretation of cross-sectional and longitudinal data from multiple sources. These models will also be used to deﬁne subpopulations of patients who have different prognoses or require different therapeutic approaches based on data from different sources. Further, we will make use of recent advances in network theory to model the complex multilateral relationships in molecular data from multiple sources. The proposed methods will be applied to several publicly available datasets and cohorts to ensure that we can generalize our work to other datasets and cohorts and thus increase the long-term impact of our research. The proposed research will also contribute valuable statistical and machine learning algorithms that will be broadly applicable to data from multiple sources and multiple cohorts and will be made available to the public free of charge. Project Narrative This proposed research is expected to lay the foundation for advances in disease diagnosis, treatment, and personalized care through the integration and interpretation of cross-sectional and longitudinal data from multiple sources; it will contribute valuable tools and methods with potential for identiﬁcation of novel molecular targets for therapeutic interventions and for discovery of novel disease subtypes for improved patient prognosis.",Statistical and Machine Learning Methods to Address Biomedical Challenges for Integrating Multi-view Data,10274846,R35GM142695,"['Address', 'Affect', 'Biological Markers', 'Biological Process', 'Charge', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Set', 'Disease', 'Ensure', 'Environmental Risk Factor', 'Epidemiology', 'Foundations', 'Genes', 'Genetic', 'Genomics', 'Heterogeneity', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Pathogenesis', 'Pathway Analysis', 'Patients', 'Production', 'Prognosis', 'Research', 'Source', 'Systems Biology', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Work', 'base', 'cohort', 'disease diagnosis', 'disorder subtype', 'improved', 'insight', 'machine learning algorithm', 'machine learning method', 'metabolomics', 'molecular targeted therapies', 'multiple data sources', 'novel', 'patient subsets', 'personalized care', 'statistical and machine learning', 'theories', 'therapeutic target', 'tool']",NIGMS,UNIVERSITY OF MINNESOTA,R35,2021,351514
"Biology-aware machine learning methods for characterizing microbiome genotype and phenotype PROJECT SUMMARY 1 The Mirarab laboratory designs leading computational methods for answering biological and biomedical ques- 2 tions, focusing on scalability and accuracy. These methods span several areas (e.g., microbiome proﬁling, 3 multiple sequence alignment, and phylogenomics), and a common thread among them is evolutionary mod- 4 eling. The lab has developed scalable and accurate methods for reconstructing evolutionary histories (i.e.,  5 phylogenies) and using these histories in downstream biomedical applications. Reconstructing phylogenies is a  6 fundamental goal and a precursor to many biological analyses. Methods developed by this lab (e.g., ASTRAL) 7 are at the forefronts of modern genome-wide phylogenetics. Moreover, biomedical research increasingly uses 8 evolutionary histories in diverse areas like microbiome analyses, immunology, epidemiology, and comparative 9 genomics. While the lab has previously focused more on inferring species histories, it has recently started 10 to shift its focus to developing methods for microbiome analyses. The inference and the use of evolutionary 11 histories in analyzing environmental microbiome samples present a unique set of challenges. 12 In the next ﬁve years, the Mirarab lab will focus on designing, testing, and applying improved methods for 13 statistical analyses of microbiome data. These methods will target two questions. (i) Proﬁling: What organisms 14 constitute a given sample? (ii) Association: How are samples different in their organismal composition, and 15 how do these differences connect to measurable characteristics of their environment? While both questions 16 have been subject to considerable research, many computational challenges remain, providing an opportunity 17 for better methods to make a signiﬁcant impact. Instead of focusing solely on new algorithms, the lab will 18 also work on building better reference datasets and combining data from multiple sources. Thus, the project 19 aims to harness the unprecedented computational power, large available datasets, and recent advances in 20 machine learning to improve state-of-the-art dramatically. The project will not use off-the-shelf machine learning 21 methods in a black-box fashion. Instead, it develops methods that incorporate biological knowledge (e.g., of the 22 evolutionary relationships) into machine learning methods in a principled biologically-motivated fashion. 23 The lab will pursue several ambitious goals for both proﬁling and association questions. The project will 24 (i) create methods to infer a continuously-updated reference alignment and tree encompassing all sequenced 25 prokaryotic genomes (half a million currently) to be used for proﬁling, (ii) build methods for ultra-sensitive sam- 26 ple proﬁling, (iii) use deep learning to connect data obtained using amplicon sequencing and metagenomics, 27 (iv) build discordance-aware phylogenetic measures of sample differentiation, and (v) develop machine learning 28 methods for associating a proﬁled microbiome to phenotypes of interest such as disease. These new methods 29 will draw on statistics, machine learning, discrete optimization, and high-performance computing. Consistent 30 with the goals of MIRA, the project may explore new unforeseen opportunities if they ﬁt its general goals. PROJECT NARRATIVE Despite intensive efforts to develop methods for analyzing fast-growing environmentally-sequenced microbiome data, many challenges remain, and there is substantial room for improvements. We will build several methods for building better reference datasets, increasing the accuracy of proﬁling contents of microbiome samples, and ﬁnding associations between changes in the proﬁle and phenotypes of interest. Our publicly available methods will use advanced algorithms, statistics, and state-of-the-art machine learning techniques, but will adopt these techniques to incorporate a deep understanding of the evolutionary processes that shape the microbiome.",Biology-aware machine learning methods for characterizing microbiome genotype and phenotype,10275055,R35GM142725,"['Adopted', 'Algorithms', 'Area', 'Awareness', 'Biological', 'Biology', 'Biomedical Research', 'Characteristics', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Epidemiology', 'Genome', 'Genomics', 'Genotype', 'Goals', 'High Performance Computing', 'Immunology', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Measures', 'Metagenomics', 'Methods', 'Modernization', 'Organism', 'Phenotype', 'Phylogenetic Analysis', 'Phylogeny', 'Process', 'Recording of previous events', 'Research', 'Sampling', 'Sequence Alignment', 'Shapes', 'Statistical Data Interpretation', 'Techniques', 'Testing', 'Trees', 'Update', 'Work', 'comparative', 'deep learning', 'design', 'genome-wide', 'improved', 'interest', 'machine learning method', 'microbiome', 'microbiome analysis', 'multiple data sources', 'statistics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R35,2021,344669
"Robust, Generalizable, and Fair Machine Learning Models for Biomedicine Project Summary  Modern machine learning approaches have attained substantial success in pattern recognition and high-dimensional data analyses. However, these algorithms heavily rely on association discovery, which cannot elucidate the mechanisms underpinning the observed correlations and suffers from limited generalizability. To address this challenge, the Yu Lab focuses on the development of robust and generalizable machine learning approaches to integrate various types of biomedical data, including multi-omics, pathology, and phenotypic information. The goal of the next five years is to develop novel computational methods that connect machine learning algorithms with causal inference methodologies to better understand the molecular mechanisms underpinning disease pathology and enable fair and robust predictions of drug response and toxicity. The overall vision of the proposed research program is to establish generalizable data-driven methods to transform biomedical data into robust prediction and mechanistic models. The proposed approach will systematically connect diverse biomedical signals to extract previously unknown knowledge on the molecular mechanisms and derive reliable prediction models for the effects of medications. The proposed approaches are innovative because they depart from the status quo by incorporating advanced causal inference techniques with data-driven algorithms to enhance mechanistic and predictive modeling. This research program is significant because it is expected to improve our understanding of disease pathology and provide a fair and generalizable informatics framework for drug response and adverse effects prediction in diverse populations. The proposed research activities will open new research horizons by establishing a new machine learning platform for generating reliable predictions, which will vertically advance molecular biology, pharmacology, and computational research in biomedicine. Project Narrative  The research program outlined in this proposal is relevant to public health because it will establish novel machine learning algorithms for modeling the molecular mechanisms of pathologic changes, enable robust drug response prediction, and ensure the fairness and generalizability of the analytical methods for biomedical data. The proposed approaches are relevant to NIGMS’s mission of supporting the development of computational methods for understanding basic biological questions and advancing disease treatment.","Robust, Generalizable, and Fair Machine Learning Models for Biomedicine",10275864,R35GM142879,"['Address', 'Adverse effects', 'Algorithms', 'Biological', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Disease', 'Ensure', 'Goals', 'Informatics', 'Knowledge', 'Machine Learning', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Pathologic', 'Pathology', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Population Heterogeneity', 'Public Health', 'Research', 'Research Activity', 'Signal Transduction', 'Techniques', 'Toxic effect', 'Vision', 'advanced disease', 'analytical method', 'drug response prediction', 'improved', 'innovation', 'machine learning algorithm', 'molecular modeling', 'multidimensional data', 'multiple omics', 'novel', 'predictive modeling', 'programs', 'response', 'success']",NIGMS,HARVARD MEDICAL SCHOOL,R35,2021,422709
"Developing tools for the unbiased analysis and visualization of scRNA-seq data ABSTRACT Single-cell RNA sequencing (scRNA-seq) provides genome-wide information about gene expression at the resolution of individual cells. The unprecedented scope of these data is revolutionizing our understanding of development and tissue homeostasis as well as diseases like cancer. A major issue with scRNA-seq, however, is the shear scale of the data, consisting of ~20,000 gene expression measurements in thousands to millions of cells. Effective computational approaches are clearly required to translate data of this size and complexity into actionable biological insights. For instance, scRNA-seq data are approximately 20,000-dimensional, and as a result all available analysis pipelines rely on multiple dimensionality reduction steps. This usually entails a combination of linear tools like PCA and non-linear techniques like t-SNE and UMAP. The data is generally reduced to between 10- and 100-D for data analysis (e.g. clustering into distinct cell types) and 2-D for visualization. The problem, however, is that dimensionality reduction can lead to loss of information. We recently showed that this loss of information is dramatic: for any given cell, over 95% of its neighbors are changed in the process of dimensionality reduction. This complete change in the structure of the data can introduce significant noise and bias into the analysis, and suggests the critical need for alternative approaches. The premise of this application is that reducing bias in scRNA-seq data analysis will maximize our ability to extract meaningful information from the data. In this proposal, we focus on developing new algorithms to address three specific steps in the typical analysis pipeline: (1) Dimensionality Reduction: Our hypothesis is that deep neural networks can be explicitly trained to maximize the amount of information that can be retained for both data analysis and visualization. (2) Feature Selection: Not all genes are equally informative for downstream analyses, so researchers generally choose a subset of genes based on variation in the population. We have shown that standard approaches to selecting genes convolve true biological variation with technical noise from the experiment. We hypothesize that statistical models based on our understanding of sources of technical noise can be used to select more informative genes. (3) Cell clustering: Clustering the data to determine cell types is critical, but cells with different identities often form complex, overlapping geometries in gene expression space that are difficult for existing algorithms to resolve. Our hypothesis is that new clustering tools, guided by prior knowledge and leveraging innovations in clustering from image segmentation, can overcome this problem. We will build these new tools and test them against existing benchmark datasets and novel data generated by our experimental collaborators. We will also integrate these tools into popular scRNA-seq analysis packages. Successful completion of the proposed work will allow the field to extract more biologically relevant information from the burgeoning set of scRNA-seq datasets. PROJECT NARRATIVE Single-cell RNA sequencing (scRNA-seq) provides genome-wide information on gene expression at single-cell resolution, and is revolutionizing the progress of biomedical research. The size and complexity of this data necessitates the development of computational algorithms that can distill critical biological insights from high- dimensional datasets. Here, we propose to develop and test an innovative new class of algorithms that are aimed at reducing the potential for noise and bias in the analysis of scRNA-seq data.",Developing tools for the unbiased analysis and visualization of scRNA-seq data,10279320,R01GM143378,"['Address', 'Adipose tissue', 'Algorithms', 'B-Cell Development', 'B-Cell Lymphomas', 'Benchmarking', 'Binomial Model', 'Biological', 'Biological Preservation', 'Biomedical Research', 'Candidate Disease Gene', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computational algorithm', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Geometry', 'Goals', 'Homeostasis', 'Individual', 'Knowledge', 'Lead', 'Malignant Neoplasms', 'Measurement', 'Messenger RNA', 'Methods', 'Microscopy', 'Modeling', 'Neighborhoods', 'Noise', 'Pharmaceutical Preparations', 'Population', 'Process', 'Research Personnel', 'Resolution', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Tissue-Specific Gene Expression', 'Tissues', 'Training', 'Translating', 'Variant', 'Visualization', 'Work', 'analysis pipeline', 'base', 'cell type', 'computerized tools', 'data complexity', 'data visualization', 'deep neural network', 'experimental study', 'feature selection', 'genome-wide', 'high dimensionality', 'imaging Segmentation', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'single-cell RNA sequencing', 'tool', 'treatment response']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,296743
"Developing cell-penetrating miniproteins as a new class of therapeutics Project Summary Current protein therapeutics have a major limitation: they generally cannot cross the cellular membrane or interact with cytosolic targets. The ability to design protein therapeutics that enter the cell cytosol would enable new therapeutic strategies across many disease areas, including cancer, autoimmunity, and neurological disease. Therapeutic “miniproteins” (30-60 residues in length) have the potential to address this challenge, and several miniproteins capable of efficiently reaching the cell cytosol have recently been identified. However, we lack a general understanding of the “design rules” for cell-penetrating miniproteins, limiting the development of this class of molecules. Furthermore, current approaches to measure cytosolic delivery require measuring each protein individually, which is slow and labor intensive. This makes it impossible to test large numbers of miniproteins to develop a robust, quantitative understanding of the determinants of cytosolic delivery. In this exploratory project, we will develop a new approach to measure delivery for each different protein in a large mixed pool, using targeted mass spectrometry to individually identify each miniprotein sequence. In our approach, a soluble mixed pool containing thousands of designed miniprotein sequences is incubated with cells, and miniproteins that enter those cells are captured by a cytosolic target. Miniproteins captured by the target are then purified out of the cellular contents and identified and quantified using targeted proteomics. The amount of each protein in the captured sample (relative to the starting sample) will provide a quantitative measure of delivery efficiency. This approach is unprecedented, and we will test and optimize this approach using different positive and negative control miniproteins, different library sizes, and different cell lines. With this method in hand, we will use approaches we previously pioneered to computationally design thousands of candidate cell-penetrating miniproteins with intentionally diverse sequence and structural properties. We will then quantify cytosolic delivery for these new proteins using our new high-throughput approach, creating unprecedented large-scale data on delivery efficiency. We will then use these data to build machine learning models that predict miniprotein delivery based on sequence and structural properties. Finally, we will repeatedly iterate, designing new miniprotein libraries based on our predictive models of delivery, testing these designs using our high-throughput experimental approach, and further updating our models. This iterative design-test- learn approach will build a robust, predictive understanding of the determinants of delivery. Ultimately, the ability to design cell-penetrating miniproteins will unlock a wide range of new therapeutic targets inside the cell. Project Narrative Protein drugs have revolutionized numerous areas of medicine, but a major part of biology – the inside of human cells – is currently inaccessible by protein drugs. Here, we develop a powerful new experimental approach to discover the rules for delivering protein drugs into cells. Discovering these rules will enable the development of new protein drugs with entirely new mechanisms of action.",Developing cell-penetrating miniproteins as a new class of therapeutics,10289040,R21GM143560,"['Address', 'Affinity', 'Amino Acids', 'Area', 'Autoimmunity', 'Binding Proteins', 'Biological Assay', 'Biology', 'Cell Line', 'Cell membrane', 'Cells', 'Cellular Membrane', 'Charge', 'Clinical', 'Cytolysis', 'Cytosol', 'Data', 'Development', 'Disease', 'Dose', 'Drug Targeting', 'Endosomes', 'Engineering', 'Ensure', 'Escherichia coli', 'Future', 'Goals', 'Hand', 'Human', 'Hydrophobicity', 'Incubated', 'Individual', 'Learning', 'Length', 'Libraries', 'Link', 'Lysosomes', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Peptides', 'Pharmaceutical Preparations', 'Plasma Cells', 'Property', 'Protein Engineering', 'Proteins', 'Proteomics', 'Recombinants', 'Recovery', 'Risk', 'Sampling', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Technology', 'Testing', 'Therapeutic', 'Update', 'Ursidae Family', 'Validation', 'base', 'course development', 'design', 'drug development', 'improved', 'insight', 'iterative design', 'large scale data', 'multiplex assay', 'nanomolar', 'nervous system disorder', 'new therapeutic target', 'novel drug class', 'novel strategies', 'novel therapeutic intervention', 'novel therapeutics', 'peptide drug', 'pre-clinical', 'predictive modeling', 'protein protein interaction', 'small molecule', 'success', 'supervised learning', 'therapeutic protein']",NIGMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2021,231323
"Predictive Personalized Public Health (P3H): A Novel Paradigm to Treat Infectious Disease Challenge, Innovation and Impact: In recent years, we have demonstrated that it is feasible to predict epidemic disease outbreaks from retrospective seasonal and geographical case data and to show that we can take climate factors into account in our predictive models. We are moving closer to real-time prediction at the population level. But we have never used prediction at point-of-care for treating the individual patient.  Presently, personalized medicine uses delayed results of laboratory testing of individuals. For infectious disease, most of such testing has targeted the pathogen in the host-pathogen interaction. The role of laboratory testing is to modify therapy after a variable period of time delay. Personalized medicine today is reactive. Complicating matters further, many infectious epidemic diseases are strongly dependent on environmental factors and climate. Lastly, we want to name the pathogens we are fighting, but we really need to know the resistance characteristics to select therapy for patients effectively. Both speciation and resistance can now be determined from molecular data, which can be integrated into point-of-care treatment predictions.  We here propose a radically different approach to the treatment of infectious diseases. Our hypothesis is that the alternative to time-delayed and expensive laboratory analysis of specimens from individual patients, is to use predictive modeling to forecast point-of-care treatment. Time-delayed personalized testing can be conducted as surveillance, and that data used for real-time prediction to guide point-of-care treatment.  We will introduce predictive personalized public health (P3H) policy at the individual patient level, with the potential to substantially improve patient outcomes compared with our present reactive approaches. Our key rationale is to expand population infectious disease predictive modeling in order to achieve prediction for treatment at point-of-care. Our primary insight is that we can reposition the delayed reactive personalized testing from the urgent medical decision-making process, and into a predictive modeling framework. The gaps and opportunities in technology that we will address are four-fold. First, we will employ individual case geospatial mapping at a fine scale to take into account infection spread and environmental factors. Second, our ability to perform pan-microbial analysis using molecular techniques is now feasible. Third, modeling our novel fusion of data has no simple low-dimensional solution – but machine learning technologies are now capable of handling such big data assimilation, model discovery and prediction. Fourth, our proposal is not an academic exercise. We have a partnership with the economic planners within a developing country to design and implement our new methods. We will prospectively tune and validate our algorithms in real-time. Our deliverable will be an open-source framework ready for clinical trials testing and adaptation to the public health infrastructure in any country. Project Narrative We have made substantial progress in our abilities to track and predict infectious disease epidemics at the population level, but prediction has never been used at the individual level to guide treatment at point-of-care. The individual treatment for all infectious disease syndromes at point-of-care is presently empirical, because laboratory testing is reactive and time delayed. We here propose a novel framework to use rigorous prediction strategies to guide point-of-care treatment for infectious diseases, and to validate this approach under real-world conditions.",Predictive Personalized Public Health (P3H): A Novel Paradigm to Treat Infectious Disease,10241253,R01AI145057,"['Acute', 'Address', 'Algorithms', 'Assimilations', 'Bacterial Meningitis', 'Bacteriology', 'Big Data', 'Cessation of life', 'Characteristics', 'Cholera', 'Climate', 'Clinical Trials', 'Communicable Diseases', 'Complex', 'Country', 'Data', 'Decision Making', 'Developed Countries', 'Developing Countries', 'Diagnostic', 'Diarrhea', 'Dimensions', 'Disease', 'Disease Outbreaks', 'Economics', 'Engineering', 'Environmental Risk Factor', 'Epidemic', 'Equilibrium', 'Exanthema', 'Exercise', 'Fever', 'Frequencies', 'Genus staphylococcus', 'Geography', 'HIV', 'Hand', 'Health Policy', 'Hospitals', 'Hybrids', 'Individual', 'Infant', 'Infection', 'Infrastructure', 'Investments', 'Laboratories', 'Leadership', 'Leptospirosis', 'Machine Learning', 'Malaria', 'Measles', 'Medical', 'Medical emergency', 'Melioidosis', 'Meningitis', 'Methods', 'Microbiology', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Names', 'Newborn Infant', 'Paralysed', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Preventive', 'Process', 'Public Health', 'Rain', 'Reaction', 'Resistance', 'Resources', 'Role', 'Sepsis', 'Specimen', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Uganda', 'Work', 'acute infection', 'antigen test', 'antimicrobial', 'authority', 'climate data', 'cost', 'cost outcomes', 'data fusion', 'design', 'effective therapy', 'fighting', 'flu', 'global health', 'improved', 'individual patient', 'infant infection', 'infectious disease model', 'infectious disease treatment', 'innovation', 'insight', 'microbial', 'mortality', 'novel', 'open source', 'pathogen', 'personalized medicine', 'personalized predictions', 'point of care', 'predictive modeling', 'prospective', 'resistance gene', 'spreading factor', 'surveillance data']",NIAID,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R01,2021,1650504
"A Spatially Resolved Molecular Atlas of Human Endothelium Project Abstract Recent advances in imaging and genomics are revolutionizing our understanding of human tissues. As these two technologies become more intertwined and high-throughput, there is an increasing need for scalable methods to interpret these data with single-cell resolution. In this Supplement, we seek to build on ongoing work to develop scalable and accurate algorithms for single-cell analysis of spatial genomics data. We propose to develop annotation software for annotating individual cells, their cell types, and functional tissue units in multiplexed imaging data. This software will be essential to produce training data to power the next generation of deep learning models for analyzing multiplexed imaging data. Project Narrative With this HubMAP supplement, we will create software for performing both semantic and instance annotation of multiplexed imaging data. With this annotation software, we help HubMAP investigators annotate individual cells and their cell types, as well as functional tissue units.",A Spatially Resolved Molecular Atlas of Human Endothelium,10411809,U54HL145611,"['Address', 'Algorithms', 'Area', 'Atlases', 'Biological', 'Biological Assay', 'Categories', 'Cells', 'Characteristics', 'Collaborations', 'Collection', 'Color', 'Communities', 'Computer Analysis', 'Computer software', 'Cytometry', 'Data', 'Data Set', 'Detection', 'Development', 'Dimensions', 'Disease', 'Endothelium', 'Genomics', 'Health', 'Human', 'Human BioMolecular Atlas Program', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Investigation', 'Label', 'Libraries', 'Machine Learning', 'Mechanics', 'Methods', 'Modeling', 'Molecular', 'Nuclear', 'Positioning Attribute', 'Proteome', 'Proteomics', 'Research Personnel', 'Resolution', 'Semantics', 'Software Tools', 'Spottings', 'Technology', 'Tissue imaging', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cell type', 'crowdsourcing', 'data modeling', 'deep learning', 'design', 'falls', 'genomic data', 'high dimensionality', 'human imaging', 'human tissue', 'human-in-the-loop', 'learning strategy', 'member', 'multiplexed imaging', 'next generation', 'open source', 'operation', 'preservation', 'single cell analysis', 'single molecule', 'terabyte', 'transcriptome', 'transcriptomics', 'two-dimensional']",NHLBI,CALIFORNIA INSTITUTE OF TECHNOLOGY,U54,2021,99999
"Tracking single-cell gene expression heterogeneity and its consequences in bacterial biofilms Project Summary Bacterial biofilms are surface-attached communities of bacterial cells enclosed in an extracellular matrix. Biofilms are a concern in health and in industrial operations because of persistent infections, clogging of flows, and surface fouling. Recent advances in single-cell live imaging have revealed well-defined cell ordering in individual biofilm clusters and the underlying biomechanical principles that shape them. However, we have little understanding of which genes are activated in each biofilm-dwelling cell and how cell organization is determined by the gene expression pattern at the single-cell level. We do not know whether and how gene expression profiles vary from cell to cell in biofilms, and what consequences such heterogeneity has on biofilm development. Cell-to-cell variation in biofilms could underly the notorious difficulty in eradicating biofilms in chronic infections because of the differential response of biofilm cells to antibiotic treatment. In this proposal we put forward ideas to address this challenge by developing new imaging platforms to capture the biofilm growth dynamics and associated gene expression pattern at the single-cell level. Using these imaging platforms, we will uncover the intricate interplay between single-cell gene expression, individual cell behavior, and local cell organization that underlies the developmental program of bacterial biofilms. Specifically, we will use deep learning algorithms to push the temporal and spatial resolution limits in single-cell biofilm imaging, and develop an innovative, coupled segmentation-tracking method to generate a robust three-dimensional lineage tracing algorithm in growing biofilms. By combining lineage tracing and fluorescent reporters, we will follow the spatiotemporal expression pattern of each individual cell throughout biofilm development. By focusing on matrix production, degradation, and cell dispersion, we will create concrete examples of gene expression heterogeneity at the single-cell level and the associated consequences in 3D biofilms. In addition, we will investigate heterogeneity in genes involved in intra- and intercellular signaling, in motility and attachment, and in cell shape regulation to broaden our finding. With these efforts, we will reveal how individual gene expression, cell behavior, and local cell ordering reciprocally interact with each other to define biofilm architecture and development. The knowledge obtained in the current proposal offers new strategies for manipulating complex bacterial communities and has the potential to change the clinical procedure of treating biofilm-related diseases, for example by developing new chemicals that specifically induce dispersal or target the recalcitrant cell populations. Project Narrative: Bacterial biofilms are the predominant lifestyle of bacteria in nature and they can also cause chronic infections that are difficulty to treat. This study aims to track the gene expression profile in each biofilm cell and to dissect the intricate interplay between single-cell gene expression, individual cell behavior, and local cell organization that underlies the developmental program of bacterial biofilms. Such an understanding is crucial for combatting biofilm-related problems and harnessing beneficial biofilms.",Tracking single-cell gene expression heterogeneity and its consequences in bacterial biofilms,10242439,DP2GM146253,"['3-Dimensional', 'Address', 'Algorithms', 'Antibiotic Therapy', 'Architecture', 'Bacteria', 'Biomechanics', 'Cells', 'Chemicals', 'Clinical', 'Complex', 'Coupled', 'Development', 'Disease', 'Extracellular Matrix', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Growth', 'Health', 'Heterogeneity', 'Image', 'Individual', 'Industrialization', 'Knowledge', 'Life Style', 'Methods', 'Microbial Biofilms', 'Nature', 'Pattern', 'Population', 'Procedures', 'Production', 'Regulation of Cell Shape', 'Reporter', 'Resolution', 'Shapes', 'Signal Transduction', 'Surface', 'Variant', 'bacterial community', 'cell behavior', 'cell motility', 'chronic infection', 'deep learning algorithm', 'imaging platform', 'innovation', 'live cell imaging', 'operation', 'programs', 'response', 'spatiotemporal']",NIGMS,YALE UNIVERSITY,DP2,2021,1507500
"Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences PROJECT SUMMARY/ABSTRACT In the era of newly emerging computational tools for data science, biostatisticians need to play a fundamental role in health sciences research. There is an urgent need to encourage US Citizens and Permanent Residents to pursue graduate training in biostatistics. The design, conduct, and analysis of clinical trials and observational studies; the setting of regulatory policy; and the conception of laboratory experiments have been shaped by the fundamental contributions of biostatisticians for decades. Advances in genomics, medical imaging technologies, and computational biology; the increasing emphasis on precision and evidence-based medicine; and the widespread adoption of electronic health records; demand the skills of biostatisticians trained to collaborate effectively in a multidisciplinary environment and to develop statistical and machine learning methods to address the challenges presented by this data-rich revolutionary era of health sciences research. The proposed summer program which includes world-renowned clinical scientists and biostatisticians from two local universities, will provide an immense opportunity for student participants to learn basic yet modern statistical methods that are critical to uncovering new insights from such big and complex biomedical data and also illustrate the potential pitfalls of confounding and bias that may arise when analyzing biomedical data. A unique feature of the proposed training program is thus to expose the participants to not only basic statistical methods but also to the topics of computer science and bioinformatics which will be invaluable in creating the multidisciplinary teams required to tackle the complex research questions that often requires multipronged approaches. The proposed six-week training program will be structured around the NIH's Translation Science Spectrum and will introduce participants to opportunities in biostatistics through the lens of the science advanced by the contributions of biostatisticians. Following an initial set of weeks on basic training of biostatistical methods, the program will culminate in a data hack-a-thon style competition in which participants will employ the statistical and scientific knowledge gained during the program to produce the most innovative, statistically-sound, scientifically-relevant and effectively-communicated response to a set of research questions. The proposed research education program will enroll up to 20 such participants from across the nation and, through lectures, field trips, and opportunities to analyze data from real health sciences, inspire them to pursue graduate training. The program will draw upon considerable past collaborations and complementary resources of two local world-renowned universities to provide participants with an unparalleled view of the field, including award-winning instructors, internationally known methodological and clinical researchers, and a local area rich in opportunities to showcase careers in biostatistics. Special efforts will be made to enroll participants from underrepresented groups. Participants will be followed after completion, and the numbers attending graduate school in statistics and pursuing biostatistics careers will be documented. PROJECT NARRATIVE Biostatisticians are indispensible contributors to health sciences research. The demand for professionals with advanced training in biostatistics is high and will continue to increase, especially with the expanding challenges posed by big biomedical data. This six week summer research education program, a joint effort of North Carolina State University and Duke University, will enroll up to 20 US citizen/permanent resident participants from across the nation in the summers of 2020-2022 and expose them to the opportunities presented by careers in biostatistics and encourage them to seek graduate training in the field.",Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences,10219349,R25HL147228,"['Address', 'Adoption', 'Area', 'Attention', 'Award', 'Bioinformatics', 'Biomedical Research', 'Biometry', 'Biostatistical Methods', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Conceptions', 'Data', 'Data Science', 'Development', 'Discipline', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Evaluation', 'Evidence Based Medicine', 'Exposure to', 'Faculty', 'Future', 'Genomics', 'Goals', 'Health Sciences', 'Health system', 'Imaging technology', 'Institution', 'International', 'Joints', 'Knowledge', 'Learning', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Observational Study', 'Participant', 'Play', 'Policies', 'Positioning Attribute', 'Principal Investigator', 'Program Effectiveness', 'Request for Applications', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Schools', 'Science', 'Scientist', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Students', 'Talents', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Underrepresented Populations', 'United States National Institutes of Health', 'Universities', 'analytical method', 'big biomedical data', 'career', 'career development', 'clinical trial analysis', 'cohort', 'computer science', 'computerized tools', 'data resource', 'design', 'education research', 'experience', 'field trip', 'graduate student', 'health science research', 'innovation', 'insight', 'instructor', 'interest', 'investigator training', 'laboratory experiment', 'lectures', 'lens', 'machine learning method', 'multidisciplinary', 'next generation', 'programs', 'public health research', 'recruit', 'response', 'skills', 'sound', 'statistical and machine learning', 'statistics', 'summer institute', 'summer program', 'summer research', 'tool', 'undergraduate student']",NHLBI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R25,2021,249789
"Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use Project Summary. This project is designed to identify validated biomarkers for use in the assessment of electronic nicotine delivery systems (ENDS) by the FDA. Since the introduction of ENDS, commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. With the goal of validated biomarker discovery in two independent cohorts, the COPDGene and UCSD ENDS studies, we propose to identify ENDS-related inflammatory biomarkers in ENDS only and dual users and relate these biomarkers to five-year lung health outcomes. COPDGene is an ongoing, longitudinal study of >6,000 current and former traditional cigarette (t-cig) smokers enriched for chronic obstructive pulmonary disease (COPD) with detailed longitudinal lung phenotyping data (including chest CT), genome-wide blood RNA-seq, and proteomic data. The UCSD ENDS Study is a controlled study of young ENDS only users and controls with detailed assessment of inflammatory biomarkers in the oropharynx, airways and blood.  Biomarkers used as validated surrogate measures must be 1) associated with ENDS use, 2) predictive of health outcomes, and 3) have a strong biological rationale. We hypothesize that inflammatory biomarkers of ENDS use will be predictive of five-year lung health effects. In Aim 1 of this proposal, discovery of inflammatory transcriptomic and proteomic biomarkers of ENDS exposure will be performed in subjects from the COPDGene five-year study visit, and biomarkers will be validated in two independent sets of subjects from the COPDGene ten-year visit and the UCSD ENDS Study. In Aim 2 we will identify antibody-specific adaptive immune response biomarkers of ENDS exposure using adaptive immune receptor repertoire sequencing (AIRR-seq). Auto-antibodies are biomarkers that are associated with the degree of lung damage in COPD. AIRR-seq is a powerful tool for inflammatory biomarker discovery that characterizes an individual’s decades-long history of antibody responses. In Aim 3 we will use machine learning predictive models to relate ENDS-associated biomarker panels to five-year lung health outcomes from COPDGene. The investigative team for this grant is well-positioned to identify novel inflammatory biomarkers of ENDS use. The COPDGene and UCSD cohorts have the detailed lung phenotyping and molecular characterization necessary to discover and clinically validate biomarkers in two important populations of ENDS users, i.e. ENDS only and dual users. Public Health Relevance: Since the introduction of electronic nicotine delivery systems (ENDS), commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. Using two studies of ENDS users and controls, this project is designed to identify validated biomarkers for use in the health assessment of ENDS products.",Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use,10226191,R01HL147326,"['Acute', 'Adaptive Immune System', 'Address', 'Antibodies', 'Antibody Response', 'Autoantibodies', 'B-Lymphocytes', 'Biological', 'Biological Markers', 'Blood', 'Cells', 'Chronic Obstructive Airway Disease', 'Cigarette Smoker', 'Clinical', 'Control Groups', 'Controlled Study', 'Data', 'Disease', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Elements', 'Evaluation', 'Genomics', 'Goals', 'Grant', 'Health', 'Human', 'Immunologic Receptors', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Response', 'Link', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Measures', 'Methods', 'Molecular', 'Mouse Strains', 'Oropharyngeal', 'Outcome', 'Pattern', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Proteomics', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Questionnaires', 'Recording of previous events', 'Respiratory Signs and Symptoms', 'Smoker', 'Spirometry', 'Surrogate Endpoint', 'T cell response', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Testing', 'United States Food and Drug Administration', 'Visit', 'X-Ray Computed Tomography', 'adaptive immune response', 'authority', 'biomarker discovery', 'biomarker panel', 'candidate marker', 'chest computed tomography', 'cohort', 'combustible cigarette', 'design', 'electronic cigarette use', 'genome-wide', 'health assessment', 'lung injury', 'novel', 'novel strategies', 'patient population', 'phenotypic data', 'predictive modeling', 'prospective', 'public health relevance', 'random forest', 'response biomarker', 'study population', 'targeted sequencing', 'tool', 'transcriptome sequencing', 'transcriptomics', 'young adult']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,512662
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10155396,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2021,391250
"Mechanobiology of aortic smooth muscle cells in human iPSC-based models of Marfan Syndrome PROJECT SUMMARY Marfan Syndrome (MFS), one of the most common heritable connective tissue disorders, affects 1 in 5,000 individuals and has destructive manifestations in multiple organ systems; notably the cardiovascular system. MFS is an autosomal dominant disease caused by a genetic mutation in the Fibrillin-1 gene leading to aberrant TGFβ signaling, and frequently results in aortic aneurysm, dissection, and death. Interestingly, the associated degeneration within the aortic vessel wall almost always occurs in the aortic root or ascending aorta and not in the descending or abdominal aorta; while this putatively reflects regional differences in hemodynamic stress, antihypertensive treatment alone is not effective in managing aortic aneurysm in MFS. Alternatively, it is also the case that aortic smooth muscle cells (ASMCs), which predominate the vasoactive medial layer of the vessel wall, have heterogeneous subtypes stemming from distinct developmental germ-layers based on their anatomical location; Neuroectoderm (NE) origin gives rise to ascending ASMCs and Paraxial mesoderm (PM) origin gives rise to descending ASMCs. This project will use origin-specific ASMCs differentiated from induced pluripotent stem cells (iPSCs) from patients with MFS and healthy controls to test a novel hypothesis that developmental origin causes location-specific abnormalities in ASMCs associated with medial degeneration in MFS. Additionally, it will explore for biomarkers of presymptomatic congenital defects in Marfan Syndrome to identify novel targets for prophylactic therapeutic intervention. These studies will characterize phenotypic differences in human ASMC subtypes at the cellular and tissue level with stem-cell culturing and vascular tissue engineering techniques. Using state-of-the-art core facilities we will also conduct transcriptomic and proteomic analysis on these cellular and tissue models to cultivate a rich biological profile for bioinformatic analysis. Furthermore, we will develop a bioinformatics pipeline to elucidate novel prophylactic targets inherently responsible for ascending aortic MFS-induced medial degeneration, using our uniquely combined phenotypic, transcriptomic, and proteomic results as input. Lastly, based on our bioinformatic outputs we will test our intervention on our human iPSC-based in vitro models and compare to treatment with Losartan, a commonly used anti-hypertensive drug that also exhibits unique anti-remodeling properties and has shown promise for managing the symptoms of MFS in animals and in patients. The training plan for this fellowship will focus on technical skills, experimental design and critical analysis, critique of published scientific data, and presentation skills. It will be achieved by regular mentor meetings, journal clubs, conference presentations, bi- annual committee meetings, and advanced coursework. The majority of training will occur in the Costa Lab at the Cardiovascular Research Center at ISMMS, a highly active and collaborative environment with available mentors and students aligned with my research topics and career goals. Additional training will occur in the Ramirez Lab with senior researchers in Marfan Syndrome and biochemical investigation techniques. PROJECT NARRATIVE This research proposes a bioengineering approach for investigating new human induced pluripotent stem cell (hiPSC)-based cellular and 3D tissue models of Marfan Syndrome (MFS), a rare connective tissue disorder that frequently causes aortic aneurysm and dissection specifically in the ascending aorta. Our findings will elucidate mechanobiological differences in aortic smooth muscle cells of distinct embryologic origin, and their underlying mechanisms of response to mechanical stimuli. This will help improve our understanding of aneurysm localization in MFS, and guide more effective therapies for MFS patients in the future.",Mechanobiology of aortic smooth muscle cells in human iPSC-based models of Marfan Syndrome,10215619,F31HL149271,"['3-Dimensional', 'Abdomen', 'Actins', 'Affect', 'Anatomy', 'Aneurysm', 'Animal Model', 'Animals', 'Antihypertensive Agents', 'Aorta', 'Aortic Aneurysm', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Engineering', 'Calcium Signaling', 'Cardiovascular system', 'Cell Culture Techniques', 'Cell Differentiation process', 'Cell model', 'Cells', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Congenital Abnormality', 'Connective Tissue Diseases', 'Core Facility', 'Critiques', 'Cytoskeleton', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Descending aorta', 'Development', 'Disease', 'Dissection', 'Engineering', 'Exhibits', 'Experimental Designs', 'Extracellular Matrix', 'FBN1', 'Fellowship', 'Fluorescence', 'Future', 'Gene Expression Profile', 'Gene set enrichment analysis', 'Genes', 'Germ', 'Germ Layers', 'Goals', 'High Prevalence', 'Human', 'In Vitro', 'Incidence', 'Individual', 'Intervention', 'Investigation', 'Journals', 'Lead', 'Length', 'Location', 'Losartan', 'Marfan Syndrome', 'Measures', 'Mechanics', 'Medial', 'Mentors', 'Modeling', 'Neural Crest', 'Neuroectoderm', 'Outcome', 'Output', 'Paraxial Mesoderm', 'Patients', 'Phenotype', 'Physiological', 'Plant Roots', 'Population', 'Predisposition', 'Property', 'Proteomics', 'Publishing', 'Research', 'Research Personnel', 'Role', 'Rupture', 'Scanning Probe Microscopes', 'Serum', 'Signal Transduction', 'Smooth Muscle Myocytes', 'Stimulus', 'Stress', 'Students', 'Sudden Death', 'Technical Expertise', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Tissue Engineering', 'Tissue Model', 'Tissue-Specific Gene Expression', 'Tissues', 'Training', 'Transforming Growth Factor beta', 'Vascular remodeling', 'abdominal aorta', 'ascending aorta', 'base', 'bioinformatics pipeline', 'biomarker discovery', 'body system', 'career', 'cell dimension', 'collaborative environment', 'confocal imaging', 'drug candidate', 'effective therapy', 'healthy volunteer', 'hemodynamics', 'heritable connective tissue disorder', 'human model', 'hydrogel scaffold', 'improved', 'in vitro Model', 'induced pluripotent stem cell', 'insight', 'lead candidate', 'machine learning algorithm', 'mechanotransduction', 'meetings', 'multidimensional data', 'nanoindentation', 'next generation', 'novel', 'prophylactic', 'protein biomarkers', 'protein expression', 'regional difference', 'response', 'skills', 'stem', 'stem cell model', 'stem cells', 'symposium', 'symptom management', 'targeted treatment', 'transcriptome sequencing', 'transcriptomics', 'two-dimensional', 'vascular tissue engineering']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,F31,2021,44436
"Combining Systems Pharmacology Modeling With Machine Learning To Identify Sub-Populations At Risk Of Drug-Induced Torsades de Pointes Project Summary  Torsades de Pointes, a lethal ventricular arrhythmia, is a side effect of several commonly used antiarrhythmics, antibiotics, antipsychotics, antihistamines and other ‘non-cardiovascular’ therapies. Though this adverse event is rare, it can lead to ventricular fibrillation and sudden cardiac death. The ignorance about the underlying differences between those at high risk versus low risk of forming this drug-induced arrhythmia halts any considerable progress in preventing it. Rather than simply removing these drugs from the market, a closer examination of the physiological and clinical traits of patients who benefited from the treatment and those who formed the arrhythmia needs to be performed. This highlights the idea of precision medicine and the importance of identifying relevant sub-groups of patients likely to benefit from a treatment versus those who are highly susceptible to a drug-induced adverse event. The current standards for predicting risk, a lengthened action potential (AP) duration of cells and a prolonged QT interval on an echocardiogram (ECG) have proven ineffective. Thus, there is a need to extract pertinent information from the cellular and tissue levels before administration of the therapeutic to detect patterns only apparent in the high-risk population. To analyze this concept, I plan to (1) explain at a mechanistic level the differences between the healthy and at-risk patients, (2) identify important AP and ECG signatures that can predict risk early on, and (3) connect the physiological and clinical findings to improve the profile and description of the high-risk population. I will combine two complementary computational techniques: (1) simulations with mechanistic quantitative systems pharmacology models of heart cells and tissues; and (2) advanced machine learning approaches that can identify hidden patterns. Thus, this project aims to develop an algorithm which will improve risk prediction and upgrade the current imperfect and unreliable standards for prescribing proarrhythmic therapies. Project Narrative Current standards for identifying patients at risk of forming the rare but lethal ventricular tachycardia, Drug- induced Torsades de Pointes include measuring the QT interval on the electrocardiogram (ECG). Although this decently predicts susceptibility, there remains a percentage of patients who still succumb to an arrhythmia with a normal QT. To improve patient risk stratification, this research project aims to develop an algorithm that can unmask subtle precursors at both the physiological and clinical levels, classify high risk patients, and upgrade the current imperfect standards for prescribing these therapies.",Combining Systems Pharmacology Modeling With Machine Learning To Identify Sub-Populations At Risk Of Drug-Induced Torsades de Pointes,10082298,F31HL149358,"['Action Potentials', 'Adverse event', 'Algorithms', 'Antibiotics', 'Antihistamines', 'Antipsychotic Agents', 'Arrhythmia', 'Biological Factors', 'Cardiac', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Consumption', 'Disease', 'Echocardiography', 'Electrocardiogram', 'Exposure to', 'Goals', 'Hand', 'Incidence', 'Individual', 'Ion Channel', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Modeling', 'Molecular', 'Muscle Cells', 'Patient risk', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Physiology', 'Population', 'Populations at Risk', 'Predisposition', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Statistical Data Interpretation', 'System', 'Therapeutic', 'Time', 'Tissues', 'Torsades de Pointes', 'Translating', 'Ventricular', 'Ventricular Arrhythmia', 'Ventricular Fibrillation', 'Ventricular Tachycardia', 'base', 'complex data', 'delayed rectifier potassium channel', 'drug market', 'efficacious treatment', 'experimental study', 'heart cell', 'high risk', 'high risk population', 'improved', 'insight', 'patient subsets', 'precision medicine', 'prevent', 'responders and non-responders', 'risk prediction', 'risk stratification', 'side effect', 'simulation', 'sudden cardiac death', 'supervised learning', 'trait']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,F31,2021,44436
"Systematic discovery, characterization, and design of novel genome editing and delivery tools using a high-throughput metagenomic screening pipeline Project Summary Despite extraordinary advances in genome engineering, tools for precise and efficient gene correction and delivery across all cell types remain lacking. Current programmable DNA cleavage tools, such as meganucleases, Zinc finger nucleases, transcription activator like effector nucleases (TALENs), and CRISPR- Cas9, rely on recruiting the DNA repair machinery, either using error-prone, non-homologous end joining (NHEJ) repair for gene knockout, or homology directed repair (HDR) for precise correction. However, HDR is inactive in post-mitotic cells, such as neurons, and is often inefficient, achieving 50% correction at most. Genome editing still lacks efficient, robust tools that can insert, delete, and recombine large stretches of DNA sequence. Moreover, delivery tools are a significant barrier to deploying tissue-specific genomic engineering technologies as current vehicles, including widely-used viral vectors and liposomal approaches, have limited capacity, offer variable efficiency, and lack precise tissue tropism. The proposed work involves computationally mining bacteria for new classes of gene editing enzymes and delivery vectors. We know that natural recombinases and transposases can mediate programmed DNA rearrangement and insertion, and these classes of enzymes are present in phage defense and mobile islands in bacteria, which largely remain uncharacterized. Additionally, recent work has demonstrated that retroviral/retrotransposon gag-like proteins can self-assemble and encapsulate nucleic acid in extracellular vesicles (EVs) and viral-like particles (VLPs) for cell-to-cell communication. As with defense islands, these proteins can also be systematically catalogued via a bioinformatic pipeline and experimentally characterized. The proposed work will focus on three main goals: 1) signatures for phage defense, mobile genetic activity, or VLP-forming activity will be mined to build a machine learning pipeline for comprehensively discovering novel gene clusters from novel metagenomic sequences with a focus for proteins that can manipulate nucleic acid or self-assemble, 2) candidate gene clusters will be cloned from metagenomic samples and undergo high-throughput screening using biochemical and bacterial assays for gene editing and capsid formation, as well as engineering to hone activity, and 3) the most promising candidates will be evaluated for activity in mammalian systems with assays for highly efficient gene insertion and VLP formation. The work will elucidate novel bacterial phage defense and VLP biology, and result in the development of new technologies for more efficient genetic manipulation and gene delivery. Moreover, this gene exploration and engineering framework will serve as a model for discovering diverse bacterial gene clusters and defense systems, evaluating biochemical activity across a range of assays, and converting these findings into high impact biotechnologies. The developed technologies will accelerate the pace of biomedical research and enable greater exploration of basic biological processes and disease mechanisms. Project Narrative There are more than 5,000 human diseases caused by known genetic variation, including mutations, insertions, and deletions, but programmable tools and delivery vectors to reliably study and model these diseases are lacking. We propose a two-pronged approach to discovering novel gene editing and delivery strategies by (1) mining bacterial and archaeal systems to identify novel defense systems and enzymes that have activities useful for genome editing and (2) identifying gene clusters linked to extracellular vesicle or viral-like particle formation that will allow development of better gene delivery systems. The technologies developed from this work will accelerate the study and modeling of disease biology and provide a framework for general prokaryotic gene discovery across many biotechnological areas.","Systematic discovery, characterization, and design of novel genome editing and delivery tools using a high-throughput metagenomic screening pipeline",10128377,R21AI149694,"['Animal Model', 'Area', 'Bacteria', 'Bacterial Genes', 'Bacterial Model', 'Bacteriophages', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Biotechnology', 'CRISPR/Cas technology', 'Candidate Disease Gene', 'Capsid', 'Cell Communication', 'Cell physiology', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Codon Nucleotides', 'Communities', 'DNA', 'DNA Repair', 'DNA Sequence', 'DNA Sequence Alteration', 'Data', 'Development', 'Directed Molecular Evolution', 'Disease', 'Disease model', 'Elements', 'Encapsulated', 'Engineering', 'Enzymes', 'Escherichia coli', 'Feedback', 'Future', 'Gene Cluster', 'Gene Delivery', 'Gene Rearrangement', 'Gene Transfer', 'Generations', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic Transcription', 'Genetic Variation', 'Genome engineering', 'Genomics', 'Goals', 'Heart', 'Horizontal Gene Transfer', 'Human', 'In Vitro', 'Island', 'Libraries', 'Link', 'Liposomes', 'Machine Learning', 'Mammalian Cell', 'Mediating', 'Metagenomics', 'Methods', 'Microfluidics', 'Mining', 'Mitotic', 'Mobile Genetic Elements', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutagenesis', 'Mutation', 'Neurons', 'Nonhomologous DNA End Joining', 'Nucleic Acids', 'Pathway interactions', 'Phylogeny', 'Process', 'Property', 'Protein Engineering', 'Proteins', 'Reporter', 'Research', 'Retrotransposon', 'Role', 'Sampling', 'Specificity', 'Stretching', 'Study models', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Translations', 'Transposase', 'Viral', 'Viral Vector', 'Work', 'base', 'bioinformatics pipeline', 'cell regeneration', 'cell type', 'design', 'environmental adaptation', 'enzyme activity', 'extracellular vesicles', 'fitness', 'gene correction', 'gene delivery system', 'gene discovery', 'gene repair', 'genetic manipulation', 'genetic variant', 'genome editing', 'genome-wide', 'high throughput screening', 'human disease', 'improved', 'in vivo', 'insertion/deletion mutation', 'knockout gene', 'new technology', 'novel', 'overexpression', 'particle', 'programs', 'protein profiling', 'recombinase', 'recruit', 'repaired', 'restraint', 'screening', 'technology development', 'tissue tropism', 'tool', 'transcription activator-like effector nucleases', 'transcription factor', 'vector', 'vector genome', 'zinc finger nuclease']",NIAID,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2021,225900
"A peptide-based point-of-care vertical flow assay for the rapid diagnosis of Lyme disease Abstract Project Summary There is an obvious need for new approaches and better assays for the laboratory diagnosis of Lyme disease. All attempts to develop a practical assay for the direct detection of Borrelia burgdorferi in infected patients have failed. Thus far, all proposed alternatives to serology have been unsuccessful, not cost-effective, or are still in early development. Improving serological detection in early disease is the fastest and most effective way to improve patient outcomes in Lyme disease. The antigen targets utilized in current serodiagnostic assays have considerable defects. They often contain conserved epitopes that cross-react with antibodies raised to other antigens, reducing specificity and requiring the use of a two-tier seroassay paradigm that preserves specificity at the cost of poor sensitivity in the detection of early disease. The use of peptides as serodiagnostic targets demonstrate improved efficacy, but the use of one or two peptides containing single epitopes still provides re- duced sensitivity in early disease. Putting the same old antigen targets into new platforms, no matter how in- novative the platform, will not succeed in improving serodiagnostics for Lyme disease. Both the target anti- gens and assays need an innovative approach. By incorporating unique peptides containing linear epitopes highly specific to B. burgdorferi, into a cutting-edge, multiplex, portable paper-based point-of-care diagnostic assay that uses a cost-effective smartphone-based reader, we aim to transform the diagnosis of Lyme disease. An ideal test for Lyme disease could be performed in a single step and yield an answer on the spot to support diagnosis and direct the course of clinical treatment. We have developed an innovative vertical-flow assay which allows for the multiplexed detection of IgM and IgG binding of up to 25 independent antigen targets in a point-of-care setting. The VFA design allows for uniform flow of sample across the target membrane, creating uniform binding conditions and maximizing developed signal. We coupled this design with a cost-effective portable smart-phone based reader allowing for quantitative measure of antibody binding, eliminating subjectiv- ity. By multiplexing peptide antigens each containing 1-2 epitopes unique to B. burgdorferi from multiple differ- ent antigens expressed at different stages during mammalian infection we can generate a single tier, POC as- say that can specifically and sensitively detect patient antibody at all stages of the disease. The assay can be completed in less than 25 min allowing for rapid in office results to support clinical diagnosis, thereby improving patient outcomes. PUBLIC HEALTH RELEVANCE: Early diagnosis of Lyme disease is critical to prevent disease progression and sequelae; however current laboratory diagnostics that are used to support clinical diagnosis are insensitive during early infection, failing ~50% of the time. We propose the development of a sensitive and specific multi-antigen point-of-care assay that will provide immediate serological detection of antibodies against Borrelia burgdorferi, the causative agent of Lyme disease, to aid in physician diagnosis. Accurate, rapid diagnosis will improve patient outcomes by reducing the likelihood of developing potentially debilitating late stage disease through early antibiotic intervention.",A peptide-based point-of-care vertical flow assay for the rapid diagnosis of Lyme disease,10404209,R44AI150060,"['Address', 'Antibiotics', 'Antibodies', 'Antigen Targeting', 'Antigens', 'Bacterial Proteins', 'Binding', 'Binding Proteins', 'Biological Assay', 'Borrelia burgdorferi', 'Borrelia miyamotoi', 'Cells', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Clinical', 'Clinical Treatment', 'Coupled', 'DBL Oncoprotein', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Early treatment', 'Epitopes', 'Family', 'Generations', 'Goals', 'ITGB3 gene', 'ImProv', 'Immunoglobulin G', 'Immunoglobulin M', 'Individual', 'Infection', 'Intervention', 'Laboratories', 'Laboratory Diagnosis', 'Legal patent', 'Lyme Disease', 'Machine Learning', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microbe', 'Musculoskeletal System', 'Nature', 'Nervous system structure', 'OspC protein', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Peptides', 'Phase', 'Physicians', 'Proteins', 'Reader', 'Reporting', 'Research', 'Sampling', 'Serology', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Speed', 'Spottings', 'System', 'Technology', 'Testing', 'Time', 'Work', 'antibody detection', 'base', 'biological systems', 'blind', 'clinical Diagnosis', 'cost', 'cost effective', 'cross reactivity', 'decorin binding protein B', 'design', 'detection assay', 'detection platform', 'diagnostic assay', 'efficacy testing', 'improved', 'innovation', 'member', 'multiplex detection', 'novel strategies', 'point of care', 'point of care testing', 'point-of-care detection', 'point-of-care diagnostics', 'portability', 'preservation', 'prevent', 'prototype', 'public health relevance', 'rapid diagnosis', 'rapid test', 'relapsing fever borrelia', 'screening']",NIAID,"BIOPEPTIDES, INC.",R44,2021,1000000
"Molecular characterization of pulmonary edema: a window to an injured lung Acute respiratory distress syndrome (ARDS) is a heterogeneous, life-threatening condition defined by poor oxygenation and bilateral pulmonary edema that carries a mortality rate >40% in most studies. Every ARDS drug trial to date has failed, perhaps because the clinical criteria defining ARDS include a substantial subset of low-risk patients. Clinical scoring systems poorly predict which ARDS patients will develop prolonged respiratory failure and are at increased risk of death.  Molecular profiling of pulmonary edema fluid could serve as a window on the alveolar microenvironment, enabling identification of high-risk patients. Pulmonary edema directly reflects lung pathobiology including loss of barrier integrity, inflammation, and epithelial damage. Unfortunately, free-flowing pulmonary edema has limited clinical utility because it can only be captured in a minority of patients. Molecular characterization of pulmonary edema is now possible in every patient with ARDS because of two critical innovations. First, we discovered that edema fluid condensing in the HME (heat and moisture exchanger) filter of the ventilator circuit, usually discarded as trash, closely reflects free-flowing edema. Second, we developed a non-targeted metabolomic fingerprinting method using mass spectroscopy that characterizes molecular components in trace quantities of fluid. Together, these innovations make it possible to test the central hypothesis that molecular features of edema fluid reflect pathobiology and enable ARDS risk stratification.  To address the prognostic enrichment potential of HME edema fluid, 300 early ARDS patients will be recruited at 3 US centers, with protocolized HME edema fluid collection. Aim 1 is to study whether high HME edema fluid total protein and lung-injury specific proteins predict prolonged respiratory failure ≥48h in ARDS. Aim 2 is to test whether hypermetabolic edema fluid and inflammatory lipids predict prolonged respiratory failure ≥48h in ARDS. In Aim 3, LASSO machine learning will be used to integrate all proteomic and metabolomic edema features into a prolonged mechanical ventilation classifier. The robustness of the classifier will be assessed by measuring whether it adds prognostic value to clinical ARDS severity scores, identifying how well key molecular features are reflected in plasma, and testing for replication in an independent cohort.  The goal of these studies is to examine to what extent a novel and readily available lung-specific sample, obtained early in the course of ARDS, reflects biology and can predict ARDS outcomes, thus offering prognostic enrichment for future clinical trials. Successful completion of the Specific Aims offers the potential for a much-needed classification scheme to better refine, understand, and therapeutically-target ARDS. PROJECT NARRATIVE Acute Respiratory Distress Syndrome (ARDS) is a common, life-threatening condition with no approved drug treatments. Pulmonary edema is a cardinal feature of ARDS and is mirrored closely by edema fluid collected passively in the Heat Moisture Exchanger (HME) filter; thus HME filter edema provides a novel and completely non-invasive window to the alveolar microenvironment. This proposal seeks to understand whether molecular characteristics of HME filter edema predict prolonged respiratory failure and could facilitate enrollment of high-risk patients into ARDS clinical trials.",Molecular characterization of pulmonary edema: a window to an injured lung,10231005,R01HL152083,"['Address', 'Adult Respiratory Distress Syndrome', 'Alveolar', 'Bilateral', 'Bioinformatics', 'Biology', 'Bronchoscopy', 'Cessation of life', 'Characteristics', 'Classification', 'Classification Scheme', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collection', 'Data', 'Development', 'Disease', 'Edema', 'Electrons', 'Enrollment', 'Epithelial', 'Failure', 'Fingerprint', 'Functional disorder', 'Future', 'Goals', 'Heterogeneity', 'Hour', 'Individual', 'Inflammation', 'Inflammatory', 'Informatics', 'Intensive Care', 'Life', 'Lipids', 'Liquid substance', 'Lung', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Mechanical ventilation', 'Methods', 'Minority', 'Modeling', 'Molecular', 'Molecular Profiling', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Edema', 'Reporting', 'Research', 'Research Personnel', 'Respiratory Failure', 'Risk', 'Sample Size', 'Sampling', 'Severities', 'System', 'Technology', 'Testing', 'Ventilator', 'alveolar epithelium', 'cohort', 'effective therapy', 'epithelial injury', 'high risk', 'innovation', 'ionization', 'lung injury', 'metabolomics', 'mortality', 'mortality risk', 'multidisciplinary', 'novel', 'peripheral blood', 'primary outcome', 'prognostic', 'prognostic value', 'prospective', 'protein metabolite', 'receptor for advanced glycation endproducts', 'recruit', 'risk stratification', 'secondary outcome', 'systemic inflammatory response', 'therapeutic target', 'treatment strategy']",NHLBI,STANFORD UNIVERSITY,R01,2021,539888
"Investigation of arterial changes in the Circle of Willis during intracranial aneurysm growth in humans PROJECT SUMMARY/ABSTRACT Prevalence of saccular intracranial aneurysms (IA) in western populations is estimated at around ~3%. Clinically, IA present a dilemma, in that they are usually asymptomatic; however, IA are extremely dangerous if they rupture, causing subarachnoid hemorrhage (~50% mortality). There is convincing evidence that continued IA growth increases the risk of rupture (12-24 times). To better monitor and predict IA progression, there is a compelling need to better understand clinical IA growth (aneurysmal remodeling). 90% of IA occur within the arteries of the Circle of Willis (CoW). Despite there being overwhelming evidence connecting CoW vascular remodeling and IA disease, the majority of IA research focuses only on the IA site, and does not consider the contribution of connected arteries. Specific vascular remodeling in the CoW arteries may provide an additional indicator for monitoring IA progression. The biochemical processes that occur at the IA site include inflammation and extracellular matrix remodeling leading to cell death and vessel wall degeneration. Analyses in animal models have strongly connected arterial wall shear stress (WSS) as a trigger of these processes, leading to IA initiation and remodeling. Patient-oriented research has further linked areas of low WSS with IA growth. Because CoW vasculature can change during IA growth, the blood flow entering IA changes and may create a new level of WSS to stabilize the remodeling process. Better understanding how human IA may naturally stabilize is highly relevant to predicting IA progression, and the role of changing WSS will be investigated in this grant. In our recent study of 520 clinically monitored IA, we found that while many IA grew consistently, following a projected growth path, others became stable. We also found that IA growth speed is significantly faster in women. Given the association of IA with sex, family history, and disease, different patterns of vascular remodeling may occur within groups with different genetics or medical history. We propose a clinical translational study to study IA growth in different genetic and medical history groups. We hypothesize IA growth may associate with patterns of vascular remodeling within the CoW. We will test our hypothesis with the following specific aims: (1) Is IA growth a local phenomenon or it associated with vascular remodeling within the CoW? (2) Do genetically similar individuals undergo similar patterns of vascular remodeling? (3) Does blood flow within the CoW associate with vascular remodeling? By identifying how IA disease progression may associate with other remodeling within the CoW, this study can identify new imaging biomarkers that enable improved IA treatment decisions. This proposal is significant because there is an unmet need to accurately assess IA disease progression and changes in risk. This proposal is innovative because it will extend existing IA studies to include more, relevant cerebrovascular arteries and longitudinal data, while implementing several technical innovations specific to this problem which can translate to clinical tracking of cerebrovascular changes PROJECT NARRATIVE Intracranial aneurysms are extremely dangerous when they rupture. When one is detected, it may be treated or monitored through imaging, with aneurysm growth a strong indication of increased risk of rupture. This project will study how remodeling in the arteries of the Circle of Willis associates with aneurysm growth, and how blood flow may determine locations of remodeling, in order to identify new biomarkers to improve tracking and assessment of aneurysm progression.",Investigation of arterial changes in the Circle of Willis during intracranial aneurysm growth in humans,10175024,R01HL152270,"['Affect', 'Aneurysm', 'Angiography', 'Animal Model', 'Area', 'Arteries', 'Autosomal Dominant Polycystic Kidney', 'Biochemical Process', 'Biological Markers', 'Blood Vessels', 'Blood flow', 'Caliber', 'Cell Death', 'Characteristics', 'Circle of Willis', 'Clinical', 'Dangerousness', 'Data', 'Data Set', 'Disease', 'Disease Progression', 'Extracellular Matrix', 'Family', 'Gender', 'Genetic', 'Geometry', 'Grant', 'Growth', 'Human', 'Hypertension', 'Image', 'Individual', 'Inflammation', 'Intracranial Aneurysm', 'Investigation', 'Length', 'Lesion', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Medical History', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Prevalence', 'Process', 'Prospective cohort', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Role', 'Rupture', 'Site', 'Speed', 'Statistical Models', 'Stroke', 'Subarachnoid Hemorrhage', 'Techniques', 'Testing', 'Time', 'Translating', 'United States', 'Validation', 'Vascular remodeling', 'Woman', 'Work', 'arterial tortuosity', 'cerebrovascular', 'clinical risk', 'data modeling', 'demographics', 'hemodynamics', 'imaging biomarker', 'improved', 'innovation', 'mortality', 'novel', 'patient oriented research', 'risk stratification', 'sex', 'shape analysis', 'shear stress', 'side effect', 'tool', 'translational study']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,645367
"T4SS effectors and tick tropism in Anaplasma phagocytolium Project Summary  Tick-borne diseases are on the increase, and are responsible for nearly all of the vector-transmitted disease in the US. Vector-borne pathogens face the dual challenge of adaptation to two very different host environments: the arthropod vector and the mammalian host. To survive within eukaryotic cells, the rickettsial pathogen Anaplasma phagocytophilum blocks phago-lysosome maturation, inhibits apoptosis, modulates host gene expression, redirects trans-Golgi trafficking, and repurposes autophagic machinery to build a replication vacuole. A. phagocytophilum must accomplish this, all while evading the unique innate immune defenses of mammalian and arthropod host cells. All pathogens in the order Rickettsiales utilize a specialized Type IV Secretion System (T4SS) to deliver effector molecules into the host cell cytosol to mediate host pathogen interactions. However, identification of the secreted effectors has been limited by the obligate nature of these pathogens. Even less is known about how effectors contribute to rickettsial growth in tick cells, as the tick vector remains an understudied niche of these pathogens. To overcome this, our group has developed a T4SS effector prediction program Optimal-features Predictor for T4SS Effectors (OPT4e). When applied to A. phagocytophilum, OPT4e identified 48 putative T4SS effectors. Transcriptomics finds that 15 of these predicted effector genes are specifically expressed during growth within either tick or mammalian cells. We have demonstrated that one of these tick- specific effector candidates, Aph1383, is translocated in a T4 specific manner by the Legionella pneumophila T4SS. Aph1383 also belongs to a paralogous family of six proteins encoded by the gene cluster aph1380-1386. This entire cluster is expressed 2.5-fold more highly during A. phagocytophilum growth in tick cells than during mammalian cell infections. We hypothesize that this family of Aph1383 paralogs are all T4SS effectors which target host cell processes specifically important for A. phagocytophilum growth within tick cells. In this study, we will first use transposon insertion mutants in the aph1380-1386 gene cluster to test the fitness contribution of these genes during A. phagocytophilum growth within tick cells. Next, we will evaluate the T4SS translocation of all Aph1383 paralogs and identify the amino acid sequences necessary for secretion. Finally, we will identify the subcellular localization and molecular targets of Aph1383 within tick cells. Characterizing these molecular interactions of A. phagocytophilum within the tick cell will open the door to development of vector targeted interventions to reduce transmissibility of the pathogen. Project Narrative Vector-borne diseases account for >17% of the global burden of all infectious diseases. The ability of the tick-borne rickettsial pathogen Anaplasma phagocytophilum to manipulate the cell biology of both mammalian and tick cells is achieved through delivery of effector molecules by a specialized secretion system. This project investigates how a family of tick specific effectors enables A. phagocytophilum to survive and replicate within tick cells.",T4SS effectors and tick tropism in Anaplasma phagocytolium,10174737,R21AI154023,"['Amino Acid Sequence', 'Anaplasma', 'Anaplasma phagocytophilum', 'Apoptosis', 'Arthropod Vectors', 'Arthropods', 'Bacteria', 'Binding', 'Biochemical', 'Biological Assay', 'Blood', 'Case Study', 'Cell Culture Techniques', 'Cell Line', 'Cell Survival', 'Cell physiology', 'Cells', 'Cellular biology', 'Climate', 'Communicable Diseases', 'Cytosol', 'Defect', 'Dependence', 'Development', 'Ectopic Expression', 'Environment', 'Epithelial Cells', 'Eukaryotic Cell', 'Face', 'Family', 'Gene Cluster', 'Gene Expression', 'Genes', 'Genome', 'Golgi Apparatus', 'Growth', 'Human Cell Line', 'Immune', 'Infection', 'Intervention', 'Legionella pneumophila', 'Libraries', 'Life Cycle Stages', 'Life Style', 'Mammalian Cell', 'Mammals', 'Mediating', 'Membrane', 'Midgut', 'Molecular Target', 'Mutagenesis', 'Nature', 'Parasites', 'Pattern', 'Phagolysosome', 'Process', 'Protein Family', 'Proteins', 'Reporter', 'Rickettsia', 'Salivary Glands', 'Signal Transduction', 'System', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Transfection', 'Tropism', 'Type IV Secretion System Pathway', 'United States', 'Vacuole', 'Vector-transmitted infectious disease', 'cell type', 'feeding', 'fitness test', 'innovation', 'machine learning algorithm', 'mutant', 'neutrophil', 'paralogous gene', 'pathogen', 'pathogenic bacteria', 'programs', 'protein aminoacid sequence', 'tick-borne', 'tool', 'trafficking', 'transcriptomics', 'transmission process', 'vector', 'vector tick', 'vector-borne pathogen']",NIAID,WASHINGTON STATE UNIVERSITY,R21,2021,229500
"COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS COPD SUBTYPING AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS ABSTRACT One of the main obstacles in developing efficient personalized therapeutic and disease management strategies is that most common diseases are typically defined based on symptoms and clinical measurements, although they are believed to be syndromes, consisting of multiple subtypes with variable etiology. Identifying disease subtypes has thus become very important, but so far it has been met with limited success for most diseases. In asthma, a notable exception, it was the clinical characterization that led to successful subtyping; and this is now incorporated in treatment guidelines. Unsupervised machine learning approaches of single data modalities (e.g., omics, radiographic images) have not produced actionable subtypes due to instability across cohorts. Developing data integrative approaches for multi-scale data, which are becoming available for a number of diseases, is expected to lead to robust subtyping and provide mechanistic insights of disease onset and progression. This proposal focuses on developing new computational methods, based on probabilistic graphical models (PGMs), to address this unmet need; and apply them to investigate three problems of clinical importance in chronic obstructive pulmonary disease (COPD), which is the fourth leading cause of mortality in USA. Our underlying hypothesis is that PGMs can integrate and analyze under the same probabilistic framework heterogeneous biomedical data (omics, chest CT scan, clinical) and identify disease subtypes and their main determinants. The objectives of our proposal is to build a comprehensive computational framework for disease subclassification, identify stable COPD subtypes at the baseline and longitudinally, and build interpretable models of the disease The deliverables of this project are: (1) new integrative computational approaches for clinical subtyping from multi-scale data; (2) new predictors of COPD progression and severity; (3) new discoveries of longitudinally stable COPD subtypes; (4) new predictors of future development of COPD; (5) new omics datasets that will be invaluable to future research in the area (baseline and longitudinal). To ensure the success of the project we follow a team science approach. This multi-PI proposal builds on the ongoing efforts of our group in the area of graphical models and their applications in biomedicine; and the ongoing collaboration of the three PIs that have complementary strengths: Prof. Benos (systems medicine and machine learning), Dr. Hersh (COPD genetics and genomics) and Dr. Sciurba (clinical aspects of COPD). It is powered by the access of the investigators to three major COPD cohorts (COPDGene®, SCCOR, ECLIPSE) that contain multiple parallel deep phenotyping and omics data from thousands of patients and controls. Although in this project we focus on COPD, our methods are generally applicable to any disease, therefore our project will have a positive impact beyond the above deliverables. We believe that due to their robust nature and interpretability, PGMs will soon become the norm for multi-scale biomedical data integration and modeling, when genetic and genomic data collection will become routine prognostic and diagnostic tools in clinical practice. PROJECT NARRATIVE Understanding the etiology of complex diseases and categorizing patients from samples taken from easily accessible tissues (like blood) are two very important aspects that will lead to development of new precision medicine strategies. In this proposal, we plan to develop new computational methods and tools that will allow researchers to identify subphenotypes in any disease. We will apply these methods on three cohorts with thousands of patients with chronic obstructive pulmonary disease (COPD) and our results are expected to help us understand the complexities of this disease and build predictors of future development.",COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS,10206417,R01HL157879,"['Address', 'Algorithms', 'Area', 'Asthma', 'Biology', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Disease Progression', 'Disease model', 'Enrollment', 'Ensure', 'Etiology', 'Functional Imaging', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genetic', 'Genetic Diseases', 'Genomics', 'Graph', 'Health Care Costs', 'Image', 'Incidence', 'Individual', 'Lead', 'Link', 'Machine Learning', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Target', 'Multiomic Data', 'Nature', 'Onset of illness', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Pulmonary function tests', 'Pulmonology', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Severities', 'Severity of illness', 'Stable Disease', 'Symptoms', 'Syndrome', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Visit', 'X-Ray Computed Tomography', 'airway obstruction', 'analytical method', 'base', 'cellular targeting', 'chest computed tomography', 'clinical practice', 'clinical subtypes', 'clinically relevant', 'cohort', 'computer framework', 'computerized tools', 'data integration', 'data modeling', 'disability', 'disease phenotype', 'disorder subtype', 'follow-up', 'genetic variant', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'insight', 'learning algorithm', 'mortality', 'mortality risk', 'multimodal data', 'multimodality', 'multiscale data', 'peripheral blood', 'personalized predictions', 'personalized therapeutic', 'precision medicine', 'predictive modeling', 'prognostic', 'prognostic value', 'pulmonary function', 'success', 'tool', 'treatment guidelines', 'unsupervised learning', 'vector']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,739755
"Interpretable graphical models for large multi-modal COPD data INTERPRETABLE GRAPHICAL MODELS FOR LARGE MULTI-MODAL COPD DATA ABSTRACT One of the most important tasks in today’s era of precision medicine is to understand the mechanisms and the factors affecting the development of clinical outcomes. Another important task is to develop interpretable, predictive models for outcomes. In the last years, many machine learning methods have dominated the task of predictive modeling, including deep learning, random forests and others. They are fueled by the unprecedent volume of data that have been generated in some research areas. However, the interpretability of these methods is not straight forward and their accuracy decreases when only small to medium size training datasets are available. Furthermore, their predictive models do not uncover the complex web of interactions between other variables in the dataset, which is essential for fully understanding disease mechanisms. Also, most such methods are not well suited to accommodate mixed data types (e.g., continuous, discrete) in the same dataset. Probabilistic graphical models (PGMs) offer a promising alternative to classical machine learning methods, because they are flexible and versatile. They can identify both the direct (causal) relations between variables, pointing to disease mechanisms, and build predictive models over diverse data, with good results even with smaller training datasets. They have been used for classification, biomarker selection, identification of modifiable risk factors of an outcome, or for mechanistic studies of perturbations of disease networks. In the previous years we extended the PGM theoretical framework to the analysis of mixed continuous and discrete variables, with or without unmeasured confounders; and we can now evaluate and incorporate prior information in mixed data graph learning. We successfully applied those methods to diverse clinically important problems, including malignancy prediction of undetermined lung nodules, identification of microbiome and other factors affecting pneumonia, selection of SNP biomarkers for combination treatment of cancer patients. Our objective is to develop novel interpretable methods for analysis of any-type data and use them to address clinically relevant questions in COPD, an important chronic lung disease. Method evaluation will be done on synthetic and real data, including parallel datasets with genomic, genetic, imaging and clinical COPD data. Our central aim is to identify factors of disease mechanisms of progression using different modalities of patient data. The deliverables will be (1) new PGM approaches for integrative analysis of any-type data; (2) a new, fully documented software package (in R, Python) that can be incorporated in other pipelines; (3) a new web portal to disseminate our methodologies to non-computer-savvy COPD researchers; (4) results on the pathogenesis and predictive features of chronic obstructive pulmonary disease (COPD). This cross-disciplinary team project is expected to have a positive impact beyond the above deliverables, since the generality of our approaches makes them suitable for studying any disease; and they can be easily integrated into personalized medicine strategies when high-throughput data collection will become a routine diagnostic procedure in all hospitals. PROJECT NARRATIVE New data collection methods have the potential to revolutionize medicine by generating multiple and informationally complementary data streams from patients. A current roadblock is the efficient analysis of such multi-modal datasets. We propose to use causal graphical models to represent the data and identify the direct associations between variables; and use those algorithms to address important medical questions related to Chronic Obstructive Pulmonary Disease (COPD).",Interpretable graphical models for large multi-modal COPD data,10301433,R01HL159805,"['Address', 'Affect', 'Algorithms', 'Area', 'Biological Markers', 'Cancer Patient', 'Cause of Death', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Clinical Data', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Dose', 'Evaluation', 'Explosion', 'Face', 'Genetic', 'Genomics', 'Grant', 'Graph', 'Health Care Costs', 'Hospitals', 'Image', 'Internet', 'Joints', 'Knowledge', 'Learning', 'Letters', 'Libraries', 'Lung nodule', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Outcome', 'Pathogenesis', 'Patients', 'Pneumonia', 'Probability', 'Process', 'Production', 'Property', 'Pythons', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Series', 'System', 'Theoretical model', 'Time', 'Training', 'Validation', 'biomarker selection', 'cancer therapy', 'clinical development', 'clinically relevant', 'cohort', 'data streams', 'deep learning', 'disability', 'diverse data', 'flexibility', 'high dimensionality', 'machine learning method', 'microbiome', 'modifiable risk', 'mortality', 'multimodal data', 'multimodality', 'non-Gaussian model', 'novel', 'personalized medicine', 'precision medicine', 'predictive modeling', 'programs', 'random forest', 'success', 'theories', 'tool', 'web portal', 'web server']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,559193
"Systems analysis and prediction of endothelial cross-family signaling PROJECT SUMMARY/ABSTRACT The vascular endothelial growth factors (VEGFs) direct key signaling processes in obesity and at least 70 other diseases. However, focus on this signaling node alone has not achieved the promise of predictable angiogenic control. Current models are incomplete as other growth factors, besides VEGF, contribute to vascular disease progression, presenting a complexity that cannot be predictably regulated by targeting one node in this system. Therefore, there is a continuing need to account for the complexity of additional, multi-component signaling networks, a goal that can be achieved via data-driven, computational systems biology in close concert with experimental analysis of signaling and functional response. Toward this goal, we aim to examine a novel paradigm of network regulation called cross-family signaling, in which members from one growth factor family [e.g., platelet derived growth factors (PDGFs)] bind to and signal through members of another family (e.g., VEGFRs). We hypothesize that systematic examination of protein structure and downstream signaling within the cross-family paradigm via simulation, ligand-engineering, network quantification, and computational modeling can uncover novel mechanisms to control angiogenesis. We will test this hypothesis through three aims, sensitively quantifying receptor activation rates and functional responses of cross-family binding (e.g., proliferation, migration, and barrier function); predicting and measuring the structural properties of cross-family binding via molecular simulations and directed evolution; and developing validated deterministic models (mass-action kinetic modeling) of cross- family signaling and applying them to study and control the dynamics of cross-family signaling in human cell systems, in silico. We are primed to lead this new research because we are among the first to pursue this important theoretical paradigm, and we lead this cause to understand cell signaling via structure/function–based computational modeling. This work will catalyze a shift in perspective and innovation in the areas of cell signaling, systems biology, and predictive design of obesity- focused therapies. PROJECT NARRATIVE Angiogenesis is a key pathogenic component of obesity and at least 70 known diseases, and it is primarily driven by the vascular endothelial growth factor receptor (VEGFR) and its family of VEGF ligands. However, targeting VEGF alone has not achieved the promise of stable vascular control, so new approaches are needed to control and direct vascular development. The purpose of these studies is to biologically and computationally assess how the new theory of cross- family signaling may control vascular signaling at the molecular, protein, and cellular levels.",Systems analysis and prediction of endothelial cross-family signaling,10317179,R01HL159946,"['Adaptor Signaling Protein', 'Adipocytes', 'Adipose tissue', 'Affinity', 'Amino Acids', 'Area', 'Binding', 'Biological', 'Blood Vessels', 'Cell Proliferation', 'Cell Survival', 'Cell physiology', 'Cells', 'Computer Models', 'Data', 'Development', 'Directed Molecular Evolution', 'Disease', 'Disease Progression', 'Dose', 'Effector Cell', 'Endothelial Cells', 'Endothelial Growth Factors Receptor', 'Endothelium', 'Engineering', 'Family', 'Fibrinogen', 'Fibroblasts', 'Fibrosis', 'Goals', 'Growth Factor', 'Growth Factor Receptors', 'Health', 'Human', 'In Vitro', 'Inflammation', 'Insulin Resistance', 'KDR gene', 'Knowledge', 'Lead', 'Libraries', 'Ligands', 'Lipids', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medicine', 'Modeling', 'Molecular', 'National Heart, Lung, and Blood Institute', 'Obesity', 'Organoids', 'PTK2 gene', 'Pathogenicity', 'Permeability', 'Phosphorylation', 'Platelet Activating Factor', 'Platelet-Derived Growth Factor', 'Platelet-Derived Growth Factor Receptor', 'Pre-Clinical Model', 'Process', 'Property', 'Proteins', 'Receptor Activation', 'Regulation', 'Research', 'Role', 'Scheme', 'Signal Transduction', 'Site', 'Structure', 'System', 'Systems Analysis', 'Systems Biology', 'Testing', 'Therapeutic', 'Tissue Expansion', 'Tissues', 'Translating', 'Tyrosine', 'Validation', 'Vascular Diseases', 'Vascular Endothelial Growth Factors', 'Vascularization', 'Work', 'angiogenesis', 'base', 'design', 'experimental analysis', 'in silico', 'innovation', 'kinetic model', 'member', 'migration', 'molecular dynamics', 'mutation screening', 'novel', 'novel strategies', 'obesity treatment', 'obesogenic', 'pedagogy', 'pre-clinical', 'predictive test', 'protein structure', 'receptor', 'receptor binding', 'response', 'screening', 'simulation', 'text searching', 'theories']",NHLBI,WASHINGTON UNIVERSITY,R01,2021,698854
"Long Acting Injectable Depots for TB Therapy PROJECT SUMMARY/ABSTRACT Patient dosing adherence is often compromised by the complex pill regimes and long duration of current TB drug therapies. These challenges are exacerbated in settings for patients in many social and global settings where TB co-therapy with HIV positive patients is stigmatized. Long-acting drug delivery products should therefore play an important role to increase patient adherence and increase drug efficacy. This project will develop a new injectable depot technology that address a general target product profile that includes multiple-month delivery from a single injection, low volume and low viscosity formulations to reduce patient pain, combination drug formulation where required, sustained drug release with designable PK profiles, minimal initial and run-out burst release to increase safety and prevent drug resistance, and for global settings has low cost of goods and lowered cold-chain requirements. This depot technology also has the important translational product attributes of streamlined CMC and cGMP manufacturing that could lead to more rapid clinical development achievement. A new injectable depot product for TB therapy will be developed that is differentiated from current dispersal based formulation approaches by being a fully synthetic depot. The proposal is structured around 2 specific aims in the R61 phase and two further aims in the R33 phase: (1) Prodrug monomers made by synthetic chemistry are directly polymerized in a second synthetic step to create “drugamer” depot therapeutics that have the drugs built into the depot itself. Compared to current dispersion formulation approaches, the drugamers exhibit higher drug loading efficiencies, the ability to co-formulate drugs of different lipophilicities, and linear, individually tailorable PK profiles that minimize first- and last-week burst release. These PK profiles are kinetically controlled by the linker properties that are tied to the individual drugs, along with polymer architectural design. This aim will exploit a unique high throughput polymer library and screening platform at CSIRO Melbourne to identify lead injectable depot designs using bedaquiline and moxifloxicin as initial drug examples. Sophisticated LC-MS/MS PK characterization will assess the sustained PK profile together with PK/PK modeling. (2) Evolve and optimize depot lead candidates through efficacy in an initial TB model that allows higher throughput imaging characterization of activity. This will be followed by an Mtb model assessment and selection to a lead depot candidate; (3) Test and optimize the two lead drug depot candidates in an A/BSL3 Mtb model, by the criteria of PK/PD, efficacy and dose dependence, and dosing duration. The lead depot will also be characterized in accelerated stability studies to test whether they can avoid cold-chain storage. (4) Evaluate iterated up-selected depots in combination depots from mixing optimized bedaquiline and moxifloxacin depots, including dual PK profiling and PK/PD modeling. This same approach could also be expanded to develop future therapeutic products based on other combination drug depot designs. These favorable platform attributes motivate this this project as a potential new addition to the repertoire of anti-TB patient products. Project Narrative This project will provide TB therapy products that make patient adherence to monotherapy and combination drug therapy more effective. The new technology will provide drug dosing from a single injectable product that can be tailored to 2-3 month dosing from single injections. Patients will experience lower pain and the product will reduce the need for refrigeration to increase impact globally.",Long Acting Injectable Depots for TB Therapy,10236790,R61AI161820,"['Achievement', 'Acute', 'Address', 'Adherence', 'Architecture', 'Attenuated', 'Automation', 'Chemistry', 'Clinical', 'Clinical Trials', 'Cold Chains', 'Combination Drug Therapy', 'Complex', 'Cyclic GMP', 'Data', 'Dependence', 'Development', 'Dimethyl Sulfoxide', 'Dose', 'Drug Combinations', 'Drug Delivery Systems', 'Drug Formulations', 'Drug Interactions', 'Drug resistance', 'Exhibits', 'Formulation', 'Freeze Drying', 'Future', 'HIV', 'HIV Seropositivity', 'HIV therapy', 'HIV/TB', 'High Prevalence', 'Image', 'Impairment', 'Implant', 'Individual', 'Infection', 'Injectable', 'Injections', 'Kinetics', 'Lead', 'Length', 'Libraries', 'Machine Learning', 'Maps', 'Modeling', 'Moxifloxacin', 'Mycobacterium tuberculosis', 'Pain', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Plasma', 'Play', 'Polymer Chemistry', 'Polymers', 'Powder dose form', 'Prodrugs', 'Property', 'Refrigeration', 'Regimen', 'Robotics', 'Role', 'Running', 'Safety', 'Solubility', 'Stigmatization', 'Structure', 'Synthesis Chemistry', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Translations', 'Virulent', 'Viscosity', 'Water', 'Weight', 'base', 'biosafety level 3 facility', 'chronic infection', 'clinical development', 'co-infection', 'compliance behavior', 'cost', 'design', 'drug efficacy', 'drug release profile', 'experience', 'first-in-human', 'innovation', 'lead candidate', 'lipophilicity', 'monomer', 'mouse model', 'multidisciplinary', 'new technology', 'pharmacokinetics and pharmacodynamics', 'pill', 'prevent', 'product development', 'screening', 'social', 'solid state', 'therapy duration', 'tuberculosis drugs', 'tuberculosis treatment']",NIAID,UNIVERSITY OF WASHINGTON,R61,2021,686389
"Innovative Vaccine Approaches ABSTRACT Support is requested for a Keystone Symposia conference entitled Innovative Vaccine Approaches, organized by Drs. Mariagrazia Pizza, Galit Alter and Gordon Dougan. The conference will be held in Vancouver, Canada from June 27- July 1, 2021. Vaccines have the power to prevent and potentially eradicate a wide range of infectious diseases, representing one of the most effective life-saving measures at our disposal against global health threats. The recent coronavirus pandemic has brought the importance and urgency of vaccine development efforts into sharp focus. Moreover, the vaccinology field is evolving very rapidly, thanks to advances in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis of antigens and antigen- antibody complexes and impacts of variation. Over the years, this field has also experienced an elucidation of mechanisms of immunity and protection, and identification of correlates. However, many questions are still unsolved and innovative approaches are needed to address new vaccine challenges like antimicrobial resistance, emerging infectious diseases, cancer and diseases associated with our aging population. This conference will cover the latest advances and novel approaches towards vaccine development, including: (1) novel antigen delivery systems; (2) in vitro and in vivo model systems for vaccine appraisal (3) the use of human challenge models; (4) the role of ‘systems biology’ in the comprehensive analysis of immune correlates, biomarker identification and safety; (5) machine-learning approaches to define correlations between antibody repertoires and protection; and (6) strategies for developing low cost vaccines for economically challenged populations. Together these topics will provide attendees with the new ideas and tools to continue to forge new frontiers in vaccine capabilities. PROJECT NARRATIVE Vaccines have the power to prevent and potentially eradicate a wide range of both infectious and non- infectious diseases. The field is evolving very rapidly due to improvements in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis techniques. This conference will accelerate advances the field, bringing together public and private communities to ensure the end of the COVID-19 pandemic and other epidemics that afflict the population. This event provides a unique opportunity for discussion of the key challenges in making low cost vaccines for economically challenged populations and how to address burning topics such as pandemics, antimicrobial resistance, emerging infectious diseases, cancer and an aging population.",Innovative Vaccine Approaches,10237543,R13AI161938,"['Address', 'Antibody Repertoire', 'Antibody-mediated protection', 'Antigen-Antibody Complex', 'Antigens', 'Antimicrobial Resistance', 'Biological Models', 'COVID-19 pandemic', 'Canada', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Coronavirus', 'Disease', 'Educational workshop', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Event', 'Future', 'Genomics', 'Human', 'Immersion', 'Immune', 'Immunity', 'Immunology', 'In Vitro', 'Knowledge', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Microbiology', 'Modeling', 'Outcome', 'Population', 'Privatization', 'Research', 'Research Personnel', 'Role', 'Safety', 'Savings', 'Scientist', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Vaccines', 'Variant', 'aging population', 'biomarker identification', 'clinical practice', 'cost', 'experience', 'frontier', 'global health', 'in vivo Model', 'innovation', 'manufacturability', 'next generation', 'novel', 'novel strategies', 'novel vaccines', 'pandemic disease', 'posters', 'prevent', 'symposium', 'tool', 'vaccine development', 'vaccine discovery', 'vaccinology']",NIAID,KEYSTONE SYMPOSIA,R13,2021,8000
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"Intelligently predicting viral spillover risks from bats and other wild mammals PROJECT SUMMARY The transmission or ‘spillover’ of wildlife viruses to humans is a critical threat to global health, with outbreaks of viral pathogens like filoviruses, paramyxoviruses, and coronaviruses all originating in wild mammals. A key outstanding question is whether specific taxonomic groups, such as bats, warrant extra surveillance as ‘special reservoirs’ of viruses that are potentially pathogenic to humans. However, existing host-virus datasets are not sufficiently resolved to predict fine-grain risk for species or genera. An effective response must therefore address two core aims: (i) synthesizing knowledge regarding virus-to-mammal interactions; and (ii) using that knowledgebase to robustly predict future spillover events (i.e., zoonotic risk). To enable robust analysis and reusability of public datasets of NIAID’s Bioinformatics Resource Center (BRC; especially NCBI Virus and Virus Pathogen Resources, ViPR), the project will develop Host-Virus Data Intelligence to address three main problems for data reuse: confidence of the taxonomic assignments of mammals and viruses in observations; confidence in the evidence for proposed mammal-virus interactions; and connecting all the relevant data in published texts that are hidden from existing databases. The project team will construct a novel bioinformatic pipeline that will digitally connect taxonomic knowledge, use it to search dark data to find evidence of potential host-virus interactions, and then link it together using metadata layers (‘data about the data’) to form a more expansive host-virus knowledge graph than previously feasible. The project’s computational approach leverages information extraction methods in natural language processing as well as novel applications of artificial intelligence methods such as probabilistic inductive logic programming. A key anticipated outcome is to expand the dataset of host-virus interactions by 3-fold compared to comprehensive existing datasets. The proposed project will lay the foundation for a new generation of work reusing host-virus interaction data to test previously inaccessible hypotheses about how species’ traits impact viral spillover to humans. Shifting the paradigm to graph-based analyses, compared to purely taxonomic representations of host-virus interactions, will allow researchers to directly investigate the impact of ecosystem structure and human encroachment upon viral loads. Determining whether all mammals have equal risk of viral spillover, or whether some groups have higher taxon-specific zoonotic risk (e.g., horseshoe bats, murid rodents), is critical information for public health workers and epidemiologists. More definitive risk quantification will also help researchers identify which ecophysiological adaptations predispose certain groups to tolerating more viruses, which may in turn lead to clinical treatments by modeling the immune responses of wild mammals. Filling the identified gaps in host-virus knowledge is therefore essential to aid the progress of zoonotic disease research in the wake of COVID-19. PROJECT NARRATIVE Synthesizing scientific data about mammal-to-virus interactions is essential to predicting the risk of future events like the COVID-19 pandemic. The project overcomes major obstacles to full and accurate reuse of existing mammal-virus data by applying computational methods for unifying relevant but disconnected data from published sources. Anticipated results will triple available knowledge, opening the door for asking whether some mammals carry more viruses than others and why with unprecedented levels of precision.",Intelligently predicting viral spillover risks from bats and other wild mammals,10289637,R21AI164268,"['Address', 'Artificial Intelligence', 'Attention', 'Base Sequence', 'Bioinformatics', 'COVID-19', 'COVID-19 pandemic', 'Chiroptera', 'Clinical Treatment', 'Computing Methodologies', 'Coronavirus', 'Data', 'Data Set', 'Databases', 'Disease', 'Disease Outbreaks', 'Ecology', 'Ecosystem', 'Epidemiologist', 'Event', 'FAIR principles', 'Feces', 'Filovirus', 'Foundations', 'Future', 'Generations', 'Goals', 'Grain', 'Graph', 'Human', 'Immune Tolerance', 'Immune response', 'Immunological Models', 'Infectious Diseases Research', 'Information Retrieval', 'Infrastructure', 'Intelligence', 'Investigation', 'Knowledge', 'Lead', 'Life', 'Link', 'Logic', 'Mammals', 'Metadata', 'Methods', 'Molecular', 'Muridae', 'Names', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nature', 'Outcome', 'Paramyxovirus', 'Pathogenicity', 'Public Health', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Rodent', 'Sampling', 'Serology', 'Services', 'Source', 'Structure', 'Taxon', 'Taxonomy', 'Testing', 'Time', 'Tissues', 'Trees', 'Uncertainty', 'Urine', 'Viral', 'Viral Load result', 'Viral reservoir', 'Virus', 'Work', 'Zoonoses', 'base', 'bioinformatics pipeline', 'bioinformatics resource', 'data reuse', 'digital', 'flexibility', 'global health', 'high risk', 'improved', 'inclusion criteria', 'indexing', 'innovation', 'insight', 'interest', 'knowledge base', 'knowledge graph', 'novel', 'pathogenic virus', 'prevent', 'response', 'secondary analysis', 'spillover event', 'surveillance study', 'trait', 'transmission process', 'virus host interaction']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2021,244519
"Using three-dimensional protein networks to uncover immuno-modulatory molecular phenotypes in infectious disease Using three-dimensional protein networks to uncover immuno-modulatory molecular phenotypes in  infectious disease CHALLENGE: Over the past decade, technologies for deep profiling of the human immune system, both in the context of natural and vaccine-mediated immunity, have become readily available. These approaches have generated a wide range of molecular profiles across infectious disease contexts. However, existing studies primarily focus on individual `omic datasets, and do not take into account the underlying molecular networks. Thus, the primary emphasis has been on uncovering predictive biomarkers, but these biomarkers may often be correlative surrogates and have little or no connection with the underlying molecular phenotypes driving disease pathophysiology. GOAL I propose to develop and use a novel framework to integrate genomic data with three-dimensional (3D) structurally-resolved protein networks to uncover immuno-modulatory molecular phenotypes in infectious disease. While protein networks are typically viewed as two-dimensional, with proteins as nodes and interactions between them as edges, this simplifying representation fails to take into account the 3D structures of the proteins themselves, and the corresponding interaction interfaces. My past work has demonstrated the critical importance of taking into account corresponding structural information in the integration of Mendelian mutations with protein networks, to elucidate molecular phenotypes underlying the corresponding genetic disorders, with high sensitivity and specificity. Here, I propose to develop a novel framework that integrates structural genomic data with host-pathogen protein interactome networks to generate 3D host-pathogen interactomes. These 3D interactome networks are then integrated with host (human) genetic data to uncover immuno-modulatory molecular phenotypes in HIV and influenza. INNOVATION AND IMPACT: The proposed work integrates both two orthogonal facets of my expertise in network systems biology and machine learning, and pushes the envelope on multiple key frontiers. First, it provides a novel framework for the integration of host genetic data with host-pathogen protein networks. Second, a key novelty is the incorporation of structural information corresponding to host-pathogen protein interaction interfaces to refine the traditional principle of “guilt-by-association”, and hone in on specific molecular phenotypes that modulate infectious disease risk. The identified molecular phenotypes will generate key mechanistic hypotheses regarding corresponding disease pathophysiology, and help design interventional strategies. Finally, while the focus here is to use this approach in HIV and influenza, the framework itself is generalizable and can be used across infectious disease contexts. Project Narrative I propose to develop and use a novel framework to integrate host genetic data with three-dimensional structurally-resolved host-pathogen protein networks to uncover immuno-modulatory molecular phenotypes in infectious disease. The incorporation of structural information provides a significant refinement over the traditional principle of “guilt-by-association”, and allows us to hone in on specific molecular phenotypes that modulate infectious disease risk. While the focus of the proposal is to use this approach to infectious diseases, the framework itself is generalizable and can be used across other immunological disease contexts.",Using three-dimensional protein networks to uncover immuno-modulatory molecular phenotypes in infectious disease,10295268,DP2AI164325,"['3-Dimensional', 'Antiviral Response', 'Automobile Driving', 'Biological Markers', 'Communicable Diseases', 'Data', 'Data Set', 'Databases', 'Disease', 'Disease Progression', 'Functional disorder', 'Generations', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genomics', 'Goals', 'Guilt', 'HIV', 'HIV risk', 'HIV/TB', 'Homology Modeling', 'Human', 'Human Genetics', 'Immune System Diseases', 'Immune system', 'Immunity', 'Individual', 'Influenza', 'Intervention', 'Machine Learning', 'Malaria', 'Mediating', 'Mendelian disorder', 'Modernization', 'Molecular', 'Molecular Profiling', 'Mutation', 'Pathway Analysis', 'Penetrance', 'Phenotype', 'Population Genetics', 'Proteins', 'Resolution', 'Role', 'Sensitivity and Specificity', 'Structural Protein', 'Structure', 'System', 'Systems Biology', 'Technology', 'Vaccines', 'Validation', 'Variant', 'Viral Proteins', 'Work', 'base', 'comparative', 'disorder risk', 'experience', 'flu', 'frontier', 'genetic variant', 'genomic data', 'genomic locus', 'genomic variation', 'immunoregulation', 'molecular phenotype', 'novel', 'pathogen', 'predictive marker', 'protein data bank', 'structural genomics', 'therapy design', 'three dimensional structure', 'two-dimensional']",NIAID,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,DP2,2021,470125
"Next generation mosquito control through technology-driven trap development and artificial intelligence guided detection of mosquito breeding habitats Project Summary Each year, approximately 400 million people are infected with an arboviral disease from the bite of an Aedes spp mosquito. Aedes spp. mosquitoes are a leading public health threat due to their high competency to vector multiple pathogens, their preference to bite humans, and their ability to adapt to new domestic environments. In the US, reintroduction and establishment of Aedes aegypti and Aedes albopictus mosquito populations has resulted in local epidemics of Zika, dengue and chikungunya in the past decade. Unfortunately, mosquito control programs in the US generally operate with limited budgets, forcing the majority of insecticide spraying to be conducted in reaction to population exposure instead of targeted prevention, which has also contributed to considerable growth of insecticide resistant populations, yielding a widening gap of infrastructure vulnerability. Our current proposal aims to leverage existing technologies from non-health disciplines to advance mosquito detection and abatement. We propose to validate the use of technology-driven mosquito traps that allow for high- throughput identification and counting of Aedes mosquitos at various life stages to inform decision making when selecting areas for insecticide spraying and abatement. Additionally, we propose to develop rigorous remote sensing workflows for identification of neighborhood-level Aedes abundance risk and rapid detection of individual Aedes mosquito breeding habitats on a household-level. This innovative proposal uses multi-year and real-world mosquito data from two different metropolitan areas to statistically adjust for variances in geographic ecologies, urban microclimates, seasonal climate patterns, and annual weather events. Our study will result in low-cost tools immediately ready for broad distribution and integration by vector control agencies nationally. The outcomes of our study have promise to directly impact vector control agency’s decision-making processes for mosquito trapping site selection, inform preventative abetment protocols, and shorten the time required for mosquito collection and identification. Further, integration of our proposed technology traps and informed site selection maps will increase overall collection volumes while preserving scarce resources for local vector control agencies. This proposal has the potential to create a paradigm shift in how we approach vector control globally, with a targeted intervention resulting in significant economic, environmental, and clinical benefits. Project Narrative Mosquito-borne diseases are a global concern that impact public health, tourism, and natural disaster recovery efforts. With no preventative vaccines or effective therapeutic option available for most mosquito-borne diseases, vector control efforts are the only combative option; however, these efforts are often limited by financial constraint and insecticide resistance concern. This proposed project aims to integrate cutting-edge mosquito collection traps, and novel remote sensing and machine learning workflows to guide local vector operations and direct abatement efforts in a cost-efficient manner.",Next generation mosquito control through technology-driven trap development and artificial intelligence guided detection of mosquito breeding habitats,10339610,R01AI165560,"['Abate', 'Aedes', 'Algorithms', 'Aptitude', 'Arbovirus Infections', 'Arboviruses', 'Area', 'Artificial Intelligence', 'Bite', 'Breeding', 'Budgets', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Characteristics', 'Chikungunya virus', 'Cities', 'Climate', 'Clinical', 'Collection', 'Comparative Study', 'Competence', 'Complex', 'Compost', 'Culicidae', 'Data', 'Decision Making', 'Dengue', 'Dengue Virus', 'Detection', 'Development', 'Discipline', 'Disease', 'Disease Outbreaks', 'Ecology', 'Economics', 'Environment', 'Environmental Health', 'Environmental Impact', 'Epidemic', 'Evaluation', 'Event', 'Eye', 'Food', 'Gases', 'Geography', 'Gravid', 'Growth', 'Habitats', 'Health', 'Health Benefit', 'Household', 'Human', 'Human Bites', 'Image Analysis', 'Imagery', 'Impairment', 'Individual', 'Industry', 'Infrastructure', 'Insecticide Resistance', 'Insecticides', 'Intervention', 'Lasers', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Microclimate', 'Modeling', 'Mosquito Control', 'Mosquito-borne infectious disease', 'Natural Disasters', 'Neighborhoods', 'Neurologic', 'Oils', 'Outcome', 'Pattern', 'Pilot Projects', 'Population', 'Prevention', 'Preventive vaccine', 'Process', 'Protocols documentation', 'Public Health', 'Reaction', 'Recovery', 'Reproducibility', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Security', 'Sentinel', 'Side', 'Site', 'Solid', 'Sorting - Cell Movement', 'Surveillance Methods', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toy', 'United States National Aeronautics and Space Administration', 'Visualization', 'Weather', 'ZIKA', 'Zika Virus', 'atmospheric sciences', 'base', 'chikungunya', 'climate change', 'combat', 'cost', 'cost efficient', 'data standards', 'high risk', 'improved', 'indexing', 'innovation', 'meteorological data', 'metropolitan', 'next generation', 'novel', 'operation', 'pathogen', 'predictive modeling', 'predictive signature', 'preference', 'preservation', 'programs', 'prospective', 'rapid detection', 'remote sensing', 'therapeutically effective', 'tool', 'transmission process', 'vector', 'vector control', 'wasting', 'weather patterns']",NIAID,UNIVERSITY OF SOUTH CAROLINA AT COLUMBIA,R01,2021,782998
"Mayo Clinic Hepatobiliary SPORE Diversity Supplement Dr. Musa Gabere STATEMENT OF CANDIDATE ELIGIBILITY AND DIVERSITY Dr. Musa Gabere is a permanent resident of the United States (Green card number: 063-359-769) of African descent. He completed his undergraduate studies at the University of Nairobi. He then moved to South Africa, where he completed post-graduate diploma, Master of Science and Doctor of Philosophy. Dr. Gabere is interested in applying genetics and bioinformatics approaches to identify common biomarkers that can be used to develop targeted therapies for hepatobiliary cancers. In particular, he will train in understanding the transcriptome changes in hepatocarcinoma treated with immunovirotherapy, a new class of immunotherapeutic. He will be mentored by Dr. Mitesh J. Borad (Primary mentor), Dr. Richard G. Vile (Co- mentor), and Dr. Lewis Roberts (co-mentor) as part of the parent grant 5P50CA210964-03 (P.I. Dr. Richard G. Vile). The overall goal of Dr. Gabere is to pursue research in cancer genetics. Dr. Gabere will participate in various training in Mayo Clinic. These include training in virotherapy, immunotherapy, translational research and ethics. Additionally, there are weekly meetings in cancer, where he can learn and interact with Mayo Clinic Cancer Center senior investigators. In addition, to this, Dr Gabere will have the opportunity to work with large cancer genetics datasets with experts in liver and pancreatic cancer research. These datasets include but not restricted to whole genome, exome, methylome, metabolome and transcriptome for various cancers such as Cholangiocarcinoma. Dr Gabere will also have opportunity to mentor and supervise PhD students and visiting scientists to identify of antigens both in-silico and functional assays. The diversity grant will also allow Dr. Gabere to increase the number of racial and ethnic minorities who participate in biomarker discovery and clinical trials. This will allow Dr Gabere to inform and educate the minorities in the importance of clinical trials and early cancer screening. It is expected that upon receipt of the Diversity Supplement, Dr. Gabere will be able to generate vital data and apply for extramural funding, such as the care award (R21) at the end of his second year. PERSONAL STATEMENT OF THE CANDIDATE Background: Dr. Gabere completed one-year postdoctoral training at Mayo Clinic, Department of Neurology on June 31st, 2020. He was under the umbrella of Dr. Keith Josephs and Dr. Jennifer Whitwell. Prior to his postgraduate studies, Dr. Gabere completed his undergraduate studies in Kenya and graduated with a first- class honor in Mathematics. Subsequently, he was awarded scholarship to pursue a postgraduate diploma in Mathematical sciences at Stellenbosch University in South Africa from 2004-2005. After the postgraduate diploma, he received a full scholarship to pursue a Master of Science in Computational and Applied Mathematics at the University of Witwatersrand from 2005-2007. Finally, he completed his Ph.D. in Bioinformatics under the supervision of the late Prof Vladimir Bajic and Prof Alan Christoffels at the University of Western Cape. His Ph.D. thesis was on prediction of antimicrobial peptides using optimized hyperparameters of the support vector machine. The antimicrobial peptides he predicted showed activities against viral, bacterial and fungi diseases. In particular, he built a webserver for predicting antimicrobial peptides in Glossina Morsitans species. Research on system biology and development of therapies: Dr. Gabere worked on determining the biologically relevant genes that were involved in colorectal cancer by using a feature selection approach based on minimum redundancy maximum relevancy coupled with various machine learning approaches such as support vector machines, artificial neural network, Naïve Bayes and Random Forest. In addition, he worked on understanding system biology vis-à-vis heat stroke. He has also developed therapeutics agents to treat Middle East Respiratory Syndrome using antimicrobial peptides. This work has been patented. Career Goals: In the next two years, Dr. Gabere’s research will focus on understanding the transcriptome changes in Hepatocarcinoma patients undergoing Phase I clinical trials subjected to immunovirotherapy. This is important in identifying biomarkers for prediction of prognosis and response to oncolytic viral therapy and immunotherapy. This will lay the foundation for applying R-series grants to understand the important biomarkers for subsequent clinical trials in relation cancer patients’ treatment. In the long-run, the career goals of Dr. Gabere is to establish an independent research program in the field of personalized medicine in cancer by (1) gaining independence by securing both intramural and extramural funding, (2) publishing high-quality work that contributes to development of personalized medicine (3) expanding collaboration efforts in the field and (4) expanding knowledge base to new and emerging technologies in cancer genetics and bioinformatics analyses. Sincerely, 11/26/2020 Musa Gabere, Ph.D.",Mayo Clinic Hepatobiliary SPORE Diversity Supplement Dr. Musa Gabere,10310895,P50CA210964,"['African', 'Antigens', 'Award', 'Bacterial Infections', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Markers', 'Cancer Patient', 'Caring', 'Cholangiocarcinoma', 'Clinic', 'Clinical Trials', 'Collaborations', 'Colorectal Cancer', 'Coupled', 'Data', 'Data Set', 'Development', 'Doctor of Philosophy', 'Eligibility Determination', 'Emerging Technologies', 'Extramural Activities', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Goals', 'Grant', 'Green Card', 'Heat Stroke', 'Hepatobiliary', 'Immunotherapeutic agent', 'Immunotherapy', 'Kenya', 'Learning', 'Legal patent', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Malignant neoplasm of pancreas', 'Master of Science', 'Mathematics', 'Mayo Clinic Cancer Center', 'Mentors', 'Middle East Respiratory Syndrome', 'Minority', 'Musa plant', 'Mycoses', 'Neurology', 'Patients', 'Phase I Clinical Trials', 'Primary carcinoma of the liver cells', 'Prognosis', 'Publishing', 'Research', 'Research Ethics', 'Research Personnel', 'Scholarship', 'Scientist', 'Screening for cancer', 'Secure', 'Series', 'South Africa', 'Supervision', 'Systems Biology', 'Systems Development', 'Therapeutic Agents', 'Training', 'Translational Research', 'Tsetse Flies', 'United States', 'Universities', 'Virotherapy', 'Virus Diseases', 'Visit', 'Work', 'anticancer research', 'antimicrobial peptide', 'artificial neural network', 'base', 'biomarker discovery', 'cancer genetics', 'career', 'doctoral student', 'ethnic minority population', 'exome', 'feature selection', 'hepatobiliary cancer', 'immunotherapeutic virotherapy', 'in silico', 'interest', 'knowledge base', 'mathematical sciences', 'meetings', 'metabolome', 'methylome', 'new technology', 'oncolytic virotherapy', 'parent grant', 'personalized medicine', 'post-doctoral training', 'programs', 'racial minority', 'random forest', 'response', 'support vector machine', 'targeted treatment', 'therapy development', 'transcriptome', 'undergraduate student', 'whole genome']",NCI,MAYO CLINIC ROCHESTER,P50,2021,136012
"Identification of Microbiome Based Markers to Improve Colorectal Cancer Detection Project Summary One of every 20 Americans develops colorectal cancer (CRC) and, once diagnosed, more than one-third will not survive 5 years. Although screening is available, stool assays such as fecal immunochemical test (FIT) have true positive rates ranging between 64-68% and false positive rate ranging between 5-10%. Moreover, other approaches such as colonoscopy are invasive and expensive and have low rates of patient adherence. There is clearly a need for improved non-invasive methods to screen individuals or subsequent colonoscopy. The current proposal describes using an innovative source of CRC-related biomarkers: the gut microbiome. This collection of bacteria inhabits the gastrointestinal tract and has largely been ignored in previous studies of the etiology and detection of CRC in humans. The long-term goal of this research is to develop biomarkers that improve the detection of CRC and to understand the mechanisms behind the biological changes that increase the risk of developing CRC. The objective of this proposal is to assess the use of microbiome-based fecal biomarkers of CRC. The central hypothesis is that development of colonic adenomas and carcinomas is in part mediated by the gut microbiome and that changes to the microbiome can be used to identify changes in health. Animal studies from have demonstrated that changes in the microbiome can lead to chronic local and systemic inflammation, which promotes the development of CRC. Through a recent collaboration with the University of Michigan members of the Early Detection Research Network Great Lakes New England Clinical Validation Center it was shown that the abundance of bacterial populations within intact feces could significantly improve the ability to detect CRC. The current proposal seeks to demonstrate that combining microbiome-based analyses with standard stool-based analyses will improve CRC detection. Three specific aims are proposed: (i) quantify the sensitivity and specificity of a combined FIT and microbiome model to improve the sensitivity and specificity of detecting SRN, (ii) assess the ability of residual FIT material to serve as a proxy for a whole fecal sample in detecting SRN, and (iii) measure the association between patient characteristics and model performance. The proposed research will yield a significant contribution because for the first time there will be a validated set of biomarkers for CRC that are based on the microbiome that approach the predictive value of colonoscopies for a fraction of the cost. The proposed research is innovative because of its scope, target population and ability to link microbiome composition with a physical sample, access to patient clinical data, and potential opportunities to incorporate data from parallel biomarker validation studies that have used the same samples. Successful completion of these aims will yield a significant translational step in the detection of colonic adenoma with a very real opportunity to develop a robust panel of microbial biomarkers that complement existing technologies. Project Narrative The proposed research is relevant to public health because it will yield a significant translational step in the early detection of colon cancers leading to reduced mortality. We seek to improve detection by developing microbiome-based biomarkers that can be screened using a non-invasive approach. Thus the research is relevant to the part of NCI’s mission to support research into the diagnosis of cancer.",Identification of Microbiome Based Markers to Improve Colorectal Cancer Detection,10082437,R01CA215574,"['Address', 'Adult', 'Age', 'Aliquot', 'American', 'Animals', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Markers', 'Blinded', 'Body mass index', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Collection', 'Colon Carcinoma', 'Colonic Adenoma', 'Colonic Diseases', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Complement', 'DNA', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Detection Research Network', 'Early Diagnosis', 'Early treatment', 'Elements', 'Etiology', 'Feces', 'Gastrointestinal tract structure', 'Gender', 'Genes', 'Genetic Variation', 'Goals', 'Health', 'Hemoglobin', 'Hemoglobin concentration result', 'High grade dysplasia', 'Histopathology', 'Human', 'Human body', 'Individual', 'Intake', 'Large Intestine Carcinoma', 'Lead', 'Lesion', 'Link', 'Machine Learning', 'Mass Screening', 'Materials Testing', 'Measures', 'Meat', 'Mediating', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Neoplasms', 'New England', 'Non-Steroidal Anti-Inflammatory Agents', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Predictive Value', 'Preparation', 'Process', 'Prospective Studies', 'Proxy', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Resected', 'Residual state', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Somatic Cell', 'Source', 'Specificity', 'Target Populations', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Villous', 'Work', 'adenoma', 'base', 'biobank', 'biomarker validation', 'cancer diagnosis', 'cohort', 'colon cancer screening', 'colon carcinogenesis', 'colorectal cancer screening', 'compliance behavior', 'cost', 'density', 'design', 'fecal microbiome', 'gut microbiome', 'gut microbiota', 'improved', 'innovation', 'insight', 'interest', 'member', 'microbial', 'microbiome', 'microbiome composition', 'microbiota', 'mortality', 'patient subsets', 'predictive modeling', 'rRNA Genes', 'random forest', 'screening', 'stool sample', 'systemic inflammatory response', 'validation studies']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,319318
"Deep learning based antibody design using high-throughput affinity testing of synthetic sequences Project Summary We will develop and apply a new high-throughput methodology for rapidly designing and testing antibodies for a myriad of purposes, including cancer and infectious disease immunotherapeutics. We will improve upon current approaches for antibody design by providing time, cost, and humane benefits over immunized animal methods and greatly improving the power of present synthetic methods that use randomized designs. To accomplish this, we will display millions of computationally designed antibody sequences using recently available technology, test the displayed antibodies in a high-throughput format at low cost, and use the resulting test data to train molecular dynamics and machine learning methods to generate new sequences for testing. Based on our test data our computational method will identify sequences that have ideal properties for target binding and therapeutic efficacy. We will accomplish these goals with three specific aims. We will develop a new approach to integrated molecular dynamics and machine learning using control targets and known receptor sequences to refine our methods for receptor generalization and model updating from observed data (Aim 1). We will design an iterative framework intended to enable identification of highly effective antibodies within a minimal number of experiments, in which our methods automatically propose promising antibody sequences to profile in subsequent assays (Aim 2). We will employ rounds of automated synthetic design, affinity test, and model improvement to produce highly target-specific antibodies. (Aim 3). ! Project Narrative We will develop new computational methods that learn from millions of examples to design antibodies that can be used to help cure a wide variety of human diseases such as cancer and viral infection. Previous antibody design approaches used a trial and error approach to find antibodies that worked well. In contrast our mathematical methods will directly produce new antibody designs by learning from large-scale experiments that test antibodies for function against disease targets. !",Deep learning based antibody design using high-throughput affinity testing of synthetic sequences,10116306,R01CA218094,"['Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Binding', 'Biological Assay', 'Budgets', 'Classification', 'Cloud Computing', 'Communicable Diseases', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Fc Receptor', 'Goals', 'Human', 'Immunize', 'Immunotherapeutic agent', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modeling', 'Molecular Machines', 'Oligonucleotides', 'Output', 'Performance', 'Phage Display', 'Property', 'Randomized', 'Research', 'Services', 'Specific qualifier value', 'Specificity', 'Statistical Models', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Thinness', 'Time', 'Training', 'Treatment Efficacy', 'Update', 'Virus Diseases', 'Work', 'antibody test', 'base', 'cloud based', 'commercialization', 'computing resources', 'cost', 'deep learning', 'design', 'experimental study', 'human disease', 'improved', 'iterative design', 'learning strategy', 'machine learning method', 'mathematical methods', 'molecular dynamics', 'novel', 'novel strategies', 'outcome prediction', 'predictive test', 'receptor']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,591130
"Endogenous fluorescence lifetime endoscopy for early detection of oral cancer and dysplasia The American Cancer Society estimates that 48,330 new cases of cancer in the oral cavity and pharynx will be reported this year. When diagnosed at early stages, the 5-year survival rate is 83%. However, when diagnosed at intermediate or advance stages, the 5-year survival rate drops to 62% and 38%, respectively. In addition, while early stage treatment may only require minor surgery to remove the localized tumor, later stage treatment could require surgical removal of parts of the face and neck, hence drastically reducing the patient’s quality of life. Unfortunately, benign oral lesions are sometimes difficult to distinguish from dysplasia or early invasive cancer even for healthcare professionals. As a result, only 31% of patients are diagnosed at early stages despite the fact that the oral cavity is easily accessible for direct examination. Hence, there is a critical need for new clinical technologies for reliable early diagnosis of oral cancer and dysplasia. Several screening tools for oral cancer have been commercially available, including exfoliative cytology, vital staining, salivary test, and optical interrogation; however, none of them have been demonstrated to be capable of clinically relevant sensitivity and specificity. We hypothesize that several biomarkers for oral cancer and dysplasia can be accurately quantified by endogenous fluorescence lifetime imaging (FLIM) thus enabling levels of sensitivity and specificity adequate for early detection. This bioengineering research grant focuses on developing and validating a cost-effective wide-field multispectral FLIM endoscope for noninvasive in situ detection of oral cancer and dysplasia. To that end we have developed three specific aims. Aim 1: To design and build a cost-effective multispectral FLIM endoscope for in vivo imaging of epithelial tissue in the oral cavity. Aim 2: To develop algorithms for fast and automated FLIM based early detection of oral epithelial cancer and dysplasia. Aim 3: To quantify prospectively in a pilot clinical study the capability of the proposed FLIM endoscopic tools for noninvasively early detection of oral epithelial cancer and dysplasia. The successful completion of these aims will result in a novel, accurate and cost-effective clinical tool for noninvasive in situ early detection of cancer and dysplasia. Such a tool could potentially help to improve significantly both the life expectancy and the quality of life for the more than 33,000 oral cancer patients being diagnosed each year at intermediate and advance stages. Beyond early diagnosis, this tool could also assist at every step involved on the clinical management of oral cancer patients, including treatment guidance and monitoring of disease recurrence. Finally, the demonstrated success of this clinical tool in oral epithelial cancer will herald future success with other cancers of epithelial origin, which accounts for more than 80% of all cancers. Early detection of both new and recurrent oral cancer holds great promise for improving both the survival rate and the quality of live of these patients. The proposed work is to develop a clinical tool capable of quantifying noninvasively different biomarkers associated to oral epithelial cancer progression and detecting early stage oral cancer and dysplasia. Such tool will revolutionize oral epithelial cancer management by allowing not only early screening and diagnosis, but also treatment guidance and monitoring for disease recurrence.",Endogenous fluorescence lifetime endoscopy for early detection of oral cancer and dysplasia,10245057,R01CA218739,"['Adopted', 'Algorithms', 'American Cancer Society', 'Benign', 'Biological Markers', 'Biomedical Engineering', 'Biopsy', 'Blinded', 'Cancer Patient', 'Carcinoma', 'Characteristics', 'Chicago', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Coenzymes', 'Collagen', 'Data', 'Databases', 'Dentists', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Drops', 'Dysplasia', 'Early Diagnosis', 'Endoscopes', 'Endoscopy', 'Epithelial', 'Evaluation', 'Excision', 'Face', 'Fluorescence', 'Frequencies', 'Future', 'Geometry', 'Goals', 'Gold', 'Health Professional', 'Histopathology', 'Image', 'Imaging Device', 'In Situ', 'Intraepithelial Neoplasia', 'Lesion', 'Life Expectancy', 'Malignant Epithelial Cell', 'Malignant Neoplasms', 'Metabolic', 'Metabolism', 'Mild Dysplasia', 'Minor Surgical Procedures', 'Mitochondria', 'Modality', 'Monitor', 'Monitoring for Recurrence', 'Neck', 'Operative Surgical Procedures', 'Optics', 'Oral', 'Oral Stage', 'Oral cavity', 'Pathologic', 'Patient Recruitments', 'Patients', 'Pharyngeal structure', 'Pilot Projects', 'Predictive Value', 'Quality of life', 'Recurrence', 'Reporting', 'Research Personnel', 'Research Project Grants', 'Screening for Oral Cancer', 'Screening for cancer', 'Screening procedure', 'Sensitivity and Specificity', 'Specificity', 'Speed', 'Stains', 'Survival Rate', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Work', 'automated algorithm', 'base', 'cancer invasiveness', 'clinically relevant', 'computerized tools', 'cost', 'cost effective', 'design', 'early screening', 'exfoliative cytology', 'experience', 'fluorescence lifetime imaging', 'image processing', 'imaging biomarker', 'improved', 'in vivo', 'in vivo imaging', 'machine learning algorithm', 'malignant mouth neoplasm', 'noninvasive diagnosis', 'novel', 'optical imaging', 'oral cavity epithelium', 'oral dysplasia', 'oral lesion', 'precision medicine', 'prospective', 'salivary assay', 'success', 'tool', 'tumor', 'tumor progression', 'volunteer']",NCI,UNIVERSITY OF OKLAHOMA NORMAN,R01,2021,304459
"Methods and Tools for Integrating Pathomics Data into Cancer Registries The goal of this project is to enrich SEER registry data with high‐quality population‐based biospecimen data in the form of digital pathology, machine learning based classifications and quantitative pathomics feature sets. We will create a well‐curated repository of high‐quality digitized pathology images for subjects whose data is being collected by the registries. These images will be processed to extract computational features and establish deep linkages with registry data, thus enabling the creation of information‐rich, population cohorts containing objective imaging and clinical attributes. Specific examples of digital Pathology derived feature sets include quantification of tumor infiltrating lymphocytes and segmentation and characterization of cancer or stromal nuclei. Features will also include spectral and spatial signatures of the underlying pathology. The scientific premise for this approach stems from increasing evidence that information extracted from digitized pathology images (pathomic features) are a quantitative surrogate of what is described in a pathology report. The important distinction being that these features are quantitative and reproducible, unlike human observations that are highly qualitative and subject to a high degree of inter‐ and intra‐observer variability. This dataset will provide, a unique, population‐wide tissue based view of cancer, and dramatically accelerate our understanding of the stages of disease progression, cancer outcomes, and predict and assess therapeutic effectiveness.  This work will be carried out in collaboration with three SEER registries. We will partner with The New Jersey State Cancer Registry during the development phase of the project (UG3). During the validation phase of the project (UH3), the Georgia and Kentucky State Cancer Registries will join the project. The infrastructure will be developed in close collaboration with SEER registries to ensure consistency with registry processes, scalability and ability support creation of population cohorts that span multiple registries. We will deploy visual analytic tools to facilitate the creation of population cohorts for epidemiological studies, tools to support visualization of feature clusters and related whole‐slide images while providing advanced algorithms for conducting content based image retrieval. The scientific validation of the proposed environment will be undertaken through three studies in Prostate Cancer, Lymphoma and NSCLC, led by investigators at the three sites. The goal of this project is to enrich SEER cancer registry data with high‐quality population‐based information arising from digitized Pathology slides. Data extracted directly from digitized pathology images (Pathomics data) promise to provide information not consistently available from Pathology reports. This dataset will provide, a unique, population‐wide tissue based view of cancer, and dramatically accelerate our understanding of the stages of disease progression, cancer outcomes, and predict and assess therapeutic effectiveness. The scientific validation of the proposed environment will be undertaken through three studies in Prostate Cancer, Lymphoma and NSCLC, led by investigators at the three sites.",Methods and Tools for Integrating Pathomics Data into Cancer Registries,10247096,UH3CA225021,"['Advanced Development', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Area', 'Automobile Driving', 'Biological Assay', 'Biological Markers', 'Cell Nucleus', 'Classification', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Collaborations', 'Communities', 'Cues', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease Progression', 'Ensure', 'Environment', 'Evaluation Studies', 'Exhibits', 'Eye', 'Goals', 'Histopathology', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Intraobserver Variability', 'Investigation', 'Kentucky', 'Link', 'Lymphoma', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Methodology', 'Methods', 'Modernization', 'Morphology', 'New Jersey', 'Non-Small-Cell Lung Carcinoma', 'Nuclear', 'Outcome', 'Pathology', 'Pathology Report', 'Patients', 'Perception', 'Phase', 'Phenotype', 'Population', 'Process', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Retrieval', 'Science', 'Scientific Evaluation', 'Site', 'Slide', 'Specimen', 'Testing', 'Texture', 'Tissues', 'Transcend', 'Tumor Subtype', 'Tumor-Infiltrating Lymphocytes', 'Universities', 'Validation', 'Visual', 'Visualization', 'Work', 'analytical tool', 'base', 'cohort', 'computer infrastructure', 'computing resources', 'data management', 'data registry', 'digital pathology', 'epidemiology study', 'feature extraction', 'image archival system', 'image visualization', 'improved', 'informatics infrastructure', 'interest', 'neoplasm registry', 'pathology imaging', 'patient population', 'patient stratification', 'population based', 'precision medicine', 'prognostic', 'prototype', 'repository', 'response', 'scale up', 'stem', 'therapeutic effectiveness', 'tool', 'tumor', 'tumor registry', 'validation studies', 'whole slide imaging']",NCI,STATE UNIVERSITY NEW YORK STONY BROOK,UH3,2021,620871
"SCH: Active Learning for Medical Applications Cancer is considered one of the most dilapidating health problems that the world is facing due to its physical, emotional, financial, and spiritual toll. Automating cancer diagnosis can ultimately impact its treatment and recovery. Computational algorithmic methods can greatly improve the efficiency of pathologists through partial or complete automation of the diagnostic process. Computer-aided diagnosis has augmented preventive check-ups for many medical conditions like breast cancer, colonic polyps, and lung cancer. Digitization of tissue slides has thus opened up the process of diagnosis through analysis of digital images. The dearth of highly trained pathologists who can address the growing diagnostic needs heightens the importance of such automation. Recent advances in big data analytics and in particular machine learning can possibly impact greatly the domain of computer-aided cancer diagnosis. Convolutional Neural Networks (CNNs) in particular have already revolutionized the domain of computer vision with performances in various cases compared to that exhibited by humans. One of the main factors that fueled the recent resurgence of CNNs is the availability of large datasets. CNNs adjust, via training, millions of parameters allowing them to learn complex and highly nonlinear dependencies among data (i.e., images). However, collecting such large amounts of annotated data (assigning them to one of many possible categories, e.g., benign vs. cancerous vs. other stages) is either challenging or very expensive or in many cases unavailable. This is definitely the case of the medical domain. Tissue slides from suspected cancerous regions are examined under a microscope and are classified as benign or malignant. CNNs offer a promising pathway to achieve some degree of automation in identifying cancerous cases in image data. This research work will explore the challenges· of discovering the underlying discriminative features, hidden in the image and possibly different than those used by human experts, in order to improve the accuracy of diagnosis. We will also focus on algorithms to minimize the amount of data required to train the neural network without sacrificing performance and generalization. Cancer has been a major health concern and one of the leading causes of death in the US and around the world. Automating cancer diagnosis can impact cancer staging and ultimately its treatment, effectively leading to higher survival rates. This proposal' promises the creation of computational algorithmic methods that can lead to partial or complete automation of the cancer diagnostic process.",SCH: Active Learning for Medical Applications,10086856,R01CA225435,"['Active Learning', 'Address', 'Algorithms', 'Attention', 'Automation', 'Benchmarking', 'Benign', 'Big Data Methods', 'Breast', 'Cancer Diagnostics', 'Cancerous', 'Categories', 'Cause of Death', 'Clinics and Hospitals', 'Collaborations', 'Colonic Polyps', 'Communities', 'Complex', 'Computational algorithm', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Discovery', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Early Diagnosis', 'Educational Curriculum', 'Educational workshop', 'Emotional', 'Engineering', 'Exhibits', 'Health', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Information Retrieval', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Microscope', 'Middle School Student', 'Modality', 'Pathologist', 'Pathway interactions', 'Pattern', 'Performance', 'Preventive', 'Process', 'Prostate', 'Recovery', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Security', 'Slide', 'Survival Rate', 'System', 'Testing', 'Tissues', 'Training', 'Transportation', 'Underrepresented Populations', 'Variant', 'Visual Manifestations', 'Work', 'X-Ray Computed Tomography', 'algorithmic methodologies', 'cancer diagnosis', 'cancer type', 'cohesion', 'convolutional neural network', 'data exploration', 'diagnostic accuracy', 'digital imaging', 'hands-on learning', 'histological slides', 'image processing', 'improved', 'interest', 'kidney imaging', 'large datasets', 'learning community', 'learning strategy', 'machine learning method', 'malignant breast neoplasm', 'neural network', 'object recognition', 'online repository', 'outreach', 'outreach program', 'phenomenological models', 'programs', 'repository', 'self-directed learning', 'stem', 'tool', 'user-friendly', 'web page', 'wiki']",NCI,UNIVERSITY OF MINNESOTA,R01,2021,309176
"PRedictiOn Algorithms for the DeTECTion of Early Stage Pancreatic Cancer (PRO-TECT) Project Title: PRedictiOn algorithms for the deTECTion of early stage pancreatic cancer (PRO-TECT) Project Summary Pancreatic cancer is the fourth leading cause of cancer death in the United States. A major reason for the lethal nature of this disease is the lack of effective strategies for early detection. As a result, the vast majority of cancers are detected at a very late stage. The delay in diagnosis and treatment of pancreatic cancer could be due to many reasons including, 1) lack of a clear quantitative or algorithm-based definition of a high-risk population who would benefit from active surveillance, 2) suboptimal use of image findings that could potentially foretell a growing tumor, 3) system or referral-related delay from time of abnormal finding to diagnosis and treatment. Methods to accelerate the detection of pancreatic cancer leading to increased proportion of early stage tumors at the time of diagnosis have the potential to have an immediate impact on survival. The objective of the proposed work is to establish a platform for development and implementation of a data-driven approach for detection of early stage pancreatic cancer within an integrated care setting. Specifically, the proposed work will focus on development of empiric algorithms for prediction of early stage pancreatic cancer as well as systematic pancreatic cancer-risk stratification of patients based on natural language processing-aided extraction of pancreatic features from existing pre-diagnostic imaging reports to enhance understanding of the natural history of disease progression. Finally, we will conduct a prospective cohort study to assess the accuracy of an algorithm-based approach for detection of early stage pancreatic cancer. Project Narrative Pancreatic cancer is most often diagnosed in a late, incurable stage. Population-based screening is not effective based on the relatively low incidence of this disease. The current study seeks to develop and apply an alternative approach to enhance our ability to identify patients with early stage pancreatic cancer through use of an electronic ‘trigger’ system based on information gathered from large electronic health systems.",PRedictiOn Algorithms for the DeTECTion of Early Stage Pancreatic Cancer (PRO-TECT),10201527,R01CA230442,"['Algorithms', 'Biological Markers', 'California', 'Cancer Etiology', 'Caring', 'Cessation of life', 'Clinical', 'Collection', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Future', 'Health Information System', 'Health system', 'Image', 'Incidence', 'Information Systems', 'Laboratory Study', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Nested Case-Control Study', 'Pancreas', 'Participant', 'Patient Outcomes Assessments', 'Patients', 'Pharmaceutical Preparations', 'Process', 'Prospective cohort', 'Prospective cohort study', 'Reporting', 'Research Design', 'Risk', 'Staging', 'Surveys', 'Symptoms', 'System', 'Testing', 'Text', 'Time', 'Tumor stage', 'United States', 'United States National Institutes of Health', 'Veterans Health Administration', 'Work', 'X-Ray Computed Tomography', 'base', 'comorbidity', 'demographics', 'detection platform', 'disease natural history', 'electronic data', 'gastrointestinal', 'high risk population', 'patient stratification', 'population based', 'prediction algorithm', 'predictive modeling', 'recruit', 'repository', 'risk stratification', 'screening', 'tumor']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2021,816240
"A Federated Galaxy for user-friendly large-scale cancer genomics research Project Summary Cancer research is now a data-driven discipline, but only a minority of cancer researchers are data scientists. This severely restricts our ability to effectively study and cure the disease. The far reaching significance of our project is in federating disparate data and computational resources in order to provide a unifying analysis platform for computational cancer research.  We will extend the popular scientific workbench Galaxy (https://galaxyproject.org) so that it can integrate with distributed data and compute resources used and needed by cancer researchers, including those resources in the NCI Cancer Research Data Commons (NCR DC). Our Federated Galaxy system will allow users to seamlessly access NCR DC data across multiple resources. It will support multiple analysis scenarios tuned to skills and computational requirements of individual researchers.  The aims of this project are: Aim 1. Extend Galaxy for working with distributed cancer genomics and phenotypic data. This will enable Galaxy users to access both public and private cancer data regardless of their actual physical location. Best-practice approaches will be used for accessing restricted datasets.  Aim 2. Enhance Galaxy for context-aware, distributed cancer genomics analyses using shared workflow representations. This will enable Galaxy users to run genomics analyses on different clouds, ultimately reducing the time, cost, and data transfer associated with analyses.  Aim 3. Apply Federated Galaxy to precision oncology research. Workflows developed in this aim will leverage the technologies in Aims 1 and 2 to benchmark machine learning algorithms for predicting tumor phenotype and drug response. Interactive reports will summarize benchmarking results and utilize ITCR visualizations for deep dives into results.  Our system will provide a singular access point to distributed cancer datasets and will enable these data to be analyzed within a single portal in a way that satisfies multiple analysis scenarios and utilizes diverse computational resources. Finally, a cloud-centric Galaxy built for the NCR DC will substantially grow the community of users working with the GDC and the NCR DC. This is because Galaxy brings with itself a vibrant world-wide community of users and developers, which numbers tens of thousands of scientists. These individuals will help to tune the GDC and other resources within the NCR DC to the needs of real-life analysis scenarios and will enrich the set of tools accessible to cancer researchers. Project Narrative This project will develop a user-friendly scientific analysis workbench for analyzing cancer genomics data on the NCI Cancer Research Data Commons cloud platform. The workbench will democratize access to cloud-based cancer genomic analyses. It will also aid in precision cancer medicine by benchmarking and identifying the most accurate analytic methods for classifying tumors and predicting drug response.",A Federated Galaxy for user-friendly large-scale cancer genomics research,10245142,U24CA231877,"['Awareness', 'Benchmarking', 'Centers for Disease Control and Prevention (U.S.)', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Analyses', 'Data Analytics', 'Data Commons', 'Data Scientist', 'Data Set', 'Data Sources', 'Data Store', 'Development', 'Discipline', 'Disease', 'Galaxy', 'Genomic Data Commons', 'Genomics', 'Health', 'Health Sciences', 'Individual', 'Informatics', 'Infrastructure', 'Internet', 'Knowledge', 'Language', 'Lead', 'Life', 'Location', 'Malignant Neoplasms', 'Maps', 'Metadata', 'Minority', 'Names', 'Online Systems', 'Oregon', 'Output', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Privatization', 'Proteomics', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Scientist', 'Services', 'Standardization', 'System', 'Technology', 'Time', 'Universities', 'Variant', 'Visualization', 'Work', 'analytical method', 'anticancer research', 'cancer genomics', 'cancer health disparity', 'cloud based', 'cloud platform', 'computational platform', 'computing resources', 'cost', 'data exchange', 'data resource', 'data standards', 'design', 'distributed data', 'drug response prediction', 'empowered', 'flexibility', 'genomic data', 'genomics cloud', 'machine learning algorithm', 'machine learning method', 'multiple omics', 'next generation', 'phenotypic data', 'precision oncology', 'prediction algorithm', 'response', 'skills', 'tool', 'transcriptome sequencing', 'tumor', 'user-friendly', 'web interface']",NCI,OREGON HEALTH & SCIENCE UNIVERSITY,U24,2021,762330
"Extension to the HTAN Pre-Cancer Atlas Project For many cancer types, the wide-spread adoption of cancer screening has increased the detection of pre-malignant lesions (PML). Despite such efforts, screening has had limited impact on overall survival. Clinical guidelines vary widely from watchful waiting (e.g., prostate) to radical surgery and adjuvant treatment (e.g., breast). In absence of reliable progression risk biomarkers and models, these interventions may have deleterious consequences at the two clinical extremes: delay in life-saving treatment or overtreatment. The study of pre-malignant lesions (PML) at molecular level present significant challenges: PML are small, generally archived in formalin. Moreover, the clinical significance of any identified marker can only be assessed after long follow- up, limiting the translational studies to retrospective collections. These hurdles have prevented the development and application of precision medicine approaches and unbiased biomarker to develop models of progression. The current proposal will extend the MCL Pre-Cancer Atlas Pilot Project (PCAPP initiated in September 2017) with the goal to build multi-modal profiles of highly characterized pre-malignant lesions from the 4 target organs (Lung, Breast, Prostate and Pancreas). The four organs included represent a diverse spectrum of histology - pure histology or mixed with invasive lesions - and clinical settings - treatment or active surveillance. Similarly, the selected profiling methods are as comprehensiveas for invasive tumors atlas (whole transcriptome gene expression or DNA mutations) but also innovative, focusing on micro- environment and exploring spatial heterogeneity (multiplex IHC) and, for a few cases, cellular heterogeneity (single-nuclei sequencing). The propose extension will support the completion of the PCAPP and enable a uniform data analysis and sharing with the community. UCSD Statement of Work The following resources or laboratories will be involved in the work specified in this subcontract. The Oncogenomics Laboratory at Moores Cancer Center: Lead by Dr Harismendy, the Oncogenomics laboratory is located in the Moores Cancer center. Dr Harismendy has established his laboratory to be able to develop molecular assays, sequence in high throughput at the UCSD-IGM core facility and analyzed the results on a compute-cloud compliant with HIPAA regulation. The laboratory includes 1 senior research associate, 3 computational biology students and one programmer. It further contracts with systems and databases administrators located in the division of biomedical informatics or at the San Diego Super Computer Center. The IGM Genomics Center at UCSD: The UCSD IGM Genomics Center offers full services in high throughput sequencing as well as whole-genome genotyping and copy number variation analysis. The IGM Genomics Center offers assay design consultation, sequencing library preparation (DNA/RNA/smallRNA/targeted sequencing), single cell RNA sequencing (10X Genomics), lllumina platform sequencing (MiSeq, HiSeq2500, HiSeq4000 and NovaSeq 6000), and Illumina genotyping and methylation arrays. The UC Davis Center for Genomic Pathology Laboratory provides expert histology and pathology services on a recharge basis. We provide tissue processing/sectioning, routine and special tissue staining, immunohistochemistry, whole slide scanning, database hosting, help with quantitative image analysis and pathology consulting services. Proposed Work: For the budget period we will perform the following work a. PCAPP project management x Continue to organize PCAPP monthly calls: Until December 2020, these calls will be used to keep track on  progress. The goal will be to ensure that data is being generated and shared and to address any logistical  or technical question that may delay progress. In 2021, the focus of the calls will be slowly transitioning to  discuss standardized analysis and present preliminary analysis across teams and organs. x Continue to attend and collaborate with the Human Tumor Atlas Network (HTAN). In particular identify  immediate opportunities for collaboration and data sharing. x Complete the data sharing via JPL LabCAS and dbGaP. Data standardization, upload and registration is a  complex process and every member will need to be assisted to accomplish these goals. b. PCAPP data generation and analysis support x The UCSD IGM genomic center will be contracted to perfrom Exome library preparation and sequencing of  any supplemental DNA samples that need additional coverage or replication x The UCSD team will offer to assist PCAPP teams to analyze and QC their raw data. They will determine  whether the JPL cloud can be used to scale up this analysis and will provide forums and discussion board  for data generator and analyst to discuss the results and suggest novel iterations. x The UC Davis histology core facility will be contracted to perform high resolution scanning, cell counting  and analysis of the multiplex immuno-histochemistry data from the other PCAPP teams. c. Pan-PCAPP analysis, data enrichment and integration Unified data processing: The raw sequencing data (RNA and DNA) from all PCAPP teams will be re-processed at once to generate a uniform call of gene expression, mutations and copy number aberrations. Similarly, the multiplex IHC primary analysis results will be aggregated and processed at once to ensure that no team or organ specific technical differences occurs. The results of the Pan-PCAPP unified analysis will be made available in dbGaP through a new version of the data. Pan-expression analysis: Mitotic grade, immune-infiltration, presence of necrosis, or lesion morphology (papillary, cribriform, tubular, solid) may reveal commonalities across organs. Each component, or expression state, driving these differences will be annotated via gene set enrichment analysis to understand which biological signal and processes may be responsible Pan-mutational analysis: from a set of known driver genes in cancer we will build the oncomap of driver events (mutations or copy number gains and losses), annotate them for their known, likely or unknown pathogenic consequences and determine how their prevalence differs from the drivers identified in more advanced tumors. Pan-spatial immune analysis; across all PML and organs we will determine the relative number of each cell types in the stroma, defining hot, warm and cold immune states and determine their association with expression states or mutational status, after correcting for organ type. We will contract with Dr. Cambell (UCSF) to calculate the EcoScore for each PML, which will summarize a more context depend micro- environmental status, accounting for the clustering and distance between cells. We will determine whether the EcoScore is associated with specific histological features or epithelial expression states, independently of the overall immune-infiltration. Mutational burden and signature analysis: The mutational load (substitution and copy number) will be calculated for all PMLs and tested for association with expression state and histology features. Similarly for PML with sufficient number of mutations, we will determine the contribution of each of the COSMIC mutational signatures [4] to the mutational load and determine whether the presence of any signature is associated with expression state, histology features, or stromal-immune states. Stromal-Epithelial interactions: we will perform an unsupervised integration of the data to investigate stromal vs epithelial interaction. We will first select and abstract multiple epithelial features derived for RNA and DNA analysis above, such as proliferation, burden, presence of key mutational signature, organ-independent expression state (NMF cluster membership), common mutation drivers. We will then use random forest regression with 5 fold-cross validation to determine which features associate with specific stromal immune features derived from the mIHC experiments: hot / cold stroma, immuno-suppressive, proliferative T-cells, EcoScore, etc.",Extension to the HTAN Pre-Cancer Atlas Project,10269615,U2CCA233254,"['Accounting', 'Address', 'Adjuvant', 'Administrator', 'Adoption', 'Archives', 'Atlases', 'Automobile Driving', 'Biological', 'Biological Assay', 'Biological Markers', 'Breast', 'Budgets', 'Cancer Center', 'Cell Count', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computational Biology', 'Consult', 'Consultations', 'Contracts', 'Copy Number Polymorphism', 'Core Facility', 'DNA', 'DNA Sequence Alteration', 'DNA analysis', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Ensure', 'Epithelial', 'Epithelial-Stromal Communication', 'Event', 'Formalin', 'Gene Expression', 'Gene set enrichment analysis', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Guidelines', 'Health Insurance Portability and Accountability Act', 'Heterogeneity', 'High-Throughput Nucleotide Sequencing', 'Histologic', 'Histology', 'Human', 'Image Analysis', 'Immune', 'Immunohistochemistry', 'Intervention', 'Invasive Lesion', 'Laboratories', 'Lead', 'Lesion', 'Lesion by Morphology', 'Libraries', 'Life', 'Logistics', 'Lung', 'Malignant Neoplasms', 'Methods', 'Methylation', 'Mitotic', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Necrosis', 'Operative Surgical Procedures', 'Organ', 'Pancreas', 'Papillary', 'Pathogenicity', 'Pathology', 'Patient observation', 'Pilot Projects', 'Postdoctoral Fellow', 'Preparation', 'Prevalence', 'Process', 'Prostate', 'RNA', 'RNA analysis', 'Regulation', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Savings', 'Scanning', 'Screening for cancer', 'Services', 'Signal Transduction', 'Slide', 'Solid', 'Specific qualifier value', 'Standardization', 'Students', 'System', 'T-Cell Proliferation', 'Testing', 'Tissue Stains', 'Tubular formation', 'Tumor-infiltrating immune cells', 'Validation', 'Work', 'biomedical informatics', 'cancer genomics', 'cancer type', 'cell type', 'clinically significant', 'computer center', 'computerized data processing', 'data integration', 'data sharing', 'data standards', 'database of Genotypes and Phenotypes', 'design', 'driver mutation', 'exome', 'experimental study', 'follow-up', 'innovation', 'member', 'multimodality', 'mutational status', 'novel', 'overtreatment', 'precision medicine', 'premalignant', 'prevent', 'quantitative imaging', 'random forest', 'scale up', 'screening', 'sequencing platform', 'single-cell RNA sequencing', 'targeted sequencing', 'tissue processing', 'transcriptome', 'translational study', 'tumor', 'whole genome']",NCI,DUKE UNIVERSITY,U2C,2021,304550
"Addressing Sparsity in Metabolomics Data Analysis Comprehensive profiling of the small molecule repertoire in a sample is referred to as metabolomics and it is being used to address a variety of scientific questions in biomedical studies. Recent technological advances in mass spectrometry-based metabolomics have allowed for more comprehensive and sensitive measurements of metabolites. Despite the technological advances, the bottleneck for taking full advantage of metabolomics data is often the availability and usability of analysis tools. The goal of the parent award (U01CA235488) is to develop novel statistical methods and software for the research community to improve the utilization of metabolomics data, which will help maximize the potential of metabolomics to provide new discoveries in disease etiology, diagnosis, and drug development. Software tools specifically designed for metabolomics data, like those proposed in the parent U01 award and attendant RFA (NIH RFA-RM-17-012), are being developed at an increasing rate. Many of these tools are open-source and freely available, but they are very diverse with respect to programming language, data formats, and stage in the metabolomics pipeline. Several of the challenges recognized in the NIH Common Fund Metabolomics Program are to “meet increasing demand for user-friendly, open-source, bioinformatics tools for data analysis and interpretation” and “coordinate community-wide identification and adoption of best practices for rigor, reproducibility and data reuse.” To mitigate these challenges and further the consortium’s goals, we have built the MSCAT database (https://mscat.metabolomicsworkbench.org) of metabolomics software tools that can be sustainably and continually updated (U01CA235488-02S1). The database provides a survey of the landscape of available tools and can assist researchers in the selection of data analysis workflows according to their specific needs. This supplement proposal aims to extend this database project by further mining the literature to characterize tool interoperability as outlined by their use in metabolomics studies and by analyzing the collected data about software tools to extract factors contributing to tool adoption, usability, and utility. In Aim 1, we will develop a text-mining process where the full text and co-citations of metabolomics studies are mined to identify which combinations of tools were used in past studies to validate the set of tools suggested by our database. In Aim 2, we assess the metabolomics software landscape for tool redundancy (based on functionality) and correlate software characteristics with tool adoption and interoperability. Specialized software tools has been developed to analyze the metabolome, which is the comprehensive repertoire of small molecules. However, there are many tools making it difficult for investigators to make decisions on best practices for their analysis. In this supplement, we plan to extend the functionality of our metabolomics tools database to better determine the interoperability between software tools so that users can select analysis workflows, and to better identify the factors that contribute to successful software adoption.",Addressing Sparsity in Metabolomics Data Analysis,10396831,U01CA235488,"['Address', 'Adoption', 'Area', 'Award', 'Bibliometrics', 'Biological', 'Characteristics', 'Classification', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Decision Making', 'Dependence', 'Diagnosis', 'Disease', 'Etiology', 'Feedback', 'Funding', 'Goals', 'Guidelines', 'Individual', 'Literature', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic Pathway', 'Methods', 'Multivariate Analysis', 'Natural Language Processing', 'Operating System', 'Parents', 'Pathway Analysis', 'Procedures', 'Process', 'Programming Languages', 'Recommendation', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Sampling', 'Scanning', 'Science', 'Semantics', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Statistical Methods', 'Suggestion', 'Surveys', 'Testing', 'Text', 'United States National Institutes of Health', 'Update', 'analysis pipeline', 'analytical tool', 'base', 'bioinformatics tool', 'data analysis pipeline', 'data format', 'data reuse', 'design', 'drug development', 'expiration', 'file format', 'improved', 'innovation', 'interoperability', 'member', 'metabolome', 'metabolomics', 'novel', 'open source', 'open source tool', 'programs', 'small molecule', 'software development', 'syntax', 'text searching', 'tool', 'tool development', 'usability', 'user-friendly', 'working group']",NCI,UNIVERSITY OF COLORADO DENVER,U01,2021,96362
"Reactome IDG portal: Pathway-based analysis and visualization of understudied human proteins Project Summary Proteins function through interactions with other proteins and biological entities to form biological pathways inside and between cells. Targeted therapies are designed to mitigate or reverse malfunctions caused by mutations in proteins via providing drugs to recover normal biological pathways’ activities. Projecting understudied proteins in the context of biological pathways is a powerful way to infer potential functions of these proteins. Pathway-based approaches are now routinely applied in bioinformatics and computational biology data analysis and visualization. Pathway databases are essential for those approaches. During the past two decades, our team has been working together on building the Reactome knowledgebase, arguably the most popular and comprehensive open source biological pathway database, covering over half of human protein-coding genes and widely used in the research community. In this application, we propose to develop a Reactome IDG pathway portal, which will allow localization of understudied proteins in biological pathways, identifying likely interactions with better-known proteins in specific processes annotated in Reactome, pinpointing most effective drug targets via pathway modeling, thus generating testable predictions of molecular functions of these proteins in key domains of biology. Specially we will develop a web-based application to place understudied proteins in the context of Reactome pathways by importing a variety of data types collected in the IDG projects and other resources and then overlaying them onto the Reactome pathways by leveraging existing Reactome software tools (e.g. interaction overlay). Furthermore, we will develop a machine learning approach to predict functional interactions between understudied proteins and well-known Reactome annotated proteins and a Boolean network-based fuzzy logic modeling approach to integrate the scores produced from the machine learning approach to simulate the impacts of understudied proteins on pathways’ activities. We believe our approach will provide a unique and powerful approach to help the community to understand the contribution of the understudied proteins to cellular functions. Project Narrative Projecting understudied proteins in the context of biological pathways provides a framework to understand potential functions of these proteins. Reactome is the most comprehensive open source biological pathway knowledgebase. We propose to develop a Reactome IDG portal for understudied proteins, assisting researchers to infer biological functions of understudied proteins.",Reactome IDG portal: Pathway-based analysis and visualization of understudied human proteins,10348828,U01CA239069,"['Animal Model', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell physiology', 'Cells', 'Code', 'Communities', 'Computational Biology', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Fuzzy Logic', 'Genes', 'Grant', 'Human', 'Infectious Agent', 'Level of Evidence', 'Machine Learning', 'Modeling', 'Molecular', 'Mutation', 'Network-based', 'Online Systems', 'Pathway interactions', 'Pharmaceutical Preparations', 'Play', 'Probability', 'Process', 'Proteins', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Role', 'Software Tools', 'Synaptic Transmission', 'Technology', 'Tissue-Specific Gene Expression', 'Validation', 'Visualization', 'Zebrafish', 'base', 'data visualization', 'knowledge base', 'open source', 'portability', 'precision medicine', 'protein function', 'protein protein interaction', 'side effect', 'simulation', 'targeted treatment', 'therapy design', 'web app']",NCI,OREGON HEALTH & SCIENCE UNIVERSITY,U01,2021,400015
"Illuminating the Druggable Genome by Knowledge Graphs PROJECT SUMMARY / ABSTRACT About 1500 of the ~20,000 protein-coding genes of the human genome can bind drug-like molecules, and yet only about 600 are currently targeted by FDA-approved drugs. Therefore, at least 930 proteins are potential drug targets that are not yet being utilized for human medicine and, given our incomplete state of knowledge about the human genome, the actual number could be much higher. There is therefore a substantial unmet need to improve our understanding of this so-called genomic dark matter in order to develop novel classes of drugs to improve treatment of disease. Comprehensive experimental investigation of these proteins in the context of hundreds of thousands of compounds and thousands of diseases would be prohibitively expensive, but computational approaches could significantly refine the list. In this project we will apply two sophisticated computational approaches to the task of predicting the most promising novel drug targets. We will integrate the knowledge bases DrugCentral and other resources with the disease and phenotype knowledge base of the Monarch Initiative into a semantically harmonized knowledge graph (KG). This will result in a KG with comprehensive coverage of diseases, genes, gene functions, phenotypic abnormalities, drugs, drug mechanisms, and drug targets. Machine learning (ML) identifies patterns from training sets and applies the patterns to predict entities and relations in new data. ML using KGs has become a hot new research area in computer science, but remains difficult to use for real-world applications, owing to the lack of adequate software packages. We will therefore implement state-of-the art learning algorithms based on deep learning on KGs by extending and adapting selected algorithms to the task of drug and drug target discovery. We will develop an easy-to-use software library and demonstrate its use by means of notebooks that will be designed to serve as starting points for future computational research by other scientists, since they will contain the analysis workflow along with documentation about each step. The human genome codes more than 500 protein kinases, which are enzymes that add a phosphate group to specific amino acid residues and thereby transmit a biological signal. There are currently 35 FDA approved protein kinase modulators acting on 38 protein kinases, which are thus one of the most important groups of druggable proteins encoded by our genome. We will perform a detailed computational study of this group and experimentally validate our top, novel candidate using a patient-derived xenograft model system. PROJECT NARRATIVE / RELEVANCE TO PUBLIC HEALTH The human genome codes for over 20,000 proteins, roughly 3,000 of which are thought to be “druggable”, meaning that in principle they could be targeted by medications to treat disease. However, only about 600 of these proteins are currently targeted by an approved medication, and our knowledge about most of the remaining proteins is limited. Our goal is to develop bioinformatic software that will combine information about these proteins, diseases, clinical manifestations, medications, and other relevant data into a network of information (i.e., a graph), and to use sophisticated machine learning algorithms to predict novel drugs and drug targets. We will focus our computational strategy on the class of protein kinase inhibitors, which are a leading target for cancer drugs. The human genome encodes an estimated 555 kinases, 37 of which have been successfully targeted by anti-cancer medications. By using machine learning to predict which of the remaining 500+ protein kinases are most likely to be amenable to medical treatment, there is a potential to accelerate the pace of research into novel treatments. We will perform a pilot study of the top predicted candidates using a mouse model of cancer.",Illuminating the Druggable Genome by Knowledge Graphs,10348825,U01CA239108,"['Address', 'Algorithms', 'Aloral', 'Amino Acids', 'Animal Model', 'Antineoplastic Agents', 'Area', 'Binding', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Models', 'Cancer Model', 'Catalogs', 'Categories', 'Clinical', 'Code', 'Computer Analysis', 'Computer software', 'Data', 'Data Sources', 'Disease', 'Documentation', 'Drug Design', 'Drug Targeting', 'Emerging Technologies', 'Enzymes', 'FDA approved', 'Future', 'Gene Targeting', 'Genes', 'Genome', 'Genomics', 'Goals', 'Graph', 'Human', 'Human Genome', 'Information Networks', 'Information Resources Management', 'Investigation', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Medical', 'Medicine', 'Molecular Biology', 'Ontology', 'Outcome', 'Outcomes Research', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Pilot Projects', 'Process', 'Protein Kinase', 'Proteins', 'Public Health', 'Pythons', 'Research', 'Resources', 'Scientist', 'Semantics', 'Signal Transduction', 'System', 'The Jackson Laboratory', 'Training', 'Validation', 'anti-cancer', 'base', 'cheminformatics', 'computer science', 'computer studies', 'computing resources', 'dark matter', 'deep learning', 'design', 'disease phenotype', 'drug discovery', 'drug mechanism', 'drug repurposing', 'gene function', 'gene therapy', 'genome resource', 'high risk', 'human disease', 'improved', 'inorganic phosphate', 'knowledge base', 'knowledge graph', 'knowledge integration', 'learning algorithm', 'machine learning algorithm', 'machine learning method', 'mouse model', 'new therapeutic target', 'novel', 'novel drug class', 'open source', 'patient derived xenograft model', 'protein kinase inhibitor', 'protein kinase modulator', 'real world application', 'small molecule', 'tool', 'validation studies']",NCI,JACKSON LABORATORY,U01,2021,536615
"Cancer Prevention and Control (CAPAC) Research Training Program Summary Cancer is the leading cause of death among Hispanics, the largest racial/ethnic minority group in the United States and disproportionately affected by cancer health disparities. Despite this disparity, cancer datasets, specifically for Hispanic populations, are not as available as for other ethnicities. Given the need for cancer health disparities research with a focus on Hispanic health, there is a need for applying Artificial Intelligence/Machine Learning (AI/ML) approaches in this field, and an urgency on making Hispanics cancer datasets Findable, Accessible, Interoperable, and Reusable (FAIR) and AI/ML -ready. The Cancer Prevention and Control Research (CAPAC) Training Program of the University of Puerto Rico Comprehensive Cancer Center (UPRCCC), recruits graduate and health professions students for a hands-on summer research experience in PR. This supplement aims to expand the scope of the parent CAPAC training Program and prepare research workforce on 1) the techniques and approaches to manipulate and pre-process Hispanics cancer datasets to make them FAIR and AI/ML ready, and on 2) the available methods for developing ML-based models to analyze these data and create predictive models for cancer diagnosis and treatments with a focus on Hispanic datasets. We will develop an online course based on the data science project lifecycle, which includes four phases: 1) Data Understanding/ Data Pre-processing; 2) Data Wrangling; 3) Model Planning; and 4) Model Building. This 24-hour online asynchronous course will be organized in modules within two components. Component 1 will include the following topics: fundamentals of cancer data types, identifying and understanding cancer datasets, data science concepts and project lifecycles; basic programming concepts; programming with Python; exploring, pre-processing, and conditioning the cancer datasets; performing Extract, Transform, Load (ETL) prior to AI/ML modelling. Component 2 will add topics such as: principles of AI/ML; variable correlations and associations; determining datasets for training and testing; supervised and unsupervised ML approaches; classification, regression and ensembles ML-algorithms; familiarizing with ML tools. To develop our course, examples and projects, we will use Hispanics cancer datasets from the US and PR. The course would be voluntary and free for interested participants (capacity of 40 trainees), including CAPAC participants (alumni) and applicants, CAPAC mentors, as well as trainees and research staff from collaborating grants/institutions. Student’s gained skills will be evaluated with quizzes and a final practical project, while the course will be evaluated with the support of the evaluation component of the parent grant. This supplement will impact the development of human resources (e.g. students, researchers, clinicians) from the United States and Puerto Rico with the competencies and skills needed to make FAIR Hispanics cancer datasets and to apply AI/ML approaches for creating ML-based predictive models for cancer. Narrative This project will impact the development of the human resources from the United States and Puerto Rico with the competencies and skills needed to make FAIR Hispanics cancer datasets and to apply AI/ML approaches for creating ML-based predictive models for cancer. It will prepare research workforce on 1) the techniques and approaches to manipulate and pre-process Hispanic cancer datasets to make them FAIR and AI/ML ready and on 2) the available methods for developing ML-based models to analyze these data and create predictive models for cancer diagnosis and treatments with a focus on Hispanic datasets.",Cancer Prevention and Control (CAPAC) Research Training Program,10405752,R25CA240120,"['Affect', 'Algorithms', 'Artificial Intelligence', 'Cancer Control', 'Cancer Control Research', 'Cause of Death', 'Classification', 'Competence', 'Comprehensive Cancer Center', 'Data', 'Data Science', 'Data Set', 'Ethnic Origin', 'Evaluation', 'FAIR principles', 'Grant', 'Health', 'Health Occupations', 'Hispanics', 'Hour', 'Human Resources Development', 'Institution', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'Parents', 'Participant', 'Phase', 'Predictive Cancer Model', 'Process', 'Puerto Rico', 'Pythons', 'Research', 'Research Personnel', 'Students', 'Supervision', 'Techniques', 'Testing', 'Training', 'Training Programs', 'United States', 'Universities', 'base', 'cancer diagnosis', 'cancer health disparity', 'cancer prevention', 'cancer therapy', 'conditioning', 'data wrangling', 'experience', 'interest', 'model building', 'online course', 'parent grant', 'racial and ethnic', 'recruit', 'skills', 'summer research', 'tool']",NCI,COMPREHENSIVE CANCER CENTER/ UNIV/PR,R25,2021,83874
"Quantitative protein network profiling to improve CAR design and efficacy PROJECT SUMMARY This grant is in response to PAR-18-206, Bioengineering Research Grants (BRG). Our goal is to adapt a cutting-edge proteomic network analysis platform, Quantitative Multiplex co-Immunoprecipitation or QMI, to chimeric antigen receptor (CAR) T cell signaling. We will then use CAR-QMI to characterize signal transduction network activation downstream of the CAR, to both understand how the CAR instructs a T cell to attack and destroy cancerous targets, and to make batch-specific predictions about efficacy and side-effect profiles of CAR T cell products. CAR T cells are a breakthrough anti-cancer therapy that recently won FDA approval for relapsed B cell lymphomas. A true “personalized medicine”, CAR T cells are manufactured for each patient from that patient's own T cells by transducing T cells collected by leukopheresis with a viral vector encoding a CAR. However, since each batch is unique, some batches perform better than others in terms of producing remissions and/or deleterious and sometimes fatal side effects including cytokine storms and neurotoxicity. The goal of this project is to develop a “personalized signal transduction network analysis platform” that can screen each batch of CAR T cells and predict the efficacy and side-effect potential of that specific batch. Because signal transduction networks integrate information from multiple input sources- for example costimulatory and immunosuppressive cell surface receptors, patient genetic background, and T-cell specific history of activation- we hypothesize that this readout will be a powerful predictor of function. Our preliminary data show that small changes in CAR design parameters such as scFV binding domain affinity produce measurable changes in signal transduction network state that correlate with functional variables such as target killing ability and cytokine release. Further, we show that there exists considerable individual-to- individual variation in batches of CAR T cells produced from different donors. Therefore, the two prerequisites for an individualized predictive assay are present- variation in our measurement across the population, and the functional relevance of our measurement to outcome parameters. Our interdisciplinary team consists of experts in CAR development, signal transduction, proteomics, and bioinformatics. Our ambitious but achievable goals are to expand the QMI panel to include CAR-specific components; to understand how CAR design parameters influence both signal transduction network states and functional performance measures; and to develop a predictive machine learning algorithm that translates QMI-derived signal transduction network states into a functional biomarker of in vivo clinical efficacy. Successful completion these aims will (1) identify specific proteins or protein interactions that determine clinically-relevant outcomes such as cytokine production or cell killing ability, allowing CAR designers to rationally modify the design of CARs to target specific signaling outcomes; (2) provide clinicians with a test to predict the clinical performance of CAR T cells on a batch-to- batch basis; and (3) provide the community with a novel analytical platform to measure CAR activity. PROJECT NARRARATIVE CAR T cells have the potential to recognize and specifically kill cancer cells, making them the target of extensive anti-cancer drug development research. This proposal will use a novel technology for monitoring the activation state of a T cell, a protein-interaction-network based approach called Quantitative Multiplex co-Immunoprecipitation, or QMI. Our goal is to identify a protein interaction network state indicative of clinical performance, and to better understand the molecular mechanisms responsible for CAR T cell efficacy.",Quantitative protein network profiling to improve CAR design and efficacy,10144946,R01CA240985,"['Affinity', 'Antibodies', 'Antigen Targeting', 'Antigens', 'Antineoplastic Agents', 'Autoimmune Diseases', 'B-Cell Lymphomas', 'Binding', 'Bioinformatics', 'Biological Markers', 'Biomedical Engineering', 'CD19 gene', 'CD22 gene', 'CD28 gene', 'Cancerous', 'Cell Communication', 'Cell Surface Receptors', 'Cells', 'Child', 'Clinical', 'Clinical Trials', 'Co-Immunoprecipitations', 'Communities', 'Custom', 'Data', 'Development', 'Disease', 'Disease remission', 'Engineering', 'Event', 'Fc Receptor', 'Genetic', 'Goals', 'Grant', 'ITAM', 'Immunology', 'In Vitro', 'Individual', 'K-562', 'Lead', 'Logic', 'Lymphocyte', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurable', 'Measurement', 'Measures', 'Molecular', 'Monitor', 'Network-based', 'Outcome', 'Outcome Measure', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Production', 'Proteins', 'Proteomics', 'Publishing', 'Receptor Signaling', 'Recording of previous events', 'Refractory', 'Relapse', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Science', 'Signal Transduction', 'Source', 'T-Cell Activation', 'T-Cell Receptor', 'T-Lymphocyte', 'Techniques', 'Technology', 'Testing', 'Translating', 'Variant', 'Viral Vector', 'autism spectrum disorder', 'base', 'biosignature', 'cancer cell', 'cancer therapy', 'cell behavior', 'cell killing', 'cell type', 'cellular transduction', 'chimeric antigen receptor', 'chimeric antigen receptor T cells', 'clinical efficacy', 'clinical implementation', 'clinical predictors', 'clinical translation', 'clinically relevant', 'computer infrastructure', 'cytokine', 'cytokine release syndrome', 'density', 'design', 'extracellular', 'graphical user interface', 'improved', 'in vivo', 'individual variation', 'interest', 'leukemia', 'lymphoblast', 'machine learning algorithm', 'molecular modeling', 'nano-string', 'neurochemistry', 'neuropsychiatric disorder', 'neurotoxicity', 'new technology', 'novel', 'personalized medicine', 'personalized predictions', 'prediction algorithm', 'predictive marker', 'predictive test', 'programs', 'protein protein interaction', 'receptor', 'research and development', 'research clinical testing', 'response', 'side effect', 'transcriptome']",NCI,SEATTLE CHILDREN'S HOSPITAL,R01,2021,504231
"SERS diagnostics platform for liquid bioapsy analysis of tumor-associated exosomes Project Summary/Abstract For ovarian cancer (OvCa), only 27% of women diagnosed at advanced stages survive 5 years, yet more than 90% of patients survive when diagnosed at an earlier stage. Therefore, there is an urgent need for new non- invasive technologies capable of rapidly diagnosing ovarian cancers (OvCa) in early stage. Fortuitously, all cells (and tumor cells to a greater extent) expel nanoscale vesicles that are directly reflective of the biological state of their parent cells. A subset of circulating EVs known as exosomes are composed of biomolecules spanning the range of lipids, proteins, genes, and more, and hold great potential for the diagnosis and prognosis of cancer. Yet current methods for phenotyping biofluids according to detection of tumor-associated exosomes (TEXs) are not meeting clinical standards and fail to precisely capture particle to particle heterogeneity. We propose to develop a new nanoplasmonics-based technology for sensitive detection of cancer-related exosome bio-signatures enabled by multiplexed surface-enhanced Raman spectroscopy, that we call ExoSERS. Our approach encompasses three aims devised to realize the ExoSERS platform. Aim 1 outlines development of a new class of Raman-active ligands to serve as the molecular barcodes. This aim encompasses the design and synthesis of polyyne-based ligands designed to confer Raman spectroscopic encoding and also initiate a silane coating to form a protecting shell around a nanoplasmonic core. Aim 2 describes the synthesis and optimization of nanoplasmonic core-shell structures that will be well-suited to binding EVs. An inner gold core structure yields plasmonic enhancement, while the outer silica shell permits long-term stability and a convenient surface for covalent decoration with exosome and cancer-specific surface marker targeting agents. Aim 3 comprises validation of the platform’s feasibility to profile human OvCa patient plasma, including machine learning approaches to type cancers using the barcoded approach. Endpoints of platform characterization will be statistical validation of exosome detection efficiency, minimal sample volume needed, ease of utilization, and low cost. Several quantitative milestones have been proposed to gauge our progress and provide deliverables to the larger diagnostic and circulating biomarker communities. Project Narrative All cells dynamically excrete into circulation nano-sized packages called extracellular vesicles (EVs), but this pathway can be hijacked by cancer cells for means of immune system suppression and metastasis. Innovative cross-disciplinary engineering methods are urgently needed to realize the diagnostic application of circulating cancer EVs to improve early detection of diseases like ovarian cancer, which do not have effective early screening tests. This project encompasses the design of highly multiplexed new nanoplasmonic probes for sensitive chemical fingerprinting of targeted circulating EVs, to ultimately improve the limit of detection for diagnosing ovarian cancer compared to conventional methods.",SERS diagnostics platform for liquid bioapsy analysis of tumor-associated exosomes,10145619,R01CA241666,"['Address', 'Antibodies', 'Architecture', 'Area', 'Bar Codes', 'Binding', 'Biocompatible Materials', 'Biological', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Circulation', 'CA-125 Antigen', 'Cancer Detection', 'Cancer Patient', 'Cancer Prognosis', 'Cells', 'Chemicals', 'Clinical', 'Communities', 'Coupling', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease Management', 'Early Diagnosis', 'Engineering', 'Enzyme-Linked Immunosorbent Assay', 'Extinction (Psychology)', 'Fingerprint', 'Genes', 'Goals', 'Gold', 'Heterogeneity', 'Human', 'Hybrids', 'Immune system', 'Libraries', 'Ligands', 'Lipids', 'Liquid substance', 'Literature', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Mediating', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Monitor', 'Multivariate Analysis', 'Nanostructures', 'Neoplasm Metastasis', 'Optics', 'Outcome', 'Parents', 'Pathology', 'Pathway interactions', 'Patients', 'Peptides', 'Phenotype', 'Physicians', 'Plasma', 'Play', 'Population', 'Process', 'Property', 'Proteins', 'Raman Spectrum Analysis', 'Recurrence', 'Reporting', 'Reproducibility', 'Research', 'Residual Tumors', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Series', 'Shapes', 'Silanes', 'Silicon Dioxide', 'Solid', 'Standardization', 'Structure', 'Study Subject', 'Surface', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Tumor Antigens', 'Untranslated RNA', 'Validation', 'Vesicle', 'Width', 'Woman', 'antigen binding', 'base', 'biomarker evaluation', 'biomaterial compatibility', 'cancer biomarkers', 'cancer cell', 'cancer drug resistance', 'cancer type', 'chemical fingerprinting', 'circulating biomarkers', 'clinical application', 'cost', 'design', 'detection limit', 'diagnostic biomarker', 'diagnostic platform', 'diagnostic technologies', 'early screening', 'exosome', 'experimental study', 'extracellular vesicles', 'improved', 'innovation', 'liquid biopsy', 'minimally invasive', 'multiplex detection', 'multiplexed imaging', 'nanoparticle', 'nanoplasmonic', 'nanoscale', 'nanosized', 'neoplastic cell', 'new technology', 'next generation', 'novel', 'particle', 'plasmonics', 'rapid diagnosis', 'recruit', 'small molecule', 'targeted agent', 'tumor', 'tumor growth', 'vesicle transport', 'vesicular release']",NCI,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2021,533280
"Development of a multi-omic clinical decision platform to guide personalized therapy PROJECT SUMMARY The era of “big data” has opened the door for genomic and systems biology approaches to be applied to current challenges in life sciences and precision medicine. One critical challenge in these areas is how to prioritize research findings to validate and identify actionable insights that can translate into better outcomes for patients. In this regard, we have assembled a multidisciplinary group of scientists and physicians from academia and industry with a focus on creating discovery pipelines that combine high-throughput profiling technologies with advanced statistical and machine learning approaches to generate predictive tools that enable us to move rapidly from big data to better diagnoses and treatment. In this regard, we propose to apply these approaches to develop a computational clinical decision tool that will improve disease forecasting and treatment plans for Multiple Myeloma (MM), an incurable cancer that originates in bone marrow plasma cells and affects more than 30,000 patients a year. Though there have been some advances in the number and diversity of available therapeutic options for these patients, relapse remains inevitable, and MM ultimately remains a terminal diagnosis. The clinical assay and computational pipeline developed in this project will combine a targeted sequencing panel specific to myeloma patients and clonality estimates with RNA- sequencing and drug repurposing to expand therapeutic options for MM patients. We will develop this unique tool with the following specific aims: (1) Develop an integrated genomic clinical decision tool to guide precision treatment of MM and validate therapy recommendations using PDX profiling, and (2) Validate MM precision medicine platform in a prospective clinical trial and generate clone-specific treatment recommendations. To achieve these objectives, we will integrate a Cancer Genetic, Inc.'s FOCUS::Myeloma panel, a targeted panel designed to specifically interrogateall the genes and copy number alterations commonly altered in myeloma, and into a computational drug selection pipeline that utilizes RNA-sequencing data and drug repurposing algorithms to generate therapeutic recommendations matched to a patient's unique disease profile. These recommendations will be validated in mouse avatars of myeloma to confirm and refine drug predictions. We will implement our assay in a prospective clinical trial of 100 patients to determine if the treatment decisions generated by our pipeline achieves an improvement in standard-of-care. Finally, we will perform clonal modeling on relapsed patients to retrospectively evaluate clone-specific treatment responses. Completion of these studies will result in a clinic-ready assay and computational tool that will guide MM precision treatment decisions and inform new therapeutic strategies based on a patient's unique cancer profile. genomic clonal modeling PROJECT NARRATIVE Multiple Myeloma is an incurable cancer of the blood that takes the lives of over 12,000 people every year. It remains a difficult disease to treat due to its genetic complexity from the earliest stages of the disease, indicating a need for a precision medicine approach in treating these patients. In this application Icahn School of Medicine at Mount Sinai will partner with Cancer Genetics, Inc. to develop a multi-omics clinical decision assay that will improve long-term outcomes for patients with advanced myeloma and generate valuable insights and tools that can be broadly leveraged for other disease indications.",Development of a multi-omic clinical decision platform to guide personalized therapy,10101640,R01CA244899,"['Academia', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Area', 'Big Data', 'Biological', 'Biological Assay', 'Biological Sciences', 'Bone Marrow', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Clonality', 'Computer Models', 'DNA Sequence Alteration', 'Data', 'Development', 'Diagnosis', 'Disease', 'Drug resistance', 'Employment', 'Event', 'Gene Dosage', 'Genetic', 'Genetic Diseases', 'Genetic Heterogeneity', 'Genomics', 'Health', 'Hematopoietic Neoplasms', 'Heterogeneity', 'Industry', 'Inflammatory Bowel Diseases', 'Intake', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Modeling', 'Monitor', 'Multiple Myeloma', 'Mus', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physicians', 'Plasma Cells', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Primary Neoplasm', 'RNA', 'Recommendation', 'Refractory', 'Relapse', 'Research', 'Sampling', 'Schizophrenia', 'Scientist', 'Selection for Treatments', 'Solid Neoplasm', 'Stream', 'Suggestion', 'System', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Translating', 'base', 'cancer genetics', 'clinical decision support', 'clinically actionable', 'computational pipelines', 'computerized tools', 'design', 'disorder subtype', 'drug repurposing', 'efficacy testing', 'genomic data', 'genomic profiles', 'improved', 'improved outcome', 'in vivo', 'individual patient', 'insight', 'longitudinal design', 'medical schools', 'mouse model', 'multidisciplinary', 'multiple omics', 'next generation', 'novel', 'novel therapeutic intervention', 'novel therapeutics', 'patient derived xenograft model', 'personalized medicine', 'personalized therapeutic', 'pilot trial', 'point of care', 'precision medicine', 'predictive tools', 'profiles in patients', 'prospective', 'relapse patients', 'risk stratification', 'standard of care', 'statistical and machine learning', 'support tools', 'targeted sequencing', 'tool', 'transcriptome sequencing', 'transcriptomics', 'treatment planning', 'treatment response', 'tumor', 'tumor xenograft']",NCI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,531246
"Proteogenomics-driven therapeutic discovery in hepatocellular carcinoma Project Summary  Hepatocellular carcinoma (HCC) is the third leading cause of cancer-related death worldwide, and therapeutic options are limited. There is a pressing need to fully understand the molecular mechanisms underlying the disease in order to identify new effective biomarkers, drug targets, and therapeutic agents for the prognosis and treatment of HCC. Proteins are the functional molecules of the cell, and many clinically validated biomarkers and most drug targets are proteins; however, cancer omics studies have relied primarily on genomic platforms. By melding genomics with mass spectrometry (MS)-based proteomics, the new field of proteogenomics provides an opportunity to more completely understand how somatic genomes activate aberrant protein networks that drive cancer pathogenesis. A major National Cancer Institute (NCI)-funded initiative, the Clinical Proteomics Tumor Analysis Consortium (CPTAC), and the more recently established International Cancer Proteogenome Consortium (ICPC), are promoting an integrated proteogenomics approach that is postulated to produce sounder therapeutic hypotheses and a new generation of protein biomarkers. The central purpose of this application is to forge a collaboration between a CPTAC team in the US and an ICPC team in China to enable proteogenomics-driven therapeutic discoveries in hepatitis B virus-related (HBV+) HCC, which attributes to 85% of HCC cases in China. The two teams bring complementary expertise required for a successful proteogenomic study of HCC. The China team has already generated the most comprehensive multi-omics dataset yet produced for liver cancer by applying proteogenomic profiling to a Chinese HBV+ HCC cohort (CHCC-HBV) with 159 cases, and the data has been preliminarily analyzed through collaborative efforts between the two teams. In this application, the US team will perform deep computational analyses of the proteogenomics data to generate prognostic models and therapeutic hypotheses, which will be experimentally validated in cell lines, animal models, and clinical specimens by the China team. Our specific Aims are: Aim 1) To develop and validate a protein-based prognostic model; Aim 2) To identify and validate subtype-specific causal drivers and therapeutic strategies; and Aim 3) To characterize the immune landscape of HBV+ HCC. Successful completion of this project will lead to new knowledge on HCC biology as well as new prognostic and treatment strategies for HBV+ HCC. Meanwhile, experimentally validated computational methods developed in this project will have wide application to the study of other cancers and other non-cancer diseases. PROJECT NARRATIVE  Hepatitis B virus-related hepatocellular carcinoma (HBV+ HCC) attributes to 85% of all HCC cases in China, and therapeutic options are limited. This project will forge a collaboration between a computational team in the US and an HCC oncology team in China to perform comprehensive molecular characterization of a large Chinese HBV+ HCC cohort using the new proteogenomic approach that systematically integrates genomics and mass spectrometry-based proteomics data. This collaborative project will produce new biomarkers, drug targets, and therapeutic agents for the prognosis and treatment of HCC as well as experimentally validated computational methods that can be broadly applied to proteogenomic studies in other cancer types and other diseases.",Proteogenomics-driven therapeutic discovery in hepatocellular carcinoma,10135876,R01CA245903,"['Animal Model', 'Antigens', 'Automobile Driving', 'Biological Assay', 'Biological Markers', 'Biology', 'Cancer Etiology', 'Cell Line', 'Cells', 'Cessation of life', 'China', 'Chinese People', 'Clinical', 'Collaborations', 'Colon Carcinoma', 'Complement', 'Computer Analysis', 'Computing Methodologies', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Funding', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Hepatitis B Virus', 'Immune', 'Immune Evasion', 'Immunofluorescence Immunologic', 'Immunophenotyping', 'Immunotherapy', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Maps', 'Mass Spectrum Analysis', 'Messenger RNA', 'Modeling', 'Molecular', 'Monitor', 'National Cancer Institute', 'Oncology', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phase I Clinical Trials', 'Phenotype', 'Primary carcinoma of the liver cells', 'Prognosis', 'Prospective cohort', 'Proteins', 'Proteomics', 'Publishing', 'RNA analysis', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Specimen', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Training', 'Translating', 'Validation', 'base', 'biomarker selection', 'cancer type', 'cohort', 'genomic platform', 'immunogenicity', 'in silico', 'mouse model', 'multiple omics', 'neoantigens', 'next generation sequencing', 'novel therapeutics', 'patient derived xenograft model', 'phosphoproteomics', 'prognostic', 'prognostic model', 'programs', 'protein biomarkers', 'proteogenomics', 'small molecule', 'targeted treatment', 'transcriptome sequencing', 'transcriptomics', 'treatment strategy', 'tumor', 'tumor microenvironment']",NCI,BAYLOR COLLEGE OF MEDICINE,R01,2021,204000
"Commercialization of a highly-sensitive, scalable and low-input compatible kit-based solution for discovery of translocations from FFPE tumor biopsies Commercialization of a highly-sensitive, scalable and low-input compatible kit-based solution for discovery of translocations from FFPE tumor biopsies Arima Genomics Project Summary/Abstract Despite decades of research, cancer takes the lives of nearly 600,000 people every year in the US. The cancer research community has made key advancements towards improving the precision of cancer diagnosis and recently substantial efforts have been put forth into the genetic profiling of tumors. Specifically, efforts have been focused on developing methods to profile genetic alterations such as translocations that are prognostic in cancer. Knowledge of an individual's translocation profile can be used to uncover the mechanistic basis of cancer, accelerating cancer research towards development of new precision therapies. Current standard, including NGS, are limited in their ability to characterize translocations. This is because for NGS (WGS or gene panel seq.) to profile translocations, breakpoint-spanning reads are needed and NGS does not enrich for such reads. FISH enriches for breakpoint info by capturing spatial conformation of the genome within cells and but it has limited utility due to its low-throughput nature and its requirement of apriori info of the translocation partners. Spectral Karyotyping (SKY) needs living cells and cannot be performed on FFPE samples, which is a major sample type for cancer samples. Altogether, a method that is (a) high-throughput along the lines of NGS; (b) enriches translocations along the lines of FISH; (c) not requiring apriori indo of translocating partners to enable promiscuous translocation detection; and (d) compatible with FFPE samples – would result in a highly sensitive and scalable solution for translocation discovery. We satisfy the unmet need via a leapfrog solution. We use HiC to capture conformation on the lines of FISH and couple it with NGS (HiC-Seq) to detect translocations at high sensitivity, high precision, high PPV and low FP. Our team has unmatchable expertise in the science of HiC and its commercialization. Specifically, we commercialized Arima-HiC kits in 2018 for studying conformation in the context of Epigenetics research and generated $1.2M in revenue in the 1st year of commercialization with 200+ customers, all from 1 sales executive. However, these kits are not compatible to FFPE, is manual, labor- and time-intensive and cannot handle batches of >10-20 samples at a time – to enable broad adoption toward cancer research, we have shown the development a boxed kit, the “T-Seq Kit”, based on enhanced HiC optimized for performance, speed, ease of use that is compatible to low-input FFPE, fresh and frozen samples. We validate the technology development from sample to insight in a patient-derived FFPE GIST biopsy and demonstrate that we can sensitively profile translocations even from low tumor purity samples (or low MAF). As part of this direct-2-phase II program, we propose to further develop our technology into a robust kit-based “T-Seq Solution”, comprising same day 8hr sample to sequencing, full 96-plate automated and versatile HiC protocols (to all sample types) that is compatible with existing NGS (ILMN) workflow for customer convenience and bundled with cloud-based push-button bioinformatics equipped with tools for sensitive genome-wide and targeted translocation discovery. We also propose rigorous and essential product development experiments, to ensure commercialization of a robust, premium-performance kit-based product. Upon successful completion of the technical and commercial developments in Aims 1 & 2, we propose to benchmark and validate the sample-to-insight T-Seq Solution through collaboration and prototype (beta) kit and bioinformatics evaluations with key opinion leaders (KOLs) across customer segments of large sequencing centers, academic labs, and pharma. Commercialization of a highly-sensitive, scalable and low-input compatible kit-based solution for discovery of translocations from FFPE tumor biopsies Arima Genomics Project Narrative Translocations are hallmarks of Cancer. Current methods to profile translocations suffer from deficiencies of low sensitivity (WGS, Bianano), high costs (WGS, Bionano, PacBio), incompatibility to FFPE samples (SKY, Bionano, PacBio, 10X), or require direct breakpoint information (FISH and gene-panels). We have a leapfrog solution from combining FISH-type chromatin conformation capture with NGS – referred to as HiC assay with NGS sequencing (HiC-Seq). We transform the time-, labor- intensive, FFPE-incompatible and manual HiC procedure into a rapid “same day” sample to sequencing, fully automated boxed kit that handles all sample types including FFPE, fresh and frozen, and even fine needle aspirates toward high sensitivity and low cost translocation profiling. We combine the kit with push-button cloud-based informatics to enable the sample to insight T-Seq solution. Via being compatible to existing NGS workflows, our T-Seq solution offers maximum convenience, economy and sensitivity for genome-wide and targeted translocation discovery.","Commercialization of a highly-sensitive, scalable and low-input compatible kit-based solution for discovery of translocations from FFPE tumor biopsies",10147659,R44CA247185,"['3-Dimensional', 'Address', 'Adoption', 'Advanced Malignant Neoplasm', 'Age', 'Bar Codes', 'Benchmarking', 'Bioinformatics', 'Biological Assay', 'Biopsy', 'Cause of Death', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Coupled', 'DNA', 'DNA sequencing', 'Data', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Economics', 'Ensure', 'Epigenetic Process', 'Evaluation', 'Fine needle aspiration biopsy', 'Formalin', 'Freezing', 'Funding', 'Genes', 'Genome', 'Genomic Instability', 'Genomics', 'Individual', 'Informatics', 'Infrastructure', 'Knowledge', 'Lead', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Measures', 'Methods', 'Molecular Conformation', 'Molecular Weight', 'Mutation', 'Nature', 'Paraffin Embedding', 'Patients', 'Performance', 'Phase', 'Precision therapeutics', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Sales', 'Sampling', 'Science', 'Shipping', 'Spectral Karyotyping', 'Speed', 'Sum', 'Technology', 'Testing', 'Time', 'TimeLine', 'Translocation Breakpoint', 'Validation', 'anticancer research', 'base', 'cancer diagnosis', 'cancer genomics', 'cancer type', 'chromosome conformation capture', 'cloud based', 'commercialization', 'cost', 'design', 'experience', 'experimental study', 'gene panel', 'genetic information', 'genetic profiling', 'genome-wide', 'improved', 'innovation', 'insight', 'new technology', 'novel', 'precision oncology', 'preservation', 'product development', 'prognostic', 'programs', 'prototype', 'research and development', 'success', 'technology development', 'tool', 'tumor']",NCI,"ARIMA GENOMICS, INC.",R44,2021,999273
"THE CANCER EPITOPE DATABASE AND ANALYSIS RESOURCE ABSTRACT Recent years have witnessed a dramatic rise in interest towards cancer epitopes in general, and neoepitopes that encompass mutations arising in a given tumor in particular. Current lines of research examine how the epitope load in a given tumor relates to the success of checkpoint blockade treatments, and how to utilize epitope-based vaccines and adoptive transfer of epitope-specific T cells for personalized therapies. For these purposes, neoepitopes that are recurrently recognized in different individuals are of particular interest, which has also re-ignited interest in epitopes identified in classic tumor-associated antigens. Along with the interest in cancer epitopes, there is also interest in the TCRs and BCRs specifically recognizing them, as these have the potential to be used in therapeutic approaches, and they can aid in basic studies to infer the specificity of T cells or B cells characterized in single cell sequencing data. This resurgence of interest in epitopes has created a need to catalog and make accessible to the scientific community all epitope data, also linked to the biological, immunological, and clinical contexts. The ultimate goal is to come “full circle” and link epitope recognition and immunological readouts to clinical outcomes and treatment strategies alike. In parallel, there is an urgent need to develop resources for epitope prediction and analysis tools that provide access to predictive strategies and provide objective evaluations of their performance in the relevant biological, immunological, and clinical contexts. Recent years have also witnessed the publication of multiple original methodologies that reported sometimes impressive gains in the predictions of cancer epitopes. However, several of these studies were difficult to evaluate, because the methodologies and/or datasets were not fully available in a format that was readily executable. As a result, their performance could not be properly benchmarked on independent datasets. This is also because effective benchmarking on independent datasets requires the assembly of novel datasets of sufficient size and diversity. To overcome all of these information technology challenges, we propose to design and implement the Cancer Epitope Database and Analysis Resource (CEDAR), which will provide a freely accessible, comprehensive collection of cancer epitope and receptor data curated from the literature, and provide easily accessible epitope and TCR/BCR target prediction and analysis tools. As the cancer epitope data are curated, they will be used as a transparent benchmark of how well prediction tools perform, and also to develop new prediction tools for the analysis resource component of CEDAR. CEDAR will leverage our expertise from developing the Immune Epitope Database and Analysis Resource (IEDB), which is fully operational and widely used by researchers globally. CEDAR will directly complement other projects currently funded through the NIH ITCR program that provide resources and tools related to cancer omics data. Finally, we will engage in outreach activities to improve functions, user interfaces, and interoperability with other ITCR tools and promote the use of CEDAR in cancer research. NARRATIVE Progress in the use of epitopes for cancer immunology and immunotherapy is hampered by a disconnect in information technology, which segregates investigators from the data and tools needed to appropriately conduct their research. Development of a Cancer Epitope Database and Analysis Resource will overcome this issue by harmonizing and centralizing the capture of cancer epitope data, and by using these data to establish and evaluate epitope analysis and prediction tools that will be made freely available to the research community.",THE CANCER EPITOPE DATABASE AND ANALYSIS RESOURCE,10187436,U24CA248138,"['Address', 'Adopted', 'Adoptive Transfer', 'Animal Model', 'Antibodies', 'Attention', 'Autoimmunity', 'B-Cell Antigen Receptor', 'B-Lymphocytes', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Cancer Biology', 'Cancer Histology', 'Catalogs', 'Clinical', 'Clinical Research', 'Collection', 'Communicable Diseases', 'Communities', 'Complement', 'Contracts', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outcome', 'Engineering', 'Ensure', 'Epitopes', 'Evaluation', 'Feedback', 'Funding', 'Goals', 'Human', 'Hypersensitivity', 'Immune', 'Immunologics', 'Immunology', 'Immunotherapy', 'Individual', 'Informatics', 'Information Technology', 'Infrastructure', 'Intuition', 'Journals', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Modification', 'Mutation', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Ontology', 'Outcome', 'Performance', 'Procedures', 'Process', 'Property', 'Publications', 'Publishing', 'Receptor Cell', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Specificity', 'Study models', 'T-Cell Immunologic Specificity', 'T-Cell Receptor', 'T-Lymphocyte', 'T-Lymphocyte Epitopes', 'Technology', 'Therapeutic', 'Transplantation', 'Tumor Antigens', 'Tumor Tissue', 'Tumor-Infiltrating Lymphocytes', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'anticancer research', 'base', 'cancer immunotherapy', 'clinical phenotype', 'cost effective', 'data tools', 'database structure', 'design', 'disease phenotype', 'experience', 'immune checkpoint blockade', 'immunogenicity', 'improved functioning', 'interest', 'interoperability', 'meetings', 'neoantigens', 'novel', 'outreach', 'outreach program', 'personalized medicine', 'programs', 'prospective', 'prototype', 'receptor', 'single cell sequencing', 'success', 'tool', 'translational cancer research', 'treatment strategy', 'tumor', 'tumor immunology', 'web site', 'web-accessible']",NCI,LA JOLLA INSTITUTE FOR IMMUNOLOGY,U24,2021,839852
"GenePattern and GenePattern Notebook: Integrative 'Omic Analysis for Cancer Research Project Summary Over the past two decades, the landscape of cancer research has changed with the explosion of publicly available and investigator generated datasets from evolving technology platforms, and the growing number of sophisticated computational methods and tools to integrate and analyze them. To move the cancer research agenda forward, the cancer research community needs a way to easily combine the right tools and methods to analyze and visualize all the data relevant to their studies, and reproducibly capture the history of what they have done. These objectives may be especially daunting for cancer biologists who don’t program. The GenePattern computational genomics environment has served cancer investigators since 2004 and was enhanced by GenePattern Notebook, released in 2017. The goal of this proposal is to continue to support, expand, and enhance the GenePattern ecosystem. Through these efforts we will continue to support a diverse community of users at the forefront of cancer research who seek to better understand the underlying mechanisms of disease, translate improved methods for patient diagnosis and prognosis to the clinic, and identify new drug targets. Aim 1. Ensure the GenePattern ecosystem continues to keep pace with new and emerging methods and technologies and the changing cancer research environment. To increase the range of methods and approaches available to the GenePattern community, we will provide seamless access to other popular ‘omic analysis packages (Cytoscape, Galaxy, IGV) within GenePattern Notebook, allowing the interleaving of methods from multiple packages within the same executable notebook. We will also provide support for querying and accessing data hosted on selected cancer-relevant data repositories. Aim 2. Continue to author and serve GenePattern notebooks for the cancer research community. We will develop 30-50 new high utility notebooks for the GenePattern-Notebook Workspace, leveraging Aim 1 as required, that provide users with guided, step-by-step execution of their integrative analysis. These will comprise data processing and analysis workflows, including approaches that bridge the gap from discovery to translation. Aim 3. Extend, maintain, and support the GenePattern ecosystem infrastructure. We will continue to support and enhance the GenePattern ecosystem, including enabling hosting on multiple cloud architectures and high- performance compute sites, and enhancing the Notebook user interface with high-value features. Aim 4. Provide outreach, training, and support to our user community. We will engage the cancer research community to continue to address their needs. A Scientific Advisory Board of cancer biologists and physician scientists will review progress and guide our strategy as we proceed. We will continue our high level of support and outreach for GenePattern and its notebook environment, including cancer-focused tutorials and training materials, in-person workshops, conference presentations, webinars, and social media vehicles and our responsive forum. We will fully participate in all of the ITCR program activities. Relevance GenePattern is a popular bioinformatics software ecosystem that puts sophisticated computational methods within the reach of all biomedical researchers to address a variety of problems at the forefront of cancer research, including patient diagnosis and prognosis, identification of new drug targets, and understanding disease mechanisms. We will continue to support and enhance the system by providing interoperable access to additional software tools and data resources from GenePattern Notebook, a beginning-to-end computational electronic lab notebook environment for combining analysis and text. Moreover, we will expand our collection of notebooks that provide cancer investigators with scientist-oriented cancer analysis scenarios and tasks for use in their own studies.",GenePattern and GenePattern Notebook: Integrative 'Omic Analysis for Cancer Research,10164740,U24CA248457,"['ATAC-seq', 'Address', 'Architecture', 'Bioinformatics', 'Clinic', 'Code', 'Collection', 'Communities', 'Companions', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Educational workshop', 'Ensure', 'Environment', 'Explosion', 'Funding', 'Galaxy', 'Genomics', 'Goals', 'High Performance Computing', 'Industry', 'Infrastructure', 'Letters', 'Malignant Neoplasms', 'Methods', 'Pathway Analysis', 'Patients', 'Persons', 'Physicians', 'Prognosis', 'Recording of previous events', 'Reproducibility', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Site', 'Software Tools', 'Suggestion', 'System', 'Technology', 'Text', 'Training', 'Training Support', 'Translating', 'Translations', 'Visualization', 'Work', 'anticancer research', 'base', 'computerized data processing', 'computerized tools', 'data access', 'data repository', 'data resource', 'flexibility', 'genomic platform', 'improved', 'interoperability', 'machine learning method', 'new therapeutic target', 'online resource', 'open source', 'outreach', 'patient stratification', 'programs', 'single-cell RNA sequencing', 'skills', 'social media', 'symposium', 'tool', 'webinar']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,923435
"Outcomes for CLL patients treated with novel therapy PROJECT SUMMARY/ABSTRACT We have recently conducted and published a game changing phase 3 clinical North American Intergroup (NAIG) trial (E1912) for chronic lymphocytic leukemia (CLL) therapy which tested a combination of Ibrutinib and Rituximab (IR) vs. the prior gold standard chemoimmunotherapy (CIT): fludarabine, cyclophosphamide, and rituximab (FCR). This trial showed that both progression free survival (PFS) and overall survival (OS) are superior with IR and subsequently was the driving factor in FDA approval for frontline use of IR in progressive previously untreated CLL in the spring of 2020. While our work revealed distinct clinical advantages to non-CIT approaches, a number of new questions have emerged with respect to how best apply this advance. The durability of the response to first-line ibrutinib-based therapy is highly variable and requires indefinite treatment exposing patients to the risk of chronic toxicity and selective pressure that may foster resistant clones. The ability to more accurately predict the durability of response could help identify patients more likely to have long term remission with ibrutinib therapy (candidates for time limited therapy) and those more likely to have a short duration of response whom may benefit from intensive combination therapy with alternative novel agents. We wish to develop a unique model(s) incorporating multiple key prognostic factors that will have a high level of confidence in predicting patient outcomes to novel therapy combination. Our initial study on patients treated on IR arm of E1912 found a subset of patients on the IR arm with evidence for emerging mutations and changes in their clonal architecture predicting relapse. The exact mechanisms for relapse need to be defined as we predict that these patients will be difficult to treat and alternative strategies needed. We found that IR therapy was uniquely able to reactivate the previously exhausted T cell killing activity directed against the leukemic CLL cells. While we have some information on the mechanism(s) for this, much remains to be learned and also the exact timing for achieving the maximal restoration of T cell function or fitness. This beneficial impact on T cell function will also be studied as it relates to generation of CAR T cells as these cells are powerful inducers of immunotherapy which is itself capable of removing residual CLL tumor burden. We hypothesize that the outcome of the studies will add significant and important information on how to best select non-chemotherapy for CLL patients and also the treatment impact on the immune system. These goals will be accomplished through the following specific aims: Aim 1: Develop an Integrated Model to Predict Clinical Outcomes for CLL Patients Treated with Novel Agents. Aim 2: Determine the Genetic, Epigenetic and Transcriptomic Changes in Ibrutinib Treated CLL. Aim 3: Characterize the Impact of Ibrutinib Treatment on T-cell Fitness to Guide Application of Immunotherapy. PROJECT NARRATIVE These scientific studies assess important ways that Ibrutinib-based therapy for upfront therapy of CLL patients can be evaluated adding important decision parameters on who would benefit the most from this approach, strategies on how to best treat refractory or relapsed patients and on the most opportune times to utilize blood T cells for immunotherapy. In total this collective analysis will provide critical insights on this therapeutic approach and in this fashion improve the health of individuals with this disease.",Outcomes for CLL patients treated with novel therapy,10208516,R01CA251801,"['ATAC-seq', 'Agammaglobulinaemia tyrosine kinase', 'American', 'Architecture', 'Archives', 'Automobile Driving', 'Biological Assay', 'Blood', 'Blood specimen', 'CAR T cell therapy', 'Cell Compartmentation', 'Cell Therapy', 'Cell physiology', 'Cells', 'Chromatin', 'Chronic', 'Chronic Lymphocytic Leukemia', 'Clinical', 'Clinical Data', 'Combined Modality Therapy', 'Cyclophosphamide', 'Data', 'Decision Aid', 'Decision Making', 'Disease', 'Disease Progression', 'Disease remission', 'Drug resistance', 'Early treatment', 'Epigenetic Process', 'Fostering', 'Future', 'Gene Activation', 'Gene Expression', 'Generations', 'Genetic', 'Goals', 'Gold', 'Health', 'Immune', 'Immune system', 'Immuno-Chemotherapy', 'Immunotherapeutic agent', 'Immunotherapy', 'Individual', 'International Prognostic Index', 'Knowledge', 'Leukemic Cell', 'Longitudinal Studies', 'Medical Genetics', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Mutation', 'Outcome', 'Outcome Study', 'PLCG2 gene', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Phase III Clinical Trials', 'Phenotype', 'Prognostic Factor', 'Progression-Free Survivals', 'Progressive Disease', 'Publishing', 'Recurrent disease', 'Refractory', 'Regulatory Pathway', 'Relapse', 'Residual Neoplasm', 'Residual Tumors', 'Residual state', 'Resistance', 'Risk', 'Sampling', 'Somatic Mutation', 'T-Lymphocyte', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Tumor Burden', 'Tyrosine Kinase Inhibitor', 'Validation', 'Work', 'arm', 'base', 'cell killing', 'chimeric antigen receptor T cells', 'chronic T-cell leukemia', 'chronic lymphocytic leukemia cell', 'cohort', 'comparative', 'design', 'epigenomics', 'exhaust', 'fitness', 'fludarabine', 'follow-up', 'high dimensionality', 'improved', 'innovation', 'insight', 'molecular marker', 'multiple omics', 'novel', 'novel therapeutics', 'patient population', 'patient subsets', 'phase III trial', 'phase change', 'predict clinical outcome', 'pressure', 'prognostic model', 'prognostic tool', 'relapse patients', 'relapse prediction', 'response', 'restoration', 'risk prediction', 'rituximab', 'statistical and machine learning', 'targeted sequencing', 'targeted treatment', 'tool', 'transcriptome sequencing', 'transcriptomics']",NCI,MAYO CLINIC ROCHESTER,R01,2021,705542
"Canine MHC-I genotyping and tumor specific neoantigen determination Abstract Being naturally occurring and with an intact immune system, spontaneous cancers in pet dogs have the potential to effectively bridge a current gap between preclinical models and human clinical trials, advancing cancer immunotherapy. However, a current lack of essential resources creates roadblocks to the effective use of canine cancers. The deficiency is clearly seen in predicting tumor-specific neoantigen (TSNA), attractive targets in cancer treatment and prevention. TSNAs arise when intracellular mutant peptides, created by cancer-associated somatic alterations, are presented by the cell’s histocompatibility complex class I (MHC-I) molecules. Hence, MHC-I genotyping is a prerequisite for TSNA prediction. However, with few MHC-I alleles known to date, MHC-I genotyping for the dog is a significant challenge. Moreover, because of the very limited MHC-I protein crystal structures and experimental peptide binding data, there currently lack public tools to predict TSNAs specifically for the dog, in contrast to the human with many tools developed. With the next generation sequencing (NGS) data published for thousands of dogs from hundreds of breeds, now is the time to address these deficiencies. We propose to combine our expertise, NGS data analysis by the Zhao (PI) lab and MHC-I characterization by the Hildebrand (MPI) lab, to develop software tools and data resources for large scale MHC-I genotyping and systematic TSNA prediction for the dog. We will also genotype MHC-I alleles of thousands of dogs sequenced and predict TSNAs for hundreds of canine tumors characterized. We will use our proposed MHC-I genotype and TSNA discovery tools to assist a NCI-funded immunotherapy trial via collaboration with Dr. Steven Dow, and the Vaccination Against Canine Cancer Study (VACCS) trial via collaboration with Dr. Douglas Thamm. By establishing resources that are critically missing at present, our work will significantly enhance the applicability of the dog model for translational research. Project Narrative We propose to build resources to support cancer immunotherapy, by establishing essential software tools and generating data critically missing at present for canine histocompatibility complex class I (MHC-I) genotyping and tumor-specific neoantigen (TSNA) discovery. Our proposed research will significantly enhance the applicability of the dog model for translational research.",Canine MHC-I genotyping and tumor specific neoantigen determination,10220542,R01CA252713,"['Address', 'Advanced Malignant Neoplasm', 'Algorithms', 'Alleles', 'Base Pairing', 'Behavior Therapy', 'Binding', 'Canis familiaris', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Crystallization', 'Data', 'Data Analyses', 'Data Commons', 'Databases', 'Development', 'Etiology', 'Funding', 'Genome', 'Genotype', 'Heterogeneity', 'Human', 'Immune system', 'Institutes', 'Major Histocompatibility Complex', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measures', 'Modeling', 'Molecular', 'National Cancer Institute', 'Neural Network Simulation', 'Oncology', 'Outcome', 'Peptides', 'Population', 'Pre-Clinical Model', 'Proteins', 'Publishing', 'Quality Control', 'Research', 'Resources', 'Rodent Model', 'Sampling', 'Sequence Read Archive', 'Software Tools', 'Structure', 'Time', 'Training', 'Translating', 'Translational Research', 'Treatment outcome', 'Vaccination', 'Validation', 'Work', 'artificial neural network', 'cancer immunotherapy', 'cancer prevention', 'cancer therapy', 'data resource', 'exome sequencing', 'experience', 'genome sequencing', 'human genomics', 'immunogenicity', 'immunotherapy trials', 'mutant', 'neoantigens', 'next generation sequencing', 'pre-clinical', 'prevent', 'software development', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'translational model', 'tumor', 'whole genome']",NCI,UNIVERSITY OF GEORGIA,R01,2021,492039
"Integrated visualization, control, and analysis of GEF – GTPase networks in living cells A small number of Rho family GTPases participate in a broad array of fundamental cellular behaviors. Specificity is possible due to spatial and temporal control of GTPase “activation”; Guanine exchange factors (GEFs) generate activated, GTP-bound GTPases with precise timing and localization, while specialized interactions with adhesion molecules, membrane domains and other localized structures specify GEF-GTPase interactions. GEF/GTPase circuits are complex, with localized feedbacks, multiple GEFs controlling one GTPase, and vice versa. To dissect this spatiotemporally regulated circuitry requires imaging, and new analytical techniques that can dissect causal relationships from imaging data. Following the intentions of PAR- 19-158 (Bioengineering Research Grants), we propose a multidisciplinary collaboration leveraging organic chemistry, protein engineering, imaging, and computer science to fudnamentally advance signal transduction imaging and analysis. As a biological testbed we will explore the role of GEF-GTPase interactions in cell protrusion, single cell migration and collective migration. We will develop a generalizable approach to GEF biosensors, and adapt our proven GTPase biosensors to image GEF and GTPase activities in the same cell. Because GEF-GTPase interactions are heterogeneous and complex, multiplexed imaging is necessary to quantify their relative dynamics. However, perturbation of cell behavior is especially problematic when using two biosensors in the same cell. We will therefore develop new biosensor designs that greatly reduce cell perturbation. Even the most precise imaging of overlapping molecular activations has not revealed causal relationships. We will therefore adopt the framework of Granger Causality inference, which was originally devised for financial market analysis, to extract causal connections and feedback interactions from imaging data. Numerous steps will be necessary to translate the existing concepts of Granger causality to the analysis of spatially and temporally distributed molecular processes. Most importantly, we will implement a schema for Granger causality inference in multivariate time series models that will capture spatial relations, and we will combine principles of high-dimensional statistical regression with approaches from control theory to estimate information flows between variables that are coupled by strong feedbacks. We will also develop a novel clustering approach that preserves the neighborhood topology of data in a high-dimensional feature space and in the Euclidian space of the cell outline to identify signaling microdomains. Finally, to test and confirm our hypotheses, we will use new photo-activatable and photo-inhibitable analogs of GEFs together with GTPase biosensors to control one protein while observing another. This research plan will produce biosensors with reduced perturbation, biosensor/optogenetic multiplexing capabilities, and image analysis/modeling approaches necessary to shed light on the network topology of nonlinear, spatiotemporally controlled signaling pathways. All tools will efficiently deployed to the community. In this project we are developing new ways to understand the mechanisms by which cells interpret, and in cancer misinterpret, the host of stimuli from outside and inside the cell that determine behavior. We are building molecules that can report, through light emission, the behavior of multiple key elements of the cellular “decision making circuits”, and in parallel developing new mathematical tools to interpret the output of these molecules, and to integrate this data into overall models that reveal information flow in the circuitry. We are also developing the ability to control one circuit component while watching the activity of another, enabling us to dissect out causal relationships within cellular circuits.","Integrated visualization, control, and analysis of GEF – GTPase networks in living cells",10221568,R01CA252826,"['Actomyosin', 'Acute', 'Address', 'Adhesions', 'Adopted', 'Adoption', 'Architecture', 'Basic Science', 'Behavior', 'Binding', 'Biological', 'Biomedical Engineering', 'Biosensor', 'Cell Adhesion', 'Cell Adhesion Molecules', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computing Methodologies', 'Coupled', 'Data', 'Decision Making', 'Disease', 'Dyes', 'Elements', 'Engineering', 'Environment', 'Etiology', 'Event', 'Family', 'Feedback', 'Fiber', 'Fluorescence Resonance Energy Transfer', 'GTP Binding', 'Guanine', 'Guanine Nucleotide Exchange Factors', 'Guanosine Triphosphate Phosphohydrolases', 'Homeostasis', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Label', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Membrane', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Molecular Conformation', 'Morphogenesis', 'Neighborhoods', 'Nonlinear Dynamics', 'Oncogenic', 'Organic Chemistry', 'Output', 'Pathway interactions', 'Play', 'Process', 'Protein Engineering', 'Proteins', 'Proxy', 'Regression Analysis', 'Regulation', 'Reporting', 'Research', 'Research Project Grants', 'Resolution', 'Role', 'Route', 'Series', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Specific qualifier value', 'Specificity', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Translating', 'Translational Research', 'Visualization', 'analog', 'base', 'cancer therapy', 'cell behavior', 'cell motility', 'computer science', 'control theory', 'design', 'econometrics', 'guanine analog', 'high dimensionality', 'image processing', 'imaging approach', 'interdisciplinary approach', 'interest', 'light emission', 'mathematical methods', 'mathematical theory', 'migration', 'multiplexed imaging', 'novel', 'optogenetics', 'preservation', 'response', 'rho', 'rho GTP-Binding Proteins', 'single molecule', 'spatiotemporal', 'tool']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,541157
"Development of personalized ex vivo predictive technology for rapidly matching patient tumors with chemotherapy regimens before treatment. Project Summary/Abstract Pancreatic ductal adenocarcinoma (PDAC) is among the deadliest cancers with <9% five-year survival rate and an estimated 60,000 deaths/year by 2030. PDAC is often diagnosed at an advanced stage thereby precluding surgical resection for most patients. While new systemic therapy regimens have improved survival, availability of multiple options, without tools to select an optimal regimen from these (on an individualized basis), has created a frustrating paradox in clinical decision-making. Due to a lack of personalized predictive tools, current standard of care treatment strategy is based on prognostic factors such as age, stage, performance status, serum albumin, etc. There is a critical, urgent and unmet need to develop predictive tools that can identify optimal systemic therapy regimens and eliminate from consideration ineffective options, on an individualized basis, to improve quality of life and reduce overtreatment. CerFlux, Inc. is developing such predictive technology with its low-cost and rapid Personalized Oncology Efficacy Test (POET) to match each patient with the right treatment – before treatment – to transform pancreatic cancer treatment in the near-term and make a difference in the lives of patients and providers around the world. Our personalized medicine approach is unique and further enhanced by a commercial-academic collaboration between CerFlux, Inc. and the James Comprehensive Cancer Center at the Ohio State University. The proposed project will build on recent work by our team including a patented (US 10,114,010B1) biomimetic in vitro platform for pharmacological transport and pancreatic microtissue tumor models. The commercial goal of this proposal is to identify best practices for using POET in personalized therapy. Our hypothesis is that response to treatment observed in POET will approximate the response in the corresponding patient. Our objective is to predict both effective and ineffective treatments for each patient prior to initiating treatment. We propose the following aims to achieve our objective: Aim 1: Calibrate and optimize POET for evaluating therapeutics using human PDAC cell-line xenografts for subsequent testing with patient tissue. Aim 2: Evaluate efficacy of various systemic therapy agents in POET on an individualized basis to establish protocols and best practices for using POET in personalized therapy. We envision substantial continuing commercial-academic collaboration between CerFlux, Inc. and the James Comprehensive Cancer Center at the Ohio State University including the integration of machine learning to derive a “POET Score” – a personalized quantitative efficacy score – based on a combination of factors. Data from POET and the POET Score will help clinical teams rank treatments for individual patients before the first drug infusion. If successful, this SBIR-driven study has the potential to transform pancreatic cancer treatment in the near-term and make a positive impact around the world. Project Narrative Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest cancers with <9% five-year survival rate, is often diagnosed at an advanced stage thereby precluding surgical resection for most patients. There is a critical, urgent and unmet need to develop predictive tools that can identify optimal systemic therapy regimens and eliminate from consideration ineffective options on an individualized basis to improve quality of life and reduce overtreatment. CerFlux, Inc. is developing such predictive technology with its low-cost and rapid Personalized Oncology Efficacy Test (POET) to match each patient with the right treatment – before treatment – to transform pancreatic cancer treatment in the near-term and make a difference in the lives of patients and providers around the world.",Development of personalized ex vivo predictive technology for rapidly matching patient tumors with chemotherapy regimens before treatment.,10303439,R43CA254493,"['Age', 'Biomimetics', 'Cell Line', 'Cessation of life', 'Chemotherapy-Oncologic Procedure', 'Clinical', 'Collaborations', 'Comprehensive Cancer Center', 'Data', 'Development', 'Diagnosis', 'Excision', 'Goals', 'Human', 'In Vitro', 'Infusion procedures', 'Legal patent', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Modeling', 'Ohio', 'Operative Surgical Procedures', 'Pancreas', 'Pancreatic Ductal Adenocarcinoma', 'Patients', 'Performance Status', 'Pharmaceutical Preparations', 'Pharmacology', 'Prognostic Factor', 'Protocols documentation', 'Provider', 'Quality of life', 'Regimen', 'Serum Albumin', 'Small Business Innovation Research Grant', 'Survival Rate', 'Systemic Therapy', 'Technology', 'Testing', 'Therapeutic Uses', 'Tissues', 'Universities', 'Work', 'Xenograft procedure', 'base', 'cancer therapy', 'clinical decision-making', 'cost', 'effective therapy', 'efficacy evaluation', 'efficacy testing', 'improved', 'individual patient', 'ineffective therapies', 'overtreatment', 'pancreatic ductal adenocarcinoma cell', 'personalized medicine', 'personalized predictions', 'precision oncology', 'predictive tools', 'response', 'standard of care', 'tool', 'treatment response', 'treatment strategy', 'tumor']",NCI,"CERFLUX, INC.",R43,2021,52000
"Single cell quantification of genomic instability in cancer as a determinant of therapeutic response PROJECT ABSTRACT Tumor genetic heterogeneity is an extensive feature of cancer biology and underlies patient response to therapy. One aspect of tumor heterogeneity that has been difficult to study is heterogeneity of large genomic aberrations, including high level amplifications a few megabases in size, whole or partial chromosomal gains and losses and whole genome duplications. This is because identifying these aberrations in subclonal populations (present in <100% of cells) is extremely challenging when sequencing tumors in “bulk”. Single cell genomics however, can resolve these alterations at cellular resolution enabling precise quantification of heterogeneity at these genomic length scales. To comprehensively investigate the extent and consequences of intra-tumor heterogeneity generated by these types of genomic aberrations I will leverage recent advances in robust highly scalable single cell whole genome sequencing and my expertise in computational modeling. In the K99 phase of the award I will investigate how differences in the ability of cells to repair their genomes results in different patterns of genetic heterogeneity, and how such cellular diversity can cause differential response to treatment in high grade serous ovarian cancer, a cancer driven by genomic instability. In the independent phase of the award I will focus on heterogeneity and evolutionary dynamics of extra-chromosomal DNA, small circular pieces of DNA that cause high level amplification of oncogenes. The results of this proposal have the potential to give fundamental new insight into the biology of genomic instability and enable better predication of patient response to therapy and identification of therapeutic vulnerability that may be exploited. This proposal also describes a training plan to advance my career to an independent investigator, combining computational modeling inspired by evolutionary theory, machine learning and high-resolution genomics to quantify cancer evolution in order to better predict patient response to therapy and uncover the mechanisms driving cancer progression. During the K99 phase I will be supported by an interdisciplinary team of experts in single cell genomics, cancer evolution, ovarian cancer biology and genomic instability. I will broaden my knowledge of machine learning, genomic instability and scalable bioinformatics software engineering and improve my communication and leadership skills vital for my transition. PROJECT NARRATIVE In this research proposal we will study how the instability inherent to the genomes of cancer cells impact patient response to therapy. We envisage that the results from this proposal will enable better prediction of patient response to therapy and reveal therapeutic vulnerabilities that may be exploited to design more effective therapies.",Single cell quantification of genomic instability in cancer as a determinant of therapeutic response,10115351,K99CA256508,"['Aftercare', 'Alleles', 'Automobile Driving', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Bioinformatics', 'Biological', 'Biology', 'Breast Epithelial Cells', 'CCNE1 gene', 'Cancer Biology', 'Cancer Patient', 'Cell Line', 'Cells', 'Chromosomal Gain', 'Chromosomal Loss', 'Collection', 'Communication', 'Computer Models', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Pathway', 'Data', 'Defect', 'Elements', 'Environment', 'Evolution', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genetic Heterogeneity', 'Genome', 'Genomic Instability', 'Genomics', 'Heterogeneity', 'Immersion', 'Knowledge', 'Leadership', 'Length', 'Lesion', 'Loss of Heterozygosity', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Mentors', 'Methods', 'Modeling', 'Mutagenesis', 'Neoplasm Metastasis', 'Oncogenes', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Play', 'Population', 'Prediction of Response to Therapy', 'Primary Neoplasm', 'Process', 'Prognosis', 'Property', 'Relapse', 'Research', 'Research Personnel', 'Research Proposals', 'Resistance development', 'Resolution', 'Role', 'Route', 'Sampling', 'Serous', 'Software Engineering', 'TP53 gene', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Treatment outcome', 'cancer cell', 'cancer genome', 'cancer genomics', 'cancer type', 'career', 'chromosome missegregation', 'design', 'effective therapy', 'extrachromosomal DNA', 'fitness', 'genome sequencing', 'genomic aberrations', 'genotoxicity', 'improved', 'insight', 'mutant', 'novel strategies', 'patient derived xenograft model', 'patient response', 'profiles in patients', 'programs', 'repaired', 'response', 'single cell technology', 'single-cell RNA sequencing', 'skills', 'theories', 'tool', 'treatment comparison', 'treatment response', 'tumor', 'tumor heterogeneity', 'tumor progression', 'whole genome']",NCI,SLOAN-KETTERING INST CAN RESEARCH,K99,2021,99798
"Phylogenetic approaches to the quantification and serilization of variants enabling cancer theraputic resistance and the reconstruction of etilogically relevant ancestral states PROJECT SUMMARY/ABSTRACT Cancer progression is an evolutionary process, enabling tumors to evade our best therapeutics and, ultimately, to recur and metastasize. The evolution of therapeutic resistance remains enigmatic in part because it must be reconstructed from patient biopsies which are prescribed by patient care, rather than from design to empower discovery. Some mechanisms of resistance in select cancer-therapy systems have been discovered, but this knowledge is the result of extensive work and is subject to obsolescence as therapeutic strategies themselves evolve, necessitating systematic approaches to reveal how therapy is subverted. Our goal is to leverage tumor phylogenies to examine the evolutionary forces operating on variants responsible for therapeutic resistance. To expose the timing of specific SNVs and quantify their contribution to therapeutic resistance, I will perform deconvolution of selection from the underlying mutation rate on therapy-exposed branches of tumor phylogenies to obtain cancer effect sizes for SNVs in the context of therapy. I employed this approach in a preliminary analysis of EGFR L850R-driven, erlotinib-treated lung adenocarcinoma, and it revealed that the EGFR T790M mutation in has a vast effect size—roughly 45× higher in the context of therapy than the L858R mutation driving primary progression has during primary progression. The results support molecular and clinical observations that EGFR T790M confers strong erlotinib resistance and suggest vulnerability of EGFR L850R-driven cancer lineages to simultaneous, orthogonal treatments. Application of this method to less well characterized cancer-therapeutic systems will enable detection of currently unknown enablers of resistance. Development of these approaches to illuminate the evolutionary dynamics of therapeutic resistance will reveal the series and timing of mutations enabling resistance. To fully utilize this knowledge, we will perform analyses of somatic variant epistasis on cancer chronograms, resolving the gene interactions and evolutionary trajectories that lead to therapeutic resistance. Further, we will learn from convergences in the mechanisms of therapeutic resistance, modifying a Markov Chain Monte Carlo approach to the Bayesian reconstruction of cancer chronograms, to quantify—on average—the time until specific mutations reach high frequency. Finally, we will develop synergistic phylogenetic and machine-learning strategies that characterize the etiology of unobservable ancestral features of cancer. For instance, our initial analysis of a lung adenocarcinoma patient receiving erlotinib preceded by cisplatin found that platin-induced mutational signature peaked on the same branch of the phylogeny as the EGFR c.2369C→T substitution causing the T790M resistance mutation, suggesting that preceding erlotinib therapy with cisplatin can supply exactly the genetic heterogeneity needed by the tumor to evade erlotinib therapy. These approaches will also extend to evolutionary changes of other clinical features on which we will perform similar ancestral reconstructions on gene expression, neoantigens, and exome sequencing, illuminating myriad other aspects of the evolutionary context of therapeutic resistance. PROJECT NARRATIVE The progression of cancer, including the acquisition of therapeutic resistance and the mortality-inducing metastatic spread of therapy-resistant cell populations, is fundamentally an evolutionary process. To contribute to the development of effective treatments against this evolving scourge, I will leverage phylogenetics, statistics, and machine learning techniques to quantify the effects of genetic variants responsible for therapeutic resistance, resolve the timing of their occurrence, and understand their genetic and developmental trajectories within cancer subtypes. These essential insights obtained will illuminate the mechanistic evolution of therapeutic resistance in the selected systems while creating a general and powerful framework for understanding resistance to future therapies.",Phylogenetic approaches to the quantification and serilization of variants enabling cancer theraputic resistance and the reconstruction of etilogically relevant ancestral states,10141576,F31CA257288,"['Algorithms', 'Automobile Driving', 'Biopsy', 'Cancer Biology', 'Cells', 'Characteristics', 'Cisplatin', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Epidermal Growth Factor Receptor', 'Erlotinib', 'Etiology', 'Evolution', 'Exposure to', 'Frequencies', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genetic', 'Genetic Epistasis', 'Genetic Heterogeneity', 'Glass', 'Glioma', 'Goals', 'Immune system', 'Individual', 'Induced Mutation', 'Intervention', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Lung Adenocarcinoma', 'Machine Learning', 'Malignant Neoplasms', 'Markov Chains', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Neoplasm Metastasis', 'Patient Care', 'Patients', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Probability', 'Process', 'Recording of previous events', 'Regimen', 'Resistance', 'Resolution', 'Safety', 'Sampling', 'Scourge', 'Series', 'System', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'TimeLine', 'Variant', 'Work', 'cancer subtypes', 'cancer therapy', 'cancer type', 'carcinogenesis', 'clinical decision-making', 'clinical effect', 'cohort', 'cost', 'design', 'effective therapy', 'exome sequencing', 'gene interaction', 'genetic variant', 'improved', 'insight', 'learning strategy', 'mortality', 'neoantigens', 'pressure', 'public repository', 'reconstruction', 'resistance mechanism', 'resistance mutation', 'response', 'statistics', 'temporal measurement', 'therapy resistant', 'tumor', 'tumor progression']",NCI,YALE UNIVERSITY,F31,2021,46036
"Multimodal computational models to stratify ovarian cancer patients Project Summary/Abstract High-grade serous ovarian cancer (HGSC) is the most lethal gynecologic malignancy, with a five-year survival rate of less than 30% for metastatic disease. Our lab has identified mutational processes as predictors of survival and response to therapy, along with a working model to predict homologous recombination deficiency from hematoxylin and eosin (H&E) whole-slide images. Our collaborators in diagnostic radiology have discovered robust associations between BRCA mutational status and qualitative features on contrast-enhanced computed tomography (CE-CT). These two imaging modalities, however, have yet to be combined with genomic information to improve stratification of HGSC patients. Based on these preliminary data, I will test the hypothesis that combined mesoscopic information in CE-CT and microscopic information in H&E can be used to infer known mutational subtypes and also to identify novel patient strata. I have curated a cohort of 118 HGSC patients with matched targeted panel-based genome sequencing, scanned H&E whole-slide images, and segmented pre-treatment CE-CT images for this purpose. In Specific Aim 1, I will develop a machine learning model to integrate CE-CT and H&E imaging to predict mutational subtype from these ubiquitous imaging modalities. In Specific Aim 2, I will develop an end-to-end deep learning model to integrate the complementary information from CE-CT, H&E, and genome sequencing for survival analysis using a Cox Proportional Hazards model. I anticipate that this work will (1) identify refined stratification of HGSC patients using this multimodal prognostic signature and (2) develop a general-purpose machine learning model to integrate CE-CT, H&E, and genomic sequencing for cancer patient survival analysis. This research will be conducted at Memorial Sloan Kettering Cancer Center under the mentorship of Dr. Sohrab Shah. The training plan that Dr. Shah and I have developed will prepare me well for a future as a physician- scientist conducting machine learning research for cancer patient prognosis. Project Narrative Mutational subtypes of high-grade serous ovarian cancer stratify patients by clinical outcome, yet genomic sequencing omits spatial information with potential prognostic relevance. In the proposed project, I aim to (1) infer mutational subtype by combining radiologic and histologic imaging and (2) identify refined patient strata by integrating radiologic and histologic imaging with genomic sequencing. Completion of this work will identify new strata of ovarian cancer patients and result in new machine learning models to integrate cancer imaging with genomic sequencing.",Multimodal computational models to stratify ovarian cancer patients,10146152,F30CA257414,"['Anatomy', 'Area', 'BRCA mutations', 'Biological Markers', 'Cancer Patient', 'Clinical', 'Collaborations', 'Computer Models', 'Cox Proportional Hazards Models', 'DNA Repair', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Eosine Yellowish', 'Future', 'Gene Targeting', 'Genomics', 'Glioma', 'Goals', 'Hematoxylin and Eosin Staining Method', 'High Performance Computing', 'Hospitals', 'Image', 'Infrastructure', 'Institution', 'Joints', 'Machine Learning', 'Malignant Female Reproductive System Neoplasm', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Mutation', 'Neoplasm Metastasis', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platinum', 'Point Mutation', 'Poly(ADP-ribose) Polymerases', 'Positioning Attribute', 'Primary Neoplasm', 'Process', 'Prognosis', 'Publishing', 'Research', 'Scanning', 'Scientist', 'Serous', 'Slide', 'Stratification', 'Structure', 'Survival Analysis', 'Survival Rate', 'Techniques', 'Testing', 'Training', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer genome', 'cancer imaging', 'chemotherapy', 'clinical imaging', 'cohort', 'contrast enhanced', 'cost', 'deep learning', 'genome sequencing', 'health care settings', 'histological image', 'homologous recombination', 'imaging modality', 'improved', 'indexing', 'inhibitor/antagonist', 'innovation', 'interstitial', 'large datasets', 'malignant breast neoplasm', 'multimodality', 'mutational status', 'novel', 'patient response', 'patient stratification', 'prognostic', 'prognostic signature', 'prospective', 'radiological imaging', 'radiologist', 'radiomics', 'response', 'standard of care', 'survival prediction', 'targeted sequencing', 'tumor', 'whole genome', 'whole slide imaging']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F30,2021,51036
"Global Health Catalyst (GHC) Summit Project Summary Recently, leaders in cancer policy from the USA and 14 economically diverse countries concluded that successful campaigns to control cancer will increasingly depend on concerted international collaborations. The recent World Health Organization Cancer Report highlights urgency for such international collaborations, with over 60% of 14 million new cancer cases and 70% of 8.2 million deaths per year occurring in low and middle income countries (LMIC), some of which, sadly, are the least capable of dealing with cancer without some form of collaboration. These major disparities in cancer deaths are in part a reflection of poignant underlying disparities in Radiation Oncology. For example, radiotherapy, which is needed in the treatment of over 50% of cancer patients, is not available in about half of Africa's 54 countries, and preliminary research shows major safety concerns in implementation of radiotherapy where available. The overall goal of this proposal is to organize yearly global health catalyst (GHC) cancer summits designed to catalyze high impact international collaborations between US and African Institutions to address the growing global burden of cancers, and associated disparities. This GHC summits, will build on the success and lessons learned over the past years during previously organized summits, that have catalyzed collaborations to support cancer healthcare institutions in different African countries, supported education and training efforts to build human/research capacity, and established fecund research collaborations, along with disease prevention and advocacy programs in global oncology. An innovative component of the summit is the focus on outreach engagement of under-represented minorities and the resource-laden Africans in Diaspora (AiD) to turn the devastating effects of brain drain to gain against cancer. Outcomes will include: new and strengthened collaborations involving partners from both USA and African institutions each year, significant increase in participation of under-represented minorities and diaspora in global oncology, peer-reviewed publications co-authored by both USA and African collaborators, joint patents resulting from research collaborations, and continuous growth to engage more participation from USA and African Institutions to address the growing global burden of cancer and associated disparities. Project Narrative The overall goal of this project is to organize Global Health Catalyst cancer summits which will catalyze sustainable high impact USA-Africa collaborations designed to significantly enhance cancer research and education benefiting both USA and African countries. An innovative component of the summits is the focus on unprecedented engagement of under-represented minorities and the Diaspora to catalyze or support these collaborations.",Global Health Catalyst (GHC) Summit,10318812,R13CA257481,"['Address', 'Advocacy', 'Africa', 'African', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Brain Drains', 'Cancer Burden', 'Cancer Control', 'Cancer Patient', 'Cessation of life', 'Collaborations', 'Country', 'Development', 'Education', 'Ensure', 'Evaluation', 'Faculty', 'Feedback', 'Fertility', 'Funding', 'Funding Opportunities', 'Goals', 'Growth', 'Health Professional', 'Healthcare', 'Human', 'Immigrant', 'Industry', 'Industry Collaboration', 'Information Technology', 'Institution', 'International', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Legal patent', 'Malignant Neoplasms', 'Mentors', 'Multi-Institutional Clinical Trial', 'Multimedia', 'Oncology', 'Outcome', 'Peer Review', 'Pennsylvania', 'Policies', 'Population', 'Professional Organizations', 'Publications', 'Publishing', 'Radiation Oncology', 'Radiation therapy', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Safety', 'Students', 'Technology', 'Training', 'Training and Education', 'Underrepresented Minority', 'United States', 'Universities', 'Work', 'World Health Organization', 'anticancer research', 'base', 'cancer care', 'cancer education', 'cancer health disparity', 'catalyst', 'cost effective', 'design', 'disorder prevention', 'education research', 'evidence base', 'experience', 'global health', 'improved', 'industry partner', 'innovation', 'interest', 'low and middle-income countries', 'outreach', 'overtreatment', 'programs', 'response', 'success', 'symposium', 'tool', 'virtual platform', 'web site']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2021,20000
"Making antibody generation rapid, scalable, and democratic through machine learning and continuous evolution Project Summary/Abstract It is hard to overstate the importance of monoclonal antibodies in the life sciences. Antibodies are critical tools in biomedical research and diagnostics (e.g. western blotting, immunoprecipitation, cytometry, biomarker discovery, and histology), are one of the most rapidly growing class of therapeutics, and are the basis for myriad new strategies in cancer therapy, such as checkpoint inhibitors that are revolutionizing treatment. Unfortunately, current methods for the generation of custom antibodies, including animal immunization and phage display, are slow, costly, inaccessible to most researchers, and often unsuccessful. We propose Autonomously EvolvinG Yeast-displayed antibodieS (AEGYS), a system for the continuous and rapid evolution of high-quality antibodies against custom antigens that requires only the simple culturing of yeast cells. We believe this can be achieved by combining cutting-edge generative machine learning algorithms for antibody library design with a new technology for in vivo continuous evolution and a yeast antigen-presenting cell that we will engineer. If successful, AEGYS should have a transformative impact across the whole of biomedicine by turning monoclonal antibody generation into a rapid, scalable, and accessible process where any lab with standard molecular biology capabilities can generate custom antibodies on demand simply by “immunizing” a test tube of yeast cells with an antigen. We anticipate that this democratization of antibody generation will also result in an explosion of crowdsourced antibody sequence data that will train our machine learning algorithms to design better antibody libraries for AEGYS, starting a virtuous cycle. We ourselves will use AEGYS to generate a panel of subtype- and conformation-specific nanobodies against biogenic amine receptors including those that respond to acetylcholine, adrenaline, dopamine, and other neurotransmitters, so that we can understand their role in neurobiology and addiction.! Project Narrative This proposal will provide a system for the scalable continuous evolution and computational design of antibodies against user-selected antigens. Antibodies are critical tools in medical research and are the basis for numerous therapies, but the generation of custom antibodies against new targets is a difficult and specialized task. The system proposed will turn antibody generation into a routine and widely accessible process for researchers in almost any field.","Making antibody generation rapid, scalable, and democratic through machine learning and continuous evolution",10260452,R01CA260415,"['Acetylcholine', 'Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antibody Formation', 'Antigen Targeting', 'Antigen-Presenting Cells', 'Antigens', 'Architecture', 'Area', 'Back', 'Biogenic Amine Receptors', 'Biological Sciences', 'Biomedical Research', 'Cell Surface Receptors', 'Cells', 'Chemistry', 'Clinic', 'Collection', 'Communities', 'Cultured Cells', 'Custom', 'Cytometry', 'Data', 'Data Set', 'Detergents', 'Diagnostic', 'Directed Molecular Evolution', 'Docking', 'Dopamine', 'Elements', 'Engineering', 'Epidemic', 'Epinephrine', 'Evolution', 'Explosion', 'G-Protein-Coupled Receptors', 'Generations', 'Genes', 'Genetic', 'Histology', 'Human', 'Hybridomas', 'Image', 'Immune checkpoint inhibitor', 'Immune system', 'Immunization', 'Immunize', 'Immunoglobulin Fragments', 'Immunoprecipitation', 'Libraries', 'Machine Learning', 'Medical Research', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Monoclonal Antibodies', 'Neuraxis', 'Neurobiology', 'Neurosciences', 'Neurotransmitters', 'Nobel Prize', 'Outcome', 'Pathogen detection', 'Phage Display', 'Pharmaceutical Preparations', 'Pheromone', 'Play', 'Problem Solving', 'Process', 'Production', 'Protein Engineering', 'Proteins', 'Proteome', 'Public Health', 'Reagent', 'Research', 'Research Personnel', 'Role', 'Signal Transduction', 'Specificity', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Studies', 'Training', 'Tube', 'Update', 'V(D)J Recombination', 'Western Blotting', 'Yeasts', 'addiction', 'antibody engineering', 'antibody libraries', 'antigen binding', 'base', 'biomarker discovery', 'cancer therapy', 'cost', 'crowdsourcing', 'decision research', 'design', 'empowered', 'experimental study', 'follow-up', 'improved', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'nanobodies', 'new technology', 'novel', 'receptor', 'response', 'scaffold', 'structural biology', 'tool']",NCI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2021,1665161
"Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring Abstract  Building on its commercially available Absolute Q digital PCR platform, during the 24-month Phase 2 SBIR project, Combinati will complete the development of the first Digital Melt Curve Analysis (DMCA) platform to the market to further advance the adoption of digital genomics for highly accurate, sensitive and reproducible nucleic acid quantification for longitudinal patient monitoring. To provide the “whole product” solution and prove the function, we will demonstrate the DMCA platform with Luminex’s 11- plex ESR1 (Estrogen Receptor 1) assay and conduct Beta testing at Dana Farber Cancer Institute: 1. Three beta instruments and the analysis software capable of digital melt curve analysis. 2. Complete dMCA validation internally with commercially available melt calibration kits. 3. Demonstrate <0.1% Mutation Allele Frequency of 11 cell-free DNA targets using Luminex  Corporation’s discrete melt assay. 4. Beta testing at Dana Farber Cancer Institute Narrative  Since PCR was invented back in 1983, it has become the gold standard for applications requiring quantification of nucleic acids. The continuous evolution of the technology enables PCR to be more quantitative (qPCR), more accurate, precise and reproducible (digital PCR). In parallel, with the invention of melt curve analysis in 1997, it opens another dimension in melt temperatures for applications requiring simple and inexpensive genotyping, high degree qualitative multiplexing without sequencing, and assay optimization. Despite that there is a handful of dPCR platforms in the market, none of them supports Melt Curve Analysis. By combining melt curve analysis with digital PCR, Combinati strives to accelerate the adoption of digital genomics for all nucleic acid quantification needs in research and clinical markets.",Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring,10256226,R44CA261523,"['Adopted', 'Adoption', 'Architecture', 'Back', 'Biological Assay', 'Blinded', 'Breast Cancer Patient', 'Calibration', 'Cancer Patient', 'Chemistry', 'Clinical', 'Collection', 'Color', 'Computer software', 'Computers', 'DNA', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'ESR1 gene', 'Evolution', 'Gene Frequency', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Journals', 'Letters', 'Light', 'Mainstreaming', 'Manuscripts', 'Mechanics', 'Memory', 'Metastatic breast cancer', 'Microfluidics', 'Monitor', 'Mutation', 'Nucleic Acids', 'Optics', 'Oranges', 'Patient Monitoring', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Running', 'Sampling', 'Science', 'Small Business Innovation Research Grant', 'Source', 'Speed', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Validation', 'cell free DNA', 'clinically relevant', 'cost', 'cyanine dye 5', 'data exchange', 'design', 'detection limit', 'digital', 'fluorescence imaging', 'graphical user interface', 'image processing', 'improved', 'instrument', 'invention', 'lens', 'liquid biopsy', 'machine learning algorithm', 'meetings', 'melting', 'multidimensional data', 'mutant', 'mutation assay', 'neural network', 'product development', 'sensor', 'simulation']",NCI,"COMBINATI, INC.",R44,2021,772720
"Validation of a saliva test using methylated microRNAs for head and neck cancer recurrence PROJECT SUMMARY The objective of this combined UH2/UH3 application is to develop a non-invasive, accurate, and cost-effective saliva-based test for early detection of squamous cell carcinoma of the head and neck (SCCHN) recurrence. SCCHN includes squamous cell carcinomas derived from oral cavity, tongue, pharynx and larynx. It is the 7th most common cancer in US and worldwide by incidence, and the 3rd in US and 4th worldwide by 5-year prevalence. SCCHN is a biologically aggressive cancer in which high rates of recurrence (local, locoregional or distant) contribute significantly to poor patient survival. Current clinical practice methods for detection of SCCHN recurrence are either subjective, invasive, hard to access, not able to detect recurrence in a timely manner or expensive. There is an unmet medical need for an objective, non-invasive, easy to access test that is able to detect SCCHN recurrence in a timely and a cost-effective way. Our solution is “HNKlear”, a non- invasive, saliva-based candidate test for early detection of SCCHN recurrence. HNKlear incorporates a 7- methylated microRNA biomarker panel. The real-time nature of our test will provide more timely and precise detection of SCCHN recurrence. In our published proof of concept studies, HNKlear demonstrated 92% sensitivity and 98% specificity in ~300 SCCHN and control tissue samples and 85% sensitivity and 95% in ~200 SCCHN and control saliva samples using continuous variables, which supports the clinical translation of the test. We propose a combined UH2/UH3 application for the clinical translation of HNKlear. In the UH2 phase, we will analytically validate the test and algorithm in a pre-clinical study and in a new patient cohort. Success of this phase will let us lock down the test and cut-off when the milestone is met. We will then conduct a clinical study in the UH3 phase to demonstrate the clinical validity of HNKlear for SCCHN recurrence in an observational clinical follow-up study incorporating HNKlear into current clinical practice. Success of this phase will generate robust evidence of the clinical validity of HNKlear for early detection of SCCHN recurrence, and will further enable clinical application of HNKlear as a Laboratory Developed Test. PROJECT NARRATIVE This application is to develop a robust, non-invasive, easy to access saliva test that is able to detect head and neck cancer recurrence in a timely and cost-effective way. Success in meeting the objective will enable its clinical utility into current clinical practice as a Laboratory Developed Test.",Validation of a saliva test using methylated microRNAs for head and neck cancer recurrence,10281743,UH2CA262045,"['Algorithms', 'Applications Grants', 'Biological', 'Biological Assay', 'Clinical', 'Clinical Practice Guideline', 'Clinical Research', 'Detection', 'Development', 'Distant', 'Early Diagnosis', 'Follow-Up Studies', 'Future', 'Goals', 'Head and Neck Cancer', 'Head and Neck Neoplasms', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Health Care Costs', 'Incidence', 'Institution', 'Intervention', 'Laboratories', 'Larynx', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Methods', 'MicroRNAs', 'National Comprehensive Cancer Network', 'Nature', 'Observational Study', 'Operative Surgical Procedures', 'Oral cavity', 'Outcome', 'PET/CT scan', 'Patients', 'Performance', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Positron-Emission Tomography', 'Prevalence', 'Prospective Studies', 'Publishing', 'Radiation exposure', 'Radiation therapy', 'Recurrence', 'Reproducibility', 'Research', 'Resources', 'Roentgen Rays', 'Saliva', 'Screening for cancer', 'Specificity', 'Squamous cell carcinoma', 'System', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Tumor Burden', 'Tumor Tissue', 'Ultrasonography', 'Universities', 'Validation', 'Washington', 'base', 'biomarker development', 'biomarker panel', 'cancer biomarkers', 'cancer recurrence', 'clinical application', 'clinical practice', 'clinical translation', 'cohort', 'cost effective', 'detection method', 'experimental study', 'genomic locus', 'improved', 'meetings', 'microRNA biomarkers', 'patient population', 'preclinical study', 'prediction algorithm', 'prospective', 'random forest', 'rural area', 'saliva analysis', 'saliva sample', 'salivary assay', 'screening', 'success', 'testing access', 'tool']",NCI,UNIVERSITY OF COLORADO DENVER,UH2,2021,273315
"Algorithm-based prevention and reduction of cancer health disparity arising from data inequality Ethnic minority groups have a long-term cumulative data disadvantage in biomedical research and clinical studies. Statistics have shown that over 90% of the samples in cancer-related GWAS and clinical omics projects were collected from Individuals of European ancestry. This severe data disadvantage of the ethnic minority groups is set to produce new health disparities as data-driven, algorithm-based biomedical research and clinical decisions become increasingly common. The new cancer disparity arising from data inequality can potentially impact all ethnic minority groups in all types of cancers where data inequality exists. Thus, its negative impact is not limited to the cancer types or subtypes for which significant ethnic disparities have already been evident. The long-term goal of the proposed research is to prevent or reduce the heath disparities arising from the data disadvantage of ethnic minority groups. The overall objective of this work is to obtain key knowledge and create open resources to establish a new paradigm for machine learning with multiethnic clinical omics data. Our central hypothesis is that the knowledge learned from data of the majority population can be transferred to improve machine learning performance on the data-disadvantaged ethnic minority groups. Guided by strong preliminary data, we will pursuit two specific aims to 1) Discover from cancer clinical omics data and genotype-phenotype data: under what conditions and to what extent the transfer learning scheme improves machine learning model performance on data-disadvantaged ethnic minority groups; 2) Create an open resource system for unbiased multiethnic machine learning to prevent or reduce new health disparities arising from the data disadvantage of ethnic minorities. The approach is innovative because it represents a substantive departure from the status quo by shifting the paradigm of multiethnic machine learning from mixture learning and independent learning schemes to a transfer learning scheme. The proposed research is significant, because it is expected to establish a new paradigm for unbiased multiethnic machine learning and to provide an open resource system to facilitate the paradigm shift, and thus to prevent or reduce health disparities arising from the data disadvantage of ethnic minorities. Ethnic minorities have a severe data-disadvantage that is set to produce new health disparities as data-driven and algorithm-based biomedical research and clinical decisions become increasingly common. The proposed research addresses this challenge by discovering critical knowledge and creating open resources for a paradigm shift in multiethnic machine learning using cancer clinical omics data. This paradigm shift is expected to prevent or reduce health disparities arising from the data-disadvantage of ethnic minorities.",Algorithm-based prevention and reduction of cancer health disparity arising from data inequality,10275989,R01CA262296,"['Address', 'Affect', 'African American', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Asians', 'Benchmarking', 'Biomedical Research', 'Caucasians', 'Clinical', 'Clinical Research', 'Cohort Studies', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disadvantaged', 'Distant', 'Ethnic group', 'European', 'Genomics', 'Genotype', 'Goals', 'Healthcare Systems', 'Hispanics', 'Individual', 'Inequality', 'Information Resources Management', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Medical Genetics', 'Minority', 'Minority Groups', 'Modeling', 'Multiomic Data', 'Outcome', 'Performance', 'Population', 'Predictive Analytics', 'Prevention', 'Prognosis', 'Psychological Transfer', 'Race', 'Research', 'Research Project Grants', 'Resources', 'Retrieval', 'Sampling', 'Scheme', 'System', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Work', 'base', 'cancer genomics', 'cancer health disparity', 'cancer risk', 'cancer subtypes', 'cancer type', 'cohort', 'database of Genotypes and Phenotypes', 'disorder risk', 'ethnic disadvantage', 'ethnic disparity', 'ethnic diversity', 'ethnic minority population', 'experimental study', 'genetic architecture', 'genome wide association study', 'genomic data', 'health disparity', 'improved', 'innovation', 'knowledge base', 'machine learning method', 'multi-ethnic', 'phenotypic data', 'precision medicine', 'prevent', 'research study', 'response', 'secondary analysis', 'self-directed learning', 'statistics', 'user-friendly']",NCI,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2021,352275
"Systematic Characterization of Small Nucleolar RNAs in Cancer Abstract Despite recent advancements in treatment options for cancer, a majority of cancer types continue to lack fully characterized and effective targeted therapies. This insufficiency has resulted in the demand for alternative, previously unconsidered treatment approaches to improve disease diagnostics, prognoses, and patient survival outcomes. Recently, we performed integrative analysis for small nucleolar RNA (snoRNAs) in a large number of patient samples and identified 46 snoRNAs that exhibit broad-spectrum clinical significance with 12 or more types of cancer. We developed a data portal, snoRNA in cancers (SNORic), which allows researchers to explore the significance of individual snoRNAs in cancer. SNORic has been accessed >100,000 times since its release in 2017, suggesting its broad impact in the biomedical research community. We provided initial genetic evidence indicating that elevated expression of snoRNAs facilitated the tumorigenesis of mammary gland malignancies. Mechanistically we demonstrated that SNORD46 plays important roles in promoting the initiation, growth, invasion and progression of TNBC. Therefore, elucidation of the roles of snoRNAs in promoting tumorigenesis serves as the first step in the development of a novel class of snoRNA-based biomarkers and therapeutic targets.  Our central hypothesis is that snoRNAs serve as essential RNA targets in promoting cancer initiation, progression, and drug resistance, which could be attenuated in vivo by an antisense oligonucleotide-based targeted therapy. In specific aim 1, we will delineate the diagnostic and prognostic values of these snoRNAs in triple-negative breast cancer (Aim 1.1). We will demonstrate the molecular mechanism that these snoRNAs promote TNBC cell proliferation, mobility and invasion (Aim 1.2). We will demonstrate that antisense oligonucleotide-based snoRNA targeted therapy effectively inhibits TNBC growth in vivo (Aim 1.3). We will evaluate and interpret causal effects through molQTL analysis (Aim 1.4). In specific aim 2, we will determine the role of three snoRNAs in breast cancer drug resistance (Aim 2.1). We will understand the molecular mechanisms for drug resistance through multi-omics data (Aim 2.2). To expand our perspective on drug resistance, we will predict the drug response from individual snoRNA expression with the augmentation of deep learning (Aim 2.3). We will study the drug responses effects among snoRNA-based subtypes (Aim 2.4). We will build a user-friendly data portal for releasing the date generated through integrative analysis (Aim 2.5). This study will significantly advance the prognostic, diagnostic, and therapeutic potential of snoRNAs; the absence of this research work will greatly hinder the realization of snoRNA-based therapeutic considerations for cancer patients. Project Narrative Despite improvements in clinical considerations for cancer, a considerable number of cancer subtypes continue to lack effective targeted therapies, resulting in the urgent need for the development of previously unconsidered treatment approaches and therapeutic strategies. Following the emergence of preliminary data implicating snoRNAs as key players in a significant number of cancer-related processes and signaling pathways, this project seeks to determine the functional effects of snoRNAs in vitro and in vivo, elucidate the drug response effects of snoRNAs, and provide a comprehensive data resource for exploring the biomedical significance of snoRNAs. The proposed study will shed light on future clinical considerations for the development of targeted therapies for cancer types currently lacking effective treatment options, and it is also expected that the computational methods and experimental systems established in the proposed research will be applicable to other cancer types, thereby greatly leveraging the impact of this project.",Systematic Characterization of Small Nucleolar RNAs in Cancer,10277525,R01CA262623,"['Antisense Oligonucleotides', 'Attenuated', 'Biological', 'Biological Markers', 'Biological Models', 'Biomedical Research', 'Breast Cancer Cell', 'Breast Cancer cell line', 'Cancer Patient', 'Cell Proliferation', 'Clinical', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Drug resistance', 'Exhibits', 'FDA approved', 'Fatty acid glycerol esters', 'Foundations', 'Future', 'Genetic', 'Genetic Transcription', 'Goals', 'Growth', 'In Vitro', 'Individual', 'Light', 'Malignant Neoplasms', 'Mammary Tumorigenesis', 'Mammary gland', 'Molecular', 'Multiomic Data', 'Outcome', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Process', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Signal Pathway', 'Signal Transduction', 'Small Nucleolar RNA', 'Solid Neoplasm', 'System', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Work', 'Xenograft procedure', 'base', 'cancer drug resistance', 'cancer initiation', 'cancer subtypes', 'cancer type', 'clinically relevant', 'clinically significant', 'data portal', 'data resource', 'deep learning', 'differential expression', 'drug response prediction', 'effective therapy', 'genetic variant', 'improved', 'in vivo', 'individual response', 'insight', 'large scale data', 'malignant breast neoplasm', 'mammary', 'mouse model', 'novel', 'prognostic', 'prognostic value', 'refractory cancer', 'response', 'success', 'survival outcome', 'targeted cancer therapy', 'targeted treatment', 'therapeutic target', 'treatment strategy', 'triple-negative invasive breast carcinoma', 'tumor', 'tumorigenesis', 'user-friendly']",NCI,TEXAS A&M UNIVERSITY HEALTH SCIENCE CTR,R01,2021,406018
"Dissecting drug resistance in serial uveal melanoma biopsies using integrated, multi-modal single-cell profiling and novel machine learning tools. PROJECT SUMMARY Uveal melanoma (UM) is a rare melanoma subtype with an estimated annual incidence of approximately 2000 in the United States. While most patients have excellent rates of local disease control with surgery or radiotherapy, nearly half develop metastatic disease, most frequently to the liver. Metastatic UM (MUM) is very treatment resistant and shows no significant responses to conventional chemotherapies or immune checkpoint inhibitors (ICI). UM is molecularly characterized by canonical mutations of the Gα protein subunits (GNAQ/11), which result in hyperactivation of the MAPK pathway. Targeting this pathway with MEK inhibitors (MEKi) results in significant anti-tumor activity in vitro, and response rates of up to 14% in patients with MUM, thereby exhibiting significantly higher activity compared to other available systemic therapies. However, there remains significant potential to improve the efficacy of MEKi. To better define modifiers of MEKi sensitivity and resistance, it is important to consider the fact that most UM harbor mutually exclusive GNAQ/11co-mutations, including inactivating mutations or bi-allelic loss of BAP1 (~33%) or deleterious mutations in SF3B1 (~23%) or EIF1AX (13%), thus define distinct genomic subtypes of UM. These alterations likely provide dependencies that are not abrogated with MEKi alone, yet they may represent synthetic lethal vulnerabilities in the context of MEKi. Furthermore, there has not been a systematic evaluation of how MEKi (or any other therapy) alters cancer cell autonomous and cell non-autonomous mechanisms that could confer drug resistance. This is in part due to technical barriers and lack of in vivo models that faithfully recapitulate human MUM. In this proposal, we build on several innovations to systematically determine the impact of MEKi on the MUM ecosystem and define synthetic lethal dependencies across the UM genomic landscape and in the context of MEKi. We will achieve this in two specifim aims: In Aim 1, we will perform single-nuclei RNA-sequencing (snRNA-seq) in patients with MUM who underwent therapy with MEKi selumetinib and had serial biopsies (pre-, on- and off-therapy), and analyze these with several established analytical methods. Second, building on recent developments, we will build machine learning tools for the analysis of sequential single-cell data sets. In Aim 2, we will perform patient- informed CRISPR-screens with multi-modal single-cell RNA/protein readouts across the genomic spectrum of UM. Finally, we will perform genome-scale CRISPR-screens across multiple models to define genotype-shared and -unique modifiers of MEKi responses. Together, these approaches will provide the a comprehensive sequential single-cell analysis in solid tumors, develop tools for temporal single-cell analyses that can be referenced against a ground truth, and define genotype-dependent synthetic lethal vulnerabilities with concurrent MEKi therapy. PROJECT NARRATIVE Uveal melanoma (UM) is a rare form of melanoma that metastasizes in 50% of affected patients, which is associated with treatment resistance poor survival. There is currently no Food-and-Drug-Administration (FDA)- approved therapy for patients with metastatic UM, but MEK inhibitors (MEKi) are promising. Here, we will use a broad spectrum of single-cell genomic, genome-editing and machine-learning tools to define drug resistance to MEKi and potential synthetic lethal vulnerabilities across the distinct genomic landscape of UM.","Dissecting drug resistance in serial uveal melanoma biopsies using integrated, multi-modal single-cell profiling and novel machine learning tools.",10290692,R21CA263381,"['Affect', 'Biopsy', 'CRISPR screen', 'Caring', 'Cell Line', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Clinical', 'Clinical Trials', 'Cues', 'Cutaneous', 'DNA Damage', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Drug Targeting', 'Drug resistance', 'Ecosystem', 'Evaluation', 'Evolution', 'Exhibits', 'Freezing', 'GNAQ gene', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Human', 'Immune checkpoint inhibitor', 'Impairment', 'Incidence', 'Liver', 'Loss of Heterozygosity', 'MAP Kinase Gene', 'MAPK Signaling Pathway Pathway', 'MEKs', 'Machine Learning', 'Maintenance', 'Melanoma Cell', 'Metastatic Melanoma', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Nature', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Pathway interactions', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Pilot Projects', 'Protein Subunits', 'Proteins', 'RNA', 'RNA Splicing', 'Radiation therapy', 'Resistance', 'Small Nuclear RNA', 'Solid Neoplasm', 'Specimen', 'Systemic Therapy', 'Therapeutic', 'Tissues', 'Translations', 'United States', 'United States Food and Drug Administration', 'Uveal Melanoma', 'analytical method', 'base', 'brca gene', 'cancer cell', 'chemotherapy', 'combinatorial', 'disorder control', 'experience', 'genome editing', 'genome-wide', 'improved', 'in vitro activity', 'in vivo Model', 'inhibitor/antagonist', 'innovation', 'loss of function', 'malignant breast neoplasm', 'melanoma', 'molecular subtypes', 'multimodality', 'mutational status', 'novel', 'preclinical study', 'prospective', 'resistance mechanism', 'response', 'single cell analysis', 'therapy resistant', 'tool', 'transcriptome', 'transcriptome sequencing', 'tumor']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R21,2021,189338
"TOPIC 428 ""CLOUD-BASED LIQUID-BIOPSY PLATFORM FOR THE CANCER RESEARCH DATA COMMONS"" Integrative analysis of multi-omics datasets is revolutionizing cancer research and patient care. To take advantage of the full breadth of CRDC’s petabyte-scale data, EarlyDx will seamlessly integrate its liquid biopsy cloud-computing platform, a cfDNA–based bioinformatics platform with proprietary machine learning algorithms, with the CRDC data repositories and computational capacity in a cloud infrastructure. Liquid biopsies provide a non-invasive approach for interrogating the genomic and epigenomic profiles of tumors and can easily acquire a large number of specimens. Co-analysis of CRDC tissue-based TCGA, TARGET, CPTAC datasets with user-provided data from a tube of blood will ensure broad user adoption of CRDC. Our long-term goals are to advance our understanding of tumorigenesis, therapeutic resistance and response, and to improve patient care. Specifically, we will conduct the following aims: 1) establish a multidisciplinary team; 2) design, develop, and implement strategies for integration of EarlyDx liquid biopsy bioinformatics platform with CRDC; 3) recruit at least 25 users of an early phase prototype for usability testing; 4) report Phase I results to NCI, and plan for further development and commercialization. Our platform with CRDC integration will accelerate cancer research, and promote clinical applications such as cancer detection and treatment in broad populations. n/a","TOPIC 428 ""CLOUD-BASED LIQUID-BIOPSY PLATFORM FOR THE CANCER RESEARCH DATA COMMONS""",10489552,5N91021C00023,"['Adoption', 'Bioinformatics', 'Blood', 'Cancer Detection', 'Cancer Patient', 'Cloud Computing', 'Data', 'Data Commons', 'Data Set', 'Development', 'Ensure', 'Genomics', 'Goals', 'Patient Care', 'Phase', 'Population', 'Reporting', 'Specimen', 'Testing', 'The Cancer Genome Atlas', 'Tissues', 'Tube', 'anticancer research', 'base', 'cancer therapy', 'clinical application', 'cloud based', 'cloud platform', 'commercialization', 'computational platform', 'data repository', 'design', 'epigenomics', 'improved', 'liquid biopsy', 'machine learning algorithm', 'multidisciplinary', 'multiple omics', 'petabyte', 'prototype', 'recruit', 'therapy resistant', 'treatment response', 'tumor', 'tumorigenesis', 'usability']",NCI,"EARLYDIAGNOSTICS, INC.",N43,2021,395918
