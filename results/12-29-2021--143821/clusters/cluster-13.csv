text,title,id,project_number,terms,administration,organization,mechanism,year,award_amount,cong_dist,score
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           ",Development of Speech Perception and Brain Plasticity,8063408,R01HD037954,"['Cues ', ' Acoustics ', ' Acoustic ', ' Commit ', ' Address ', ' Age-Months ', ' Age-Years ', ' Data ', ' Evolution ', ' Characteristics ', ' Process ', ' Development ', ' developmental ', ' Adult ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Future ', ' catalyst ', ' Human ', ' Modern Man ', ' Man (Taxonomy) ', ' Phase ', ' Infant Development ', ' Link ', ' Infant ', ' Newborn Infant ', ' newborn human (0-6 weeks) ', ' Newborns ', ' 0-6 weeks old ', ' Laboratories ', ' Language ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' disability ', ' infancy ', ' infantile ', ' Learning ', ' Individual ', ' Linguistics ', ' Linguistic ', ' Longevity ', ' lifespan ', ' life span ', ' Length of Life ', ' Funding ', ' Magnetoencephalography ', ' Mothers ', ' Neurobiology ', ' neurobiological ', ' Neurosciences ', ' Event-Related Potentials ', ' event related potential ', ' Perception ', ' Phonetics ', ' Play ', ' Exposure to ', ' Psychological Theory ', ' Psychologic Theory ', ' Nature ', ' Research ', ' Research Design ', ' study design ', ' Study Type ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Social Interaction ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Life ', ' Speech ', ' Speech Perception ', ' Television ', ' Testing ', ' Time ', ' Audiotape ', ' Work ', ' Autistic Disorder ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autism ', ' Hour ', ' Pattern ', ' Techniques ', ' Biology ', ' Birth ', ' Parturition ', ' foreign language ', ' relating to nervous system ', ' neural ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' skills ', ' Positioning Attribute ', ' Position ', ' Measures ', ' Child ', ' youngster ', ' children ', ' Children (0-21) ', ' Child Youth ', ' Child Human ', ' 0-11 years old ', ' Child Development ', ' Infant and Child Development ', ' Developmental Disabilities ', ' Child Development Disorders ', ' Modeling ', ' Property ', ' LOINC Axis 2 Property ', ' Speech Development ', ' theories ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' language processing ', ' critical period ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' ']",NICHD,UNIVERSITY OF WASHINGTON,R01,2010,214173,WA-07,0.010422036800854757
"Sensitivity to spectral cues in infant speech perception    DESCRIPTION (provided by applicant): The proposed research will examine infants' sensitivity to multiple spectral cues in speech perception. Speech is a complex signal, with numerous acoustic cues for every consonant and vowel. Through experience, listeners learn to exploit correlations between multiple cues, making perception more efficient and robust. Adults display this knowledge through their use of cues that are spectrally local (e.g. formant transitions) as well as distributed (e.g. gross spectral shape, or tilt) to distinguish speech sounds. Although prior research has demonstrated infants' ability to distinguish many speech sounds, how they distinguish these sounds is unclear. Infants' sensitivity to individual cues, the relative importance they assign to each cue, and when they learn to exploit correlations between cues all remain poorly understood. We propose four experiments to address these questions. The first aim of this project is to investigate sensitivity to spectral cues. To address this issue, the first two experiments will examine speech perception when the natural covariance between two cues is violated or maintained. The latter two experiments will test sensitivity to changes in individual cues. The second aim is to assess relative cue salience across the lifespan. Results from the first experiment will be compared to existing data from normal-hearing and hearing-impaired elderly adult listeners who completed a similar task (Alexander & Kluender, in press; in preparation) to assess differential effects of listening experience and hearing health on perception of the same speech stimuli. We hypothesize that both 6-to-7-month-old and 11-to-12-month-old-infants will exhibit perceptual sensitivity to both spectral cues in speech perception, with 11-to-12-month-olds displaying the greatest sensitivity. We also hypothesize that younger infants may be relatively more influenced by spectrally global (e.g. tilt) cues than older infants. Our long-term objective is to better understand development of speech perception in infants with normal and compromised hearing. These results will help refine treatment methods for infants with hearing loss, and inform the use of devices such as hearing aids and cochlear implants. Public health statement: The proposed research will reveal the acoustic information infants use to distinguish speech sounds, and whether this information is used differently by adults. Knowing what infants listen for will benefit efforts to facilitate development of speech perception in children with compromised hearing. This research will also investigate when infants learn to exploit statistical regularities between cues in natural speech.             ",Sensitivity to spectral cues in infant speech perception,7860410,F31DC009532,"['Cues ', ' Acoustics ', ' Acoustic ', ' hearing impairment ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Environment ', ' Address ', ' Data ', ' Resolution ', ' Preparation ', ' Development ', ' developmental ', ' Exhibits ', ' Adult ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Affect ', ' Age ', ' base ', ' Elderly ', ' senior citizen ', ' over 65 Elderly ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', ' Aged 65 and Over ', ' Goals ', ' Health ', ' Hearing ', ' sound perception ', ' hearing perception ', ' Hearing Aids ', ' Sensorineural Hearing Loss ', ' Sensory Hearing Loss ', ' Sensorineural Deafness ', ' Infant ', ' infancy ', ' infantile ', ' Learning ', ' Stimulus ', ' Light ', ' Photoradiation ', ' Individual ', ' Longevity ', ' lifespan ', ' life span ', ' Length of Life ', ' Methods ', ' Perception ', ' Shapes ', ' public health medicine (field) ', ' Public Health ', ' Recruitment Activity ', ' recruit ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' Testing ', ' Voice ', ' Weight ', ' Frequencies (time pattern) ', ' Frequency ', ' Complex ', ' Sensory ', ' System ', ' LOINC Axis 4 System ', ' Body Weight Changes ', ' Weight Change ', ' experience ', ' research study ', ' experimental study ', ' experimental research ', ' experiment ', ' Modality ', ' Devices ', ' Relative (related person) ', ' Relative ', ' Child ', ' youngster ', ' children ', ' Children (0-21) ', ' Child Youth ', ' Child Human ', ' 0-11 years old ', ' response ', ' Cochlear Implants ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Population ', ' Conflict (Psychology) ', ' Conflict ', ' ']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2010,27620,WI-02,0.06690945236996561
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           ",Development of Speech Perception and Brain Plasticity,7768396,R01HD037954,"['Cues ', ' Acoustics ', ' Acoustic ', ' Commit ', ' Address ', ' Age-Months ', ' Age-Years ', ' Data ', ' Evolution ', ' Characteristics ', ' Process ', ' Development ', ' developmental ', ' Adult ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Future ', ' catalyst ', ' Human ', ' Modern Man ', ' Man (Taxonomy) ', ' Phase ', ' Infant Development ', ' Link ', ' Infant ', ' Newborn Infant ', ' newborn human (0-6 weeks) ', ' Newborns ', ' 0-6 weeks old ', ' Laboratories ', ' Language ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' disability ', ' infancy ', ' infantile ', ' Learning ', ' Individual ', ' Linguistics ', ' Linguistic ', ' Longevity ', ' lifespan ', ' life span ', ' Length of Life ', ' Funding ', ' Magnetoencephalography ', ' Mothers ', ' Neurobiology ', ' neurobiological ', ' Neurosciences ', ' Event-Related Potentials ', ' event related potential ', ' Perception ', ' Phonetics ', ' Play ', ' Exposure to ', ' Psychological Theory ', ' Psychologic Theory ', ' Nature ', ' Research ', ' Research Design ', ' study design ', ' Study Type ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Social Interaction ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Life ', ' Speech ', ' Speech Perception ', ' Television ', ' Testing ', ' Time ', ' Audiotape ', ' Work ', ' Autistic Disorder ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autism ', ' Hour ', ' Pattern ', ' Techniques ', ' Biology ', ' Birth ', ' Parturition ', ' foreign language ', ' relating to nervous system ', ' neural ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' skills ', ' Positioning Attribute ', ' Position ', ' Measures ', ' Child ', ' youngster ', ' children ', ' Children (0-21) ', ' Child Youth ', ' Child Human ', ' 0-11 years old ', ' Child Development ', ' Infant and Child Development ', ' Developmental Disabilities ', ' Child Development Disorders ', ' Modeling ', ' Property ', ' LOINC Axis 2 Property ', ' Speech Development ', ' theories ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' language processing ', ' critical period ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' ']",NICHD,UNIVERSITY OF WASHINGTON,R01,2010,530965,WA-07,0.010422036800854757
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          ",Intonation in spontaneous English & Japanese dialogue,8100589,R01DC007090,"['Linguistics ', ' Linguistic ', ' Memory ', ' Methodology ', ' Method LOINC Axis 6 ', ' Names ', ' Therapeutic ', ' Patients ', ' Phonetics ', ' Production ', ' Psycholinguistics ', ' Psycholinguistic ', ' Reading ', ' Nature ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Knowledge ', ' programs ', ' Speech ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' cognitive function ', ' Technology ', ' Testing ', ' Attention ', ' Vocabulary ', ' Vocabulary Words ', ' Writing ', ' Complex ', ' Pattern ', ' System ', ' LOINC Axis 4 System ', ' Performance ', ' syntax ', ' syntactic ', ' phonology ', ' phonological ', ' phrases ', ' Structure ', ' novel ', ' research study ', ' experimental study ', ' experimental research ', ' experiment ', ' Devices ', ' Reporting ', ' Generations ', ' Measures ', ' Modeling ', ' oral communication ', ' Property ', ' LOINC Axis 2 Property ', ' theories ', ' Cochlear Implants ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Accounting ', ' Communication ', ' Communication Aids for Disabled ', ' communication disorder aid ', ' communication device ', ' Communication Aids for Handicapped ', ' Instruction ', ' efficacy research ', ' Population ', ' clinical application ', ' clinical applicability ', ' language processing ', ' lexical ', ' speech accuracy ', ' accurate speech ', ' Cues ', ' Acoustics ', ' Acoustic ', ' Diagnosis ', ' Educational aspects ', ' Education ', ' Engineering ', ' Address ', ' Cognitive ', ' Collection ', ' Monitor ', ' transmission process ', ' Transmission ', ' Characteristics ', ' Process ', ' Development ', ' developmental ', ' Eye Movements ', ' Comprehension ', ' Future ', ' base ', ' Goals ', ' improved ', ' Head ', ' Hearing ', ' sound perception ', ' hearing perception ', ' Human ', ' Modern Man ', ' Man (Taxonomy) ', ' Specific qualifier value ', ' Specified ', ' Link ', ' Japanese Population ', ' Japanese ', ' Language ', ' disability ', ' Lead ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' aphasic ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2010,211698,OH-03,-0.01070562628064758
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           ",Development of Speech Perception and Brain Plasticity,8044743,R01HD037954,"['Age-Years ', ' Knowledge ', ' Pattern ', ' Property ', ' LOINC Axis 2 Property ', ' Characteristics ', ' Acoustics ', ' Acoustic ', ' Life ', ' Speech ', ' Funding ', ' Modeling ', ' Development ', ' developmental ', ' Individual ', ' Linguistics ', ' Linguistic ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Child Development ', ' Infant and Child Development ', ' Phonetics ', ' Event-Related Potentials ', ' event related potential ', ' critical period ', ' Television ', ' Infant Development ', ' Magnetoencephalography ', ' foreign language ', ' Speech Development ', ' catalyst ', ' Audiotape ', ' speech processing ', ' Psychological Theory ', ' Psychologic Theory ', ' Infant ', ' Process ', ' Evolution ', ' Measures ', ' Link ', ' Hour ', ' theories ', ' Future ', ' Developmental Disabilities ', ' Child Development Disorders ', ' disability ', ' Exposure to ', ' Biology ', ' Human ', ' Modern Man ', ' Man (Taxonomy) ', ' Time ', ' Cues ', ' Role ', ' social role ', ' Research ', ' Birth ', ' Parturition ', ' Data ', ' Neurobiology ', ' neurobiological ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Nature ', ' relating to nervous system ', ' neural ', ' Learning ', ' design ', ' designing ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Testing ', ' Play ', ' Child ', ' youngster ', ' children ', ' Children (0-21) ', ' Child Youth ', ' Child Human ', ' 0-11 years old ', ' Speech Perception ', ' Mothers ', ' Longevity ', ' lifespan ', ' life span ', ' Length of Life ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Techniques ', ' Address ', ' Newborn Infant ', ' newborn human (0-6 weeks) ', ' Newborns ', ' 0-6 weeks old ', ' Positioning Attribute ', ' Position ', ' Work ', ' Adult ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Laboratories ', ' Phase ', ' skills ', ' Perception ', ' infancy ', ' infantile ', ' Age-Months ', ' language processing ', ' Social Interaction ', ' Neurosciences ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Commit ', ' Language ', ' Intervention Studies ', ' interventions research ', ' intervention research ', ' Autistic Disorder ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autism ', ' ']",NICHD,UNIVERSITY OF WASHINGTON,R01,2011,526418,WA-07,0.010422036800854757
"Speech Therapy Robot (STR) to assist in the administration of evidence based spee    DESCRIPTION (provided by applicant): This SBIR phase I project will develop a Speech Therapy Robot (STR) to assist in the administration of evidence-based speech and language therapy to provide individualized monitoring of multiple clients simultaneously in a school setting. STR will use biologically plausible artificial intelligence models to prototype a system that is affordable, easy to use, portable and extensible to work with any number of students (clients) with disorder. Most children make some mistakes as they learn to say new words, but a speech sound disorder results when mistakes continue past a certain age. Speech sound disorders include problems with articulation (making sounds) and phonological processes (sound patterns), and it is one of the largest disabilities in the United States. Children with speech disorders are evaluated by a speech-language pathologist (SLP) and treated via speech-language intervention within the child's classroom (classroom-based) or outside of the classroom (pull-out). Multiple studies have demonstrated that classroom-based service is beneficial over pull- out service, but currently it is not widely practiced because of the many challenges facing SLPs: 1) it requires collaboration with classroom teachers and administrators who are not trained in speech-language pathology, 2) it can create a larger client-SLP ratio, 3) a small client-nonclient student in-class ratio, 4) unable to provide adequate intervention, 5) there is a large variation in severity of disorder within clients, 6) longer session hours over pull-out service. The American Speech-Language-Hearing Association (ASHA) recommendations caseloads should not exceed 40, but the median caseload is 50 in elementary and secondary schools, with high of 80 clients. This heavy workload for an SLP limits their capacity to provide effective treatment. Thus a robotic system capable of reducing the workload and assisting SLPs to provide improved individual care is highly desired by those in this field. In this Phase I SBIR, we will develop novel biologically plausible models to address these challenges by developing a robot-assisted therapy system capable of real time monitoring and assessment of client and client-provider interaction during the session, to determine client engagement, performance and to give feedback to providers in real time for improved treatment delivery. The biological models attempt to mimic the expert diagnostic capabilities of a SLP and extend it for use by non-SLPs to work with multiple clients at the same time. The solution will not require specialized training to use, allowing teachers to easily use it in their classrooms. In Phase I, we will demonstrate the feasibility and accuracy of STR. STR is not just a minor improvement over existing technologies but a technology and application that do not exist today. In Phase II, we will extend the capabilities towards a fully biologically plausible system to mimic expert human performance levels to develop a robotic system for speech-language therapy, this will be followed by clinical trials to ensure accuracy, efficacy of STR to facilitate evidence-based therapy. Variations of the system can be used towards phonology, morphology/syntax, pragmatics, language, fluency and/or vocabulary.      PUBLIC HEALTH RELEVANCE: Overall the project provides direct relevance to public health by facilitating new insights through the development of a novel biologically plausible artificial intelligence system capable of real time monitoring and assessment of verbal therapy session content in real time to determine patient engagement, performance and give feedback to providers in real time to improve treatment delivery, in a school setting. The novel biologically plausible device will significantly impact the current known methods of in classroom evaluation, monitoring and treatment of speech disorders. The project can help in substantial improvement in patient client interaction, better treatment, lower burden on speech language pathologists, and will significantly impact the current known methods, technologies, treatments, and address critical barriers to progress in the field.           Overall the project provides direct relevance to public health by facilitating new insights through the development of a novel biologically plausible artificial intelligence system capable of real time monitoring and assessment of verbal therapy session content in real time to determine patient engagement, performance and give feedback to providers in real time to improve treatment delivery, in a school setting. The novel biologically plausible device will significantly impact the current known methods of in classroom evaluation, monitoring and treatment of speech disorders. The project can help in substantial improvement in patient client interaction, better treatment, lower burden on speech language pathologists, and will significantly impact the current known methods, technologies, treatments, and address critical barriers to progress in the field.         ",Speech Therapy Robot (STR) to assist in the administration of evidence based spee,8207025,R43LM011325,"['Administrator ', ' Vocabulary Words ', ' Vocabulary ', ' elementary school ', ' Workload ', ' Work Load ', ' Early identification ', ' Auditory system ', ' Phonetics ', ' Florida ', ' biological systems ', ' Speech ', ' Voice ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' Pathologist ', ' robotic assistance ', ' robot assisted ', ' robot assistance ', ' Machine Intelligence ', ' Computer Reasoning ', ' Artificial Intelligence ', ' Cerebellum ', ' Client ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' Cognitive ', ' Solutions ', ' Ensure ', ' Patients ', ' improved ', ' Monitor ', ' liquid ', ' fluid ', ' Liquid substance ', ' Technology ', ' Modeling ', ' Age ', ' Recommendation ', ' United States ', ' Phase ', ' innovative ', ' innovate ', ' innovation ', ' Language Therapy ', ' clinical investigation ', ' Clinical Trials ', ' Public Health ', ' public health medicine (field) ', ' Impairment ', ' youngster ', ' children ', ' Children (0-21) ', ' Child Youth ', ' Child Human ', ' 0-11 years old ', ' Child ', ' Future ', ' LOINC Axis 4 System ', ' System ', ' Process ', ' designing ', ' design ', ' Performance ', ' interventional strategy ', ' Intervention Strategies ', ' Intervention ', ' Goals ', ' Schools ', ' insight ', ' Caring ', ' Work ', ' Variation ', ' Variant ', ' novel ', ' Area ', ' Pattern ', ' Engineering ', ' phonological ', ' phonology ', ' Feedback ', ' Therapeutic ', ' Learning ', ' Environment ', ' Training ', ' Diagnosis ', ' Affect ', ' Collaborations ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Structure ', ' disease/disorder ', ' Disorder ', ' Disease ', ' base ', ' Evaluation ', ' success ', ' Universities ', ' Services ', ' sound ', ' Address ', ' cost ', ' Small Business Innovation Research ', ' SBIRS (R43/44) ', ' SBIR ', ' Small Business Innovation Research Grant ', ' teacher ', ' neural model ', ' Provider ', ' Methods ', ' Individual ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' developmental ', ' Development ', ' Time ', ' Techniques ', ' preventing ', ' prevent ', ' Running ', ' evidence base ', ' Modality ', ' Severities ', ' prototype ', ' Minor ', ' Language ', ' Articulation ', ' Joints ', ' Diagnostic ', ' Source ', ' disability ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' Morphology ', ' effective treatment ', ' effective therapy ', ' Hour ', ' Robotics ', ' Algorithms ', ' Students ', ' Memory ', ' professor ', ' intervention therapy ', ' Therapeutic Intervention ', ' Devices ', ' Testred ', ' Testovis ', ' Testotonic B ', ' Testomet ', ' Oreton methyl ', ' Orchisterone-M ', ' Neohombreol M ', ' Metandren ', ' Malogen ', ' Estratest ', ' Ero Test ', ' Eldec ', ' Android ', ' Glosso-Sterandryl ', ' Snapdragon ', ' Antirrhinum ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Therapy ', ' American Speech-Language-Hearing Association ', ' Secondary Schools ', ' syntactic ', ' syntax ', ' Robot ', ' Speech Sound ', ' Accent ', ' Speech-Language Pathology ', ' Language Pathology ', ' speech processing ', ' ']",NLM,"AVENTUSOFT, LLC",R43,2011,95949,FL-22,0.12656103638851587
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.        PUBLIC HEALTH RELEVANCE: One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.              One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8282659,R01DC003172,"['bear ', ' Ursidae ', ' Bears ', ' Ursidae Family ', ' Behavior ', ' Acoustic ', ' Acoustics ', ' Articulators ', ' Engineering ', ' Gestures ', ' Environment ', ' Grant ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Communication ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Conceptions ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' Articulation ', ' Joints ', ' Language ', ' Linguistic ', ' Linguistics ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' In element ', ' Indium ', ' Learning ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Production ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' Speech ', ' body movement ', ' Movement ', ' Patients ', ' Reading ', ' Research ', ' base ', ' Phase ', ' Loudness ', ' Clinical ', ' Time ', ' Work ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' cognitive function ', ' Complex ', ' programs ', ' Source ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Shapes ', ' Pattern ', ' Techniques ', ' Stream ', ' Investigation ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' Evaluation ', ' Simulate ', ' sorting ', ' Sorting - Cell Movement ', ' LOINC Axis 2 Property ', ' Property ', ' Modeling ', ' syntactic ', ' syntax ', ' kinematics ', ' Participant ', ' phrases ', ' speech disorder diagnosis ', ' speech recognition ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Structure ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Nervous System Trauma ', ' LOINC Axis 4 System ', ' System ', ' Process ', ' Cognitive ', ' Characteristics ', ' Address ', ' Interruption ', ' Data ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' constriction ', ' spatiotemporal ', ' Affective ', ' Population ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2012,549459,CA-37,0.34935968375195414
"Applying Computational Linguistics to Fundamental Components of Schizophrenia     DESCRIPTION (provided by applicant): Schizophrenia is a uniquely human disorder with specific effects on the uniquely human capacity of language. Indeed, the gross and subtle language abnormalities of schizophrenia can be seen as fundamental illness components, perhaps even as part of a ""biosignature."" Bringing modern linguistics knowledge and tools to this disorder is a promising approach. We have formed a unique, inter-disciplinary collaboration (Dr. Compton, a schizophrenia researcher; Dr. Covington, a computational linguist; Dr. Lunden, a linguist specializing in phonetics; Dr. Cleary, a statistician; and Dr. Blanchard, an expert in measuring negative symptoms) to study some of the most perplexing and disabling facets of schizophrenia, the language/speech abnormalities linked closely to disorganization and negative symptoms. We will analyze speech abnormalities in patients with schizophrenia and unaffected controls. Rather than examining a single linguistic parameter, we will assess speech in ""syntactic,"" ""semantic,"" ""pragmatic,"" and ""phonetic"" domains of linguistics. We will introduce cutting- edge innovation to this area of study by assessing these indices using psycholinguistics software developed by Dr. Covington's group so that our ratings of speech abnormalities will be highly objective and ultra-reliable.  Our long-term goal is to develop multivariable models, and new methods for clinical and research settings, based on computational linguistic indices with inherent reliability from automation and proven validity. In this exploratory/developmental study, we will collect detailed symptom ratings from 100 schizophrenia patients, as well as audio-recorded speech samples and neurocognition scores from these patients and 100 controls. This study involves early/conceptual stages of new tools and models that could have a major translational impact. We strive to acquire new knowledge and then put it into action. For example, our new methods could translate into advanced clinical applications (e.g., highly reliable, voice-based monitoring of symptom progression or remission). Furthermore, our new models and methods could be a first step toward promising predictive models (e.g., combinations of factors useful in risk prediction among at-risk youth). These objectives are highly aligned with the NIMH Strategic Plan. Our 4 aims are to: (1) examine syntactic, semantic, and pragmatic linguistic parameters using computer analysis of speech, and assess their relation to disorganized symptoms; (2) examine phonetic linguistic parameters using computerized Fourier spectrum analysis of speech, and assess their relation to negative symptoms; (3) determine the combination of psycholinguistic parameters that best predicts patient versus control status; and (4) determine the combination of psycholinguistic parameters that best predicts disorganization scores and negative symptom scores among patients. Given the rich data we will collect, we will also be able to covary the effects of medication and substance use; examine variation in findings based on neutral v. emotionally laden content and spontaneous v. read speech; assess variance in linguistic measures attributable to cognitive domains; and compare results in first-episode and chronic patients.         PUBLIC HEALTH RELEVANCE: Schizophrenia is an etiologically complex, heterogeneous mental disorder-ranking among the top 10 causes of disability worldwide-with those affected contending with troubling symptoms, major psychosocial problems, unparalleled societal stigma, health disparities, diverse comorbidities, and an average lifespan reduction of 25 years. We propose a study that would significantly advance knowledge of fundamental but under-studied components of the illness-speech/language abnormalities-by examining a broad array of linguistic indices using cutting-edge artificial intelligence (computational linguistics, or computrs objectively, quickly, and ultra- reliably analyzing speech). This exploratory/developmental work could have major public health significance in terms of potential for future, high-impact clinical assessment tools that can be practicably used in routine practice settings, as well as future predictive models for those at high risk of developing schizophrenia.            ",Applying Computational Linguistics to Fundamental Components of Schizophrenia,8512143,R21MH097999,"['Acoustic ', ' Acoustics ', ' Affect ', ' senile dementia of the Alzheimer type ', ' primary degenerative dementia ', ' dementia of the Alzheimer type ', ' Primary Senile Degenerative Dementia ', ' Alzheimers disease ', ' Alzheimers Dementia ', "" Alzheimer's "", ' Alzheimer syndrome ', ' Alzheimer sclerosis ', ' Alzheimer disease ', ' Alzheimer Type Dementia ', ' Alzheimer ', "" Alzheimer's Disease "", ' Machine Intelligence ', ' Computer Reasoning ', ' Artificial Intelligence ', ' Automation ', ' Dorsum ', ' Back ', ' psychological disorder ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Clinical Study ', ' Clinical Research ', ' Cognition ', ' co-morbidity ', ' Comorbidity ', ' Complement Proteins ', ' Complement ', ' Computers ', ' Discriminant Analyses ', ' Discriminant Analysis ', ' disease/disorder ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Exhibits ', ' Future ', ' Goals ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' indexing ', ' Language ', ' Linear Regressions ', ' Linguistic ', ' Linguistics ', ' lifespan ', ' life span ', ' Length of Life ', ' Longevity ', ' Methods ', ' Method LOINC Axis 6 ', ' Methodology ', ' body movement ', ' Movement ', ' National Institute of Mental Health ', ' NIMH ', ' National Institute of Mental Health (U.S.) ', ' neurobiological ', ' Neurobiology ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Lewy Body Parkinson Disease ', ' Idiopathic Parkinson Disease ', ' Parkinson Disease ', ' Patients ', ' Phonetics ', ' Psycholinguistic ', ' Psycholinguistics ', ' Public Health ', ' public health medicine (field) ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Risk ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' Semantics ', ' Sensitivity and Specificity ', ' computer program/software ', ' Software ', ' Computer software ', ' Sound Sonography ', ' Sound Spectrography ', ' Spectrum Analyses ', ' Spectroscopy ', ' Spectrum Analysis ', ' Speech ', ' Substance Use Disorder ', ' thoughts ', ' Thinking ', ' Thinking, function ', ' Tongue ', ' Translating ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' Gender ', ' Measures ', ' Youth 10-21 ', ' Youth ', ' base ', ' density ', ' Area ', ' Chronic ', ' Clinical ', ' Variation ', ' Variant ', ' Link ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' disability ', ' using substances ', ' substance use ', ' AOD use ', ' Alcohol or Other Drugs use ', ' Collaborations ', ' Staging ', ' tool ', ' Knowledge ', ' Complex ', ' Techniques ', ' Neurocognitive ', ' psychosocial ', ' Remission ', ' Disease remission ', ' syntactic ', ' syntax ', ' Position ', ' Positioning Attribute ', ' Modeling ', ' Sampling ', ' stigma ', ' social stigma ', ' developing computer software ', ' develop software ', ' software development ', ' health disparities ', ' health disparity ', ' SKAP55R ', ' SKAP-HOM ', ' SCAP2 ', ' SAPS ', ' RA70 ', ' SCAP2 gene ', ' Address ', ' Symptoms ', ' Data ', ' Measurable ', ' Predictive Value ', ' Strategic Planning ', ' Clinical Assessment Tool ', ' Cognitive ', ' computational analysis ', ' Computer Analysis ', ' exploratory developmental study ', ' R21 Program ', ' R21 Mechanism ', ' Exploratory/Developmental Grant ', ' Monitor ', ' developmental ', ' Development ', ' Behavioral ', ' neglect ', ' computerized ', ' computer based prediction ', ' predictive modeling ', ' designing ', ' design ', ' IQ Deficit ', ' Neurocognitive Deficit ', ' Clinical assessments ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' clinical applicability ', ' clinical application ', ' Neurocognition ', ' lexical ', ' high risk ', ' public health relevance ', ' treatment response ', ' routine practice ', ' biosignature ', ' biomarker ', ' biologic marker ', ' Biological Markers ', ' ']",NIMH,GEORGE WASHINGTON UNIVERSITY,R21,2013,249349,DC-98,0.13526261079890395
"Video-based Speech Enhancement for Persons with Vision and Hearing Loss     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Persons with Vision and Hearing Loss,8443624,R21EY022200,"['Accounting ', ' Acoustic ', ' Acoustics ', ' functional capacity ', ' functional ability ', ' daily living functionality ', ' Activities of everyday life ', ' Activities of Daily Living ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' Age ', ' senior citizen ', ' over 65 Elderly ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', ' Aged 65 and Over ', ' Elderly ', ' Algorithms ', ' Amplifiers ', ' Communication ', ' computer vision ', ' Computer Vision Systems ', ' Cues ', ' Digital Signal Processing ', ' Environment ', ' face expression ', ' Facial Expression ', ' Feedback ', ' Grant ', ' Hearing Aids ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Laboratories ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Learning ', ' Lip ', ' Lip structure ', ' Literature ', ' Methods ', ' Persons ', ' Noise ', ' Play ', ' age related hearing loss ', ' Presbycusis ', ' QOL ', ' Quality of life ', ' Research ', ' social role ', ' Role ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' Sensory Aids ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Societies ', ' sound ', ' Speech ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech Perception ', ' Testing ', ' Time ', ' United States ', ' visual function ', ' Sight ', ' Vision ', ' visually impaired ', ' Subnormal Vision ', ' Reduced Vision ', ' Partial Sight ', ' Low Vision ', ' Diminished Vision ', ' Visual impairment ', ' Voice ', ' Measures ', ' Comprehension ', ' base ', ' improved ', ' Area ', ' Visual ', ' Staging ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' Auditory ', ' Dependence ', ' Sensory ', ' Source ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' Location ', ' visual loss ', ' vision loss ', ' Blindness ', ' interest ', ' Performance ', ' speech recognition ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Modality ', ' Devices ', ' social ', ' Modeling ', ' performance tests ', ' signal processing ', ' data processing ', ' computerized data processing ', ' Effectiveness ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' hearing impairment ', ' Address ', ' Age-Years ', ' Aging Process ', ' Aging-Related Process ', ' Detection ', ' Process ', ' developmental ', ' Development ', ' Output ', ' designing ', ' design ', ' new approaches ', ' novel strategy ', ' novel approaches ', ' novel strategies ', ' Population ', ' tool development ', ' prototype ', ' visual information ', ' public health relevance ', ' ']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2013,198801,CA-12,0.1084158491578475
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.          One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8445225,R01DC003172,"['Acoustic ', ' Acoustics ', ' Articulators ', ' bear ', ' Ursidae ', ' Bears ', ' Ursidae Family ', ' Behavior ', ' Communication ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Conceptions ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Engineering ', ' Environment ', ' Gestures ', ' Grant ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' In element ', ' Indium ', ' Articulation ', ' Joints ', ' Language ', ' Learning ', ' Linguistic ', ' Linguistics ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' body movement ', ' Movement ', ' Patients ', ' Production ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Time ', ' Work ', ' base ', ' Loudness ', ' Clinical ', ' Phase ', ' Evaluation ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' Simulate ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' programs ', ' cognitive function ', ' Investigation ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' speech disorder diagnosis ', ' speech recognition ', ' syntactic ', ' syntax ', ' kinematics ', ' phrases ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' sorting ', ' Sorting - Cell Movement ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Nervous System Trauma ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Interruption ', ' Cognitive ', ' Characteristics ', ' Process ', ' new approaches ', ' novel strategy ', ' novel approaches ', ' novel strategies ', ' Population ', ' Affective ', ' spatiotemporal ', ' constriction ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2013,450674,CA-37,0.3542326839502915
"Longitudinal Voice Patterns in Bipolar Disorder     DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable.         PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.                ",Longitudinal Voice Patterns in Bipolar Disorder,8494970,R34MH100404,"['Acoustic ', ' Acoustics ', ' Algorithms ', ' Anxiety Disorders ', ' Behavior ', ' psychological disorder ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' manic depressive illness ', ' manic depressive disorder ', ' bipolar affective disorder ', ' Manic-Depressive Psychosis ', ' Bipolar Affective Psychosis ', ' Bipolar Disorder ', ' Charge ', ' Clinical Study ', ' Clinical Research ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Computers ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Data Collection ', ' depression ', ' Mental Depression ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Emotions ', ' environmental testing ', ' Ecological Monitoring ', ' Ecologic Monitoring ', ' Environmental Monitoring ', ' Future ', ' Goals ', ' Health ', ' History ', ' Recording of previous events ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Interview ', ' long-term study ', ' Longitudinal Studies ', ' Moods ', ' body movement ', ' Movement ', ' Observer Bias ', ' Observer Variation ', ' Patients ', ' Perception ', ' Rhythmicity ', ' Cyclicity ', ' Periodicity ', ' Personality ', ' pressure ', ' abnormal psychology ', ' Psychopathology ', ' Psychoses ', ' Psychotic Disorders ', ' recruit ', ' Recruitment Activity ', ' Solutions ', ' Speech ', ' Speech Acoustics ', ' statistics ', ' Stress ', ' Technology ', ' Phone ', ' Telephone ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' base ', ' Loudness ', ' psychiatric treatment ', ' psychiatric therapy ', ' psychiatric care ', ' Psychiatric therapeutic procedure ', ' Clinical ', ' Phase ', ' Variation ', ' Variant ', ' Medical ', ' psychological ', ' psychologic ', ' insight ', ' Individual ', ' mental status ', ' mental state ', ' Shapes ', ' tool ', ' Manic State ', ' Manias ', ' Manic ', ' sadness ', ' depressed ', ' Depressed mood ', ' instrument ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Frequency ', ' Frequencies (time pattern) ', ' Sensory ', ' Pattern ', ' Neurocognitive ', ' Affective Disorders ', ' Mood Disorders ', ' early detection ', ' Early Diagnosis ', ' heuristics ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Prevention ', ' Devices ', ' Emotional ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' interventional strategy ', ' Intervention Strategies ', ' Intervention ', ' Accent ', ' Cellular Telephone ', ' Cell Phone ', ' Cellular Phone ', ' Mobile Phones ', ' Car Phone ', ' Address ', ' Data ', ' Detection ', ' Measurable ', ' Motor ', ' Cognitive ', ' Pattern Recognition ', ' Monitor ', ' Characteristics ', ' Process ', ' digital ', ' markov model ', ' Clinical assessments ', ' Outcome ', ' Hamilton Depression Scale ', ' HAM-D ', ' Hamilton Rating Scale for Depression ', ' Population ', ' innovative ', ' innovate ', ' innovation ', ' clinical significance ', ' clinically significant ', ' computer algorithm ', ' Computational algorithm ', ' speech processing ', ' lexical ', ' public health relevance ', ' Secure ', ' ']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2013,272125,MI-12,0.27717032118557206
"Video-based Speech Enhancement for Vision and Hearing Impairment     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Vision and Hearing Impairment,8659442,R21EY022200,"['Accounting ', ' Acoustic ', ' Acoustics ', ' functional capacity ', ' functional ability ', ' daily living functionality ', ' Activities of everyday life ', ' Activities of Daily Living ', ' adulthood ', ' adult human (21+) ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' Age ', ' senior citizen ', ' over 65 Elderly ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', ' Aged 65 and Over ', ' Elderly ', ' Algorithms ', ' Amplifiers ', ' Communication ', ' computer vision ', ' Computer Vision Systems ', ' Cues ', ' Digital Signal Processing ', ' Environment ', ' face expression ', ' Facial Expression ', ' Feedback ', ' Grant ', ' Hearing Aids ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Laboratories ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Learning ', ' Lip ', ' Lip structure ', ' Literature ', ' Methods ', ' Persons ', ' Noise ', ' Play ', ' age related hearing loss ', ' Presbycusis ', ' QOL ', ' Quality of life ', ' Research ', ' social role ', ' Role ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' Sensory Aids ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Societies ', ' sound ', ' Speech ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech Perception ', ' Testing ', ' Time ', ' United States ', ' visual function ', ' Sight ', ' Vision ', ' visually impaired ', ' Subnormal Vision ', ' Reduced Vision ', ' Partial Sight ', ' Low Vision ', ' Diminished Vision ', ' Visual impairment ', ' Voice ', ' Measures ', ' Comprehension ', ' base ', ' improved ', ' Area ', ' Visual ', ' Staging ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' Auditory ', ' Dependence ', ' Sensory ', ' Source ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' Location ', ' visual loss ', ' vision loss ', ' Blindness ', ' interest ', ' Performance ', ' speech recognition ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Modality ', ' Devices ', ' social ', ' Modeling ', ' performance tests ', ' Effectiveness ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' hearing impairment ', ' Address ', ' Age-Years ', ' Aging Process ', ' Aging-Related Process ', ' Detection ', ' Process ', ' developmental ', ' Development ', ' Output ', ' designing ', ' design ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' Population ', ' tool development ', ' prototype ', ' visual information ', ' public health relevance ', ' signal processing ', ' ']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2014,230945,CA-12,0.1112475590507262
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.          One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8643200,R01DC003172,"['Acoustic ', ' Acoustics ', ' Articulators ', ' bear ', ' Ursidae ', ' Bears ', ' Ursidae Family ', ' Behavior ', ' Communication ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Conceptions ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Engineering ', ' Environment ', ' Gestures ', ' Grant ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' In element ', ' Indium ', ' Articulation ', ' Joints ', ' Language ', ' Learning ', ' Linguistic ', ' Linguistics ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' body movement ', ' Movement ', ' Patients ', ' Production ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Time ', ' Work ', ' base ', ' Loudness ', ' Clinical ', ' Phase ', ' Evaluation ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' Simulate ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' programs ', ' cognitive function ', ' Investigation ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' speech disorder diagnosis ', ' speech recognition ', ' syntactic ', ' syntax ', ' kinematics ', ' phrases ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' sorting ', ' Sorting - Cell Movement ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Nervous System Trauma ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Interruption ', ' Cognitive ', ' Characteristics ', ' Process ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' Population ', ' Affective ', ' spatiotemporal ', ' constriction ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2014,475459,CA-37,0.3542326839502915
"Applying Computational Linguistics to Fundamental Components of Schizophrenia DESCRIPTION (provided by applicant): Schizophrenia is a uniquely human disorder with specific effects on the uniquely human capacity of language. Indeed, the gross and subtle language abnormalities of schizophrenia can be seen as fundamental illness components, perhaps even as part of a ""biosignature."" Bringing modern linguistics knowledge and tools to this disorder is a promising approach. We have formed a unique, inter-disciplinary collaboration (Dr. Compton, a schizophrenia researcher; Dr. Covington, a computational linguist; Dr. Lunden, a linguist specializing in phonetics; Dr. Cleary, a statistician; and Dr. Blanchard, an expert in measuring negative symptoms) to study some of the most perplexing and disabling facets of schizophrenia, the language/speech abnormalities linked closely to disorganization and negative symptoms. We will analyze speech abnormalities in patients with schizophrenia and unaffected controls. Rather than examining a single linguistic parameter, we will assess speech in ""syntactic,"" ""semantic,"" ""pragmatic,"" and ""phonetic"" domains of linguistics. We will introduce cutting- edge innovation to this area of study by assessing these indices using psycholinguistics software developed by Dr. Covington's group so that our ratings of speech abnormalities will be highly objective and ultra-reliable.  Our long-term goal is to develop multivariable models, and new methods for clinical and research settings, based on computational linguistic indices with inherent reliability from automation and proven validity. In this exploratory/developmental study, we will collect detailed symptom ratings from 100 schizophrenia patients, as well as audio-recorded speech samples and neurocognition scores from these patients and 100 controls. This study involves early/conceptual stages of new tools and models that could have a major translational impact. We strive to acquire new knowledge and then put it into action. For example, our new methods could translate into advanced clinical applications (e.g., highly reliable, voice-based monitoring of symptom progression or remission). Furthermore, our new models and methods could be a first step toward promising predictive models (e.g., combinations of factors useful in risk prediction among at-risk youth). These objectives are highly aligned with the NIMH Strategic Plan. Our 4 aims are to: (1) examine syntactic, semantic, and pragmatic linguistic parameters using computer analysis of speech, and assess their relation to disorganized symptoms; (2) examine phonetic linguistic parameters using computerized Fourier spectrum analysis of speech, and assess their relation to negative symptoms; (3) determine the combination of psycholinguistic parameters that best predicts patient versus control status; and (4) determine the combination of psycholinguistic parameters that best predicts disorganization scores and negative symptom scores among patients. Given the rich data we will collect, we will also be able to covary the effects of medication and substance use; examine variation in findings based on neutral v. emotionally laden content and spontaneous v. read speech; assess variance in linguistic measures attributable to cognitive domains; and compare results in first-episode and chronic patients. PUBLIC HEALTH RELEVANCE: Schizophrenia is an etiologically complex, heterogeneous mental disorder-ranking among the top 10 causes of disability worldwide-with those affected contending with troubling symptoms, major psychosocial problems, unparalleled societal stigma, health disparities, diverse comorbidities, and an average lifespan reduction of 25 years. We propose a study that would significantly advance knowledge of fundamental but under-studied components of the illness-speech/language abnormalities-by examining a broad array of linguistic indices using cutting-edge artificial intelligence (computational linguistics, or computrs objectively, quickly, and ultra- reliably analyzing speech). This exploratory/developmental work could have major public health significance in terms of potential for future, high-impact clinical assessment tools that can be practicably used in routine practice settings, as well as future predictive models for those at high risk of developing schizophrenia.",Applying Computational Linguistics to Fundamental Components of Schizophrenia,8792658,R21MH097999,"['Acoustic ', ' Acoustics ', ' Affect ', ' senile dementia of the Alzheimer type ', ' primary degenerative dementia ', ' dementia of the Alzheimer type ', ' Primary Senile Degenerative Dementia ', ' Alzheimers disease ', ' Alzheimers Dementia ', "" Alzheimer's "", ' Alzheimer syndrome ', ' Alzheimer sclerosis ', ' Alzheimer disease ', ' Alzheimer Type Dementia ', ' Alzheimer ', "" Alzheimer's Disease "", ' Machine Intelligence ', ' Computer Reasoning ', ' Artificial Intelligence ', ' Automation ', ' Dorsum ', ' Back ', ' psychological disorder ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Clinical Study ', ' Clinical Research ', ' Cognition ', ' co-morbidity ', ' Comorbidity ', ' Complement Proteins ', ' Complement ', ' Computers ', ' Discriminant Analyses ', ' Discriminant Analysis ', ' disease/disorder ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Exhibits ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' indexing ', ' Language ', ' Linear Regressions ', ' Linguistic ', ' Linguistics ', ' lifespan ', ' life span ', ' Length of Life ', ' Longevity ', ' Methods ', ' Method LOINC Axis 6 ', ' Methodology ', ' body movement ', ' Movement ', ' National Institute of Mental Health ', ' NIMH ', ' National Institute of Mental Health (U.S.) ', ' neurobiological ', ' Neurobiology ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Lewy Body Parkinson Disease ', ' Idiopathic Parkinson Disease ', ' Parkinson Disease ', ' Patients ', ' Phonetics ', ' Psycholinguistic ', ' Psycholinguistics ', ' Public Health ', ' public health medicine (field) ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Risk ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' Semantics ', ' Sensitivity and Specificity ', ' computer program/software ', ' Software ', ' Computer software ', ' Sound Sonography ', ' Sound Spectrography ', ' Spectrum Analyses ', ' Spectroscopy ', ' Spectrum Analysis ', ' Speech ', ' Substance Use Disorder ', ' thoughts ', ' Thinking ', ' Thinking, function ', ' Tongue ', ' Translating ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' Gender ', ' Measures ', ' Youth 10-21 ', ' Youth ', ' base ', ' density ', ' Area ', ' Chronic ', ' Clinical ', ' Variation ', ' Variant ', ' Link ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' disability ', ' using substances ', ' substance use ', ' AOD use ', ' Alcohol or Other Drugs use ', ' Collaborations ', ' Staging ', ' tool ', ' Knowledge ', ' Complex ', ' Techniques ', ' Neurocognitive ', ' psychosocial ', ' Remission ', ' Disease remission ', ' syntactic ', ' syntax ', ' Position ', ' Positioning Attribute ', ' Modeling ', ' Sampling ', ' stigma ', ' social stigma ', ' developing computer software ', ' develop software ', ' software development ', ' health disparities ', ' health disparity ', ' SKAP55R ', ' SKAP-HOM ', ' SCAP2 ', ' SAPS ', ' RA70 ', ' SCAP2 gene ', ' Address ', ' Symptoms ', ' Data ', ' Measurable ', ' Predictive Value ', ' Strategic Planning ', ' Clinical Assessment Tool ', ' Cognitive ', ' computational analysis ', ' Computer Analysis ', ' exploratory developmental study ', ' R21 Program ', ' R21 Mechanism ', ' Exploratory/Developmental Grant ', ' Monitor ', ' developmental ', ' Development ', ' Behavioral ', ' neglect ', ' computerized ', ' computer based prediction ', ' predictive modeling ', ' designing ', ' design ', ' IQ Deficit ', ' Neurocognitive Deficit ', ' Clinical assessments ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' clinical applicability ', ' clinical application ', ' Neurocognition ', ' lexical ', ' high risk ', ' treatment response ', ' routine practice ', ' biosignature ', ' biomarker ', ' biologic marker ', ' Biological Markers ', ' Computational Linguistics ', ' ']",NIMH,FEINSTEIN INSTITUTE FOR MEDICAL RESEARCH,R21,2014,192679,NY-03,0.13526261079890395
"Longitudinal Voice Patterns in Bipolar Disorder     DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable.         PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.                ",Longitudinal Voice Patterns in Bipolar Disorder,8658149,R34MH100404,"['Acoustic ', ' Acoustics ', ' Algorithms ', ' Anxiety Disorders ', ' Behavior ', ' psychological disorder ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' manic depressive illness ', ' manic depressive disorder ', ' bipolar affective disorder ', ' Manic-Depressive Psychosis ', ' Bipolar Affective Psychosis ', ' Bipolar Disorder ', ' Bipolar Depression ', ' Charge ', ' Clinical Study ', ' Clinical Research ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Computers ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Data Collection ', ' depression ', ' Mental Depression ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Emotions ', ' environmental testing ', ' Ecological Monitoring ', ' Ecologic Monitoring ', ' Environmental Monitoring ', ' Future ', ' Goals ', ' Health ', ' History ', ' Recording of previous events ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Interview ', ' long-term study ', ' Longitudinal Studies ', ' Moods ', ' body movement ', ' Movement ', ' Observer Bias ', ' Observer Variation ', ' Patients ', ' Perception ', ' Rhythmicity ', ' Cyclicity ', ' Periodicity ', ' Personality ', ' pressure ', ' abnormal psychology ', ' Psychopathology ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' recruit ', ' Recruitment Activity ', ' Solutions ', ' Speech ', ' Speech Acoustics ', ' statistics ', ' Stress ', ' Technology ', ' Phone ', ' Telephone ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' base ', ' Loudness ', ' psychiatric treatment ', ' psychiatric therapy ', ' psychiatric care ', ' Psychiatric therapeutic procedure ', ' Clinical ', ' Phase ', ' Variation ', ' Variant ', ' Medical ', ' psychological ', ' psychologic ', ' insight ', ' Individual ', ' mental status ', ' mental state ', ' Shapes ', ' tool ', ' Manic State ', ' Manias ', ' Manic ', ' sadness ', ' depressed ', ' Depressed mood ', ' instrument ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Frequency ', ' Frequencies (time pattern) ', ' Sensory ', ' Pattern ', ' Neurocognitive ', ' Affective Disorders ', ' Mood Disorders ', ' early detection ', ' Early Diagnosis ', ' heuristics ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Prevention ', ' Devices ', ' Emotional ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' interventional strategy ', ' Intervention Strategies ', ' Intervention ', ' Accent ', ' Cellular Telephone ', ' Cell Phone ', ' Cellular Phone ', ' Mobile Phones ', ' Car Phone ', ' Address ', ' Data ', ' Detection ', ' Measurable ', ' Motor ', ' Cognitive ', ' Pattern Recognition ', ' Monitor ', ' Characteristics ', ' Process ', ' digital ', ' markov model ', ' Clinical assessments ', ' Outcome ', ' Hamilton Depression Scale ', ' HAM-D ', ' Hamilton Rating Scale for Depression ', ' Population ', ' innovative ', ' innovate ', ' innovation ', ' clinical significance ', ' clinically significant ', ' computer algorithm ', ' Computational algorithm ', ' speech processing ', ' lexical ', ' public health relevance ', ' Secure ', ' bipolar mania ', ' Bipolar 1 ', ' Bipolar I ', ' Bipolar 2 ', ' Bipolar II ', ' ']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2014,272125,MI-12,0.27717032118557206
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS     DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer.         PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.                    ",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8613983,R01DC013547,"['General Public ', ' General Population ', ' Position ', ' Positioning Attribute ', ' Deterioration ', ' Modeling ', ' oral communication ', ' traumatic brain damage ', ' Traumatic encephalopathy ', ' Brain Trauma ', ' Traumatic Brain Injury ', ' datamining ', ' data mining ', ' Address ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Gulf War ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socioeconomic ', ' socio-economic ', ' socio economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' forging ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' motor impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' Age ', ' Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Systematics ', ' Classification ', ' communication disorder aid ', ' communication device ', ' Communication Aids for Handicapped ', ' Communication Aids for Disabled ', ' Computers ', ' Swallowing ', ' Deglutition ', ' Diagnosis ', ' disease/disorder ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' balance function ', ' balance ', ' Equilibrium ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Incidence ', ' Jaw ', ' Language ', ' Lip ', ' Lip structure ', ' Maps ', ' body movement ', ' Movement ', ' insular sclerosis ', ' MS (Multiple Sclerosis) ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' muscular ', ' Muscle Tissue ', ' Muscle ', ' Persons ', ' Neurology ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Lewy Body Parkinson Disease ', ' Idiopathic Parkinson Disease ', ' Parkinson Disease ', ' Patients ', ' Production ', ' QOL ', ' Quality of life ', ' Research ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech-Language Pathology ', ' voice synthesizer ', ' Speech Synthesizers ', ' statistics ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' degenerative disorder of motor neurons ', ' Motor Neuron Disease ', ' Device Designs ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Staging ', ' Pathologist ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' Dimensions ', ' Severities ', ' Oral ', ' LOINC Axis 4 System ', ' System ', ' American ', ' early detection ', ' Early Diagnosis ', ' jaw movement ', ' Performance ', ' Accuracy of Diagnosis ', ' diagnostic accuracy ', ' novel ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2014,642629,MA-07,0.24739112916640235
"Speech Prosody and Articulatory Dynamics in Spoken Language DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context. One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.",Speech Prosody and Articulatory Dynamics in Spoken Language,8828663,R01DC003172,"['Acoustic ', ' Acoustics ', ' Articulators ', ' bear ', ' Ursidae ', ' Bears ', ' Ursidae Family ', ' Behavior ', ' Communication ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Conceptions ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Engineering ', ' Environment ', ' Gestures ', ' Grant ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' In element ', ' Indium ', ' Articulation ', ' Joints ', ' Language ', ' Learning ', ' Linguistic ', ' Linguistics ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' body movement ', ' Movement ', ' Patients ', ' Production ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Time ', ' Work ', ' base ', ' Loudness ', ' Clinical ', ' Phase ', ' Evaluation ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' programs ', ' cognitive function ', ' Investigation ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' speech disorder diagnosis ', ' speech recognition ', ' syntactic ', ' syntax ', ' kinematics ', ' phrases ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' sorting ', ' Sorting - Cell Movement ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Nervous System Trauma ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Interruption ', ' Cognitive ', ' Characteristics ', ' Process ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' Population ', ' Affective ', ' spatiotemporal ', ' constriction ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2015,472112,CA-37,0.3542326839502915
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants     DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it.          PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.            ",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,8963088,R01DC014290,"['Acoustic ', ' Acoustics ', ' Affect ', ' Algorithms ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Cochlear Implants ', ' Environment ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Maps ', ' Masks ', ' Methods ', ' Noise ', ' Problem Solving ', ' QOL ', ' Quality of life ', ' recruit ', ' Recruitment Activity ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Comprehension ', ' base ', ' improved ', ' Surface ', ' Ensure ', ' Stimulus ', ' Individual ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Frequency ', ' Frequencies (time pattern) ', ' Home ', ' Home environment ', ' Source ', ' Location ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' Hearing Impaired Persons ', ' Performance ', ' speech recognition ', ' success ', ' simulation ', ' Categories ', ' environmental risk ', ' Environmental Factor ', ' Environmental Risk Factor ', ' Devices ', ' Modeling ', ' response ', ' Address ', ' Process ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' speech processing ', ' public health relevance ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2015,289263,NC-04,0.26989920720488025
"Investigating neural mechanisms for flexible, robust speech perception with fMRI     DESCRIPTION (provided by applicant): The brain is bombarded by sensory information from the world, and must extract certain pieces of useful information using limited neural resources. This means that the brain must be efficient, throwing away information that is not needed in order to focus on the most important part of the sensory information from the world. However, information that is uninformative in one situation may be highly informative in another, and thus this efficiency must be matched by flexibility. One domain where this is particularly true is speech perception, where a noisy, ambiguous sensory signal is mapped onto underlying linguistic units like phonemes, words, and sentences. This mapping changes substantially depending on who is talking. One way the brain might deal with this is to learn talker-specific representations which optimize the efficiency with which speech sounds are processed, and deploy or ""swap out"" those representations whenever the talker changes, learning new representations for new talkers as necessary. While there is some evidence that listeners do use such a strategy, little is known about the underlying neural mechanisms. This proposal seeks to clarify these mechanisms through two specific aims. First, functional magnetic resonance imaging (fMRI) will image the brains of listeners while they are hearing words from two talkers with different accents, mixed together. By comparing the areas that are active when the talker switches with areas that are active during periods of learning about each accent (as measured by behavioral responses), the circuits by which listeners learn and deploy talker-specific representations will be elucidated. Second, using multi-voxel pattern analysis techniques, the neural representations of identical speech sounds which have different interpretations depending on the talker will be measured to determine how deeply talker-specific knowledge affects the processing of speech sounds. If talker-specific knowledge is being used to optimize the efficiency of perceptual processing at a low level, then within-category differences should result in more similar patterns of activity, while across-category differences should result in more distinct patterns of activity.         PUBLIC HEALTH RELEVANCE: The ability to flexibly adjust the processing and representation of speech sounds depending on who is talking is absolutely fundamental to the effective and fluent comprehension of spoken language, and impairments in this ability would make daily life very difficult. Completion of the proposed research has the potential to lead to new views on neurological disorders which impact language, like Williams Syndrome and Specific Language Impairment, and possibly new classifications of these disorders. Furthermore, by linking robust speech comprehension to more general perceptual adaptation and learning, the proposed work has the potential to shed light on the underlying pathology of disorders such as Autism Spectrum Disorders, which have been hypothesized to involve deficiencies in the integration of top-down expectations and bottom-up sensory information, both in language processing (Stewart & Ota, 2008; Yu, 2010) and general perception (Pellicano & Burr, 2012).                ","Investigating neural mechanisms for flexible, robust speech perception with fMRI",8831930,F31HD082893,"['Acoustic ', ' Acoustics ', ' Affect ', ' Auditory Cortex ', ' Auditory area ', ' Behavior ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Breeding ', ' Cognition ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Environment ', ' Future ', ' Goals ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Language ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Learning ', ' Photoradiation ', ' Light ', ' Linguistic ', ' Linguistics ', ' Maps ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' nervous system disorder ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Pathology ', ' Perception ', ' Play ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Resources ', ' Resources ', ' social role ', ' Role ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Voice ', ' Work ', ' Measures ', ' doubt ', ' Uncertainty ', ' Comprehension ', ' mental retardation-typical facies-aortic stenosis syndrome ', ' idiopathic hypercalcemia-supravalvular aortic stenosis syndrome ', ' hypercalcemia/Williams-Beuren syndrome ', ' hypercalcemia-peculiar facies-supravalvular aortic stenosis syndrome ', ' elfin-facies hypercalcemia syndrome ', ' Williams-Beuren syndrome (WBS) ', ' Williams-Beuren Syndrome ', ' Williams-Barratt syndrome ', ' Williams syndrome (WMS, WS) ', ' Williams Contiguous Gene Syndrome ', ' Williams Barratt syndrome ', ' Fanconi-Schlesinger syndrome ', ' Fanconi Schlesinger syndrome ', ' Elfin Facies Syndrome ', ' Beuren syndrome ', ' Williams Syndrome ', ' base ', ' improved ', ' brain visualization ', ' Brain imaging ', ' Area ', ' Link ', ' Training ', ' insight ', ' Stimulus ', ' Staging ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' fMRI ', ' Functional MRI ', ' Functional Magnetic Resonance Imaging ', ' Knowledge ', ' Life ', ' Auditory ', ' Sensory ', ' Pattern ', ' Techniques ', ' LOINC Axis 4 System ', ' System ', ' specific language impairment ', ' experience ', ' neural ', ' relating to nervous system ', ' Structure ', ' skills ', ' expectation ', ' novel ', ' Categories ', ' nosology ', ' disorder classification ', ' disease classification ', ' Coding System ', ' Code ', ' synaptic circuitry ', ' synaptic circuit ', ' neural circuitry ', ' neural circuit ', ' LOINC Axis 2 Property ', ' Property ', ' Accent ', ' Peach ', ' Thickness ', ' Thick ', ' Sensory Process ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Transmission ', ' transmission process ', ' Process ', ' Behavioral ', ' neural mechanism ', ' neuromechanism ', ' cognitive neuroscience ', ' Impairment ', ' speech processing ', ' language processing ', ' public health relevance ', ' neural patterning ', ' flexible ', ' flexibility ', ' ']",NICHD,UNIVERSITY OF ROCHESTER,F31,2015,28238,NY-25,0.12160884341830175
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication     DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders.         PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.                ",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,8957652,R03DC013990,"['Age ', ' Algorithms ', ' American Cancer Society ', ' Dorsum ', ' Back ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Diagnosis ', ' Electromagnetic ', ' Electromagnetics ', ' balance function ', ' balance ', ' Equilibrium ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Articulation ', ' Joints ', ' Language ', ' Laryngectomy ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Artificial Larynx ', ' Laryngeal Prosthesis ', ' Lip ', ' Lip structure ', ' Maps ', ' body movement ', ' Movement ', ' Persons ', ' Patients ', ' Play ', ' Research ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' sound ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Sound ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' Voice ', ' Voice Disorders ', ' Gender ', ' Measures ', ' base ', ' improved ', ' Clinical ', ' Individual ', ' Pathologist ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Pattern ', ' LOINC Axis 4 System ', ' System ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Operative Surgical Procedures ', ' innovative technologies ', ' Performance ', ' computer science ', ' kinematics ', ' novel ', ' Participant ', ' Devices ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Excision ', ' oral communication ', ' anticancer therapy ', ' Malignant Neoplasm Treatment ', ' Malignant Neoplasm Therapy ', ' Cancer Treatment ', ' cancer therapy ', ' Address ', ' Data ', ' Motor ', ' Tracheo-Esophageal Speech ', ' Tracheoesophageal Speech ', ' Characteristics ', ' Text ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' Output ', ' Population ', ' public health relevance ', ' clinical practice ', ' efficacy testing ', ' ']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2015,153000,TX-32,0.2750270428952173
"Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates     DESCRIPTION (provided by applicant): 90% of the 1.5 million Americans living with idiopathic Parkinson's disease (PD) and 50% of the 500,000 Americans living with Multiple Sclerosis (MS) will experience dysarthria. Dysarthria has devastating consequences for life quality and participation in society due to its effects on employment, leisure activities and social relationships. Knowledge of therapy techniques for maximizing perceived speech adequacy, as indexed by the gold standard perceptual construct of intelligibility is thus of vital importance. Owing to the scarcity of impartial comparative studies, the choice of one technique over others is often based on trial and error or reflects clinician bias, both of which are at odds with evidence-based practice. This project has sought to address this critical gap in knowledge regarding the comparative merits of dysarthria treatment techniques since its inception. Toward this end, published studies from the past funding cycle compared the acoustic and perceptual merits of three common, global dysarthria treatment techniques including 1) rate manipulation, 2) an increased vocal intensity and 3) clear speech in MS and PD as well as age and sex matched neurotypical talkers. Global treatment techniques by their very nature elicit co-occurring acoustic changes (e.g., duration, segmental articulation). Because an explanatory, acoustically-based model of intelligibility is lacking, the acoustic change(s) causing or explainin the improved perceptual outcomes of global treatment techniques are unknown. Determining the acoustic variables explaining intelligibility variation in dysarthria would not only tremendousy advance theoretical understanding of intelligibility but also would strengthen the scientific basis for treatment. Treatment focused on those acoustic variables explanatory for improved intelligibility may further accelerate progress in therapy. Importantly, research from the previous funding cycle suggests the promise of speech analysis-resynthesis for identifying segmental and suprasegmental acoustic variables explanatory for intelligibility in dysarthria. Building upon this work, the overarching goal of the continuation is to contribute towards development of an acoustically-based explanatory model of intelligibility. Our approach 1) employs established perceptual procedures and acoustic measures, 2) uses an innovative analysis-resynthesis technique that permits conclusions concerning the explanatory relationship between acoustic changes accompanying dysarthria therapy techniques and intelligibility, and 3) leverages methods from machine learning to build a predictive model of intelligibility from acoustics. The impact of this work is in its contribution to 1) advancing conceptual understanding of intelligibility, 2) strengthening the scientific basis for treatment, and 3) optimizing clinical implementation of dysarthria therapy techniques.         PUBLIC HEALTH RELEVANCE: This project is directly relevant to the mission of NIDCD due to its focus on investigating the therapeutic techniques for maximizing intelligibility in dysarthra secondary to Parkinson's disease and Multiple Sclerosis. By advancing conceptual understanding of intelligibility, this research will strengthen the scientific basis for dysarthria treatments and will optimize their clinical implementation.            ",Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates,8955720,R01DC004689,"['Acoustic ', ' Acoustics ', ' Affect ', ' Age ', ' Comparative Study ', ' Dysarthosis ', ' Dysarthria ', ' Employment ', ' Goals ', ' Au element ', ' Gold ', ' indexing ', ' Articulation ', ' Joints ', ' Leisure Activities ', ' Methods ', ' Mission ', ' insular sclerosis ', ' MS (Multiple Sclerosis) ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Lewy Body Parkinson Disease ', ' Idiopathic Parkinson Disease ', ' Parkinson Disease ', ' Production ', ' Publishing ', ' QOL ', ' Quality of life ', ' Research ', ' Societies ', ' Speech ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Secondary to ', ' base ', ' improved ', ' Procedures ', ' Clinical ', ' Variation ', ' Variant ', ' Individual ', ' Funding ', ' Therapeutic ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' Life ', ' Frequency ', ' Frequencies (time pattern) ', ' Techniques ', ' American ', ' experience ', ' treatment program ', ' social ', ' Modeling ', ' orthographical ', ' orthographic ', ' Orthography ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' hearing impairment ', ' Address ', ' Evidence based practice ', ' sex ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' innovative ', ' innovate ', ' innovation ', ' comparative ', ' public health relevance ', ' clear speech ', ' ']",NIDCD,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2015,544862,NY-26,0.060050512759730355
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8775639,R01DC013547,"['Age ', ' Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Systematics ', ' Classification ', ' communication disorder aid ', ' communication device ', ' Communication Aids for Handicapped ', ' Communication Aids for Disabled ', ' Computers ', ' Swallowing ', ' Deglutition ', ' Diagnosis ', ' disease/disorder ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' balance function ', ' balance ', ' Equilibrium ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Incidence ', ' Jaw ', ' Language ', ' Lip ', ' Lip structure ', ' Maps ', ' body movement ', ' Movement ', ' insular sclerosis ', ' MS (Multiple Sclerosis) ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' muscular ', ' Muscle Tissue ', ' Muscle ', ' Persons ', ' Neurology ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Lewy Body Parkinson Disease ', ' Idiopathic Parkinson Disease ', ' Parkinson Disease ', ' Patients ', ' Production ', ' QOL ', ' Quality of life ', ' Research ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech-Language Pathology ', ' voice synthesizer ', ' Speech Synthesizers ', ' statistics ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' Motor Neuron Disease ', ' degenerative disorder of motor neurons ', ' Device Designs ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Staging ', ' Pathologist ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' Dimensions ', ' Severities ', ' Oral ', ' LOINC Axis 4 System ', ' System ', ' American ', ' early detection ', ' Early Diagnosis ', ' jaw movement ', ' Performance ', ' Accuracy of Diagnosis ', ' diagnostic accuracy ', ' novel ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' General Public ', ' General Population ', ' Position ', ' Positioning Attribute ', ' Deterioration ', ' Modeling ', ' oral communication ', ' traumatic brain damage ', ' Traumatic encephalopathy ', ' Brain Trauma ', ' Traumatic Brain Injury ', ' datamining ', ' data mining ', ' Address ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Gulf War ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socioeconomic ', ' socio-economic ', ' socio economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' forging ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' motor impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2015,584132,MA-07,0.24739112916640235
"Longitudinal Voice Patterns in Bipolar Disorder DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable. PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.",Longitudinal Voice Patterns in Bipolar Disorder,8843048,R34MH100404,"['Acoustic ', ' Acoustics ', ' Algorithms ', ' Anxiety Disorders ', ' Behavior ', ' psychological disorder ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' manic depressive illness ', ' manic depressive disorder ', ' bipolar disease ', ' bipolar affective disorder ', ' Manic-Depressive Psychosis ', ' Bipolar Affective Psychosis ', ' Bipolar Disorder ', ' bipolar depressed ', ' Bipolar Depression ', ' Charge ', ' Clinical Study ', ' Clinical Research ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Computers ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Data Collection ', ' depression ', ' Mental Depression ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Emotions ', ' environmental testing ', ' Ecological Monitoring ', ' Ecologic Monitoring ', ' Environmental Monitoring ', ' Future ', ' Goals ', ' Health ', ' History ', ' Recording of previous events ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' Interview ', ' long-term study ', ' Longitudinal Studies ', ' Moods ', ' body movement ', ' Movement ', ' Observer Bias ', ' Observer Variation ', ' Patients ', ' Perception ', ' Rhythmicity ', ' Cyclicity ', ' Periodicity ', ' Personality ', ' pressure ', ' abnormal psychology ', ' Psychopathology ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' recruit ', ' Recruitment Activity ', ' Solutions ', ' Speech ', ' Speech Acoustics ', ' statistics ', ' Stress ', ' Technology ', ' Phone ', ' Telephone ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' base ', ' Loudness ', ' psychiatric treatment ', ' psychiatric therapy ', ' psychiatric care ', ' Psychiatric therapeutic procedure ', ' Clinical ', ' Phase ', ' Variation ', ' Variant ', ' Medical ', ' psychological ', ' psychologic ', ' insight ', ' Individual ', ' mental status ', ' mental state ', ' Shapes ', ' tool ', ' Manic State ', ' Manias ', ' Manic ', ' sadness ', ' depressed ', ' Depressed mood ', ' instrument ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Frequency ', ' Frequencies (time pattern) ', ' Sensory ', ' Pattern ', ' Neurocognitive ', ' Affective Disorders ', ' Mood Disorders ', ' early detection ', ' Early Diagnosis ', ' heuristics ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Prevention ', ' Devices ', ' Emotional ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' interventional strategy ', ' Intervention Strategies ', ' Intervention ', ' Accent ', ' Cellular Telephone ', ' Cell Phone ', ' Cellular Phone ', ' Mobile Phones ', ' Car Phone ', ' Address ', ' Data ', ' Detection ', ' Measurable ', ' Motor ', ' Cognitive ', ' Pattern Recognition ', ' Monitor ', ' Characteristics ', ' Process ', ' digital ', ' markov model ', ' Clinical assessments ', ' Outcome ', ' Hamilton Depression Scale ', ' HAM-D ', ' Hamilton Rating Scale for Depression ', ' Population ', ' innovative ', ' innovate ', ' innovation ', ' clinical significance ', ' clinically significant ', ' computer algorithm ', ' Computational algorithm ', ' speech processing ', ' lexical ', ' Secure ', ' bipolar mania ', ' Bipolar 1 ', ' Bipolar I ', ' Bipolar 2 ', ' Bipolar II ', ' ']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2015,155500,MI-12,0.27717032118557206
"Neurophysiology of robust speech perception in human superior temporal gyrus     DESCRIPTION (provided by applicant): Perceiving and following an individual speaker in a crowded, noisy environment is a commonplace task for listeners with normal hearing. The underlying neurophysiology, however, is complex, and the task remains a struggle for people with peripheral and central auditory pathway disorders. The lack of a detailed neurobiological model of mechanisms and functions underlying robust speech perception has hindered our understanding of how these processes become impaired in the suffering population. In our innovative approach, we will record from high-density micro and macro electrode arrays surgically implanted on the superior temporal gyrus of epilepsy patients as part of their clinical evaluation. This method offers an exceptionally detailed perspective of cortical population activity. We will build upon two recent complementary findings where we identified a highly selective, spatially distributed neural representation of phonetic features (Mesgarani et. al. Science, 2014), which at the same time is highly dynamic and can change rapidly to reflect the perceptual bias of the listener (Mesgarani & Chang, Nature 2012). While significant, these studies revealed several gaps in our understanding of this process, which we intend to address in this proposal. Specifically, we will resolve the following unanswered questions: 1) what is the neural mechanism for joint encoding of both phonetic and speaker features? 2) How does attention modulate phonetic and speaker feature selectivity of neural responses? And 3) what computational mechanisms can account for dynamic feature selectivity of responses in STG? Answering these questions will significantly advance our understanding of a remarkable human ability, and will be of great interest to researchers from many areas including neurologists, and sensory and cognitive neuroscientists.         PUBLIC HEALTH RELEVANCE: Understanding the mechanisms underlying speech perception in challenging environments is a crucial step in determining how these processes deteriorate in various disorders of peripheral and central auditory pathways. Our studies will result in novel neurobiological models of robust speech perception that will serve as a necessary step toward designing innovative therapeutic measures.                ",Neurophysiology of robust speech perception in human superior temporal gyrus,8801902,R01DC014279,"['Accounting ', ' Acoustic ', ' Acoustics ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Aphasias ', ' Anepia ', ' Alogia ', ' Aphasia ', ' Attention ', ' Central Auditory Pathway Disorders ', ' Central Auditory Dysfunction ', ' Central Auditory Diseases ', ' auditory pathway ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Crowding ', ' Cues ', ' disease/disorder ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' Environment ', ' epileptogenic ', ' epileptiform ', ' epilepsia ', ' Seizure Disorder ', ' Epileptics ', ' Epileptic Seizures ', ' Epilepsy ', ' Feedback ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Modern Man ', ' Man (Taxonomy) ', ' Human ', ' indexing ', ' Articulation ', ' Joints ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Language Development ', ' Literature ', ' Methods ', ' neurobiological ', ' Neurobiology ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Patients ', ' Perception ', ' Phonetics ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' social role ', ' Role ', ' Science ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Specificity ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' Speech Pathology ', ' Mediating ', ' Superior temporal gyrus ', ' Comprehension ', ' Intention ', ' Prosthetics ', ' Prosthetic device ', ' Prosthesis ', ' density ', ' Peripheral ', ' Site ', ' Area ', ' Surface ', ' Link ', ' selective attention ', ' receptive field ', ' Discipline ', ' Individual ', ' Neurologist ', ' Therapeutic ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Complex ', ' Sensory ', ' Techniques ', ' Word Blindness ', ' Dyslexia ', ' interest ', ' neural ', ' relating to nervous system ', ' expectation ', ' neuroimaging ', ' novel ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Coding System ', ' Code ', ' Modeling ', ' LOINC Axis 2 Property ', ' Property ', ' response ', ' Address ', ' Resolution ', ' clinical test ', ' Clinical Testing ', ' Clinical Evaluation ', ' research clinical testing ', ' Cognitive ', ' Characteristics ', ' Process ', ' computational framework ', ' computer framework ', ' designing ', ' design ', ' Population ', ' neural mechanism ', ' neuromechanism ', ' innovative ', ' innovate ', ' innovation ', ' Implant ', ' speech processing ', ' attentional modulation ', ' spatiotemporal ', ' public health relevance ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2015,408878,NY-13,0.1701572157265675
"Speech Prosody and Articulatory Dynamics in Spoken Language DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context. One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.",Speech Prosody and Articulatory Dynamics in Spoken Language,9036989,R01DC003172,"['Acoustic ', ' Acoustics ', ' Articulators ', ' bear ', ' Ursidae ', ' Bears ', ' Ursidae Family ', ' Behavior ', ' Communication ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Conceptions ', ' Disorder ', ' Disease ', ' Engineering ', ' Environment ', ' Gestures ', ' Grant ', ' Modern Man ', ' Human ', ' In element ', ' Indium ', ' Articulation ', ' Joints ', ' Language ', ' Learning ', ' Linguistic ', ' Linguistics ', ' body movement ', ' Movement ', ' Patients ', ' Production ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Time ', ' Work ', ' base ', ' Loudness ', ' Clinical ', ' Phase ', ' Evaluation ', ' Mouth ', ' Cavitas Oris ', ' Buccal Cavity Head and Neck ', ' Buccal Cavity ', ' Oral cavity ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' programs ', ' cognitive function ', ' Investigation ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Techniques ', ' System ', ' speech disorder diagnosis ', ' speech recognition ', ' syntactic ', ' syntax ', ' kinematic model ', ' kinematics ', ' phrases ', ' Structure ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' sorting ', ' Sorting - Cell Movement ', ' neurotrauma ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Nervous System Trauma ', ' Modeling ', ' Property ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Interruption ', ' Cognitive ', ' Characteristics ', ' Process ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' Population ', ' Affective ', ' spatiotemporal ', ' constriction ', ' cognitive load ', ' cognitive burden ', ' dynamic system ', ' dynamical system ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,477237,CA-37,0.3542326839502915
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9205890,U01NS098969,"['Stimulus ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Deep Brain Stimulation ', ' Event ', ' Stream ', ' Pattern ', ' Techniques ', ' System ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Operative Surgical Procedures ', ' Performance ', ' neural ', ' relating to nervous system ', ' kinematic model ', ' kinematics ', ' novel ', ' member ', ' Coding System ', ' Code ', ' Modeling ', ' response ', ' treatment adverse effect ', ' therapy adverse effect ', ' side effect ', ' Treatment Side Effects ', ' Adverse effects ', ' Address ', ' Data ', ' Motor ', ' Output ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' cognitive neuroscience ', ' gain of function ', ' STN stimulation ', ' subthalamic nucleus stimulation ', ' microstimulation ', ' learning strategy ', ' learning method ', ' learning activity ', ' motor symptom ', ' Acoustic ', ' Acoustics ', ' Basal Nuclei ', ' Basal Ganglia ', ' Cues ', ' Dysarthosis ', ' Dysarthria ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Electrophysiology (science) ', ' Goals ', ' Language ', ' Linguistic ', ' Linguistics ', ' Methods ', ' body movement ', ' Movement ', ' Movement Disorder Syndromes ', ' Dyskinesia Syndromes ', ' Movement Disorders ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' nervous system disorder ', ' neurobiological ', ' Neurobiology ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Neurosciences ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Parkinson Disease ', ' Patients ', ' Phonetics ', ' Production ', ' social role ', ' Role ', ' Speech ', ' Testing ', ' Time ', ' Universities ', ' Voice ', ' Measures ', ' Structure of subthalamic nucleus ', ' Subthalamic Nucleus ', ' Nucleus Subthalamicus ', ' base ', ' Clinical ', ' Phase ', ' ']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2016,1028607,PA-18,0.22462395316098602
"Dynamics of Vocal Tract Shaping     DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate.         PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.            ",Dynamics of Vocal Tract Shaping,9030116,R01DC007124,"['Accounting ', ' Acoustic ', ' Acoustics ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' apraxia ', ' Dyspraxia ', ' Apraxias ', ' Articulators ', ' Beds ', ' Communication ', ' Communities ', ' Swallowing Disorders ', ' Dysphagia ', ' Deglutition Disorders ', ' Engineering ', ' Epiglottis ', ' Epiglottis structure ', ' Gestures ', ' Glossectomy ', ' Goals ', ' Modern Man ', ' Human ', ' Articulation ', ' Joints ', ' Language ', ' language deficit ', ' Language disability ', ' Language Disorders ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Linguistic ', ' Linguistics ', ' Lip ', ' Lip structure ', ' Zeugmatography ', ' Nuclear Magnetic Resonance Imaging ', ' NMR Tomography ', ' NMR Imaging ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' MRI ', ' MR Tomography ', ' MR Imaging ', ' Magnetic Resonance Imaging ', ' Motion ', ' body movement ', ' Movement ', ' Noise ', ' Throat ', ' Pharynx ', ' Pharyngeal structure ', ' Play ', ' Posture ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' sleep-related breathing disorder ', ' Sleep-Disordered Breathing ', ' Sleep Hypopnea ', ' Sleep Apnea ', ' Sleep Apnea Syndromes ', ' sound ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Island Flaps ', ' Flaps ', ' Surgical Flaps ', ' Teaching ', ' Educational process of instructing ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Traction ', ' Work ', ' Measures ', ' base ', ' image processing ', ' improved ', ' Lateral ', ' Clinical ', ' Variation ', ' Variant ', ' Series ', ' Training ', ' tongue tip ', ' tongue apex ', ' Individual ', ' Recovery ', ' Shapes ', ' tool ', ' German ', ' German population ', ' instrument ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' Investigation ', ' Dimensions ', ' Complex ', ' Event ', ' Oral ', ' In Situ ', ' Pattern ', ' System ', ' oral pharyngeal ', ' Oropharynxs ', ' Oropharynx ', ' Oropharyngeal ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Operative Surgical Procedures ', ' speech recognition ', ' phonological ', ' phonology ', ' internal control ', ' Speed ', ' Structure ', ' novel ', ' movie ', ' outreach ', ' technological innovation ', ' Modeling ', ' Property ', ' theories ', ' biomedical imaging ', ' bio-imaging ', ' bioimaging ', ' Three Dimensional Medical Imaging ', ' 3D imaging ', ' 3-D Imaging ', ' Three-Dimensional Imaging ', ' Data ', ' International ', ' Resolution ', ' Cardiac ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' website ', ' web site ', ' reconstruction ', ' computational tools ', ' computerized tools ', ' remediation ', ' Imaging technology ', ' Population ', ' Coupled ', ' innovation ', ' innovative ', ' innovate ', ' spatiotemporal ', ' public health relevance ', ' constriction ', ' dexterity ', ' program dissemination ', ' project dissemination ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,433810,CA-37,0.32452589820963934
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases     DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand.         PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.            ",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9054574,R01DC014498,"['Algorithms ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Child ', ' Communication ', ' computer vision ', ' Computer Vision Systems ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Deafness ', ' Emotions ', ' facial ', ' faces ', ' Face ', ' face expression ', ' Facial Expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Modern Man ', ' Human ', ' Articulation ', ' Joints ', ' Linguistic ', ' Linguistics ', ' Logic ', ' Manuals ', ' Methods ', ' body movement ', ' Movement ', ' Parents ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Science ', ' Semantics ', ' American Sign Language ', ' Sign Language ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Software ', ' Computer software ', ' Speech ', ' Teaching ', ' Educational process of instructing ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specified ', ' Specific qualifier value ', ' Series ', ' Visual ', ' Individual ', ' data repository ', ' clinical data repository ', ' Databanks ', ' Data Bases ', ' Data Banks ', ' Databases ', ' Shapes ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' System ', ' expression of emotion ', ' emotional expression ', ' showing emotion ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' Hearing Impaired Persons ', ' interest ', ' instructor ', ' Visual System ', ' Visual system structure ', ' experience ', ' syntactic ', ' syntax ', ' Structure ', ' Agreement ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Controlled Study ', ' Devices ', ' Academic achievement ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Excision ', ' Coding System ', ' Code ', ' face perception ', ' interventional strategy ', ' Intervention Strategies ', ' Intervention ', ' outreach to information ', ' Access to Information ', ' body position ', ' preventing ', ' prevent ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' imaging ', ' Image ', ' reconstruction ', ' computational tools ', ' computerized tools ', ' designing ', ' design ', ' innovation ', ' innovative ', ' innovate ', ' Computational algorithm ', ' computer algorithm ', ' comparative ', ' public health relevance ', ' Teacher Professional Development ', ' teacher development ', ' instructor training ', ' faculty professional development ', ' faculty development ', ' Teacher Training ', ' Teacher Preparation ', ' Teacher Educator ', ' Teacher Education ', ' Faculty Training ', ' Faculty Education ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2016,331310,OH-03,0.07835202109578018
"Neurophysiology of robust speech perception in human superior temporal gyrus DESCRIPTION (provided by applicant): Perceiving and following an individual speaker in a crowded, noisy environment is a commonplace task for listeners with normal hearing. The underlying neurophysiology, however, is complex, and the task remains a struggle for people with peripheral and central auditory pathway disorders. The lack of a detailed neurobiological model of mechanisms and functions underlying robust speech perception has hindered our understanding of how these processes become impaired in the suffering population. In our innovative approach, we will record from high-density micro and macro electrode arrays surgically implanted on the superior temporal gyrus of epilepsy patients as part of their clinical evaluation. This method offers an exceptionally detailed perspective of cortical population activity. We will build upon two recent complementary findings where we identified a highly selective, spatially distributed neural representation of phonetic features (Mesgarani et. al. Science, 2014), which at the same time is highly dynamic and can change rapidly to reflect the perceptual bias of the listener (Mesgarani & Chang, Nature 2012). While significant, these studies revealed several gaps in our understanding of this process, which we intend to address in this proposal. Specifically, we will resolve the following unanswered questions: 1) what is the neural mechanism for joint encoding of both phonetic and speaker features? 2) How does attention modulate phonetic and speaker feature selectivity of neural responses? And 3) what computational mechanisms can account for dynamic feature selectivity of responses in STG? Answering these questions will significantly advance our understanding of a remarkable human ability, and will be of great interest to researchers from many areas including neurologists, and sensory and cognitive neuroscientists. PUBLIC HEALTH RELEVANCE: Understanding the mechanisms underlying speech perception in challenging environments is a crucial step in determining how these processes deteriorate in various disorders of peripheral and central auditory pathways. Our studies will result in novel neurobiological models of robust speech perception that will serve as a necessary step toward designing innovative therapeutic measures.",Neurophysiology of robust speech perception in human superior temporal gyrus,9024503,R01DC014279,"['Accounting ', ' Acoustic ', ' Acoustics ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Aphasia ', ' Attention ', ' Central Auditory Pathway Disorders ', ' Central Auditory Dysfunction ', ' Central Auditory Diseases ', ' auditory pathway ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Crowding ', ' Cues ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' Environment ', ' epileptogenic ', ' epileptiform ', ' epilepsia ', ' Seizure Disorder ', ' Epileptics ', ' Epileptic Seizures ', ' Epilepsy ', ' Feedback ', ' Health ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Modern Man ', ' Human ', ' indexing ', ' Articulation ', ' Joints ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Language Development ', ' Literature ', ' Methods ', ' neurobiological ', ' Neurobiology ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Patients ', ' Perception ', ' Phonetics ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' social role ', ' Role ', ' Science ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Specificity ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' Speech Pathology ', ' Mediating ', ' Superior temporal gyrus ', ' Comprehension ', ' Intention ', ' Prosthetics ', ' Prosthetic device ', ' Prosthesis ', ' density ', ' Peripheral ', ' Site ', ' Area ', ' Surface ', ' Link ', ' selective attention ', ' receptive field ', ' Discipline ', ' Individual ', ' Neurologist ', ' Therapeutic ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Complex ', ' Sensory ', ' Techniques ', ' Word Blindness ', ' Dyslexia ', ' interest ', ' neural ', ' relating to nervous system ', ' expectation ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Coding System ', ' Code ', ' Modeling ', ' Property ', ' response ', ' Address ', ' Resolution ', ' clinical test ', ' Clinical Testing ', ' Clinical Evaluation ', ' research clinical testing ', ' Cognitive ', ' Characteristics ', ' Process ', ' computational framework ', ' computer framework ', ' designing ', ' design ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' innovation ', ' innovative ', ' innovate ', ' Implant ', ' speech processing ', ' attentional modulation ', ' attention modulation ', ' spatiotemporal ', ' cognitive ability ', ' learning strategy ', ' learning method ', ' learning activity ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2016,395101,NY-13,0.1701572157265675
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication     DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders. PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,9114061,R03DC013990,"['Age ', ' Algorithms ', ' American Cancer Society ', ' Dorsum ', ' Back ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Diagnosis ', ' Electromagnetic ', ' Electromagnetics ', ' balance function ', ' balance ', ' Equilibrium ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Human ', ' Articulation ', ' Joints ', ' Language ', ' Laryngectomy ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Artificial Larynx ', ' Laryngeal Prosthesis ', ' Lip ', ' Lip structure ', ' Maps ', ' body movement ', ' Movement ', ' Persons ', ' Patients ', ' Play ', ' Research ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' sound ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Sound ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' Voice ', ' Voice Disorders ', ' Gender ', ' Measures ', ' base ', ' improved ', ' Clinical ', ' Individual ', ' Pathologist ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Pattern ', ' System ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Operative Surgical Procedures ', ' innovative technologies ', ' Performance ', ' computer science ', ' kinematic model ', ' kinematics ', ' novel ', ' Participant ', ' Devices ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Excision ', ' oral communication ', ' anticancer therapy ', ' Malignant Neoplasm Treatment ', ' Malignant Neoplasm Therapy ', ' Cancer Treatment ', ' cancer therapy ', ' Address ', ' Data ', ' Motor ', ' Tracheo-Esophageal Speech ', ' Tracheoesophageal Speech ', ' Characteristics ', ' Text ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' Output ', ' Population ', ' clinical practice ', ' efficacy testing ', ' movement analysis ', ' ']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2016,153000,TX-32,0.2750270428952173
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants     DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9100672,R01DC014290,"['Acoustic ', ' Acoustics ', ' Affect ', ' Algorithms ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Cochlear Implants ', ' Environment ', ' Health ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Maps ', ' Masks ', ' Methods ', ' Noise ', ' Problem Solving ', ' QOL ', ' Quality of life ', ' recruit ', ' active recruitment ', ' Recruitment Activity ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Comprehension ', ' base ', ' improved ', ' Surface ', ' Ensure ', ' Stimulus ', ' Individual ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Frequencies ', ' Home ', ' Home environment ', ' Source ', ' Location ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' Hearing Impaired Persons ', ' Performance ', ' speech recognition ', ' success ', ' simulation ', ' Categories ', ' environmental risk ', ' Environmental Factor ', ' Environmental Risk Factor ', ' Devices ', ' Modeling ', ' response ', ' Address ', ' Process ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' speech processing ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2016,293885,NC-04,0.26989920720488025
"Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates     DESCRIPTION (provided by applicant): 90% of the 1.5 million Americans living with idiopathic Parkinson's disease (PD) and 50% of the 500,000 Americans living with Multiple Sclerosis (MS) will experience dysarthria. Dysarthria has devastating consequences for life quality and participation in society due to its effects on employment, leisure activities and social relationships. Knowledge of therapy techniques for maximizing perceived speech adequacy, as indexed by the gold standard perceptual construct of intelligibility is thus of vital importance. Owing to the scarcity of impartial comparative studies, the choice of one technique over others is often based on trial and error or reflects clinician bias, both of which are at odds with evidence-based practice. This project has sought to address this critical gap in knowledge regarding the comparative merits of dysarthria treatment techniques since its inception. Toward this end, published studies from the past funding cycle compared the acoustic and perceptual merits of three common, global dysarthria treatment techniques including 1) rate manipulation, 2) an increased vocal intensity and 3) clear speech in MS and PD as well as age and sex matched neurotypical talkers. Global treatment techniques by their very nature elicit co-occurring acoustic changes (e.g., duration, segmental articulation). Because an explanatory, acoustically-based model of intelligibility is lacking, the acoustic change(s) causing or explainin the improved perceptual outcomes of global treatment techniques are unknown. Determining the acoustic variables explaining intelligibility variation in dysarthria would not only tremendousy advance theoretical understanding of intelligibility but also would strengthen the scientific basis for treatment. Treatment focused on those acoustic variables explanatory for improved intelligibility may further accelerate progress in therapy. Importantly, research from the previous funding cycle suggests the promise of speech analysis-resynthesis for identifying segmental and suprasegmental acoustic variables explanatory for intelligibility in dysarthria. Building upon this work, the overarching goal of the continuation is to contribute towards development of an acoustically-based explanatory model of intelligibility. Our approach 1) employs established perceptual procedures and acoustic measures, 2) uses an innovative analysis-resynthesis technique that permits conclusions concerning the explanatory relationship between acoustic changes accompanying dysarthria therapy techniques and intelligibility, and 3) leverages methods from machine learning to build a predictive model of intelligibility from acoustics. The impact of this work is in its contribution to 1) advancing conceptual understanding of intelligibility, 2) strengthening the scientific basis for treatment, and 3) optimizing clinical implementation of dysarthria therapy techniques. PUBLIC HEALTH RELEVANCE: This project is directly relevant to the mission of NIDCD due to its focus on investigating the therapeutic techniques for maximizing intelligibility in dysarthra secondary to Parkinson's disease and Multiple Sclerosis. By advancing conceptual understanding of intelligibility, this research will strengthen the scientific basis for dysarthria treatments and will optimize their clinical implementation.",Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates,9120824,R01DC004689,"['Acoustic ', ' Acoustics ', ' Affect ', ' Age ', ' Comparative Study ', ' Dysarthosis ', ' Dysarthria ', ' Employment ', ' Goals ', ' Au element ', ' Gold ', ' Health ', ' indexing ', ' Articulation ', ' Joints ', ' Leisure Activities ', ' Methods ', ' Mission ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Parkinson Disease ', ' Production ', ' Publishing ', ' QOL ', ' Quality of life ', ' Research ', ' Societies ', ' Speech ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Secondary to ', ' base ', ' improved ', ' Procedures ', ' Clinical ', ' Variation ', ' Variant ', ' Individual ', ' Funding ', ' Therapeutic ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' Life ', ' Frequencies ', ' Techniques ', ' American ', ' experience ', ' treatment program ', ' social ', ' Modeling ', ' orthographical ', ' orthographic ', ' Orthography ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' hearing impairment ', ' Address ', ' Evidence based practice ', ' sex ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' innovation ', ' innovative ', ' innovate ', ' comparative ', ' clear speech ', ' Idiopathic Parkinson Disease ', ' ']",NIDCD,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2016,504687,NY-26,0.060050512759730355
"The Cortical Dynamics of Motor Activity During Speech Production Speech is critical for human communication, but the cortical control of the fundamental movements of speech production is not clearly understood. Current knowledge primarily stems from functional imaging and lesion studies, which lack the ability to observe rapid changes in activity. Advances in electrocorticography (ECoG) now enable investigation of rapid changes over multiple cortical regions. Early ECoG studies have found ventral motor cortex (M1) activity broadly related to large vocal pitch change and loosely correlated with production of speech sounds, or phonemes. I have demonstrated that even single instances of phonemes can be identified during word production from patterns in activity in M1. However, motor control studies show M1 activity primarily represents movements. Correspondingly, the movements of speech, such as those of the laryngeal musculature involved in vocal pitch, are well understood. Similarly, phonology literature suggests the basic units of speech production are simple articulator movements, or gestures, such as tongue tip closure. Despite strong evidence for movement representation in M1, speech movements have yet to be been investigated with ECoG. The objective of this proposal is to elucidate how the motor cortices control speech movements of articulators and vocal pitch. The research aims of this proposal are to determine the cortical representation of articulatory gestures and vocal pitch during speech and non-speech movements. I will decode high-gamma activity (70-200 Hz) of M1, premotor cortex (PM) and inferior frontal gyrus (IFG) to estimate representation of these movements. Decoding accuracy will quantify the extent to which gestures are represented in each cortical area during speech and non-speech movements. Preliminary results reveal distinct cortical signatures in M1 related to gesture production. Completion of these goals will result in a model of cortical representation of speech movements. This work will enable substantiation of neurophysiological theories, lead to practical applications for patients, and enable investigations of motor activity during higher- order processes of speech. Moreover, we enable comparison of speech to other motor control processes. Results will improve understanding of the cortical representation of the larynx, which remains poorly understood in human physiology research. This study examines cortical activity of motor areas during speech production, with the goal of identifying the cortical representation of articulatory movements and vocal pitch. This research will address fundamental questions about speech motor control during production and phonation, which will enable evaluation of neurophysiological theories and lead to practical applications for patients.",The Cortical Dynamics of Motor Activity During Speech Production,9191603,F32DC015708,"['Acoustic ', ' Acoustics ', ' Algorithms ', ' Articulators ', ' Communication ', ' skull incision ', ' Craniotomy ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Electrophysiology (science) ', ' Gestures ', ' Goals ', ' Modern Man ', ' Human ', ' larynx muscle ', ' Laryngeal Muscles ', ' Laryngeal muscle structure ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Lip ', ' Lip structure ', ' Literature ', ' Maps ', ' Mentors ', ' Locomotor Activity ', ' Motor Activity ', ' Motor Cortex ', ' body movement ', ' Movement ', ' neurophysiological ', ' neurophysiology ', ' neurosurgery ', ' Patients ', ' Phonation ', ' Physiology ', ' Production ', ' Reading ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Speech ', ' Speech Sound ', ' Technology ', ' Testing ', ' Time ', ' Work ', ' Inferior frontal gyrus ', ' Inferior Frontal Convolution ', ' improved ', ' Area ', ' Variation ', ' Variant ', ' Evaluation ', ' Training ', ' Lesion ', ' tongue tip ', ' tongue apex ', ' awake ', ' analog ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' mechanical ', ' Mechanics ', ' Investigation ', ' electrocorticography ', ' Electrocorticogram ', ' Pattern ', ' restoration ', ' phonological ', ' phonology ', ' neural prosthetic ', ' neural prosthesis ', ' neural ', ' relating to nervous system ', ' phrases ', ' Controlled Study ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Excision ', ' Modeling ', ' theories ', ' Address ', ' Physiologic Imaging ', ' Functional Imaging ', ' Process ', ' designing ', ' design ', ' innovation ', ' innovative ', ' innovate ', ' practical application ', ' application in practice ', ' speech processing ', ' stem ', ' tumor ', ' motor control ', ' patient population ', ' ']",NIDCD,NORTHWESTERN UNIVERSITY AT CHICAGO,F32,2016,53358,IL-07,0.183575672057535
"Investigating neural mechanisms for flexible, robust speech perception with fMRI     DESCRIPTION (provided by applicant): The brain is bombarded by sensory information from the world, and must extract certain pieces of useful information using limited neural resources. This means that the brain must be efficient, throwing away information that is not needed in order to focus on the most important part of the sensory information from the world. However, information that is uninformative in one situation may be highly informative in another, and thus this efficiency must be matched by flexibility. One domain where this is particularly true is speech perception, where a noisy, ambiguous sensory signal is mapped onto underlying linguistic units like phonemes, words, and sentences. This mapping changes substantially depending on who is talking. One way the brain might deal with this is to learn talker-specific representations which optimize the efficiency with which speech sounds are processed, and deploy or ""swap out"" those representations whenever the talker changes, learning new representations for new talkers as necessary. While there is some evidence that listeners do use such a strategy, little is known about the underlying neural mechanisms. This proposal seeks to clarify these mechanisms through two specific aims. First, functional magnetic resonance imaging (fMRI) will image the brains of listeners while they are hearing words from two talkers with different accents, mixed together. By comparing the areas that are active when the talker switches with areas that are active during periods of learning about each accent (as measured by behavioral responses), the circuits by which listeners learn and deploy talker-specific representations will be elucidated. Second, using multi-voxel pattern analysis techniques, the neural representations of identical speech sounds which have different interpretations depending on the talker will be measured to determine how deeply talker-specific knowledge affects the processing of speech sounds. If talker-specific knowledge is being used to optimize the efficiency of perceptual processing at a low level, then within-category differences should result in more similar patterns of activity, while across-category differences should result in more distinct patterns of activity.         PUBLIC HEALTH RELEVANCE: The ability to flexibly adjust the processing and representation of speech sounds depending on who is talking is absolutely fundamental to the effective and fluent comprehension of spoken language, and impairments in this ability would make daily life very difficult. Completion of the proposed research has the potential to lead to new views on neurological disorders which impact language, like Williams Syndrome and Specific Language Impairment, and possibly new classifications of these disorders. Furthermore, by linking robust speech comprehension to more general perceptual adaptation and learning, the proposed work has the potential to shed light on the underlying pathology of disorders such as Autism Spectrum Disorders, which have been hypothesized to involve deficiencies in the integration of top-down expectations and bottom-up sensory information, both in language processing (Stewart & Ota, 2008; Yu, 2010) and general perception (Pellicano & Burr, 2012).                ","Investigating neural mechanisms for flexible, robust speech perception with fMRI",8992857,F31HD082893,"['Acoustic ', ' Acoustics ', ' Affect ', ' Auditory Cortex ', ' Auditory area ', ' Behavior ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Breeding ', ' Cognition ', ' Complement Proteins ', ' Complement ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Disorder ', ' Disease ', ' Environment ', ' Future ', ' Goals ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Language ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Learning ', ' Photoradiation ', ' Light ', ' Linguistic ', ' Linguistics ', ' Maps ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' nervous system disorder ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Pathology ', ' Perception ', ' Play ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Resources ', ' Resources ', ' social role ', ' Role ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Voice ', ' Work ', ' Measures ', ' Uncertainty ', ' doubt ', ' Comprehension ', ' mental retardation-typical facies-aortic stenosis syndrome ', ' idiopathic hypercalcemia-supravalvular aortic stenosis syndrome ', ' hypercalcemia/Williams-Beuren syndrome ', ' hypercalcemia-peculiar facies-supravalvular aortic stenosis syndrome ', ' elfin-facies hypercalcemia syndrome ', ' Williams-Beuren Syndrome ', ' Williams-Barratt syndrome ', ' Williams Contiguous Gene Syndrome ', ' Williams Barratt syndrome ', ' Fanconi-Schlesinger syndrome ', ' Fanconi Schlesinger syndrome ', ' Elfin Facies Syndrome ', ' Beuren syndrome ', ' Williams Syndrome ', ' base ', ' improved ', ' brain visualization ', ' Brain imaging ', ' Area ', ' Link ', ' Training ', ' insight ', ' Stimulus ', ' Staging ', ' Shapes ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' fMRI ', ' Functional MRI ', ' Functional Magnetic Resonance Imaging ', ' Knowledge ', ' Life ', ' Auditory ', ' Sensory ', ' Pattern ', ' Techniques ', ' System ', ' specific language impairment ', ' experience ', ' neural ', ' relating to nervous system ', ' Structure ', ' skills ', ' expectation ', ' novel ', ' Categories ', ' nosology ', ' disorder classification ', ' disease classification ', ' Coding System ', ' Code ', ' synaptic circuitry ', ' synaptic circuit ', ' neural circuitry ', ' neural circuit ', ' Property ', ' Accent ', ' Peach ', ' Thickness ', ' Thick ', ' Sensory Process ', ' Address ', ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Transmission ', ' transmission process ', ' Process ', ' Behavioral ', ' neuromechanism ', ' neural mechanism ', ' cognitive neuroscience ', ' speech processing ', ' language processing ', ' public health relevance ', ' neural patterning ', ' flexibility ', ' flexible ', ' behavioral response ', ' behavior response ', ' language impairment ', ' ']",NICHD,UNIVERSITY OF ROCHESTER,F31,2016,20746,NY-25,0.12160884341830175
"Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome     DESCRIPTION (provided by applicant): A major limitation of existing assessments of clinically-relevant mental states related to drug use, abuse, and treatment is that self-report measures rely on the capacity and motivation to accurately report one's internal experiences. A potential alternative is presented by emerging computer-based natural language processing methods that can extract fine-grained semantic, structural, and syntactic features from free speech1, potentially providing a unique 'window into the mind.' These methods are widely used in industry2, yet remain largely unknown in clinical research. To begin to assess the potential of these advanced analytic methods in clinical research, we recently partnered with IBM computer science researchers to test computer-based analysis of speech semantic structure. In preliminary work, we were able to demonstrate that such methods could detect acute drug intoxication3 and accurately predicted the development of psychosis in clinical risk states4. Here, we propose to build on these highly promising initial findings, conducting three secondary data analyses to rapidly and cost-effectively advance this novel direction. Projects 1 and 2 will extend our preliminary work on speech markers of mental state changes during acute drug intoxication. In Project 1, we will assess speech semantic, structural, and syntactic features as markers of mental state changes due to MDMA (0, 0.75, 1.5 mg/kg; oral). In Project 2, we will extend these findings to another drug, assessing speech markers of intoxication with LSD (0, 70 g; intravenous). These projects are possible because we have access to existing transcripts of free speech from within-subject, controlled laboratory studies of the effects of MDMA (N = 77) and LSD (N = 19). Potential future uses for these methods could include rapid characterization of the effects of emerging drugs and, potentially, detection of acute drug intoxication in the absence of biochemical confirmation. Project 3 will assess the use of speech analysis as a prognostic marker in substance abuse treatment. Specifically, we will use speech transcripts (N = 50) from a currently ongoing study to assess whether features extracted from baseline free speech can predict treatment outcome in cocaine users undergoing 12 weeks of CBT relapse prevention. Self-report5,6 and manual coding of speech7-9 suggest that motivation to change may be a predictor of treatment outcome for substance use disorders: we expect that the fine-grained computational methods we will employ will allow the development of more accurate predictive models. The capacity to use automated methods to detect mental states from free speech has wide ranging, potentially transformative implications for addiction medicine and psychiatry more broadly4,10. Results of the proposed secondary analyses projects will efficiently advance understanding of how automated speech analysis, a non-invasive and cost- effective assessment method, could be used in clinical practice and research about drug abuse. More broadly, results may contribute to the empirical basis for the development of automated, objective, speech- based diagnostic and prognostic tests in psychiatry.         PUBLIC HEALTH RELEVANCE: Free speech, a unique `window into the mind', represents a rich source of information that can be mined for clinically-relevant information. This application proposes to apply novel computer science speech analysis methods in three secondary data analysis projects to investigate 1) speech markers of mental states during acute drug intoxication; and 2) speech as a prognostic marker in cognitive behavioral treatment for drug abuse. Results will rapidly and cost-effectively advance understanding of how automated speech analysis could be used in clinical practice and research about drug use, abuse, and treatment.            ",Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome,9017684,R03DA040855,"['Behavior ', ' psychological disorder ', ' psychiatric illness ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Grain ', ' Cereals ', ' Clinical Study ', ' Clinical Research ', ' Cocaine ', ' Cocaine Abuse ', ' cognitive behavioral treatment ', ' cognitive behavioral therapy ', ' cognitive behavioral modification ', ' cognitive behavioral intervention ', ' cognitive behavior therapy ', ' cognitive behavior modification ', ' cognitive behavior intervention ', ' Cognitive Psychotherapy ', ' Cognition Therapy ', ' Cognitive Therapy ', ' Computers ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' data interpretation ', ' Data Analysis ', ' Data Analyses ', ' Disorder ', ' Disease ', ' Double-Masked Study ', ' Double-Masked Method ', ' Double-Blinded ', ' Double-Blind Study ', ' Double-Blind Method ', ' abuses drugs ', ' abuse of drugs ', ' Drug abuse ', ' drug treatment ', ' Drug Therapy ', ' Pharmacotherapy ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Future ', ' Modern Man ', ' Human ', ' Industry ', ' Language ', ' Lysergide ', ' LSD-25 ', ' Lysergic Acid Diethylamide ', ' Manuals ', ' Medicine ', ' Methods ', ' Mining ', ' Moods ', ' Motivation ', ' natural language understanding ', ' Natural Language Processing ', ' Patients ', ' sham therapy ', ' Sham Treatment ', ' Placebos ', ' Psychiatry ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Proposals ', ' Semantics ', ' Speech ', ' Substance Use Disorder ', ' Technology ', ' Testing ', ' Work ', ' Measures ', ' Treatment outcome ', ' Diagnostic tests ', ' ecstasy ', ' N-Methyl-3,4-methylenedioxyamphetamine ', ' N,alpha-dimethyl-1,3-benzodioxole-5-ethanamine ', ' Methylenedioxymethamphetamine ', ' MDMA ', ' 3,4 methylenedioxymethamphetamine ', ' base ', ' Acute ', ' Clinical ', ' Biochemical ', ' Individual ', ' Cocaine Users ', ' drug use ', ' Drug usage ', ' Funding ', ' mental status ', ' mental state ', ' Intravenous ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' programs ', ' Scientist ', ' Complex ', ' Oral ', ' Source ', ' experience ', ' syntactic ', ' syntax ', ' computer science ', ' Structure ', ' novel ', ' research in practice ', ' Laboratory Study ', ' Study Subject ', ' Self-Report ', ' Patient Self-Report ', ' Reporting ', ' Intoxication ', ' Bypass ', ' Coding System ', ' Code ', ' relapse prevention ', ' recurrence prevention ', ' disorder recurrence prevention ', ' disease recurrence prevention ', ' disorder later incidence prevention ', ' Sampling ', ' Data ', ' Detection ', ' prognostic indicator ', ' prognostic biomarker ', ' Prognosis Marker ', ' Molecular Marker of Prognosis ', ' Prognostic Marker ', ' randomly assigned ', ' randomization ', ' randomisation ', ' Randomized ', ' Funding Mechanisms ', ' Transcript ', ' Characteristics ', ' developmental ', ' Development ', ' substance abuse therapy ', ' substance abuse treatment ', ' cost ', ' computerized ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' cost effective ', ' cost-effective ', ' Mind ', ' innovation ', ' innovative ', ' innovate ', ' clinically relevant ', ' clinical relevance ', ' addiction ', ' addictive disorder ', ' high risk ', ' public health relevance ', ' clinical practice ', ' natural language ', ' cocaine use ', ' clinical risk ', ' outcome prediction ', ' predictors of outcomes ', ' predictive outcomes ', ' prognostic assays ', ' prognostic test ', ' ']",NIDA,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2016,81000,NY-13,0.2686426377327967
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9205946,U01NS098971,"['Acoustic ', ' Acoustics ', ' Affect ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Aphasia ', ' apraxia ', ' Dyspraxia ', ' Apraxias ', ' Engineering / Architecture ', ' Architecture ', ' Articulators ', ' Award ', ' Behavior ', ' bioengineering ', ' Biomedical Engineering ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Brain Mapping ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' Communities ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Statistical Correlation ', ' Correlation Studies ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' ethical ', ' Ethics ', ' facial ', ' faces ', ' Face ', ' Gestures ', ' Goals ', ' Modern Man ', ' Human ', ' Jaw ', ' Articulation ', ' Joints ', ' Language ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Learning ', ' Photoradiation ', ' Light ', ' Linguistic ', ' Linguistics ', ' Lip ', ' Lip structure ', ' Maps ', ' Methods ', ' Motor Cortex ', ' body movement ', ' Movement ', ' Mutism ', ' National Institutes of Health ', ' NIH ', ' United States National Institutes of Health ', ' neuronal degeneration ', ' neurodegenerative ', ' neurodegeneration ', ' neural degeneration ', ' Neuron Degeneration ', ' Nerve Degeneration ', ' neurobiological ', ' Neurobiology ', ' Neurology ', ' neurophysiological ', ' neurophysiology ', ' Neurosciences ', ' neurosurgery ', ' Physiology ', ' Play ', ' Population Dynamics ', ' Production ', ' rehabilitative ', ' Rehabilitation ', ' Medical Rehabilitation ', ' Rehabilitation therapy ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' social role ', ' Role ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Stammering ', ' Stuttering ', ' Technology ', ' Time ', ' Tongue ', ' Ultrasonography ', ' ultrasound scanning ', ' ultrasound imaging ', ' ultrasound ', ' sound measurement ', ' sonography ', ' sonogram ', ' diagnostic ultrasound ', ' Ultrasound Test ', ' Ultrasound Medical Imaging ', ' Ultrasound Diagnosis ', ' Ultrasonogram ', ' Ultrasonic Imaging ', ' Medical Ultrasound ', ' Echotomography ', ' Echography ', ' Measures ', ' Mediating ', ' Prefrontal Cortex ', ' Visualization ', ' Imagery ', ' base ', ' density ', ' Procedures ', ' image evaluation ', ' Image Analyses ', ' Image Analysis ', ' Left ', ' Site ', ' Area ', ' Acute ', ' Chronic ', ' Clinical ', ' insight ', ' Individual ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Functional disorder ', ' tool ', ' Nature ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Knowledge ', ' Dimensions ', ' Auditory ', ' Complex ', ' Pattern ', ' System ', ' Amentia ', ' Dementia ', ' paralytic ', ' paralysis ', ' Plegia ', ' Palsy ', ' Paralysed ', ' experience ', ' model organism ', ' Animal Models and Related Studies ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' trait ', ' kinematic model ', ' kinematics ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' Devices ', ' Position ', ' Positioning Attribute ', ' Property ', ' response ', ' Brain region ', ' Address ', ' Data ', ' Resolution ', ' Cognitive ', ' Monitor ', ' Behavioral ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' Trauma ', ' innovation ', ' innovative ', ' innovate ', ' Implant ', ' implantation ', ' cognitive control ', ' spatiotemporal ', ' motor control ', ' sharing data ', ' relational database ', ' temporal measurement ', ' time measurement ', ' temporal resolution ', ' cortex mapping ', ' cortical mapping ', ' cortical map ', ' ']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2016,1099295,CA-12,0.3163779992503433
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8985675,R01DC013547,"['Age ', ' Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Systematics ', ' Classification ', ' Computers ', ' Swallowing ', ' Deglutition ', ' Diagnosis ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' balance function ', ' balance ', ' Equilibrium ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Human ', ' Incidence ', ' Jaw ', ' Language ', ' Lip ', ' Lip structure ', ' Maps ', ' body movement ', ' Movement ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' muscular ', ' Muscle Tissue ', ' Muscle ', ' Persons ', ' Neurology ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Parkinson Disease ', ' Patients ', ' Production ', ' QOL ', ' Quality of life ', ' Research ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech-Language Pathology ', ' voice synthesizer ', ' Speech Synthesizers ', ' statistics ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' stroke ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' Motor Neuron Disease ', ' degenerative disorder of motor neurons ', ' Device Designs ', ' Outcome Measure ', ' Data Set ', ' Dataset ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Staging ', ' Pathologist ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Life ', ' Dimensions ', ' Severities ', ' Oral ', ' System ', ' American ', ' early detection ', ' Early Diagnosis ', ' jaw movement ', ' Performance ', ' Accuracy of Diagnosis ', ' diagnostic accuracy ', ' novel ', ' Participant ', ' experimental study ', ' experimental research ', ' experiment ', ' research study ', ' General Public ', ' General Population ', ' Position ', ' Positioning Attribute ', ' Deterioration ', ' Modeling ', ' oral communication ', ' traumatic brain damage ', ' Brain Trauma ', ' Traumatic Brain Injury ', ' datamining ', ' data mining ', ' Address ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Gulf War ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socio-economically ', ' socio-economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' forging ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' motor impairment ', ' movement limitation ', ' movement impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' movement analysis ', ' communication device ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2016,585316,MA-07,0.24739112916640235
"Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.     DESCRIPTION (provided by applicant): In an effort to intervene before psychosis onset and prevent morbidity, a major recent focus in schizophrenia research has been the identification of young people during a putative prodromal period, so as to develop safe and effective interventions to modify disease course. Over the past decades, studies at Columbia and elsewhere have evaluated clinical high-risk (CHR) individuals across a range of cognitive processes in an effort to identify core deficits of schizophrenia evident before psychosis onset. Subtle thought disorder, manifest in disturbance of language production, is a feature that predates rather than follows, psychosis onset in CHR individuals, and therefore may be an indicator of schizophrenia liability. Subtle thought disorder in schizophrenia and its risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. Here, we propose to instead use a novel automated machine-learning approach to speech analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language. It also evaluates syntax through ""part-of-speech"" tagging. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture subtle thought disorder and discriminate psychosis outcome among CHR individuals. Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we were able to identify a classifier with high accuracy for psychosis onset in a small CHR cohort at Columbia, which included semantic coherence from phrase to phrase, shortened phrase length, and decreased use of determiner pronouns (""which"", ""what"", ""that""). These features were correlated with prodromal symptoms but outperformed them in terms of classification accuracy. They also discriminated schizophrenia from normal speech. While promising, these automated methods of analysis require validation in a second CHR cohort. In this proposal, in collaboration with IBM, we will validate these automated methods using a large archive of speech data from the UCLA CHR cohort. This dataset has several advantages. First, the UCLA CHR cohort has a high prevalence of psychosis transition, important as machine learning is sensitive to group size. Second, it has undergone prior manual linguistic analysis, identifying features of language production that predicted psychosis outcome; hence, automated and manual methods can be directly compared. Third, there are speech data available from healthy controls and recent-onset psychosis patients (for validation). Fourth, several participants have multiple speech assays (such that stability of the classifier can be examined). Beyond validation of methods, we will maximize group size and combine speech data from Columbia and UCLA to characterize a common classifier of psychosis outcome. Automated methods for language analysis may improve prediction of psychosis onset and inform remediation strategies for its prevention.         PUBLIC HEALTH RELEVANCE: Subtle thought disorder is an early core feature of schizophrenia evident before psychosis onset: it has traditionally been evaluated using clinical ratings or labor-intensive manual linguistic analyses. This proposal will apply novel computer-based speech analysis methods to existing datasets to identify abnormal semantic and syntactic features of language production that can predict or classify psychosis outcome among youths at clinical high risk for psychosis. Improved characterization of thought disorder can inform targeted preventive interventions for young people at risk for schizophrenia and related psychotic disorders, so as to reduce the morbidity of psychosis.            ",Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.,9017082,R03MH108933,"['Age ', ' senior citizen ', ' over 65 Elderly ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', ' Aged 65 and Over ', ' Elderly ', ' Archives ', ' Machine Intelligence ', ' Computer Reasoning ', ' Artificial Intelligence ', ' psychological disorder ', ' psychiatric illness ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Biologic Assays ', ' Bioassay ', ' Assay ', ' Biological Assay ', ' Grain ', ' Cereals ', ' Systematics ', ' Classification ', ' Computers ', ' Data Sources ', ' Diagnosis ', ' Disorder ', ' Disease ', ' Modern Man ', ' Human ', ' indexing ', ' Language ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Linguistic ', ' Linguistics ', ' Manuals ', ' Methods ', ' Morbidity ', ' Morbidity - disease rate ', ' natural language understanding ', ' Natural Language Processing ', ' Professional Positions ', ' Jobs ', ' Occupations ', ' Patients ', ' Poverty ', ' Production ', ' Psychiatrist ', ' Psychiatry ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' Research ', ' Risk ', ' social role ', ' Role ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' Semantics ', ' Speech ', ' Testing ', ' thoughts ', ' Thinking ', ' Friends ', ' Youth ', ' Youth 10-21 ', ' Data Set ', ' Dataset ', ' base ', ' improved ', ' Site ', ' Clinical ', ' Training ', ' Individual ', ' Sample Size ', ' Collaborations ', ' tool ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Machine Learning ', ' Scientist ', ' Source ', ' Predniocil ', ' Prednihexal ', ' Predni-POS ', ' Predni-H ', ' Prednefrin SF ', ' Predcor ', ' Predate ', ' Predalone ', ' Predaject ', ' Pred Mild ', ' Pred Forte ', ' Pred Fort ', ' Ophtho-Tate ', ' Locaseptil-Neo ', ' Key-Pred ', ' Inflanefran ', ' Inf-Oph ', ' Hydrocortancyl ', ' Hexacortone ', ' Econopred ', ' Diopred ', ' Deltacortilen ', ' Balpred ', ' Articulose-50 ', ' Ak-Tate ', ' Deltastab ', ' syntactic ', ' syntax ', ' hazard ', ' cohort ', ' phrases ', ' Structure ', ' novel ', ' Participant ', ' Prevention ', ' Emotional ', ' Sampling ', ' preventing ', ' prevent ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' High Prevalence ', ' preventional intervention strategy ', ' Prevention intervention ', ' Preventative intervention ', ' Preventive Intervention ', ' Validation ', ' Text ', ' developmental ', ' Development ', ' Output ', ' remediation ', ' Outcome ', ' Population ', ' Impairment ', ' demographics ', ' high risk ', ' public health relevance ', ' effective intervention ', ' standard of care ', ' targeted treatment ', ' targeted therapy ', ' targeted therapeutic agents ', ' targeted therapeutic ', ' targeted drug treatments ', ' targeted drug therapy ', ' cognitive process ', ' disabling symptom ', ' debilitating symptom ', ' ']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2016,81000,NY-13,0.1175872370871114
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility  the final arbiter of speech goodness  is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.  There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9312085,R01DC006859,"['Acoustic ', ' Acoustics ', ' Affect ', ' Algorithms ', ' Attention ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Cues ', ' Dysarthosis ', ' Dysarthria ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' treatment access ', ' health services availability ', ' health service access ', ' care access ', ' availability of services ', ' accessibility to health services ', ' access to treatment ', ' access to services ', ' access to health services ', ' Access to Care ', ' Health Services Accessibility ', ' Judgment ', ' Language ', ' Learning ', ' Theoretical model ', ' Theoretic Models ', ' nervous system disorder ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Periodicity ', ' Rhythmicity ', ' Cyclicity ', ' Recruitment Activity ', ' recruit ', ' active recruitment ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' instructional intervention ', ' Training Intervention ', ' Instruction Intervention ', ' Education for Intervention ', ' Educational Intervention ', ' Pathologist ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Trauma ', ' neurotrauma ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Code ', ' Coding System ', ' Modeling ', ' Sampling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' health disparity ', ' disparity in health ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' outcome prediction ', ' predictors of outcomes ', ' predictive outcomes ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,311471,AZ-09,0.3565471150187476
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants     DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9305035,R01DC014290,"['Acoustic ', ' Acoustics ', ' Affect ', ' Algorithms ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Cochlear Implants ', ' Environment ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Maps ', ' Masks ', ' Methods ', ' Noise ', ' Problem Solving ', ' Quality of life ', ' QOL ', ' Recruitment Activity ', ' recruit ', ' active recruitment ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Comprehension ', ' base ', ' improved ', ' Surface ', ' Ensure ', ' Stimulus ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Frequencies ', ' Home environment ', ' Home ', ' Source ', ' Location ', ' Hearing Impaired Persons ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' Performance ', ' speech recognition ', ' success ', ' simulation ', ' Categories ', ' Environmental Risk Factor ', ' environmental risk ', ' Environmental Factor ', ' Devices ', ' Modeling ', ' response ', ' Address ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' speech processing ', ' public health relevance ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2017,293476,NC-04,0.26989920720488025
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9356341,U01NS098971,"['Acoustic ', ' Acoustics ', ' Affect ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Aphasia ', ' apraxia ', ' Dyspraxia ', ' Apraxias ', ' Engineering / Architecture ', ' Architecture ', ' Archives ', ' Articulators ', ' Award ', ' Behavior ', ' bioengineering ', ' Biomedical Engineering ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Brain Mapping ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' Communities ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Statistical Correlation ', ' Correlation Studies ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' ethical ', ' Ethics ', ' facial ', ' faces ', ' Face ', ' Foundations ', ' Gestures ', ' Goals ', ' Modern Man ', ' Human ', ' Jaw ', ' Language ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Learning ', ' Light ', ' Photoradiation ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Maps ', ' Methods ', ' Methodology ', ' Motor Cortex ', ' Movement ', ' body movement ', ' Mutism ', ' United States National Institutes of Health ', ' National Institutes of Health ', ' NIH ', ' Nerve Degeneration ', ' neuronal degeneration ', ' neurodegenerative ', ' neurodegeneration ', ' neural degeneration ', ' Neuron Degeneration ', ' Neurobiology ', ' neurobiological ', ' Neurology ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' neurosurgery ', ' Physiology ', ' Play ', ' Population Dynamics ', ' Production ', ' Rehabilitation therapy ', ' rehabilitative ', ' Rehabilitation ', ' Medical Rehabilitation ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Stuttering ', ' Stammering ', ' Technology ', ' Time ', ' Tongue ', ' ultrasound scanning ', ' ultrasound imaging ', ' ultrasound ', ' sound measurement ', ' sonography ', ' sonogram ', ' diagnostic ultrasound ', ' Ultrasound Test ', ' Ultrasound Medical Imaging ', ' Ultrasound Diagnosis ', ' Ultrasonogram ', ' Ultrasonic Imaging ', ' Medical Ultrasound ', ' Echotomography ', ' Echography ', ' Ultrasonography ', ' Measures ', ' Mediating ', ' Prefrontal Cortex ', ' Visualization ', ' Imagery ', ' base ', ' density ', ' Procedures ', ' Left ', ' Site ', ' Area ', ' Acute ', ' Chronic ', ' Clinical ', ' insight ', ' Individual ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Functional disorder ', ' tool ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Electrocorticogram ', ' electrocorticography ', ' Dimensions ', ' Auditory ', ' Complex ', ' Pattern ', ' System ', ' Dementia ', ' Amentia ', ' Paralysed ', ' paralytic ', ' paralysis ', ' Plegia ', ' Palsy ', ' experience ', ' synergism ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' trait ', ' kinematics ', ' kinematic model ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Devices ', ' Positioning Attribute ', ' Position ', ' Property ', ' response ', ' Brain region ', ' Address ', ' Data ', ' Resolution ', ' Cognitive ', ' Monitor ', ' Behavioral ', ' imaging ', ' Image ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' Trauma ', ' innovation ', ' innovative ', ' innovate ', ' multidisciplinary ', ' Implant ', ' implantation ', ' cognitive control ', ' spatiotemporal ', ' motor control ', ' sharing data ', ' relational database ', ' temporal measurement ', ' time measurement ', ' temporal resolution ', ' Articulation ', ' ']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,1099885,CA-12,0.3163779992503433
"Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests Project summary. This Phase I will establish the feasibility of increasing audiological diagnostic information by carrying out word- and phoneme-level analyses of open set responses during speech audiometry and by obtaining subjective hearing measures. Speech audiometry is used in characterizing functional hearing in settings of hearing screening, diagnosis, hearing aid fitting, counseling, aural rehabilitation/training, occupational fitness, and research. A typical procedure used with word and sentence tests in background noise is to ask the client/patient to repeat back what was just said (i.e., give an open set response). Responses are then scored in terms of words or keywords correct/incorrect. This method discards potentially diagnostic information in response errors, because noise can reveal systematic phonetic feature or phoneme confusions, and with background babble, intrusions from the babble. Other response patterns attributable to cognitive or memory declines may manifest in the paucity or verbosity of response words. Specific types of phoneme perception errors are thought to be associated with extent and configuration of hearing loss; and different types of noise maskers (i.e., energetic and informational maskers) present different types of perceptual problems that vary in severity across individuals. In order to utilize response errors, computational methods are needed to establish their relationships to the stimulus. This is because response errors may incorporate incorrect stimulus-to-response phoneme substitutions, as well as insertions or deletions of phonemes or words relative to the stimulus. We have developed sequence alignment methods to mine errors during speech audiometry, which we propose to evaluate using our system (Multi-Measure SPIN Chart: MMSPIN Chart). MMSPIN chart will be further developed and installed in the George Washington University Speech & Hearing Center (Aim 1). Audiologists will use the system during QuickSin sentence and NU-6 word testing with 200 clients (18-85 years of age) who give permission to access their entire clinic records (Aim 2). Their conventional speech audiometry will be augmented by obtaining subjective hearing accuracy judgments and hearing self-efficacy measures. These subjective judgments are designed to expose discrepancies with objective performance and to reveal individual differences in social cognition associated with hearing loss, both of which may account for the large individual differences in performance and intervention outcomes not accounted for by the audiogram. Evaluation of results in Aim 3 will include developing group and individual profile models comprising objective and subjective clinical data. With our clinician partners, we will develop formats for communicating MMSPIN Chart results to clients. In Aim 4, we will present results in a public lecture for audiologists and solicit opinions about how our new results may best impact clinical practice. Our approach can deliver more informative and efficient speech audiometry using existing test materials and can pave the way to more sensitive speech audiometry, including tests that are adaptive to specific levels of speech processing difficulty. Narrative. The typical approach to speech audiometry is to elicit open set responses that are scored in terms of words/keywords correct, discarding information in response errors. This Phase I will establish the feasibility of increasing diagnostic information provided to audiologists by carrying out word- and phoneme-level analyses of open set responses and obtaining subjective hearing measures in conjunction with speech audiometry. The goal is to improve clinical efficiency and effectiveness and to improve patient outcomes.","Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests",9408539,R43DC015749,"['adulthood ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' ages ', ' Age ', ' health attitude ', ' Attitude to Health ', ' Audiometric Test ', ' Audiogram ', ' Audiometry ', ' Pure-Tone Audiometry ', ' Speech Audiometry ', ' Dorsum ', ' Back ', ' Systematics ', ' Classification ', ' Client ', ' Computers ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Mental Confusion ', ' Confusional State ', ' Confusion ', ' Counseling ', ' Diagnosis ', ' Focus Groups ', ' Goals ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Hearing Aids ', ' Judgment ', ' Materials Testing ', ' Methods ', ' Noise ', ' Patients ', ' Perception ', ' permissiveness ', ' Questionnaires ', ' Records ', ' Recruitment Activity ', ' recruit ', ' active recruitment ', ' Rehabilitation therapy ', ' rehabilitative ', ' Rehabilitation ', ' Medical Rehabilitation ', ' Research ', ' Role ', ' social role ', ' Speech ', ' Speech Perception ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Universities ', ' visual function ', ' Sight ', ' Vision ', ' Voice ', ' Washington ', ' Work ', ' Measures ', ' sequencing alignment ', ' Sequence Alignment ', ' Factor Analyses ', ' Factor Analysis ', ' improved ', ' Procedures ', ' Clinical ', ' Phase ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' data repository ', ' Databanks ', ' Data Bases ', ' Data Banks ', ' Databases ', ' satisfaction ', ' Impaired cognition ', ' cognitively impaired ', ' cognitive loss ', ' cognitive dysfunction ', ' Disturbance in cognition ', ' Cognitive function abnormal ', ' Cognitive decline ', ' Cognitive Impairment ', ' Cognitive Disturbance ', ' Diagnostic ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' lectures ', ' Severities ', ' Clinic ', ' Pattern ', ' System ', ' Test Result ', ' hearing screening ', ' Occupational ', ' Performance ', ' speech recognition ', ' phonology ', ' phonological ', ' Self Efficacy ', ' Patient Self-Report ', ' Self-Report ', ' Memory Loss ', ' memory decline ', ' Modeling ', ' response ', ' social cognition ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Effectiveness ', ' hearing impairment ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' fitness ', ' Age-Years ', ' Data ', ' Clinical Data ', ' Patient-Centered Outcomes ', ' Patient outcome ', ' Patient-Focused Outcomes ', ' Permission ', ' Authorization ', ' Authorization documentation ', ' developmental ', ' Development ', ' comparison group ', ' data modeling ', ' designing ', ' design ', ' touchscreen panel ', ' touch screen panel ', ' touch screen ', ' touch panel ', ' touchscreen ', ' Outcome ', ' Individual Differences ', ' speech processing ', ' clinical practice ', ' ']",NIDCD,"SEEHEAR, LLC",R43,2017,147919,VA-08,0.1986927753578535
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,9185964,R01DC013547,"['ages ', ' Age ', ' Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Systematics ', ' Classification ', ' Computers ', ' Swallowing ', ' Deglutition ', ' Diagnosis ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Human ', ' Incidence ', ' Jaw ', ' Language ', ' Lip structure ', ' Lip ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Muscle ', ' muscular ', ' Muscle Tissue ', ' Persons ', ' Neurology ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Synthesizers ', ' voice synthesizer ', ' statistics ', ' stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' degenerative disorder of motor neurons ', ' Motor Neuron Disease ', ' Device Designs ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Pathologist ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Dimensions ', ' Severities ', ' Oral ', ' System ', ' American ', ' Early Diagnosis ', ' early detection ', ' jaw movement ', ' Performance ', ' diagnostic accuracy ', ' Accuracy of Diagnosis ', ' novel ', ' Participant ', ' General Population ', ' General Public ', ' Positioning Attribute ', ' Position ', ' Deterioration ', ' Modeling ', ' oral communication ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' data mining ', ' datamining ', ' Address ', ' Gulf War ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socio-economically ', ' socio-economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' improved functioning ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' motor impairment ', ' movement limitation ', ' movement impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' movement analysis ', ' communication device ', ' experimental study ', ' experimental research ', ' experiment ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2017,581327,MA-07,0.24739112916640235
"Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome     DESCRIPTION (provided by applicant): A major limitation of existing assessments of clinically-relevant mental states related to drug use, abuse, and treatment is that self-report measures rely on the capacity and motivation to accurately report one's internal experiences. A potential alternative is presented by emerging computer-based natural language processing methods that can extract fine-grained semantic, structural, and syntactic features from free speech1, potentially providing a unique 'window into the mind.' These methods are widely used in industry2, yet remain largely unknown in clinical research. To begin to assess the potential of these advanced analytic methods in clinical research, we recently partnered with IBM computer science researchers to test computer-based analysis of speech semantic structure. In preliminary work, we were able to demonstrate that such methods could detect acute drug intoxication3 and accurately predicted the development of psychosis in clinical risk states4. Here, we propose to build on these highly promising initial findings, conducting three secondary data analyses to rapidly and cost-effectively advance this novel direction. Projects 1 and 2 will extend our preliminary work on speech markers of mental state changes during acute drug intoxication. In Project 1, we will assess speech semantic, structural, and syntactic features as markers of mental state changes due to MDMA (0, 0.75, 1.5 mg/kg; oral). In Project 2, we will extend these findings to another drug, assessing speech markers of intoxication with LSD (0, 70 g; intravenous). These projects are possible because we have access to existing transcripts of free speech from within-subject, controlled laboratory studies of the effects of MDMA (N = 77) and LSD (N = 19). Potential future uses for these methods could include rapid characterization of the effects of emerging drugs and, potentially, detection of acute drug intoxication in the absence of biochemical confirmation. Project 3 will assess the use of speech analysis as a prognostic marker in substance abuse treatment. Specifically, we will use speech transcripts (N = 50) from a currently ongoing study to assess whether features extracted from baseline free speech can predict treatment outcome in cocaine users undergoing 12 weeks of CBT relapse prevention. Self-report5,6 and manual coding of speech7-9 suggest that motivation to change may be a predictor of treatment outcome for substance use disorders: we expect that the fine-grained computational methods we will employ will allow the development of more accurate predictive models. The capacity to use automated methods to detect mental states from free speech has wide ranging, potentially transformative implications for addiction medicine and psychiatry more broadly4,10. Results of the proposed secondary analyses projects will efficiently advance understanding of how automated speech analysis, a non-invasive and cost- effective assessment method, could be used in clinical practice and research about drug abuse. More broadly, results may contribute to the empirical basis for the development of automated, objective, speech- based diagnostic and prognostic tests in psychiatry. PUBLIC HEALTH RELEVANCE: Free speech, a unique `window into the mind', represents a rich source of information that can be mined for clinically-relevant information. This application proposes to apply novel computer science speech analysis methods in three secondary data analysis projects to investigate 1) speech markers of mental states during acute drug intoxication; and 2) speech as a prognostic marker in cognitive behavioral treatment for drug abuse. Results will rapidly and cost-effectively advance understanding of how automated speech analysis could be used in clinical practice and research about drug use, abuse, and treatment.",Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome,9232130,R03DA040855,"['Complex ', ' Oral ', ' Source ', ' experience ', ' syntax ', ' syntactic ', ' computer science ', ' Structure ', ' novel ', ' Laboratory Study ', ' Study Subject ', ' Patient Self-Report ', ' Self-Report ', ' Reporting ', ' Intoxication ', ' Bypass ', ' Code ', ' Coding System ', ' disorder later incidence prevention ', ' relapse prevention ', ' recurrence prevention ', ' disorder recurrence prevention ', ' disease recurrence prevention ', ' Sampling ', ' Data ', ' Detection ', ' Prognostic Marker ', ' prognostic indicator ', ' prognostic biomarker ', ' Prognosis Marker ', ' Molecular Marker of Prognosis ', ' Randomized ', ' randomly assigned ', ' randomization ', ' randomisation ', ' Funding Mechanisms ', ' Transcript ', ' Characteristics ', ' developmental ', ' Development ', ' substance abuse therapy ', ' substance abuse treatment ', ' cost ', ' computerized ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Clinical assessments ', ' cost effective ', ' cost-effective ', ' Mind ', ' innovation ', ' innovative ', ' innovate ', ' clinically relevant ', ' clinical relevance ', ' addiction ', ' addictive disorder ', ' high risk ', ' public health relevance ', ' clinical practice ', ' natural language ', ' cocaine use ', ' clinical risk ', ' Patient risk ', ' outcome prediction ', ' predictors of outcomes ', ' predictive outcomes ', ' prognostic assays ', ' prognostic test ', ' secondary analysis ', ' Behavior ', ' psychological disorder ', ' psychiatric illness ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Grain ', ' Cereals ', ' Clinical Study ', ' Clinical Research ', ' Cocaine ', ' Cocaine Abuse ', ' cognitive behavioral treatment ', ' cognitive behavioral therapy ', ' cognitive behavioral modification ', ' cognitive behavioral intervention ', ' cognitive behavior therapy ', ' cognitive behavior modification ', ' cognitive behavior intervention ', ' Cognitive Psychotherapy ', ' Cognition Therapy ', ' Cognitive Therapy ', ' Computers ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' data interpretation ', ' Data Analysis ', ' Data Analyses ', ' Disorder ', ' Disease ', ' Double-Masked Study ', ' Double-Masked Method ', ' Double-Blinded ', ' Double-Blind Study ', ' Double-Blind Method ', ' abuses drugs ', ' abuse of drugs ', ' Drug abuse ', ' drug treatment ', ' Drug Therapy ', ' Pharmacotherapy ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Future ', ' Modern Man ', ' Human ', ' Industry ', ' Language ', ' Lysergic Acid Diethylamide ', ' Lysergide ', ' LSD-25 ', ' Manuals ', ' Medicine ', ' Methods ', ' Moods ', ' Motivation ', ' Natural Language Processing ', ' natural language understanding ', ' Patients ', ' Placebos ', ' sham therapy ', ' Sham Treatment ', ' Psychiatry ', ' Psychotic Disorders ', ' psychotic illness ', ' Psychoses ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Research Proposals ', ' Semantics ', ' Speech ', ' Substance Use Disorder ', ' Technology ', ' Testing ', ' Work ', ' Measures ', ' Treatment outcome ', ' Diagnostic tests ', ' N-Methyl-3,4-methylenedioxyamphetamine ', ' N,alpha-dimethyl-1,3-benzodioxole-5-ethanamine ', ' Methylenedioxymethamphetamine ', ' MDMA ', ' 3,4 methylenedioxymethamphetamine ', ' ecstasy ', ' analytical method ', ' base ', ' Acute ', ' Clinical ', ' Biochemical ', ' Individual ', ' Cocaine Users ', ' drug use ', ' Drug usage ', ' Funding ', ' mental status ', ' mental state ', ' Intravenous ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' programs ', ' Scientist ', ' ']",NIDA,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2017,81000,NY-13,0.2686426377327967
"Neurophysiology of robust speech perception in human superior temporal gyrus DESCRIPTION (provided by applicant): Perceiving and following an individual speaker in a crowded, noisy environment is a commonplace task for listeners with normal hearing. The underlying neurophysiology, however, is complex, and the task remains a struggle for people with peripheral and central auditory pathway disorders. The lack of a detailed neurobiological model of mechanisms and functions underlying robust speech perception has hindered our understanding of how these processes become impaired in the suffering population. In our innovative approach, we will record from high-density micro and macro electrode arrays surgically implanted on the superior temporal gyrus of epilepsy patients as part of their clinical evaluation. This method offers an exceptionally detailed perspective of cortical population activity. We will build upon two recent complementary findings where we identified a highly selective, spatially distributed neural representation of phonetic features (Mesgarani et. al. Science, 2014), which at the same time is highly dynamic and can change rapidly to reflect the perceptual bias of the listener (Mesgarani & Chang, Nature 2012). While significant, these studies revealed several gaps in our understanding of this process, which we intend to address in this proposal. Specifically, we will resolve the following unanswered questions: 1) what is the neural mechanism for joint encoding of both phonetic and speaker features? 2) How does attention modulate phonetic and speaker feature selectivity of neural responses? And 3) what computational mechanisms can account for dynamic feature selectivity of responses in STG? Answering these questions will significantly advance our understanding of a remarkable human ability, and will be of great interest to researchers from many areas including neurologists, and sensory and cognitive neuroscientists. PUBLIC HEALTH RELEVANCE: Understanding the mechanisms underlying speech perception in challenging environments is a crucial step in determining how these processes deteriorate in various disorders of peripheral and central auditory pathways. Our studies will result in novel neurobiological models of robust speech perception that will serve as a necessary step toward designing innovative therapeutic measures.",Neurophysiology of robust speech perception in human superior temporal gyrus,9231432,R01DC014279,"['Acoustic ', ' Acoustics ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Aphasia ', ' Attention ', ' Central Auditory Pathway Disorders ', ' Central Auditory Dysfunction ', ' Central Auditory Diseases ', ' auditory pathway ', ' Encephalon ', ' Brain Nervous System ', ' Brain ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Crowding ', ' Cues ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' Environment ', ' epileptogenic ', ' epileptiform ', ' epilepsia ', ' Seizure Disorder ', ' Epileptics ', ' Epileptic Seizures ', ' Epilepsy ', ' Feedback ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Modern Man ', ' Human ', ' indexing ', ' Joints ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Literature ', ' Methods ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' neurophysiology ', ' neurophysiological ', ' Patients ', ' Perception ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Science ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Specificity ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' Speech Pathology ', ' Mediating ', ' Superior temporal gyrus ', ' Comprehension ', ' Custom ', ' Intention ', ' Prosthetics ', ' Prosthetic device ', ' Prosthesis ', ' density ', ' Peripheral ', ' Site ', ' Area ', ' Surface ', ' Link ', ' selective attention ', ' receptive field ', ' Discipline ', ' Individual ', ' Neurologist ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Complex ', ' Sensory ', ' Techniques ', ' Dyslexia ', ' Word Blindness ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' interest ', ' relating to nervous system ', ' neural ', ' expectation ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Code ', ' Coding System ', ' Modeling ', ' Property ', ' response ', ' Address ', ' Resolution ', ' clinical test ', ' Clinical Testing ', ' Clinical Evaluation ', ' research clinical testing ', ' Cognitive ', ' Characteristics ', ' Process ', ' computational framework ', ' computer framework ', ' designing ', ' design ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' Implant ', ' speech processing ', ' attentional modulation ', ' attention modulation ', ' spatiotemporal ', ' public health relevance ', ' cognitive ability ', ' learning strategy ', ' learning method ', ' learning activity ', ' experimental study ', ' experimental research ', ' experiment ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2017,396360,NY-13,0.1701572157265675
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9355730,U01NS098969,"['Acoustic ', ' Acoustics ', ' Basal Nuclei ', ' Basal Ganglia ', ' Cues ', ' Dysarthosis ', ' Dysarthria ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Electrophysiology (science) ', ' Goals ', ' Language ', ' Linguistics ', ' Linguistic ', ' Methods ', ' Movement ', ' body movement ', ' Movement Disorders ', ' Movement Disorder Syndromes ', ' Dyskinesia Syndromes ', ' nervous system disorder ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Production ', ' Role ', ' social role ', ' Speech ', ' Supervision ', ' Testing ', ' Time ', ' Universities ', ' Voice ', ' Measures ', ' Subthalamic Nucleus ', ' Nucleus Subthalamicus ', ' Structure of subthalamic nucleus ', ' analytical method ', ' base ', ' Clinical ', ' Phase ', ' Stimulus ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Deep Brain Stimulation ', ' Event ', ' Stream ', ' Pattern ', ' Techniques ', ' System ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Performance ', ' relating to nervous system ', ' neural ', ' kinematics ', ' kinematic model ', ' novel ', ' member ', ' Code ', ' Coding System ', ' Modeling ', ' response ', ' Adverse effects ', ' treatment adverse effect ', ' therapy adverse effect ', ' side effect ', ' Treatment Side Effects ', ' Address ', ' Data ', ' Motor ', ' Output ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' cognitive neuroscience ', ' multidisciplinary ', ' gain of function ', ' STN stimulation ', ' subthalamic nucleus stimulation ', ' microstimulation ', ' learning strategy ', ' learning method ', ' learning activity ', ' motor symptom ', ' ']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2017,1157250,PA-18,0.22462395316098602
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustic ', ' Acoustics ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' Affect ', ' Animals ', ' Auditory Cortex ', ' Auditory area ', ' Auditory Perception ', ' Psychoacoustical Disorders ', ' Auditory Processing Disorder ', ' Auditory Perceptual Diseases ', ' Auditory Comprehension Disorder ', ' Acoustic Perceptual Disorder ', ' Auditory Perceptual Disorders ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autism ', ' Autistic Disorder ', ' Behavior ', ' Biologic Assays ', ' Bioassay ', ' Assay ', ' Biological Assay ', ' Avian ', ' Aves ', ' Birds ', ' Communication ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' Cues ', ' Diagnosis ', ' Disorder ', ' Disease ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Electrophysiology (science) ', ' Elements ', ' Environment ', ' Foundations ', ' Goals ', ' Heart ', ' Modern Man ', ' Human ', ' Infant ', ' Language ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Learning ', ' Longevity ', ' lifespan ', ' life span ', ' Length of Life ', ' Methods ', ' Biological Models ', ' Model System ', ' Biologic Models ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurosciences ', ' Perception ', ' Population Dynamics ', ' Quality of life ', ' QOL ', ' Research ', ' Role ', ' social role ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Testing ', ' Time ', ' Work ', ' Measures ', ' Superior temporal gyrus ', ' Comprehension ', ' improved ', ' Physiologic ', ' Physiological ', ' Link ', ' Training ', ' Failure ', ' Stimulus ', ' Individual ', ' root ', ' Plant Roots ', ' Sturnus vulgaris ', ' Sturnidae ', ' Starlings ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Auditory ', ' Complex ', ' Parietal ', ' Stream ', ' Pattern ', ' Techniques ', ' System ', ' specific language impairment ', ' Dyslexia ', ' Word Blindness ', ' Nuclear ', ' Services ', ' Auditory system ', ' speech recognition ', ' success ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' Songbirds ', ' song bird ', ' Oscines ', ' Structure ', ' Transition Elements ', ' transition metal ', ' Categories ', ' Devices ', ' Learning Disabilities ', ' Learning disability ', ' Code ', ' Coding System ', ' neural circuit ', ' synaptic circuitry ', ' synaptic circuit ', ' neural circuitry ', ' Modeling ', ' Property ', ' response ', ' model development ', ' pattern perception ', ' hearing impairment ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Data ', ' Cognitive ', ' Computational Technique ', ' Process ', ' Behavioral ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' bird song ', ' birdsong ', ' speech processing ', ' language processing ', ' spatiotemporal ', ' neurobiological mechanism ', ' neural patterning ', ' microstimulation ', ' Systems Development ', ' signal processing ', ' cognitive process ', ' experimental study ', ' experimental research ', ' experiment ', ' auditory processing ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,CA-52,0.06289920749652303
"Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates     DESCRIPTION (provided by applicant): 90% of the 1.5 million Americans living with idiopathic Parkinson's disease (PD) and 50% of the 500,000 Americans living with Multiple Sclerosis (MS) will experience dysarthria. Dysarthria has devastating consequences for life quality and participation in society due to its effects on employment, leisure activities and social relationships. Knowledge of therapy techniques for maximizing perceived speech adequacy, as indexed by the gold standard perceptual construct of intelligibility is thus of vital importance. Owing to the scarcity of impartial comparative studies, the choice of one technique over others is often based on trial and error or reflects clinician bias, both of which are at odds with evidence-based practice. This project has sought to address this critical gap in knowledge regarding the comparative merits of dysarthria treatment techniques since its inception. Toward this end, published studies from the past funding cycle compared the acoustic and perceptual merits of three common, global dysarthria treatment techniques including 1) rate manipulation, 2) an increased vocal intensity and 3) clear speech in MS and PD as well as age and sex matched neurotypical talkers. Global treatment techniques by their very nature elicit co-occurring acoustic changes (e.g., duration, segmental articulation). Because an explanatory, acoustically-based model of intelligibility is lacking, the acoustic change(s) causing or explainin the improved perceptual outcomes of global treatment techniques are unknown. Determining the acoustic variables explaining intelligibility variation in dysarthria would not only tremendousy advance theoretical understanding of intelligibility but also would strengthen the scientific basis for treatment. Treatment focused on those acoustic variables explanatory for improved intelligibility may further accelerate progress in therapy. Importantly, research from the previous funding cycle suggests the promise of speech analysis-resynthesis for identifying segmental and suprasegmental acoustic variables explanatory for intelligibility in dysarthria. Building upon this work, the overarching goal of the continuation is to contribute towards development of an acoustically-based explanatory model of intelligibility. Our approach 1) employs established perceptual procedures and acoustic measures, 2) uses an innovative analysis-resynthesis technique that permits conclusions concerning the explanatory relationship between acoustic changes accompanying dysarthria therapy techniques and intelligibility, and 3) leverages methods from machine learning to build a predictive model of intelligibility from acoustics. The impact of this work is in its contribution to 1) advancing conceptual understanding of intelligibility, 2) strengthening the scientific basis for treatment, and 3) optimizing clinical implementation of dysarthria therapy techniques. PUBLIC HEALTH RELEVANCE: This project is directly relevant to the mission of NIDCD due to its focus on investigating the therapeutic techniques for maximizing intelligibility in dysarthra secondary to Parkinson's disease and Multiple Sclerosis. By advancing conceptual understanding of intelligibility, this research will strengthen the scientific basis for dysarthria treatments and will optimize their clinical implementation.",Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates,9334170,R01DC004689,"['Acoustic ', ' Acoustics ', ' Affect ', ' ages ', ' Age ', ' Comparative Study ', ' Dysarthosis ', ' Dysarthria ', ' Employment ', ' Goals ', ' Gold ', ' indexing ', ' Leisure Activities ', ' Methods ', ' Mission ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Production ', ' Publishing ', ' Quality of life ', ' QOL ', ' Research ', ' Societies ', ' Speech ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Secondary to ', ' base ', ' improved ', ' Procedures ', ' Clinical ', ' Variation ', ' Variant ', ' Individual ', ' Funding ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Frequencies ', ' Techniques ', ' American ', ' experience ', ' treatment program ', ' social ', ' Modeling ', ' Orthography ', ' orthographical ', ' orthographic ', ' hearing impairment ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Address ', ' Evidence based practice ', ' sex ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' innovation ', ' innovative ', ' innovate ', ' comparative ', ' public health relevance ', ' clear speech ', ' Idiopathic Parkinson Disease ', ' Articulation ', ' ']",NIDCD,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2017,517281,NY-26,0.060050512759730355
"Speech Movement Classification for Assessing and Treating ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",Speech Movement Classification for Assessing and Treating ALS,9341526,R01DC013547,"['ages ', ' Age ', ' Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Systematics ', ' Classification ', ' Computers ', ' Swallowing ', ' Deglutition ', ' Diagnosis ', ' Disorder ', ' Disease ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Human ', ' Incidence ', ' Jaw ', ' Language ', ' Lip structure ', ' Lip ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Muscle ', ' muscular ', ' Muscle Tissue ', ' Persons ', ' Neurology ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Synthesizers ', ' voice synthesizer ', ' statistics ', ' stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' degenerative disorder of motor neurons ', ' Motor Neuron Disease ', ' Device Designs ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Pathologist ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Dimensions ', ' Severities ', ' Oral ', ' System ', ' American ', ' Early Diagnosis ', ' early detection ', ' jaw movement ', ' Performance ', ' diagnostic accuracy ', ' Accuracy of Diagnosis ', ' novel ', ' Participant ', ' General Population ', ' General Public ', ' Positioning Attribute ', ' Position ', ' Deterioration ', ' Modeling ', ' oral communication ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' data mining ', ' datamining ', ' Address ', ' Gulf War ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socio-economically ', ' socio-economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' improved functioning ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' motor impairment ', ' movement limitation ', ' movement impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' movement analysis ', ' communication device ', ' experimental study ', ' experimental research ', ' experiment ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2017,93248,MA-07,0.24739112916640235
"Dynamics of Vocal Tract Shaping     DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9177754,R01DC007124,"['Acoustic ', ' Acoustics ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Adult ', ' apraxia ', ' Dyspraxia ', ' Apraxias ', ' Articulators ', ' Beds ', ' Communication ', ' Communities ', ' Swallowing Disorders ', ' Dysphagia ', ' Deglutition Disorders ', ' Engineering ', ' Epiglottis ', ' Epiglottis structure ', ' Gestures ', ' Glossectomy ', ' Goals ', ' Modern Man ', ' Human ', ' Language ', ' Language Disorders ', ' language deficit ', ' Language disability ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Magnetic Resonance Imaging ', ' Zeugmatography ', ' Nuclear Magnetic Resonance Imaging ', ' NMR Tomography ', ' NMR Imaging ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' MRI ', ' MR Tomography ', ' MR Imaging ', ' Motion ', ' Movement ', ' body movement ', ' Noise ', ' Pharyngeal structure ', ' Throat ', ' Pharynx ', ' Play ', ' Posture ', ' Production ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Self-Help Devices ', ' assistive device ', ' Assistive Technology ', ' Sleep Apnea Syndromes ', ' sleep-related breathing disorder ', ' Sleep-Disordered Breathing ', ' Sleep Hypopnea ', ' Sleep Apnea ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Surgical Flaps ', ' Island Flaps ', ' Flaps ', ' Educational process of instructing ', ' Teaching ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Traction ', ' Work ', ' Measures ', ' base ', ' image processing ', ' improved ', ' Lateral ', ' Clinical ', ' Variation ', ' Variant ', ' Series ', ' Training ', ' tongue tip ', ' tongue apex ', ' Individual ', ' Recovery ', ' Shapes ', ' tool ', ' German population ', ' German ', ' instrument ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Investigation ', ' Dimensions ', ' Complex ', ' Event ', ' Oral ', ' In Situ ', ' Pattern ', ' System ', ' Oropharyngeal ', ' oral pharyngeal ', ' Oropharynxs ', ' Oropharynx ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' speech recognition ', ' phonology ', ' phonological ', ' cohesion ', ' Speed ', ' Structure ', ' novel ', ' movie ', ' outreach ', ' technological innovation ', ' Modeling ', ' Property ', ' theories ', ' bioimaging ', ' biomedical imaging ', ' bio-imaging ', ' Three-Dimensional Imaging ', ' Three Dimensional Medical Imaging ', ' 3D imaging ', ' 3-D Imaging ', ' Data ', ' International ', ' Resolution ', ' Cardiac ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' website ', ' web site ', ' reconstruction ', ' shape description ', ' shape analysis ', ' computational tools ', ' computerized tools ', ' remediation ', ' Imaging technology ', ' Population ', ' Coupled ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' cognitive control ', ' spatiotemporal ', ' public health relevance ', ' constriction ', ' dexterity ', ' program dissemination ', ' project dissemination ', ' Articulation ', ' high dimensionality ', ' imaging capabilities ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,433810,CA-37,0.32452589820963934
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication     DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders. PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,9319226,R03DC013990,"['ages ', ' Age ', ' Algorithms ', ' American Cancer Society ', ' Dorsum ', ' Back ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Diagnosis ', ' Electromagnetic ', ' Electromagnetics ', ' Future ', ' Goals ', ' Health ', ' Modern Man ', ' Human ', ' Language ', ' Laryngectomy ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Laryngeal Prosthesis ', ' Artificial Larynx ', ' Lip structure ', ' Lip ', ' Maps ', ' Movement ', ' body movement ', ' Persons ', ' Patients ', ' Play ', ' Research ', ' Self-Help Devices ', ' assistive device ', ' Assistive Technology ', ' sound ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' Voice ', ' Voice Disorders ', ' Gender ', ' Measures ', ' base ', ' improved ', ' Clinical ', ' Individual ', ' Pathologist ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Pattern ', ' System ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' innovative technologies ', ' Performance ', ' computer science ', ' kinematics ', ' kinematic model ', ' novel ', ' Participant ', ' Devices ', ' Excision ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' oral communication ', ' cancer therapy ', ' anticancer therapy ', ' Malignant Neoplasm Treatment ', ' Malignant Neoplasm Therapy ', ' Cancer Treatment ', ' Address ', ' Data ', ' Motor ', ' Tracheo-Esophageal Speech ', ' Tracheoesophageal Speech ', ' Characteristics ', ' Text ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' Output ', ' Population ', ' Impairment ', ' public health relevance ', ' clinical practice ', ' efficacy testing ', ' movement analysis ', ' Articulation ', ' ']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2017,153000,TX-32,0.2750270428952173
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating devicea virtual vocal tractthat can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9370414,K24DC016312,"['Algorithms ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Amyotrophic Lateral Sclerosis ', ' Articulators ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Malignant neoplasm of larynx ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disorder ', ' Disease ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Persons ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Play ', ' Quality of life ', ' QOL ', ' Questionnaires ', ' Records ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Running ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Surveys ', ' Survey Instrument ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' Cellular Phone ', ' smartphone ', ' smart phone ', ' iPhone ', ' Cellular Telephone ', ' Cell Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' developmental ', ' Development ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' usability ', ' motor impairment ', ' movement limitation ', ' movement impairment ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' Tablet Computer ', ' tablet device ', ' experimental study ', ' experimental research ', ' experiment ', ' Articulation ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2017,189841,MA-07,0.22035089065134175
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases     DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9199411,R01DC014498,"['Algorithms ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Child ', ' Communication ', ' computer vision ', ' Computer Vision Systems ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' Deafness ', ' Emotions ', ' facial ', ' faces ', ' Face ', ' face expression ', ' Facial Expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' sound perception ', ' hearing perception ', ' Hearing ', ' Modern Man ', ' Human ', ' Linguistics ', ' Linguistic ', ' Logic ', ' Manuals ', ' Methods ', ' Movement ', ' body movement ', ' Parents ', ' Production ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Science ', ' Semantics ', ' Sign Language ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Computer software ', ' Software ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specified ', ' Specific qualifier value ', ' Series ', ' Visual ', ' Individual ', ' data repository ', ' Databanks ', ' Data Bases ', ' Data Banks ', ' Databases ', ' Shapes ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Life ', ' Dimensions ', ' System ', ' showing emotion ', ' expression of emotion ', ' emotional expression ', ' Hearing Impaired Persons ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' interest ', ' instructor ', ' Visual system structure ', ' Visual System ', ' experience ', ' syntax ', ' syntactic ', ' Structure ', ' Agreement ', ' Controlled Study ', ' Devices ', ' Academic achievement ', ' Excision ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Code ', ' Coding System ', ' face perception ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Access to Information ', ' outreach to information ', ' body position ', ' prevent ', ' preventing ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' imaging ', ' Image ', ' reconstruction ', ' computational tools ', ' computerized tools ', ' designing ', ' design ', ' innovation ', ' innovative ', ' innovate ', ' Computational algorithm ', ' computer algorithm ', ' comparative ', ' public health relevance ', ' Teacher Professional Development ', ' teacher development ', ' instructor training ', ' faculty professional development ', ' faculty development ', ' Teacher Training ', ' Teacher Preparation ', ' Teacher Educator ', ' Teacher Education ', ' Faculty Training ', ' Faculty Education ', ' experimental study ', ' experimental research ', ' experiment ', ' Articulation ', ' American Sign Language ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2017,319382,OH-03,0.07835202109578018
"Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.     DESCRIPTION (provided by applicant): In an effort to intervene before psychosis onset and prevent morbidity, a major recent focus in schizophrenia research has been the identification of young people during a putative prodromal period, so as to develop safe and effective interventions to modify disease course. Over the past decades, studies at Columbia and elsewhere have evaluated clinical high-risk (CHR) individuals across a range of cognitive processes in an effort to identify core deficits of schizophrenia evident before psychosis onset. Subtle thought disorder, manifest in disturbance of language production, is a feature that predates rather than follows, psychosis onset in CHR individuals, and therefore may be an indicator of schizophrenia liability. Subtle thought disorder in schizophrenia and its risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. Here, we propose to instead use a novel automated machine-learning approach to speech analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language. It also evaluates syntax through ""part-of-speech"" tagging. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture subtle thought disorder and discriminate psychosis outcome among CHR individuals. Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we were able to identify a classifier with high accuracy for psychosis onset in a small CHR cohort at Columbia, which included semantic coherence from phrase to phrase, shortened phrase length, and decreased use of determiner pronouns (""which"", ""what"", ""that""). These features were correlated with prodromal symptoms but outperformed them in terms of classification accuracy. They also discriminated schizophrenia from normal speech. While promising, these automated methods of analysis require validation in a second CHR cohort. In this proposal, in collaboration with IBM, we will validate these automated methods using a large archive of speech data from the UCLA CHR cohort. This dataset has several advantages. First, the UCLA CHR cohort has a high prevalence of psychosis transition, important as machine learning is sensitive to group size. Second, it has undergone prior manual linguistic analysis, identifying features of language production that predicted psychosis outcome; hence, automated and manual methods can be directly compared. Third, there are speech data available from healthy controls and recent-onset psychosis patients (for validation). Fourth, several participants have multiple speech assays (such that stability of the classifier can be examined). Beyond validation of methods, we will maximize group size and combine speech data from Columbia and UCLA to characterize a common classifier of psychosis outcome. Automated methods for language analysis may improve prediction of psychosis onset and inform remediation strategies for its prevention. PUBLIC HEALTH RELEVANCE: Subtle thought disorder is an early core feature of schizophrenia evident before psychosis onset: it has traditionally been evaluated using clinical ratings or labor-intensive manual linguistic analyses. This proposal will apply novel computer-based speech analysis methods to existing datasets to identify abnormal semantic and syntactic features of language production that can predict or classify psychosis outcome among youths at clinical high risk for psychosis. Improved characterization of thought disorder can inform targeted preventive interventions for young people at risk for schizophrenia and related psychotic disorders, so as to reduce the morbidity of psychosis.",Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.,9231498,R03MH108933,"['ages ', ' Age ', ' senior citizen ', ' over 65 Elderly ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', ' Aged 65 and Over ', ' Elderly ', ' Archives ', ' Machine Intelligence ', ' Computer Reasoning ', ' Artificial Intelligence ', ' psychological disorder ', ' psychiatric illness ', ' mental illness ', ' Psychiatric Disorder ', ' Psychiatric Disease ', ' Mental health disorders ', ' Mental disorders ', ' Biologic Assays ', ' Bioassay ', ' Assay ', ' Biological Assay ', ' Grain ', ' Cereals ', ' Systematics ', ' Classification ', ' Computers ', ' Data Sources ', ' Diagnosis ', ' Disorder ', ' Disease ', ' Modern Man ', ' Human ', ' indexing ', ' Language ', ' Lead ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Linguistics ', ' Linguistic ', ' Manuals ', ' Methods ', ' Morbidity - disease rate ', ' Morbidity ', ' Natural Language Processing ', ' natural language understanding ', ' Occupations ', ' Professional Positions ', ' Jobs ', ' Patients ', ' Poverty ', ' Production ', ' Psychiatrist ', ' Psychiatry ', ' Psychotic Disorders ', ' psychotic illness ', ' Psychoses ', ' Research ', ' Risk ', ' Role ', ' social role ', ' Schizophrenia ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Semantics ', ' Speech ', ' Testing ', ' Thinking ', ' thoughts ', ' Friends ', ' Youth 10-21 ', ' Youth ', ' Dataset ', ' Data Set ', ' analytical method ', ' base ', ' improved ', ' Site ', ' Clinical ', ' Training ', ' Individual ', ' Sample Size ', ' Collaborations ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Scientist ', ' Source ', ' Deltastab ', ' Predniocil ', ' Prednihexal ', ' Predni-POS ', ' Predni-H ', ' Prednefrin SF ', ' Predcor ', ' Predate ', ' Predalone ', ' Predaject ', ' Pred Mild ', ' Pred Forte ', ' Pred Fort ', ' Ophtho-Tate ', ' Locaseptil-Neo ', ' Key-Pred ', ' Inflanefran ', ' Inf-Oph ', ' Hydrocortancyl ', ' Hexacortone ', ' Econopred ', ' Diopred ', ' Deltacortilen ', ' Balpred ', ' Articulose-50 ', ' Ak-Tate ', ' syntax ', ' syntactic ', ' hazard ', ' cohort ', ' phrases ', ' Structure ', ' novel ', ' Participant ', ' Prevention ', ' Emotional ', ' Sampling ', ' prevent ', ' preventing ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' High Prevalence ', ' Preventive Intervention ', ' preventional intervention strategy ', ' Prevention intervention ', ' Preventative intervention ', ' Validation ', ' Text ', ' developmental ', ' Development ', ' Output ', ' remediation ', ' Outcome ', ' Population ', ' Impairment ', ' demographics ', ' high risk ', ' public health relevance ', ' effective intervention ', ' standard of care ', ' targeted treatment ', ' targeted therapy ', ' targeted therapeutic agents ', ' targeted therapeutic ', ' targeted drug treatments ', ' targeted drug therapy ', ' cognitive process ', ' disabling symptom ', ' debilitating symptom ', ' ']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2017,35453,NY-13,0.1175872370871114
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants     DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9513918,R01DC014290,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Cochlear Implants ', ' Cochlear Prosthesis ', ' Auditory Prosthesis ', ' Environment ', ' Hearing ', ' sound perception ', ' hearing perception ', ' Maps ', ' Masks ', ' Methods ', ' Noise ', ' Problem Solving ', ' Quality of life ', ' QOL ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Comprehension ', ' base ', ' improved ', ' Surface ', ' Ensure ', ' Stimulus ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Frequencies ', ' Home environment ', ' Home ', ' Source ', ' Location ', ' Hearing Impaired Persons ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' Performance ', ' speech recognition ', ' success ', ' simulation ', ' Categories ', ' Environmental Risk Factor ', ' environmental risk ', ' Environmental Factor ', ' Devices ', ' Modeling ', ' response ', ' Address ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' speech processing ', ' public health relevance ', ' recruit ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2018,326840,NC-04,0.26989920720488025
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,9390468,R01DC013547,"['Age ', ' ages ', ' Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Malignant neoplasm of larynx ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Cerebral Palsy ', ' Classification ', ' Systematics ', ' Computers ', ' Deglutition ', ' Swallowing ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Pharmaceutical Preparations ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Dysarthria ', ' Dysarthosis ', ' Electromagnetics ', ' Electromagnetic ', ' Family ', ' Future ', ' Goals ', ' Health ', ' Human ', ' Modern Man ', ' Incidence ', ' Jaw ', ' Language ', ' Lip structure ', ' Lip ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Muscle ', ' muscular ', ' Muscle Tissue ', ' Persons ', ' Neurology ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Synthesizers ', ' voice synthesizer ', ' statistics ', ' Stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Technology ', ' Time ', ' Tongue ', ' Veterans ', ' Wit ', ' Work ', ' Gender ', ' Measures ', ' Motor Neuron Disease ', ' degenerative disorder of motor neurons ', ' Device Designs ', ' Outcome Measure ', ' Data Set ', ' Dataset ', ' Custom ', ' base ', ' improved ', ' Clinical ', ' prognostic ', ' Individual ', ' Neurologist ', ' Disease Progression ', ' Pathologist ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Dimensions ', ' Severities ', ' Oral ', ' System ', ' American ', ' Early Diagnosis ', ' early detection ', ' jaw movement ', ' Performance ', ' diagnostic accuracy ', ' Accuracy of Diagnosis ', ' novel ', ' Participant ', ' General Population ', ' General Public ', ' Positioning Attribute ', ' Position ', ' Deterioration ', ' Modeling ', ' oral communication ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' data mining ', ' datamining ', ' Address ', ' Gulf War ', ' Operation Desert Storm ', ' Operation Desert Shield ', ' Data ', ' Motor ', ' Validation ', ' Monitor ', ' socioeconomically ', ' socio-economically ', ' socio-economic ', ' socioeconomics ', ' developmental ', ' Development ', ' Healthcare professional ', ' Health Care Professional ', ' Health Professional ', ' pathway ', ' Pathway interactions ', ' National Institute of Neurological Diseases and Stroke ', ' NINDS ', ' National Institute of Neurological Disorders and Stroke ', ' orofacial ', ' digital ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' improved functioning ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' movement limitation ', ' movement impairment ', ' motor impairment ', ' public health relevance ', ' clinical practice ', ' clinical decision-making ', ' movement analysis ', ' communication device ', ' experimental research ', ' experiment ', ' experimental study ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2018,686265,MA-07,0.24739112916640235
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9548753,U01NS098971,"['Acoustics ', ' Acoustic ', ' Affect ', ' Aphasia ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Apraxias ', ' apraxia ', ' Dyspraxia ', ' Architecture ', ' Engineering / Architecture ', ' Archives ', ' Articulators ', ' Award ', ' Behavior ', ' Biomedical Engineering ', ' bioengineering ', ' bio-engineers ', ' bio-engineered ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Brain Mapping ', ' Communication impairment ', ' Communicative Disorders ', ' Communication Disorders ', ' Communities ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Correlation Studies ', ' Statistical Correlation ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Ethics ', ' ethical ', ' Face ', ' facial ', ' faces ', ' Foundations ', ' Gestures ', ' Goals ', ' Human ', ' Modern Man ', ' Jaw ', ' Language ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Learning ', ' Light ', ' Photoradiation ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Maps ', ' Methods ', ' Methodology ', ' Motor Cortex ', ' Movement ', ' body movement ', ' Mutism ', ' United States National Institutes of Health ', ' National Institutes of Health ', ' NIH ', ' Nerve Degeneration ', ' neuronal degeneration ', ' neurological degeneration ', ' neurodegenerative ', ' neurodegeneration ', ' neural degeneration ', ' Neuron Degeneration ', ' Neurobiology ', ' neurobiological ', ' Neurology ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' neurosurgery ', ' Physiology ', ' Play ', ' Population Dynamics ', ' Production ', ' Rehabilitation therapy ', ' rehabilitative ', ' Rehabilitation ', ' Medical Rehabilitation ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' Stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Stuttering ', ' Stammering ', ' Technology ', ' Time ', ' Tongue ', ' Ultrasonography ', ' ultrasound scanning ', ' ultrasound imaging ', ' ultrasound ', ' sound measurement ', ' sonography ', ' sonogram ', ' diagnostic ultrasound ', ' Ultrasound Test ', ' Ultrasound Medical Imaging ', ' Ultrasound Diagnosis ', ' Ultrasonogram ', ' Ultrasonic Imaging ', ' Medical Ultrasound ', ' Echotomography ', ' Echography ', ' Measures ', ' Mediating ', ' Prefrontal Cortex ', ' Visualization ', ' Imagery ', ' base ', ' density ', ' Procedures ', ' Left ', ' Site ', ' Area ', ' Acute ', ' Chronic ', ' Clinical ', ' insight ', ' Individual ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Functional disorder ', ' tool ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Electrocorticogram ', ' electrocorticography ', ' Dimensions ', ' Auditory ', ' Complex ', ' Pattern ', ' System ', ' Dementia ', ' Amentia ', ' Paralysed ', ' paralytic ', ' paralysis ', ' Plegia ', ' Palsy ', ' experience ', ' synergism ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' trait ', ' kinematics ', ' kinematic model ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Devices ', ' Positioning Attribute ', ' Position ', ' Property ', ' response ', ' Brain region ', ' Address ', ' Data ', ' Resolution ', ' Cognitive ', ' Monitor ', ' Behavioral ', ' imaging ', ' Image ', ' Population ', ' neural mechanism ', ' neuromechanism ', ' Trauma ', ' innovative ', ' innovate ', ' innovation ', ' multidisciplinary ', ' Implant ', ' implantation ', ' cognitive control ', ' spatiotemporal ', ' motor control ', ' sharing data ', ' relational database ', ' time measurement ', ' temporal resolution ', ' temporal measurement ', ' Articulation ', ' ']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,1075477,CA-12,0.3163779992503433
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating devicea virtual vocal tractthat can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9525935,K24DC016312,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disease ', ' Disorder ', ' Dysarthria ', ' Dysarthosis ', ' Electromagnetics ', ' Electromagnetic ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Persons ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Play ', ' Quality of life ', ' QOL ', ' Questionnaires ', ' Records ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Running ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Surveys ', ' Survey Instrument ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' Cellular Phone ', ' smartphone ', ' smart phone ', ' iPhone ', ' Cellular Telephone ', ' Cell Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' developmental ', ' Development ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' usability ', ' movement limitation ', ' movement impairment ', ' motor impairment ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' tablet device ', ' Tablet Computer ', ' experimental research ', ' experiment ', ' experimental study ', ' Articulation ', ' virtual vocal tract ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2018,189841,MA-07,0.22035089065134175
"Objectively Quantifying Speech Outcomes of Children with Cleft Palate Perceptual assessment of hypernasality is considered a critical component when evaluating the speech of children with cleft lip and/or palate (CLP). However, most speech-language pathologists (SLPs) do not receive formal training for perceptual evaluation of speech and, as a result, research shows that the subjective ratings are inherently biased to the perceiver and exhibit considerable variability. In this project, we aim to develop an artificial intelligence (AI) algorithm that automatically evaluates speech along four dimensions deemed to be critically important by the Americleft Speech Outcomes Group (ASOG), namely speech acceptability, articulation, hypernasality, and audible nasal emissions. The AI algorithm in this project is based on an existing database of speech collected as a part of an NIH-funded project to develop reliable speech outcomes by improving the reliability of perceptual ratings by training clinicians (NIDCR DE019-01235, PI: Kathy Chapman). This database contains speech samples from 125 5-7 year olds along with multiple perceptual rating for each speech sample. The clinicians participating in this study were successfully trained using a new protocol from the Americleft Speech Outcomes Group and they exhibit excellent inter-clinician reliability.  In SA1 we will develop an AI algorithm that automatically learns the relationship between a comprehensive set of speech acoustics and the average of the ASOG-trained expert ratings for each of the four perceptual dimensions. This approach is based on technology that the PIs have successfully used to evaluate dysarthric speech. Unique to these algorithms is modeling of perceptual judgments of trained experts using tools from statistical signal processing and AI. The output of the algorithms will map to a clinically- relevant scale, rather than to norm-referenced values that may or may not be meaningful. In SA2, we will evaluate the tool on new data by collecting new speech samples using a mobile app at a partner clinic using the same protocol as in the original study. Every collected sample will be further evaluated by ASOG trained clinicians. We will use this data to evaluate the accuracy of the AI model by comparing the model's predictions with the average of ASOG-trained experts. Preliminary results show promise that the proposed approach will yield a successful tool for accurately characterizing perceptual dimensions in the speech of children with CLP. These results indicate that a number of acoustic features that have been developed previously by the PIs accurately capture differences in hypernasality and articulation between the speech of three children with CLP (with varying severity). Furthermore, we show the success of our approach on a different, but related, task: objective evaluation of dysarthric speech. We show that an algorithm that automatically rates hypernasality performs on par with the judgment of human evaluators. The results of the proposed research will form the basis for a subsequent R01 proposal for the development and evaluation of a clinical tool to objectively quantify and track speech production in children with CLP. Project Narrative Perceptual assessment of the speech of children with cleft lip and/or palate is commonly used as a key clinical indicator upon which follow-on decisions are made about intervention. However, studies show that the inter- clinician reliability can be low. As an alternative, we propose a new objective outcome tool based on signal processing and artificial intelligence that automatically assesses speech acceptability, articulation, hypernasality, and audible nasal emissions directly from speech; the output of the tool is on a scale defined by the Americleft Speech Outcomes Group and can be used by clinicians to objectively measure progress.",Objectively Quantifying Speech Outcomes of Children with Cleft Palate,9601604,R21DE026252,"['tool ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Clinic ', ' Protocols documentation ', ' Protocol ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Visit ', ' American ', ' craniofacial ', ' craniofacies ', ' impression ', ' Performance ', ' success ', ' Proxy ', ' novel ', ' Reporting ', ' Palate ', ' Positioning Attribute ', ' Position ', ' Modeling ', ' Sampling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Data ', ' International ', ' National Institute of Dental and Craniofacial Research ', ' National Institute of Dental Research ', ' NIDR ', ' NIDCR ', ' Validation ', ' developmental ', ' Development ', ' Output ', ' risk prediction model ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' Population ', ' seven years of age ', ' seven year old ', ' age 7 years ', ' 7 years of age ', ' 7 year old ', ' clinical relevance ', ' clinically relevant ', ' 4-dimensional ', ' Four-dimensional ', ' mobile app ', ' mobile application ', ' signal processing ', ' improved outcome ', ' Articulation ', ' Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Behavior Therapy ', ' behavioral intervention ', ' behavior intervention ', ' Conditioning Therapy ', ' Behavioral Treatment ', ' Behavioral Therapy ', ' Behavioral Modification ', ' Behavioral Conditioning Therapy ', ' Behavior Treatment ', ' Behavior Modification ', ' Behavior Conditioning Therapy ', ' Child ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Cleft Lip ', ' hare lip ', ' Harelip ', ' Cleft Palate ', ' Clinical Research ', ' Clinical Study ', ' Communities ', ' Ear ', ' Environment ', ' Exhibits ', ' Gold ', ' Human ', ' Modern Man ', ' Judgment ', ' Language ', ' Learning ', ' Maps ', ' Methods ', ' United States National Institutes of Health ', ' National Institutes of Health ', ' NIH ', ' Nose ', ' Respiratory System, Nose, Nasal Passages ', ' Nasal Passages Nose ', ' Nasal ', ' Perception ', ' Production ', ' Reference Values ', ' Reference Ranges ', ' Validity and Reliability ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Technology ', ' Time ', ' Utah ', ' Work ', ' Measures ', ' Outcomes Research ', ' cleft palate/lip ', ' cleft lip/palate ', ' cleft lip and palate ', ' base ', ' Clinical ', ' Series ', ' Ensure ', ' Evaluation ', ' Training ', ' Individual ', ' data base ', ' Data Bases ', ' Databases ', ' Funding ', ' Pathologist ', ' ']",NIDCR,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2018,203708,AZ-09,0.3263792297328562
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through part-of-speech tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (which, what, that). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis  semantics and syntax  that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9435649,R01MH115332,"['Age ', ' ages ', ' Archives ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Felis catus ', ' Felis sylvestris catus ', ' Felis domesticus ', ' Felis domestica ', ' Feline Species ', ' Domestic Cats ', ' Cats Mammals ', ' Cats ', ' Classification ', ' Systematics ', ' Cognition ', ' Communication ', ' Computers ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Canis familiaris ', ' domestic dog ', ' canine ', ' Dogs Mammals ', ' Dogs ', ' Canine Species ', ' Electroencephalography ', ' EEG ', ' Human ', ' Modern Man ', ' indexing ', ' Interview ', ' Language ', ' Linguistics ', ' Linguistic ', ' Manuals ', ' Methods ', ' Morbidity - disease rate ', ' Morbidity ', ' National Institute of Mental Health ', ' NIMH ', ' United States National Institutes of Health ', ' National Institutes of Health ', ' NIH ', ' Natural Language Processing ', ' natural language understanding ', ' Patients ', ' Poverty ', ' Production ', ' Psychotic Disorders ', ' psychotic illness ', ' Psychoses ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Resources ', ' Research Resources ', ' Risk ', ' Schizophrenia ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Semantics ', ' Speech ', ' Thinking ', ' thoughts ', ' Work ', ' Yogurt ', ' Measures ', ' Data Set ', ' Dataset ', ' analytical method ', ' base ', ' Site ', ' Clinical ', ' Physiologic ', ' Physiological ', ' Series ', ' Individual ', ' Collaborations ', ' Metaphor ', ' Genetic ', ' Morphology ', ' Diagnostic ', ' Scientist ', ' Dimensions ', ' syntax ', ' syntactic ', ' cohort ', ' relating to nervous system ', ' neural ', ' phrases ', ' novel ', ' NIH Program Announcements ', ' Program Announcement ', ' Graph ', ' Categories ', ' response ', ' functional disability ', ' Functional impairment ', ' Mediator of activation protein ', ' Mediator of Activation ', ' Mediator ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' International ', ' Sum ', ' scientific advances ', ' scientific accomplishments ', ' Scientific Advances and Accomplishments ', ' Text ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' Output ', ' vector ', ' Outcome ', ' Mind ', ' Affective ', ' healthy volunteer ', ' high risk ', ' natural language ', ' RDoC ', ' Research Domain Criteria ', ' Patient risk ', ' neural correlate ', ' data archive ', ' secondary analysis ', ' Grain ', ' ']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2018,513989,NY-13,0.03378951410178257
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases     DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9402599,R01DC014498,"['Algorithms ', ' Child ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Communication ', ' Computer Vision Systems ', ' computer vision ', ' Computing Methodologies ', ' computing method ', ' computer methods ', ' computational methods ', ' computational methodology ', ' Deafness ', ' Emotions ', ' Face ', ' facial ', ' faces ', ' Facial Expression ', ' face expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' Hearing ', ' sound perception ', ' hearing perception ', ' Human ', ' Modern Man ', ' Linguistics ', ' Linguistic ', ' Logic ', ' Manuals ', ' Methods ', ' Movement ', ' body movement ', ' Parents ', ' Production ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Science ', ' Semantics ', ' Sign Language ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Computer software ', ' Software ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specified ', ' Specific qualifier value ', ' Series ', ' Visual ', ' Individual ', ' data base ', ' Data Bases ', ' Databases ', ' Shapes ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Life ', ' Dimensions ', ' System ', ' showing emotion ', ' expression of emotion ', ' emotional expression ', ' Hearing Impaired Persons ', ' Persons With Hearing Impairments ', ' Hard of Hearing Persons ', ' Deaf ', ' interest ', ' instructor ', ' Visual system structure ', ' Visual System ', ' experience ', ' syntax ', ' syntactic ', ' Structure ', ' Agreement ', ' Devices ', ' Academic achievement ', ' Excision ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Code ', ' Coding System ', ' face perception ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Access to Information ', ' outreach to information ', ' body position ', ' prevent ', ' preventing ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' imaging ', ' Image ', ' reconstruction ', ' computational tools ', ' computerized tools ', ' designing ', ' design ', ' innovative ', ' innovate ', ' innovation ', ' computer algorithm ', ' Computational algorithm ', ' comparative ', ' public health relevance ', ' teacher development ', ' instructor training ', ' faculty professional development ', ' faculty development ', ' Teacher Training ', ' Teacher Preparation ', ' Teacher Educator ', ' Teacher Education ', ' Faculty Training ', ' Faculty Education ', ' Teacher Professional Development ', ' experimental research ', ' experiment ', ' experimental study ', ' Articulation ', ' American Sign Language ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,318898,OH-03,0.07835202109578018
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9645876,U01NS098971,"['Acoustics ', ' Acoustic ', ' Affect ', ' Aphasia ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Apraxias ', ' apraxia ', ' Dyspraxia ', ' Architecture ', ' Engineering / Architecture ', ' Archives ', ' Articulators ', ' Award ', ' Behavior ', ' Biomedical Engineering ', ' bioengineering ', ' bio-engineers ', ' bio-engineered ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Brain Mapping ', ' Communication impairment ', ' Communicative Disorders ', ' Communication Disorders ', ' Communities ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Correlation Studies ', ' Statistical Correlation ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Ethics ', ' ethical ', ' Face ', ' facial ', ' faces ', ' Foundations ', ' Gestures ', ' Goals ', ' Human ', ' Modern Man ', ' Jaw ', ' Language ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Learning ', ' Light ', ' Photoradiation ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Maps ', ' Methods ', ' Methodology ', ' Motor Cortex ', ' Movement ', ' body movement ', ' Mutism ', ' United States National Institutes of Health ', ' National Institutes of Health ', ' NIH ', ' Nerve Degeneration ', ' neuronal degeneration ', ' neurological degeneration ', ' neurodegenerative ', ' neurodegeneration ', ' neural degeneration ', ' Neuron Degeneration ', ' Neurobiology ', ' neurobiological ', ' Neurology ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' neurosurgery ', ' Physiology ', ' Play ', ' Population Dynamics ', ' Production ', ' Rehabilitation therapy ', ' rehabilitative ', ' Rehabilitation ', ' Medical Rehabilitation ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' Stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Stuttering ', ' Stammering ', ' Technology ', ' Time ', ' Tongue ', ' Ultrasonography ', ' ultrasound scanning ', ' ultrasound imaging ', ' ultrasound ', ' sound measurement ', ' sonography ', ' sonogram ', ' diagnostic ultrasound ', ' Ultrasound Test ', ' Ultrasound Medical Imaging ', ' Ultrasound Diagnosis ', ' Ultrasonogram ', ' Ultrasonic Imaging ', ' Medical Ultrasound ', ' Echotomography ', ' Echography ', ' Measures ', ' Mediating ', ' Prefrontal Cortex ', ' Visualization ', ' Imagery ', ' base ', ' density ', ' Procedures ', ' Left ', ' Site ', ' Area ', ' Acute ', ' Chronic ', ' Clinical ', ' insight ', ' Individual ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Functional disorder ', ' tool ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Electrocorticogram ', ' electrocorticography ', ' Dimensions ', ' Auditory ', ' Complex ', ' Pattern ', ' System ', ' Dementia ', ' Amentia ', ' Paralysed ', ' paralytic ', ' paralysis ', ' Plegia ', ' Palsy ', ' experience ', ' synergism ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' trait ', ' kinematics ', ' kinematic model ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Devices ', ' Positioning Attribute ', ' Position ', ' Property ', ' response ', ' Brain region ', ' Address ', ' Data ', ' Resolution ', ' Cognitive ', ' Monitor ', ' Behavioral ', ' imaging ', ' Image ', ' Population ', ' neural mechanism ', ' neuromechanism ', ' Trauma ', ' innovative ', ' innovate ', ' innovation ', ' multidisciplinary ', ' Implant ', ' implantation ', ' cognitive control ', ' spatiotemporal ', ' motor control ', ' sharing data ', ' relational database ', ' time measurement ', ' temporal resolution ', ' temporal measurement ', ' Articulation ', ' ']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,189567,CA-12,0.3163779992503433
"Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates     DESCRIPTION (provided by applicant): 90% of the 1.5 million Americans living with idiopathic Parkinson's disease (PD) and 50% of the 500,000 Americans living with Multiple Sclerosis (MS) will experience dysarthria. Dysarthria has devastating consequences for life quality and participation in society due to its effects on employment, leisure activities and social relationships. Knowledge of therapy techniques for maximizing perceived speech adequacy, as indexed by the gold standard perceptual construct of intelligibility is thus of vital importance. Owing to the scarcity of impartial comparative studies, the choice of one technique over others is often based on trial and error or reflects clinician bias, both of which are at odds with evidence-based practice. This project has sought to address this critical gap in knowledge regarding the comparative merits of dysarthria treatment techniques since its inception. Toward this end, published studies from the past funding cycle compared the acoustic and perceptual merits of three common, global dysarthria treatment techniques including 1) rate manipulation, 2) an increased vocal intensity and 3) clear speech in MS and PD as well as age and sex matched neurotypical talkers. Global treatment techniques by their very nature elicit co-occurring acoustic changes (e.g., duration, segmental articulation). Because an explanatory, acoustically-based model of intelligibility is lacking, the acoustic change(s) causing or explainin the improved perceptual outcomes of global treatment techniques are unknown. Determining the acoustic variables explaining intelligibility variation in dysarthria would not only tremendousy advance theoretical understanding of intelligibility but also would strengthen the scientific basis for treatment. Treatment focused on those acoustic variables explanatory for improved intelligibility may further accelerate progress in therapy. Importantly, research from the previous funding cycle suggests the promise of speech analysis-resynthesis for identifying segmental and suprasegmental acoustic variables explanatory for intelligibility in dysarthria. Building upon this work, the overarching goal of the continuation is to contribute towards development of an acoustically-based explanatory model of intelligibility. Our approach 1) employs established perceptual procedures and acoustic measures, 2) uses an innovative analysis-resynthesis technique that permits conclusions concerning the explanatory relationship between acoustic changes accompanying dysarthria therapy techniques and intelligibility, and 3) leverages methods from machine learning to build a predictive model of intelligibility from acoustics. The impact of this work is in its contribution to 1) advancing conceptual understanding of intelligibility, 2) strengthening the scientific basis for treatment, and 3) optimizing clinical implementation of dysarthria therapy techniques. PUBLIC HEALTH RELEVANCE: This project is directly relevant to the mission of NIDCD due to its focus on investigating the therapeutic techniques for maximizing intelligibility in dysarthra secondary to Parkinson's disease and Multiple Sclerosis. By advancing conceptual understanding of intelligibility, this research will strengthen the scientific basis for dysarthria treatments and will optimize their clinical implementation.",Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates,9549036,R01DC004689,"['Acoustics ', ' Acoustic ', ' Affect ', ' Age ', ' ages ', ' Comparative Study ', ' Dysarthria ', ' Dysarthosis ', ' Employment ', ' Goals ', ' Gold ', ' indexing ', ' Leisure Activities ', ' Methods ', ' Mission ', ' Multiple Sclerosis ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Production ', ' Publishing ', ' Quality of life ', ' QOL ', ' Research ', ' Societies ', ' Speech ', ' Genetic Transcription ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Work ', ' Measures ', ' Secondary to ', ' base ', ' improved ', ' Procedures ', ' Variation ', ' Variant ', ' Individual ', ' Funding ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Frequencies ', ' Techniques ', ' American ', ' experience ', ' treatment program ', ' social ', ' Modeling ', ' Orthography ', ' orthographical ', ' orthographic ', ' hearing impairment ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Address ', ' Evidence based practice ', ' sex ', ' developmental ', ' Development ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' innovative ', ' innovate ', ' innovation ', ' comparative ', ' public health relevance ', ' clear speech ', ' Idiopathic Parkinson Disease ', ' Articulation ', ' clinical implementation ', ' therapy optimization ', ' treatment optimization ', ' ']",NIDCD,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2018,517281,NY-26,0.060050512759730355
"Neurophysiology of robust speech perception in human superior temporal gyrus DESCRIPTION (provided by applicant): Perceiving and following an individual speaker in a crowded, noisy environment is a commonplace task for listeners with normal hearing. The underlying neurophysiology, however, is complex, and the task remains a struggle for people with peripheral and central auditory pathway disorders. The lack of a detailed neurobiological model of mechanisms and functions underlying robust speech perception has hindered our understanding of how these processes become impaired in the suffering population. In our innovative approach, we will record from high-density micro and macro electrode arrays surgically implanted on the superior temporal gyrus of epilepsy patients as part of their clinical evaluation. This method offers an exceptionally detailed perspective of cortical population activity. We will build upon two recent complementary findings where we identified a highly selective, spatially distributed neural representation of phonetic features (Mesgarani et. al. Science, 2014), which at the same time is highly dynamic and can change rapidly to reflect the perceptual bias of the listener (Mesgarani & Chang, Nature 2012). While significant, these studies revealed several gaps in our understanding of this process, which we intend to address in this proposal. Specifically, we will resolve the following unanswered questions: 1) what is the neural mechanism for joint encoding of both phonetic and speaker features? 2) How does attention modulate phonetic and speaker feature selectivity of neural responses? And 3) what computational mechanisms can account for dynamic feature selectivity of responses in STG? Answering these questions will significantly advance our understanding of a remarkable human ability, and will be of great interest to researchers from many areas including neurologists, and sensory and cognitive neuroscientists. PUBLIC HEALTH RELEVANCE: Understanding the mechanisms underlying speech perception in challenging environments is a crucial step in determining how these processes deteriorate in various disorders of peripheral and central auditory pathways. Our studies will result in novel neurobiological models of robust speech perception that will serve as a necessary step toward designing innovative therapeutic measures.",Neurophysiology of robust speech perception in human superior temporal gyrus,9444452,R01DC014279,"['Acoustics ', ' Acoustic ', ' Aphasia ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Attention ', ' Central Auditory Diseases ', ' Central Auditory Pathway Disorders ', ' Central Auditory Dysfunction ', ' auditory pathway ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Communication impairment ', ' Communicative Disorders ', ' Communication Disorders ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Crowding ', ' Cues ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Environment ', ' Epilepsy ', ' epileptogenic ', ' epileptiform ', ' epilepsia ', ' Seizure Disorder ', ' Epileptics ', ' Epileptic Seizures ', ' Feedback ', ' Hearing ', ' sound perception ', ' hearing perception ', ' Human ', ' Modern Man ', ' indexing ', ' Joints ', ' Language Development ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Literature ', ' Methods ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' neurophysiology ', ' neurophysiological ', ' Patients ', ' Perception ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Role ', ' social role ', ' Science ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Specificity ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' Speech Pathology ', ' Mediating ', ' Superior temporal gyrus ', ' Comprehension ', ' Custom ', ' Intention ', ' Prosthetics ', ' Prosthetic device ', ' Prosthesis ', ' density ', ' Peripheral ', ' Site ', ' Area ', ' Surface ', ' Link ', ' selective attention ', ' receptive field ', ' Discipline ', ' Individual ', ' Neurologist ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Complex ', ' Sensory ', ' Techniques ', ' Dyslexia ', ' Word Blindness ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' interest ', ' relating to nervous system ', ' neural ', ' expectation ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Code ', ' Coding System ', ' Modeling ', ' Property ', ' response ', ' Address ', ' Resolution ', ' clinical test ', ' Clinical Testing ', ' Clinical Evaluation ', ' research clinical testing ', ' Cognitive ', ' Characteristics ', ' Process ', ' computational framework ', ' computer framework ', ' designing ', ' design ', ' Population ', ' neural mechanism ', ' neuromechanism ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' Implant ', ' speech processing ', ' attention modulation ', ' attentional modulation ', ' spatiotemporal ', ' public health relevance ', ' cognitive ability ', ' learning method ', ' learning activity ', ' learning strategy ', ' experimental research ', ' experiment ', ' experimental study ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2018,397659,NY-13,0.1701572157265675
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility  the final arbiter of speech goodness  is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.  There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9432492,R01DC006859,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Attention ', ' Communication impairment ', ' Communicative Disorders ', ' Communication Disorders ', ' Computer Simulation ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Cues ', ' Dysarthria ', ' Dysarthosis ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' Health Services Accessibility ', ' treatment access ', ' health services availability ', ' health service access ', ' care access ', ' availability of services ', ' accessibility to health services ', ' access to treatment ', ' access to services ', ' access to health services ', ' Access to Care ', ' Judgment ', ' Language ', ' Learning ', ' Theoretical model ', ' Theoretic Models ', ' nervous system disorder ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Periodicity ', ' Rhythmicity ', ' Cyclicity ', ' Research ', ' Signal Transduction ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' instructional intervention ', ' Training Intervention ', ' Instruction Intervention ', ' Education for Intervention ', ' Educational Intervention ', ' Pathologist ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Trauma ', ' neurotrauma ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Code ', ' Coding System ', ' Modeling ', ' Sampling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' health disparity ', ' disparity in health ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' risk prediction model ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' predictive modeling ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' predictors of outcomes ', ' predictive outcomes ', ' outcome prediction ', ' recruit ', ' optimal therapies ', ' optimal treatments ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,310124,AZ-09,0.3565471150187476
"Dynamics of Vocal Tract Shaping     DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9390471,R01DC007124,"['Acoustics ', ' Acoustic ', ' Adult ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Apraxias ', ' apraxia ', ' Dyspraxia ', ' Articulators ', ' Beds ', ' Communication ', ' Communities ', ' Deglutition Disorders ', ' Swallowing Disorders ', ' Dysphagia ', ' Engineering ', ' Epiglottis structure ', ' Epiglottis ', ' Gestures ', ' Glossectomy ', ' Goals ', ' Human ', ' Modern Man ', ' Language ', ' Language Disorders ', ' language deficit ', ' Language disability ', ' Larynx ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Magnetic Resonance Imaging ', ' Zeugmatography ', ' Nuclear Magnetic Resonance Imaging ', ' NMR Tomography ', ' NMR Imaging ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' MRI ', ' MR Tomography ', ' MR Imaging ', ' Motion ', ' Movement ', ' body movement ', ' Noise ', ' Pharyngeal structure ', ' Throat ', ' Pharynx ', ' Play ', ' Posture ', ' Production ', ' Research ', ' Research Personnel ', ' Researchers ', ' Investigators ', ' Self-Help Devices ', ' assistive device ', ' Assistive Technology ', ' Sleep Apnea Syndromes ', ' sleep-related breathing disorder ', ' Sleep-Disordered Breathing ', ' Sleep Hypopnea ', ' Sleep Apnea ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Stroke ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Surgical Flaps ', ' Island Flaps ', ' Flaps ', ' Educational process of instructing ', ' Teaching ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Traction ', ' Work ', ' Measures ', ' base ', ' image processing ', ' improved ', ' Lateral ', ' Clinical ', ' Variation ', ' Variant ', ' Series ', ' Training ', ' tongue tip ', ' tongue apex ', ' Individual ', ' Recovery ', ' Shapes ', ' tool ', ' German population ', ' German ', ' instrument ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Investigation ', ' Dimensions ', ' Complex ', ' Event ', ' Oral ', ' In Situ ', ' Pattern ', ' System ', ' Oropharyngeal ', ' oral pharyngeal ', ' Oropharynxs ', ' Oropharynx ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' speech recognition ', ' phonology ', ' phonological ', ' cohesion ', ' Speed ', ' Structure ', ' novel ', ' movie ', ' outreach ', ' technological innovation ', ' Modeling ', ' Property ', ' theories ', ' bioimaging ', ' biomedical imaging ', ' bio-imaging ', ' Three-Dimensional Imaging ', ' Three Dimensional Medical Imaging ', ' 3D imaging ', ' 3-D Imaging ', ' Data ', ' International ', ' Resolution ', ' Cognitive ', ' Cardiac ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' website ', ' web site ', ' reconstruction ', ' shape description ', ' shape analysis ', ' computational tools ', ' computerized tools ', ' remediation ', ' Imaging technology ', ' Population ', ' Coupled ', ' innovative ', ' innovate ', ' innovation ', ' Impairment ', ' spatiotemporal ', ' public health relevance ', ' constriction ', ' dexterity ', ' project dissemination ', ' program dissemination ', ' Articulation ', ' high dimensionality ', ' imaging capabilities ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,467515,CA-37,0.32452589820963934
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9492650,U01NS098969,"['Acoustics ', ' Acoustic ', ' Basal Ganglia ', ' Basal Nuclei ', ' Cues ', ' Dysarthria ', ' Dysarthosis ', ' Electrophysiology (science) ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Goals ', ' Language ', ' Linguistics ', ' Linguistic ', ' Methods ', ' Movement ', ' body movement ', ' Movement Disorders ', ' Movement Disorder Syndromes ', ' Dyskinesia Syndromes ', ' nervous system disorder ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' Parkinson Disease ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Patients ', ' Production ', ' Role ', ' social role ', ' Speech ', ' Supervision ', ' Testing ', ' Time ', ' Universities ', ' Voice ', ' Measures ', ' Subthalamic Nucleus ', ' Nucleus Subthalamicus ', ' Structure of subthalamic nucleus ', ' analytical method ', ' base ', ' Clinical ', ' Phase ', ' Stimulus ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Deep Brain Stimulation ', ' Event ', ' Stream ', ' Pattern ', ' Techniques ', ' System ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Performance ', ' relating to nervous system ', ' neural ', ' kinematics ', ' kinematic model ', ' novel ', ' member ', ' Code ', ' Coding System ', ' Modeling ', ' response ', ' Adverse effects ', ' treatment adverse effect ', ' therapy adverse effect ', ' side effect ', ' Treatment Side Effects ', ' Address ', ' Data ', ' Motor ', ' Output ', ' novel strategy ', ' novel approaches ', ' new approaches ', ' novel strategies ', ' cognitive neuroscience ', ' multidisciplinary ', ' gain of function ', ' subthalamic nucleus stimulation ', ' STN stimulation ', ' microstimulation ', ' learning method ', ' learning activity ', ' learning strategy ', ' motor symptom ', ' predictive assay ', ' predictive test ', ' ']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2018,1134330,PA-18,0.22462395316098602
"Neurophysiology of robust speech perception in human superior temporal gyrus DESCRIPTION (provided by applicant): Perceiving and following an individual speaker in a crowded, noisy environment is a commonplace task for listeners with normal hearing. The underlying neurophysiology, however, is complex, and the task remains a struggle for people with peripheral and central auditory pathway disorders. The lack of a detailed neurobiological model of mechanisms and functions underlying robust speech perception has hindered our understanding of how these processes become impaired in the suffering population. In our innovative approach, we will record from high-density micro and macro electrode arrays surgically implanted on the superior temporal gyrus of epilepsy patients as part of their clinical evaluation. This method offers an exceptionally detailed perspective of cortical population activity. We will build upon two recent complementary findings where we identified a highly selective, spatially distributed neural representation of phonetic features (Mesgarani et. al. Science, 2014), which at the same time is highly dynamic and can change rapidly to reflect the perceptual bias of the listener (Mesgarani & Chang, Nature 2012). While significant, these studies revealed several gaps in our understanding of this process, which we intend to address in this proposal. Specifically, we will resolve the following unanswered questions: 1) what is the neural mechanism for joint encoding of both phonetic and speaker features? 2) How does attention modulate phonetic and speaker feature selectivity of neural responses? And 3) what computational mechanisms can account for dynamic feature selectivity of responses in STG? Answering these questions will significantly advance our understanding of a remarkable human ability, and will be of great interest to researchers from many areas including neurologists, and sensory and cognitive neuroscientists. PUBLIC HEALTH RELEVANCE: Understanding the mechanisms underlying speech perception in challenging environments is a crucial step in determining how these processes deteriorate in various disorders of peripheral and central auditory pathways. Our studies will result in novel neurobiological models of robust speech perception that will serve as a necessary step toward designing innovative therapeutic measures.",Neurophysiology of robust speech perception in human superior temporal gyrus,9650571,R01DC014279,"['Acoustics ', ' Acoustic ', ' Aphasia ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Attention ', ' Central Auditory Diseases ', ' Central Auditory Pathway Disorders ', ' Central Auditory Dysfunction ', ' auditory pathway ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Crowding ', ' Cues ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' Environment ', ' epileptogenic ', ' epileptiform ', ' epilepsia ', ' Seizure Disorder ', ' Epileptics ', ' Epileptic Seizures ', ' Epilepsy ', ' Feedback ', ' Modern Man ', ' Human ', ' indexing ', ' Joints ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Language Development ', ' Literature ', ' Methods ', ' neurobiological ', ' Neurobiology ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' neurophysiological ', ' neurophysiology ', ' Patients ', ' Perception ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' social role ', ' Role ', ' Science ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Specificity ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Voice ', ' Work ', ' Measures ', ' Speech Pathology ', ' Mediating ', ' Superior temporal gyrus ', ' Comprehension ', ' Custom ', ' Intention ', ' Prosthesis ', ' Prosthetics ', ' Prosthetic device ', ' density ', ' Peripheral ', ' Site ', ' Area ', ' Surface ', ' Link ', ' selective attention ', ' receptive field ', ' Discipline ', ' Individual ', ' Neurologist ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Complex ', ' Sensory ', ' Techniques ', ' Dyslexia ', ' Word Blindness ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' interest ', ' relating to nervous system ', ' neural ', ' expectation ', ' neuroimaging ', ' neuro-imaging ', ' novel ', ' Code ', ' Coding System ', ' Modeling ', ' Property ', ' response ', ' Address ', ' Resolution ', ' research clinical testing ', ' clinical test ', ' Clinical Testing ', ' Clinical Evaluation ', ' Cognitive ', ' Characteristics ', ' Process ', ' computer framework ', ' computational framework ', ' design ', ' designing ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' Implant ', ' speech processing ', ' attentional modulation ', ' attention modulation ', ' spatiotemporal ', ' public health relevance ', ' cognitive ability ', ' learning strategy ', ' learning method ', ' learning activity ', ' experimental study ', ' experimental research ', ' experiment ', ' normal hearing ', ' healthy hearing ', ' good hearing ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2019,398995,NY-13,0.1701572157265675
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many evidence-based treatments for substance abuse are talk based therapies, such as motivational interviewing (MI), but the existing research-based methodology for evaluating counseling quality is to record sessions and use human rating teams to evaluate them. However, using humans as the assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling sessions, provide automatic and intuitive quality scores, and summarize these in actionable feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous NIH-funded research laid a computational foundation for generating MI quality metrics from speech and language features in MI sessions, and led to a prototype of a clinical software support tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical workflows, assessing usability, and initial validation of machine learning of MI fidelity measures in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase II will focus on robust validation of the speech and language technologies underlying the CORE-MI tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability, usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence of increased client retention. The successful execution of this project will break the reliance on human judgment for providing performance-based feedback to MI and will massively expand the capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling interventions, such as motivational interviewing. There are currently no methods for evaluating the quality of such counseling interventions in the real world to support training, supervision, and quality assurance. Building on an existing prototype, Lyssn.io  a technology start-up focused on scalable and cost-efficient human-centered technologies  will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9741887,R44DA046243,"['Adoption ', ' Algorithms ', ' Behavior Therapy ', ' behavioral intervention ', ' behavior intervention ', ' Conditioning Therapy ', ' Behavioral Treatment ', ' Behavioral Therapy ', ' Behavioral Modification ', ' Behavioral Conditioning Therapy ', ' Behavior Treatment ', ' Behavior Modification ', ' Behavior Conditioning Therapy ', ' Client ', ' Communities ', ' web-based training ', ' web-based instruction ', ' virtual learning ', ' virtual education ', ' technology-enhanced learning ', ' online learning ', ' online education ', ' on-line learning ', ' on-line education ', ' multimedia learning ', ' internet-based training ', ' internet-assisted education ', ' electronic learning ', ' eLearning ', ' digital learning ', ' digital education ', ' computer-based training ', ' computer-based learning ', ' computer-based instruction ', ' computer-based education ', ' computer-assisted instruction ', ' E-learning ', ' Counseling ', ' Counselor ', ' Professional counselor ', ' drug/agent ', ' Pharmaceutic Preparations ', ' Medication ', ' Drugs ', ' Pharmaceutical Preparations ', ' Environment ', ' Feasibility Studies ', ' Feedback ', ' Foundations ', ' Goals ', ' Modern Man ', ' Human ', ' Judgment ', ' Language ', ' Learning ', ' Methods ', ' Methodology ', ' Mission ', ' Persons ', ' National Institutes of Health ', ' NIH ', ' United States National Institutes of Health ', ' web based ', ' online computer ', ' On-Line Systems ', ' Online Systems ', ' opioid drug abuse ', ' opiate drug abuse ', ' opiate abuse ', ' opioid abuse ', ' Psychology ', ' Psychotherapy ', ' Research ', ' R&D ', ' R & D ', ' Development and Research ', ' research and development ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Resources ', ' Resources ', ' Software ', ' Computer software ', ' Computer Software Engineering ', ' Computer Software Development ', ' Software Engineering ', ' Computer Software Tools ', ' Software Tools ', ' sound ', ' Speech ', ' Substance Use Disorder ', ' suicidality ', ' intent to die ', ' fatal suicide ', ' fatal attempt ', ' Suicide ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Training Support ', ' Universities ', ' Utah ', ' Work ', ' Measures ', ' Administrator ', ' base ', ' quality assurance ', ' improved ', ' Site ', ' Clinical ', ' Phase ', ' Evaluation ', ' Training ', ' Intuition ', ' Alcohol or Other Drugs use ', ' using substances ', ' substance using ', ' substance use ', ' AOD use ', ' Opioid ', ' Opiates ', ' Measurement ', ' Funding ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Dependence ', ' Stream ', ' Clinic ', ' Protocols documentation ', ' Protocol ', ' Pattern ', ' System ', ' Benchmarking ', ' Best Practice Analysis ', ' Needs Assessment ', ' American ', ' experience ', ' Performance ', ' visual feedback ', ' Health Insurance Portability and Accountability Act ', ' United States Health Insurance Portability and Accountability Act ', ' Public Law 104-191 ', ' PL104-191 ', ' PL 104-191 ', ' Kennedy Kassebaum Act ', ' HIPAA ', ' skills ', ' novel ', ' motivational enhancement therapy ', ' motivational interview ', ' technological innovation ', ' Reporting ', ' Substance abuse problem ', ' substance abuse ', ' abuse of substances ', ' Health Technology ', ' Healthcare Technology ', ' Health Care Technology ', ' Code ', ' Coding System ', ' protocol development ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Enhancement Technology ', ' Provider ', ' automobile accident ', ' car accident ', ' Adherence ', ' National Institute of Drug Abuse ', ' National Institute on Drug Abuse ', ' NIDA ', ' Small Business Innovation Research Grant ', ' Small Business Innovation Research ', ' SBIR ', ' Update ', ' Validation ', ' Process ', ' Development ', ' developmental ', ' Behavioral ', ' Evidence based treatment ', ' substance abuse treatment ', ' substance abuse therapy ', ' cost ', ' implementation research ', ' virtual ', ' design ', ' designing ', ' Outcome ', ' cost efficient ', ' Consumption ', ' innovation ', ' innovative ', ' innovate ', ' speech processing ', ' user centered design ', ' usability ', ' addiction ', ' addictive disorder ', ' tool development ', ' prototype ', ' community setting ', ' evidence base ', ' clinical practice ', ' overdose death ', ' signal processing ', ' cloud based ', ' Assessment tool ', ' Assessment instrument ', ' support tools ', ' prediction algorithm ', ' predictor algorithm ', ' predictive algorithm ', ' dashboard ', ' treatment services ', ' opioid treatment program ', ' gun homicide ', ' automated speech recognition ', ' automatic speech recognition ', ' ']",NIDA,"LYSSN.IO, INC.",R44,2019,553403,WA-07,0.1036355459562089
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants     DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9722203,R01DC014290,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Cochlear Prosthesis ', ' Cochlear Implants ', ' Environment ', ' Hearing ', ' Maps ', ' Masks ', ' Methods ', ' Noise ', ' Problem Solving ', ' QOL ', ' Quality of life ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Time ', ' Comprehension ', ' base ', ' improved ', ' Surface ', ' Ensure ', ' Stimulus ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Frequencies ', ' Home environment ', ' Home ', ' Source ', ' Location ', ' Performance ', ' speech recognition ', ' success ', ' simulation ', ' Categories ', ' Environmental Risk Factor ', ' environmental risk ', ' Environmental Factor ', ' Devices ', ' Modeling ', ' response ', ' Address ', ' Development ', ' developmental ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' speech processing ', ' public health relevance ', ' recruit ', ' microphone ', ' deaf ', ' profound hearing loss ', ' deafened ', ' normal hearing ', ' healthy hearing ', ' good hearing ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2019,326399,NC-04,0.26989920720488025
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,9835650,F32DC018205,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', "" Alzheimer's Disease "", ' senile dementia of the Alzheimer type ', ' primary degenerative dementia ', ' dementia of the Alzheimer type ', ' Primary Senile Degenerative Dementia ', ' Alzheimers disease ', ' Alzheimers Dementia ', "" Alzheimer's "", ' Alzheimer syndrome ', ' Alzheimer sclerosis ', ' Alzheimer disease ', ' Alzheimer Type Dementia ', ' Alzheimer ', ' Aphasia ', ' Logasthenia ', ' Logamnesia ', ' Logagnosia ', ' Anepia ', ' Alogia ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' sound perception ', ' hearing perception ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Cognition ', ' Communication ', ' Foundations ', ' Goals ', ' Modern Man ', ' Human ', ' Judgment ', ' Linguistic ', ' Linguistics ', ' magnetoencephalographic imaging ', ' MEG imaging ', ' Magnetoencephalography ', ' Music ', ' Noise ', ' Perception ', ' Rhythmicity ', ' Cyclicity ', ' Periodicity ', ' psychophysical ', ' Psychophysics ', ' Records ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' social role ', ' Role ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Work ', ' Measures ', ' career ', ' Solid ', ' Series ', ' insight ', ' Stimulus ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Functional Magnetic Resonance Imaging ', ' fMRI ', ' Functional MRI ', ' programs ', ' Frequencies ', ' Auditory ', ' System ', ' Performance ', ' relating to nervous system ', ' neural ', ' Structure ', ' neuroimaging ', ' neuro-imaging ', ' Participant ', ' Brain region ', ' Address ', ' autism spectrum disorder ', ' autistic spectrum disorder ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autistic Disorder ', ' Autism ', ' Data ', ' Process ', ' Behavioral ', ' Pathway interactions ', ' pathway ', ' Mind ', ' neuromechanism ', ' neural mechanism ', ' cognitive neuroscience ', ' speech processing ', ' operation ', ' non-invasive imaging ', ' noninvasive imaging ', ' spectral energy ', ' spectrum energy ', ' experimental study ', ' experimental research ', ' experiment ', ' auditory processing ', ' ']",NIDCD,NEW YORK UNIVERSITY,F32,2019,60854,NY-12,0.2969489311245828
"Using Speech Acoustics to Reveal Motor Disruptions in Psychosis Project summary The goal of this project is to investigate the feasibility of using speech acoustics as a clinical biomarker in individuals at clinical high risk (CHR) for developing psychosis. There is evidence that disruptions to cortico-cerebellar circuits in individuals experiencing attenuated psychosis symptoms impact motor control of the face and limbs. This proposal would be the first study to examine whether these motor disruptions in high-risk populations also affect the complex motor control required for speech. In Aim 1 an instrumental approach will be used to investigate the acoustic correlates of psychosis risk. Specifically, speech data will be collected to investigate fine-grained acoustic properties of vowels and consonants in simple repetition tasks as well as during more naturalistic conversational speech. The speech of CHR young adults will be compared to age-matched healthy controls to discover if there are group differences in the speech acoustics that allow us to classify speech samples into healthy and clinical groups. To enable fast, reliable analysis, machine learning-based algorithms will be used to measure the acoustics speech properties of interest. In Aim 2, the speech properties measured in Aim 1 will be compared to other behavioral measures, in order to discover if they correlate with several measures of cerebellar dysfunction (posture control, procedural learning, and motor timing) that are known to occur in CHR individuals. These measures will provide convergent validity for these novel speech measures. Cognitive capabilities which are related and unrelated to speech and motor control will also be assessed, to provide specificity and divergent validity to these measures. In Aim 3, the links between speech features and changes in symptom severity will be assessed at two time points, connecting changes in speech motor control to longitudinal changes in the progression of the symptoms over 12 months. These investigations may reveal speech as a novel and easily-collected biomarker enabling early detection of psychosis risk. Project narrative The goal of this proposal is to determine whether speech patterns can signal vulnerability to psychotic disorders such as schizophrenia. Speech samples will be collected from high-risk and matched healthy control participants in order to: determine if there are abnormalities in the acoustics of vowels and consonants; evaluate if these properties map on to dysfunction of the cerebellum (a brain region impacted in the development of psychosis that also plays a role in speech motor control); and relate these properties to symptom severity and illness progression. This study will lay the groundwork for the use of speech as an inexpensive, non-invasive, and mechanistically-relevant metric that will ultimately support earlier identification and facilitate timely treatment.",Using Speech Acoustics to Reveal Motor Disruptions in Psychosis,9746454,R21MH119677,"['Acoustics ', ' Acoustic ', ' Affect ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Behavior ', ' Cerebellum Diseases ', ' Cerebellar Syndromes ', ' Cerebellar Dysfunction ', ' Cerebellar Disorders ', ' Cerebellar Diseases ', ' Cerebellum ', ' Computers ', ' Control Groups ', ' Diagnosis ', ' Dyskinesias ', ' Abnormal Movements ', ' Dyskinetic syndrome ', ' balance function ', ' balance ', ' Equilibrium ', ' Non-Trunk ', ' Limbs ', ' Extremities ', ' Limb structure ', ' facial ', ' faces ', ' Face ', ' Fingers ', ' Goals ', ' indexing ', ' Interview ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Learning ', ' Linguistic ', ' Linguistics ', ' Lip ', ' Lip structure ', ' Literature ', ' Maps ', ' body movement ', ' Movement ', ' NIMH ', ' National Institute of Mental Health ', ' Play ', ' Posture ', ' Production ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Risk ', ' social role ', ' Role ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Specificity ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Sound ', ' Testing ', ' Time ', ' Tongue ', ' Measures ', ' Youth 10-21 ', ' Youth ', ' Roter ', ' base ', ' improved ', ' Clinical ', ' Variant ', ' Variation ', ' Neurologic ', ' Neurological ', ' Link ', ' Ensure ', ' motor disorder ', ' motor dysfunction ', ' motor disease ', ' Individual ', ' young adult ', ' young adulthood ', ' adult youth ', ' Measurement ', ' Early Intervention ', ' Functional disorder ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Attenuated ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Scientist ', ' Investigation ', ' Severities ', ' Complex ', ' Sensory ', ' Pattern ', ' System ', ' Severity of illness ', ' disease severity ', ' interest ', ' Cueing for speech ', ' cued speech ', ' Early Diagnosis ', ' early detection ', ' experience ', ' behavior measurement ', ' behavioral measurement ', ' behavioral measure ', ' relating to nervous system ', ' neural ', ' Structure ', ' sensory integration ', ' novel ', ' Participant ', ' Positioning Attribute ', ' Position ', ' motor deficit ', ' Early identification ', ' Sampling ', ' Property ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Pathogenicity ', ' postural control ', ' Postural Equilibrium ', ' Postural Balance ', ' Musculoskeletal Equilibrium ', ' Brain region ', ' disease causation ', ' causation ', ' Causality ', ' Etiology ', ' Address ', ' Symptoms ', ' Data ', ' Motor ', ' Cognitive ', ' Process ', ' Development ', ' developmental ', ' Behavioral ', ' Population ', ' vocal control ', ' motor learning ', ' locomotor learning ', ' motor control ', ' high risk ', ' novel marker ', ' novel biomarker ', ' new marker ', ' Biological Markers ', ' biomarker ', ' biologic marker ', ' bio-markers ', ' individualized medicine ', ' unique treatment ', ' tailored treatment ', ' tailored therapy ', ' tailored medical treatment ', ' individualized treatment ', ' individualized therapy ', ' individualized patient treatment ', ' customized treatment ', ' customized therapy ', ' clinical predictors ', ' potential biomarker ', ' potential biological marker ', ' clinical biomarkers ', ' clinically useful biomarkers ', ' high risk population ', ' high risk group ', ' Grain ', ' ']",NIMH,NORTHWESTERN UNIVERSITY,R21,2019,239000,IL-07,0.30906975167672157
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics ', ' Acoustic ', ' Adult ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Affect ', ' Algorithms ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' sound perception ', ' hearing perception ', ' Auditory Perceptual Disorders ', ' central processing disorder ', ' Psychoacoustical Disorders ', ' Auditory Processing Disorder ', ' Auditory Perceptual Diseases ', ' Auditory Comprehension Disorder ', ' Acoustic Perceptual Disorder ', ' Behavior ', ' cognitive syndrome ', ' cognitive disorder ', ' cognitive disease ', ' Cognition Disorders ', ' Communication ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Cues ', ' Diagnosis ', ' Disorder ', ' Disease ', ' Electrodes ', ' electrophysiological ', ' Neurophysiology / Electrophysiology ', ' Electrophysiology ', ' Electrophysiology (science) ', ' Elements ', ' Foundations ', ' Goals ', ' hearing\xa0device ', ' hearing\xa0assistive device ', ' hearing assistance ', ' hearing amplification ', ' assistive listening device ', ' assistive hearing device ', ' Hearing Aids ', ' Heart ', ' Modern Man ', ' Human ', ' Infant ', ' Language ', ' language learning ', ' language acquisition ', ' acquiring language skills ', ' Language Development ', ' Learning ', ' lifespan ', ' life span ', ' Length of Life ', ' Longevity ', ' Model System ', ' Biologic Models ', ' Biological Models ', ' neurobiological ', ' Neurobiology ', ' neuronal ', ' Neurocyte ', ' Neural Cell ', ' Nerve Unit ', ' Nerve Cells ', ' Neurons ', ' Neurosciences ', ' Perception ', ' QOL ', ' Quality of life ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Testing ', ' Time ', ' Work ', ' Generations ', ' Superior temporal gyrus ', ' Comprehension ', ' improved ', ' Physiological ', ' Physiologic ', ' Failure ', ' Stimulus ', ' Individual ', ' Plant Roots ', ' root ', ' Sturnus vulgaris ', ' Sturnidae ', ' Starlings ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Auditory ', ' Complex ', ' Parietal ', ' Stream ', ' Sensory ', ' Pattern ', ' Techniques ', ' specific language impairment ', ' Dyslexia ', ' Word Blindness ', ' Auditory system ', ' experience ', ' speech recognition ', ' success ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' Songbirds ', ' song bird ', ' Oscines ', ' sensory system ', ' Categories ', ' Modality ', ' Learning Disabilities ', ' Learning disability ', ' Code ', ' Coding System ', ' neural circuit ', ' synaptic circuitry ', ' synaptic circuit ', ' neural circuitry ', ' Modeling ', ' response ', ' model development ', ' pattern perception ', ' hearing impairment ', ' hearing dysfunction ', ' hearing disability ', ' hearing difficulty ', ' hearing deficit ', ' hearing defect ', ' dysfunctional hearing ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' autism spectrum disorder ', ' autistic spectrum disorder ', "" Kanner's Syndrome "", ' Infantile Autism ', ' Early Infantile Autism ', ' Autistic Disorder ', ' Autism ', ' Data ', ' Detection ', ' Cognitive ', ' Process ', ' Grouping ', ' groupings ', ' Behavioral ', ' computer framework ', ' computational framework ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' bird song ', ' birdsong ', ' speech processing ', ' language processing ', ' spatiotemporal ', ' neurobiological mechanism ', ' learned behavior ', ' learning behavior ', ' language comprehension ', ' comprehending language ', ' signal processing ', ' cognitive process ', ' sensory input ', ' learning strategy ', ' learning method ', ' learning activity ', ' experimental study ', ' experimental research ', ' experiment ', ' auditory processing ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,CA-52,0.0536514151285587
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility  the final arbiter of speech goodness  is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.  There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9631443,R01DC006859,"['Acoustics ', ' Acoustic ', ' Affect ', ' Attention ', ' Communicative Disorders ', ' Communication Disorders ', ' Communication impairment ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Cues ', ' Dysarthosis ', ' Dysarthria ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' treatment access ', ' service availability ', ' health services availability ', ' health service access ', ' care access ', ' availability of services ', ' accessibility to health services ', ' access to treatment ', ' access to services ', ' access to health services ', ' Access to Care ', ' Health Services Accessibility ', ' Judgment ', ' Language ', ' Learning ', ' Theoretic Models ', ' Theoretical model ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' nervous system disorder ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Rhythmicity ', ' Cyclicity ', ' Periodicity ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' Educational Intervention ', ' instructional intervention ', ' Training Intervention ', ' Instruction Intervention ', ' Education for Intervention ', ' Pathologist ', ' tool ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Trauma ', ' neurotrauma ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Code ', ' Coding System ', ' Modeling ', ' Sampling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' disparity in health ', ' health disparity ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' predictive modeling ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' outcome prediction ', ' predictors of outcomes ', ' predictive outcomes ', ' recruit ', ' optimal treatments ', ' optimal therapies ', ' machine learning algorithm ', ' speech in noise ', ' speech recognition in noise ', ' speech in speech recognition ', ' speech in background noise ', ' hearing in noise ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,308669,AZ-09,0.3565471150187476
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through part-of-speech tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (which, what, that). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis  semantics and syntax  that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9669113,R01MH115332,"['Age ', ' ages ', ' Archives ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Felis sylvestris catus ', ' Felis domesticus ', ' Felis domestica ', ' Feline Species ', ' Domestic Cats ', ' Cats Mammals ', ' Cats ', ' Felis catus ', ' Systematics ', ' Classification ', ' Cognition ', ' Communication ', ' Computers ', ' Diagnosis ', ' Disorder ', ' Disease ', ' domestic dog ', ' canine ', ' Dogs Mammals ', ' Dogs ', ' Canine Species ', ' Canis familiaris ', ' EEG ', ' Electroencephalography ', ' Modern Man ', ' Human ', ' indexing ', ' Interview ', ' Language ', ' Linguistic ', ' Linguistics ', ' Manuals ', ' Methods ', ' Morbidity ', ' Morbidity - disease rate ', ' NIMH ', ' National Institute of Mental Health ', ' National Institutes of Health ', ' NIH ', ' United States National Institutes of Health ', ' natural language understanding ', ' Natural Language Processing ', ' Patients ', ' Poverty ', ' Production ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Resources ', ' Resources ', ' Risk ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' Semantics ', ' Speech ', ' thoughts ', ' Thinking ', ' Work ', ' Yogurt ', ' Measures ', ' Dataset ', ' Data Set ', ' analytical method ', ' base ', ' Site ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Series ', ' Individual ', ' Collaborations ', ' Metaphor ', ' Genetic ', ' Morphology ', ' Diagnostic ', ' Scientist ', ' Dimensions ', ' syntax ', ' syntactic ', ' cohort ', ' relating to nervous system ', ' neural ', ' phrases ', ' novel ', ' NIH Program Announcements ', ' Program Announcement ', ' Graph ', ' Categories ', ' response ', ' functional disability ', ' Functional impairment ', ' Mediator of activation protein ', ' Mediator of Activation ', ' Mediator ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' International ', ' Sum ', ' Scientific Advances and Accomplishments ', ' scientific advances ', ' scientific accomplishments ', ' Text ', ' Development ', ' developmental ', ' Image ', ' imaging ', ' Output ', ' vector ', ' Outcome ', ' Mind ', ' Affective ', ' healthy volunteer ', ' high risk ', ' natural language ', ' Research Domain Criteria ', ' RDoC ', ' neural correlate ', ' data archive ', ' secondary analysis ', ' Grain ', ' ']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,468909,NY-13,0.03378951410178257
"A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia Abstract 1 in 3 seniors in the United States dies with dementia, of which Alzheimers disease (AD) is the most common form. AD patients suffer from decreased ability to meaningfully communicate and interact, which causes significant stress and burden for both professional caregivers and family members. Socially assistive robots (SARs) have been designed to promote therapeutic interaction and communication. Unfortunately, artificial intelligence (AI) has long been challenged by the speech of elderly persons, who exhibit age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers that can be exacerbated by the neurological changes associated with AD, further complicated by common environmental noises such as the ceiling fan, television, etc. Because of the resulting poor real-world speech and language understanding by available SAR technologies, scarce human caregivers are often required to guide AD patients through SAR interactions, limiting SARs to small deployments, mostly as part of research studies. Unlike existing approaches relying purely on AI, care.coach is developing a SAR-like avatar that converses with elderly and AD patients through truly natural speech. Each avatar is controlled by a 24x7 team of trained human staff who can cost-effectively monitor and engage 12 or more patients sequentially (2 simultaneously) through the audio/visual feeds from the patients avatar device. The staff communicate with each patient by sending text commands which are converted into the avatars voice through a speech synthesis engine. The staff contribute to the system their human abilities for speech and natural language processing (NLP) and for generating free-form conversational responses to help patients build personal relationships with the avatar. The staff are guided by a software-driven expert system embedded into their work interface, which is programmed with evidence-based prompting and protocols to support healthy behaviors and self-care. This SBIR Fast-Track project will leverage the unique data generated by our human- in-the-loop platform to develop new ASR capabilities, enabling fully automatic conversational protocols to engage and support AD patients without human intervention. We aim in Phase I to leverage our unique prior work dataset to train an automatic speech recognition (ASR) engine to enable the understanding of certain types of elderly and AD patient speech more successfully than any currently available engine. We aim in Phase II to incorporate this new engine along with an NLP module into our existing human-in-the-loop avatar system, recruiting a population of AD patients to further train and validate with during a 2-year human subjects study so that we can demonstrate full automation of a significant portion of our avatar conversations with mild- to-moderate level AD patients. Thus, we will improve the commercial scalability of our avatars, while validating our new ASR/NLP engine as the most accurate platform for enabling the next generation of AD-focused SARs. Narrative Artificial intelligence (AI) has long been challenged by the speech of elderly persons, and especially persons with dementia, due to age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers. Unlike existing approaches to socially assistive robots (SARs) relying purely on limited AI for conversation, care.coach has been commercializing a SAR-like avatar that converses with elderly and AD patients through truly natural speech, powered by a 24x7 team of trained human staff. The unique data sets that our solution enables us to gather at commercial scale will be leveraged in this SBIR project to develop an automatic speech recognition (ASR) and natural language processing (NLP) engine that is best-in-class for AD applications, improving the commercial scalability of our avatars by reducing our dependence on human staff, while serving as a new AI platform for enabling the next generation of AD- focused, conversational SARs.",A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia,9777444,R44AG062014,"['Age ', ' ages ', ' Elderly ', ' senior citizen ', ' older person ', ' older adult ', ' later life ', ' late life ', ' geriatric ', ' elders ', ' advanced age ', "" Alzheimer's Disease "", ' senile dementia of the Alzheimer type ', ' primary degenerative dementia ', ' dementia of the Alzheimer type ', ' Primary Senile Degenerative Dementia ', ' Alzheimers disease ', ' Alzheimers Dementia ', "" Alzheimer's "", ' Alzheimer syndrome ', ' Alzheimer sclerosis ', ' Alzheimer disease ', ' Alzheimer Type Dementia ', ' Alzheimer ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Automation ', ' Behavior ', ' Clinical Study ', ' Clinical Research ', ' Communication ', ' Computers ', ' delirious ', ' Delirium ', ' Disorder ', ' Disease ', ' Exhibits ', ' Intelligent systems ', ' Expert Systems ', ' Family ', ' Goals ', ' Hospitals ', ' Community Hospitals ', ' Modern Man ', ' Human ', ' Hybrids ', ' Institutes ', ' Jamaica ', ' Language ', ' lonely ', ' Loneliness ', ' Manuals ', ' Persons ', ' natural language understanding ', ' Natural Language Processing ', ' Noise ', ' Patients ', ' Production ', ' personal care ', ' Self Care ', ' Semantics ', ' Social Interaction ', ' social support network ', ' Social support ', ' Software ', ' Computer software ', ' Speech ', ' Stress ', ' Technology ', ' Television ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Tremor ', ' United States ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' World Health Organization ', ' Generations ', ' Measures ', ' pricing ', ' Price ', ' Care Givers ', ' Caregivers ', ' falls ', ' depressive ', ' depression symptom ', ' Emotional Depression ', ' depressive symptoms ', ' Family member ', ' Dataset ', ' Data Set ', ' Caring ', ' human subject ', ' Label ', ' improved ', ' Phase ', ' Neurologic ', ' Neurological ', ' Training ', ' Visual ', ' Individual ', ' Licensing ', ' satisfaction ', ' Therapeutic ', ' Contracts ', ' Contracting Opportunities ', ' restraint ', ' Hour ', ' Frequencies ', ' Dependence ', ' Home environment ', ' Home ', ' Protocols documentation ', ' Protocol ', ' Reaction ', ' Techniques ', ' System ', ' Dementia ', ' Amentia ', ' Medical center ', ' speech recognition ', ' success ', ' phrases ', ' skills ', ' research study ', ' Study Subject ', ' Devices ', ' Modeling ', ' Neural Network Simulation ', ' Perceptrons ', ' Neural Network Models ', ' Connectionist Models ', ' response ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Feeds ', ' Data ', ' Small Business Innovation Research Grant ', ' Small Business Innovation Research ', ' SBIR ', ' Validation ', ' Monitor ', ' Text ', ' age related ', ' age dependent ', ' cost ', ' feeding ', ' design ', ' designing ', ' next generation ', ' older patient ', ' elderly patient ', ' Population ', ' Network-based ', ' usability ', ' aging population ', ' population aging ', ' aged population ', ' evidence base ', ' human-in-the-loop ', ' recruit ', ' care providers ', ' primary care provider ', ' health plan ', ' health plans ', ' patient engagement ', ' patient response ', ' responsive patient ', ' deep neural network ', ' deep neural net ', ' deep learning neural network ', ' deep learning based neural network ', ' speech synthesis ', "" Alzheimer's disease related dementia "", ' Alzheimer related dementia ', ' ADRD ', ' automated speech recognition ', ' automatic speech recognition ', ' social assistive robot ', ' ']",NIA,CARE.COACH CORPORATION,R44,2019,349998,CA-14,0.04363185312010418
"Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates     DESCRIPTION (provided by applicant): 90% of the 1.5 million Americans living with idiopathic Parkinson's disease (PD) and 50% of the 500,000 Americans living with Multiple Sclerosis (MS) will experience dysarthria. Dysarthria has devastating consequences for life quality and participation in society due to its effects on employment, leisure activities and social relationships. Knowledge of therapy techniques for maximizing perceived speech adequacy, as indexed by the gold standard perceptual construct of intelligibility is thus of vital importance. Owing to the scarcity of impartial comparative studies, the choice of one technique over others is often based on trial and error or reflects clinician bias, both of which are at odds with evidence-based practice. This project has sought to address this critical gap in knowledge regarding the comparative merits of dysarthria treatment techniques since its inception. Toward this end, published studies from the past funding cycle compared the acoustic and perceptual merits of three common, global dysarthria treatment techniques including 1) rate manipulation, 2) an increased vocal intensity and 3) clear speech in MS and PD as well as age and sex matched neurotypical talkers. Global treatment techniques by their very nature elicit co-occurring acoustic changes (e.g., duration, segmental articulation). Because an explanatory, acoustically-based model of intelligibility is lacking, the acoustic change(s) causing or explainin the improved perceptual outcomes of global treatment techniques are unknown. Determining the acoustic variables explaining intelligibility variation in dysarthria would not only tremendousy advance theoretical understanding of intelligibility but also would strengthen the scientific basis for treatment. Treatment focused on those acoustic variables explanatory for improved intelligibility may further accelerate progress in therapy. Importantly, research from the previous funding cycle suggests the promise of speech analysis-resynthesis for identifying segmental and suprasegmental acoustic variables explanatory for intelligibility in dysarthria. Building upon this work, the overarching goal of the continuation is to contribute towards development of an acoustically-based explanatory model of intelligibility. Our approach 1) employs established perceptual procedures and acoustic measures, 2) uses an innovative analysis-resynthesis technique that permits conclusions concerning the explanatory relationship between acoustic changes accompanying dysarthria therapy techniques and intelligibility, and 3) leverages methods from machine learning to build a predictive model of intelligibility from acoustics. The impact of this work is in its contribution to 1) advancing conceptual understanding of intelligibility, 2) strengthening the scientific basis for treatment, and 3) optimizing clinical implementation of dysarthria therapy techniques. PUBLIC HEALTH RELEVANCE: This project is directly relevant to the mission of NIDCD due to its focus on investigating the therapeutic techniques for maximizing intelligibility in dysarthra secondary to Parkinson's disease and Multiple Sclerosis. By advancing conceptual understanding of intelligibility, this research will strengthen the scientific basis for dysarthria treatments and will optimize their clinical implementation.",Therapeutic Approaches to Dysarthria:  Acoustic and Perceptual Correlates,9766229,R01DC004689,"['Acoustics ', ' Acoustic ', ' Affect ', ' Age ', ' ages ', ' Comparative Study ', ' Dysarthosis ', ' Dysarthria ', ' Employment ', ' Goals ', ' Gold ', ' indexing ', ' Leisure Activities ', ' Methods ', ' Mission ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Parkinson Disease ', ' Production ', ' Publishing ', ' QOL ', ' Quality of life ', ' Research ', ' Societies ', ' Speech ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Work ', ' Measures ', ' Secondary to ', ' base ', ' improved ', ' Procedures ', ' Variant ', ' Variation ', ' Individual ', ' Funding ', ' Therapeutic ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Frequencies ', ' Techniques ', ' American ', ' experience ', ' treatment program ', ' social ', ' Modeling ', ' Orthography ', ' hearing impairment ', ' hearing dysfunction ', ' hearing disability ', ' hearing difficulty ', ' hearing deficit ', ' hearing defect ', ' dysfunctional hearing ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Address ', ' Evidence based practice ', ' sex ', ' Development ', ' developmental ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' Instruction ', ' predictive modeling ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' Outcome ', ' innovation ', ' innovative ', ' innovate ', ' comparative ', ' public health relevance ', ' clear speech ', ' Idiopathic Parkinson Disease ', ' Articulation ', ' clinical implementation ', ' treatment optimization ', ' therapy optimization ', ' ']",NIDCD,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2019,517281,NY-26,0.060050512759730355
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9623341,R01DC012048,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Environment ', ' Goals ', ' Hearing ', ' hearing\xa0device ', ' hearing\xa0assistive device ', ' hearing assistance ', ' hearing amplification ', ' assistive listening device ', ' assistive hearing device ', ' Hearing Aids ', ' Laboratories ', ' Masks ', ' Methods ', ' Modernization ', ' Noise ', ' Recurrent ', ' Recurrence ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' sound ', ' Speech ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Voice ', ' Work ', ' Racial Segregation ', ' segregation ', ' base ', ' improved ', ' Surface ', ' Chronic ', ' Training ', ' Individual ', ' Investigation ', ' Frequencies ', ' Auditory ', ' Complex ', ' Source ', ' Techniques ', ' System ', ' American ', ' success ', ' Structure ', ' Modeling ', ' Neural Network Simulation ', ' Perceptrons ', ' Neural Network Models ', ' Connectionist Models ', ' hearing impairment ', ' hearing dysfunction ', ' hearing disability ', ' hearing difficulty ', ' hearing deficit ', ' hearing defect ', ' dysfunctional hearing ', ' Hypoacusis ', ' Hypoacuses ', ' Hearing Loss ', ' Address ', ' Symptoms ', ' Data ', ' digital ', ' design ', ' designing ', ' innovation ', ' innovative ', ' innovate ', ' Network-based ', ' real world application ', ' combat ', ' signal processing ', ' network architecture ', ' Formulation ', ' experimental study ', ' experimental research ', ' experiment ', ' deep neural network ', ' deep neural net ', ' deep learning neural network ', ' deep learning based neural network ', ' deep learning ', ' microphone ', ' supervised learning ', ' supervised machine learning ', ' Auditory Prosthesis ', ' hearing prosthetic ', ' hearing prosthesis ', ' auditory prosthetic ', ' normal hearing ', ' healthy hearing ', ' good hearing ', ' speech in noise ', ' speech recognition in noise ', ' speech in speech recognition ', ' speech in background noise ', ' hearing in noise ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,304865,OH-03,0.30848144351414103
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes Project Summary The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility  the final arbiter of speech goodness  is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multidimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long- term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries. Project Narrative There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9911475,R01DC006859,"['Acoustics ', ' Acoustic ', ' virtual simulation ', ' in silico ', ' computerized simulation ', ' computerized modeling ', ' computer based models ', ' computational simulation ', ' computational models ', ' computational modeling ', ' Mathematical Models and Simulations ', ' Mathematical Model Simulation ', ' Computerized Models ', ' Computer based Simulation ', ' Computer Models ', ' Computer Simulation ', ' Dysarthosis ', ' Dysarthria ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' treatment access ', ' service availability ', ' health services availability ', ' health service access ', ' care access ', ' availability of services ', ' accessibility to health services ', ' access to treatment ', ' access to services ', ' access to health services ', ' Access to Care ', ' Health Services Accessibility ', ' Judgment ', ' Language ', ' Learning ', ' Theoretic Models ', ' Theoretical model ', ' neurological disease ', ' Neurological Disorders ', ' Neurologic Disorders ', ' Nervous System Diseases ', ' nervous system disorder ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Transcription ', ' RNA Expression ', ' Gene Transcription ', ' Genetic Transcription ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Educational Intervention ', ' instructional intervention ', ' Training Intervention ', ' Instruction Intervention ', ' Education for Intervention ', ' Pathologist ', ' Country ', ' novel ', ' Nervous System Trauma ', ' neurotrauma ', ' Neurological trauma ', ' Neurological Injury ', ' Neurological Damage ', ' Nervous System damage ', ' Nervous System Injuries ', ' Code ', ' Coding System ', ' Modeling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' disparity in health ', ' health disparity ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' predictive modeling ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' Outcome ', ' standard of care ', ' clinical practice ', ' outcome prediction ', ' predictors of outcomes ', ' predictive outcomes ', ' machine learning algorithm ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,208745,AZ-09,0.3554926412603302
"Acoustic speech analysis of patients with decompensated heart failure Abstract Heart failure (HF) is the most common cause of hospitalization among Americans over 65 years of age. A major goal of HF management is to maintain stability by predicting and preventing episodes of acute decompensated HF (ADHF). Body weight is currently used for non-invasive, at-home monitoring of volume status, and as an early warning for decompensation, by patients with HF. However, HF-related weight changes occur relatively close to the onset of symptoms and may not be detected in time to prevent an episode of decompensation. In contrast, the vocal folds consist of thin tissue layers that are impacted by body hydration levels and may therefore be especially sensitive to HF-related fluid retention. The amount of laryngeal edema required to change voice acoustics is expected to be small relative to the large amount of systemic edema needed to significantly increase body weight. Therefore, we hypothesize that clinicians will be able to detect and track HF-related volume overload more closely by monitoring voice metrics in addition to weight. The goal of this project is to investigate the potential of voice and speech characteristics as correlates of clinical improvement during treatment for ADHF. In a pilot study, acoustic voice and speech measures from ten HF patients undergoing diuresis for HF were analyzed. Several promising voice measures were identified for additional investigation, including measures reflecting higher pitch and increased vocal stability following successful ADHF treatment. In this project, the study size will be expanded to facilitate more rigorous and extensive statistical analysis techniques, including machine learning and multi-level modeling analyses. Additionally, the potential of a neck-surface vibration sensor for noise-robust, confidential monitoring of ADHF status will be evaluated. The vibration sensor has been used extensively for voice monitoring in our lab because it is minimally affected by environmental noise and does not record intelligible speech, making it ideal for recording voice while preserving patient privacy in noisy environments. The performance of microphone-based recordings in predicting patients heart failure status will be compared with that of vibration-sensor-based recordings, with the hypothesis that the vibration sensor will work as well as, or better than, a conventional audio microphone. Completion of this project will result in a novel, voice-based method using wearable sensor technology to provide a monitoring system for HF patients recovering from decompensation, and will aid us in future work as we move towards developing an early warning system for patients at risk of ADHF. Project Narrative The proposed project will investigate how voice and speech production change in response to treatment of acute decompensated heart failure (ADHF), which is characterized by an abnormal accumulation of fluid throughout the body. Excess fluid in the vocal folds and lungs is hypothesized to cause a number of changes in voice and speech, which can be detected with acoustic analysis of recordings from both a conventional microphone and a novel neck-skin vibration sensor. This research may provide clinicians and patients with a method of detecting impending ADHF earlier and more easily than is currently possible, which could save lives, reduce healthcare costs, and improve patients quality of life.",Acoustic speech analysis of patients with decompensated heart failure,9744304,F31HL143824,"['Acoustics ', ' Acoustic ', ' Affect ', ' Blood ', ' Blood Reticuloendothelial System ', ' Body Weight ', ' Body Weight Changes ', ' Weight Change ', ' statistical analysis ', ' Statistical Data Analysis ', ' Statistical Data Analyses ', ' Statistical Data Interpretation ', ' Diagnosis ', ' Diuresis ', ' Hydrops ', ' Dropsy ', ' Edema ', ' Environment ', ' Exhibits ', ' Future ', ' Goals ', ' Gold ', ' Heart ', ' cardiac failure ', ' Heart failure ', ' Hospital Admission ', ' Hospitalization ', ' Modern Man ', ' Human ', ' Laboratories ', ' larynx edema ', ' Laryngeal Edema ', ' pulmonary ', ' Lung Respiratory System ', ' Lung ', ' Methods ', ' mortality ', ' Neck ', ' Noise ', ' Patients ', ' pilot study ', ' Pilot Projects ', ' pressure ', ' Production ', ' Publishing ', ' QOL ', ' Quality of life ', ' Records ', ' Research ', ' respiratory mechanism ', ' Respiration ', ' Risk ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Leanness ', ' Thinness ', ' Time ', ' Body Tissues ', ' Tissues ', ' Vocal Fold ', ' vocal cord ', ' Voice ', ' wt gain ', ' body weight increase ', ' body weight gain ', ' Weight Increase ', ' Weight Gain ', ' Weight ', ' Work ', ' Measures ', ' Healthcare Costs ', ' Health Costs ', ' Health Care Costs ', ' base ', ' Patient Monitoring System ', ' Pump ', ' sensor ', ' improved ', ' Surface ', ' Acute ', ' Clinical ', ' Medical ', ' Liquid substance ', ' liquid ', ' fluid ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Life ', ' Investigation ', ' Hour ', ' Home environment ', ' Home ', ' Protocols documentation ', ' Protocol ', ' Techniques ', ' System ', ' vibration ', ' EFRAC ', ' Ejection Fraction ', ' respiratory ', ' American ', ' experience ', ' Performance ', ' cohort ', ' novel ', ' Admission activity ', ' Admission ', ' multilevel analysis ', ' multilevel modeling ', ' multilevel model ', ' multi-level model ', ' multi-level analysis ', ' methods to study multiple-level influences ', ' response ', ' Vascular blood supply ', ' vascular supply ', ' blood supply ', ' Skin ', ' preventing ', ' prevent ', ' Hydration ', ' Hydration status ', ' Symptoms ', ' Age-Years ', ' Data ', ' Clinical Management ', ' Enrollment ', ' enroll ', ' Monitor ', ' Characteristics ', ' patient privacy ', ' treatment response ', ' therapeutic response ', ' response to treatment ', ' Biological Markers ', ' biomarker ', ' biologic marker ', ' bio-markers ', ' wearable sensor technology ', ' wireless sensor technology ', ' preservation ', ' microphone ', ' ']",NHLBI,HARVARD MEDICAL SCHOOL,F31,2019,32658,MA-07,0.06978757787263834
"Dynamics of Vocal Tract Shaping     DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9605700,R01DC007124,"['Acoustics ', ' Acoustic ', ' Adult ', ' adulthood ', ' Adult Human ', ' 21+ years old ', ' Apraxias ', ' apraxia ', ' Dyspraxia ', ' Articulators ', ' Beds ', ' Communication ', ' Communities ', ' Swallowing Disorders ', ' Dysphagia ', ' Deglutition Disorders ', ' Engineering ', ' Epiglottis ', ' Epiglottis structure ', ' Gestures ', ' Glossectomy ', ' Goals ', ' Modern Man ', ' Human ', ' Language ', ' language deficit ', ' Language disability ', ' Language Disorders ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Linguistic ', ' Linguistics ', ' Lip ', ' Lip structure ', ' Zeugmatography ', ' Nuclear Magnetic Resonance Imaging ', ' NMR Tomography ', ' NMR Imaging ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' MRI ', ' MR Tomography ', ' MR Imaging ', ' Magnetic Resonance Imaging ', ' Motion ', ' body movement ', ' Movement ', ' Noise ', ' Throat ', ' Pharynx ', ' Pharyngeal structure ', ' Play ', ' Posture ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' sleep-related breathing disorder ', ' Sleep-Disordered Breathing ', ' Sleep Hypopnea ', ' Sleep Apnea ', ' Sleep Apnea Syndromes ', ' sound ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' Island Flaps ', ' Flaps ', ' Surgical Flaps ', ' Teaching ', ' Educational process of instructing ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Traction ', ' Work ', ' Measures ', ' base ', ' image processing ', ' improved ', ' Lateral ', ' Clinical ', ' Variant ', ' Variation ', ' Series ', ' Training ', ' tongue apex ', ' tongue tip ', ' Individual ', ' Recovery ', ' Shapes ', ' tool ', ' German population ', ' German ', ' instrument ', ' Nature ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Investigation ', ' Dimensions ', ' Complex ', ' Event ', ' Oral ', ' In Situ ', ' Pattern ', ' System ', ' 3-Dimensional ', ' 3D ', ' 3-D ', ' Oropharyngeal ', ' oral pharyngeal ', ' Oropharynxs ', ' Oropharynx ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' phonology ', ' cohesion ', ' Speed ', ' Structure ', ' novel ', ' movie ', ' outreach ', ' technological innovation ', ' Modeling ', ' Property ', ' theories ', ' bioimaging ', ' biomedical imaging ', ' bio-imaging ', ' Three-Dimensional Imaging ', ' 3D imaging ', ' 3-D Imaging ', ' Data ', ' International ', ' Resolution ', ' Cognitive ', ' Cardiac ', ' Development ', ' developmental ', ' Image ', ' imaging ', ' web site ', ' website ', ' post stroke ', ' poststroke ', ' after stroke ', ' reconstruction ', ' shape analysis ', ' shape description ', ' computerized tools ', ' computational tools ', ' remediation ', ' Imaging technology ', ' Population ', ' Coupled ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' spatiotemporal ', ' public health relevance ', ' constriction ', ' dexterity ', ' program dissemination ', ' project dissemination ', ' Articulation ', ' high dimensionality ', ' imaging capabilities ', ' speech synthesis ', ' automated speech recognition ', ' automatic speech recognition ', ' real-time images ', ' realtime image ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,467515,CA-37,0.32452589820963934
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,9720522,K01DC017751,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Behavior ', ' Biomechanics ', ' biomechanical ', ' Communication ', ' statistical analysis ', ' Statistical Data Analysis ', ' Statistical Data Analyses ', ' Statistical Data Interpretation ', ' Diagnosis ', ' Endoscopes ', ' Goals ', ' Gold ', ' Health ', ' Modern Man ', ' Human ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' heavy metal lead ', ' heavy metal Pb ', ' Pb element ', ' Lead ', ' Methods ', ' Methodology ', ' Mining ', ' statistical linear models ', ' statistical linear mixed models ', ' Probability Models ', ' Probabilistic Models ', ' Statistical Models ', ' Patients ', ' Physics ', ' Production ', ' Research ', ' Speech ', ' Testing ', ' Time ', ' Tremor ', ' Vocal Fold ', ' vocal cord ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Measures ', ' Outcomes Research ', ' Dataset ', ' Data Set ', ' base ', ' image processing ', ' improved ', ' Area ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Series ', ' Evaluation ', ' Visual ', ' Measurement ', ' Spastic Dysphonias ', ' spasmodic dysphonia ', ' Functional disorder ', ' pathophysiology ', ' Physiopathology ', ' Dysfunction ', ' Therapeutic ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Severities ', ' Auditory ', ' Protocols documentation ', ' Protocol ', ' Source ', ' Techniques ', ' System ', ' vibration ', ' vocalization ', ' Paralysed ', ' paralytic ', ' paralysis ', ' Plegia ', ' Palsy ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' cohort ', ' kinematics ', ' kinematic model ', ' Speed ', ' Categories ', ' Prevention ', ' Modeling ', ' Address ', ' Data ', ' Strategic Planning ', ' Characteristics ', ' sex ', ' Development ', ' developmental ', ' Voice Disturbances ', ' Dysphonia ', ' Phonation Disorders ', ' Image ', ' imaging ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' time use ', ' Outcome ', ' Coupling ', ' innovation ', ' innovative ', ' innovate ', ' clinically relevant ', ' clinical relevance ', ' clinical application ', ' clinical applicability ', ' treatment strategy ', ' clinical practice ', ' flexibility ', ' flexible ', ' temporal measurement ', ' time measurement ', ' temporal resolution ', ' clinical development ', ' imaging approach ', ' imaging based approach ', ' ']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2019,137795,MI-08,0.2895177230947933
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. ",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,9916239,R01DC018446,"['Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomy Qualifier ', ' Anatomical Sciences ', ' Anatomic structures ', ' Anatomic Structures and Systems ', ' Anatomic Structure, System, or Substance ', ' Anatomic Sites ', ' Anatomic ', ' Animals ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Behavior ', ' Birds ', ' Avian ', ' Aves ', ' Brain ', ' Encephalon ', ' Brain Nervous System ', ' Nucleus ', ' Cell Nucleus ', ' Clinical Study ', ' Clinical Research ', ' Communication ', ' Communities ', ' Complement Proteins ', ' Complement ', ' Computers ', ' Diagnosis ', ' Disorder ', ' Disease ', ' Electrodes ', ' Engineering ', ' Non-Trunk ', ' Limbs ', ' Extremities ', ' Limb structure ', ' Feedback ', ' Future ', ' Goals ', ' History ', ' Recording of previous events ', ' Modern Man ', ' Human ', ' Language ', ' language deficit ', ' Language disability ', ' Language Disorders ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Maps ', ' Methods ', ' Motor Cortex ', ' neurophysiological ', ' neurophysiology ', ' Neurosciences ', ' Patients ', ' Play ', ' Production ', ' tetraplegic ', ' Tetraplegia ', ' Quadriplegic ', ' Quadriplegia ', ' Research ', ' social role ', ' Role ', ' Running ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Software ', ' Computer software ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Generations ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Comprehension ', ' Prosthesis ', ' Prosthetics ', ' Prosthetic device ', ' Injury ', ' base ', ' human subject ', ' Computer Interface ', ' improved ', ' Area ', ' Evaluation ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' Educational workshop ', ' Workshop ', ' Space Models ', ' Finches ', ' Robot ', ' Limb Prosthesis ', ' prosthetic limb ', ' Artificial Limbs ', ' Artificial Extremities ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' programs ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Neurodegenerative Disorders ', ' neurodegenerative illness ', ' degenerative neurological diseases ', ' degenerative diseases of motor and sensory neurons ', ' Neurologic Degenerative Conditions ', ' Neurodegenerative Diseases ', ' Neural degenerative Disorders ', ' Neural Degenerative Diseases ', ' Nervous System Degenerative Diseases ', ' Degenerative Neurologic Disorders ', ' Degenerative Neurologic Diseases ', ' meetings ', ' auditory feedback ', ' mind control ', ' brain control ', ' Performance ', ' success ', ' neural prosthesis ', ' neural prosthetic ', ' high school ', ' Animal Model ', ' model organism ', ' model of animal ', ' Animal Models and Related Studies ', ' relating to nervous system ', ' neural ', ' neurodevelopment ', ' Neural Development ', ' Songbirds ', ' song bird ', ' Oscines ', ' neurotransmission ', ' neuronal signaling ', ' neural signaling ', ' nerve signaling ', ' glial signaling ', ' glia signaling ', ' axonal signaling ', ' axon-glial signaling ', ' axon signaling ', ' Neuronal Transmission ', ' Nerve Transmission ', ' Nerve Impulse Transmission ', ' novel ', ' Basic Science ', ' Basic Research ', ' graduate student ', ' Prevention ', ' Modeling ', ' response ', ' Speech Development ', ' repository ', ' model development ', ' Limes ', ' Upper Extremity ', ' Upper Limb ', ' Membrum superius ', ' vocal learning ', ' Effectiveness ', ' Data ', ' Educational Materials ', ' Motor ', ' Principal Investigator ', ' Characteristics ', ' Development ', ' developmental ', ' Behavioral ', ' Output ', ' web site ', ' website ', ' Instruction ', ' design ', ' designing ', ' Clinical assessments ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' Implant ', ' bird song ', ' birdsong ', ' open source ', ' functional restoration ', ' restore lost function ', ' restore functionality ', ' restore function ', ' motor control ', ' data sharing ', ' operation ', ' undergraduate student ', ' undergraduate ', ' signal processing ', ' Learning Module ', ' Teaching Module ', ' Educational Module ', ' Education Module ', ' High School Student ', ' Secondary Student ', ' Secondary School Student ', ' Course Content ', ' course curriculum ', ' High School Outreach ', ' Data Science ', ' hackathon ', ' hackfest ', ' hack day ', ' Infrastructure ', ' machine learning algorithm ', ' functional electrical stimulation ', ' functional electrostimulation ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,354676,CA-52,0.19786225826742085
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Contact PD/PI: Corcoran, Cheryl M  Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through part-of-speech tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (which, what, that). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Project Summary/Abstract Page 7 Contact PD/PI: Corcoran, Cheryl M Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis  semantics and syntax  that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses. Project Narrative Page 8",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9903990,R01MH115332,"['Archives ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Systematics ', ' Classification ', ' Computers ', ' Disorder ', ' Disease ', ' EEG ', ' Electroencephalography ', ' Modern Man ', ' Human ', ' indexing ', ' Language ', ' Linguistic ', ' Linguistics ', ' Manuals ', ' Methods ', ' National Institutes of Health ', ' NIH ', ' United States National Institutes of Health ', ' Patients ', ' Poverty ', ' Production ', ' psychotic illness ', ' Psychoses ', ' Psychotic Disorders ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Research Resources ', ' Resources ', ' Risk ', ' schizophrenic ', ' dementia praecox ', ' Schizophrenic Disorders ', ' Schizophrenia ', ' Semantics ', ' Speech ', ' thoughts ', ' Thinking ', ' Work ', ' Measures ', ' Dataset ', ' Data Set ', ' analytical method ', ' base ', ' Site ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Individual ', ' Collaborations ', ' Scientist ', ' Dimensions ', ' syntax ', ' syntactic ', ' cohort ', ' phrases ', ' novel ', ' Graph ', ' response ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' International ', ' Text ', ' Image ', ' imaging ', ' Outcome ', ' Mind ', ' healthy volunteer ', ' Research Domain Criteria ', ' RDoC ', ' secondary analysis ', ' Grain ', ' ']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,89238,NY-13,0.03378951410178257
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases     DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9619075,R01DC014498,"['Algorithms ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Child ', ' Communication ', ' computer vision ', ' Computer Vision Systems ', ' computing method ', ' computer methods ', ' computer based method ', ' computational methods ', ' computational methodology ', ' Computing Methodologies ', ' deafness ', ' Emotions ', ' facial ', ' faces ', ' Face ', ' face expression ', ' Facial Expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' Hearing ', ' Modern Man ', ' Human ', ' Linguistic ', ' Linguistics ', ' Logic ', ' Manuals ', ' Methods ', ' body movement ', ' Movement ', ' Parents ', ' Production ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Science ', ' Semantics ', ' Sign Language ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Software ', ' Computer software ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specific qualifier value ', ' Specified ', ' Series ', ' Visual ', ' Individual ', ' Databases ', ' data base ', ' Data Bases ', ' Shapes ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Life ', ' Dimensions ', ' System ', ' showing emotion ', ' expression of emotion ', ' emotional expression ', ' interest ', ' instructor ', ' Visual system structure ', ' Visual System ', ' experience ', ' syntax ', ' syntactic ', ' Structure ', ' Agreement ', ' Devices ', ' Academic achievement ', ' Excision ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Code ', ' Coding System ', ' face perception ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Access to Information ', ' outreach to information ', ' body position ', ' preventing ', ' prevent ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' Image ', ' imaging ', ' reconstruction ', ' computerized tools ', ' computational tools ', ' design ', ' designing ', ' innovation ', ' innovative ', ' innovate ', ' Computational algorithm ', ' computer algorithm ', ' comparative ', ' public health relevance ', ' Teacher Professional Development ', ' teacher development ', ' instructor training ', ' faculty professional development ', ' faculty development ', ' Teacher Training ', ' Teacher Preparation ', ' Teacher Educator ', ' Teacher Education ', ' Faculty Training ', ' Faculty Education ', ' experimental study ', ' experimental research ', ' experiment ', ' Articulation ', ' American Sign Language ', ' machine learning algorithm ', ' deaf ', ' profound hearing loss ', ' deafened ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,318386,OH-03,0.07835202109578018
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speakers voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patients voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patients voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,9740858,R01DC016621,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Communication ', ' Data Collection ', ' depression ', ' Mental Depression ', ' Electromagnetic ', ' Electromagnetics ', ' Goals ', ' Gold ', ' Health ', ' Voice Hoarseness ', ' Hoarseness ', ' Modern Man ', ' Human ', ' language training ', ' Laryngectomy ', ' voice box ', ' Larynx Head and Neck ', ' Laryngeal ', ' Larynx ', ' Artificial Larynx ', ' Laryngeal Prosthesis ', ' Lip ', ' Lip structure ', ' Maps ', ' Motion ', ' body movement ', ' Movement ', ' Patients ', ' Production ', ' QOL ', ' Quality of life ', ' Research ', ' Remote Operation (Robotics) ', ' Robotics ', ' Science ', ' assistive device ', ' Assistive Technology ', ' Self-Help Devices ', ' sound ', ' Speech ', ' Speech Manifestations ', ' Speech Disorders ', ' Speech Sound ', ' voice synthesizer ', ' Speech Synthesizers ', ' Speech Therapy ', ' Alaryngeal Voice Production ', ' Alaryngeal Speech ', ' Esophageal Speechs ', ' Esophageal Speech ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' Vocal Fold ', ' vocal cord ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Gender ', ' Measures ', ' range of motion ', ' Joint Range of Motion ', ' Articular Range of Motion ', ' base ', ' improved ', ' Individual ', ' tool ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Knowledge ', ' Life ', ' Mechanics ', ' mechanical ', ' millisecond ', ' Msec ', ' Pattern ', ' vibration ', ' Magnetism ', ' magnetic ', ' auditory feedback ', ' Performance ', ' visual feedback ', ' kinematics ', ' kinematic model ', ' Speed ', ' novel ', ' Participant ', ' new technology ', ' novel technologies ', ' Devices ', ' social ', ' Excision ', ' resection ', ' Surgical Removal ', ' Removal ', ' Extirpation ', ' Abscission ', ' Positioning Attribute ', ' Position ', ' oral communication ', ' Enhancement Technology ', ' Data ', ' Electrolarynx ', ' Motor ', ' Laryngectomee ', ' Tracheoesophageal Speech ', ' Tracheo-Esophageal Speech ', ' Wireless Technology ', ' wireless ', ' Characteristics ', ' Tracer ', ' Development ', ' developmental ', ' Output ', ' design ', ' designing ', ' alternative communication ', ' Population ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' prototype ', ' social exclusion ', ' marginalization ', ' experimental study ', ' experimental research ', ' experiment ', ' Articulation ', ' wearable device ', ' wearable sensor ', ' body worn sensor ', ' body sensor ', ' preservation ', ' machine learning algorithm ', ' speech synthesis ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,618564,TX-10,0.30616519644360474
"Objectively Quantifying Speech Outcomes of Children with Cleft Palate Perceptual assessment of hypernasality is considered a critical component when evaluating the speech of children with cleft lip and/or palate (CLP). However, most speech-language pathologists (SLPs) do not receive formal training for perceptual evaluation of speech and, as a result, research shows that the subjective ratings are inherently biased to the perceiver and exhibit considerable variability. In this project, we aim to develop an artificial intelligence (AI) algorithm that automatically evaluates speech along four dimensions deemed to be critically important by the Americleft Speech Outcomes Group (ASOG), namely speech acceptability, articulation, hypernasality, and audible nasal emissions. The AI algorithm in this project is based on an existing database of speech collected as a part of an NIH-funded project to develop reliable speech outcomes by improving the reliability of perceptual ratings by training clinicians (NIDCR DE019-01235, PI: Kathy Chapman). This database contains speech samples from 125 5-7 year olds along with multiple perceptual rating for each speech sample. The clinicians participating in this study were successfully trained using a new protocol from the Americleft Speech Outcomes Group and they exhibit excellent inter-clinician reliability.  In SA1 we will develop an AI algorithm that automatically learns the relationship between a comprehensive set of speech acoustics and the average of the ASOG-trained expert ratings for each of the four perceptual dimensions. This approach is based on technology that the PIs have successfully used to evaluate dysarthric speech. Unique to these algorithms is modeling of perceptual judgments of trained experts using tools from statistical signal processing and AI. The output of the algorithms will map to a clinically- relevant scale, rather than to norm-referenced values that may or may not be meaningful. In SA2, we will evaluate the tool on new data by collecting new speech samples using a mobile app at a partner clinic using the same protocol as in the original study. Every collected sample will be further evaluated by ASOG trained clinicians. We will use this data to evaluate the accuracy of the AI model by comparing the model's predictions with the average of ASOG-trained experts. Preliminary results show promise that the proposed approach will yield a successful tool for accurately characterizing perceptual dimensions in the speech of children with CLP. These results indicate that a number of acoustic features that have been developed previously by the PIs accurately capture differences in hypernasality and articulation between the speech of three children with CLP (with varying severity). Furthermore, we show the success of our approach on a different, but related, task: objective evaluation of dysarthric speech. We show that an algorithm that automatically rates hypernasality performs on par with the judgment of human evaluators. The results of the proposed research will form the basis for a subsequent R01 proposal for the development and evaluation of a clinical tool to objectively quantify and track speech production in children with CLP. Project Narrative Perceptual assessment of the speech of children with cleft lip and/or palate is commonly used as a key clinical indicator upon which follow-on decisions are made about intervention. However, studies show that the inter- clinician reliability can be low. As an alternative, we propose a new objective outcome tool based on signal processing and artificial intelligence that automatically assesses speech acceptability, articulation, hypernasality, and audible nasal emissions directly from speech; the output of the tool is on a scale defined by the Americleft Speech Outcomes Group and can be used by clinicians to objectively measure progress.",Objectively Quantifying Speech Outcomes of Children with Cleft Palate,9765280,R21DE026252,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Artificial Intelligence ', ' Machine Intelligence ', ' Computer Reasoning ', ' Behavior Therapy ', ' behavioral intervention ', ' behavior intervention ', ' Conditioning Therapy ', ' Behavioral Treatment ', ' Behavioral Therapy ', ' Behavioral Modification ', ' Behavioral Conditioning Therapy ', ' Behavior Treatment ', ' Behavior Modification ', ' Behavior Conditioning Therapy ', ' youngster ', "" childrens' "", ' children ', ' Children (0-21) ', ' Child Youth ', ' 0-11 years old ', ' Child ', ' Cleft Palate ', ' Clinical Study ', ' Clinical Research ', ' Communities ', ' Ear ', ' Environment ', ' Exhibits ', ' Gold ', ' Modern Man ', ' Human ', ' Judgment ', ' Language ', ' Learning ', ' Maps ', ' Methods ', ' National Institutes of Health ', ' NIH ', ' United States National Institutes of Health ', ' Respiratory System, Nose, Nasal Passages ', ' Nasal Passages Nose ', ' Nasal ', ' Nose ', ' Perception ', ' Production ', ' Reference Ranges ', ' Reference Values ', ' Validity and Reliability ', ' Research ', ' biological signal transduction ', ' Signaling ', ' Signal Transduction Systems ', ' Intracellular Communication and Signaling ', ' Cell Signaling ', ' Cell Communication and Signaling ', ' Signal Transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Manifestations ', ' Speech Disorders ', ' Technology ', ' Time ', ' Utah ', ' Work ', ' Measures ', ' Outcomes Research ', ' cleft lip and palate ', ' cleft palate/lip ', ' cleft lip/palate ', ' base ', ' Clinical ', ' Series ', ' Ensure ', ' Evaluation ', ' Training ', ' Individual ', ' Databases ', ' data base ', ' Data Bases ', ' Funding ', ' Pathologist ', ' tool ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Clinic ', ' Protocols documentation ', ' Protocol ', ' Operative Surgical Procedures ', ' surgery ', ' Surgical Procedure ', ' Surgical Interventions ', ' Surgical ', ' Operative Procedures ', ' Visit ', ' American ', ' craniofacial ', ' craniofacies ', ' impression ', ' Performance ', ' success ', ' Proxy ', ' novel ', ' Reporting ', ' Positioning Attribute ', ' Position ', ' Cleft lip with or without cleft palate ', ' cleft of the lip and/or palate ', ' cl/p ', ' Modeling ', ' Sampling ', ' Intervention ', ' interventional strategy ', ' Intervention Strategies ', ' Data ', ' International ', ' National Institute of Dental and Craniofacial Research ', ' National Institute of Dental Research ', ' NIDR ', ' NIDCR ', ' Validation ', ' Development ', ' developmental ', ' Output ', ' predictive modeling ', ' prognostic model ', ' prediction model ', ' computer based prediction ', ' Outcome ', ' Population ', ' 7 year old ', ' seven years of age ', ' seven year old ', ' age 7 years ', ' 7 years of age ', ' clinically relevant ', ' clinical relevance ', ' Four-dimensional ', ' 4-dimensional ', ' mobile application ', ' mobile app ', ' signal processing ', ' improved outcome ', ' Articulation ', ' learning algorithm ', ' ']",NIDCR,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2019,225535,AZ-09,0.3263792297328562
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating devicea virtual vocal tractthat can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9719822,K24DC016312,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Lou Gehrig Disease ', "" Gehrig's Disease "", ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Malignant Tumor of the Larynx ', ' Malignant Laryngeal Tumor ', ' Malignant Laryngeal Neoplasm ', ' Larynx Cancer ', ' Laryngeal Cancer ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disorder ', ' Disease ', ' Dysarthosis ', ' Dysarthria ', ' Electromagnetic ', ' Electromagnetics ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip ', ' Lip structure ', ' Maps ', ' Motion ', ' body movement ', ' Movement ', ' insular sclerosis ', ' Disseminated Sclerosis ', ' Multiple Sclerosis ', ' Persons ', ' Primary Parkinsonism ', ' Parkinsons disease ', "" Parkinson's disease "", "" Parkinson's "", ' Parkinson ', ' Paralysis Agitans ', ' Parkinson Disease ', ' Patients ', ' Play ', ' QOL ', ' Quality of life ', ' Questionnaires ', ' Records ', ' Research ', ' Researchers ', ' Investigators ', ' Research Personnel ', ' Running ', ' Speech ', ' Speech Intelligibilities ', ' Speech Intelligibility ', ' Speech Sound ', ' cerebrovascular accident ', ' cerebral vascular accident ', ' brain attack ', ' Cerebrovascular Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebral Stroke ', ' Brain Vascular Accident ', ' Apoplexy ', ' Stroke ', ' Survey Instrument ', ' Surveys ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' Machine Learning ', ' support vector machine ', ' statistical learning ', ' kernel methods ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' 3-Dimensional ', ' 3D ', ' 3-D ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Traumatic Brain Injury ', ' traumatic brain damage ', ' Brain Trauma ', ' Cellular Phone ', ' smartphone ', ' smart phone ', ' iPhone ', ' Cellular Telephone ', ' Cell Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' Development ', ' developmental ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovation ', ' innovative ', ' innovate ', ' Impairment ', ' usability ', ' motor impairment ', ' movement limitation ', ' movement impairment ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' Tablet Computer ', ' tablet device ', ' experimental study ', ' experimental research ', ' experiment ', ' Articulation ', ' virtual vocal tract ', ' machine learning algorithm ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2019,189841,MA-07,0.22035089065134175
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility  the final arbiter of speech goodness  is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.  There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9850868,R01DC006859,"['Acoustics ', ' Acoustic ', ' Affect ', ' Attention ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Dysarthria ', ' Dysarthosis ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' Health Services Accessibility ', ' Access to Care ', ' access to health services ', ' access to services ', ' access to treatment ', ' accessibility to health services ', ' availability of services ', ' care access ', ' health service access ', ' health services availability ', ' service availability ', ' treatment access ', ' Judgment ', ' Language ', ' Learning ', ' Theoretical model ', ' Theoretic Models ', ' nervous system disorder ', ' Nervous System Diseases ', ' Neurologic Disorders ', ' Neurological Disorders ', ' neurological disease ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Periodicity ', ' Cyclicity ', ' Rhythmicity ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' Education for Intervention ', ' Instruction Intervention ', ' Training Intervention ', ' instructional intervention ', ' Educational Intervention ', ' Pathologist ', ' tool ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Injuries ', ' Nervous System damage ', ' Neurological Damage ', ' Neurological Injury ', ' Neurological trauma ', ' neurotrauma ', ' Nervous System Trauma ', ' Coding System ', ' Code ', ' Modeling ', ' Sampling ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' disparity in health ', ' health disparity ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' computer based prediction ', ' prediction model ', ' prognostic model ', ' predictive modeling ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' predictive outcomes ', ' predictors of outcomes ', ' outcome prediction ', ' recruit ', ' optimal therapies ', ' optimal treatments ', ' machine learned algorithm ', ' machine learning algorithm ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' speech in noise ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' Computer Models ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,307097,AZ-09,0.3565471150187476
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9831633,R01DC012048,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Environment ', ' Goals ', ' Hearing ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Laboratories ', ' Masks ', ' Methods ', ' Modernization ', ' Noise ', ' Recurrence ', ' Recurrent ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Voice ', ' Work ', ' segregation ', ' Racial Segregation ', ' base ', ' improved ', ' Surface ', ' Chronic ', ' Training ', ' Individual ', ' Investigation ', ' Frequencies ', ' Auditory ', ' Complex ', ' Source ', ' Techniques ', ' System ', ' American ', ' success ', ' Structure ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Address ', ' Symptoms ', ' Data ', ' digital ', ' designing ', ' design ', ' innovate ', ' innovative ', ' innovation ', ' Network-based ', ' real world application ', ' combat ', ' signal processing ', ' network architecture ', ' Formulation ', ' experiment ', ' experimental research ', ' experimental study ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' deep neural network ', ' deep learning ', ' microphone ', ' supervised machine learning ', ' supervised learning ', ' hearing prosthesis ', ' Auditory Prosthesis ', ' good hearing ', ' healthy hearing ', ' normal hearing ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' speech in noise ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2020,303452,OH-03,0.30848144351414103
"Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders Abstract: Early and accurate diagnosis of neurocognitive disorders (NCDs) is critical for planning, treatment, and research referral, but demands time and expertise often unavailable to primary care providers. Speech and language are often impaired early in the disease course of several NCDs. Previous research has demonstrated the diagnostic potential of computer speech analysis (CSA), with differences between healthy controls and disorders such as mild cognitive impairment (MCI) and Alzheimer's disease. However, there are several additional steps that must be taken to make CSA a diagnostically viable screening tool. This proposal includes a career development plan providing the applicant with training, mentorship, and experience in the following areas in order to bring CSA techniques into clinical practice: 1) computational linguistics and paralinguistics, 2) longitudinal markers of disease, and 3) design of novel technology for dissemination. As part of this training, academic and professional skills, including ethics in research, will also be expanded. Uniquely qualified mentorship and advisory teams have been selected to ensure the success of the proposed training and research. The proposed study is a prospective, longitudinal, observational, cohort investigation of two distinct research groups. The first group is a highly selected and well-characterized research cohort of healthy control, Alzheimer's disease, and MCI subjects (Group A). In Group A, the performance and reproducibility of a machine learning algorithm will be improved to distinguish Alzheimer's disease and MCI from healthy controls using CSA. Multiple regression and voxel-based morphometry will be used to better understand what may drive group differences in CSA measures in Group A as well. Clinical applications of this algorithm will then be assessed in a clinic-based cohort of patients with different NCDs (Group B) in order reduce spectrum bias likely present in prior studies. As sub-aims in both groups, possible further improvement of the algorithmic outcomes with longitudinal CSA measures will also be examined. The overall objective is to develop intuitive, reliable and reproducible CSA-based clinical measures by correlating them with established neuropsychiatric and imaging markers, determining their efficacy in clinical populations, and determining how they change over time. As a result, this research will validate specific speech traits as useful diagnostic markers of neurocognitive disease and explain why those markers differ between patient groups, both of which are major steps towards the design of novel and easily implemented tools in the screening of NCDs such as Alzheimer's disease. PROJECT NARRATIVE Computational speech analysis (CSA) has shown promise as a cost-effective, rapid screening for patients with neurocognitive disorders (NCDs) by objectively and automatically quantifying speech and language use; however, critical steps must be taken before these measures can become clinically useful. I have training and experience in the neurology of speech and language, but require additional training in computational linguistics and paralinguistics, longitudinal markers of disease including neuroimaging and neuropsychological measures, and design of novel technology for dissemination in order to bring CSA into clinical practice. In this project, we propose to investigate the utility of using CSA measures in two distinct patient groups, including a highly characterized group of research participants that includes healthy controls, Alzheimer's disease patients, and mild cognitive impairment patients (Group A), and a group of consented clinic patients with different NCDs (Group B) and to follow these two groups in prospective, longitudinal studies to correlate spontaneous speech measures with standardized linguistic, neuropsychological, and biological measures.",Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders,9975566,K23AG063900,"['Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Algorithms ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Classification ', ' Systematics ', ' Clinical Trials ', ' Communities ', ' Computers ', ' Cross-Sectional Studies ', ' Cross Sectional Analysis ', ' Cross-Sectional Analyses ', ' Cross-Sectional Survey ', ' Disease Frequency Surveys ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Ethics ', ' ethical ', ' Goals ', ' Language ', ' Language Tests ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Linguistics ', ' Linguistic ', ' Longitudinal Studies ', ' long-term study ', ' longitudinal outcome studies ', ' longterm study ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Memory ', ' Mentorship ', ' Neurology ', ' Neuropsychological Tests ', ' Neuropsychologic Tests ', ' Neuropsychology ', ' Neuropsychologies ', ' neuropsychologic ', ' Patients ', ' Primary Health Care ', ' Primary Care ', ' Primary Healthcare ', ' Quality of life ', ' QOL ', ' Research ', ' Speech ', ' Standardization ', ' Technology ', ' Testing ', ' Time ', ' Measures ', ' Caregivers ', ' Care Givers ', ' Task Forces ', ' advisory team ', ' Advisory Committees ', ' base ', ' improved ', ' morphometry ', ' Area ', ' Clinical ', ' Variation ', ' Variant ', ' Biological ', ' Ensure ', ' Evaluation ', ' screening tools ', ' Screening procedure ', ' Training ', ' Intuition ', ' Individual ', ' Fostering ', ' Development Plans ', ' fluid ', ' liquid ', ' Liquid substance ', ' tool ', ' Frontal Temporal Dementia ', ' front temporal dementia ', ' frontal lobe dementia ', ' fronto-temporal dementia ', ' fronto-temporal lobar dementia ', ' frontotemporal lobar dementia ', ' frontotemporal lobe degeneration associated with dementia ', ' Frontotemporal Dementia ', ' Cognitive Disturbance ', ' Cognitive Impairment ', ' Cognitive decline ', ' Cognitive function abnormal ', ' Disturbance in cognition ', ' cognitive dysfunction ', ' cognitive loss ', ' Impaired cognition ', ' Diagnostic ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Investigation ', ' Diagnostic Method ', ' Diagnostic Technique ', ' Diagnostic Procedure ', ' Clinic ', ' Techniques ', ' Amentia ', ' Dementia ', ' Neurocognitive ', ' early detection ', ' Early Diagnosis ', ' experience ', ' Performance ', ' success ', ' cohort ', ' tech development ', ' technology development ', ' trait ', ' skills ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' Participant ', ' novel technologies ', ' new technology ', ' Position ', ' Positioning Attribute ', ' career development ', ' neuropsychiatric ', ' neuropsychiatry ', ' Accent ', ' Effectiveness ', ' Address ', ' Consent ', ' Diagnostic Sensitivity ', ' Disease Marker ', ' Reproducibility ', ' Cognitive ', ' enroll ', ' Enrollment ', ' Preparation ', ' Characteristics ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' designing ', ' design ', ' Outcome ', ' cost effective ', ' Population ', ' Prevalence ', ' prospective ', ' Impairment ', ' clinical applicability ', ' clinical application ', ' new drug treatments ', ' new drugs ', ' new therapeutics ', ' new therapy ', ' next generation therapeutics ', ' novel drug treatments ', ' novel drugs ', ' novel therapy ', ' novel therapeutics ', ' new diagnostics ', ' next generation diagnostics ', ' novel diagnostics ', ' Alzheimer screening ', ' Alzheimer disease screening ', ' aged population ', ' population aging ', ' aging population ', ' healthy aging ', ' primary outcome ', ' clinical practice ', ' screening ', ' mild cognitive disorder ', ' mild cognitive impairment ', ' Dementia with Lewy Bodies ', ' LB dementia ', ' Lewy Body Type Senile Dementia ', ' Lewy dementia ', ' Lewy Body Dementia ', ' Computational Linguistics ', ' neurocognitive disorder ', ' accurate diagnosis ', ' AD pathology ', "" Alzheimer's pathology "", "" Alzheimer's disease pathology "", ' imaging marker ', ' imaging-based biological marker ', ' imaging-based biomarker ', ' imaging-based marker ', ' imaging biomarker ', ' diagnostic marker ', ' diagnostic biomarker ', ' recruit ', ' primary care provider ', ' care providers ', ' patient screening ', ' machine learned algorithm ', ' machine learning algorithm ', "" Alzheimer's diagnosis "", "" Alzheimer's disease diagnosis "", "" Alzheimer's patient "", "" Alzheimer's disease patient "", ' ']",NIA,UNIVERSITY OF COLORADO DENVER,K23,2020,188384,CO-06,0.13313048291445065
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,9901502,K01DC017751,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Behavior ', ' Biomechanics ', ' biomechanical ', ' Communication ', ' Statistical Data Interpretation ', ' Statistical Data Analyses ', ' Statistical Data Analysis ', ' statistical analysis ', ' Diagnosis ', ' Endoscopes ', ' Goals ', ' Gold ', ' Health ', ' Human ', ' Modern Man ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Methods ', ' Methodology ', ' Mining ', ' Statistical Models ', ' Probabilistic Models ', ' Probability Models ', ' statistical linear mixed models ', ' statistical linear models ', ' Patients ', ' Physics ', ' Production ', ' Research ', ' Speech ', ' Testing ', ' Time ', ' Tremor ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Measures ', ' Outcomes Research ', ' Dataset ', ' Data Set ', ' base ', ' image processing ', ' improved ', ' Area ', ' Clinical ', ' Physiologic ', ' Physiological ', ' Series ', ' Evaluation ', ' Visual ', ' Measurement ', ' Laryngeal dystonia ', ' spasmodic dysphonia ', ' Spastic Dysphonias ', ' Dysfunction ', ' Physiopathology ', ' pathophysiology ', ' Functional disorder ', ' Therapeutic ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Severities ', ' Auditory ', ' Protocol ', ' Protocols documentation ', ' Source ', ' Techniques ', ' System ', ' vibration ', ' vocalization ', ' Palsy ', ' Plegia ', ' paralysis ', ' paralytic ', ' Paralysed ', ' Operative Procedures ', ' Surgical ', ' Surgical Interventions ', ' Surgical Procedure ', ' surgery ', ' Operative Surgical Procedures ', ' cohort ', ' kinematic model ', ' kinematics ', ' Speed ', ' Categories ', ' Prevention ', ' Modeling ', ' Address ', ' Data ', ' Strategic Planning ', ' Characteristics ', ' sex ', ' developmental ', ' Development ', ' Voice Disturbances ', ' Phonation Disorders ', ' Dysphonia ', ' imaging ', ' Image ', ' NIDCD ', ' National Institute on Deafness and Other Communication Disorders ', ' time use ', ' Outcome ', ' Coupling ', ' innovate ', ' innovative ', ' innovation ', ' clinical relevance ', ' clinically relevant ', ' clinical applicability ', ' clinical application ', ' treatment strategy ', ' clinical practice ', ' flexible ', ' flexibility ', ' temporal resolution ', ' time measurement ', ' temporal measurement ', ' clinical development ', ' imaging based approach ', ' imaging approach ', ' ']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2020,137795,MI-08,0.2895177230947933
"Using Speech Acoustics to Reveal Motor Disruptions in Psychosis Project summary The goal of this project is to investigate the feasibility of using speech acoustics as a clinical biomarker in individuals at clinical high risk (CHR) for developing psychosis. There is evidence that disruptions to cortico-cerebellar circuits in individuals experiencing attenuated psychosis symptoms impact motor control of the face and limbs. This proposal would be the first study to examine whether these motor disruptions in high-risk populations also affect the complex motor control required for speech. In Aim 1 an instrumental approach will be used to investigate the acoustic correlates of psychosis risk. Specifically, speech data will be collected to investigate fine-grained acoustic properties of vowels and consonants in simple repetition tasks as well as during more naturalistic conversational speech. The speech of CHR young adults will be compared to age-matched healthy controls to discover if there are group differences in the speech acoustics that allow us to classify speech samples into healthy and clinical groups. To enable fast, reliable analysis, machine learning-based algorithms will be used to measure the acoustics speech properties of interest. In Aim 2, the speech properties measured in Aim 1 will be compared to other behavioral measures, in order to discover if they correlate with several measures of cerebellar dysfunction (posture control, procedural learning, and motor timing) that are known to occur in CHR individuals. These measures will provide convergent validity for these novel speech measures. Cognitive capabilities which are related and unrelated to speech and motor control will also be assessed, to provide specificity and divergent validity to these measures. In Aim 3, the links between speech features and changes in symptom severity will be assessed at two time points, connecting changes in speech motor control to longitudinal changes in the progression of the symptoms over 12 months. These investigations may reveal speech as a novel and easily-collected biomarker enabling early detection of psychosis risk. Project narrative The goal of this proposal is to determine whether speech patterns can signal vulnerability to psychotic disorders such as schizophrenia. Speech samples will be collected from high-risk and matched healthy control participants in order to: determine if there are abnormalities in the acoustics of vowels and consonants; evaluate if these properties map on to dysfunction of the cerebellum (a brain region impacted in the development of psychosis that also plays a role in speech motor control); and relate these properties to symptom severity and illness progression. This study will lay the groundwork for the use of speech as an inexpensive, non-invasive, and mechanistically-relevant metric that will ultimately support earlier identification and facilitate timely treatment.",Using Speech Acoustics to Reveal Motor Disruptions in Psychosis,9898478,R21MH119677,"['Acoustics ', ' Acoustic ', ' Affect ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Cerebellar Diseases ', ' Cerebellar Disorders ', ' Cerebellar Dysfunction ', ' Cerebellar Syndromes ', ' Cerebellum Diseases ', ' Cerebellum ', ' Computers ', ' Control Groups ', ' Diagnosis ', ' Dyskinetic syndrome ', ' Abnormal Movements ', ' Dyskinesias ', ' Equilibrium ', ' balance ', ' balance function ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Face ', ' faces ', ' facial ', ' Fingers ', ' Goals ', ' indexing ', ' Interview ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Learning ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Literature ', ' Maps ', ' Movement ', ' body movement ', ' National Institute of Mental Health ', ' NIMH ', ' Play ', ' Posture ', ' Production ', ' Psychotic Disorders ', ' Psychoses ', ' psychotic illness ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Risk ', ' Role ', ' social role ', ' Schizophrenia ', ' Schizophrenic Disorders ', ' dementia praecox ', ' schizophrenic ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Specificity ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Testing ', ' Time ', ' Tongue ', ' Measures ', ' Youth 10-21 ', ' Youth ', ' Roter ', ' base ', ' improved ', ' Clinical ', ' Variation ', ' Variant ', ' Neurological ', ' Neurologic ', ' Link ', ' Ensure ', ' motor disease ', ' motor dysfunction ', ' motor disorder ', ' Individual ', ' adult youth ', ' young adulthood ', ' young adult ', ' Measurement ', ' Early Intervention ', ' Dysfunction ', ' Physiopathology ', ' pathophysiology ', ' Functional disorder ', ' Attenuated ', ' tool ', ' machine learned ', ' Machine Learning ', ' Scientist ', ' Investigation ', ' Severities ', ' Complex ', ' Sensory ', ' Pattern ', ' System ', ' disease severity ', ' Severity of illness ', ' interest ', ' cued speech ', ' Cueing for speech ', ' early detection ', ' Early Diagnosis ', ' experience ', ' behavioral measure ', ' behavioral measurement ', ' behavior measurement ', ' neural ', ' relating to nervous system ', ' Structure ', ' sensory integration ', ' novel ', ' Participant ', ' Position ', ' Positioning Attribute ', ' motor deficit ', ' Early identification ', ' Sampling ', ' Property ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Pathogenicity ', ' Postural Balance ', ' Postural Equilibrium ', ' postural control ', ' Musculoskeletal Equilibrium ', ' Brain region ', ' Causality ', ' causation ', ' disease causation ', ' Etiology ', ' Address ', ' Symptoms ', ' Data ', ' Motor ', ' Cognitive ', ' Process ', ' developmental ', ' Development ', ' Behavioral ', ' Population ', ' vocal control ', ' locomotor learning ', ' motor learning ', ' motor control ', ' high risk ', ' new marker ', ' novel biomarker ', ' novel marker ', ' bio-markers ', ' biologic marker ', ' biomarker ', ' Biological Markers ', ' customized therapy ', ' customized treatment ', ' individualized patient treatment ', ' individualized therapy ', ' individualized treatment ', ' patient specific therapies ', ' patient specific treatment ', ' tailored medical treatment ', ' tailored therapy ', ' tailored treatment ', ' unique treatment ', ' individualized medicine ', ' clinical predictors ', ' potential biological marker ', ' potential biomarker ', ' clinically useful biomarkers ', ' clinical biomarkers ', ' high risk group ', ' high risk population ', ' Grain ', ' automatic algorithm ', ' automated algorithm ', ' motor behavior ', ' ']",NIMH,NORTHWESTERN UNIVERSITY,R21,2020,185000,IL-07,0.30906975167672157
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics ', ' Acoustic ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Affect ', ' Algorithms ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' hearing perception ', ' sound perception ', ' Auditory Perceptual Disorders ', ' Acoustic Perceptual Disorder ', ' Auditory Comprehension Disorder ', ' Auditory Perceptual Diseases ', ' Auditory Processing Disorder ', ' Psychoacoustical Disorders ', ' central processing disorder ', ' Behavior ', ' Cognition Disorders ', ' cognitive disease ', ' cognitive disorder ', ' cognitive syndrome ', ' Communication ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Electrophysiology (science) ', ' Electrophysiology ', ' Neurophysiology / Electrophysiology ', ' electrophysiological ', ' Elements ', ' Foundations ', ' Goals ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Heart ', ' Human ', ' Modern Man ', ' Infant ', ' Language ', ' Language Development ', ' acquiring language skills ', ' language acquisition ', ' language learning ', ' Learning ', ' Longevity ', ' Length of Life ', ' life span ', ' lifespan ', ' Biological Models ', ' Biologic Models ', ' Model System ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Perception ', ' Quality of life ', ' QOL ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Testing ', ' Time ', ' Work ', ' Generations ', ' Superior temporal gyrus ', ' Comprehension ', ' improved ', ' Physiologic ', ' Physiological ', ' Failure ', ' Stimulus ', ' Individual ', ' root ', ' Plant Roots ', ' Starlings ', ' Sturnidae ', ' Sturnus vulgaris ', ' machine learned ', ' Machine Learning ', ' Auditory ', ' Complex ', ' Parietal ', ' Stream ', ' Sensory ', ' Pattern ', ' Techniques ', ' specific language impairment ', ' Word Blindness ', ' Dyslexia ', ' Auditory system ', ' experience ', ' speech recognition ', ' success ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Oscines ', ' song bird ', ' Songbirds ', ' sensory system ', ' Categories ', ' Modality ', ' Learning disability ', ' Learning Disabilities ', ' Coding System ', ' Code ', ' neural circuitry ', ' neurocircuitry ', ' synaptic circuit ', ' synaptic circuitry ', ' neural circuit ', ' Modeling ', ' response ', ' model development ', ' pattern perception ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Autism ', ' Autistic Disorder ', ' Early Infantile Autism ', ' Infantile Autism ', "" Kanner's Syndrome "", ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Detection ', ' Cognitive ', ' Process ', ' groupings ', ' Grouping ', ' Behavioral ', ' computational framework ', ' computer framework ', ' Population ', ' neural mechanism ', ' neuromechanism ', ' birdsong ', ' bird song ', ' speech processing ', ' language processing ', ' spatiotemporal ', ' neurobiological mechanism ', ' learning behavior ', ' learned behavior ', ' comprehending language ', ' language comprehension ', ' signal processing ', ' cognitive process ', ' sensory input ', ' experiment ', ' experimental research ', ' experimental study ', ' auditory processing ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' Computer Models ', ' machine learning method ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,CA-52,0.0536514151285587
"A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia Abstract 1 in 3 seniors in the United States dies with dementia, of which Alzheimers disease (AD) is the most common form. AD patients suffer from decreased ability to meaningfully communicate and interact, which causes significant stress and burden for both professional caregivers and family members. Socially assistive robots (SARs) have been designed to promote therapeutic interaction and communication. Unfortunately, artificial intelligence (AI) has long been challenged by the speech of elderly persons, who exhibit age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers that can be exacerbated by the neurological changes associated with AD, further complicated by common environmental noises such as the ceiling fan, television, etc. Because of the resulting poor real-world speech and language understanding by available SAR technologies, scarce human caregivers are often required to guide AD patients through SAR interactions, limiting SARs to small deployments, mostly as part of research studies. Unlike existing approaches relying purely on AI, care.coach is developing a SAR-like avatar that converses with elderly and AD patients through truly natural speech. Each avatar is controlled by a 24x7 team of trained human staff who can cost-effectively monitor and engage 12 or more patients sequentially (2 simultaneously) through the audio/visual feeds from the patients avatar device. The staff communicate with each patient by sending text commands which are converted into the avatars voice through a speech synthesis engine. The staff contribute to the system their human abilities for speech and natural language processing (NLP) and for generating free-form conversational responses to help patients build personal relationships with the avatar. The staff are guided by a software-driven expert system embedded into their work interface, which is programmed with evidence-based prompting and protocols to support healthy behaviors and self-care. This SBIR Fast-Track project will leverage the unique data generated by our human- in-the-loop platform to develop new ASR capabilities, enabling fully automatic conversational protocols to engage and support AD patients without human intervention. We aim in Phase I to leverage our unique prior work dataset to train an automatic speech recognition (ASR) engine to enable the understanding of certain types of elderly and AD patient speech more successfully than any currently available engine. We aim in Phase II to incorporate this new engine along with an NLP module into our existing human-in-the-loop avatar system, recruiting a population of AD patients to further train and validate with during a 2-year human subjects study so that we can demonstrate full automation of a significant portion of our avatar conversations with mild- to-moderate level AD patients. Thus, we will improve the commercial scalability of our avatars, while validating our new ASR/NLP engine as the most accurate platform for enabling the next generation of AD-focused SARs. Narrative Artificial intelligence (AI) has long been challenged by the speech of elderly persons, and especially persons with dementia, due to age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers. Unlike existing approaches to socially assistive robots (SARs) relying purely on limited AI for conversation, care.coach has been commercializing a SAR-like avatar that converses with elderly and AD patients through truly natural speech, powered by a 24x7 team of trained human staff. The unique data sets that our solution enables us to gather at commercial scale will be leveraged in this SBIR project to develop an automatic speech recognition (ASR) and natural language processing (NLP) engine that is best-in-class for AD applications, improving the commercial scalability of our avatars by reducing our dependence on human staff, while serving as a new AI platform for enabling the next generation of AD- focused, conversational SARs.",A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia,10230460,R44AG062014,"['Age ', ' ages ', ' Elderly ', ' advanced age ', ' elders ', ' geriatric ', ' late life ', ' later life ', ' older adult ', ' older person ', ' senior citizen ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Automation ', ' Behavior ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Computers ', ' Delirium ', ' delirious ', ' Disease ', ' Disorder ', ' Exhibits ', ' Expert Systems ', ' Intelligent systems ', ' Family ', ' Goals ', ' Hospitals ', ' Community Hospitals ', ' Human ', ' Modern Man ', ' Hybrids ', ' Institutes ', ' Jamaica ', ' Language ', ' Loneliness ', ' lonely ', ' Manuals ', ' Persons ', ' Natural Language Processing ', ' natural language understanding ', ' Noise ', ' Patients ', ' Production ', ' Self Care ', ' personal care ', ' Semantics ', ' Social Interaction ', ' Social support ', ' social support network ', ' Computer software ', ' Software ', ' Speech ', ' Stress ', ' Technology ', ' Television ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Tremor ', ' United States ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' World Health Organization ', ' Generations ', ' Measures ', ' Price ', ' pricing ', ' Caregivers ', ' Care Givers ', ' falls ', ' Emotional Depression ', ' depression symptom ', ' depressive ', ' depressive symptoms ', ' Family member ', ' Dataset ', ' Data Set ', ' Caring ', ' human subject ', ' Label ', ' improved ', ' Phase ', ' Neurological ', ' Neurologic ', ' Training ', ' Visual ', ' Individual ', ' Licensing ', ' satisfaction ', ' Therapeutic ', ' Contracting Opportunities ', ' Contracts ', ' restraint ', ' Hour ', ' Frequencies ', ' Dependence ', ' Home ', ' Home environment ', ' Protocol ', ' Protocols documentation ', ' Reaction ', ' Techniques ', ' System ', ' Amentia ', ' Dementia ', ' Medical center ', ' speech recognition ', ' success ', ' phrases ', ' skills ', ' research study ', ' Study Subject ', ' Devices ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' response ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Feeds ', ' Data ', ' SBIR ', ' Small Business Innovation Research ', ' Small Business Innovation Research Grant ', ' Validation ', ' Monitor ', ' Text ', ' age dependent ', ' age related ', ' cost ', ' designing ', ' design ', ' next generation ', ' elderly patient ', ' older patient ', ' Population ', ' Network-based ', ' usability ', ' aged population ', ' population aging ', ' aging population ', ' evidence base ', ' human-in-the-loop ', ' recruit ', ' primary care provider ', ' care providers ', ' health plans ', ' health plan ', ' patient engagement ', ' patient specific response ', ' responsive patient ', ' patient response ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' deep neural network ', ' speech synthesis ', ' AD related dementia ', ' ADRD ', ' Alzheimer related dementia ', "" Alzheimer's disease related dementia "", ' automatic speech recognition ', ' automated speech recognition ', ' social robot ', ' social assistive robot ', "" Alzheimer's patient "", "" Alzheimer's disease patient "", ' ']",NIA,CARE.COACH CORPORATION,R44,2020,1502690,CA-14,0.04363185312010418
"Decoding inner speech: An AI approach to transcribing thoughts via EEG & EMG ABSTRACT  Losing the capacity to communicate through language has a significant negative impact on a persons autonomy, social interactions, occupation, mental health, and overall quality of life. Many people lose the capacity to speak and write but keep their thinking intact.  Inner speech is internally and willfully generated, non-articulated verbal thoughts (e.g., reading in silence). Changes in the activation patterns of the brains language-related areas co-occur with inner speech and can be detected with electroencephalography (EEG). Furthermore, while inner speech doesnt lead to any discernible voice sound or articulation, co-occurring low amplitude electrical discharges in the articulatory muscles can be detected with electromyography (EMG). The information about ongoing inner speech reflected in electrophysiological signals (EEG and EMG) can be used to transcribe inner speech into text or voice.  Machine learning algorithms have been used for this purpose, however, the resulting systems have low accuracy and/or are constrained by very small vocabularies (~10 words). Furthermore, these systems need to be trained anew for each user, which significantly increases individual data-collection time. The development of ready-to-use/minimal-training (fine tuning) systems requires large training datasets that algorithms can use to learn high-level features capable of being transferred between individuals. Unfortunately, to date there are no available datasets that are large enough to train these systems.  To tackle these issues, I have assembled a multidisciplinary team of collaborators from Google AI, Yale linguistics, and Yale Psychiatry to develop a state-of-the-art deep neural network to transcribe inner speech to text using EEG and EMG signals. This system will incorporate some of the latest advances in artificial intelligence and data processing developed by Google AI. It will be designed to transcribe phonemes, thus, in principle, will be able to transcribe any word. Furthermore, we will collect the largest (x120 times) multi-subject (n=150) electrophysiological (EEG+EMG) inner speech dataset to date (300 hrs. in total) to train the first ready- to-use/minimal-training inner speech transcriber system.  The technology resulting from this study has the potential to radically improve the quality of life of thousands of patients by providing them with a fast method of communicating their verbal thoughts. Furthermore, by combining this system with one of the many text-to-speech AIs that are currently available, our system could potentially restore the patients capacity to produce conversational speech. PROJECT NARRATIVE People that have lost their capacity for verbal communication struggle with isolation, mental illness, and poor quality of life. Artificial intelligence offers an opportunity to translate verbal thoughts into text or synthesized voice and restore verbal communication in impaired people. In this study, we introduce a state-of-the art artificial intelligence system designed to transduce the electrophysiological activity (electroencephalography [EEG] and electromyography [EMG]) accompanying verbal thoughts into text.",Decoding inner speech: An AI approach to transcribing thoughts via EEG & EMG,10058047,R21EB029607,"['Algorithms ', ' Architecture ', ' Engineering / Architecture ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Attention ', ' Mental disorders ', ' Mental health disorders ', ' Psychiatric Disease ', ' Psychiatric Disorder ', ' mental illness ', ' psychiatric illness ', ' psychological disorder ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Data Collection ', ' Electroencephalography ', ' EEG ', ' Electromyography ', ' Electrophysiology (science) ', ' Electrophysiology ', ' Neurophysiology / Electrophysiology ', ' electrophysiological ', ' Expert Systems ', ' Intelligent systems ', ' Hand ', ' Language ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Learning ', ' Linguistics ', ' Linguistic ', ' Maps ', ' Mental Health ', ' Mental Hygiene ', ' Psychological Health ', ' Methods ', ' Muscle ', ' Muscle Tissue ', ' muscular ', ' Persons ', ' Occupations ', ' Jobs ', ' Professional Positions ', ' Patients ', ' Psychiatry ', ' Quality of life ', ' QOL ', ' Reading ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Social Interaction ', ' sound ', ' Speech ', ' Technology ', ' Thinking ', ' thoughts ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Translating ', ' Vocabulary ', ' Vocabulary Words ', ' Voice ', ' Writing ', ' Gender ', ' Measures ', ' Dataset ', ' Data Set ', ' improved ', ' Area ', ' Clinical ', ' Training ', ' mental ', ' Psyche structure ', ' Stimulus ', ' Individual ', ' Fostering ', ' Letters ', ' machine learned ', ' Machine Learning ', ' Complex ', ' Pattern ', ' System ', ' Location ', ' American ', ' Performance ', ' Modeling ', ' performance tests ', ' data processing ', ' computerized data processing ', ' Data ', ' Sum ', ' Text ', ' developmental ', ' Development ', ' Output ', ' digital ', ' designing ', ' design ', ' blind ', ' innovate ', ' innovative ', ' innovation ', ' Impairment ', ' multidisciplinary ', ' accurate speech ', ' speech accuracy ', ' healthy volunteer ', ' ALS2 ', ' ALSJ ', ' Amyotrophic Lateral Sclerosis 2, Juvenile ', ' ALS2 gene ', ' Articulation ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' deep neural network ', ' deep learning ', ' machine learned algorithm ', ' machine learning algorithm ', ' large data sets ', ' large datasets ', ' algorithm training ', ' ']",NIBIB,YALE UNIVERSITY,R21,2020,523600,CT-03,0.20240671542720207
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through part-of-speech tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (which, what, that). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis  semantics and syntax  that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9859468,R01MH115332,"['Age ', ' ages ', ' Archives ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Felis catus ', ' Cats ', ' Cats Mammals ', ' Domestic Cats ', ' Feline Species ', ' Felis domestica ', ' Felis domesticus ', ' Felis sylvestris catus ', ' Classification ', ' Systematics ', ' Cognition ', ' Communication ', ' Computers ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Canis familiaris ', ' Canine Species ', ' Dogs ', ' Dogs Mammals ', ' canine ', ' domestic dog ', ' Electroencephalography ', ' EEG ', ' Human ', ' Modern Man ', ' indexing ', ' Interview ', ' Language ', ' Linguistics ', ' Linguistic ', ' Manuals ', ' Methods ', ' Morbidity - disease rate ', ' Morbidity ', ' National Institute of Mental Health ', ' NIMH ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Natural Language Processing ', ' natural language understanding ', ' Patients ', ' Poverty ', ' Production ', ' Psychotic Disorders ', ' Psychoses ', ' psychotic illness ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Resources ', ' Research Resources ', ' Risk ', ' Schizophrenia ', ' Schizophrenic Disorders ', ' dementia praecox ', ' schizophrenic ', ' Semantics ', ' Speech ', ' Thinking ', ' thoughts ', ' Work ', ' Yogurt ', ' Measures ', ' Dataset ', ' Data Set ', ' analytical method ', ' base ', ' Site ', ' Clinical ', ' Physiologic ', ' Physiological ', ' Series ', ' Individual ', ' Collaborations ', ' Metaphor ', ' Genetic ', ' Morphology ', ' Diagnostic ', ' Scientist ', ' Dimensions ', ' Techniques ', ' Affective Disorders ', ' Mood Disorders ', ' syntactic ', ' syntax ', ' cohort ', ' neural ', ' relating to nervous system ', ' phrases ', ' novel ', ' Program Announcement ', ' NIH Program Announcements ', ' Graph ', ' Categories ', ' response ', ' Functional impairment ', ' functional disability ', ' Mediator ', ' Mediator of Activation ', ' Mediator of activation protein ', ' Address ', ' Length ', ' Symptoms ', ' Data ', ' International ', ' Sum ', ' scientific accomplishments ', ' scientific advances ', ' Scientific Advances and Accomplishments ', ' Text ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' Output ', ' vector ', ' functional outcomes ', ' Outcome ', ' Mind ', ' healthy volunteer ', ' high risk ', ' natural language ', ' RDoC ', ' Research Domain Criteria ', ' neural correlate ', ' data library ', ' data archive ', ' secondary analysis ', ' Grain ', ' ']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,533776,NY-13,0.03378951410178257
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many evidence-based treatments for substance abuse are talk based therapies, such as motivational interviewing (MI), but the existing research-based methodology for evaluating counseling quality is to record sessions and use human rating teams to evaluate them. However, using humans as the assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling sessions, provide automatic and intuitive quality scores, and summarize these in actionable feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous NIH-funded research laid a computational foundation for generating MI quality metrics from speech and language features in MI sessions, and led to a prototype of a clinical software support tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical workflows, assessing usability, and initial validation of machine learning of MI fidelity measures in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase II will focus on robust validation of the speech and language technologies underlying the CORE-MI tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability, usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence of increased client retention. The successful execution of this project will break the reliance on human judgment for providing performance-based feedback to MI and will massively expand the capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling interventions, such as motivational interviewing. There are currently no methods for evaluating the quality of such counseling interventions in the real world to support training, supervision, and quality assurance. Building on an existing prototype, Lyssn.io  a technology start-up focused on scalable and cost-efficient human-centered technologies  will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9847959,R44DA046243,"['Adoption ', ' Algorithms ', ' Behavior Therapy ', ' Behavior Conditioning Therapy ', ' Behavior Modification ', ' Behavior Treatment ', ' Behavioral Conditioning Therapy ', ' Behavioral Modification ', ' Behavioral Therapy ', ' Behavioral Treatment ', ' Conditioning Therapy ', ' behavior intervention ', ' behavioral intervention ', ' Client ', ' Communities ', ' E-learning ', ' computer-assisted instruction ', ' computer-based education ', ' computer-based instruction ', ' computer-based learning ', ' computer-based training ', ' digital education ', ' digital learning ', ' eLearning ', ' electronic learning ', ' internet-assisted education ', ' internet-based training ', ' multimedia learning ', ' on-line education ', ' on-line learning ', ' online education ', ' online learning ', ' technology-enhanced learning ', ' virtual learning ', ' web-based instruction ', ' web-based training ', ' Counseling ', ' Professional counselor ', ' Counselor ', ' Pharmaceutical Preparations ', ' Drugs ', ' Medication ', ' Pharmaceutic Preparations ', ' drug/agent ', ' Environment ', ' Feasibility Studies ', ' Feedback ', ' Foundations ', ' Goals ', ' Human ', ' Modern Man ', ' Judgment ', ' Language ', ' Learning ', ' Methods ', ' Methodology ', ' Mission ', ' Persons ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Online Systems ', ' On-Line Systems ', ' online computer ', ' web based ', ' opioid abuse ', ' opiate abuse ', ' opiate drug abuse ', ' opioid drug abuse ', ' Psychology ', ' Psychotherapy ', ' Research ', ' research and development ', ' Development and Research ', ' R & D ', ' R&D ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Resources ', ' Research Resources ', ' Computer software ', ' Software ', ' Software Engineering ', ' Computer Software Development ', ' Computer Software Engineering ', ' Software Tools ', ' Computer Software Tools ', ' sound ', ' Speech ', ' Substance Use Disorder ', ' Suicide ', ' fatal attempt ', ' fatal suicide ', ' intent to die ', ' suicidality ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Training Support ', ' Universities ', ' Utah ', ' Work ', ' Measures ', ' Administrator ', ' base ', ' quality assurance ', ' improved ', ' Site ', ' Clinical ', ' Phase ', ' Evaluation ', ' Training ', ' Intuition ', ' AOD use ', ' substance use ', ' substance using ', ' using substances ', ' Alcohol or Other Drugs use ', ' Opiates ', ' Opioid ', ' Measurement ', ' Funding ', ' tool ', ' machine learned ', ' Machine Learning ', ' Dependence ', ' Stream ', ' Clinic ', ' Protocol ', ' Protocols documentation ', ' Pattern ', ' System ', ' Best Practice Analysis ', ' Benchmarking ', ' Needs Assessment ', ' American ', ' experience ', ' Performance ', ' visual feedback ', ' HIPAA ', ' Kennedy Kassebaum Act ', ' PL 104-191 ', ' PL104-191 ', ' Public Law 104-191 ', ' United States Health Insurance Portability and Accountability Act ', ' Health Insurance Portability and Accountability Act ', ' skills ', ' novel ', ' motivational interview ', ' motivational enhancement therapy ', ' technological innovation ', ' Reporting ', ' abuse of substances ', ' substance abuse ', ' Substance abuse problem ', ' Health Care Technology ', ' Healthcare Technology ', ' Health Technology ', ' Coding System ', ' Code ', ' protocol development ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Enhancement Technology ', ' Provider ', ' car accident ', ' automobile accident ', ' Adherence ', ' NIDA ', ' National Institute on Drug Abuse ', ' National Institute of Drug Abuse ', ' SBIR ', ' Small Business Innovation Research ', ' Small Business Innovation Research Grant ', ' Update ', ' Validation ', ' Process ', ' developmental ', ' Development ', ' Behavioral ', ' Evidence based treatment ', ' substance abuse therapy ', ' substance abuse treatment ', ' cost ', ' implementation research ', ' virtual ', ' designing ', ' design ', ' Outcome ', ' cost efficient ', ' Consumption ', ' innovate ', ' innovative ', ' innovation ', ' speech processing ', ' encryption ', ' user centered design ', ' usability ', ' addictive disorder ', ' addiction ', ' tool development ', ' prototype ', ' community setting ', ' evidence base ', ' clinical practice ', ' overdose death ', ' signal processing ', ' cloud based ', ' Assessment instrument ', ' Assessment tool ', ' support tools ', ' predictive algorithm ', ' predictor algorithm ', ' prediction algorithm ', ' dashboard ', ' treatment services ', ' opioid treatment program ', ' gun homicide ', ' automatic speech recognition ', ' automated speech recognition ', ' ']",NIDA,"LYSSN.IO, INC.",R44,2020,394059,WA-07,0.1036355459562089
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many  evidence-based treatments for substance abuse are talk based therapies, such as motivational  interviewing (MI), but the existing research-based methodology for evaluating counseling quality is  to record sessions and use human rating teams to evaluate them. However, using humans as the  assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is  virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling  sessions, provide automatic and intuitive quality scores, and summarize these in actionable  feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and  quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support  evidence-based counseling.  Our goal is to develop innovative health technology solutions that are  objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing,  machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling.  Previous NIH-funded research laid a computational foundation for generating MI quality metrics from  speech and language features in MI sessions, and led to a prototype of a clinical software support  tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical  workflows, assessing usability, and initial validation of machine learning of MI fidelity measures  in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase  II will focus on robust validation of the speech and language technologies underlying the CORE-MI  tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback  for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported  supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability,  usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence  of increased client retention.  The successful execution of this project will break the reliance on  human judgment for providing performance-based feedback to MI and will massively expand the  capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling  interventions, such as motivational interviewing. There are currently no methods for evaluating the  quality of such counseling interventions in the real world to support training, supervision, and  quality assurance. Building on an existing prototype, Lyssn.io  a technology start-up focused on  scalable and cost-efficient human-centered technologies  will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community  based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9930480,R44DA046243,"['Adoption ', ' Client ', ' Communities ', ' Counseling ', ' Professional counselor ', ' Counselor ', ' Feedback ', ' Foundations ', ' Goals ', ' Health Personnel ', ' Health Care Providers ', ' Healthcare Providers ', ' Healthcare worker ', ' health care personnel ', ' health care worker ', ' health provider ', ' health workforce ', ' healthcare personnel ', ' medical personnel ', ' treatment provider ', ' Human ', ' Modern Man ', ' Interview ', ' Judgment ', ' Language ', ' Methods ', ' Methodology ', ' Persons ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Patients ', ' Primary Health Care ', ' Primary Care ', ' Primary Healthcare ', ' Psychotherapy ', ' Research ', ' Computer software ', ' Software ', ' Software Engineering ', ' Computer Software Development ', ' Computer Software Engineering ', ' Software Tools ', ' Computer Software Tools ', ' sound ', ' Speech ', ' Supervision ', ' Technology ', ' Time ', ' Training Support ', ' Measures ', ' Administrator ', ' base ', ' quality assurance ', ' improved ', ' Clinical ', ' Phase ', ' Evaluation ', ' Training ', ' Intuition ', ' AOD use ', ' substance use ', ' substance using ', ' using substances ', ' Alcohol or Other Drugs use ', ' Opiates ', ' Opioid ', ' Measurement ', ' Funding ', ' machine learned ', ' Machine Learning ', ' Clinic ', ' Protocol ', ' Protocols documentation ', ' Pattern ', ' American ', ' Performance ', ' HIPAA ', ' Kennedy Kassebaum Act ', ' PL 104-191 ', ' PL104-191 ', ' Public Law 104-191 ', ' United States Health Insurance Portability and Accountability Act ', ' Health Insurance Portability and Accountability Act ', ' motivational interview ', ' motivational enhancement therapy ', ' abuse of substances ', ' substance abuse ', ' Substance abuse problem ', ' Health Care Technology ', ' Healthcare Technology ', ' Health Technology ', ' Coding System ', ' Code ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Provider ', ' SBIR ', ' Small Business Innovation Research ', ' Small Business Innovation Research Grant ', ' Transcript ', ' Validation ', ' technology implementation ', ' technology validation ', ' developmental ', ' Development ', ' Behavioral ', ' Evidence based treatment ', ' substance abuse therapy ', ' substance abuse treatment ', ' cost ', ' virtual ', ' designing ', ' design ', ' cost efficient ', ' innovate ', ' innovative ', ' innovation ', ' user centered design ', ' usability ', ' tool development ', ' prototype ', ' commercialization ', ' evidence base ', ' primary care setting ', ' signal processing ', ' cloud based ', ' Assessment instrument ', ' Assessment tool ', ' support tools ', ' treatment services ', ' opioid treatment program ', ' automatic speech recognition ', ' automated speech recognition ', ' ']",NIDA,"LYSSN.IO, INC.",R44,2020,134649,WA-07,0.1036355459562089
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speakers voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patients voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patients voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,9994877,R01DC016621,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Communication ', ' Data Collection ', ' Mental Depression ', ' depression ', ' Electromagnetics ', ' Goals ', ' Gold ', ' Health ', ' Hoarseness ', ' Voice Hoarseness ', ' Human ', ' Modern Man ', ' language training ', ' Laryngectomy ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Laryngeal Prosthesis ', ' Artificial Larynx ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Robotics ', ' Science ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Speech Synthesizers ', ' voice synthesizer ', ' Speech Therapy ', ' Alaryngeal Speech ', ' Alaryngeal Voice Production ', ' Esophageal Speech ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Gender ', ' Measures ', ' Articular Range of Motion ', ' Joint Range of Motion ', ' range of motion ', ' base ', ' improved ', ' Individual ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Life ', ' mechanical ', ' Mechanics ', ' Msec ', ' millisecond ', ' Pattern ', ' vibration ', ' magnetic ', ' Magnetism ', ' auditory feedback ', ' Performance ', ' visual feedback ', ' kinematic model ', ' kinematics ', ' Speed ', ' novel ', ' Participant ', ' novel technologies ', ' new technology ', ' Devices ', ' social ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Position ', ' Positioning Attribute ', ' oral communication ', ' Enhancement Technology ', ' Data ', ' Electrolarynx ', ' Motor ', ' Laryngectomee ', ' Tracheo-Esophageal Speech ', ' Tracheoesophageal Speech ', ' wireless ', ' Wireless Technology ', ' Characteristics ', ' Tracer ', ' developmental ', ' Development ', ' Output ', ' designing ', ' design ', ' alternative communication ', ' Population ', ' innovate ', ' innovative ', ' innovation ', ' Impairment ', ' prototype ', ' marginalization ', ' social exclusion ', ' experiment ', ' experimental research ', ' experimental study ', ' Articulation ', ' wearable electronics ', ' wearable technology ', ' wearable device ', ' preservation ', ' machine learned algorithm ', ' machine learning algorithm ', ' speech synthesis ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2020,580870,TX-10,0.30616519644360474
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. ",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,9981725,R01DC018446,"['Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Animals ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Behavior ', ' Birds ', ' Aves ', ' Avian ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cell Nucleus ', ' Nucleus ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Communities ', ' Complement ', ' Complement Proteins ', ' Computers ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Feedback ', ' Future ', ' Goals ', ' Recording of previous events ', ' History ', ' Human ', ' Modern Man ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Maps ', ' Methods ', ' Motor Cortex ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' Patients ', ' Play ', ' Production ', ' Quadriplegia ', ' Quadriplegic ', ' Tetraplegia ', ' tetraplegic ', ' Research ', ' Role ', ' social role ', ' Running ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Generations ', ' Outcome Measure ', ' Dataset ', ' Data Set ', ' Comprehension ', ' Prosthetic device ', ' Prosthetics ', ' Prosthesis ', ' injuries ', ' Injury ', ' base ', ' human subject ', ' Computer Interface ', ' improved ', ' Area ', ' Evaluation ', ' Individual ', ' non-human primate ', ' nonhuman primate ', ' Workshop ', ' Educational workshop ', ' Space Models ', ' Finches ', ' Robot ', ' Artificial Extremities ', ' Artificial Limbs ', ' prosthetic limb ', ' Limb Prosthesis ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' meetings ', ' auditory feedback ', ' brain control ', ' mind control ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' high school ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Neural Development ', ' neurodevelopment ', ' Oscines ', ' song bird ', ' Songbirds ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' Basic Research ', ' Basic Science ', ' graduate student ', ' Prevention ', ' Modeling ', ' response ', ' Speech Development ', ' depository ', ' repository ', ' model development ', ' Limes ', ' Membrum superius ', ' Upper Limb ', ' Upper Extremity ', ' vocal learning ', ' Data ', ' Educational Materials ', ' Motor ', ' Principal Investigator ', ' Characteristics ', ' developmental ', ' Development ', ' Behavioral ', ' Output ', ' website ', ' web site ', ' Instruction ', ' designing ', ' design ', ' Clinical assessments ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' Implant ', ' birdsong ', ' bird song ', ' open source ', ' restore function ', ' restore functionality ', ' restore lost function ', ' functional restoration ', ' motor control ', ' data sharing ', ' operation ', ' undergraduate ', ' undergraduate student ', ' signal processing ', ' Education Module ', ' Educational Module ', ' Teaching Module ', ' Learning Module ', ' Secondary School Student ', ' Secondary Student ', ' High School Student ', ' course curriculum ', ' Course Content ', ' High School Outreach ', ' Data Science ', ' hack day ', ' hackfest ', ' hackathon ', ' Infrastructure ', ' machine learned algorithm ', ' machine learning algorithm ', ' functional electrostimulation ', ' functional electrical stimulation ', ' large data sets ', ' large datasets ', ' effectiveness testing ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,344725,CA-52,0.19786225826742085
"Dynamics of Vocal Tract Shaping     DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9829092,R01DC007124,"['Acoustics ', ' Acoustic ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Air Movements ', ' air flow ', ' airflow ', ' Apraxias ', ' Dyspraxia ', ' apraxia ', ' Articulators ', ' Beds ', ' Communication ', ' Communities ', ' Deglutition Disorders ', ' Dysphagia ', ' Swallowing Disorders ', ' Engineering ', ' Epiglottis structure ', ' Epiglottis ', ' Gestures ', ' Glossectomy ', ' Goals ', ' Human ', ' Modern Man ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Linguistics ', ' Linguistic ', ' Lip structure ', ' Lip ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Motion ', ' Movement ', ' body movement ', ' Noise ', ' Pharyngeal structure ', ' Pharynx ', ' Throat ', ' Play ', ' Posture ', ' Production ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Sleep Apnea Syndromes ', ' Sleep Apnea ', ' Sleep Hypopnea ', ' Sleep-Disordered Breathing ', ' sleep-related breathing disorder ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Surgical Flaps ', ' Flaps ', ' Island Flaps ', ' Educational process of instructing ', ' Teaching ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Traction ', ' Work ', ' Measures ', ' base ', ' image processing ', ' improved ', ' Lateral ', ' Clinical ', ' Variation ', ' Variant ', ' Series ', ' Training ', ' tongue tip ', ' tongue apex ', ' Individual ', ' Recovery ', ' Shapes ', ' tool ', ' German ', ' German population ', ' instrument ', ' Nature ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Investigation ', ' Complex ', ' Event ', ' Oral ', ' In Situ ', ' Pattern ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' Oropharynx ', ' Oropharynxs ', ' oral pharyngeal ', ' Oropharyngeal ', ' Operative Procedures ', ' Surgical ', ' Surgical Interventions ', ' Surgical Procedure ', ' surgery ', ' Operative Surgical Procedures ', ' phonology ', ' cohesion ', ' Speed ', ' Structure ', ' novel ', ' movie ', ' outreach ', ' technological innovation ', ' Modeling ', ' Property ', ' theories ', ' bio-imaging ', ' biomedical imaging ', ' bioimaging ', ' 3-D Imaging ', ' 3D imaging ', ' Three-Dimensional Imaging ', ' Data ', ' International ', ' Resolution ', ' Cognitive ', ' Cardiac ', ' developmental ', ' Development ', ' imaging ', ' Image ', ' website ', ' web site ', ' after stroke ', ' poststroke ', ' post stroke ', ' reconstruction ', ' shape description ', ' shape analysis ', ' computational tools ', ' computerized tools ', ' remediation ', ' Imaging technology ', ' Population ', ' Coupled ', ' innovate ', ' innovative ', ' innovation ', ' Impairment ', ' spatiotemporal ', ' public health relevance ', ' constriction ', ' dexterity ', ' project dissemination ', ' program dissemination ', ' Articulation ', ' high dimensionality ', ' imaging capabilities ', ' speech synthesis ', ' automatic speech recognition ', ' automated speech recognition ', ' realtime image ', ' real-time images ', ' data tools ', ' ']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,467515,CA-37,0.32452589820963934
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating devicea virtual vocal tractthat can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9964782,K24DC016312,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disease ', ' Disorder ', ' Dysarthria ', ' Dysarthosis ', ' Electromagnetics ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' Disseminated Sclerosis ', ' insular sclerosis ', ' Persons ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Play ', ' Quality of life ', ' QOL ', ' Questionnaires ', ' Records ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Running ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Stroke ', ' Apoplexy ', ' Brain Vascular Accident ', ' Cerebral Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebrovascular Stroke ', ' brain attack ', ' cerebral vascular accident ', ' cerebrovascular accident ', ' Surveys ', ' Survey Instrument ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' machine learned ', ' Machine Learning ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Brain Trauma ', ' traumatic brain damage ', ' Traumatic Brain Injury ', ' Cell Phone ', ' Cellular Telephone ', ' iPhone ', ' smart phone ', ' smartphone ', ' Cellular Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' developmental ', ' Development ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovate ', ' innovative ', ' innovation ', ' Impairment ', ' usability ', ' movement impairment ', ' movement limitation ', ' motor impairment ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' tablet device ', ' Tablet Computer ', ' experiment ', ' experimental research ', ' experimental study ', ' Articulation ', ' speech-generating device ', ' virtual vocal tract ', ' machine learned algorithm ', ' machine learning algorithm ', ' effectiveness testing ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2020,189841,MA-07,0.22035089065134175
