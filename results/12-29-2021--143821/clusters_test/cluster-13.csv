text,title,id,project_number,terms,administration,organization,mechanism,year,award_amount,cong_dist
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,10160864,R01DC018055,"['Acoustics ', ' Acoustic ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Affect ', ' Algorithms ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' hearing perception ', ' sound perception ', ' Auditory Perceptual Disorders ', ' Acoustic Perceptual Disorder ', ' Auditory Comprehension Disorder ', ' Auditory Perceptual Diseases ', ' Auditory Processing Disorder ', ' Psychoacoustical Disorders ', ' central processing disorder ', ' Behavior ', ' Cognition Disorders ', ' cognitive disease ', ' cognitive disorder ', ' cognitive syndrome ', ' Communication ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Electrophysiology (science) ', ' Electrophysiology ', ' Neurophysiology / Electrophysiology ', ' electrophysiological ', ' Elements ', ' Foundations ', ' Goals ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Heart ', ' Human ', ' Modern Man ', ' Infant ', ' Language ', ' Language Development ', ' acquiring language skills ', ' language acquisition ', ' language learning ', ' Learning ', ' Longevity ', ' Length of Life ', ' life span ', ' lifespan ', ' Biological Models ', ' Biologic Models ', ' Model System ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Perception ', ' Quality of life ', ' QOL ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Testing ', ' Time ', ' Work ', ' Generations ', ' Superior temporal gyrus ', ' Comprehension ', ' improved ', ' Physiological ', ' Physiologic ', ' Failure ', ' Stimulus ', ' Individual ', ' Plant Roots ', ' root ', ' Starlings ', ' Sturnidae ', ' Sturnus vulgaris ', ' machine learned ', ' Machine Learning ', ' Auditory ', ' Complex ', ' Parietal ', ' Stream ', ' Sensory ', ' Pattern ', ' Techniques ', ' specific language impairment ', ' Word Blindness ', ' Dyslexia ', ' Auditory system ', ' experience ', ' speech recognition ', ' success ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Oscines ', ' song bird ', ' Songbirds ', ' sensory system ', ' Categories ', ' Modality ', ' Learning disability ', ' Learning Disabilities ', ' Coding System ', ' Code ', ' neural circuitry ', ' neurocircuitry ', ' synaptic circuit ', ' synaptic circuitry ', ' neural circuit ', ' Modeling ', ' response ', ' model development ', ' pattern perception ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Autism ', ' Autistic Disorder ', ' Early Infantile Autism ', ' Infantile Autism ', "" Kanner's Syndrome "", ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Detection ', ' Cognitive ', ' Process ', ' Grouping ', ' groupings ', ' Behavioral ', ' computer framework ', ' computational framework ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' bird song ', ' birdsong ', ' speech processing ', ' language processing ', ' spatiotemporal ', ' neurobiological mechanism ', ' learned behavior ', ' learning behavior ', ' language comprehension ', ' comprehending language ', ' signal processing ', ' cognitive process ', ' sensory input ', ' experimental study ', ' experiment ', ' experimental research ', ' auditory processing ', ' Computer Models ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' machine learning method ', ' machine learning methodologies ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,335661,CA-52
"Single-neuron population dynamics in human speech motor cortex for a speech prosthesis PROJECT SUMMARY Augmentative and alternative communication (AAC) technology for people with severe speech and motor impairment (SSMI) continues to improve, with recent advances being made in the neural control of communication devices. In prior NIDCD-supported research, our research team developed a high-performance intracortical brain-computer interface (iBCI) that decodes arm movement intentions directly from brain activity. This technology has allowed people with SSMI to control a computer cursor with sufficient speed and accuracy to type at up to 8 words/min and has enabled full control of unmodified consumer devices using only decoded motor cortical activity. In the proposed U01 clinical research, performed as part of the multi-site BrainGate consortium, we will build upon decades of experience in studying the motor system in humans and non-human primates, with the end goal of advancing iBCI technology. The goals of this project are to study how speech is prepared and produced at the level of ensembles of single neurons in speech-related motor areas of the brain in people with amyotrophic lateral sclerosis (ALS), and to create a speech prosthesis that will allow communication at rates approaching conversational speech (120-150 words per minute). We will approach these investigations with a suite of advanced methods, including (1) newly-developed dynamical systems computational approaches that have provided fundamental insights into the function of the motor system, and (2) machine learning algorithms for decoding of movement intention and language modeling that have formed the basis of the fastest communication prosthesis yet reported. Finally, we will continue to evaluate the safety profile of Utah-array based iBCIs through the ongoing BrainGate2 pilot clinical trial. Upon completion, this project will advance both the capabilities of iBCIs for communication and our understanding of the detailed neural mechanisms of speech production. PROJECT NARRATIVE People with brainstem stroke, advanced amyotrophic lateral sclerosis (ALS, also known as Lou Gehrig’s disease), or other disorders can become unable to speak despite being awake and alert. In this project, we seek a fundamental understanding of how the brain produces speech, and to develop an intracortical brain-computer interface (iBCI) to restore communication at conversational speeds by people with paralysis.",Single-neuron population dynamics in human speech motor cortex for a speech prosthesis,10200463,U01DC019430,"['Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', "" Broca's area "", ' Clinical Research ', ' Clinical Study ', ' Clinical Trials ', ' Communication ', ' Computers ', ' Disease ', ' Disorder ', ' Electrodes ', ' Face ', ' faces ', ' facial ', ' Goals ', ' Hand ', ' Handwriting ', ' Human ', ' Modern Man ', ' Language ', ' Locked-In Syndrome ', ' Methods ', ' Microelectrodes ', ' Miniaturized Electrodes ', ' Modernization ', ' Motor Cortex ', ' Movement ', ' body movement ', ' Muscle ', ' Muscle Tissue ', ' muscular ', ' nervous system disorder ', ' Nervous System Diseases ', ' Neurologic Disorders ', ' Neurological Disorders ', ' neurological disease ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Population Dynamics ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Research Support ', ' Safety ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' Utah ', ' Voice ', ' Inferior frontal gyrus ', ' Inferior Frontal Convolution ', ' Precentral gyrus ', ' Custom ', ' Intention ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' base ', ' improved ', ' Dorsal ', ' Site ', ' Area ', ' Chronic ', ' Training ', ' insight ', ' awake ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' machine learned ', ' Machine Learning ', ' Functional MRI ', ' fMRI ', ' Functional Magnetic Resonance Imaging ', ' Investigation ', ' electrocorticography ', ' Electrocorticogram ', ' Dimensions ', ' Techniques ', ' System ', ' Brainstem Infarctions ', ' Brainstem Stroke ', ' Brain Stem Infarctions ', ' Palsy ', ' Plegia ', ' paralysis ', ' paralytic ', ' Paralysed ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' experience ', ' Performance ', ' neural control ', ' neural regulation ', ' neuromodulation ', ' neuromodulatory ', ' neuroregulation ', ' neural ', ' relating to nervous system ', ' kinematic model ', ' kinematics ', ' Speed ', ' Participant ', ' Devices ', ' Reporting ', ' Modeling ', ' Address ', ' AAC Device ', ' AAC Intervention ', ' Augmentative and Alternative Communication ', ' Data ', ' Motor ', ' Preparation ', ' Text ', ' Output ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' orofacial ', ' design ', ' designing ', ' brain computer interface ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' Impairment ', ' Implant ', ' speech accuracy ', ' accurate speech ', ' motor impairment ', ' movement impairment ', ' movement limitation ', ' arm ', ' neural correlate ', ' arm movement ', ' dynamic system ', ' dynamical system ', ' communication device ', ' recurrent neural network ', ' deep learning ', ' machine learning algorithm ', ' machine learned algorithm ', ' automated speech recognition ', ' automatic speech recognition ', ' safety assessment ', ' ']",NIDCD,STANFORD UNIVERSITY,U01,2021,1050840,CA-18
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['Algorithms ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Communication ', ' Computer Vision Systems ', ' computer vision ', ' Computing Methodologies ', ' computational methodology ', ' computational methods ', ' computer based method ', ' computer methods ', ' computing method ', ' deafness ', ' Emotions ', ' Face ', ' faces ', ' facial ', ' Facial Expression ', ' face expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' Hearing ', ' Human ', ' Modern Man ', ' Linguistics ', ' Linguistic ', ' Logic ', ' Manuals ', ' Methods ', ' Movement ', ' body movement ', ' Parents ', ' Production ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Science ', ' Semantics ', ' Sign Language ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specific qualifier value ', ' Specified ', ' Series ', ' Visual ', ' Individual ', ' Databases ', ' Data Bases ', ' data base ', ' Shapes ', ' tool ', ' machine learned ', ' Machine Learning ', ' Life ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' emotional expression ', ' expression of emotion ', ' showing emotion ', ' interest ', ' instructor ', ' Visual System ', ' Visual system structure ', ' experience ', ' syntactic ', ' syntax ', ' Structure ', ' Agreement ', ' Devices ', ' Academic achievement ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Coding System ', ' Code ', ' face perception ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' outreach to information ', ' Access to Information ', ' body position ', ' preventing ', ' prevent ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' Image ', ' imaging ', ' reconstruction ', ' computerized tools ', ' computational tools ', ' design ', ' designing ', ' innovation ', ' innovate ', ' innovative ', ' Computational algorithm ', ' computer algorithm ', ' comparative ', ' public health relevance ', ' Teacher Professional Development ', ' Faculty Education ', ' Faculty Training ', ' Teacher Education ', ' Teacher Educator ', ' Teacher Preparation ', ' Teacher Training ', ' faculty development ', ' faculty professional development ', ' instructor training ', ' teacher development ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' American Sign Language ', ' machine learning algorithm ', ' machine learned algorithm ', ' deaf ', ' deafened ', ' profound hearing loss ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844,OH-03
"Algorithmic Classification of Paraphasias Project Summary This application’s parent grant, R01DC015999, is focused on the development of automated systems for identifying and categorizing paraphasic speech errors in language samples from individuals with post-stroke aphasia, both in the context of confrontation naming tests as well as in connected speech. Current approaches require that language samples be manually transcribed, which is both time-consuming and error-prone, and limits the clinical applicability of the technology. Since the parent grant was written, there have been major improvements in automatic speech recognition (ASR) technology, and it may soon be possible to automate this transcription step. This would open many new avenues for applying automated systems of the sort developed under the parent grant, both in clinical and research settings. However, these promising new ASR techniques depend on large and carefully-annotated datasets, of the sort that do not exist currently for aphasic speech. Under this administrative supplement, we propose to address this issue by performing an extensive campaign of transcription and detailed annotation of an already-existing publicly-available library of audio recordings of aphasic speech, including both structured naming tests and discourse samples. In addition to phonemic transcription of utterances themselves, we will annotate other features of aphasic speech (false starts, disfluencies, etc.) so as to support the development of automated algorithms for analyzing such speech. Our interdisciplinary team of machine learning researchers and aphasiologists will collaborate closely to produce a curated dataset of the sort needed to develop, train, and evaluate modern machine learning techniques for speech recognition. Importantly, the resulting dataset will be documented and organized in a similar manner to other large-scale ASR datasets, and will be released publicly to both the clinical and machine learning communities. In order to raise awareness of the dataset (and of this problem space in general) within the machine learning community, we further propose to organize a shared evaluation task, in which participating teams will make use of our final dataset to build automated transcription systems for naming tests, which will be compared in a “bakeoff” setting. Project Narrative Patients who have experienced a stroke or other brain injury frequently experience anomia- a condition in which they are unable to produce words when speaking. Our parent R01's goal is to create a computerized system for detecting and characterizing an individual’s anomia, which will open the door to new ways of treating anomia and reduce clinical workload. In this administrative supplement, we will prepare a new dataset for use in training these computerized systems, and organize a shared task evaluation within the speech recognition community that will use this dataset.",Algorithmic Classification of Paraphasias,10411534,R01DC015999,"['Anomia ', ' Amnesic Aphasia ', ' Anomic Aphasia ', ' Anomic Dysphasia ', ' Dysnomia ', ' Nominal Aphasia ', ' Nominal Dysphasia ', ' Aphasia ', ' Alogia ', ' Anepia ', ' Logagnosia ', ' Logamnesia ', ' Logasthenia ', ' Awareness ', ' Clinical Research ', ' Clinical Study ', ' Communities ', ' Goals ', ' Language ', ' Libraries ', ' Manuals ', ' Modernization ', ' Names ', ' Parents ', ' Patients ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Speech ', ' Stroke ', ' Apoplexy ', ' Brain Vascular Accident ', ' Cerebral Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebrovascular Stroke ', ' brain attack ', ' cerebral vascular accident ', ' cerebrovascular accident ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Workload ', ' Work Load ', ' Data Set ', ' Dataset ', ' Clinical ', ' Evaluation ', ' Training ', ' Individual ', ' Brain Injuries ', ' Acquired brain injury ', ' brain damage ', ' brain-injured ', ' machine learned ', ' Machine Learning ', ' Techniques ', ' System ', ' experience ', ' speech recognition ', ' Structure ', ' Sampling ', ' Address ', ' Administrative Supplement ', ' Development ', ' developmental ', ' post stroke ', ' after stroke ', ' poststroke ', ' computerized ', ' Consumption ', ' clinical application ', ' clinical applicability ', ' parent grant ', ' Algorithmic Analysis ', ' Algorithmic Analyses ', ' Analyses of Algorithms ', ' Analysis of Algorithms ', ' learning community ', ' automated speech recognition ', ' automatic speech recognition ', ' stroke-induced aphasia ', ' aphasia due to stroke ', ' aphasia following stroke ', ' poststroke aphasia ', ' stroke aphasia ', ' stroke survivor with aphasia ', ' classification algorithm ', ' automated algorithm ', ' automatic algorithm ', ' ']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,294197,OR-03
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,10118008,F32DC018205,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Aphasia ', ' Alogia ', ' Anepia ', ' Logagnosia ', ' Logamnesia ', ' Logasthenia ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' hearing perception ', ' sound perception ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cognition ', ' Communication ', ' Foundations ', ' Goals ', ' Human ', ' Modern Man ', ' Judgment ', ' Linguistics ', ' Linguistic ', ' Magnetoencephalography ', ' MEG imaging ', ' magnetoencephalographic imaging ', ' Music ', ' Noise ', ' Perception ', ' Periodicity ', ' Cyclicity ', ' Rhythmicity ', ' Psychophysics ', ' psychophysical ', ' Records ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Role ', ' social role ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Work ', ' Measures ', ' career ', ' Solid ', ' Series ', ' insight ', ' Stimulus ', ' machine learned ', ' Machine Learning ', ' Functional MRI ', ' fMRI ', ' Functional Magnetic Resonance Imaging ', ' programs ', ' Frequencies ', ' Auditory ', ' System ', ' Performance ', ' neural ', ' relating to nervous system ', ' Structure ', ' neuro-imaging ', ' neuroimaging ', ' Participant ', ' Brain region ', ' Address ', ' Data ', ' Process ', ' Behavioral ', ' Pathway interactions ', ' pathway ', ' Mind ', ' neuromechanism ', ' neural mechanism ', ' cognitive neuroscience ', ' speech processing ', ' operation ', ' non-invasive imaging ', ' noninvasive imaging ', ' spectral energy ', ' spectrum energy ', ' experimental study ', ' experiment ', ' experimental research ', ' auditory processing ', ' individuals with autism spectrum disorder ', ' autistic individuals ', ' individuals with ASD ', ' individuals with autism ', ' people with ASD ', ' people with autism ', ' people with autism spectrum disorder ', ' ']",NIDCD,NEW YORK UNIVERSITY,F32,2021,65994,NY-12
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,10087511,R01DC006859,"['Acoustics ', ' Acoustic ', ' Affect ', ' Attention ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Dysarthria ', ' Dysarthosis ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' Health Services Accessibility ', ' Access to Care ', ' access to health services ', ' access to services ', ' access to treatment ', ' accessibility to health services ', ' availability of services ', ' care access ', ' health service access ', ' health services availability ', ' service availability ', ' treatment access ', ' Judgment ', ' Language ', ' Learning ', ' Theoretical model ', ' Theoretic Models ', ' nervous system disorder ', ' Nervous System Diseases ', ' Neurologic Disorders ', ' Neurological Disorders ', ' neurological disease ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Periodicity ', ' Cyclicity ', ' Rhythmicity ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' Educational Intervention ', ' Education for Intervention ', ' Instruction Intervention ', ' Training Intervention ', ' instructional intervention ', ' Pathologist ', ' tool ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Injuries ', ' Nervous System damage ', ' Neurological Damage ', ' Neurological Injury ', ' Neurological trauma ', ' neurotrauma ', ' Nervous System Trauma ', ' Coding System ', ' Code ', ' Modeling ', ' Sampling ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' disparity in health ', ' health disparity ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' predictive modeling ', ' computer based prediction ', ' prediction model ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' outcome prediction ', ' predictive outcomes ', ' predictors of outcomes ', ' recruit ', ' optimal treatments ', ' optimal therapies ', ' machine learning algorithm ', ' machine learned algorithm ', ' speech in noise ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' Computer Models ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,305399,AZ-09
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,10064139,R01DC012048,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Environment ', ' Goals ', ' Hearing ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Laboratories ', ' Masks ', ' Methods ', ' Modernization ', ' Noise ', ' Recurrence ', ' Recurrent ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Voice ', ' Work ', ' segregation ', ' Racial Segregation ', ' base ', ' improved ', ' Surface ', ' Chronic ', ' Training ', ' Individual ', ' Investigation ', ' Frequencies ', ' Auditory ', ' Complex ', ' Source ', ' Techniques ', ' System ', ' American ', ' success ', ' Structure ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Address ', ' Symptoms ', ' Data ', ' digital ', ' design ', ' designing ', ' innovation ', ' innovate ', ' innovative ', ' Network-based ', ' real world application ', ' combat ', ' signal processing ', ' network architecture ', ' Formulation ', ' experimental study ', ' experiment ', ' experimental research ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' deep learning ', ' microphone ', ' supervised learning ', ' supervised machine learning ', ' Auditory Prosthesis ', ' hearing prosthesis ', ' normal hearing ', ' good hearing ', ' healthy hearing ', ' speech in noise ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,301954,OH-03
"Biofeedback-Enhanced Treatment for Speech Sound Disorder: Randomized Controlled Trial and Delineation of Sensorimotor Subtypes Project Summary/Abstract Children with speech sound disorder show diminished accuracy and intelligibility in spoken communication and may thus be perceived as less capable or intelligent than peers, with negative consequences for both socio- emotional and socioeconomic outcomes [1]–[3]. While most speech errors resolve by the late school-age years, between 2-5% of speakers exhibit residual speech sound disorder (RSSD) that persists through adoles- cence or even adulthood [4], [5], reflecting about 6 million cases in the US. In a series of experimental studies since 2013, our research team has demonstrated that treatment incorporating technologically-enhanced feed- back can improve speech production in individuals with RSSD who have not responded to previous interven- tion [6]–[10]. The primary objective of the parent award (R01 DC017476, “Biofeedback-Enhanced Treatment for Speech Sound Disorder”) is to conduct the first well-powered randomized controlled trial comparing tradi- tional vs biofeedback intervention for the most common type of RSSD, misarticulation of the English /r/ sound.  Treatment of RSSD could also be enhanced through the development of tools incorporating artificial intelligence/machine learning (AI/ML). Applications with automated scoring of speech sounds could in principle be used to augment clinician services and achieve higher-intensity practice for faster progress. However, no computerized treatment to date has demonstrated sufficient accuracy for clinical use with children [11]. Existing systems are limited primarily by the fact that publicly available speech corpora have very little representation of either children or individuals with speech impairments. This data scarcity represents a fundamental issue hin- dering advances in clinical applications of automatic speech recognition (ASR) [12]. The proposed sup- plement will address this barrier by modifying and augmenting PERCEPT (Perceptual Error Rating for the Clin- ical Evaluation of Phonetic Targets), an existing corpus of acoustic recordings of child speech assembled through the parent award and the investigators’ previous NIH-funded research since 2013. AI/ML applications of the augmented database are expected to have a twofold scientific impact. First, we anticipate direct benefits for children with RSSD affecting /r/, whose speech samples make up the majority of the current corpus. We will use our database to train a neural network to classify novel child productions containing /r/ as correct or incor- rect. This classifier could then be incorporated into AI tools to increase the efficacy of intervention for children with RSSD. Second, we anticipate that engineers working on the broader problem of ASR for child or clinical speech will be interested in using PERCEPT for model training, especially after the corpus is augmented with more diverse data, as proposed here. We expect to show that acoustic models generated with PERCEPT can improve the performance of currently available open-access speech recognition systems (e.g., Kaldi [13]) in recognition of novel child speech stimuli. The PERCEPT database will be made publicly available through part- nership with PhonBank, an NIH-funded data-sharing platform for speech research (e.g., [14]–[16]). Project Narrative Speech sound disorder in childhood poses a barrier to academic and social participation, with potentially life- long consequences for educational and occupational outcomes. The parent award aims to meet a public health need by conducting the first randomized controlled trial comparing the efficacy and efficiency of speech inter- vention with and without real-time visual biofeedback. The proposed supplement will lay groundwork for the development of automated speech recognition tools for speech sound disorder by modifying and augmenting an existing corpus of acoustic recordings of child speech in preparation for sharing with researchers in artificial intelligence and machine learning (AI/ML).",Biofeedback-Enhanced Treatment for Speech Sound Disorder: Randomized Controlled Trial and Delineation of Sensorimotor Subtypes,10412492,R01DC017476,"['Acoustics ', ' Acoustic ', ' Adolescence ', ' 12-20 years old ', ' adolescence (12-20) ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Affect ', ' Articulation Disorders ', ' Dysarticulation Disorders ', ' Misarticulation ', ' Phonological Impairments ', ' Phonology Impairment ', ' Speech Articulation Disorders ', ' Articulators ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Award ', ' Biofeedback ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Decision Making ', ' Disease ', ' Disorder ', ' Engineering ', ' Exhibits ', ' Feedback ', ' Foundations ', ' Recording of previous events ', ' History ', ' Intelligence ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Learning ', ' Methods ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Parents ', ' Perception ', ' Production ', ' Public Health ', ' Publishing ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' Surveys ', ' Survey Instrument ', ' Technology ', ' Testing ', ' Time ', ' Tweens ', ' Ultrasonography ', ' Echography ', ' Echotomography ', ' Medical Ultrasound ', ' Ultrasonic Imaging ', ' Ultrasonogram ', ' Ultrasound Diagnosis ', ' Ultrasound Medical Imaging ', ' Ultrasound Test ', ' diagnostic ultrasound ', ' sonogram ', ' sonography ', ' sound measurement ', ' ultrasound ', ' ultrasound imaging ', ' ultrasound scanning ', ' Work ', ' Measures ', ' base ', ' sensory feedback ', ' improved ', ' Procedures ', ' Clinical ', ' Residual state ', ' Residual ', ' Series ', ' Link ', ' Training ', ' Childhood ', ' pediatric ', ' insight ', ' Stimulus ', ' Visual ', ' Individual ', ' Databases ', ' Data Bases ', ' data base ', ' School-Age Population ', ' school age ', ' Funding ', ' Randomized Controlled Trials ', ' tool ', ' machine learned ', ' Machine Learning ', ' Life ', ' bully ', ' bullying ', ' Auditory ', ' Oral ', ' Sensory ', ' System ', ' Occupational ', ' interest ', ' Services ', ' preference ', ' experience ', ' Performance ', ' speech recognition ', ' trait ', ' novel ', ' Participant ', ' peer ', ' Emotional ', ' Modeling ', ' Sampling ', ' response ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Address ', ' Age-Years ', ' Data ', ' Motor ', ' predict therapeutic response ', ' predict therapy response ', ' predict treatment response ', ' therapy prediction ', ' treatment prediction ', ' treatment response prediction ', ' Prediction of Response to Therapy ', ' randomisation ', ' randomization ', ' randomly assigned ', ' Randomized ', ' research clinical testing ', ' Clinical Evaluation ', ' Clinical Testing ', ' clinical test ', ' Enrollment ', ' enroll ', ' Preparation ', ' socioeconomics ', ' socio-economic ', ' socio-economically ', ' socioeconomically ', ' Development ', ' developmental ', ' computerized ', ' predictive modeling ', ' computer based prediction ', ' prediction model ', ' Treatment Efficacy ', ' intervention efficacy ', ' therapeutic efficacy ', ' therapy efficacy ', ' Outcome ', ' Population ', ' Prevalence ', ' Individual Differences ', ' Impairment ', ' somatosensory ', ' clinical application ', ' clinical applicability ', ' speech accuracy ', ' accurate speech ', ' trial comparing ', ' tool development ', ' visual information ', ' evidence base ', ' comparative efficacy ', ' compare efficacy ', ' personalized learning ', ' predicting response ', ' prediction of response ', ' predictive response ', ' predictor of response ', ' response prediction ', ' responders and non-responders ', ' responders from non-responders ', ' responders or non-responders ', ' responders versus non-responders ', ' responders vs non-responders ', ' social engagement ', ' social involvement ', ' social participation ', ' experimental study ', ' experiment ', ' experimental research ', ' recruit ', ' Biofeedback Training ', ' Biofeedback Approach ', ' Biofeedback Therapy ', ' Biofeedback Treatment ', ' neural network ', ' automated speech recognition ', ' automatic speech recognition ', ' diverse data ', ' data diversity ', ' sharing platform ', ' ']",NIDCD,NEW YORK UNIVERSITY,R01,2021,268779,NY-12
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive/augmentative technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functionally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird’s own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the development of prostheses and other assistive/augmentative technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control that we will acquire will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development.",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses,10408524,R01DC018446,"['Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Animals ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Behavior ', ' Birds ', ' Aves ', ' Avian ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Communities ', ' Complement ', ' Complement Proteins ', ' Data Collection ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Engineering ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Future ', ' Goals ', ' Human ', ' Modern Man ', ' indexing ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Maps ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Online Systems ', ' On-Line Systems ', ' online computer ', ' web based ', ' Production ', ' Research ', ' Running ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Software Tools ', ' Computer Software Tools ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Self-Examination ', ' Self evaluation ', ' Self-Surveillance ', ' Self-reflection ', ' Data Set ', ' Dataset ', ' Comprehension ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' Injury ', ' injuries ', ' base ', ' improved ', ' Area ', ' Training ', ' Stimulus ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' Educational workshop ', ' Workshop ', ' Interdisciplinary Study ', ' Interdisciplinary Research ', ' Multidisciplinary Collaboration ', ' Multidisciplinary Research ', ' Measurement ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Hour ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' meetings ', ' brain control ', ' mind control ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' cohort ', ' neural ', ' relating to nervous system ', ' Neural Development ', ' neurodevelopment ', ' Oscines ', ' song bird ', ' Songbirds ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' member ', ' Basic Research ', ' Basic Science ', ' Prevention ', ' Modeling ', ' Speech Development ', ' vocal learning ', ' Brain region ', ' Data ', ' Motor ', ' Resource Sharing ', ' Collection ', ' Validation ', ' Development ', ' developmental ', ' Behavioral ', ' Metadata ', ' meta data ', ' Output ', ' virtual ', ' design ', ' designing ', ' Visualization software ', ' visualization tool ', ' Outcome ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' open source ', ' functional restoration ', ' restore function ', ' restore functionality ', ' restore lost function ', ' prototype ', ' motor control ', ' parent project ', ' data sharing ', ' software repository ', ' undergraduate student ', ' undergrad ', ' undergraduate ', ' Learning Module ', ' Education Module ', ' Educational Module ', ' Teaching Module ', ' High School Student ', ' Secondary School Student ', ' Secondary Student ', ' webinar ', ' hackathon ', ' hack day ', ' hackfest ', ' terabyte ', ' FAIR principles ', ' FAIR data ', ' FAIR guiding principles ', ' Findable, Accessible, Interoperable and Re-usable ', ' Findable, Accessible, Interoperable, and Reusable ', ' Infrastructure ', ' data tools ', ' large scale data ', ' large scale data sets ', ' large scale datasets ', ' large datasets ', ' large data sets ', ' data exploration ', ' data reuse ', ' data re-use ', ' effectiveness testing ', ' data repository ', ' Data Banks ', ' Databanks ', ' data depository ', ' TRUST principles ', ' Transparency, Responsibility, User focus, Sustainability, and Technology ', ' Border Community ', ' Border City ', ' Border Town ', ' community based research ', ' community based design ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,219319,CA-52
"Longitudinal neuroimaging and neurocognitive assessment of risk and protective factors across the schizophrenia spectrum ABSTRACT  The parent R01 project is a longitudinal study examining risk and protective factors in the schizophrenia (SZ) spectrum—from healthy controls (HCs) to individuals with schizotypal personality disorder (SPD) to recent-onset SZ patients (80 per group)—using MRI and neurocognitive approaches. It tests a neurobiological model which posits that individuals with SPD—an intermediate phenotype—have protective factors against developing threshold psychosis, such as preservation of frontal lobe and less severe temporal lobe abnormalities compared to SZ that lead to milder cognitive and social impairments. Examining natural language processing (NLP) as proposed in this supplement is in line with the scope and aims of the parent R01 project and may inform the key neurobiological model being tested. Moreover, examining NLP using novel measures of semantics and syntax in association with measures from the parent R01 of frontal and temporal white matter integrity/connectivity assessed with diffusion tensor imaging and cognitive domains such as processing speed and working memory is innovative.  Speech and language provide a rich source of data on human thought, including semantic and emotional content, semantic coherence (i.e. flow of meaning), and syntactic structure and complexity (i.e. usage of parts of speech). There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder in SZ spectrum. The use of automated linguistic analytic methods has been limited to only a few studies focused on discriminating SZ patients from HCs and predicting psychosis.  Together with our colleagues with expertise in NLP at Icahn School of Medicine at Mount Sinai, we will use advanced computational speech analytic approaches to identify the linguistic basis of language production along a spectrum from normal to thought disordered. We will use optimal interviewing techniques1 to obtain open-ended 30-45 minute narratives from the large (N = 240) English-speaking sample in the parent R01 study, with a range of language disturbances across the spectrum ranging from none/subtle to severe. NLP techniques including Latent Semantic Analysis2 (LSA) and part-of-speech (POS) tagging3,4 will be conducted using artificial intelligence to examine semantic and syntactic language features to include in our overall neurobiological model. These analyses yield fine-grained indices of speech and language that may more accurately capture thought disorder.  Three specific aims will assess (1) semantic coherence in language production using LSA2 and examine its association with positive symptoms and functional impairment across the spectrum; (2) syntactic complexity in language production using POS tagging3,4 and measure acoustic features to examine their association with negative symptoms and functional impairment; and (3) the relationship between language and speech features (semantic, syntactic, and acoustic) with putative white matter integrity assessed using diffusion tensor imaging. PROJECT NARRATIVE Speech and language provide a rich source of data on human thought, including semantic and emotional content, semantic coherence (i.e. flow of meaning), and syntactic structure and complexity (i.e. usage of parts of speech). This supplement is in line with the scope and aims of the parent R01 study and in collaboration with our colleagues with expertise in natural language processing at ISMMS, we will: (a) leverage the parent R01—a study of risk and protective factors in the schizophrenia (SZ) spectrum using MRI and neurocognitive measures in healthy controls, individuals with schizotypal personality disorder (SPD), and SZ patients (80 per group); and (b) use advanced computational speech analytic approaches to identify the linguistic basis– semantics and syntax–that underlies language production along a spectrum from normal to gradations of thought disorder across the SZ spectrum. No study has rigorously examined this in individuals with SPD as proposed in this application.",Longitudinal neuroimaging and neurocognitive assessment of risk and protective factors across the schizophrenia spectrum,10381940,R01MH121411,"['Acoustics ', ' Acoustic ', ' Activities of Daily Living ', ' Activities of everyday life ', ' daily living functionality ', ' functional ability ', ' functional capacity ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Computers ', ' Disease ', ' Disorder ', ' frontal lobe ', ' frontal cortex ', ' Goals ', ' Grant ', ' Human ', ' Modern Man ', ' indexing ', ' Interview ', ' Language ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Linguistics ', ' Linguistic ', ' Longitudinal Studies ', ' long-term study ', ' longitudinal outcome studies ', ' longterm study ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Short-Term Memory ', ' Immediate Memory ', ' Shortterm Memory ', ' working memory ', ' Methods ', ' Natural Language Processing ', ' natural language understanding ', ' Neurobiology ', ' neurobiological ', ' Parents ', ' Patients ', ' Phenotype ', ' Production ', ' Quality of life ', ' QOL ', ' Risk ', ' Risk Factors ', ' Schizophrenia ', ' Schizophrenic Disorders ', ' dementia praecox ', ' schizophrenic ', ' Schizotypal Personality Disorder ', ' schizotypal ', ' medical schools ', ' medical college ', ' school of medicine ', ' Semantics ', ' Social Adjustment ', ' social adaptation ', ' Speech ', ' Temporal Lobe ', ' temporal cortex ', ' Testing ', ' Time ', ' Measures ', ' Anisotropy ', ' Risk Assessment ', ' analytical method ', ' Clinical ', ' Individual ', ' Collaborations ', ' Metaphor ', ' machine learned ', ' Machine Learning ', ' Scientist ', ' Source ', ' Techniques ', ' Neurocognitive ', ' Inferior ', ' processing speed ', ' Performance ', ' syntactic ', ' syntax ', ' cohort ', ' Structure ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' Graph ', ' substantia alba ', ' white matter ', ' social ', ' Emotional ', ' Modeling ', ' Sampling ', ' social cognition ', ' Functional impairment ', ' functional disability ', ' DWI (diffusion weighted imaging) ', ' DWI-MRI ', ' Diffusion MRI ', ' Diffusion Weighted MRI ', ' Diffusion weighted imaging ', ' Diffusion-weighted Magnetic Resonance Imaging ', ' dMRI ', ' diffusion tensor imaging ', ' Diffusion Magnetic Resonance Imaging ', ' Thickness ', ' Thick ', ' Symptoms ', ' Administrative Supplement ', ' Data ', ' multi-modal imaging ', ' multi-modality imaging ', ' multimodality imaging ', ' Multimodal Imaging ', ' Cognitive ', ' functional outcomes ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' blood oxygenation level dependent response ', ' BOLD response ', ' multimodality ', ' multi-modality ', ' longitudinal course ', ' brain abnormalities ', ' preservation ', ' protective factors ', ' Grain ', ' Psychoses ', ' schizophrenia-spectrum disorder ', ' schizophrenia-spectrum ', ' ']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,206753,NY-13
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speaker’s voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patient’s voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patient’s voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,10218134,R01DC016621,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Communication ', ' Data Collection ', ' Mental Depression ', ' depression ', ' Electromagnetics ', ' Goals ', ' Gold ', ' Health ', ' Hoarseness ', ' Voice Hoarseness ', ' Human ', ' Modern Man ', ' language training ', ' Laryngectomy ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Laryngeal Prosthesis ', ' Artificial Larynx ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Robotics ', ' Science ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Speech Synthesizers ', ' voice synthesizer ', ' Speech Therapy ', ' Alaryngeal Speech ', ' Alaryngeal Voice Production ', ' Esophageal Speech ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Gender ', ' Measures ', ' Articular Range of Motion ', ' Joint Range of Motion ', ' range of motion ', ' base ', ' improved ', ' Individual ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Life ', ' mechanical ', ' Mechanics ', ' Msec ', ' millisecond ', ' Pattern ', ' vibration ', ' magnetic ', ' Magnetism ', ' auditory feedback ', ' Performance ', ' visual feedback ', ' kinematic model ', ' kinematics ', ' Speed ', ' novel ', ' Participant ', ' novel technologies ', ' new technology ', ' Devices ', ' social ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Position ', ' Positioning Attribute ', ' oral communication ', ' Enhancement Technology ', ' Data ', ' Electrolarynx ', ' Motor ', ' Laryngectomee ', ' Tracheoesophageal Speech ', ' Tracheo-Esophageal Speech ', ' Wireless Technology ', ' wireless ', ' Characteristics ', ' Tracer ', ' Development ', ' developmental ', ' Output ', ' design ', ' designing ', ' alternative communication ', ' Population ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' prototype ', ' social exclusion ', ' marginalization ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' wearable device ', ' wearable electronics ', ' wearable technology ', ' preservation ', ' machine learning algorithm ', ' machine learned algorithm ', ' speech synthesis ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,581235,TX-10
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,10201558,K24DC016312,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disease ', ' Disorder ', ' Dysarthria ', ' Dysarthosis ', ' Electromagnetics ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' Disseminated Sclerosis ', ' insular sclerosis ', ' Persons ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Play ', ' Quality of life ', ' QOL ', ' Questionnaires ', ' Records ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Running ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Stroke ', ' Apoplexy ', ' Brain Vascular Accident ', ' Cerebral Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebrovascular Stroke ', ' brain attack ', ' cerebral vascular accident ', ' cerebrovascular accident ', ' Surveys ', ' Survey Instrument ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' machine learned ', ' Machine Learning ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Brain Trauma ', ' traumatic brain damage ', ' Traumatic Brain Injury ', ' Cell Phone ', ' Cellular Telephone ', ' iPhone ', ' smart phone ', ' smartphone ', ' Cellular Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' Development ', ' developmental ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' usability ', ' motor impairment ', ' movement impairment ', ' movement limitation ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' Tablet Computer ', ' tablet device ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' virtual vocal tract ', ' speech-generating device ', ' machine learning algorithm ', ' machine learned algorithm ', ' effectiveness testing ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2021,189937,MA-07
"A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia Abstract 1 in 3 seniors in the United States dies with dementia, of which Alzheimer’s disease (AD) is the most common form. AD patients suffer from decreased ability to meaningfully communicate and interact, which causes significant stress and burden for both professional caregivers and family members. Socially assistive robots (SARs) have been designed to promote therapeutic interaction and communication. Unfortunately, artificial intelligence (AI) has long been challenged by the speech of elderly persons, who exhibit age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers that can be exacerbated by the neurological changes associated with AD, further complicated by common environmental noises such as the ceiling fan, television, etc. Because of the resulting poor real-world speech and language understanding by available SAR technologies, scarce human caregivers are often required to guide AD patients through SAR interactions, limiting SARs to small deployments, mostly as part of research studies. Unlike existing approaches relying purely on AI, care.coach™ is developing a SAR-like avatar that converses with elderly and AD patients through truly natural speech. Each avatar is controlled by a 24x7 team of trained human staff who can cost-effectively monitor and engage 12 or more patients sequentially (2 simultaneously) through the audio/visual feeds from the patient’s avatar device. The staff communicate with each patient by sending text commands which are converted into the avatar’s voice through a speech synthesis engine. The staff contribute to the system their human abilities for speech and natural language processing (NLP) and for generating free-form conversational responses to help patients build personal relationships with the avatar. The staff are guided by a software-driven expert system embedded into their work interface, which is programmed with evidence-based prompting and protocols to support healthy behaviors and self-care. This SBIR Fast-Track project will leverage the unique data generated by our human- in-the-loop platform to develop new ASR capabilities, enabling fully automatic conversational protocols to engage and support AD patients without human intervention. We aim in Phase I to leverage our unique prior work dataset to train an automatic speech recognition (ASR) engine to enable the understanding of certain types of elderly and AD patient speech more successfully than any currently available engine. We aim in Phase II to incorporate this new engine along with an NLP module into our existing human-in-the-loop avatar system, recruiting a population of AD patients to further train and validate with during a 2-year human subjects study so that we can demonstrate full automation of a significant portion of our avatar conversations with mild- to-moderate level AD patients. Thus, we will improve the commercial scalability of our avatars, while validating our new ASR/NLP engine as the most accurate platform for enabling the next generation of AD-focused SARs. Narrative Artificial intelligence (AI) has long been challenged by the speech of elderly persons, and especially persons with dementia, due to age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers. Unlike existing approaches to socially assistive robots (SARs) relying purely on limited AI for conversation, care.coach™ has been commercializing a SAR-like avatar that converses with elderly and AD patients through truly natural speech, powered by a 24x7 team of trained human staff. The unique data sets that our solution enables us to gather at commercial scale will be leveraged in this SBIR project to develop an automatic speech recognition (ASR) and natural language processing (NLP) engine that is best-in-class for AD applications, improving the commercial scalability of our avatars by reducing our dependence on human staff, while serving as a new AI platform for enabling the next generation of AD- focused, conversational SARs.",A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia,10263325,R44AG062014,"['Age ', ' ages ', ' Elderly ', ' advanced age ', ' elders ', ' geriatric ', ' late life ', ' later life ', ' older adult ', ' older person ', ' senior citizen ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Automation ', ' Behavior ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Computers ', ' Delirium ', ' delirious ', ' Disease ', ' Disorder ', ' Exhibits ', ' Expert Systems ', ' Intelligent systems ', ' Family ', ' Goals ', ' Hospitals ', ' Community Hospitals ', ' Human ', ' Modern Man ', ' Hybrids ', ' Institutes ', ' Jamaica ', ' Language ', ' Loneliness ', ' lonely ', ' Manuals ', ' Persons ', ' Natural Language Processing ', ' natural language understanding ', ' Noise ', ' Patients ', ' Production ', ' Self Care ', ' personal care ', ' Semantics ', ' Social Interaction ', ' Social support ', ' social support network ', ' Computer software ', ' Software ', ' Speech ', ' Stress ', ' Technology ', ' Television ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Tremor ', ' United States ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' World Health Organization ', ' Generations ', ' Measures ', ' Price ', ' pricing ', ' Caregivers ', ' Care Givers ', ' falls ', ' depressive symptoms ', ' Emotional Depression ', ' depression symptom ', ' depressive ', ' Family member ', ' Data Set ', ' Dataset ', ' Caring ', ' human subject ', ' Label ', ' improved ', ' Phase ', ' Neurologic ', ' Neurological ', ' Training ', ' Visual ', ' Individual ', ' Licensing ', ' satisfaction ', ' Therapeutic ', ' Contracting Opportunities ', ' Contracts ', ' restraint ', ' Hour ', ' Frequencies ', ' Dependence ', ' Protocol ', ' Protocols documentation ', ' Reaction ', ' Techniques ', ' System ', ' Amentia ', ' Dementia ', ' Medical center ', ' speech recognition ', ' success ', ' phrases ', ' skills ', ' research study ', ' Study Subject ', ' Devices ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' response ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Feeds ', ' Data ', ' Small Business Innovation Research Grant ', ' SBIR ', ' Small Business Innovation Research ', ' Validation ', ' Monitor ', ' Text ', ' age related ', ' age dependent ', ' cost ', ' design ', ' designing ', ' next generation ', ' older patient ', ' elderly patient ', ' Population ', ' Network-based ', ' usability ', ' aging population ', ' aged population ', ' population aging ', ' evidence base ', ' human-in-the-loop ', ' recruit ', ' care providers ', ' primary care provider ', ' health plan ', ' health plans ', ' patient engagement ', ' participant engagement ', ' patient response ', ' patient specific response ', ' responsive patient ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' speech synthesis ', "" Alzheimer's disease related dementia "", ' AD related dementia ', ' ADRD ', ' Alzheimer related dementia ', ' automated speech recognition ', ' automatic speech recognition ', ' social assistive robot ', ' social robot ', "" Alzheimer's disease patient "", "" Alzheimer's patient "", ' Home ', ' ']",NIA,CARE.COACH CORPORATION,R44,2021,1386676,CA-14
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,10134315,K01DC017751,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Behavior ', ' Biomechanics ', ' biomechanical ', ' Communication ', ' Statistical Data Interpretation ', ' Statistical Data Analyses ', ' Statistical Data Analysis ', ' statistical analysis ', ' Diagnosis ', ' Endoscopes ', ' Goals ', ' Gold ', ' Health ', ' Human ', ' Modern Man ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Methods ', ' Methodology ', ' Mining ', ' Statistical Models ', ' Probabilistic Models ', ' Probability Models ', ' statistical linear mixed models ', ' statistical linear models ', ' Patients ', ' Physics ', ' Production ', ' Research ', ' Speech ', ' Testing ', ' Time ', ' Tremor ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Measures ', ' Outcomes Research ', ' Data Set ', ' Dataset ', ' base ', ' image processing ', ' improved ', ' Area ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Series ', ' Evaluation ', ' Visual ', ' Measurement ', ' Spastic Dysphonias ', ' Laryngeal dystonia ', ' spasmodic dysphonia ', ' Functional disorder ', ' Dysfunction ', ' Physiopathology ', ' pathophysiology ', ' Therapeutic ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Severities ', ' Auditory ', ' Protocol ', ' Protocols documentation ', ' Source ', ' Techniques ', ' System ', ' vibration ', ' vocalization ', ' Palsy ', ' Plegia ', ' paralysis ', ' paralytic ', ' Paralysed ', ' Operative Procedures ', ' Surgical ', ' Surgical Interventions ', ' Surgical Procedure ', ' surgery ', ' Operative Surgical Procedures ', ' cohort ', ' kinematic model ', ' kinematics ', ' Speed ', ' Categories ', ' Prevention ', ' Modeling ', ' Address ', ' Data ', ' Strategic Planning ', ' Characteristics ', ' sex ', ' Development ', ' developmental ', ' Voice Disturbances ', ' Dysphonia ', ' Phonation Disorders ', ' Image ', ' imaging ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' time use ', ' Outcome ', ' Coupling ', ' innovation ', ' innovate ', ' innovative ', ' clinically relevant ', ' clinical relevance ', ' clinical application ', ' clinical applicability ', ' treatment strategy ', ' clinical practice ', ' flexibility ', ' flexible ', ' temporal measurement ', ' temporal resolution ', ' time measurement ', ' clinical development ', ' imaging approach ', ' imaging based approach ', ' ']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2021,137795,MI-08
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of the parent R01 project (R01DC016621, 08/15/2019 – 06/31/2024) are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). The parent R01 project aims to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders as well as visual feedback-based secondary language training and speech therapy. Through the parent R01 project, we are collecting a unique multi-modal speech dataset from patients following laryngectomy and healthy controls. This data set includes speech kinematics from multiple tracers attached on the tongue and the lips, and speech acoustics. Each tracer comprises multiple sensors that measure inertial and magnetic information that can provide additional information to assist the speech acoustic and the articulation-to-speech algorithm. Making such data ML ready for others to consume was out of scope due to required effort and complexity needed to pre-process and synchronize sampling between kinematic and acoustic data. The specific goal of this supplemental project is to make data AI/ML ready by developing the pre-processing algorithms needed to generate a set of features, along with proper formatting and labeling, that can be more easily shared through repositories and used by others to evaluate different ML algorithms. New ML models that will be tested on these ML-ready shared datasets will significantly advance our capabilities to translate articulatory motion into speech sounds, which will not only improve the quality of life for people affected by laryngectomy but also for the millions of individuals living with speech sound disorders such as Parkinson’s disease, and amyotrophic lateral sclerosis. Project Narrative The parent R01 project is to develop a wearable silent speech interface (SSI), a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer) by converting their tongue and lip motion into intelligible speech. Lack of such a publicly available AI/ML ready data set is a critical gap in this field, thus the proposed supplemental project is to make the unique, multi-modal data collected in the parent R01 project AI/ML ready. If successful, this supplement project will have high impact on the speech production affected by laryngectomy.",Wearable silent speech technology to enhance impaired oral communication,10412276,R01DC016621,"['Acceleration ', ' Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' California ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Felis catus ', ' Cats ', ' Cats Mammals ', ' Domestic Cats ', ' Feline Species ', ' Felis domestica ', ' Felis domesticus ', ' Felis sylvestris catus ', ' Communication ', ' Communities ', ' Mental Depression ', ' depression ', ' Disease ', ' Disorder ', ' Engineering ', ' Feedback ', ' Goals ', ' Health ', ' Hoarseness ', ' Voice Hoarseness ', ' Human ', ' Modern Man ', ' language training ', ' Laryngectomy ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Parents ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Production ', ' Publishing ', ' Quality of life ', ' QOL ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Robotics ', ' Rotation ', ' Science ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Speech Therapy ', ' Alaryngeal Speech ', ' Alaryngeal Voice Production ', ' Standardization ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Translating ', ' United States ', ' Universities ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Measures ', ' Data Set ', ' Dataset ', ' base ', ' community planning ', ' Label ', ' sensor ', ' improved ', ' Site ', ' Physiological ', ' Physiologic ', ' Series ', ' Ensure ', ' Individual ', ' tool ', ' Nature ', ' machine learned ', ' Machine Learning ', ' mechanical ', ' Mechanics ', ' Route ', ' Pattern ', ' vibration ', ' Best Practice Analysis ', ' Benchmarking ', ' interest ', ' magnetic ', ' Magnetism ', ' visual feedback ', ' kinematic model ', ' kinematics ', ' novel ', ' novel technologies ', ' new technology ', ' Devices ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Position ', ' Positioning Attribute ', ' Modeling ', ' Sampling ', ' oral communication ', ' depository ', ' repository ', ' Documentation ', ' Enhancement Technology ', ' Preparedness ', ' Readiness ', ' datamining ', ' data mining ', ' Address ', ' Data ', ' Motor ', ' Wireless Technology ', ' wireless ', ' Characteristics ', ' Process ', ' Tracer ', ' Output ', ' Consumption ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' multimodality ', ' multi-modality ', ' social exclusion ', ' marginalization ', ' data archive ', ' data library ', ' Articulation ', ' recruit ', ' wearable device ', ' wearable electronics ', ' wearable technology ', ' multimodal data ', ' multi-modal data ', ' multi-modal datasets ', ' multimodal datasets ', ' public repository ', ' publicly accessible repository ', ' publicly available repository ', ' archive data ', ' archiving data ', ' archived data ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,292804,TX-10
"International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL) Project Abstract This proposal requests support to convene the next three International Conferences on Advances in Quantitative Laryngology, Voice and Speech Research (AQL). During the 5 years of requested support, the 14th, 15th, and 16th AQL (2021, 2023, and 2025 respectively) will be assembled. The 14th AQL will be held in Bogota, Colombia, South America, June 9 and 10, 2021 (pre-conference workshops June 7 and 8), the 15th will be in Phoenix, AZ, USA, in April 2023, while location of the 16th AQL conference will be determined during the 2021 conference (potential locations in South Korea or Germany). AQL is a valuable scientific meeting in the field of voice research and is regarded by voice and speech science specialists as a high quality international scientific meeting. AQL fosters the exchange of theoretical, experimental, and methodological advances, thereby progressing the translational and clinical aspects of voice and speech science. This multidisciplinary conference brings together scientists, clinicians, and students from around the world in various disciplines including Engineering, Biology, Physics, Otolaryngology and Speech Pathology. This proposal will allow for conference development and continuity to ensure an equitable conference that maintains its cutting-edge focus and provide support for students and early career investigators. The continuity of support will also ensure metrics and evaluations from previous conferences to be used to guide future AQL planning. The goals of this proposal are: to promote and support the education and development of young and underrepresented investigators in the voice and speech research community, organize special sessions on emerging research areas specific to quantitative laryngology, voice and speech research, to develop and foster digital networking strategies to provide a more inclusive and equitable conference, and to establish a Steering Committee. NIH funds are requested to provide support for child/family care, conference support for students and keynote speakers, students to assist Chair/Co-Chairs with various logistic needs, before, during and after the AQL conferences, website design and management, and streaming support during the meeting. In the off- conference years, necessary activities will include: student research trainee support, maintaining AQL website, Steering Committee meetings for conference evaluation and planning. Project Narrative This proposal seeks funding for the upcoming 14th, 15th, and 16th International Conference on Advances in Quantitative Laryngology, Voice and Speech Research (AQL) and the associated workshops and pre- conference, taking place in 2021, 2023, and 2025. AQL is an important international scientific meeting specialized in translational research and methods for measurement and modeling of voice and speech. Special emphasis will be given to promoting young investigators and underrepresented populations, digital networks to support a more inclusive and equitable conference, and to develop a permanent AQL website to help disseminate AQL information.","International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL)",10237766,R13DC019564,"['Award ', ' Biology ', ' Carbon ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Colombia ', ' Communities ', ' Education ', ' Educational aspects ', ' Engineering ', ' Environment ', ' Family ', ' Fees ', ' Future ', ' Germany ', ' Goals ', ' Disabled Persons ', ' Disabled Population ', ' Handicapped ', ' People with Disabilities ', ' Persons with Disabilities ', ' disabled ', ' disabled individual ', ' disabled people ', ' individuals with disabilities ', ' Health ', ' Recording of previous events ', ' History ', ' South Korea ', ' Republic of Korea ', ' Leadership ', ' Mentors ', ' Methodology ', ' Persons ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Occupations ', ' Jobs ', ' Professional Positions ', ' Online Systems ', ' On-Line Systems ', ' online computer ', ' web based ', ' Otolaryngology ', ' otorhinolaryngology ', ' Physics ', ' Request for Proposals ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Safety ', ' Science ', ' South America ', ' Speech ', ' Students ', ' Travel ', ' Voice ', ' Woman ', ' Child Support ', ' Measures ', ' Speech Pathology ', ' symposium ', ' conference ', ' convention ', ' summit ', ' symposia ', ' Research Methodology ', ' Research Methods ', ' Specialist ', ' Caring ', ' career ', ' improved ', ' Area ', ' Clinical ', ' Ensure ', ' Evaluation ', ' Discipline ', ' Educational workshop ', ' Workshop ', ' Fostering ', ' Logistics ', ' Measurement ', ' Funding ', ' meeting abstracts ', ' machine learned ', ' Machine Learning ', ' posters ', ' programs ', ' Scientist ', ' Event ', ' Stream ', ' Location ', ' interest ', ' meetings ', ' expectation ', ' member ', ' outreach ', ' social ', ' Modeling ', ' International ', ' Collection ', ' Translational Research ', ' Translational Science ', ' translation research ', ' Update ', ' Development ', ' developmental ', ' web site ', ' website ', ' cost ', ' virtual ', ' digital ', ' design ', ' designing ', ' ethnic minority population ', ' ethnic minority ', ' multidisciplinary ', ' racial and ethnic ', ' ethnoracial ', ' Underrepresented Populations ', ' Underrepresented Groups ', ' under representation of groups ', ' under represented groups ', ' under represented populations ', ' underrepresentation of groups ', ' minority student ', ' recruit ', ' preservation ', ' COVID-19 pandemic ', ' COVID crisis ', ' COVID epidemic ', ' COVID pandemic ', ' COVID-19 crisis ', ' COVID-19 epidemic ', ' COVID-19 global health crisis ', ' COVID-19 global pandemic ', ' COVID-19 health crisis ', ' COVID-19 public health crisis ', ' COVID19 crisis ', ' COVID19 epidemic ', ' COVID19 global health crisis ', ' COVID19 global pandemic ', ' COVID19 health crisis ', ' COVID19 pandemic ', ' COVID19 public health crisis ', ' SARS-CoV-2 epidemic ', ' SARS-CoV-2 global health crisis ', ' SARS-CoV-2 global pandemic ', ' SARS-CoV-2 pandemic ', ' SARS-CoV2 epidemic ', ' SARS-CoV2 pandemic ', ' SARS-coronavirus-2 epidemic ', ' SARS-coronavirus-2 pandemic ', ' Severe Acute Respiratory Syndrome CoV 2 epidemic ', ' Severe Acute Respiratory Syndrome CoV 2 pandemic ', ' Severe acute respiratory syndrome coronavirus 2 epidemic ', ' Severe acute respiratory syndrome coronavirus 2 pandemic ', ' corona virus disease 2019 epidemic ', ' corona virus disease 2019 pandemic ', ' coronavirus disease 2019 crisis ', ' coronavirus disease 2019 epidemic ', ' coronavirus disease 2019 global health crisis ', ' coronavirus disease 2019 global pandemic ', ' coronavirus disease 2019 health crisis ', ' coronavirus disease 2019 pandemic ', ' coronavirus disease 2019 public health crisis ', ' coronavirus disease crisis ', ' coronavirus disease epidemic ', ' coronavirus disease pandemic ', ' severe acute respiratory syndrome coronavirus 2 global health crisis ', ' severe acute respiratory syndrome coronavirus 2 global pandemic ', ' ']",NIDCD,MAYO CLINIC ARIZONA,R13,2021,40000,AZ-06
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. ",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,10216216,R01DC018446,"['axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' Basic Research ', ' Basic Science ', ' graduate student ', ' Prevention ', ' Modeling ', ' response ', ' Speech Development ', ' depository ', ' repository ', ' model development ', ' Limes ', ' Membrum superius ', ' Upper Limb ', ' Upper Extremity ', ' vocal learning ', ' Data ', ' Educational Materials ', ' Motor ', ' Principal Investigator ', ' Characteristics ', ' Development ', ' developmental ', ' Behavioral ', ' Output ', ' web site ', ' website ', ' Instruction ', ' design ', ' designing ', ' Clinical assessments ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' Implant ', ' bird song ', ' birdsong ', ' open source ', ' functional restoration ', ' restore function ', ' restore functionality ', ' restore lost function ', ' motor control ', ' data sharing ', ' operation ', ' undergraduate student ', ' undergrad ', ' undergraduate ', ' signal processing ', ' Learning Module ', ' Education Module ', ' Educational Module ', ' Teaching Module ', ' High School Student ', ' Secondary School Student ', ' Secondary Student ', ' Course Content ', ' course curriculum ', ' High School Outreach ', ' Data Science ', ' hackathon ', ' hack day ', ' hackfest ', ' Infrastructure ', ' machine learning algorithm ', ' machine learned algorithm ', ' functional electrical stimulation ', ' functional electrostimulation ', ' large datasets ', ' large data sets ', ' effectiveness testing ', ' Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Animals ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Behavior ', ' Birds ', ' Aves ', ' Avian ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cell Nucleus ', ' Nucleus ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Communities ', ' Complement ', ' Complement Proteins ', ' Computers ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Feedback ', ' Future ', ' Goals ', ' Recording of previous events ', ' History ', ' Human ', ' Modern Man ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Maps ', ' Methods ', ' Motor Cortex ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' Patients ', ' Play ', ' Production ', ' Quadriplegia ', ' Quadriplegic ', ' Tetraplegia ', ' tetraplegic ', ' Research ', ' Role ', ' social role ', ' Running ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Generations ', ' Outcome Measure ', ' Data Set ', ' Dataset ', ' Comprehension ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' Injury ', ' injuries ', ' base ', ' human subject ', ' Computer Interface ', ' improved ', ' Area ', ' Evaluation ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' Educational workshop ', ' Workshop ', ' Space Models ', ' Finches ', ' Robot ', ' Artificial Extremities ', ' Artificial Limbs ', ' prosthetic limb ', ' Limb Prosthesis ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' meetings ', ' auditory feedback ', ' brain control ', ' mind control ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' high school ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Neural Development ', ' neurodevelopment ', ' Oscines ', ' song bird ', ' Songbirds ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,333282,CA-52
