text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"POPULATION GENOMICS OF ADAPTATION Project Summary Malaria that results from Plasmodium falciparum is among the most globally devastating human diseases. The principle vector of malaria, mosquitoes of the Anopheles gambiae species complex, are thus central targets for controlling the human health burden of Plasmodium. For nearly two decades, there have been large-scale, coordinated efforts to diminish mosquito populations, generally through spraying and insecticide treated bed nets. Indeed such control efforts have now led to a nearly 50% decrease in the rates of malaria infection in many parts of sub-Saharan Africa. At present, however, control efforts of A. gambiae are being threatened by evolutionary responses within mosquitos: A. gambiae populations have shown increases in insecticide resistance as well as behavioral adaptations that allow mosquitos to avoid spraying all together. Thus adaptation of mosquitos to the control efforts themselves is currently a risk to maintain the gains made in the fight against malaria. In this proposal we lay out an integrated population genomic approach for systematically identifying regions of the A. gambiae genome that are evolving adaptively in response to ongoing control efforts. Our approach centers upon state-of-the-art supervised machine learning techniques that we have recently introduced for finding the signatures of selective sweeps in genomes (Schrider and Kern, 2016), coupled with the large-scale population genomic datasets currently in production by the Ag1000G consortium. Project Narrative Malaria is a mosquito-borne infectious disease that has enormous impacts on human health globally. For the past 16 years, large gains have been made in decreasing the rate of malaria transmission through control of its mosquito vector Anopheles gambiae; unfortunately at present these control efforts are in danger of collapse due to the evolution of insecticide resistance in the mosquitos. We aim to discover the genomic targets of such resistance through the development of sophisticated population genomic approaches and their application to state-of- the-art genome sequence datasets from Anopheles gambiae.",POPULATION GENOMICS OF ADAPTATION,9753261,R01GM117241,"['Affect', 'Africa South of the Sahara', 'Anopheles Genus', 'Anopheles gambiae', 'Awareness', 'Back', 'Beds', 'Behavioral', 'Catalogs', 'Cessation of life', 'Chromosomes', 'Classification', 'Complex', 'Coupled', 'Culicidae', 'Data', 'Data Set', 'Dependence', 'Detection', 'Development', 'Distant', 'Equipment and supply inventories', 'Evolution', 'Frequencies', 'Funding', 'Genome', 'Genomic approach', 'Genomics', 'Geography', 'Goals', 'Health', 'Human', 'Individual', 'Insecticide Resistance', 'Insecticides', 'Link', 'Location', 'Machine Learning', 'Malaria', 'Methodology', 'Methods', 'Mosquito-borne infectious disease', 'Mutation', 'Pattern', 'Phase', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Prevalence', 'Production', 'Recording of previous events', 'Research', 'Residual state', 'Resistance', 'Risk', 'Sampling', 'Techniques', 'Time', 'Variant', 'Work', 'deep neural network', 'fight against', 'genomic data', 'global health', 'human disease', 'learning strategy', 'malaria infection', 'malaria mosquito', 'malaria transmission', 'markov model', 'novel', 'recurrent neural network', 'resistance allele', 'response', 'supervised learning', 'tool', 'vector', 'vector control', 'vector mosquito']",NIGMS,UNIVERSITY OF OREGON,R01,2019,295000,0.040837947994814515
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9610628,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Infrastructure', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multi-task learning', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2019,224899,0.061685765538196866
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9783881,U01EB029373,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIBIB,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2019,611358,0.03807749999636406
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9666926,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2019,242725,0.037986825405608556
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9699440,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'machine learning algorithm', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2019,186101,0.044861187239205215
"Computational modeling of spatial genome organization and gene regulation PROJECT SUMMARY/ABSTRACT The three-dimensional (3D) organization of the genome plays an essential role in genome stability, gene regulation, and many diseases, including cancer. The recent development of high-throughput chromatin conformation capture (Hi-C) and its variants provide an unprecedented opportunity to investigate higher-order chromatin organization. Despite the rapidly accumulating resources for investigating 3D genome organization, our understanding of the regulatory mechanisms and functions of the genome organization remain largely incomplete. Hi-C analyses and 3D genome research are still in their early stage and face several challenges. First, high-resolution chromatin contact maps require extremely deep sequencing and hence have been achieved only for a few cell lines. Second, it is computationally challenging to complement 3D genome structure with one-dimensional (1D) genomic and epigenomic features. Third, recent studies have just begun to infer associations between chromatin interactions and genetic variants and to identify potential target genes of those variants at the genome-wide scale. Given these challenges and my unique multi-disciplinary training, my long-term research goal is to develop innovative computational and statistical methods to uncover the interplay between 3D genome structure and function. Speciﬁcally, in the next ﬁve years, I will i) develop computational approaches to enhance the resolution of existing Hi-C data and investigate ﬁne-scale 3D genome architecture as well as its spatiotemporal dynamics and ii) build scalable and interpretable machine learning models that leverage 1D epigenomic data to predict cell type-speciﬁc 3D chromatin interactions and gene expression and elucidate the function of 3D genome organization in gene regulation and human diseases. The completion of the proposed work will deepen our knowledge of 3D genome architecture as well as its functions in gene regulation and disease. PROJECT NARRATIVE The overarching mission of my research is to understand the interplay between genome architecture and gene regulation. Recent development of high-throughput chromatin conformation capture techniques has allowed us to look beyond the nucleotide sequence of DNA and investigate the principles of higher-order chromatin organization. I will develop innovative computational and statistical strategies to investigate 3D genome organization at an unprecedented scale, thereby elucidating the impacts of genome organization on gene regulation and disease.",Computational modeling of spatial genome organization and gene regulation,9798957,R35GM133678,"['3-Dimensional', 'Architecture', 'Base Sequence', 'Cell Line', 'Chromatin', 'Complement 3d', 'Computer Simulation', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Dimensions', 'Disease', 'Face', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome Stability', 'Genomics', 'Goals', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mission', 'Modeling', 'Play', 'Research', 'Resolution', 'Resources', 'Role', 'Statistical Methods', 'Structure', 'Techniques', 'Training', 'Variant', 'Work', 'cell type', 'chromosome conformation capture', 'deep sequencing', 'epigenomics', 'genetic variant', 'genome-wide', 'human disease', 'innovation', 'multidisciplinary', 'spatiotemporal']",NIGMS,UNIVERSITY OF CALIFORNIA RIVERSIDE,R35,2019,369984,0.006515071062863377
"Development of New Genome Editing Agents Using RNA Modifying Enzymes Komor – Project Summary/Abstract - “Development of New Genome Editing Agents Using RNA Modifying Enzymes”  While targeted genome editing, the introduction of a specific modification in genomic DNA, has the potential to allow researchers to study and better understand mechanisms of human genetic diseases, traditional genome editing methods (including CRISPR-Cas9) that rely on the initial introduction of double stranded DNA breaks (DSB) suffer from modest genome editing efficiencies as well as unwanted gene alterations (indels), particularly when attempting to correct point mutations. Recently, a class of genome editing agents called single base editors was developed that does not involve DSBs, but rather uses a dCas9-tethered single-stranded DNA (ssDNA) modifying enzyme to directly chemically modify target nucleobases within a ~5 nucleotide window determined by the protospacer. Two classes of editors have been developed that use cytosine and adenine deamination chemistries to catalyze the conversion of C•G base pairs to T•A (CBEs), and A•T base pairs to G•C (ABEs), respectively. Here we propose the development and characterization of new base editors capable of facilitating new point mutations using methylation chemistry. We have use a bioinformatic approach to identify RNA modifying enzymes that have the potential to be repurposed into new base editors, and have rationally designed mutant libraries to use with directed evolution to convert these enzymes into base editors (Aim 1). Concurrently, we are developing a machine learning program that utilizes existing ssDNA modifying enzymes to identify putative mutations that will expand the substrate scope of the identified methyltransferases to ssDNA (Aim 2). Mutations identified from both strategies will then be tested and characterized for base editing in multiple orthogonal systems (Aim 3). The successful completion of the proposed work will represent a significant addition to existing base editing technologies, and will enable researchers to cleanly and efficiently install two additional types of point mutations into the genome of living cells, allowing researchers to quickly and effectively general model systems for the study of human genetic diseases. Komor – Project Narrative - “Development of New Genome Editing Agents Using RNA Modifying Enzymes” Base editing enables high efficiency genomic point mutation introduction in a variety of cell types and has the potential to allow researchers to better study human genetic diseases. We propose transformative improvements to current base editing technologies that will expand the types of point mutations that can be introduced by base editors. The tools developed here will enable researchers to cleanly and efficiently install additional types of point mutations into the genome of living cells for the study and potential treatment of human genetic diseases.",Development of New Genome Editing Agents Using RNA Modifying Enzymes,9876634,R21GM135736,"['Adenine', 'Adoption', 'Algorithms', 'Base Pairing', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'CRISPR/Cas technology', 'Case Study', 'Cell Line', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'Deamination', 'Development', 'Directed Molecular Evolution', 'Engineering', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Mutation', 'Generations', 'Genetic Diseases', 'Genome', 'Genomic DNA', 'Genomics', 'Human', 'Human Genetics', 'In Vitro', 'Individual', 'Inosine', 'Lesion', 'Libraries', 'Link', 'Machine Learning', 'Mammalian Cell', 'Measures', 'Mediating', 'Methods', 'Methylation', 'Methyltransferase', 'Modification', 'Mutation', 'Nucleotides', 'Pathogenicity', 'Point Mutation', 'Program Development', 'Proteins', 'Purines', 'Pyrimidine', 'RNA', 'Research Personnel', 'Single-Stranded DNA', 'Site', 'Specificity', 'System', 'Technology', 'Testing', 'Transfer RNA', 'Uracil', 'Variant', 'Work', 'adenosine deaminase', 'base', 'cell type', 'combat', 'design', 'genome editing', 'insertion/deletion mutation', 'machine learning algorithm', 'molecular dynamics', 'mutant', 'novel', 'nucleobase', 'preference', 'programs', 'tool', 'transition mutation', 'transversion mutation']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,205479,0.05372461942843878
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9766330,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'competitive environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2019,468098,0.04458101832368061
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9658531,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2019,479215,0.07518726299427876
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9751141,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2019,1186500,0.05413325088507007
"Interrogating regulatory variants by multiplexed genome editing A major result from recent genome wide association studies (GWAS) is that the majority of genetic variants driving common human diseases lie in regulatory, rather than protein-coding, regions. Massive efforts to map epigenomic features such as localization of histone modifications (HMs) and transcription factors (TFs) have paved the way toward understanding the regulatory genome. However, dissecting the impact of an individual non-coding variant remains an unsolved challenge.  A variety of computational methods have been proposed, such as quantitative trait loci (QTL) studies and machine learning techniques. However, these methods still do not provide conclusive information about causality of any specific non-coding mutation and lack gold-standard experimental results for evaluation. Several techniques are used to experimentally test the impact of individual regulatory variants. For example, massively parallel reporter assays (MPRA) synthesize thousands of oligonucleotides encoding mutated versions of putative regulatory elements placed in plasmids upstream of reporter genes. However, a major limitation is that tested sequences are outside of their endogenous chromosomal locus, and hence do not necessarily provide physiological relevance.  CRISPR enables targeted editing of genomic DNA. Indeed, CRISPR is widely used, but studies of individual point mutations have been primarily on a small scale and are usually limited to a handful of variants or to a single gene. The major throughput challenge in studying a specific variant using genome editing is in tying genotype to phenotype. Introducing individual mutations exhibits low efficiency, and thus there is a need for enrichment of the genotype or phenotype of interest prior to assessing the impact of a mutation on a phenotype, such as gene expression. Current enrichment methods either disrupt the physiological context or are low throughput. Recent efforts overcame these challenges using pooled editing to analyze thousands of mutations simultaneously, but were limited to variants in protein coding regions.  This proposal aims to develop a novel technique merging multiplexed genome editing of putative regulatory variants followed by chromatin immunoprecipitation sequencing (ChIP-seq) to simultaneously measure the impact of hundreds of non-coding variants on regulatory potential in their native genomic context. The key insight of the proposed approach is that mutations impacting epigenomic features can be measured both in genomic DNA and in phenotypic readouts such as ChIP-seq of TFs or HMs, avoiding the need for a selection step to connect genotypes with phenotypes. ​Aim 1 develops the pooled editing technique on a pilot set of previously validated regulatory variants. ​Aim 2 scales this approach to interrogate thousands of mutations at once. ​Aim 3 integrates experimental predictions with state of the art machine learning methods to evaluate and optimize computational methods for regulatory variant effect prediction. Recent studies have demonstrated that the majority of genetic changes in the population contributing to common human diseases, such as schizophrenia, heart disease, and diabetes, lie in regions of the genome that do not code for proteins, but rather regulate the expression of genes. Despite massive efforts to map regulatory regions across dozens of human cell types, it is still difficult to predict the effect of an individual non-coding mutation. This project develops a high-throughput genome editing technique to simultaneously measure the impact of hundreds of non-coding mutations on regulatory potential in their native genomic context, with the ultimate goal of interpreting genetic changes leading to human disease.",Interrogating regulatory variants by multiplexed genome editing,9761568,R21HG010070,"['Address', 'Affect', 'Allelic Imbalance', 'Automobile Driving', 'Binding', 'Biological Assay', 'CRISPR/Cas technology', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Computing Methodologies', 'DNA', 'Data Set', 'Diabetes Mellitus', 'Enhancers', 'Etiology', 'Evaluation', 'Exhibits', 'Frequencies', 'Gene Expression', 'Genes', 'Genome', 'Genomic DNA', 'Genomics', 'Genotype', 'Goals', 'Gold', 'HNF4A gene', 'Heart Diseases', 'HepG2', 'Hepatocyte', 'Human', 'Individual', 'Machine Learning', 'Malignant Epithelial Cell', 'Maps', 'Measures', 'Messenger RNA', 'Methods', 'Molecular', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Oligonucleotides', 'Open Reading Frames', 'Phenotype', 'Physiological', 'Plasmids', 'Point Mutation', 'Population', 'Primary carcinoma of the liver cells', 'Proteins', 'Quantitative Trait Loci', 'Regulatory Element', 'Reporter', 'Reporter Genes', 'Resources', 'Schizophrenia', 'Sorting - Cell Movement', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'cell type', 'epigenomics', 'genetic variant', 'genome editing', 'genome wide association study', 'histone modification', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'mRNA Expression', 'molecular phenotype', 'novel', 'transcription factor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,236250,-0.009664223666642754
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9626416,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Infrastructure', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2019,2000000,0.032497315773930335
"Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation Project Summary The ENCODE project has generated comprehensive maps of cis-regulatory elements (CREs) controlling the transcription of genes within the human genome. These maps have been crucial in our efforts to understand sequence variants linked to human traits and disease, as the majority of these variants are non- coding regulatory changes rather than amino acid substitutions. However, even though we know the locations of thousands of CREs, our understanding of how they operate is derived from a relatively small set of well- described examples. Therefore, we plan to directly characterize the function of ENCODE CREs at a genome- wide scale in multiple cell-types. This will transition the field of functional genomics from a simple map of regulatory elements towards a deep understanding of the fundamental rules governing regulatory logic down to the basepair resolution. Achieving this will dramatically expand ENCODE's utility by strengthening our ability to interpret the effects of natural human variation on gene regulation. We propose to directly measure regulatory activity of over 3% of the genome, pursuing loci highlighted as important by ENCODE and other functional data. We will first apply computational methods to identify the most biologically informative CREs, representing a diversity of regulatory logic and architecture, and will use machine learning techniques to prioritize functional variants for characterization relevant to common and rare human diseases, traits, and adaptation. Of these we will select 200,000 CREs and 300,000 variants, representing 100 Mb of genomic sequence, and characterize them using the massively parallel reporter assay (MPRA) to understand each element's regulatory activity. Then, to complement data from the MPRA, we will characterize additional 1 Mb regions across 10 loci using CRISPR-based non-coding screens to build a comprehensive picture of these loci. This strategy leverages the throughput and flexibility of MPRA while maintaining the connectivity of regulatory logic in the CRISPR-based screens, which perturb elements within their endogenous genomic context. This will help us judge the accuracy and completeness of ENCODE, while also providing data from both approaches to address a wide-variety of research questions. These methods are difficult to apply to disease relevant primary cells at full scale, but we will use the results of our MPRA and CRISPR screens to inform our models and better predict the fundamental rules of regulatory logic. We will then construct smaller, targeted libraries to test disease-specific variants in primary cells and use assays specific for each of three autoimmune diseases: type 1 diabetes, inflammatory bowel disease, and lupus. This approach will inform the research community on the rules governing the activity of the CREs mapped by the ENCODE project, and will simultaneously provide concrete information about the function of hundreds of thousands of sequence variants relevant for human traits, health, and disease. Project Narrative In our proposal we seek to extend the efforts by the ENCODE consortium and others who have made significant strides towards mapping the regulatory landscape of the human genome. We will apply large-scale functional characterization methods to directly test over 3% of the human genome for cis-regulatory activity. In doing so, we will create a resource that will improve our ability to pinpoint regulatory elements in our genome, increase our understanding of how they function, and aid in our ability to link genetic variation to human health and disease.",Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation,9766882,UM1HG009435,"['Address', 'Amino Acid Substitution', 'Architecture', 'Autoimmune Diseases', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Bypass', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Catalogs', 'Cell Differentiation process', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Dissection', 'Elements', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'HepG2', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inflammatory Bowel Diseases', 'Insulin-Dependent Diabetes Mellitus', 'K-562', 'Learning', 'Libraries', 'Link', 'Location', 'Logic', 'Lupus', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Resources', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'Work', 'base', 'biological systems', 'cell type', 'computerized tools', 'design', 'experimental study', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'improved', 'interest', 'tool', 'trait']",NHGRI,"BROAD INSTITUTE, INC.",UM1,2019,1497668,0.016774691031348137
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9678589,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'sensor', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2019,30442,-0.006031550746437383
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9785353,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Structure', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'nonsynonymous mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,ALBERT EINSTEIN COLLEGE OF MEDICINE,K99,2019,135945,0.04751096245193638
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9693291,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2019,397125,0.03854579376617691
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9765970,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Simulation', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2019,433604,0.051943468210594375
"Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation Summary Most variants obtained from tumor whole-genome sequences (WGS) occur in non- coding regions of the genome. Although variants in protein-coding regions have received the majority of attention, numerous studies have now noted the importance of non- coding variants in cancer. Identification of functional non-coding variants that drive tumor growth remains a challenge and a bottleneck for the use of whole-genome sequencing in the clinic. Cancer drivers are generally identified by the high frequency at which their mutations occur across patients. However, mutation rate is highly heterogeneous in non- coding regions and many non-driver elements show higher mutation frequency than others, such as regions bound by transcription factors in melanoma or regions replicating late during cell division in colon cancer. In this proposal, we will use high- throughput pooled CRISPR screen and novel computational methods to predict non- coding cancer drivers. We will quantitatively measure the impact of thousands of non- coding mutations using our innovative high-throughput CRISPR screen that directly ties modifications in the native context of the non-coding genome (i.e. not a reporter assay) to a cancer relevant phenotype (cell growth). The results of the screen will be used as training data for the development of NC_Driver, a computational cancer driver prediction tool. NC_Driver will integrate the signals of high functional impact with the recurrence of variants across multiple tumor samples to identify the non-coding mutations under positive selection in cancer. We will identify drivers in promoters, enhancers and CTCF insulators. CTCF insulators are the most mutated yet least studied regulatory elements in the cancer genome. Using this integrative experimental and computational approach, we will identify high-confidence candidate drivers. Finally, we will perform functional evaluation of prioritized non-coding drivers in colorectal and prostate cancers. We will use CRISPR/Cas9 genome editing in patient-derived cell cultures to test 20 high-ranking candidate driver promoter/enhancer/insulator mutations. Overall, this proposal addresses the critical need to identify drivers in the non-coding genome and over long- term enable the maximal benefit of genome sequencing for each patient. Project Narrative Cancer genomes contain thousands of mutations but only a few of them play an important role in cancer proliferation and are called drivers. Most of the mutations occur in regions of the genome that do not make proteins, yet the majority of previous studies have focused on protein-coding regions. In this proposal, we will use integrative computational and experimental approaches to identify drivers in the non-protein-coding regions of the genome.",Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation,9831005,R01CA218668,"['Accounting', 'Address', 'Attention', 'Benchmarking', 'Biological Assay', 'CRISPR screen', 'CRISPR/Cas technology', 'Cancer Patient', 'Catalogs', 'Cell Culture Techniques', 'Cell Line', 'Cell Survival', 'Cell division', 'Cells', 'Chromatin', 'Clinic', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Colon', 'Colon Carcinoma', 'Colorectal Cancer', 'Computer Simulation', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Dissection', 'Elements', 'Enhancers', 'Evaluation', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Heterogeneity', 'Institutes', 'Knock-in', 'Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methods', 'Modification', 'Molecular Conformation', 'Mutagenesis', 'Mutate', 'Mutation', 'Nature', 'Open Reading Frames', 'Parents', 'Patients', 'Phenotype', 'Play', 'Prostate', 'Proteins', 'Recurrence', 'Regulatory Element', 'Reporter', 'Research', 'Role', 'Running', 'Sampling', 'Screening Result', 'Signal Transduction', 'Somatic Mutation', 'Statistical Algorithm', 'Structure', 'Targeted Resequencing', 'Testing', 'Training', 'Transcript', 'Untranslated RNA', 'Validation', 'Variant', 'Xenograft procedure', 'actionable mutation', 'base', 'biobank', 'cancer genome', 'cancer type', 'cell growth', 'cohort', 'colon cancer cell line', 'deep learning', 'genome editing', 'genome sequencing', 'genome-wide', 'high throughput screening', 'innovation', 'knock-down', 'melanoma', 'novel', 'precision medicine', 'promoter', 'tool', 'transcription factor', 'tumor', 'tumor growth', 'tumor heterogeneity', 'tumor microenvironment', 'tumorigenesis', 'tumorigenic', 'whole genome']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,113967,0.01625108602560216
"Predicting and analyzing variation in cellular interactomes Project Summary Over the last two decades, significant experimental efforts have determined large sets of “reference” interactions for humans and other model organisms, along with substantial knowledge about the binding specificities of proteins, including for a large fraction of human transcription factors (TFs). The resulting data have proven to be an incredibly useful resource for understanding how cells function; nevertheless, they do not capture how molecular interactions and networks are different from the reference across individuals. Indeed, while human genomes in both healthy and disease populations are rapidly being sequenced, the corresponding individual-specific interaction networks remain largely unexamined; this represents a major gap in our knowledge, as mutations that alter molecular interactions underlie a wide range of human diseases. Further, the substantial amount of genetic variation across populations makes it infeasible in the near term to experimentally determine per-individual interaction networks. Thus our long-term goal is to develop computational methods to uncover whether and how mutations within coding and non-coding portions of the genome perturb cellular interactions and networks. Our specific aims are: (1) We will develop computational structure-based approaches to identify and catalog, at proteome-scale, variations within proteins that are likely to impact their ability to bind with DNA, RNA, small molecules, peptides or ions, thereby providing a comprehensive resource for analyzing protein interaction variation. (2) We will develop novel structure-based and probabilistic methods to predict how DNA-binding specificities are altered when a TF is mutated; since mutated TFs have been linked to numerous diseases, this will be a great aid in understanding disease networks and pathology. (3) We will develop new methods to uncover non-coding somatic mutations that alter human regulatory networks in cancer; this is a critical step towards ultimately uncovering patient-specific cancer networks. Overall by pursuing these aims—which integrate mutational information with existing knowledge about reference interactions, interfaces and specificities—we will develop novel computational methods that will significantly advance our understanding of molecular interactions perturbed in disease and healthy contexts. Narrative The proposed research will yield new software tools that predict whether specific genetic mutations alter molecular interactions and networks. Since many human diseases are caused by mutations that affect molecular interactions, this research will expand our understanding of the underlying basis of disease and will provide new avenues for diagnosis and treatment.",Predicting and analyzing variation in cellular interactomes,9740714,R01GM076275,"['Affect', 'Alleles', 'Amino Acid Sequence', 'Animal Model', 'Binding', 'Binding Proteins', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Process', 'Catalogs', 'Cell physiology', 'Code', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Binding', 'DNA Sequence Alteration', 'DNA-Protein Interaction', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Human Genome', 'Individual', 'Infrastructure', 'Internet', 'Ions', 'Knowledge', 'Ligand Binding', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Mutagenesis', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Organism', 'Pathology', 'Patients', 'Pattern', 'Peptides', 'Play', 'Population', 'Property', 'Protein Analysis', 'Proteins', 'Proteome', 'RNA', 'Regulator Genes', 'Research', 'Resources', 'Sampling', 'Site', 'Software Tools', 'Somatic Mutation', 'Specificity', 'Structure', 'Untranslated RNA', 'Variant', 'Work', 'Zinc Fingers', 'base', 'cancer genome', 'disease-causing mutation', 'experimental study', 'human disease', 'improved', 'interest', 'knowledge base', 'learning strategy', 'novel', 'predictive tools', 'preference', 'small molecule', 'software development', 'transcription factor', 'tumor', 'virtual']",NIGMS,PRINCETON UNIVERSITY,R01,2019,312660,0.010688869360500978
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9693289,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2019,864186,0.007318566013144837
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9731524,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2019,300000,0.02834256577103281
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9825986,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Simulation', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'actionable mutation', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2019,232291,0.050223505106682366
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9702844,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'causal variant', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'web server', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,300191,-0.002685097264700005
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9653955,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,587448,0.034440739395652294
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9794010,F31HD095571,"['Affect', 'Amino Acids', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2019,45016,0.007606627708106245
"Genome Based Influenza Vaccine Strain Selection using Machine Learning No abstract available PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection using Machine Learning,10044945,R01AI116744,[' '],NIAID,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,147704,0.04122042797376158
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9737246,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Stem cells', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2019,336177,0.025793680623149583
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9729028,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2019,1002519,0.03149203837876631
"The Enzymatic Reader Project Summary At this point in time, it is generally understood and agreed upon that single-molecule sequencing (SMS) is the future of genomics, transcriptomics, epigenomics, and epitranscriptomics due to its significant advantages over other technologies and methods. However, in order for these advantages to be fully realized, and for SMS to become the “gold standard” sequencing approach, significant issues and hurdles must be solved and overcome. During this program, Electronic BioSciences, Inc. (EBS) aims to demonstrate a completely new and enabling SMS method that will possess the ability to directly and correctly identify individual nucleotides, including chemically modified nucleotides. During this project, we will both demonstrate the ability of this entirely new sequencing approach to sequence DNA with high accuracy (directly comparing the obtained accuracy, throughput, error mechanisms and associated rates to other SMS approaches) and correctly identify (and sequence) 5-methylcytosine (5mC) and its derivatives, at the single molecule level. At the conclusion of this Phase I project, we will have successfully demonstrated an entirely new and dramatically improved SMS approach, and reduced the associated risks involved with its full future commercial developments. There is a current need within the field of next generation sequencing (NGS) or so called third generation sequencing (TGS) for new, enabling instrumentation that is capable of high-accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats. The entirely new SMS methodology that will be developed during this project will overcome known hurdles and limitations of currently available NGS, TGS, and SMS technologies, resulting in technology that is cost-efficient, highly accurate, easy to setup and utilize, capable of de novo sequencing and modified base calling, and yields highly simplistic data for easy analysis and post possessing. Through significant advancements made during this program, this resulting technology will revolutionize the use of the genome and epigenome, radically change standard R&D and clinical practices, and greatly advance clinical diagnostics, prognostics, and therapeutic decision making. Project Narrative The novel single-molecule sequencing (SMS) technology developed during this project will enable high- accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats via a cost-efficient and easy-to-use methodology. The impact of these advances in SMS will eventually enable wide-scale, routine clinical care and diagnostics toward advanced precision medicine, not just R&D. The performance and accessibility of such technology will transform the understanding and application of genomics and epigenomics, the associated clinical practices, that ability to provide precision clinical diagnostics, prognostics, and therapeutic decision making for improved public healthcare and wellbeing.",The Enzymatic Reader,9677956,R43HG010427,"['Biological', 'Biological Sciences', 'Caliber', 'Chemicals', 'Chemistry', 'Church', 'Complex', 'DNA Primers', 'DNA Sequence', 'DNA polymerase A', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disadvantaged', 'Drops', 'Electrodes', 'Enzymes', 'Evaluation', 'Future', 'Genome', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Ions', 'Label', 'Length', 'Lipid Bilayers', 'Logistics', 'Methodology', 'Methods', 'Motor', 'Movement', 'Noise', 'Nucleotides', 'Performance', 'Personal Satisfaction', 'Phase', 'Polymerase', 'Polymers', 'Preparation', 'Process', 'Proteins', 'RNA', 'Reader', 'Reading Frames', 'Reproducibility', 'Risk', 'Sampling', 'Side', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Tools', 'Speed', 'Stretching', 'System', 'Technology', 'Therapeutic', 'Third Generation Sequencing', 'Time', 'base', 'clinical care', 'clinical diagnostics', 'clinical practice', 'cost', 'cost efficient', 'electric field', 'epigenome', 'epigenomics', 'epitranscriptomics', 'improved', 'instrumentation', 'machine learning algorithm', 'nanopore', 'next generation sequencing', 'novel', 'precision medicine', 'prevent', 'prognostic', 'programs', 'research and development', 'single molecule', 'solid state', 'transcriptomics']",NHGRI,"ELECTRONIC BIOSCIENCES, INC.",R43,2019,247611,0.038591114722052046
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9735436,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,454366,0.0038424298917522095
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9406205,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2018,372603,0.061685765538196866
"Population genomics of adaptation Project Summary Malaria that results from Plasmodium falciparum is among the most globally devastating human diseases. The principle vector of malaria, mosquitoes of the Anopheles gambiae species complex, are thus central targets for controlling the human health burden of Plasmodium. For nearly two decades, there have been large-scale, coordinated efforts to diminish mosquito populations, generally through spraying and insecticide treated bed nets. Indeed such control efforts have now led to a nearly 50% decrease in the rates of malaria infection in many parts of sub-Saharan Africa. At present, however, control efforts of A. gambiae are being threatened by evolutionary responses within mosquitos: A. gambiae populations have shown increases in insecticide resistance as well as behavioral adaptations that allow mosquitos to avoid spraying all together. Thus adaptation of mosquitos to the control efforts themselves is currently a risk to maintain the gains made in the fight against malaria. In this proposal we lay out an integrated population genomic approach for systematically identifying regions of the A. gambiae genome that are evolving adaptively in response to ongoing control efforts. Our approach centers upon state-of-the-art supervised machine learning techniques that we have recently introduced for finding the signatures of selective sweeps in genomes (Schrider and Kern, 2016), coupled with the large-scale population genomic datasets currently in production by the Ag1000G consortium. Project Narrative Malaria is a mosquito-borne infectious disease that has enormous impacts on human health globally. For the past 16 years, large gains have been made in decreasing the rate of malaria transmission through control of its mosquito vector Anopheles gambiae; unfortunately at present these control efforts are in danger of collapse due to the evolution of insecticide resistance in the mosquitos. We aim to discover the genomic targets of such resistance through the development of sophisticated population genomic approaches and their application to state-of- the-art genome sequence datasets from Anopheles gambiae.",Population genomics of adaptation,9554999,R01GM117241,"['Affect', 'Africa South of the Sahara', 'Anopheles Genus', 'Anopheles gambiae', 'Awareness', 'Back', 'Beds', 'Behavioral', 'Catalogs', 'Cessation of life', 'Chromosomes', 'Classification', 'Complex', 'Coupled', 'Culicidae', 'Data', 'Data Set', 'Dependence', 'Detection', 'Development', 'Distant', 'Equipment and supply inventories', 'Evolution', 'Frequencies', 'Funding', 'Genome', 'Genomic approach', 'Genomics', 'Geography', 'Goals', 'Health', 'Human', 'Individual', 'Insecticide Resistance', 'Insecticides', 'Link', 'Location', 'Machine Learning', 'Malaria', 'Methodology', 'Methods', 'Mosquito-borne infectious disease', 'Mutation', 'Pattern', 'Phase', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Prevalence', 'Production', 'Recording of previous events', 'Research', 'Residual state', 'Resistance', 'Risk', 'Sampling', 'Supervision', 'Techniques', 'Time', 'Variant', 'Work', 'deep learning', 'deep neural network', 'fight against', 'genomic data', 'global health', 'human disease', 'learning strategy', 'malaria infection', 'malaria transmission', 'markov model', 'novel', 'recurrent neural network', 'resistance allele', 'response', 'tool', 'vector', 'vector control', 'vector mosquito']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",R01,2018,18944,0.040837947994814515
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell- based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off- target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9678132,U01HL145793,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety testing', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NHLBI,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2018,651251,0.03807749999636406
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9617314,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2018,249000,0.037986825405608556
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9507167,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2018,242837,0.044861187239205215
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9486266,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2018,479215,0.07518726299427876
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9531422,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,468098,0.04458101832368061
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9562959,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2018,1186500,0.05413325088507007
"Interrogating regulatory variants by multiplexed genome editing A major result from recent genome wide association studies (GWAS) is that the majority of genetic variants driving common human diseases lie in regulatory, rather than protein-coding, regions. Massive efforts to map epigenomic features such as localization of histone modifications (HMs) and transcription factors (TFs) have paved the way toward understanding the regulatory genome. However, dissecting the impact of an individual non-coding variant remains an unsolved challenge.  A variety of computational methods have been proposed, such as quantitative trait loci (QTL) studies and machine learning techniques. However, these methods still do not provide conclusive information about causality of any specific non-coding mutation and lack gold-standard experimental results for evaluation. Several techniques are used to experimentally test the impact of individual regulatory variants. For example, massively parallel reporter assays (MPRA) synthesize thousands of oligonucleotides encoding mutated versions of putative regulatory elements placed in plasmids upstream of reporter genes. However, a major limitation is that tested sequences are outside of their endogenous chromosomal locus, and hence do not necessarily provide physiological relevance.  CRISPR enables targeted editing of genomic DNA. Indeed, CRISPR is widely used, but studies of individual point mutations have been primarily on a small scale and are usually limited to a handful of variants or to a single gene. The major throughput challenge in studying a specific variant using genome editing is in tying genotype to phenotype. Introducing individual mutations exhibits low efficiency, and thus there is a need for enrichment of the genotype or phenotype of interest prior to assessing the impact of a mutation on a phenotype, such as gene expression. Current enrichment methods either disrupt the physiological context or are low throughput. Recent efforts overcame these challenges using pooled editing to analyze thousands of mutations simultaneously, but were limited to variants in protein coding regions.  This proposal aims to develop a novel technique merging multiplexed genome editing of putative regulatory variants followed by chromatin immunoprecipitation sequencing (ChIP-seq) to simultaneously measure the impact of hundreds of non-coding variants on regulatory potential in their native genomic context. The key insight of the proposed approach is that mutations impacting epigenomic features can be measured both in genomic DNA and in phenotypic readouts such as ChIP-seq of TFs or HMs, avoiding the need for a selection step to connect genotypes with phenotypes. ​Aim 1 develops the pooled editing technique on a pilot set of previously validated regulatory variants. ​Aim 2 scales this approach to interrogate thousands of mutations at once. ​Aim 3 integrates experimental predictions with state of the art machine learning methods to evaluate and optimize computational methods for regulatory variant effect prediction. Recent studies have demonstrated that the majority of genetic changes in the population contributing to common human diseases, such as schizophrenia, heart disease, and diabetes, lie in regions of the genome that do not code for proteins, but rather regulate the expression of genes. Despite massive efforts to map regulatory regions across dozens of human cell types, it is still difficult to predict the effect of an individual non-coding mutation. This project develops a high-throughput genome editing technique to simultaneously measure the impact of hundreds of non-coding mutations on regulatory potential in their native genomic context, with the ultimate goal of interpreting genetic changes leading to human disease.",Interrogating regulatory variants by multiplexed genome editing,9509167,R21HG010070,"['Address', 'Affect', 'Allelic Imbalance', 'Automobile Driving', 'Binding', 'Biological Assay', 'CRISPR/Cas technology', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Computing Methodologies', 'DNA', 'Data Set', 'Diabetes Mellitus', 'Enhancers', 'Etiology', 'Evaluation', 'Exhibits', 'Frequencies', 'Gene Expression', 'Genes', 'Genome', 'Genomic DNA', 'Genomics', 'Genotype', 'Goals', 'Gold', 'HNF4A gene', 'Heart Diseases', 'HepG2', 'Hepatocyte', 'Human', 'Individual', 'Machine Learning', 'Malignant Epithelial Cell', 'Maps', 'Measures', 'Messenger RNA', 'Methods', 'Molecular', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Oligonucleotides', 'Open Reading Frames', 'Phenotype', 'Physiological', 'Plasmids', 'Point Mutation', 'Population', 'Primary carcinoma of the liver cells', 'Proteins', 'Quantitative Trait Loci', 'Regulatory Element', 'Reporter', 'Reporter Genes', 'Resources', 'Schizophrenia', 'Sorting - Cell Movement', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'cell type', 'epigenomics', 'genetic variant', 'genome editing', 'genome wide association study', 'histone modification', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'mRNA Expression', 'molecular phenotype', 'novel', 'transcription factor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2018,196302,-0.009664223666642754
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9420662,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2018,2000000,0.032497315773930335
"Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation Project Summary The ENCODE project has generated comprehensive maps of cis-regulatory elements (CREs) controlling the transcription of genes within the human genome. These maps have been crucial in our efforts to understand sequence variants linked to human traits and disease, as the majority of these variants are non- coding regulatory changes rather than amino acid substitutions. However, even though we know the locations of thousands of CREs, our understanding of how they operate is derived from a relatively small set of well- described examples. Therefore, we plan to directly characterize the function of ENCODE CREs at a genome- wide scale in multiple cell-types. This will transition the field of functional genomics from a simple map of regulatory elements towards a deep understanding of the fundamental rules governing regulatory logic down to the basepair resolution. Achieving this will dramatically expand ENCODE's utility by strengthening our ability to interpret the effects of natural human variation on gene regulation. We propose to directly measure regulatory activity of over 3% of the genome, pursuing loci highlighted as important by ENCODE and other functional data. We will first apply computational methods to identify the most biologically informative CREs, representing a diversity of regulatory logic and architecture, and will use machine learning techniques to prioritize functional variants for characterization relevant to common and rare human diseases, traits, and adaptation. Of these we will select 200,000 CREs and 300,000 variants, representing 100 Mb of genomic sequence, and characterize them using the massively parallel reporter assay (MPRA) to understand each element's regulatory activity. Then, to complement data from the MPRA, we will characterize additional 1 Mb regions across 10 loci using CRISPR-based non-coding screens to build a comprehensive picture of these loci. This strategy leverages the throughput and flexibility of MPRA while maintaining the connectivity of regulatory logic in the CRISPR-based screens, which perturb elements within their endogenous genomic context. This will help us judge the accuracy and completeness of ENCODE, while also providing data from both approaches to address a wide-variety of research questions. These methods are difficult to apply to disease relevant primary cells at full scale, but we will use the results of our MPRA and CRISPR screens to inform our models and better predict the fundamental rules of regulatory logic. We will then construct smaller, targeted libraries to test disease-specific variants in primary cells and use assays specific for each of three autoimmune diseases: type 1 diabetes, inflammatory bowel disease, and lupus. This approach will inform the research community on the rules governing the activity of the CREs mapped by the ENCODE project, and will simultaneously provide concrete information about the function of hundreds of thousands of sequence variants relevant for human traits, health, and disease. Project Narrative In our proposal we seek to extend the efforts by the ENCODE consortium and others who have made significant strides towards mapping the regulatory landscape of the human genome. We will apply large-scale functional characterization methods to directly test over 3% of the human genome for cis-regulatory activity. In doing so, we will create a resource that will improve our ability to pinpoint regulatory elements in our genome, increase our understanding of how they function, and aid in our ability to link genetic variation to human health and disease.",Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation,9696513,UM1HG009435,"['Address', 'Amino Acid Substitution', 'Architecture', 'Autoimmune Diseases', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Bypass', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Catalogs', 'Cell Differentiation process', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Dissection', 'Elements', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'HepG2', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inflammatory Bowel Diseases', 'Insulin-Dependent Diabetes Mellitus', 'K-562', 'Learning', 'Libraries', 'Link', 'Location', 'Logic', 'Lupus', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Resources', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'Work', 'base', 'biological systems', 'cell type', 'computerized tools', 'design', 'experimental study', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'improved', 'interest', 'tool', 'trait']",NHGRI,"BROAD INSTITUTE, INC.",UM1,2018,933353,0.016774691031348137
"Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation Project Summary The ENCODE project has generated comprehensive maps of cis-regulatory elements (CREs) controlling the transcription of genes within the human genome. These maps have been crucial in our efforts to understand sequence variants linked to human traits and disease, as the majority of these variants are non- coding regulatory changes rather than amino acid substitutions. However, even though we know the locations of thousands of CREs, our understanding of how they operate is derived from a relatively small set of well- described examples. Therefore, we plan to directly characterize the function of ENCODE CREs at a genome- wide scale in multiple cell-types. This will transition the field of functional genomics from a simple map of regulatory elements towards a deep understanding of the fundamental rules governing regulatory logic down to the basepair resolution. Achieving this will dramatically expand ENCODE's utility by strengthening our ability to interpret the effects of natural human variation on gene regulation. We propose to directly measure regulatory activity of over 3% of the genome, pursuing loci highlighted as important by ENCODE and other functional data. We will first apply computational methods to identify the most biologically informative CREs, representing a diversity of regulatory logic and architecture, and will use machine learning techniques to prioritize functional variants for characterization relevant to common and rare human diseases, traits, and adaptation. Of these we will select 200,000 CREs and 300,000 variants, representing 100 Mb of genomic sequence, and characterize them using the massively parallel reporter assay (MPRA) to understand each element's regulatory activity. Then, to complement data from the MPRA, we will characterize additional 1 Mb regions across 10 loci using CRISPR-based non-coding screens to build a comprehensive picture of these loci. This strategy leverages the throughput and flexibility of MPRA while maintaining the connectivity of regulatory logic in the CRISPR-based screens, which perturb elements within their endogenous genomic context. This will help us judge the accuracy and completeness of ENCODE, while also providing data from both approaches to address a wide-variety of research questions. These methods are difficult to apply to disease relevant primary cells at full scale, but we will use the results of our MPRA and CRISPR screens to inform our models and better predict the fundamental rules of regulatory logic. We will then construct smaller, targeted libraries to test disease-specific variants in primary cells and use assays specific for each of three autoimmune diseases: type 1 diabetes, inflammatory bowel disease, and lupus. This approach will inform the research community on the rules governing the activity of the CREs mapped by the ENCODE project, and will simultaneously provide concrete information about the function of hundreds of thousands of sequence variants relevant for human traits, health, and disease. Project Narrative In our proposal we seek to extend the efforts by the ENCODE consortium and others who have made significant strides towards mapping the regulatory landscape of the human genome. We will apply large-scale functional characterization methods to directly test over 3% of the human genome for cis-regulatory activity. In doing so, we will create a resource that will improve our ability to pinpoint regulatory elements in our genome, increase our understanding of how they function, and aid in our ability to link genetic variation to human health and disease.",Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation,9564177,UM1HG009435,"['Address', 'Amino Acid Substitution', 'Architecture', 'Autoimmune Diseases', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Bypass', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Catalogs', 'Cell Differentiation process', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Dissection', 'Elements', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'HepG2', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inflammatory Bowel Diseases', 'Insulin-Dependent Diabetes Mellitus', 'K-562', 'Learning', 'Libraries', 'Link', 'Location', 'Logic', 'Lupus', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Resources', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'Work', 'base', 'biological systems', 'cell type', 'computerized tools', 'design', 'experimental study', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'improved', 'interest', 'tool', 'trait']",NHGRI,"BROAD INSTITUTE, INC.",UM1,2018,500000,0.016774691031348137
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9527264,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell Count', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",K99,2018,40760,0.04751096245193638
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9498252,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'cancer therapy', 'computerized data processing', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",R01,2018,158992,0.03854579376617691
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9509468,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,300000,0.02834256577103281
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9483341,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2018,864186,0.007318566013144837
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases Project Summary (unchanged) Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically “on” and “off” state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by a diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: · To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity · To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. Health Narrative (unchanged) Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9700377,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Development', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Research', 'Research Personnel', 'Signal Transduction', 'Site', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'inhibitor/antagonist', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,74718,0.02627223950738813
"Development of a Neuronal Regulatory Lexicon DESCRIPTION (provided by applicant): This proposal builds upon our successes in the first funding cycle, and technological advances in in the wider scientific community. We will expand our understanding of the biology and sequence-based encryption of transcriptional regulatory instructions in clinically pertinent neuronal populations, focusing on tyrosine hydroxylase (Th)-expressing ventral midbrain neurons that are compromised in Parkinson's disease and certain behavioral and neuropsychiatric disorders. In recent years, we have made great strides in characterizing regulatory control at specific neurogenic loci by generating, validating and publicly depositing huge catalogs of neuronal enhancers. We have developed and implemented computational strategies that catalog key motif combinations that identify neuronal enhancers, and developed sequence- based vocabularies (classifiers) for neuroanatomical domains (forebrain, midbrain, hindbrain) among other more homogenous isolated cell populations. By integrating our experiences in functional and computational genomics we have been able to indict several disease-associated variants in pertinent biological processes. We are also beginning to develop the capacity to impute the functional impact of non-coding variation from primary sequence alone.  Efforts to understand the architecture of human complex disease through Genome Wide Association Studies have drawn increased attention to potential roles played by regulatory variation. Thus, understanding the connections between regulatory variants and disease risk is very important. We propose detailed characterization of cell-type appropriate genome-wide regulatory sequence catalogs, isolating labeled dopaminergic neurons ex vivo at multiple time points (Aim 1). We will functionally validate the catalogs and define the sequence motifs that specify their function, developing computational classifiers to identify human DA enhancers, and assaying the functional impact of disease-associated variants therein (Aim 2). We will determine the relationship between distal-acting regulatory sequences and their cognate genes using cutting edge chromatin conformation capture (3C)-based strategies to reveal enhancers- promoter interactions. Then we will determine the consequences of deleting selected enhancers using contemporary genome editing strategies (Aim 3). This proposal takes crucial next steps towards a neuronal regulatory lexicon that can inform our observation of disease-associated variation in non-coding, putative regulatory sequence space. PUBLIC HEALTH RELEVANCE:  We wish to better understand how the regulatory instructions are encoded in DNA sequence, telling critical genes when and where to be switched on/off. We will focus on neurons that are lost in disorders like Parkinson's disease, prioritizing the study o genes implicated in related disorders. Our work will provide new insight into the identity, composition and biological requirement for these gene switches, informing our understanding of mutations that contribute to common genetic disorders.",Development of a Neuronal Regulatory Lexicon,9511921,R01NS062972,"['Affect', 'Alleles', 'Architecture', 'Attention', 'Base Sequence', 'Behavior Disorders', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Catalogs', 'Cells', 'ChIP-seq', 'Chromatin', 'Chromatin Conformation Capture and Sequencing', 'Clinical', 'Communities', 'Complex', 'Congenital Megacolon', 'DNA Sequence', 'Data', 'Deposition', 'Development', 'Disease', 'Dissection', 'Distal', 'Dopamine', 'Embryonic Development', 'Enhancers', 'Functional disorder', 'Funding', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic Diseases', 'Genetic Transcription', 'Genomics', 'Human', 'Human Genome', 'Instruction', 'Label', 'Light', 'Machine Learning', 'Midbrain structure', 'Mitotic', 'Mus', 'Mutate', 'Mutation', 'Neurons', 'Nucleotides', 'Ontology', 'Orthologous Gene', 'Output', 'Parkinson Disease', 'Phenotype', 'Play', 'Population', 'Prosencephalon', 'Role', 'Satiation', 'Specific qualifier value', 'Switch Genes', 'Syndrome', 'Time', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Transgenic Organisms', 'Tyrosine 3-Monooxygenase', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Work', 'Zebrafish', 'addiction', 'base', 'cancer risk', 'cell type', 'chromosome conformation capture', 'disorder risk', 'dopaminergic neuron', 'encryption', 'experience', 'genetic architecture', 'genome editing', 'genome wide association study', 'genome-wide', 'hindbrain', 'human disease', 'insight', 'mutant', 'neuropsychiatric disorder', 'promoter', 'public health relevance', 'success', 'transcription factor', 'transcriptome sequencing']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2018,461240,0.0024845187532267043
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9494629,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,300473,-0.002685097264700005
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9539482,F31HD095571,"['Affect', 'Amino Acids', 'Autistic Disorder', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2018,44524,0.007606627708106245
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9518337,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2018,537909,0.034440739395652294
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9416160,R00HG008171,"['Advisory Committees', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Code', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'cancer drug resistance', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'targeted nucleases', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2018,242325,0.07196618703551978
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9548692,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2018,1002519,0.03149203837876631
"POPULATION GENOMICS OF ADAPTATION Project Summary Malaria that results from Plasmodium falciparum is among the most globally devastating human diseases. The principle vector of malaria, mosquitoes of the Anopheles gambiae species complex, are thus central targets for controlling the human health burden of Plasmodium. For nearly two decades, there have been large-scale, coordinated efforts to diminish mosquito populations, generally through spraying and insecticide treated bed nets. Indeed such control efforts have now led to a nearly 50% decrease in the rates of malaria infection in many parts of sub-Saharan Africa. At present, however, control efforts of A. gambiae are being threatened by evolutionary responses within mosquitos: A. gambiae populations have shown increases in insecticide resistance as well as behavioral adaptations that allow mosquitos to avoid spraying all together. Thus adaptation of mosquitos to the control efforts themselves is currently a risk to maintain the gains made in the fight against malaria. In this proposal we lay out an integrated population genomic approach for systematically identifying regions of the A. gambiae genome that are evolving adaptively in response to ongoing control efforts. Our approach centers upon state-of-the-art supervised machine learning techniques that we have recently introduced for finding the signatures of selective sweeps in genomes (Schrider and Kern, 2016), coupled with the large-scale population genomic datasets currently in production by the Ag1000G consortium. Project Narrative Malaria is a mosquito-borne infectious disease that has enormous impacts on human health globally. For the past 16 years, large gains have been made in decreasing the rate of malaria transmission through control of its mosquito vector Anopheles gambiae; unfortunately at present these control efforts are in danger of collapse due to the evolution of insecticide resistance in the mosquitos. We aim to discover the genomic targets of such resistance through the development of sophisticated population genomic approaches and their application to state-of- the-art genome sequence datasets from Anopheles gambiae.",POPULATION GENOMICS OF ADAPTATION,9815897,R01GM117241,[' '],NIGMS,UNIVERSITY OF OREGON,R01,2018,276973,0.040837947994814515
"Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants No abstract available PROJECT NARRATIVE Genome-wide association studies (GWAS) have successfully described the roles of many human genes by analyzing large populations with shared traits, but these phenotype-based methodologies have incompletely described the clinical implications of numerous genes. I propose to address this knowledge gap by taking an unbiased, genotype-first approach to describing the relationships between dysfunctional genes and human disease traits through gene-burden phenome-wide association studies (PheWAS), essentially intersecting data from our healthcare system-based biobank database comprised of genotype data, whole-exome sequencing, and electronic health records (EHR). In addition to capturing the disease implications of rare, loss-of-function mutations on a genome-wide scale, my proposed project has the potential to define the roles of known and novel gain-of-function mutations in human disease, offering a direction for follow-up functional studies as well as a platform for more efficient therapeutic discoveries.",Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants,9681800,F30HG010442,"['Address', 'African American', 'Animal Model', 'Authorization documentation', 'Basic Science', 'Big Data', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Doctor of Philosophy', 'Electronic Health Record', 'Environment', 'Fellowship', 'Frequencies', 'Funding', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genotype', 'Goals', 'Grant', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Laboratories', 'Literature', 'Measurement', 'Medicine', 'Mentorship', 'Methodology', 'Methods', 'Mutation', 'Natural Language Processing', 'Ontology', 'Participant', 'Patients', 'Pennsylvania', 'Phenotype', 'Physicians', 'Play', 'Population', 'Population Analysis', 'Privatization', 'Recontacts', 'Records', 'Regression Analysis', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Scientist', 'Serum', 'Structure', 'Students', 'Suggestion', 'Testing', 'Therapeutic', 'Tissue Model', 'Training', 'Universities', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'cardiometabolism', 'career', 'design', 'disease phenotype', 'exome sequencing', 'experimental study', 'follow-up', 'gain of function', 'gain of function mutation', 'gene discovery', 'gene product', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'human disease', 'human tissue', 'loss of function', 'loss of function mutation', 'medical schools', 'novel', 'phenome', 'pre-doctoral', 'precision medicine', 'programs', 'quantitative imaging', 'rare variant', 'recruit', 'symposium', 'text searching', 'tool', 'trait', 'translational approach']",NHGRI,UNIVERSITY OF PENNSYLVANIA,F30,2018,49524,-0.014486683385817888
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9205487,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2017,372603,0.061685765538196866
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9333402,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2017,37785,0.037986825405608556
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,9213314,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Supervision', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2017,17892,-0.005624878368696618
"Population genomics of adaptation Project Summary Malaria that results from Plasmodium falciparum is among the most globally devastating human diseases. The principle vector of malaria, mosquitoes of the Anopheles gambiae species complex, are thus central targets for controlling the human health burden of Plasmodium. For nearly two decades, there have been large-scale, coordinated efforts to diminish mosquito populations, generally through spraying and insecticide treated bed nets. Indeed such control efforts have now led to a nearly 50% decrease in the rates of malaria infection in many parts of sub-Saharan Africa. At present, however, control efforts of A. gambiae are being threatened by evolutionary responses within mosquitos: A. gambiae populations have shown increases in insecticide resistance as well as behavioral adaptations that allow mosquitos to avoid spraying all together. Thus adaptation of mosquitos to the control efforts themselves is currently a risk to maintain the gains made in the fight against malaria. In this proposal we lay out an integrated population genomic approach for systematically identifying regions of the A. gambiae genome that are evolving adaptively in response to ongoing control efforts. Our approach centers upon state-of-the-art supervised machine learning techniques that we have recently introduced for finding the signatures of selective sweeps in genomes (Schrider and Kern, 2016), coupled with the large-scale population genomic datasets currently in production by the Ag1000G consortium. Project Narrative Malaria is a mosquito-borne infectious disease that has enormous impacts on human health globally. For the past 16 years, large gains have been made in decreasing the rate of malaria transmission through control of its mosquito vector Anopheles gambiae; unfortunately at present these control efforts are in danger of collapse due to the evolution of insecticide resistance in the mosquitos. We aim to discover the genomic targets of such resistance through the development of sophisticated population genomic approaches and their application to state-of- the-art genome sequence datasets from Anopheles gambiae.",Population genomics of adaptation,9383198,R01GM117241,"['Affect', 'Africa South of the Sahara', 'Anopheles Genus', 'Anopheles gambiae', 'Awareness', 'Back', 'Beds', 'Behavioral', 'Biological Neural Networks', 'Catalogs', 'Cessation of life', 'Chromosomes', 'Classification', 'Complex', 'Coupled', 'Culicidae', 'Data', 'Data Set', 'Dependency', 'Detection', 'Development', 'Distant', 'Equipment and supply inventories', 'Evolution', 'Frequencies', 'Funding', 'Genome', 'Genomic approach', 'Genomics', 'Geography', 'Goals', 'Health', 'Human', 'Individual', 'Insecticide Resistance', 'Insecticides', 'Learning', 'Link', 'Location', 'Machine Learning', 'Malaria', 'Methodology', 'Methods', 'Mosquito-borne infectious disease', 'Mutation', 'Pattern', 'Phase', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Prevalence', 'Production', 'Recording of previous events', 'Recurrence', 'Research', 'Residual state', 'Resistance', 'Risk', 'Sampling', 'Supervision', 'Techniques', 'Time', 'Variant', 'Work', 'fight against', 'genomic data', 'global health', 'human disease', 'learning strategy', 'malaria infection', 'malaria transmission', 'markov model', 'novel', 'resistance allele', 'response', 'tool', 'vector', 'vector control', 'vector mosquito']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",R01,2017,295480,0.040837947994814515
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9344966,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Molecular Profiling', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2017,1186500,0.05413325088507007
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9353854,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Molecular Models', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2017,438098,0.04458101832368061
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9248178,U24HG009446,"['ATAC-seq', 'Alleles', 'Alpha Cell', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2017,2000000,0.032497315773930335
"Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation Project Summary The ENCODE project has generated comprehensive maps of cis-regulatory elements (CREs) controlling the transcription of genes within the human genome. These maps have been crucial in our efforts to understand sequence variants linked to human traits and disease, as the majority of these variants are non- coding regulatory changes rather than amino acid substitutions. However, even though we know the locations of thousands of CREs, our understanding of how they operate is derived from a relatively small set of well- described examples. Therefore, we plan to directly characterize the function of ENCODE CREs at a genome- wide scale in multiple cell-types. This will transition the field of functional genomics from a simple map of regulatory elements towards a deep understanding of the fundamental rules governing regulatory logic down to the basepair resolution. Achieving this will dramatically expand ENCODE's utility by strengthening our ability to interpret the effects of natural human variation on gene regulation. We propose to directly measure regulatory activity of over 3% of the genome, pursuing loci highlighted as important by ENCODE and other functional data. We will first apply computational methods to identify the most biologically informative CREs, representing a diversity of regulatory logic and architecture, and will use machine learning techniques to prioritize functional variants for characterization relevant to common and rare human diseases, traits, and adaptation. Of these we will select 200,000 CREs and 300,000 variants, representing 100 Mb of genomic sequence, and characterize them using the massively parallel reporter assay (MPRA) to understand each element's regulatory activity. Then, to complement data from the MPRA, we will characterize additional 1 Mb regions across 10 loci using CRISPR-based non-coding screens to build a comprehensive picture of these loci. This strategy leverages the throughput and flexibility of MPRA while maintaining the connectivity of regulatory logic in the CRISPR-based screens, which perturb elements within their endogenous genomic context. This will help us judge the accuracy and completeness of ENCODE, while also providing data from both approaches to address a wide-variety of research questions. These methods are difficult to apply to disease relevant primary cells at full scale, but we will use the results of our MPRA and CRISPR screens to inform our models and better predict the fundamental rules of regulatory logic. We will then construct smaller, targeted libraries to test disease-specific variants in primary cells and use assays specific for each of three autoimmune diseases: type 1 diabetes, inflammatory bowel disease, and lupus. This approach will inform the research community on the rules governing the activity of the CREs mapped by the ENCODE project, and will simultaneously provide concrete information about the function of hundreds of thousands of sequence variants relevant for human traits, health, and disease. Project Narrative In our proposal we seek to extend the efforts by the ENCODE consortium and others who have made significant strides towards mapping the regulatory landscape of the human genome. We will apply large-scale functional characterization methods to directly test over 3% of the human genome for cis-regulatory activity. In doing so, we will create a resource that will improve our ability to pinpoint regulatory elements in our genome, increase our understanding of how they function, and aid in our ability to link genetic variation to human health and disease.",Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation,9247640,UM1HG009435,"['Address', 'Amino Acid Substitution', 'Architecture', 'Autoimmune Diseases', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Bypass', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Catalogs', 'Cell Differentiation process', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Dissection', 'Elements', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'HepG2', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inflammatory Bowel Diseases', 'Insulin-Dependent Diabetes Mellitus', 'K-562', 'Learning', 'Libraries', 'Link', 'Location', 'Logic', 'Lupus', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Resources', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'Work', 'base', 'biological systems', 'cell type', 'computerized tools', 'design', 'experimental study', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'improved', 'interest', 'tool', 'trait']",NHGRI,"BROAD INSTITUTE, INC.",UM1,2017,654000,0.016774691031348137
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,9528959,U41HG007497,"['Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Computational algorithm', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Phenotype', 'Population', 'Process', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'experimental study', 'genetic analysis', 'genetic variant', 'improved', 'integration site', 'method development', 'novel', 'tool']",NHGRI,JACKSON LABORATORY,U41,2017,1986604,-0.007849102562145228
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,9203633,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Databases', 'DNA Integration', 'DNA Structure', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Dimensions', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gaussian model', 'Gene Components', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Minor Groove', 'Modeling', 'Molecular Biology', 'Molecular Conformation', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'experimental study', 'flexibility', 'genetic evolution', 'genome analysis', 'genome browser', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'predictive tools', 'public health relevance', 'three dimensional structure', 'tool', 'transcription factor', 'vector', 'whole genome']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,309913,0.03160693403767092
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9275537,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2017,864186,0.007318566013144837
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9301599,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2017,300000,0.02834256577103281
"Genomics-based prediction of antibiotic failure in S. aureus infections ﻿    DESCRIPTION (provided by applicant)    The Gram positive bacterium Staphylococcus aureus is both an asymptomatic human colonizer and a pathogen that can cause infections in multiple tissue sites, including blood, skin and soft tissue, bone, and internal organs. Methicillin resistant Staphylococcus aureus (MRSA) is a common cause of death by hospital infections (HA-MRSA) and is now also a common community acquired infection (CA-MRSA). Vancomycin (a glycopeptide antibiotic) is the most commonly prescribed drug to treat MRSA infections. High-level resistance (minimal inhibitory concentration (MIC) ≥16 μg/ml) to vancomycin encoded by the mobile vanA gene is rare due to a fitness burden on S. aureus. However, it is more common to encounter strains with mutations conferring intermediate resistance to vancomycin arising from selection during the course of antibiotic therapy. The genetic basis of these vancomycin intermediate S. aureus (VISA) and heterogeneous resistant (hVISA) (MIC 2-8 μg/ml) strains involves a large number of different genomic mutations that result in cell wall thickening through changes in cellular signaling and regulation. Routine phenotypic testing in clinical labs probably underestimates the incidence of VISA and hVISA. Due to the fact that mutations in several genes have been linked with VISA, genetic-based detection of intermediate vancomycin resistance has not been developed for routine clinical microbiological use. In our preliminary work, we created an extensive catalog of sequenced clinical and laboratory-selected VISA as well as databases of SNPs and genetic variation in thousands of public S. aureus genomes. In this work we plan to extend these studies toward development of a sequence-based testing protocol that could be used for large numbers of clinical strains. In Specific Aim 1 we plan to extend our knowledge of the mutations that cause VISA by sequencing a panel of 300 novel mutants strains spontaneously selected from 40 S. aureus parent genotypes. We estimate, based on the results of the preliminary data, that this number of strains will be sufficient identify mutations found in 95% of VISA strains. These data will be used for creation of a comprehensive VISA detection assay based on whole genome data with an accuracy of at least 95%. In Specific Aim 2 we will use the information learned from Aim 1 to create a multiplex PCR sequence test for VISA, VRSA and other resistance determinants of S. aureus based on the commercially available Fluidigm platform. We will ultimately aim to have an assay that can be used to monitor systemic MRSA infections, such as bacteremia, to detect development of VISA in its early stages in clinical specimens from the patient. The test will also be able to detect other S. aureus resistance phenotypes and call the genotype of the strain. PUBLIC HEALTH RELEVANCE    Vancomycin is an antibiotic commonly used to treat methicillin resistant Staphylococcus aureus (MRSA) infections in chronically ill patients. The efficacy of this relatively cheap and well-tolerated therapy is compromised by mutations in the genome of the bacterium. In this project we propose to develop a genetic test based on a library of MRSA genome sequences with known antibiotic susceptibility level that identifies bacteria with diminished resistance to vancomycin.",Genomics-based prediction of antibiotic failure in S. aureus infections,9241329,R21AI121860,"['Address', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotic susceptibility', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Base Sequence', 'Biological Assay', 'Blood', 'Catalogs', 'Cause of Death', 'Cell Wall', 'Chronically Ill', 'Clinical', 'Clinical Microbiology', 'Community-Acquired Infections', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Evolution', 'Failure', 'Frequencies', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Glycopeptide Antibiotics', 'Goals', 'Gram-Positive Bacteria', 'Healthcare', 'Human', 'Incidence', 'Infection', 'Intermediate resistance', 'Knowledge', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Methicillin', 'Modeling', 'Monitor', 'Mutation', 'Nosocomial Infections', 'Organ', 'Parents', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Protocols documentation', 'Regulation', 'Resistance', 'Signal Transduction', 'Site', 'Skin Tissue', 'Specimen', 'Staphylococcus aureus', 'Testing', 'Tissues', 'Training', 'Treatment Failure', 'University Hospitals', 'Vancomycin', 'Vancomycin Resistance', 'Vancomycin-resistant S. aureus', 'Variant', 'Virulence', 'Work', 'base', 'bone', 'design', 'economic cost', 'fitness', 'genetic predictors', 'genetic variant', 'interest', 'methicillin resistant Staphylococcus aureus', 'mortality', 'mutant', 'novel', 'pathogen', 'phenotypic data', 'pleiotropism', 'public health relevance', 'soft tissue', 'tool', 'whole genome']",NIAID,EMORY UNIVERSITY,R21,2017,195000,0.018518825332484733
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9275505,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2017,300742,-0.002685097264700005
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease. PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.",Integrative interpretation of the organismal consequences of non-coding variation,9228346,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biomedical Research', 'CRISPR/Cas technology', 'Cell Line', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex', 'Data', 'Data Set', 'Development', 'Disease', 'Event', 'Feedback', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Weight', 'candidate identification', 'clinical diagnostics', 'data resource', 'disease phenotype', 'exome', 'exome sequencing', 'experimental study', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'public health relevance', 'trait', 'transcription factor', 'whole genome']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,632716,-0.028693523309310506
"Development of a Neuronal Regulatory Lexicon DESCRIPTION (provided by applicant): This proposal builds upon our successes in the first funding cycle, and technological advances in in the wider scientific community. We will expand our understanding of the biology and sequence-based encryption of transcriptional regulatory instructions in clinically pertinent neuronal populations, focusing on tyrosine hydroxylase (Th)-expressing ventral midbrain neurons that are compromised in Parkinson's disease and certain behavioral and neuropsychiatric disorders. In recent years, we have made great strides in characterizing regulatory control at specific neurogenic loci by generating, validating and publicly depositing huge catalogs of neuronal enhancers. We have developed and implemented computational strategies that catalog key motif combinations that identify neuronal enhancers, and developed sequence- based vocabularies (classifiers) for neuroanatomical domains (forebrain, midbrain, hindbrain) among other more homogenous isolated cell populations. By integrating our experiences in functional and computational genomics we have been able to indict several disease-associated variants in pertinent biological processes. We are also beginning to develop the capacity to impute the functional impact of non-coding variation from primary sequence alone.  Efforts to understand the architecture of human complex disease through Genome Wide Association Studies have drawn increased attention to potential roles played by regulatory variation. Thus, understanding the connections between regulatory variants and disease risk is very important. We propose detailed characterization of cell-type appropriate genome-wide regulatory sequence catalogs, isolating labeled dopaminergic neurons ex vivo at multiple time points (Aim 1). We will functionally validate the catalogs and define the sequence motifs that specify their function, developing computational classifiers to identify human DA enhancers, and assaying the functional impact of disease-associated variants therein (Aim 2). We will determine the relationship between distal-acting regulatory sequences and their cognate genes using cutting edge chromatin conformation capture (3C)-based strategies to reveal enhancers- promoter interactions. Then we will determine the consequences of deleting selected enhancers using contemporary genome editing strategies (Aim 3). This proposal takes crucial next steps towards a neuronal regulatory lexicon that can inform our observation of disease-associated variation in non-coding, putative regulatory sequence space. PUBLIC HEALTH RELEVANCE:  We wish to better understand how the regulatory instructions are encoded in DNA sequence, telling critical genes when and where to be switched on/off. We will focus on neurons that are lost in disorders like Parkinson's disease, prioritizing the study o genes implicated in related disorders. Our work will provide new insight into the identity, composition and biological requirement for these gene switches, informing our understanding of mutations that contribute to common genetic disorders.",Development of a Neuronal Regulatory Lexicon,9291510,R01NS062972,"['Affect', 'Alleles', 'Architecture', 'Attention', 'Base Sequence', 'Behavior Disorders', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Catalogs', 'Cells', 'ChIP-seq', 'Chromatin', 'Clinical', 'Communities', 'Complex', 'Congenital Megacolon', 'DNA Sequence', 'Data', 'Deposition', 'Development', 'Disease', 'Dissection', 'Distal', 'Dopamine', 'Embryonic Development', 'Enhancers', 'Functional disorder', 'Funding', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Hereditary Disease', 'Human', 'Human Genome', 'Instruction', 'Label', 'Light', 'Machine Learning', 'Midbrain structure', 'Mitotic', 'Molecular Conformation', 'Mus', 'Mutate', 'Mutation', 'Neurons', 'Nucleotides', 'Ontology', 'Orthologous Gene', 'Output', 'Parkinson Disease', 'Phenotype', 'Play', 'Population', 'Prosencephalon', 'Role', 'Satiation', 'Specific qualifier value', 'Switch Genes', 'Time', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Transgenic Organisms', 'Tyrosine 3-Monooxygenase', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Work', 'Zebrafish', 'addiction', 'base', 'cancer risk', 'cell type', 'chromosome conformation capture', 'disorder risk', 'dopaminergic neuron', 'encryption', 'experience', 'genome editing', 'genome wide association study', 'genome-wide', 'hindbrain', 'human disease', 'insight', 'mutant', 'neuropsychiatric disorder', 'promoter', 'public health relevance', 'success', 'transcription factor', 'transcriptome sequencing']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2017,461190,0.0024845187532267043
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9258454,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2017,244439,0.07196618703551978
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9228843,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2017,1002725,0.03149203837876631
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8994718,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2016,370329,0.061685765538196866
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9180486,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'abstracting', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2016,83411,0.037986825405608556
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8991662,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2016,43576,-0.005624878368696618
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9172062,R01HG009188,"['Affect', 'Base Pairing', 'Binding', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'DNA', 'DNA Sequence', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Health Care Research', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Marketing', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modification', 'Molecular Models', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Process', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Staging', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'research study', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2016,584552,0.04458101832368061
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,9268117,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost effectiveness', 'cost efficient', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2016,1378926,0.06491952090906855
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,9103177,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'learning strategy', 'meetings', 'population based', 'programs', 'whole genome']",NHGRI,STANFORD UNIVERSITY,R01,2016,300000,0.03170340386643677
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,9208745,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'genetic variant', 'genome sequencing', 'improved', 'integration site', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2016,2868077,-0.007849102562145228
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,8998963,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome browser', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'predictive tools', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector', 'whole genome']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,306949,0.03160693403767092
"Discovery and analysis of structural variation in whole genome sequences DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities. PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.",Discovery and analysis of structural variation in whole genome sequences,9118280,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Alteration', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'genomic variation', 'improved', 'interest', 'markov model', 'rare variant', 'structural genomics', 'tool', 'virtual', 'whole genome']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,380625,-0.020258281418492043
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community.         PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.            ","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9132585,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Learning', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'research study', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2016,854333,0.007318566013144837
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9116916,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2016,300000,0.02834256577103281
"Genomics-based prediction of antibiotic failure in S. aureus infections ﻿    DESCRIPTION (provided by applicant)    The Gram positive bacterium Staphylococcus aureus is both an asymptomatic human colonizer and a pathogen that can cause infections in multiple tissue sites, including blood, skin and soft tissue, bone, and internal organs. Methicillin resistant Staphylococcus aureus (MRSA) is a common cause of death by hospital infections (HA-MRSA) and is now also a common community acquired infection (CA-MRSA). Vancomycin (a glycopeptide antibiotic) is the most commonly prescribed drug to treat MRSA infections. High-level resistance (minimal inhibitory concentration (MIC) ≥16 μg/ml) to vancomycin encoded by the mobile vanA gene is rare due to a fitness burden on S. aureus. However, it is more common to encounter strains with mutations conferring intermediate resistance to vancomycin arising from selection during the course of antibiotic therapy. The genetic basis of these vancomycin intermediate S. aureus (VISA) and heterogeneous resistant (hVISA) (MIC 2-8 μg/ml) strains involves a large number of different genomic mutations that result in cell wall thickening through changes in cellular signaling and regulation. Routine phenotypic testing in clinical labs probably underestimates the incidence of VISA and hVISA. Due to the fact that mutations in several genes have been linked with VISA, genetic-based detection of intermediate vancomycin resistance has not been developed for routine clinical microbiological use. In our preliminary work, we created an extensive catalog of sequenced clinical and laboratory-selected VISA as well as databases of SNPs and genetic variation in thousands of public S. aureus genomes. In this work we plan to extend these studies toward development of a sequence-based testing protocol that could be used for large numbers of clinical strains. In Specific Aim 1 we plan to extend our knowledge of the mutations that cause VISA by sequencing a panel of 300 novel mutants strains spontaneously selected from 40 S. aureus parent genotypes. We estimate, based on the results of the preliminary data, that this number of strains will be sufficient identify mutations found in 95% of VISA strains. These data will be used for creation of a comprehensive VISA detection assay based on whole genome data with an accuracy of at least 95%. In Specific Aim 2 we will use the information learned from Aim 1 to create a multiplex PCR sequence test for VISA, VRSA and other resistance determinants of S. aureus based on the commercially available Fluidigm platform. We will ultimately aim to have an assay that can be used to monitor systemic MRSA infections, such as bacteremia, to detect development of VISA in its early stages in clinical specimens from the patient. The test will also be able to detect other S. aureus resistance phenotypes and call the genotype of the strain.             PUBLIC HEALTH RELEVANCE    Vancomycin is an antibiotic commonly used to treat methicillin resistant Staphylococcus aureus (MRSA) infections in chronically ill patients. The efficacy of this relatively cheap and well-tolerated therapy is compromised by mutations in the genome of the bacterium. In this project we propose to develop a genetic test based on a library of MRSA genome sequences with known antibiotic susceptibility level that identifies bacteria with diminished resistance to vancomycin.            ",Genomics-based prediction of antibiotic failure in S. aureus infections,9017369,R21AI121860,"['Address', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotic susceptibility', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Base Sequence', 'Biological Assay', 'Blood', 'Cataloging', 'Catalogs', 'Cause of Death', 'Cell Wall', 'Chronically Ill', 'Clinical', 'Community-Acquired Infections', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Drug Prescriptions', 'Evolution', 'Failure', 'Frequencies', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Glycopeptide Antibiotics', 'Goals', 'Gram-Positive Bacteria', 'Healthcare', 'Human', 'Incidence', 'Infection', 'Intermediate resistance', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Methicillin', 'Modeling', 'Monitor', 'Mutation', 'Nosocomial Infections', 'Organ', 'Parents', 'Patients', 'Phenotype', 'Protocols documentation', 'Regulation', 'Resistance', 'Signal Transduction', 'Site', 'Skin Tissue', 'Specimen', 'Staging', 'Staphylococcus aureus', 'Testing', 'Tissues', 'Training', 'Treatment Failure', 'University Hospitals', 'Vancomycin', 'Vancomycin Resistance', 'Vancomycin-resistant S. aureus', 'Variant', 'Virulence', 'Work', 'base', 'bone', 'clinical sequencing', 'design', 'economic cost', 'fitness', 'genetic predictors', 'genetic variant', 'genome sequencing', 'interest', 'methicillin resistant Staphylococcus aureus', 'mortality', 'mutant', 'novel', 'pathogen', 'pleiotropism', 'public health relevance', 'soft tissue', 'tool', 'whole genome']",NIAID,EMORY UNIVERSITY,R21,2016,234000,0.018518825332484733
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases.         PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.            ",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9083570,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Time', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic evolution', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,300999,-0.002685097264700005
"Development of a Neuronal Regulatory Lexicon DESCRIPTION (provided by applicant): This proposal builds upon our successes in the first funding cycle, and technological advances in in the wider scientific community. We will expand our understanding of the biology and sequence-based encryption of transcriptional regulatory instructions in clinically pertinent neuronal populations, focusing on tyrosine hydroxylase (Th)-expressing ventral midbrain neurons that are compromised in Parkinson's disease and certain behavioral and neuropsychiatric disorders. In recent years, we have made great strides in characterizing regulatory control at specific neurogenic loci by generating, validating and publicly depositing huge catalogs of neuronal enhancers. We have developed and implemented computational strategies that catalog key motif combinations that identify neuronal enhancers, and developed sequence- based vocabularies (classifiers) for neuroanatomical domains (forebrain, midbrain, hindbrain) among other more homogenous isolated cell populations. By integrating our experiences in functional and computational genomics we have been able to indict several disease-associated variants in pertinent biological processes. We are also beginning to develop the capacity to impute the functional impact of non-coding variation from primary sequence alone.  Efforts to understand the architecture of human complex disease through Genome Wide Association Studies have drawn increased attention to potential roles played by regulatory variation. Thus, understanding the connections between regulatory variants and disease risk is very important. We propose detailed characterization of cell-type appropriate genome-wide regulatory sequence catalogs, isolating labeled dopaminergic neurons ex vivo at multiple time points (Aim 1). We will functionally validate the catalogs and define the sequence motifs that specify their function, developing computational classifiers to identify human DA enhancers, and assaying the functional impact of disease-associated variants therein (Aim 2). We will determine the relationship between distal-acting regulatory sequences and their cognate genes using cutting edge chromatin conformation capture (3C)-based strategies to reveal enhancers- promoter interactions. Then we will determine the consequences of deleting selected enhancers using contemporary genome editing strategies (Aim 3). This proposal takes crucial next steps towards a neuronal regulatory lexicon that can inform our observation of disease-associated variation in non-coding, putative regulatory sequence space. PUBLIC HEALTH RELEVANCE:  We wish to better understand how the regulatory instructions are encoded in DNA sequence, telling critical genes when and where to be switched on/off. We will focus on neurons that are lost in disorders like Parkinson's disease, prioritizing the study o genes implicated in related disorders. Our work will provide new insight into the identity, composition and biological requirement for these gene switches, informing our understanding of mutations that contribute to common genetic disorders.",Development of a Neuronal Regulatory Lexicon,9084287,R01NS062972,"['Affect', 'Alleles', 'Architecture', 'Attention', 'Base Sequence', 'Behavior Disorders', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cataloging', 'Catalogs', 'Cells', 'ChIP-seq', 'Chromatin', 'Communities', 'Complex', 'Congenital Megacolon', 'DNA Sequence', 'Data', 'Deposition', 'Development', 'Disease', 'Dissection', 'Distal', 'Dopamine', 'Embryonic Development', 'Enhancers', 'Functional disorder', 'Funding', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Health', 'Hereditary Disease', 'Human', 'Human Genome', 'Instruction', 'Label', 'Learning', 'Light', 'Machine Learning', 'Midbrain structure', 'Mitotic', 'Molecular Conformation', 'Mus', 'Mutate', 'Mutation', 'Neurons', 'Nucleotides', 'Ontology', 'Orthologous Gene', 'Output', 'Parkinson Disease', 'Phenotype', 'Play', 'Population', 'Prosencephalon', 'Role', 'Satiation', 'Specific qualifier value', 'Switch Genes', 'Syndrome', 'Time', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Transgenic Organisms', 'Tyrosine 3-Monooxygenase', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Work', 'Zebrafish', 'addiction', 'base', 'cancer risk', 'cell type', 'chromosome conformation capture', 'disorder risk', 'dopaminergic neuron', 'encryption', 'experience', 'genome editing', 'genome wide association study', 'genome-wide', 'hindbrain', 'human disease', 'insight', 'mutant', 'neuropsychiatric disorder', 'promoter', 'success', 'transcription factor', 'transcriptome sequencing']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2016,461141,0.0024845187532267043
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease. PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.",Integrative interpretation of the organismal consequences of non-coding variation,9024484,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological Assay', 'Biomedical Research', 'CRISPR/Cas technology', 'Cell Line', 'Chromosome Mapping', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex Genetic Trait', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Event', 'Feedback', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Peptide Sequence Determination', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Vocabulary', 'Weight', 'base', 'candidate identification', 'disease phenotype', 'exome', 'exome sequencing', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human genome sequencing', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'research study', 'trait', 'transcription factor', 'whole genome']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,636532,-0.028693523309310506
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,8974432,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",K99,2016,25020,0.07196618703551978
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9242250,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2016,246031,0.07196618703551978
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control.         PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.                ",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8859887,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2015,381704,0.061685765538196866
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8833507,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Sequences', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'mRNA Precursor', 'novel', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2015,43120,-0.005624878368696618
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy. PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8931936,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Untranslated RNA', 'Variant', 'Vision', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2015,116122,0.020585403264267683
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8889700,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2015,2005492,0.06491952090906855
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,8930750,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs']",NHGRI,STANFORD UNIVERSITY,R01,2015,292499,0.03170340386643677
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8920443,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'genetic variant', 'genome sequencing', 'improved', 'integration site', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2015,2663757,-0.007849102562145228
"Human-Specific Gain and Loss of Function DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university. PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.",Human-Specific Gain and Loss of Function,8796200,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomic Segment', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2015,54194,0.060516226913342665
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,8795204,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Binding', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Relative (related person)', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2015,304719,0.03160693403767092
"Discovery and analysis of structural variation in whole genome sequences DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities. PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.",Discovery and analysis of structural variation in whole genome sequences,8906910,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Alteration', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'genomic variation', 'improved', 'interest', 'markov model', 'rare variant', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2015,371408,-0.020258281418492043
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies.         PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.            ",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,8984471,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2015,300000,0.02834256577103281
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease.         PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.                ",Integrative interpretation of the organismal consequences of non-coding variation,8792292,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological Assay', 'Biomedical Research', 'Cell Line', 'Chromosome Mapping', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex Genetic Trait', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Event', 'Feedback', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Peptide Sequence Determination', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Vocabulary', 'Weight', 'base', 'candidate identification', 'disease phenotype', 'exome', 'exome sequencing', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human genome sequencing', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'public health relevance', 'research study', 'trait', 'transcription factor']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,666593,-0.028693523309310506
"Development of a Neuronal Regulatory Lexicon DESCRIPTION (provided by applicant): This proposal builds upon our successes in the first funding cycle, and technological advances in in the wider scientific community. We will expand our understanding of the biology and sequence-based encryption of transcriptional regulatory instructions in clinically pertinent neuronal populations, focusing on tyrosine hydroxylase (Th)-expressing ventral midbrain neurons that are compromised in Parkinson's disease and certain behavioral and neuropsychiatric disorders. In recent years, we have made great strides in characterizing regulatory control at specific neurogenic loci by generating, validating and publicly depositing huge catalogs of neuronal enhancers. We have developed and implemented computational strategies that catalog key motif combinations that identify neuronal enhancers, and developed sequence- based vocabularies (classifiers) for neuroanatomical domains (forebrain, midbrain, hindbrain) among other more homogenous isolated cell populations. By integrating our experiences in functional and computational genomics we have been able to indict several disease-associated variants in pertinent biological processes. We are also beginning to develop the capacity to impute the functional impact of non-coding variation from primary sequence alone.  Efforts to understand the architecture of human complex disease through Genome Wide Association Studies have drawn increased attention to potential roles played by regulatory variation. Thus, understanding the connections between regulatory variants and disease risk is very important. We propose detailed characterization of cell-type appropriate genome-wide regulatory sequence catalogs, isolating labeled dopaminergic neurons ex vivo at multiple time points (Aim 1). We will functionally validate the catalogs and define the sequence motifs that specify their function, developing computational classifiers to identify human DA enhancers, and assaying the functional impact of disease-associated variants therein (Aim 2). We will determine the relationship between distal-acting regulatory sequences and their cognate genes using cutting edge chromatin conformation capture (3C)-based strategies to reveal enhancers- promoter interactions. Then we will determine the consequences of deleting selected enhancers using contemporary genome editing strategies (Aim 3). This proposal takes crucial next steps towards a neuronal regulatory lexicon that can inform our observation of disease-associated variation in non-coding, putative regulatory sequence space. PUBLIC HEALTH RELEVANCE:  We wish to better understand how the regulatory instructions are encoded in DNA sequence, telling critical genes when and where to be switched on/off. We will focus on neurons that are lost in disorders like Parkinson's disease, prioritizing the study o genes implicated in related disorders. Our work will provide new insight into the identity, composition and biological requirement for these gene switches, informing our understanding of mutations that contribute to common genetic disorders.",Development of a Neuronal Regulatory Lexicon,8928251,R01NS062972,"['Affect', 'Alleles', 'Architecture', 'Attention', 'Base Sequence', 'Behavioral', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cataloging', 'Catalogs', 'Cells', 'ChIP-seq', 'Chromatin', 'Communities', 'Complex', 'Congenital Megacolon', 'DNA Sequence', 'Data', 'Deposition', 'Development', 'Disease', 'Dissection', 'Distal', 'Dopamine', 'Embryonic Development', 'Enhancers', 'Functional disorder', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Health', 'Hereditary Disease', 'Human', 'Human Genome', 'Instruction', 'Label', 'Learning', 'Light', 'Machine Learning', 'Midbrain structure', 'Mitotic', 'Molecular Conformation', 'Mus', 'Mutate', 'Mutation', 'Neurons', 'Nucleotides', 'Ontology', 'Orthologous Gene', 'Output', 'Parkinson Disease', 'Phenotype', 'Play', 'Population', 'Prosencephalon', 'Role', 'Satiation', 'Specific qualifier value', 'Switch Genes', 'Syndrome', 'Time', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Transgenic Organisms', 'Tyrosine 3-Monooxygenase', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Work', 'Zebrafish', 'addiction', 'base', 'cancer risk', 'cell type', 'disorder risk', 'dopaminergic neuron', 'encryption', 'experience', 'genome editing', 'genome wide association study', 'genome-wide', 'hindbrain', 'human disease', 'insight', 'mutant', 'neuropsychiatry', 'promoter', 'success', 'transcription factor', 'transcriptome sequencing']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2015,461094,0.0024845187532267043
"Genome engineering tools for functional screening of non-coding elements     DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root).         PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.                ",Genome engineering tools for functional screening of non-coding elements,8804084,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Laboratories', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Relative (related person)', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",K99,2015,99937,0.07196618703551978
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,0.050812994182851665
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions     DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy.         PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.        The written critiques of individual reviewers are provided in essentially unedited form in this section. Please note that these critiques and criteria scores were prepared prior to the meeting and may not have been revised subsequent to any discussions at the review meeting. The ""Resume and Summary of Discussion"" section above summarizes the final opinions of the committee.                ","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8805723,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'Critiques', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Functional RNA', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Variant', 'Vision', 'Writing', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'meetings', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'public health relevance', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2014,116122,0.020246413631601182
"Gene Prediction by Markov Models and Complementary Methods DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad. NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8909702,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'pyrosequencing', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2014,100000,0.03365229172367666
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8725717,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2014,2015775,0.06491952090906855
"Statistical and computational analysis in whole genome sequencing studies.     DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges.         PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.                ",Statistical and computational analysis in whole genome sequencing studies.,8750827,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs', 'public health relevance']",NHGRI,STANFORD UNIVERSITY,R01,2014,300000,0.03170340386643677
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8737934,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Detection', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Site', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'design', 'genetic variant', 'genome sequencing', 'improved', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2014,2684060,-0.007849102562145228
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8635216,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2014,51530,0.060516226913342665
"Genome analysis based on the integration of DNA sequence and shape  Title: Genome analysis based on the integration of DNA sequence and shape PI: Rohs, Remo (USC); Co-I: Noble, William Stafford (UW); Co-I: Tullius, Thomas D. (BU) PROJECT SUMMARY Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription factors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.            ",Genome analysis based on the integration of DNA sequence and shape,8632246,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Functional RNA', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Binding', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Relative (related person)', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'public health relevance', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2014,334303,0.03316267646831304
"Discovery and analysis of structural variation in whole genome sequences     DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities.         PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.            ",Discovery and analysis of structural variation in whole genome sequences,8733748,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'interest', 'markov model', 'public health relevance', 'rare variant', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2014,374673,-0.020258281418492043
"Informatic Profiling of Clinically Relevant Mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic Profiling of Clinically Relevant Mutation,8722025,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2014,114720,-0.007584372275553732
"Development of a Neuronal Regulatory Lexicon     DESCRIPTION (provided by applicant): This proposal builds upon our successes in the first funding cycle, and technological advances in in the wider scientific community. We will expand our understanding of the biology and sequence-based encryption of transcriptional regulatory instructions in clinically pertinent neuronal populations, focusing on tyrosine hydroxylase (Th)-expressing ventral midbrain neurons that are compromised in Parkinson's disease and certain behavioral and neuropsychiatric disorders. In recent years, we have made great strides in characterizing regulatory control at specific neurogenic loci by generating, validating and publicly depositing huge catalogs of neuronal enhancers. We have developed and implemented computational strategies that catalog key motif combinations that identify neuronal enhancers, and developed sequence- based vocabularies (classifiers) for neuroanatomical domains (forebrain, midbrain, hindbrain) among other more homogenous isolated cell populations. By integrating our experiences in functional and computational genomics we have been able to indict several disease-associated variants in pertinent biological processes. We are also beginning to develop the capacity to impute the functional impact of non-coding variation from primary sequence alone.  Efforts to understand the architecture of human complex disease through Genome Wide Association Studies have drawn increased attention to potential roles played by regulatory variation. Thus, understanding the connections between regulatory variants and disease risk is very important. We propose detailed characterization of cell-type appropriate genome-wide regulatory sequence catalogs, isolating labeled dopaminergic neurons ex vivo at multiple time points (Aim 1). We will functionally validate the catalogs and define the sequence motifs that specify their function, developing computational classifiers to identify human DA enhancers, and assaying the functional impact of disease-associated variants therein (Aim 2). We will determine the relationship between distal-acting regulatory sequences and their cognate genes using cutting edge chromatin conformation capture (3C)-based strategies to reveal enhancers- promoter interactions. Then we will determine the consequences of deleting selected enhancers using contemporary genome editing strategies (Aim 3). This proposal takes crucial next steps towards a neuronal regulatory lexicon that can inform our observation of disease-associated variation in non-coding, putative regulatory sequence space.         PUBLIC HEALTH RELEVANCE:  We wish to better understand how the regulatory instructions are encoded in DNA sequence, telling critical genes when and where to be switched on/off. We will focus on neurons that are lost in disorders like Parkinson's disease, prioritizing the study o genes implicated in related disorders. Our work will provide new insight into the identity, composition and biological requirement for these gene switches, informing our understanding of mutations that contribute to common genetic disorders.                                ",Development of a Neuronal Regulatory Lexicon,8811553,R01NS062972,"['Affect', 'Alleles', 'Architecture', 'Attention', 'Base Sequence', 'Behavioral', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cataloging', 'Catalogs', 'Cells', 'ChIP-seq', 'Chromatin', 'Communities', 'Complex', 'Congenital Megacolon', 'DNA Sequence', 'Data', 'Deposition', 'Development', 'Disease', 'Dissection', 'Distal', 'Dopamine', 'Embryonic Development', 'Enhancers', 'Functional RNA', 'Functional disorder', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Hereditary Disease', 'Human', 'Human Genome', 'Instruction', 'Label', 'Learning', 'Light', 'Machine Learning', 'Midbrain structure', 'Mitotic', 'Molecular Conformation', 'Mus', 'Mutate', 'Mutation', 'Neurons', 'Nucleotides', 'Ontology', 'Orthologous Gene', 'Output', 'Parkinson Disease', 'Phenotype', 'Play', 'Population', 'Prosencephalon', 'Role', 'Satiation', 'Specific qualifier value', 'Switch Genes', 'Syndrome', 'Time', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Transgenic Organisms', 'Tyrosine 3-Monooxygenase', 'Variant', 'Vocabulary', 'Work', 'Zebrafish', 'addiction', 'base', 'cancer risk', 'cell type', 'disorder risk', 'dopaminergic neuron', 'encryption', 'experience', 'genome wide association study', 'genome-wide', 'hindbrain', 'human disease', 'insight', 'mutant', 'neuropsychiatry', 'promoter', 'public health relevance', 'success', 'transcription factor', 'transcriptome sequencing']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2014,467946,0.0024845187532267043
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8699810,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic DNA', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,641093,0.07790729817225063
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,0.050812994182851665
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8722983,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,115680,0.06491952090906855
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8548395,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,1871839,0.06491952090906855
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8589933,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Detection', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Site', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'design', 'genetic variant', 'genome sequencing', 'improved', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2013,2766009,-0.007849102562145228
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8457179,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2013,47114,0.060516226913342665
"Discovery and analysis of structural variation in whole genome sequences     DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities.         PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.            ",Discovery and analysis of structural variation in whole genome sequences,8528145,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'interest', 'markov model', 'public health relevance', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2013,382699,-0.020258281418492043
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8526549,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2013,444076,-0.007584372275553732
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8537965,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,624741,0.07790729817225063
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,0.044633355040171685
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.      PUBLIC HEALTH RELEVANCE: The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.              The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8237596,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Delivery Systems', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2012,1010000,0.03345930680360919
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.           Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8320160,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'metagenome', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2012,204974,0.03219230721225912
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8521766,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2012,75000,0.03365229172367666
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8266525,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2012,577121,0.03365229172367666
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8402447,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Set', 'Development', 'Disease', 'Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2012,2460045,0.06491952090906855
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.         The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8331495,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2012,103535,-0.0053834577061851645
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8228154,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,323572,0.0007568780831606923
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8310258,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenome', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2012,367520,0.04175287354002271
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8537085,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenome', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2012,139853,0.04175287354002271
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8328943,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2012,461516,-0.007584372275553732
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.        PUBLIC HEALTH RELEVANCE: Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.              Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8373752,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,654177,0.07541093496890738
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,8134360,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait', 'treatment strategy']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2011,342569,0.0754366936328489
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8053866,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2011,577264,0.03365229172367666
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.      PUBLIC HEALTH RELEVANCE:    Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.                 Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8192895,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2011,180669,0.0306943984613819
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8035949,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,321670,0.0007568780831606923
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.       PUBLIC HEALTH RELEVANCE: The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.              The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8164533,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2011,102709,0.005336825948588787
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8150462,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2011,407746,0.04175287354002271
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8321717,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,342218,0.029898284236330237
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8320051,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,2615448,0.029898284236330237
"Developing Proteogenomic Mapping for Human Genome Annotation    DESCRIPTION (provided by applicant): Genome sequencing efforts are producing ever greater quantities of raw DNA sequence, but the annotation process for locating and determining the function of genetic elements has not kept up. While many aspects of annotation are difficult, it is particularly challenging to determine which parts of a genome sequence encode proteins, and therefore how the processes leading to protein translation are regulated. Not only are technologies for examining proteins more limited than those for studying RNA transcription, in an extensive study of transcription by the Encyclopedia of DNA elements consortium, a picture of great complexity emerged. The project uncovered many novel exons, alternative splice forms, and novel regulatory elements. These results indicate that nearly 9/10ths of human genes undergo alternative splicing, and the average gene produces approximately 6 splice variants. Rather than solidify knowledge regarding the location and function of genes, these results question whether we accurately know what constitutes a gene, and how the products encoded by genes determine the function of cells. The results particularly obfuscate determination of which transcripts are selected for translation to protein, further complicating annotation efforts. To address that gap, our project will determine which transcripts encode proteins, and how these are affected in several tissue types and disease conditions. We will use large tandem mass spectrometry-based proteomic data sets, mapping the analyzed protein data directly to several available human genome sequences, along with sets of predicted transcripts produced by the N-SCAN and CONTRAST gene finders, to reveal which parts of transcripts are translated into proteins, and in which types of cells this translation occurs. To accomplish this, our project has three specific aims: 1) to develop high-accuracy methods and software for mapping proteomic data from mass spec analyzed proteins directly to the genome locus encoding them; 2) to develop an analysis pipeline software system using a novel rule-based information management approach; and 3) to apply these developments for the high-throughput analysis of large proteomic data sets, identifying the transcripts that encode proteins in distinct tissue types and disease conditions, and placing the results in a publicly accessible track in the UCSC genome browser. We believe this project will yield significant knowledge about the location and timing of protein translation in cells, which will potentiate further investigation of how misregulation of the path from transcription to translation leads to human disease conditions.   PUBLIC HEALTH RELEVANCE:  Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.              NARRATIVE Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.",Developing Proteogenomic Mapping for Human Genome Annotation,8071964,R01HG003700,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Biochemical', 'Cell physiology', 'Cells', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Custom', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Elements', 'Exons', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Goals', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Genome', 'Imagery', 'Information Management', 'Investigation', 'Isotope Labeling', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nature', 'Paint', 'Peptides', 'Play', 'Procedures', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Quality Control', 'RNA', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Personnel', 'Role', 'Sampling', 'Software Tools', 'Source', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Technology', 'Time', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Variant', 'base', 'cell type', 'design', 'experience', 'flexibility', 'gene function', 'genetic element', 'genome sequencing', 'high throughput analysis', 'human disease', 'improved', 'new technology', 'novel', 'prevent', 'software systems', 'tandem mass spectrometry', 'web interface']",NHGRI,BOISE STATE UNIVERSITY,R01,2011,431250,0.016533867382065474
"Developing Proteogenomic Mapping for Human Genome Annotation    DESCRIPTION (provided by applicant): Genome sequencing efforts are producing ever greater quantities of raw DNA sequence, but the annotation process for locating and determining the function of genetic elements has not kept up. While many aspects of annotation are difficult, it is particularly challenging to determine which parts of a genome sequence encode proteins, and therefore how the processes leading to protein translation are regulated. Not only are technologies for examining proteins more limited than those for studying RNA transcription, in an extensive study of transcription by the Encyclopedia of DNA elements consortium, a picture of great complexity emerged. The project uncovered many novel exons, alternative splice forms, and novel regulatory elements. These results indicate that nearly 9/10ths of human genes undergo alternative splicing, and the average gene produces approximately 6 splice variants. Rather than solidify knowledge regarding the location and function of genes, these results question whether we accurately know what constitutes a gene, and how the products encoded by genes determine the function of cells. The results particularly obfuscate determination of which transcripts are selected for translation to protein, further complicating annotation efforts. To address that gap, our project will determine which transcripts encode proteins, and how these are affected in several tissue types and disease conditions. We will use large tandem mass spectrometry-based proteomic data sets, mapping the analyzed protein data directly to several available human genome sequences, along with sets of predicted transcripts produced by the N-SCAN and CONTRAST gene finders, to reveal which parts of transcripts are translated into proteins, and in which types of cells this translation occurs. To accomplish this, our project has three specific aims: 1) to develop high-accuracy methods and software for mapping proteomic data from mass spec analyzed proteins directly to the genome locus encoding them; 2) to develop an analysis pipeline software system using a novel rule-based information management approach; and 3) to apply these developments for the high-throughput analysis of large proteomic data sets, identifying the transcripts that encode proteins in distinct tissue types and disease conditions, and placing the results in a publicly accessible track in the UCSC genome browser. We believe this project will yield significant knowledge about the location and timing of protein translation in cells, which will potentiate further investigation of how misregulation of the path from transcription to translation leads to human disease conditions.   PUBLIC HEALTH RELEVANCE:  Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.              NARRATIVE Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.",Developing Proteogenomic Mapping for Human Genome Annotation,8321269,R01HG003700,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Biochemical', 'Cell physiology', 'Cells', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Custom', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Elements', 'Exons', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Goals', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Genome', 'Imagery', 'Information Management', 'Investigation', 'Isotope Labeling', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nature', 'Paint', 'Peptides', 'Play', 'Procedures', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Quality Control', 'RNA', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Personnel', 'Role', 'Sampling', 'Software Tools', 'Source', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Technology', 'Time', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Variant', 'base', 'cell type', 'design', 'experience', 'flexibility', 'gene function', 'genetic element', 'genome sequencing', 'high throughput analysis', 'human disease', 'improved', 'new technology', 'novel', 'prevent', 'software systems', 'tandem mass spectrometry', 'web interface']",NHGRI,BOISE STATE UNIVERSITY,R01,2011,797678,0.016533867382065474
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8238173,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2011,500661,-0.007584372275553732
"Enhance human ENCODE by function comparisons to mouse    DESCRIPTION (provided by applicant): Our goal is to discover and use relationships between mouse and human regulatory genomes to advance the ENCODE Project in its effort to map all functional elements in the human genome. Our comparative approach aims to uncover principles and solve problems that are proving difficult by studying the human genome alone. ENCODE is vigorously mapping hundreds of function-associated biochemical markers in selected cell lines, resulting already in tens of millions of reproducible biochemical features. Some observed protein:DNA interactions find and refine known transcriptional enhancers, promoters, silencers, together with associated chromatin structure, as was anticipated. But substantial questions arise as to how many of the myriad biochemical events are functional, what those functions are, which gene or genes are meaningful targets, etc. To highlight and sort functionally important biochemical marks from others, we will systematically identify the molecular events retained by both mouse and human since they diverged. We will then analyze how conservation of biochemical features relates to conservation of DNA sequence and conservation of regulated gene expression. By using the mouse, we can leverage decades of molecular genetics and manipulated mouse genomes that do not exist in any other mammal. In Aim 1 we execute genome-wide assays for biochemical signatures of functional DNA sequences in a few specific mouse cell types. By using well-studied mouse lines and cell states, we can interpret results in light of previously validated elements and in light of ENCODE human results. We will use ENCODE standards for high throughput, sequence-based assays to determine gene expression, DNase hypersensitive sites, histone modifications and selected transcription factor occupancy in seven mouse cell types. The eight selected features are the most informative ones for function, and thus most useful for comparison with human data. In Aim 2, we apply a genome-wide implementation of chromosome conformation capture to map the interactions between transcription factor binding sites and their responsive genes in two cell types. These results will be compared to those from an ENCODE developmental project. Comparative analysis in Aim 3 will insure that the impact of the data we produce will go beyond the individual mouse cell systems per se. To do this we have organized a collaboration of investigators at multiple institutions, in which each group is expert in one or more critical aspects. Our data, made public and accessible via ENCODE, will fuel and accelerate many future studies after the 2-yr stimulus both in and beyond ENCODE. This responds to NHGRI request for applications on ""Enhancement of the value of the human ENCODE Project by conducting a parallel effort on the mouse genome."" The proposed work will improve the maps of biologically functional DNA sequences in humans, which in turn will help explain how variants in human genome sequences could be associated with human diseases, leading to candidates for novel avenues for effective therapy and prevention.      PUBLIC HEALTH RELEVANCE:  Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.          Project Narrative for ""Enhance human ENCODE by functional comparisons to mouse"" Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.",Enhance human ENCODE by function comparisons to mouse,8321719,RC2HG005573,"['Adopted', 'BFU-E', 'Base Sequence', 'Binding', 'Binding Sites', 'Biochemical', 'Biochemical Markers', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell model', 'Cells', 'Chromatin Structure', 'Chromosomes', 'Classification', 'Collaborations', 'Complement', 'Complex', 'Correlative Study', 'DNA', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Deoxyribonucleases', 'Development', 'Developmental Biology', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Elements', 'Enhancers', 'Erythroblasts', 'Erythropoiesis', 'Event', 'Evolution', 'Frequencies', 'Future', 'GATA1 gene', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Goals', 'Harvest', 'Heart Diseases', 'Human', 'Human Cell Line', 'Human Genome', 'Human Genome Project', 'Indium', 'Individual', 'Institution', 'Investigation', 'Lead', 'Light', 'Location', 'Lymphocyte', 'Lymphoid', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Megakaryocytopoieses', 'Molecular', 'Molecular Conformation', 'Molecular Evolution', 'Molecular Genetics', 'Mouse Cell Line', 'Mus', 'Muscle Cells', 'Myelogenous', 'National Human Genome Research Institute', 'Nuclear', 'Persons', 'Phase', 'Phylogenetic Analysis', 'Predisposition', 'Prevention', 'Problem Solving', 'Process', 'Quality Control', 'RNA', 'Request for Applications', 'Research', 'Research Personnel', 'Sequence Analysis', 'Site', 'Sorting - Cell Movement', 'Staging', 'Stimulus', 'System', 'Technology', 'Time Study', 'Transcript', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Variant', 'Work', 'base', 'cell type', 'comparative', 'data mining', 'effective therapy', 'embryonic stem cell', 'genome sequencing', 'genome-wide', 'high standard', 'histone modification', 'human GATA1 protein', 'human data', 'human disease', 'improved', 'insight', 'mouse genome', 'novel', 'pathogen', 'promoter', 'public health relevance', 'response', 'restoration', 'transcription factor']",NHGRI,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,RC2,2011,749992,0.013788075869310374
"Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform    DESCRIPTION (provided by applicant): DNAnexus proposes to develop a complete solution for the identification and stratification of personal genetic variation from ultra-high-throughput sequencing projects. The solution will be implemented as a Web 2.0 service and online browsing tool that will integrate public data sources such as the 1000 genomes project, comparative information, and the ENCODE II project data. Users will be able to browse and stratify the identified variation in the context of these genomic annotations, and according to the likely functional impact. In Phase I of our project, we will develop a basic browser for displaying sequence reads that are mapped to a reference genome with our state-of-the-art read mapper. The browser will support viewing mate paired reads as well as display of the variation between these reads and the reference genome. It will facilitate the algorithmic development that we will perform during Phase II, and it will be the foundation for the more sophisticated variation browser also proposed in Phase II. In Phase II, we will develop algorithms for detecting genomic variation, and a state-of-the-art browser for viewing variation in the context of existing genome annotations, functional genomic and comparative genomic data. Our algorithms for detecting variation will support all major types of genomic variation, including SNPs, microindels, larger insertions and deletions, duplications, copy number variations, inversions, and translocations. Our algorithms will be based on state-of-the-art statistical and machine learning methodology for human genome resequencing. The DNAnexus browser will have two components: a list browser that displays variation as a list filtered and stratified by criteria that a user chooses, and a powerful GUI whose navigation capabilities are inspired by modern online tools such as Google Maps.      PUBLIC HEALTH RELEVANCE: DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.           Project Narrative DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.",Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform,7909096,R43HG005794,"['Algorithms', 'Architecture', 'Arts', 'Code', 'Copy Number Polymorphism', 'DNA Resequencing', 'Data', 'Data Display', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Environment', 'Foundations', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Human Genome', 'Imagery', 'Individual', 'Internet', 'Machine Learning', 'Maps', 'Methodology', 'Partner in relationship', 'Phase', 'Point Mutation', 'Reading', 'Services', 'Solutions', 'Statistical Methods', 'Stratification', 'Technology', 'Variant', 'base', 'comparative', 'comparative genomics', 'cost', 'flexibility', 'functional genomics', 'genome sequencing', 'graphical user interface', 'insertion/deletion mutation', 'public health relevance', 'tool']",NHGRI,"DNANEXUS, INC.",R43,2010,74477,0.025023077884657914
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7902231,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2010,346884,0.0754366936328489
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,7809669,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Arts', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2010,573248,0.03365229172367666
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7795846,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,326175,0.0007568780831606923
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8020799,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2010,408559,0.04175287354002271
"Developing Proteogenomic Mapping for Human Genome Annotation    DESCRIPTION (provided by applicant): Genome sequencing efforts are producing ever greater quantities of raw DNA sequence, but the annotation process for locating and determining the function of genetic elements has not kept up. While many aspects of annotation are difficult, it is particularly challenging to determine which parts of a genome sequence encode proteins, and therefore how the processes leading to protein translation are regulated. Not only are technologies for examining proteins more limited than those for studying RNA transcription, in an extensive study of transcription by the Encyclopedia of DNA elements consortium, a picture of great complexity emerged. The project uncovered many novel exons, alternative splice forms, and novel regulatory elements. These results indicate that nearly 9/10ths of human genes undergo alternative splicing, and the average gene produces approximately 6 splice variants. Rather than solidify knowledge regarding the location and function of genes, these results question whether we accurately know what constitutes a gene, and how the products encoded by genes determine the function of cells. The results particularly obfuscate determination of which transcripts are selected for translation to protein, further complicating annotation efforts. To address that gap, our project will determine which transcripts encode proteins, and how these are affected in several tissue types and disease conditions. We will use large tandem mass spectrometry-based proteomic data sets, mapping the analyzed protein data directly to several available human genome sequences, along with sets of predicted transcripts produced by the N-SCAN and CONTRAST gene finders, to reveal which parts of transcripts are translated into proteins, and in which types of cells this translation occurs. To accomplish this, our project has three specific aims: 1) to develop high-accuracy methods and software for mapping proteomic data from mass spec analyzed proteins directly to the genome locus encoding them; 2) to develop an analysis pipeline software system using a novel rule-based information management approach; and 3) to apply these developments for the high-throughput analysis of large proteomic data sets, identifying the transcripts that encode proteins in distinct tissue types and disease conditions, and placing the results in a publicly accessible track in the UCSC genome browser. We believe this project will yield significant knowledge about the location and timing of protein translation in cells, which will potentiate further investigation of how misregulation of the path from transcription to translation leads to human disease conditions.   PUBLIC HEALTH RELEVANCE:  Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.              NARRATIVE Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.",Developing Proteogenomic Mapping for Human Genome Annotation,7802061,R01HG003700,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Biochemical', 'Cell physiology', 'Cells', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Custom', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Elements', 'Exons', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Goals', 'Grant', 'Histocompatibility Testing', 'Human', 'Human Genome', 'Imagery', 'Information Management', 'Investigation', 'Isotope Labeling', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nature', 'Paint', 'Peptides', 'Play', 'Procedures', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Quality Control', 'RNA', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Software Tools', 'Source', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Technology', 'Time', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Variant', 'base', 'cell type', 'design', 'experience', 'flexibility', 'gene function', 'genetic element', 'genome sequencing', 'high throughput analysis', 'human disease', 'improved', 'new technology', 'novel', 'prevent', 'public health relevance', 'software systems', 'tandem mass spectrometry', 'web interface']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2010,435435,0.016533867382065474
"Enhance human ENCODE by function comparisons to mouse    DESCRIPTION (provided by applicant): Our goal is to discover and use relationships between mouse and human regulatory genomes to advance the ENCODE Project in its effort to map all functional elements in the human genome. Our comparative approach aims to uncover principles and solve problems that are proving difficult by studying the human genome alone. ENCODE is vigorously mapping hundreds of function-associated biochemical markers in selected cell lines, resulting already in tens of millions of reproducible biochemical features. Some observed protein:DNA interactions find and refine known transcriptional enhancers, promoters, silencers, together with associated chromatin structure, as was anticipated. But substantial questions arise as to how many of the myriad biochemical events are functional, what those functions are, which gene or genes are meaningful targets, etc. To highlight and sort functionally important biochemical marks from others, we will systematically identify the molecular events retained by both mouse and human since they diverged. We will then analyze how conservation of biochemical features relates to conservation of DNA sequence and conservation of regulated gene expression. By using the mouse, we can leverage decades of molecular genetics and manipulated mouse genomes that do not exist in any other mammal. In Aim 1 we execute genome-wide assays for biochemical signatures of functional DNA sequences in a few specific mouse cell types. By using well-studied mouse lines and cell states, we can interpret results in light of previously validated elements and in light of ENCODE human results. We will use ENCODE standards for high throughput, sequence-based assays to determine gene expression, DNase hypersensitive sites, histone modifications and selected transcription factor occupancy in seven mouse cell types. The eight selected features are the most informative ones for function, and thus most useful for comparison with human data. In Aim 2, we apply a genome-wide implementation of chromosome conformation capture to map the interactions between transcription factor binding sites and their responsive genes in two cell types. These results will be compared to those from an ENCODE developmental project. Comparative analysis in Aim 3 will insure that the impact of the data we produce will go beyond the individual mouse cell systems per se. To do this we have organized a collaboration of investigators at multiple institutions, in which each group is expert in one or more critical aspects. Our data, made public and accessible via ENCODE, will fuel and accelerate many future studies after the 2-yr stimulus both in and beyond ENCODE. This responds to NHGRI request for applications on ""Enhancement of the value of the human ENCODE Project by conducting a parallel effort on the mouse genome."" The proposed work will improve the maps of biologically functional DNA sequences in humans, which in turn will help explain how variants in human genome sequences could be associated with human diseases, leading to candidates for novel avenues for effective therapy and prevention.      PUBLIC HEALTH RELEVANCE:  Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.           Project Narrative for ""Enhance human ENCODE by functional comparisons to mouse"" Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.",Enhance human ENCODE by function comparisons to mouse,7940960,RC2HG005573,"['Adopted', 'BFU-E', 'Base Sequence', 'Binding', 'Binding Sites', 'Biochemical', 'Biochemical Markers', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell model', 'Cells', 'Chromatin Structure', 'Chromosomes', 'Classification', 'Collaborations', 'Complement', 'Complex', 'Correlative Study', 'DNA', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Deoxyribonucleases', 'Development', 'Developmental Biology', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Elements', 'Enhancers', 'Erythroblasts', 'Erythropoiesis', 'Event', 'Evolution', 'Frequencies', 'Future', 'GATA1 gene', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Goals', 'Harvest', 'Heart Diseases', 'Human', 'Human Cell Line', 'Human Genome', 'Human Genome Project', 'Indium', 'Individual', 'Institution', 'Investigation', 'Lead', 'Light', 'Location', 'Lymphocyte', 'Lymphoid', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Molecular', 'Molecular Conformation', 'Molecular Evolution', 'Molecular Genetics', 'Mouse Cell Line', 'Mus', 'Muscle Cells', 'Myelogenous', 'National Human Genome Research Institute', 'Nuclear', 'Persons', 'Phase', 'Phylogenetic Analysis', 'Predisposition', 'Prevention', 'Problem Solving', 'Process', 'Quality Control', 'Request for Applications', 'Research', 'Research Personnel', 'Sequence Analysis', 'Site', 'Sorting - Cell Movement', 'Staging', 'Stimulus', 'System', 'Technology', 'Time Study', 'Transcript', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Variant', 'Work', 'base', 'cell type', 'comparative', 'data mining', 'effective therapy', 'embryonic stem cell', 'genome sequencing', 'genome-wide', 'high standard', 'histone modification', 'human GATA1 protein', 'human data', 'human disease', 'improved', 'insight', 'mouse genome', 'novel', 'pathogen', 'promoter', 'public health relevance', 'response', 'restoration', 'transcription factor']",NHGRI,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,RC2,2010,749997,0.013788075869310374
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7681225,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2009,351164,0.0754366936328489
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,7656528,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Arts', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2009,560000,0.03365229172367666
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7635337,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2009,330660,0.0007568780831606923
"Developing Proteogenomic Mapping for Human Genome Annotation    DESCRIPTION (provided by applicant): Genome sequencing efforts are producing ever greater quantities of raw DNA sequence, but the annotation process for locating and determining the function of genetic elements has not kept up. While many aspects of annotation are difficult, it is particularly challenging to determine which parts of a genome sequence encode proteins, and therefore how the processes leading to protein translation are regulated. Not only are technologies for examining proteins more limited than those for studying RNA transcription, in an extensive study of transcription by the Encyclopedia of DNA elements consortium, a picture of great complexity emerged. The project uncovered many novel exons, alternative splice forms, and novel regulatory elements. These results indicate that nearly 9/10ths of human genes undergo alternative splicing, and the average gene produces approximately 6 splice variants. Rather than solidify knowledge regarding the location and function of genes, these results question whether we accurately know what constitutes a gene, and how the products encoded by genes determine the function of cells. The results particularly obfuscate determination of which transcripts are selected for translation to protein, further complicating annotation efforts. To address that gap, our project will determine which transcripts encode proteins, and how these are affected in several tissue types and disease conditions. We will use large tandem mass spectrometry-based proteomic data sets, mapping the analyzed protein data directly to several available human genome sequences, along with sets of predicted transcripts produced by the N-SCAN and CONTRAST gene finders, to reveal which parts of transcripts are translated into proteins, and in which types of cells this translation occurs. To accomplish this, our project has three specific aims: 1) to develop high-accuracy methods and software for mapping proteomic data from mass spec analyzed proteins directly to the genome locus encoding them; 2) to develop an analysis pipeline software system using a novel rule-based information management approach; and 3) to apply these developments for the high-throughput analysis of large proteomic data sets, identifying the transcripts that encode proteins in distinct tissue types and disease conditions, and placing the results in a publicly accessible track in the UCSC genome browser. We believe this project will yield significant knowledge about the location and timing of protein translation in cells, which will potentiate further investigation of how misregulation of the path from transcription to translation leads to human disease conditions.   PUBLIC HEALTH RELEVANCE:  Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.              NARRATIVE Sequencing of the human genome is complete, but figuring out where genes are located, how they function, and how they cause or prevent human diseases like cancer has only just begun. Genes act as blueprints for RNA and proteins, the workhorses of the cell. We are developing technologies to address the key challenges of determining which genes specify the building of which proteins and how this process is orchestrated to ultimately unravel how disease processes occur.",Developing Proteogenomic Mapping for Human Genome Annotation,7583730,R01HG003700,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Biochemical', 'Cell physiology', 'Cells', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Custom', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Elements', 'Exons', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Goals', 'Grant', 'Histocompatibility Testing', 'Human', 'Human Genome', 'Imagery', 'Information Management', 'Investigation', 'Isotope Labeling', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nature', 'Paint', 'Peptides', 'Play', 'Procedures', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Quality Control', 'RNA', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Software Tools', 'Source', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Technology', 'Time', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Variant', 'base', 'cell type', 'design', 'experience', 'flexibility', 'gene function', 'genetic element', 'genome sequencing', 'high throughput analysis', 'human disease', 'improved', 'new technology', 'novel', 'prevent', 'public health relevance', 'software systems', 'tandem mass spectrometry', 'web interface']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2009,450000,0.016533867382065474
"Enhance human ENCODE by function comparisons to mouse    DESCRIPTION (provided by applicant): Our goal is to discover and use relationships between mouse and human regulatory genomes to advance the ENCODE Project in its effort to map all functional elements in the human genome. Our comparative approach aims to uncover principles and solve problems that are proving difficult by studying the human genome alone. ENCODE is vigorously mapping hundreds of function-associated biochemical markers in selected cell lines, resulting already in tens of millions of reproducible biochemical features. Some observed protein:DNA interactions find and refine known transcriptional enhancers, promoters, silencers, together with associated chromatin structure, as was anticipated. But substantial questions arise as to how many of the myriad biochemical events are functional, what those functions are, which gene or genes are meaningful targets, etc. To highlight and sort functionally important biochemical marks from others, we will systematically identify the molecular events retained by both mouse and human since they diverged. We will then analyze how conservation of biochemical features relates to conservation of DNA sequence and conservation of regulated gene expression. By using the mouse, we can leverage decades of molecular genetics and manipulated mouse genomes that do not exist in any other mammal. In Aim 1 we execute genome-wide assays for biochemical signatures of functional DNA sequences in a few specific mouse cell types. By using well-studied mouse lines and cell states, we can interpret results in light of previously validated elements and in light of ENCODE human results. We will use ENCODE standards for high throughput, sequence-based assays to determine gene expression, DNase hypersensitive sites, histone modifications and selected transcription factor occupancy in seven mouse cell types. The eight selected features are the most informative ones for function, and thus most useful for comparison with human data. In Aim 2, we apply a genome-wide implementation of chromosome conformation capture to map the interactions between transcription factor binding sites and their responsive genes in two cell types. These results will be compared to those from an ENCODE developmental project. Comparative analysis in Aim 3 will insure that the impact of the data we produce will go beyond the individual mouse cell systems per se. To do this we have organized a collaboration of investigators at multiple institutions, in which each group is expert in one or more critical aspects. Our data, made public and accessible via ENCODE, will fuel and accelerate many future studies after the 2-yr stimulus both in and beyond ENCODE. This responds to NHGRI request for applications on ""Enhancement of the value of the human ENCODE Project by conducting a parallel effort on the mouse genome."" The proposed work will improve the maps of biologically functional DNA sequences in humans, which in turn will help explain how variants in human genome sequences could be associated with human diseases, leading to candidates for novel avenues for effective therapy and prevention.      PUBLIC HEALTH RELEVANCE:  Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.           Project Narrative for ""Enhance human ENCODE by functional comparisons to mouse"" Every person differs in his or her response to pathogens and in the likelihood that they will suffer from complex diseases such as cancer, heart disease or diabetes. Individual susceptibility to disease is determined in part by genetics, and we can map with high precision the locations of DNA variants associated with disease susceptibility. In order to understand how these variants contribute to disease susceptibility, we need to identify the biological functions of all DNA sequences; the proposed work will help us map these functional DNA sequences.",Enhance human ENCODE by function comparisons to mouse,7852369,RC2HG005573,"['Adopted', 'BFU-E', 'Base Sequence', 'Binding', 'Binding Sites', 'Biochemical', 'Biochemical Markers', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell model', 'Cells', 'Chromatin Structure', 'Chromosomes', 'Classification', 'Collaborations', 'Complement', 'Complex', 'Correlative Study', 'DNA', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Deoxyribonucleases', 'Development', 'Developmental Biology', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Elements', 'Enhancers', 'Erythroblasts', 'Erythropoiesis', 'Event', 'Evolution', 'Frequencies', 'Future', 'GATA1 gene', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Goals', 'Harvest', 'Heart Diseases', 'Human', 'Human Cell Line', 'Human Genome', 'Human Genome Project', 'Indium', 'Individual', 'Institution', 'Investigation', 'Lead', 'Light', 'Location', 'Lymphocyte', 'Lymphoid', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Molecular', 'Molecular Conformation', 'Molecular Evolution', 'Molecular Genetics', 'Mouse Cell Line', 'Mus', 'Muscle Cells', 'Myelogenous', 'National Human Genome Research Institute', 'Nuclear', 'Persons', 'Phase', 'Phylogenetic Analysis', 'Predisposition', 'Prevention', 'Problem Solving', 'Process', 'Quality Control', 'Request for Applications', 'Research', 'Research Personnel', 'Sequence Analysis', 'Site', 'Sorting - Cell Movement', 'Staging', 'Stimulus', 'System', 'Technology', 'Time Study', 'Transcript', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Variant', 'Work', 'base', 'cell type', 'comparative', 'data mining', 'effective therapy', 'embryonic stem cell', 'genome sequencing', 'genome-wide', 'high standard', 'histone modification', 'human GATA1 protein', 'human data', 'human disease', 'improved', 'insight', 'mouse genome', 'novel', 'pathogen', 'promoter', 'public health relevance', 'response', 'restoration', 'transcription factor']",NHGRI,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,RC2,2009,750003,0.013788075869310374
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7522602,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Class', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pan troglodytes', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Rate', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2008,369424,0.0754366936328489
"A Comprehensive catalog of human DNasel hypersensitive sites    DESCRIPTION (provided by applicant):   The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNaseI hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNaseI hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5).           n/a",A Comprehensive catalog of human DNasel hypersensitive sites,7410206,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Class', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonuclease I', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Histones', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Modification', 'Molecular', 'Noise', 'Numbers', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Preparation', 'Production', 'Public Domains', 'Range', 'Rate', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Score', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Standards of Weights and Measures', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'density', 'design', 'digital', 'experience', 'functional genomics', 'high throughput screening', 'human tissue', 'in vivo', 'insight', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2007,3114596,0.03007306877420082
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,7120160,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2006,414036,0.017496035558011852
"Shifting Conceptions of Human Identity DESCRIPTION (provided by applicant):  . One of the most important questions raised by the ongoing achievements of the Human Genome Project is how this new biological knowledge - and the powers it confers - will affect our identity and self-understanding as human beings. This book project focuses on one key aspect of this complex issue: exploring the extent to which human identity can be reconciled with deliberate design or partial redesign. The author proposes to shed new light on this question by comparing the debates surrounding two areas of scientific innovation that are not normally associated with each other, but that are in fact deeply related: the enterprise of human genetic intervention and the enterprise of building intelligent machines. Both these enterprises entail ""pushing the limits"" of traditional concepts of what it means to be human; and both ultimately confront their makers with the same core ""family"" of questions: What are the defining features of human personhood? To what extent can those features be modified or extended, before human personhood begins to break down? Can some (or all) of those features find embodiment in an entity other than a human being? These kinds of questions are no longer the sole province of science fiction writers, but have been taken up with increasing seriousness by mainstream scientists and technologists, as well as by a wide array of ""science watchers"" in academia, legislative circles, and the news media.   . Through documentary research and interviews, this project aims to deepen our understanding of the history and sociology of the debates surrounding these powerful new technologies, electro-mechanical and biological, that are perceived as destabilizing human identity. The intended audience for the book is a broad one: scientists and technological practitioners interested in the social and cultural reception of their research; legislators and other policymakers with a stake in the governance of science; general educated readers who are concerned about the role of science and technology in shaping our collective future. n/a",Shifting Conceptions of Human Identity,6915830,R03HG003298,"['adult human (21+)', 'artificial intelligence', 'behavioral /social science research tag', 'biotechnology', 'books', 'clinical research', 'ethics', 'genetic manipulation', 'history of life science', 'human subject', 'identity', 'interview', 'robotics', 'self concept', 'sociology /anthropology']",NHGRI,VANDERBILT UNIVERSITY,R03,2005,75833,0.03558722567573245
"BioHDF - Open Binary File Standards for Bioinformatics DESCRIPTION (provided by applicant):  Geospiza Inc. and the National Center for Supercomputing Applications (NCSA) are creating a standards based software framework around NCSA's Heirarchical Data Format (HDF5). The envisioned framework will integrate algorithms important in DNA and protein sequence analysis to create scalable high throughput software systems which will be accessed using new graphical user interfaces (GUIs) to provide researchers with new views of their data to finish sequencing projects in large-scale genome sequencing, microbial genome sequencing, viral epidemiology, polymorphism detection, phylogenetic analysis, multi-locus sequence typing, confirmatory sequencing, and EST analysis.    In our vision, algorithms will be either integrated into the system to directly read and write from HDF5 project files, or they will communicate with project files via filter programs that produce standardized XML formatted data. Through this model, a scalable solution will support different applications of DNA sequencing, fulfilling the many needs and requirements expressed by the medical research community now and into the future. As the first step in this process we will, define requirements for editing and versioning data in DNA sequencing, research and propose data models for the computational phases of DNA sequencing and annotating DNA sequence data using existing standards, create a prototype application for DNA sequencing based SNP discovery, and engage the bioinformatics community for BioHDF adoption.       In the past ten years the cost of sequencing DNA has dropped over 1000 fold and the amount of raw sequence data, entering our national repositories is doubling every 12 months. DNA sequencing is fundamental to biological research activities such as genomics, systems biology, and clinical medicine. Proposals are being sought to decrease sequencing costs by two orders of magnitude through technology refinements with an ultimate vision of developing technology to sequence human genome equivalents for $1000 each. The amount of data that will be produced through these endeavors is unimaginable. However, the $1,000 genome will not advance medical research unless we integrate all phases of the DNA sequencing process and treat the creation, management, finishing, analysis, and sharing of the data as common goals. n/a",BioHDF - Open Binary File Standards for Bioinformatics,6992995,R41HG003792,"['DNA', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'functional /structural genomics', 'genetic mapping', 'genetic polymorphism', 'mathematics', 'molecular biology information system', 'nucleic acid sequence', 'single nucleotide polymorphism', 'virus genetics']",NHGRI,"GEOSPIZA, INC.",R41,2005,142775,0.07081082122789589
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6952028,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2005,412000,0.017496035558011852
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6912979,R44HG002244,"['artificial intelligence', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'genotype', 'informatics', 'mathematical model', 'nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2004,191986,0.06885556539191784
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6737944,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2004,400000,0.017496035558011852
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6622259,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2003,560392,0.06885556539191784
"Development of Bioinformatic Tools for Virtual Cloning    DESCRIPTION (provided by applicant): The ability to delineate (at least in theory) all the proteins encoded in the human genome and all of those encoded by the genomes of major human parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease.  However, the vast increase in biological knowledge that has resulted from the last decade of genomic DNA sequencing has led us to a a crisis in bioinformatics.  This crisis is two-fold: analysis of data and planning of experiments.  Most of the scientific resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology.  All modern experimental molecular biology (and, increasingly, structural biology) depends upon the availability of plasmid clones to address specific scientific questions.  Although software facilitating DNA manipulations exists, few programs advise users of optimal strategies and none automate the process of clone generation. Genomics initiatives identify proteins at the genome level and demand the generation of hundreds of expression clones for recombinant protein production in exogenous hosts such as E. coli.  Establishment of libraries of expression clones requires automation and optimization as well as effective means of data storage, archiving, annotation and query.  To address these needs, as well as to facilitate routine DNA manipulations in virtually any molecular biology laboratory, we propose (1) to test and build a task centered virtual cloning expert system that serves as a knowledge base for DNA manipulations, and (2) to test and build an information automaton for the construction of expression clone libraries in support of structural genomics initiatives and other high throughput experiments.         n/a",Development of Bioinformatic Tools for Virtual Cloning,6583437,R43GM067279,"['artificial intelligence', ' biomedical automation', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' expression cloning', ' gene expression', ' genetic library', ' genetic manipulation', ' informatics', ' molecular biology information system', ' transfection /expression vector']",NIGMS,"VIRMATICS, LLC",R43,2003,100000,0.014001411159095613
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6444292,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2002,531259,0.06885556539191784
"COMPUTER BASED SEQUENCE ANALYSIS AND RNA VIRUS EVOLUTION The goal of the proposed research is the analysis of biological sequence         data to address the molecular mechanisms of evolution and the origin(s)          of all viruses and related genetic elements. Phylogenetic trees will             provide a framework for the mapping of cell and tissue tropism,                  pathogenicity and virulence, modes of transmission and geographical              distributions, and many other higher order characteristics of viruses.           The specific aims of proposed analytical studies are: 1) determining             functionally equivalent networks and frequency of exchange among and             between retroid elements, and their potential cellular homologues,               including new studies on 300 retroviral env proteins; 2) inferring               functionally important regions of all proteins of paramyxo-, rhabdo- and         filoviruses, (with privileged access to new Ebola sequences), and Borna          Disease virus, (including potential BDV sequences from schizophrenic             patients); and 3) the analysis of the dUTPase gene, as a model system,           to address issues relevant to the structure, function and evolution of           duplicated sequences, and potential horizontal transfer among and between        host and viral genomes. The specific aims of the technical studies are:          1) evaluation of stochastic production model approaches for generation           of multiple alignments, detection of recombination, and calculation of           evolutionary distances; and 2) development and testing of new and                existing methods for historical reconstruction of functionally equivalent        networks.                                                                                                                                                         RNA viruses (e.g. HIV, or Ebola) are the major causative agents of human,        animal and plant viral diseases world wide. The heterogeneous nature of          RNA populations makes it difficult to develop effective, anti-viral              agents. The sequence database is now large enough to conduct comparative         studies on natural variants versus chemotheraputically induced mutants           for several retroviral proteins. This model study will provide new               information on the nature of selected mutations which will be useful in          future anti-viral drug development.                                                                                                                               Computational analysis of primary sequence data is an area of intense            interest in biology, mathematics, statistics and systems science. In the         last few years new approaches to problem solving and classification, such        as machine learning, neural networks, genetic algorithms, and stochastic         production models or, ""intelligent systems"" as they are referred to              collectively, have become available. Unfortunately most biologists are           unaware of these developments. Application of these methods to real data         remains unexplored. The proposed studies will go a long way in rectifying        this gap in technological utilization. These studies will continue to            define important evolutionary relationships and events, provide                  biologically informative sequence relationships for bench-marking new            software, and contribute new information relevant to the structure and           function of viral proteins suggesting new directions in laboratory               experimentation. Strategies and techniques developed for the analysis of         highly divergent genomes can also be applied to the study of the wealth          of sequence information generated under the auspices of the Human Genome         Project.                                                                          n/a",COMPUTER BASED SEQUENCE ANALYSIS AND RNA VIRUS EVOLUTION,6163865,R01AI028309,"['DNA replication', ' Mononegavirales', ' RNA biosynthesis', ' biochemical evolution', ' computer assisted sequence analysis', ' computer program /software', ' nucleic acid sequence', ' virus genetics', ' virus protein']",NIAID,MONTANA STATE UNIVERSITY (BOZEMAN),R01,2000,225156,-0.004517029213252227
"POPULATION GENOMICS OF ADAPTATION Project Summary Malaria that results from Plasmodium falciparum is among the most globally devastating human diseases. The principle vector of malaria, mosquitoes of the Anopheles gambiae species complex, are thus central targets for controlling the human health burden of Plasmodium. For nearly two decades, there have been large-scale, coordinated efforts to diminish mosquito populations, generally through spraying and insecticide treated bed nets. Indeed such control efforts have now led to a nearly 50% decrease in the rates of malaria infection in many parts of sub-Saharan Africa. At present, however, control efforts of A. gambiae are being threatened by evolutionary responses within mosquitos: A. gambiae populations have shown increases in insecticide resistance as well as behavioral adaptations that allow mosquitos to avoid spraying all together. Thus adaptation of mosquitos to the control efforts themselves is currently a risk to maintain the gains made in the fight against malaria. In this proposal we lay out an integrated population genomic approach for systematically identifying regions of the A. gambiae genome that are evolving adaptively in response to ongoing control efforts. Our approach centers upon state-of-the-art supervised machine learning techniques that we have recently introduced for finding the signatures of selective sweeps in genomes (Schrider and Kern, 2016), coupled with the large-scale population genomic datasets currently in production by the Ag1000G consortium. Project Narrative Malaria is a mosquito-borne infectious disease that has enormous impacts on human health globally. For the past 16 years, large gains have been made in decreasing the rate of malaria transmission through control of its mosquito vector Anopheles gambiae; unfortunately at present these control efforts are in danger of collapse due to the evolution of insecticide resistance in the mosquitos. We aim to discover the genomic targets of such resistance through the development of sophisticated population genomic approaches and their application to state-of- the-art genome sequence datasets from Anopheles gambiae.",POPULATION GENOMICS OF ADAPTATION,9957109,R01GM117241,"['Affect', 'Africa South of the Sahara', 'Anopheles Genus', 'Anopheles gambiae', 'Awareness', 'Back', 'Beds', 'Behavioral', 'Catalogs', 'Cessation of life', 'Chromosomes', 'Classification', 'Complex', 'Coupled', 'Culicidae', 'Data', 'Data Set', 'Dependence', 'Detection', 'Development', 'Distant', 'Equipment and supply inventories', 'Evolution', 'Frequencies', 'Funding', 'Genome', 'Genomic approach', 'Genomics', 'Geography', 'Goals', 'Health', 'Human', 'Individual', 'Insecticide Resistance', 'Insecticides', 'Link', 'Location', 'Malaria', 'Methodology', 'Methods', 'Mosquito-borne infectious disease', 'Mutation', 'Pattern', 'Phase', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Prevalence', 'Production', 'Recording of previous events', 'Research', 'Residual state', 'Resistance', 'Risk', 'Sampling', 'Techniques', 'Time', 'Variant', 'Work', 'deep neural network', 'fight against', 'genomic data', 'global health', 'human disease', 'machine learning method', 'malaria infection', 'malaria mosquito', 'malaria transmission', 'markov model', 'novel', 'recurrent neural network', 'resistance allele', 'response', 'supervised learning', 'support vector machine', 'tool', 'vector', 'vector control', 'vector mosquito']",NIGMS,UNIVERSITY OF OREGON,R01,2020,295000,0.040837947994814515
"Genetic determinants of 4D genome folding in human cardiac development PROJECT SUMMARY A major unanswered question is how chromatin topology coordinates human development and cellular differentiation, and how genome folding is differentially regulated in human disease. It is thought that three- dimensional (3D) chromatin organization is driven by transcriptional regulators, but fundamental mechanisms of this regulation as it relates to disease-relevant human cells have not been well explored. We propose to elucidate the temporally dynamic 3D nucleome (4DN) that underlies human cardiac differentiation, its molecular underpinnings, and the impact of mutations that underly defective 4DN organization in human congenital heart disease (CHD). CHDs are the most common birth defect and arise from abnormal heart development. The genetic basis of CHD is largely mutations in genes encoding chromatin modifiers (e.g. WDR5, KMT2D) and transcription factors (TFs, e.g. TBX5, GATA4), many of which also cause adult-onset arrhythmias. The impact of CHD mutations on the 4DN has not been explored. We hypothesize that 3D genome folding is highly regulated during cardiac differentiation and is impacted by disease-causing mutations in transcriptional regulators and non-coding elements. We will use iPS cell models and machine learning to elucidate dynamic 3D chromatin organization in human cardiomyocytes and endothelial cells during normal and diseased cardiac differentiation. We propose 3 specific aims: Aim 1: Establish a kilobase-scale 4D map of genome folding in human cardiomyocytes (CM) and endothelial cell (EC) differentiation. We will use directed differentiation of human iPS cells towards the two major cell types of the developing heart: CMs and ECs, and using microC across a fine time course of differentiation we will define at kilobase scale the 3D organization of the genome, capturing the states of developmental intermediates and the final differentiated cells. This aim will generate an essential integrated 4DN template for discovery in cardiac differentiation. In Aim 2: we will Determine the regulatory and disease-related basis for cardiac 3D chromatin organization. We will perform microC in iPS cell lines with CHD-associated mutations in transcriptional regulators, differentiated into CMs and ECs. These findings will establish the degree to which CHD is caused by abnormal genome folding and chromatin states, with important relevance to other human cardiovascular diseases. Finally, Aim 3 will address High-throughput screening of millions of CHD and synthetic non- coding mutations with a deep-learning model of dynamic genome folding. We will build a deep-learning model predicting 3D chromatin contact frequencies across cardiac differentiation at kilobase-resolution. By introducing thousands of CHD patient deletions and other non-coding mutations in silico, we will prioritize variants likely to interact with transcriptional regulators to cause disease through disrupted genome folding. Several candidates will be validated in engineered iPS cells differentiated into CMs and ECs. These results will provide a novel platform for computational discovery of disease variant impact across diverse human diseases PROJECT NARRATIVE Congenital heart defects are present in 1-2 out of 100 births, and are caused by mutations in genes that may control the 3-dimensional organization of chromosomes. We will use human cellular models and Artificial Intelligence to understand how chromosome organization is controlled during heart development and altered by disease processes. This will reveal fundamental concepts of gene regulation and may lead to a better understanding congenital heart defects towards improving diagnosis and treatment.",Genetic determinants of 4D genome folding in human cardiac development,10118056,U01HL157989,"['3-Dimensional', 'ATAC-seq', 'Address', 'Adult', 'Architecture', 'Arrhythmia', 'Artificial Intelligence', 'Birth', 'CCCTC-binding factor', 'Cardiac', 'Cardiac Myocytes', 'Cardiac development', 'Cardiovascular Diseases', 'Cell Differentiation process', 'Cell Line', 'Cell model', 'Cells', 'ChIP-seq', 'Child', 'Chromatin', 'Chromatin Remodeling Factor', 'Chromosome Structures', 'Code', 'Complement', 'Complex', 'Congenital Abnormality', 'Congenital Heart Defects', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Endothelial Cells', 'Engineering', 'Enhancers', 'Family', 'Frequencies', 'GATA4 gene', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Heart', 'Heart Abnormalities', 'Heart Diseases', 'Histones', 'Human', 'Human Biology', 'Human Development', 'Lead', 'Machine Learning', 'Maps', 'Measures', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Patients', 'Phenotype', 'Process', 'Proteins', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Resolution', 'SMARCA2 gene', 'Structure', 'Time', 'Untranslated RNA', 'Variant', 'Work', 'cardiogenesis', 'cell type', 'cohesin', 'computational platform', 'congenital heart disorder', 'deep learning', 'disease-causing mutation', 'high throughput screening', 'histone modification', 'human disease', 'human model', 'human pluripotent stem cell', 'improved', 'in silico', 'machine learning method', 'novel', 'predictive modeling', 'promoter', 'stem cell differentiation', 'stem cell model', 'transcription factor']",NHLBI,J. DAVID GLADSTONE INSTITUTES,U01,2020,742240,0.006355129849766656
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,314933,0.016957190690982844
"Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders The purpose of this training and research application is to study the functional impact of mobile element insertions (MEIs) in neurological disorders (NDs) using new developments in deep learning techniques. MEIs are transposable DNA fragments that are able to insert throughout the human genome. There are at least 124 independent MEIs associated with human diseases. Approximately 20% of these diseases represent a spectrum of NDs, yet the overall contribute of MEIs to the etiology of NDs has not been systematically estimated. To address this, we will (1) characterize functional MEIs in GTEx cohorts in healthy individuals; (2) build a comprehensive functional map of MEIs to determine tissue-specific and brain-specific impact; and (3) impute transcriptional changes on various NDs where whole-genome sequencing (WGS) data will be generated. The proposed application will also develop an extensive research program for Dr. Dadi Gao, a computational biologist and statistical geneticist who has trained in functional genomic studies of alternative splicing in neurodegenerative disorders and therapeutic targeting of a splicing defect that causes a severe neurodevelopmental disorder. He has developed novel methods to investigate regulation of the transcriptome and to facilitate analyses in drug development. He now seeks to expand his expertise by applying statistical and deep learning models on large cohorts of sequencing data from controls and cases with NDs from post-mortem tissues, then impute functional consequences of MEIs from WGS in large-scale disease cohorts. The training plan consists of two years of mentored research to learn new skills in genome analysis, MEI characterization, and advanced deep learning techniques, followed by three years of shaping an independent laboratory. The research plan is developed to comprehensively explore functional variation in the genome by decomposing transcriptomic changes against MEIs. Dr. Michael Talkowski at Massachusetts General Hospital, Harvard, and the Broad Institute will serve as the primary mentor, while Dr. Manolis Kellis at MIT and the MIT Computational Biology Group, and the Broad Institute will serve as a co-mentor and close collaborator. These mentors are recognized experts in genomic structural variants, functional genomics, the genetics of neurological disorders, and computational modeling to establish functional elements in the human genome. In addition, a team of independent investigators from basic and translational research will provide Dr. Gao with comprehensive feedback to keep both his science and career development on track. The highly collaborative environment in CGM, MGH, Harvard Medical School, the Broad Institute and the University of Michigan Medical School will prepare Dr. Gao for his transition to an independent investigator. This outstanding mentorship team and training program will facilitate the career development of Dr. Gao as he seeks to redefine the functional maps of MEIs in the human genome and to impute their impact in large-scale neurological disorders. Mobile element insertions (MEIs) represent a largely undefined component of the genetic architecture of neurological disorders, as a number of MEIs have been associated with alternative splicing in these disorders but large-scale genome-wide functional characterization has not been systematically performed across tissues. This program study will functionally characterize the impact of MEIs on alternative splicing from whole-genome sequencing and transcriptome sequencing in large cohorts using new developments in deep learning models. These results will enhance our understanding of the etiological role and pathogenic mechanisms associated with MEIs in neuronal development and human neurological disorders.",Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders,10041366,K99NS118109,"['Address', 'Algorithms', 'Alternative Splicing', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Basic Science', 'Biology', 'Blood', 'Brain', 'Brain Diseases', 'CRISPR/Cas technology', 'Cells', 'Chromosome Pairing', 'Cohort Studies', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Insertion Elements', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Disease', 'Disease model', 'Dorsal', 'Dystonia', 'Elements', 'Etiology', 'Event', 'Evolution', 'Excision Repair', 'Familial Dysautonomia', 'Feedback', 'Fellowship', 'Filipino', 'General Hospitals', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Haplotypes', 'Human', 'Human Genome', 'Individual', 'Institutes', 'International', 'Introns', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Linear Regressions', 'Link', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Mind', 'Minisatellite Repeats', 'Modeling', 'Molecular', 'Mosaicism', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'Neurons', 'Outcome', 'Parkinsonian Disorders', 'Pathogenicity', 'Pattern', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Prefrontal Cortex', 'Process', 'Property', 'RNA Splicing', 'Regulation', 'Research', 'Research Personnel', 'Retroelements', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Shapes', 'Short Interspersed Nucleotide Elements', 'Source', 'Specificity', 'Structure', 'TAF1 gene', 'Techniques', 'Therapeutic Trials', 'Tissue-Specific Splicing', 'Tissues', 'Training', 'Training Programs', 'Transcription Alteration', 'Translational Research', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'brain tissue', 'career development', 'cohort', 'collaborative environment', 'convolutional neural network', 'deep learning', 'drug development', 'functional genomics', 'functional outcomes', 'gene function', 'genetic architecture', 'genome analysis', 'genome editing', 'genome sequencing', 'genome-wide', 'human disease', 'in silico', 'insight', 'medical schools', 'mind control', 'nervous system disorder', 'neuron development', 'novel', 'programs', 'response', 'skills', 'statistical learning', 'structural genomics', 'therapeutic target', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,91226,-0.0027459186542816215
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,10016298,U01AI157189,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Bar Codes', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'machine learning method', 'next generation', 'novel', 'novel therapeutics', 'off-target mutation', 'off-target site', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2020,610710,0.03807749999636406
"Scalable detection and interpretation of structural variation in human genomes PROJECT SUMMARY Structural variation (SV), is a diverse class of genome variation that includes copy number variants (CNVs) such as deletions and duplications, as well as balanced rearrangements, such as inversions and reciprocal translocations. A typical human genome harbors >4,000 SVs larger than 300bp and their large size increases the potential to delete or duplicate genes, disrupt chromatin structure, and alter expression. Despite their prevalence and potential for phenotypic consequence, SVs remain notoriously difficult to detect and genotype with high accuracy. Much of this difficulty is driven by the fact DNA sequence alignment “signals” indicating SVs are far more complex than for single-nucleotide and insertion deletion variants. Unlike SNP alignments that vary only in allele state, alignments supporting SVs vary in state (supports an alternate structure or not) alignment location, and type. Consequently, the accuracy of SV discovery is much lower than that of SNPs and INDELs. Furthermore, SV pipelines scale poorly and are difficult to run. These challenges are a barrier for single genome analysis and studies of families must invest substantial effort into eliminating a sea of false positives. These problems become exponentially more acute for large-scale sequencing efforts such as TOPmed, the Centers for Common Disease Genetics, and the All of Us program. Software efficiency is key to scalability for such projects. However, of equal importance is comprehensive, accurate discovery.  Building upon more than a decade of software development experience and analyzing SV in diverse disease contexts, we have invested significant effort into understanding the causes of the insufficient accuracy for SV discovery. These efforts, together with our research and development experience in this area, give us unique insight into improving the accuracy and scalability of SV discovery. Our goal is to narrow the accuracy gap between SNP/INDEL variation and structural variation discovery. These developments will empower studies of human genomes in diverse contexts and will therefore have broad impact. Our goals are to: 1. Develop a deep learning model to correct systematic variation in sequence depth. This new machine  learning model will correct systematic biases in DNA sequence depth and dramatically improve the  discovery of deletions and duplications. 2. Improve the speed, scalability, and accuracy of SV detection and genotyping. Using new algorithms,  we will bring the accuracy of SV detection much closer to that of SNP and INDEL discovery and allow  accurate SV discovery to be deployed at scale. 3. Create a map of genomic constraint for SV from population-scale genome analysis. We will deploy  our new methods to detect and genotype structural variation among tens of thousands of human genomes.  The resulting SV map will empower the creation of a model of genomic constraint for SV and enable new  software to predict deleterious SVs, especially in the noncoding genome. PROJECT NARRATIVE Single-nucleotide DNA changes paint an incomplete picture of a human’s genome. A more complete picture must include a genome's structural variation (SV), an important class of genome variation that includes copy number variants (CNVs) such as deletions and duplications. However, existing methods have poor accuracy. As the genetics community transitions to large-scale genome sequencing studies, there is an acute need for improved SV discovery methods. This proposal introduces a series of algorithmic and software innovations that will empower SV discovery, genotyping, and interpretation in large-scale human disease studies.",Scalable detection and interpretation of structural variation in human genomes,9973582,R01HG010757,"['Acute', 'Affect', 'Algorithmic Software', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Area', 'Automobile Driving', 'Biological Assay', 'Chromatin Structure', 'Chromosome Structures', 'Clip', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Data Reporting', 'Detection', 'Development', 'Disease', 'Environment', 'Error Sources', 'Exhibits', 'Family Study', 'Funding', 'Future', 'Gene Duplication', 'Gene Expression', 'Gene Fusion', 'Gene Structure', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Laboratories', 'Large-Scale Sequencing', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Noise', 'Nucleotides', 'Paint', 'Pathogenicity', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Process', 'Reciprocal Translocation', 'Research', 'Running', 'Sampling', 'Sea', 'Sensitivity and Specificity', 'Sequence Alignment', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Speed', 'Structure', 'Systematic Bias', 'Techniques', 'Technology', 'Training', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'algorithm development', 'base', 'convolutional neural network', 'deep learning', 'developmental disease', 'dosage', 'exome', 'experience', 'genome analysis', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'innovation', 'insertion/deletion mutation', 'insight', 'large datasets', 'method development', 'nanopore', 'novel', 'prevent', 'research and development', 'software development', 'success', 'tool', 'variant detection', 'whole genome']",NHGRI,UNIVERSITY OF UTAH,R01,2020,692048,0.030109676957613466
"A big data approach to explore epigenetic heterogeneity and interpret noncoding variants for psychiatric disorders PROJECT ABSTRACT  The incidence of diagnosed psychiatric disorders has been increasing for decades, leaving millions of afflicted individuals. Despite the high heritability, their underlying molecular mechanisms remain elusive. Most risk loci are located in noncoding genomic elements without direct effects on protein products. Comprehensive functional annotation and variant impact quantification are essential to provide new molecular insights and discover therapeutic targets.  Recent advances in novel sequencing technologies and community efforts to share genomic data provide unprecedented opportunities to understand how genetic variants contribute to psychiatric diseases. This application describes the development of integrative strategies and machine learning methods to combine novel assays (such as STARR-seq) with population-scale genomic profiles to elucidate the genetic regulatory grammar in the human prefrontal cortex (PFC) and to prioritize genetic variants in psychiatric disorders. Specifically, we will (1) dissect the cis- regulatory landscape of the PFC using population-scale epigenetics data, (2) construct multi- model gene regulatory networks by linking distal cis-regulatory elements to genes using chromatin co-variability analyses, (3) integrate genetic, epigenetic, and transcriptional data to identify key transcription factors and variants that contribute to psychiatric disorders. Distinct from existing efforts focusing on one genome, this proposed work presents a truly novel big-data approach for both modeling gene regulation and investigating disease-risk factors by incorporating heterogeneous multi-omics profiles from hundreds of individuals. The resultant comprehensive list of cis-regulatory elements will expand the number of known functional regions in the human brain by at least an order. We will release our methods and resources in the form of web services, distributed open-source software, and annotation databases, which will also benefit other investigators exploring the genetic underpinnings of neuropsychiatric disorders.  In addition to its scientific content, this application proposes a comprehensive training program for preparing an independent investigator in computational genomics and neurogenetics. This training will take place at Yale University (in the Dept. of Molecular Biophysics and Biochemistry) under the mentorship of Prof. Mark Gerstein (functional genomics), Prof. Nenad Sestan (neurogenetics), and Prof. Hongyu Zhao (statistical genetics and machine learning). A committee of experienced psychiatric disease experts and data scientists will also provide advice on both scientific research and career development. PROJECT NARRATIVE  The proposed study is to leverage advanced machine learning methods to discover cis- regulatory elements in the noncoding genome by incorporating novel functional characterization technologies (such as STARR-seq) with genetic, epigenetic, and transcriptomic data from psychiatric patients. In contrast to existing methods that rely on a single genome, this work assumes a dynamic regulatory program in each individual and explores the regulatory heterogeneity across hundreds of epigenomes, thereby significantly expanding our current knowledge of the noncoding genome and facilitating functional interpretation of genetic variants. Furthermore, it will also generate publicly available annotation resources and software packages for the scientific community, thereby significantly accelerating the pace of novel therapeutic target discovery for treating psychiatric disorders.",A big data approach to explore epigenetic heterogeneity and interpret noncoding variants for psychiatric disorders,10039384,K01MH123896,"['Affect', 'Award', 'Big Data', 'Binding', 'Biochemistry', 'Biological Assay', 'Biological Process', 'Biophysics', 'Brain', 'ChIP-seq', 'Chromatin', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Scientist', 'Databases', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Distal', 'Elements', 'Enhancers', 'Entropy', 'Epigenetic Process', 'Event', 'Gaussian model', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Heritability', 'Heterogeneity', 'Human', 'Incidence', 'Individual', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mental disorders', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nucleic Acid Regulatory Sequences', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Prefrontal Cortex', 'Proteins', 'Psychiatric Diagnosis', 'Regulator Genes', 'Regulatory Element', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Sampling', 'Scanning', 'Scoring Method', 'Shapes', 'Signal Transduction', 'Technology', 'Training', 'Training Programs', 'Transcriptional Regulation', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'base', 'career development', 'cell type', 'deep learning', 'disorder risk', 'epigenome', 'experience', 'experimental study', 'functional genomics', 'genetic profiling', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'genomic profiles', 'insight', 'machine learning method', 'multimodality', 'multiple omics', 'neurogenetics', 'neuropsychiatric disorder', 'new therapeutic target', 'novel', 'novel sequencing technology', 'open source', 'programs', 'promoter', 'recruit', 'research and development', 'risk variant', 'therapeutic target', 'transcription factor', 'transcriptomics', 'web services']",NIMH,UNIVERSITY OF CALIFORNIA-IRVINE,K01,2020,94262,-0.02914391322076628
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9868315,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'de novo mutation', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'machine learning method', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2020,237600,0.037986825405608556
"Identification of Transposable Element Insertions in the Kids First Data Project Summary Insertion of transposable elements (TEs, sometimes referred to as “jumping genes”) into the human genome can be pathogenic. Our aim in this project is to use sophisticated computational approaches to characterize TE insertions in the whole-genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program and identify any insertional mutations that may disrupt gene function. The large scale of the Kids First program provides an unprecedented opportunity to investigate the role of TE insertions in childhood cancers and structural birth defects, as well as to create a resource of reference TE maps that will be important for all other TE studies. We will first modify our existing algorithm called xTEA for the trio design of the Kids First studies and increase the accuracy and efficiency of the algorithm. Then, we will apply it to the thousands of trios that have been profiled in the Kids First program, using a pipeline optimized for the cloud environment. The resulting set of TE insertions (especially L1, Alu, SVA, and HERV insertions) will be curated with all relevant features and be made into a database for the community. We will also apply machine learning methods to improve the calls once a sufficient amount of training data have been obtained. To investigate the potential pathogenicity of the mutation, we will first focus on insertions within genes, but we will also explore those in regulatory elements inferred from epigenetic profiling data. PROJECT NARRATIVE Transposable elements, or “jumping genes”, are genetic elements that can alter the DNA of an individual. We aim to utilize a computational method to identify such elements in the genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program. Our analysis will identify transposable elements that may be causal for a disease phenotype.",Identification of Transposable Element Insertions in the Kids First Data,9957262,R03CA249364,"['Algorithms', 'Communities', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Insertion Elements', 'DNA Transposable Elements', 'Data', 'Data Set', 'Databases', 'Disease', 'Elements', 'Endogenous Retroviruses', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Human Genome', 'Individual', 'Inherited', 'Insertion Mutation', 'Jumping Genes', 'Length', 'Location', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Maps', 'Mendelian disorder', 'Methods', 'Modeling', 'Mutation', 'Neurons', 'Output', 'Parents', 'Paste substance', 'Pathogenicity', 'Pediatric Research', 'Play', 'Population', 'Regulatory Element', 'Reporting', 'Resources', 'Retrotransposon', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Speed', 'Structural Congenital Anomalies', 'Training', 'base', 'cloud based', 'cohort', 'design', 'disease phenotype', 'epigenetic profiling', 'gene function', 'genetic element', 'genome sequencing', 'improved', 'machine learning method', 'proband', 'programs', 'transcriptome sequencing', 'whole genome']",NCI,HARVARD MEDICAL SCHOOL,R03,2020,169041,0.019405550181046387
"Computational modeling of spatial genome organization and gene regulation PROJECT SUMMARY/ABSTRACT The three-dimensional (3D) organization of the genome plays an essential role in genome stability, gene regulation, and many diseases, including cancer. The recent development of high-throughput chromatin conformation capture (Hi-C) and its variants provide an unprecedented opportunity to investigate higher-order chromatin organization. Despite the rapidly accumulating resources for investigating 3D genome organization, our understanding of the regulatory mechanisms and functions of the genome organization remain largely incomplete. Hi-C analyses and 3D genome research are still in their early stage and face several challenges. First, high-resolution chromatin contact maps require extremely deep sequencing and hence have been achieved only for a few cell lines. Second, it is computationally challenging to complement 3D genome structure with one-dimensional (1D) genomic and epigenomic features. Third, recent studies have just begun to infer associations between chromatin interactions and genetic variants and to identify potential target genes of those variants at the genome-wide scale. Given these challenges and my unique multi-disciplinary training, my long-term research goal is to develop innovative computational and statistical methods to uncover the interplay between 3D genome structure and function. Speciﬁcally, in the next ﬁve years, I will i) develop computational approaches to enhance the resolution of existing Hi-C data and investigate ﬁne-scale 3D genome architecture as well as its spatiotemporal dynamics and ii) build scalable and interpretable machine learning models that leverage 1D epigenomic data to predict cell type-speciﬁc 3D chromatin interactions and gene expression and elucidate the function of 3D genome organization in gene regulation and human diseases. The completion of the proposed work will deepen our knowledge of 3D genome architecture as well as its functions in gene regulation and disease. PROJECT NARRATIVE The overarching mission of my research is to understand the interplay between genome architecture and gene regulation. Recent development of high-throughput chromatin conformation capture techniques has allowed us to look beyond the nucleotide sequence of DNA and investigate the principles of higher-order chromatin organization. I will develop innovative computational and statistical strategies to investigate 3D genome organization at an unprecedented scale, thereby elucidating the impacts of genome organization on gene regulation and disease.",Computational modeling of spatial genome organization and gene regulation,9999005,R35GM133678,"['3-Dimensional', 'Architecture', 'Base Sequence', 'Cell Line', 'Chromatin', 'Complement 3d', 'Computer Models', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Dimensions', 'Disease', 'Face', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome Stability', 'Genomics', 'Goals', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mission', 'Modeling', 'Play', 'Research', 'Resolution', 'Resources', 'Role', 'Statistical Methods', 'Structure', 'Techniques', 'Training', 'Variant', 'Work', 'cell type', 'chromosome conformation capture', 'deep sequencing', 'epigenomics', 'genetic variant', 'genome-wide', 'human disease', 'innovation', 'multidisciplinary', 'spatiotemporal']",NIGMS,UNIVERSITY OF CALIFORNIA RIVERSIDE,R35,2020,378309,0.006515071062863377
"Joint analysis of 3D chromatin organization and 1D epigenome Abstract After the completion of the Human Genome Project, thousands of experiments from ENCODE and Roadmap Epigenomics projects have successfully proﬁled regulatory elements and epigenetic landscape along the genome. More recently, over 2,000 chromatin organization datasets have been generated from 4D Nucleome (4DN) Project, and they provide complementary information about how these genomic and epigenomic elements are spatially organized in a nucleus. Joint analysis of 3D chromatin organization with previously proﬁled 1D epigenome in different cell types will be a key step to understand the mechanisms underlying transcriptional regulation over long genomic distances. However, there are two challenges. First, there is a resolution mismatch between chromatin organization data (e.g. Hi-C contacts) which are usually measured at 10k base pair resolution, and epigenome-based chromatin state features (e.g. ChIP-seq peaks) whose signals are usually at tens to hundreds of base pairs. Second, existing computational approaches for analyzing epigenome, such as annotating genome and understanding regulatory elements, all treat the DNA sequence as one-dimensional data, leaving the important 3D structural information unutilized. We aim to develop the most cutting-edge deep learning approaches for understanding the relationship between chromatin state features and chromatin organization, performing 3D and 4D genome annotation, and identifying spatially collaborative transcription factors, respectively. After the completion of the proposed work, we expect to have: (1) an accurate and interpretable computational model to predict chromatin contact maps at nucleosome resolution for a wide range of cell lines, (2) 3D and 4D genome annotations over dynamic chromatin organization, regulatory elements and epigenomic features, and (3) a computational method for identifying spatially collaborative transcription factors which can help us understand the orchestration of noncoding genetic variants. These results will provide fundamental understanding of disease-relevant genetic variation in the light of the spatial organization of these genomic and epigenomic elements and their functional implications. Project Narrative The goal of this project is to develop novel computational methods to jointly analyze 3D chromatin organization data and 1D epigenomic features, and reveal the interplay among regulatory elements, epigenomic features, and dynamic chromatin organization. These new methods will help us understand the mechanisms of the genetic variants identiﬁed in genome-wide association studies, and understand the genetic basis of many human diseases.",Joint analysis of 3D chromatin organization and 1D epigenome,10046394,R35HG011279,"['3-Dimensional', 'Base Pairing', 'Cell Line', 'Cell Nucleus', 'ChIP-seq', 'Chromatin', 'Computer Models', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Elements', 'Epigenetic Process', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Human Genome Project', 'Joints', 'Maps', 'Measures', 'Methods', 'Nucleosomes', 'Regulatory Element', 'Resolution', 'Signal Transduction', 'Three-dimensional analysis', 'Transcriptional Regulation', 'Untranslated RNA', 'Work', 'base', 'cell type', 'deep learning', 'epigenome', 'epigenomics', 'experimental study', 'genetic variant', 'genome annotation', 'genome wide association study', 'human disease', 'novel', 'three dimensional structure', 'transcription factor']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R35,2020,432839,0.011740529343740987
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9870944,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2020,397125,0.03854579376617691
"Direct Determination of Multiple Specific Forms of DNA Chemical Modifications in Human Genome PROJECT SUMMARY/ABSTRACT The information content of DNA is not limited to the primary sequence (A, C, G, T), but is also conveyed by chemical modifications of individual bases. For example, DNA methylation, specifically 5-methylcytosine (5mC), has been widely studied for its important regulatory roles in human development and diseases. In addition, the discovery of active demethylation of 5mC, mediated by TET enzymes, into 5-hydroxymethylcytosine (5hmC), 5-formylcytosine (5fC) and 5-carboxylcytosine (5caC) revealed great insights into the dynamic nature of the human methylome and its close relevance to multiple human diseases. Beyond these chemical modifications to cytosine, recent studies by us and others discovered that N6-methyladenine (6mA), another form of methylation previously thought exclusively existing in bacteria and protozoa, also exists in eukaryotic genomes including the human genome. In addition to these epigenetic marks, different forms of DNA damages represent another category of DNA chemical modifications that are of important biological relevance. Although a few methods for mapping individual chemical modifications have been developed and some are widely used, it is usually hard for broad researchers to master every protocol to map each form of modification. While third- generation sequencing technologies support the direct detection of DNA modifications, they face fundamental challenges distinguishing among different forms of modifications. The objective of this project is to develop a novel technology for the direct mapping of multiple forms of DNA methylation and DNA damage events simultaneously. The core idea is that each form of nucleic acid modification has a unique signature in terms of their physical interaction with DNA polymerase, or nanopores in third-generation sequencing; and these signatures can be modeled by deep learning methods. We will develop this technology using multiple innovative strategies to address a few fundamental challenges, and then comprehensively evaluate the technology to facilitate broad applications. PUBLIC HEALTH RELEVANCE Chemical DNA modifications are crucial components of human genome that controls many important biological processes in human development and human diseases. In this project, we will develop a novel technology for direct mapping of multiple and specific forms of DNA modifications, which will enable us and a large number of researchers to more effectively study the functions of DNA modifications in human genome. !",Direct Determination of Multiple Specific Forms of DNA Chemical Modifications in Human Genome,10267380,R56HG011095,"['Address', 'Antibodies', 'Bacteria', 'Biological', 'Biological Process', 'Categories', 'Characteristics', 'Chemicals', 'Chemistry', 'Classification', 'Complex', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Methylation', 'DNA Modification Process', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Detection', 'Development', 'Ensure', 'Enzymes', 'Epigenetic Process', 'Event', 'Face', 'Future', 'Genome', 'Goals', 'Heterogeneity', 'Human', 'Human Characteristics', 'Human Development', 'Human Genome', 'Immunoprecipitation', 'Individual', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Modification', 'Neurons', 'Nucleic Acids', 'Oligonucleotides', 'Ploidies', 'Positioning Attribute', 'Protocols documentation', 'Protozoa', 'Research Personnel', 'Resolution', 'Role', 'Technology', 'Third Generation Sequencing', 'Thymine', 'Time', 'Training', 'Variant', 'base', 'bisulfite sequencing', 'cancer risk', 'cell type', 'cost', 'deep learning', 'demethylation', 'human disease', 'innovation', 'insight', 'learning strategy', 'methylome', 'nanopore', 'network models', 'new technology', 'novel', 'predictive modeling', 'public health relevance', 'sequencing platform', 'single molecule real time sequencing']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R56,2020,233456,0.036761215579262235
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9928344,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2020,1186500,0.05413325088507007
"Advanced algorithms to infer and analyze 3D genome structures Project Summary For the past decade, the population-cell Hi-C technique has significantly improved our ability to discover genome-wide DNA proximities. However, because population Hi-C is based on a pool of cells, it will not help us reveal each single cell's 3D genome structure or understand cell-to-cell variability in terms of 3D genome structure and gene regulation. It is also difficult to achieve a high resolution, such as 1 Kbp, with population Hi- C; therefore, when finding and analyzing the spatial interactions for the promoter or enhancer regions typically associated with biologically-important regulatory elements, population Hi-C data's resolution is too low to be useful. Moreover, while we know that the CTCF-cohesin complex plays a key role in the formation of genome 3D structures, the question is whether long non-coding RNAs (lncRNAs) are involved in the process since lncRNAs have been found to recruit proteins needed for chromatin remodeling, and our preliminary research has found that lncRNA LINC00346 directly interacts with CTCF. Finally, while members of the bioinformatics community, including the PI, have developed many algorithms to reconstruct 3D genome structures based on population Hi-C data, important questions still must be answered regarding how 3D genome structures are involved in gene regulation and whether there are relationships between 3D genome structures and genetic and epigenetic features. The PI proposes to conduct leading research to overcome these challenges and address these questions. During the next five years, the PI will develop algorithms to reconstruct the 3D whole- genome structures for single cells and analyze cell-to-cell variabilities in terms of 3D genome structure and gene regulation. The PI will develop a deep learning algorithm to enhance the resolution of population Hi-C data to that of Capture Hi-C data (1 Kbp) so that we can make good use of the large amount of Hi-C data accumulated in the past decade. An online database will be built to allow the community to access both population and single-cell 3D genome structures in an integrated way. The PI will work with a cancer biologist to discover any lncRNAs that function as a scaffold to fine-tune the CTCF-cohesin protein complex, as well as two neuron scientists to develop a more complete understanding of gene regulation while considering 3D genome and other genetic and epigenetic features. Given the PI's track record and productivity, having three computational goals and two collaborative goals is not only feasible but computationally and biologically rewarding. In five years, once the proposed studies are accomplished, the PI should have established a uniquely independent place in the field of 3D genome, maintaining leading positions in inferring single-cell 3D genome structures, enhancing Hi-C data resolution, and building 3D genome databases, while establishing similar positions in reconstructing high-resolution 3D genome structures, finding lncRNAs' roles in the formation of genome structures, and understanding how 3D genome structures are involved in gene regulation. Project Narrative The three-dimensional (3D) structure of genome is critically important for gene regulation; and the abnormal 3D genome structures are often associated with diseases such as cancer. This proposal aims to reconstruct and analyze the 3D genome structures of thousands of individual cells, study how 3D genome structures participate in gene regulation, determine whether long noncoding RNAs (lncRNAs) are involved in the formation of genome structures, and build an online knowledge base integrating 3D genome structures with other biological information.",Advanced algorithms to infer and analyze 3D genome structures,10027542,R35GM137974,"['3-Dimensional', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Cells', 'Communities', 'Complex', 'DNA', 'Data', 'Databases', 'Disease', 'Enhancers', 'Epigenetic Process', 'Gene Expression Regulation', 'Genetic', 'Genome', 'Goals', 'Individual', 'Malignant Neoplasms', 'Neurons', 'Other Genetics', 'Play', 'Population', 'Positioning Attribute', 'Process', 'Productivity', 'Proteins', 'Regulatory Element', 'Research', 'Resolution', 'Rewards', 'Role', 'Scientist', 'Structure', 'Techniques', 'Untranslated RNA', 'Work', 'base', 'chromatin remodeling', 'cohesin', 'deep learning algorithm', 'genome database', 'genome-wide', 'improved', 'knowledge base', 'member', 'promoter', 'protein complex', 'recruit', 'scaffold', 'three dimensional structure', 'whole genome']",NIGMS,UNIVERSITY OF MIAMI CORAL GABLES,R35,2020,354694,0.012329431851271376
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9876220,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2020,479215,0.07518726299427876
"A database for high-resolution chromatin contact maps and human genetic variants Abstract After the completion of the Human Genome Project, several landmarking consortia have accumulated large amounts of genomic data towards understanding the functions of human genome. The ENCODE project has annotated genome-wide regulatory elements. The Roadmap Epigenomic project has characterized tissue-speciﬁc variation in epigenetic state. The NIH Common Fund GTEx project has delineated tissue-speciﬁc gene expression and transcription regulation. The NIH Common Fund 4D Nucleome (4DN) project has revealed dynamic 3D chromatin organization in many cell and tissue types. Each of the aforementioned consortia has generated thousands or even tens of thousands of datasets, and provided different insights regarding human genome at an unprecedent scale and depth. However, the datasets generated from these consortia are isolated in terms of cell types and tissue types covered, how the data are stored, and the resolution of the genomic data. These gaps bring realistic data analysis challenges to biomedical researchers when they use these public datasets jointly in their research — they need to go through different data portals with heterogeneous processing pipelines, different data formats, and unmatched resolutions. We aim to develop the most cutting-edge deep learning approaches to impute high-resolution chromatin contact maps, and integrate the high-resolution chromatin contact maps with transcriptional data available from GTEx project and epigenomic data from ENCODE/Roadmap. We plan to share the integrated data on a public web server with a multi-panel interactive visualization genome browser. The integrated data will provide an important resource for understanding of tissue-speciﬁc genetic variation in the light of the spatial organization of these genomic and epigenomic elements and their functional implications. Project Narrative The goal of this project is to develop novel computational methods to integrate 4DN datasets with GTEx datasets and ENCODE/Roadmap datasets. The integrated datasets will be critical resource to unveil the mechanisms of the genetic variants identiﬁed in genome-wide association studies. The new knowledge gained here could help us understand the genetic basis of many human diseases.",A database for high-resolution chromatin contact maps and human genetic variants,10109293,R03OD030599,"['3-Dimensional', 'Address', 'Area', 'Base Pairing', 'Cells', 'Chromatin', 'Chromatin Structure', 'Communities', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Elements', 'Epigenetic Process', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Internet', 'Knowledge', 'Maps', 'Molecular', 'Nucleosomes', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Technology', 'Tissue-Specific Gene Expression', 'Tissues', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'cell type', 'data format', 'data integration', 'data portal', 'data resource', 'data visualization', 'deep learning', 'epigenomics', 'expectation', 'genetic variant', 'genome annotation', 'genome browser', 'genome sciences', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'insight', 'interest', 'next generation sequencing', 'novel', 'open data', 'web server']",OD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2020,265495,0.010301401202193167
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9858390,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2020,2000000,0.032497315773930335
"Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation Project Summary The ENCODE project has generated comprehensive maps of cis-regulatory elements (CREs) controlling the transcription of genes within the human genome. These maps have been crucial in our efforts to understand sequence variants linked to human traits and disease, as the majority of these variants are non- coding regulatory changes rather than amino acid substitutions. However, even though we know the locations of thousands of CREs, our understanding of how they operate is derived from a relatively small set of well- described examples. Therefore, we plan to directly characterize the function of ENCODE CREs at a genome- wide scale in multiple cell-types. This will transition the field of functional genomics from a simple map of regulatory elements towards a deep understanding of the fundamental rules governing regulatory logic down to the basepair resolution. Achieving this will dramatically expand ENCODE's utility by strengthening our ability to interpret the effects of natural human variation on gene regulation. We propose to directly measure regulatory activity of over 3% of the genome, pursuing loci highlighted as important by ENCODE and other functional data. We will first apply computational methods to identify the most biologically informative CREs, representing a diversity of regulatory logic and architecture, and will use machine learning techniques to prioritize functional variants for characterization relevant to common and rare human diseases, traits, and adaptation. Of these we will select 200,000 CREs and 300,000 variants, representing 100 Mb of genomic sequence, and characterize them using the massively parallel reporter assay (MPRA) to understand each element's regulatory activity. Then, to complement data from the MPRA, we will characterize additional 1 Mb regions across 10 loci using CRISPR-based non-coding screens to build a comprehensive picture of these loci. This strategy leverages the throughput and flexibility of MPRA while maintaining the connectivity of regulatory logic in the CRISPR-based screens, which perturb elements within their endogenous genomic context. This will help us judge the accuracy and completeness of ENCODE, while also providing data from both approaches to address a wide-variety of research questions. These methods are difficult to apply to disease relevant primary cells at full scale, but we will use the results of our MPRA and CRISPR screens to inform our models and better predict the fundamental rules of regulatory logic. We will then construct smaller, targeted libraries to test disease-specific variants in primary cells and use assays specific for each of three autoimmune diseases: type 1 diabetes, inflammatory bowel disease, and lupus. This approach will inform the research community on the rules governing the activity of the CREs mapped by the ENCODE project, and will simultaneously provide concrete information about the function of hundreds of thousands of sequence variants relevant for human traits, health, and disease. Project Narrative In our proposal we seek to extend the efforts by the ENCODE consortium and others who have made significant strides towards mapping the regulatory landscape of the human genome. We will apply large-scale functional characterization methods to directly test over 3% of the human genome for cis-regulatory activity. In doing so, we will create a resource that will improve our ability to pinpoint regulatory elements in our genome, increase our understanding of how they function, and aid in our ability to link genetic variation to human health and disease.",Comprehensive functional characterization and dissection of noncoding regulatory elements and human genetic variation,9952404,UM1HG009435,"['Address', 'Amino Acid Substitution', 'Architecture', 'Autoimmune Diseases', 'Benchmarking', 'Biochemical', 'Biological', 'Biological Assay', 'Bypass', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Catalogs', 'Cell Differentiation process', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Dissection', 'Elements', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'HepG2', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inflammatory Bowel Diseases', 'Insulin-Dependent Diabetes Mellitus', 'K-562', 'Learning', 'Libraries', 'Link', 'Location', 'Logic', 'Lupus', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Resources', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Untranslated RNA', 'Variant', 'Work', 'base', 'biological systems', 'cell type', 'computerized tools', 'design', 'experimental study', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'improved', 'interest', 'tool', 'trait']",NHGRI,"BROAD INSTITUTE, INC.",UM1,2020,1496387,0.016774691031348137
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9881184,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'force sensor', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2020,48719,-0.006031550746437383
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9902467,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'stem cells', 'tissue stem cells', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2020,324350,0.025793680623149583
"A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data Project Summary / Abstract Mass spectrometry-based proteomics, used in conjunction with genomics, has been called proteogenomics. Recent exponential increases in variant identification by next-generation sequencing (NGS) is redefining the concept of the human genome/proteome. Our project is the commercialization of a first-to-market proteomic database search engine for mass spectrometry capable of directly reading NGS data for the identification of mutilations from individual samples or from curated resources. Such an offering has the potential to bring together these two fields, enabling validation of mutations at the protein-level. Mutated proteins have been shown to make ideal targets for drug therapies and diagnostics in cancer. Our software will provide an intuitive user experience, approachable by scientists who may not be expert both proteomic and genomic data analysis. Since the search engine is guided by prior knowledge, performance exceeds current practice. The software will come complete with a full array of post-processing validation, and visualization tools. Project Narrative The detection of protein variants, which differ from those predicted from the reference human genome sequence, can make ideal candidates for the development of targeted treatments and diagnostics for many clinical conditions such as cancer. This project proposes the development a first-of-its-kind “proteogenomics” search engine for the identification of protein variants by mass spectrometry, making direct use of genomic data and ever-growing public and private databases of genetic variation.",A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data,10082114,R44CA217432,"['Agreement', 'Cancer Vaccines', 'Clinical', 'Communities', 'Complement', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Databases', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Environment', 'Future', 'Gefitinib', 'Genetic Databases', 'Genetic Diseases', 'Genetic Variation', 'Genomics', 'Goals', 'Guidelines', 'Heterozygote', 'Human Genome', 'Individual', 'Informatics', 'Intuition', 'Ions', 'Isomerism', 'Knowledge', 'Licensing', 'Malignant Neoplasms', 'Marketing', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Modification', 'Monitor', 'Mutate', 'Mutation', 'Mutation Detection', 'Pathway interactions', 'Peptides', 'Performance', 'Phase', 'Post Translational Modification Analysis', 'Privatization', 'Probability', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Readability', 'Reading', 'Research', 'Resolution', 'Resources', 'Risk', 'Running', 'Sales', 'Sampling', 'Scientist', 'Services', 'Small Business Innovation Research Grant', 'Testing', 'Transcript', 'Validation', 'Variant', 'Visualization', 'Visualization software', 'Work', 'base', 'commercialization', 'cost', 'experience', 'genomic data', 'graphical user interface', 'human reference genome', 'improved', 'next generation sequencing', 'open source', 'protein expression', 'proteogenomics', 'prototype', 'repository', 'scaffold', 'search engine', 'support vector machine', 'targeted treatment', 'tool', 'transcriptome sequencing']",NCI,"SPECTRAGEN INFORMATICS, LLC",R44,2020,529294,-0.01633581652235922
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9959498,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2020,360268,0.051943468210594375
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,10145865,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'learning classifier', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2020,9815,0.02834256577103281
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,10260680,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,177000,0.050223505106682366
"Predicting and analyzing variation in cellular interactomes Project Summary Over the last two decades, significant experimental efforts have determined large sets of “reference” interactions for humans and other model organisms, along with substantial knowledge about the binding specificities of proteins, including for a large fraction of human transcription factors (TFs). The resulting data have proven to be an incredibly useful resource for understanding how cells function; nevertheless, they do not capture how molecular interactions and networks are different from the reference across individuals. Indeed, while human genomes in both healthy and disease populations are rapidly being sequenced, the corresponding individual-specific interaction networks remain largely unexamined; this represents a major gap in our knowledge, as mutations that alter molecular interactions underlie a wide range of human diseases. Further, the substantial amount of genetic variation across populations makes it infeasible in the near term to experimentally determine per-individual interaction networks. Thus our long-term goal is to develop computational methods to uncover whether and how mutations within coding and non-coding portions of the genome perturb cellular interactions and networks. Our specific aims are: (1) We will develop computational structure-based approaches to identify and catalog, at proteome-scale, variations within proteins that are likely to impact their ability to bind with DNA, RNA, small molecules, peptides or ions, thereby providing a comprehensive resource for analyzing protein interaction variation. (2) We will develop novel structure-based and probabilistic methods to predict how DNA-binding specificities are altered when a TF is mutated; since mutated TFs have been linked to numerous diseases, this will be a great aid in understanding disease networks and pathology. (3) We will develop new methods to uncover non-coding somatic mutations that alter human regulatory networks in cancer; this is a critical step towards ultimately uncovering patient-specific cancer networks. Overall by pursuing these aims—which integrate mutational information with existing knowledge about reference interactions, interfaces and specificities—we will develop novel computational methods that will significantly advance our understanding of molecular interactions perturbed in disease and healthy contexts. Narrative The proposed research will yield new software tools that predict whether specific genetic mutations alter molecular interactions and networks. Since many human diseases are caused by mutations that affect molecular interactions, this research will expand our understanding of the underlying basis of disease and will provide new avenues for diagnosis and treatment.",Predicting and analyzing variation in cellular interactomes,9896829,R01GM076275,"['Affect', 'Alleles', 'Amino Acid Sequence', 'Animal Model', 'Binding', 'Binding Proteins', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Process', 'Catalogs', 'Cell physiology', 'Code', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Binding', 'DNA Sequence Alteration', 'DNA-Protein Interaction', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Human Genome', 'Individual', 'Infrastructure', 'Internet', 'Ions', 'Knowledge', 'Ligand Binding', 'Link', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Mutagenesis', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Organism', 'Pathology', 'Patients', 'Pattern', 'Peptides', 'Play', 'Population', 'Property', 'Protein Analysis', 'Proteins', 'Proteome', 'RNA', 'Regulator Genes', 'Research', 'Resources', 'Sampling', 'Site', 'Software Tools', 'Somatic Mutation', 'Specificity', 'Structure', 'Untranslated RNA', 'Variant', 'Work', 'Zinc Fingers', 'base', 'cancer genome', 'disease-causing mutation', 'experimental study', 'human disease', 'improved', 'interest', 'knowledge base', 'machine learning method', 'novel', 'predictive tools', 'preference', 'small molecule', 'software development', 'transcription factor', 'tumor', 'virtual']",NIGMS,PRINCETON UNIVERSITY,R01,2020,312660,0.010688869360500978
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9957082,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,193576,0.050223505106682366
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",10116927,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic testing', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2020,864183,0.007318566013144837
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9923466,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large scale data', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,446831,0.0038424298917522095
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10156141,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'structured data', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2020,2075409,0.024961552982616323
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,10090262,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,38074,0.034440739395652294
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9882227,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,591815,0.034440739395652294
