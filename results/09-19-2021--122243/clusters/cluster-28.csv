text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9619075,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,318386,0.1751762766877908
"Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure,9698845,U01AA014809,"['3-Dimensional', '3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Algorithmic Software', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Printing', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Screening procedure', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'automated image analysis', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'learning strategy', 'maternal cigarette smoking', 'mouse model', 'neonatal period', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'prenatal testing', 'recruit', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure']",NIAAA,UNIVERSITY OF OXFORD,U01,2019,228537,0.0913413877217027
"Image Analysis of Neurofacial Effects of Prenatal Alcohol Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol Exposure,9903711,U01AA014809,"['3-Dimensional', '3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Algorithmic Software', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Printing', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Screening procedure', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'automated image analysis', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'learning strategy', 'maternal cigarette smoking', 'mouse model', 'neonatal period', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'prenatal testing', 'recruit', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure']",NIAAA,UNIVERSITY OF OXFORD,U01,2019,96641,0.0913413877217027
"Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues. People signal their internal emotional state by a range of cues including facial expressions, non-verbal vocalizations and the tone and content of speech. Much work to date on emotional signaling has focused on a small number of emotions and has relied on stimulus sets with limited numbers of exemplars and poor representation of individuals of different ages and ethnicities. The computer vision literature has long recognized the need to be able to compare models, for example of face recognition, across complex, diverse, and naturalistic stimulus sets. Here, we argue that a parallel approach needs to be applied if we are to achieve a robust and generalizable understanding of how the human brain represents emotion and identity related information derived from facial and vocal cues. Three multi-session functional magnetic resonance imaging (fMRI) experiments are proposed. In the first, participants will view a large corpus (~2000) of faces of individuals varying in age, gender and ethnicity and showing a wide range of emotional expressions. In the second, participants will be presented with a large (~1000) and equally diverse set of emotional vocalizations. The third experiment will make use of an even more complex and naturalistic stimulus set comprising ~1000 video clips of individuals expressing emotions through facial expression, non-verbal vocalizations and emotion-laden speech. This set will be broken into three parts, with as closely matched content as possible. These will be presented to participants in audio only, visual only and audio-visual (bimodal) conditions, with the stimuli allocated to each condition balanced across participants. For each experiment, data collection will comprise separate Model Estimation and Model Validation periods with the majority of stimuli presented at Validation being distinct from those presented at Estimation. A range of models will be fit to the fMRI data acquired during Estimation runs and tested and compared using data acquired during Validation runs. These models contain sets of features that describe the emotional content of the stimuli presented in terms of either dimensional or categorical models of emotion. By comparing the fit of these models we can determine which models capture most variance in voxel response profiles and examine how this varies across brain regions. Across the three experiments, we also seek to establish whether there are regions where voxels show common coding of emotional state regardless of whether information is carried by facial or vocal cues or a combination of both. Further, by contrasting models with and without terms for characteristics such as age, gender and ethnicity we can also investigate the (in)dependence of the representation of emotion and identity-related features. The proposed research has the potential to greatly advance our understanding of how cues to others' emotional state are represented in the human brain and the extent to which this is influenced by the characteristics of the person we are interacting with. In the medium term, we plan to extend this to also model listener/ viewer characteristics (both demographics and predisposition to anxiety or depression) in a hope to advance our understanding of how biases in the interpretation of emotional signals can arise. Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial  and vocal cues. Individuals with psychiatric conditions ranging from Social Anxiety and Depression to Autism Spectrum Disorder and Schizophrenia struggle to correctly interpret others' emotional states. To understand how alterations in brain function can give rise to the misperception of emotion cues, we first need better normative models of how information about others' emotional state derived from facial and vocal cues is represented within the human brain. Hence, here we use large, diverse and naturalistic stimulus sets encompassing facial expressions, emotional vocalizations and multi-modal videos to investigate the extent to which consistent representation of emotional state is observed across stimulus modalities, and to explore the organizational principles that can best explain voxel response profiles or tuning patterns to facial and vocal emotion cues.",Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues,9731295,R01MH112541,"['Address', 'Age', 'Anxiety', 'Arousal', 'Auditory', 'Brain', 'Brain region', 'Categories', 'Characteristics', 'Clip', 'Code', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Decision Making', 'Dependence', 'Dimensions', 'Emotional', 'Emotions', 'Ethnic Origin', 'Expressed Emotion', 'Face', 'Face Processing', 'Facial Expression', 'Functional Magnetic Resonance Imaging', 'Gender', 'Human', 'Image', 'Individual', 'Label', 'Literature', 'Mental Depression', 'Mental disorders', 'Modality', 'Modeling', 'Participant', 'Pattern', 'Persons', 'Predisposition', 'Property', 'Research', 'Running', 'Schizophrenia', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Validation', 'Visual', 'Weight', 'Work', 'autism spectrum disorder', 'blood oxygen level dependent', 'data acquisition', 'data modeling', 'demographics', 'experimental study', 'imaging study', 'information model', 'multimodality', 'neural model', 'novel', 'relating to nervous system', 'response', 'showing emotion', 'social anxiety', 'theories', 'trait', 'visual information', 'visual neuroscience', 'vocalization']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2019,125000,0.18303505052531757
"Craniofacial Microsmia: Facial Expression from Ages 1 to 3 Years Project Summary Significance. Craniofacial microsomia (CFM) impairs facial muscle movement, speech, and hearing, and compromises socio-emotional development. Children with CFM have elevated levels of internalizing behavior (shy, withdrawn) and reduced social competence and peer acceptance. Unknown at present are the mechanisms through which CFM and these social-emotional outcomes become linked. Facial asymmetries and cranial neuropathies associated with CFM likely play an important role in impairing socio-emotional outcomes. Asymmetries of the facial skeleton, soft tissue, and cranial nerve have both intra- and interpersonal effects. Intra-personally, they impact function (unilateral hearing loss, malocclusion, facial expressiveness) and form (noticeable craniofacial malformations), which can impair social signaling and responsiveness. Because asymmetry is negatively correlated with attractiveness, there may be non-specific social effects as well. Many surgical treatments for CFM are designed to restore facial symmetry in static pose (e.g., neutral expression). Less is known about restoring or even measuring spontaneous facial expressiveness. From a developmental perspective, one of the most important consequences of limitations in facial muscle movement is its potentially negative impact on affective communication. In a longitudinal design, we propose to test the hypothesis that deficits in facial expressiveness and structural and functional asymmetry increase risk for internalizing and externalizing problems. If supported, the findings would inform our understanding of socio-emotional development in children with CFM and contribute to clinical evaluation and treatment. Innovation. This is the first effort to 1) use automated, objective measurement of facial expressiveness of communicative behavior and functional asymmetry of children with CFM; 2) model change with development in these parameters and their relation to internalizing and externalizing problems; and 3) use machine learning to investigate the relation among dynamics of expressiveness and asymmetry in relation to CBCL. Approach. Children with and without CFM will be video-recorded at 1 and 3 years with an examiner. Age 1 is an interactive context intended to elicit positive and negative emotion. Age 3 is an interactive context to assess expressive speech and attention. Expressiveness and structural and functional asymmetry are assessed using automatic, objective computer-vision based measurement. Analyses include complementary approaches: statistical (regression and ANOVA) hypothesis testing and machine learning (convolutional neural networks). Relevance Using objective, automatic computer-vision-based measurements, we propose to test the hypothesis that deficits in facial expressiveness and structural and functional asymmetry among children with CFM increases their risk for internalizing and externalizing problems. If supported, clinical assessments of expressiveness and functional asymmetry could effectively target children for specialized interventions and be used to evaluate surgical interventions. Because the proposed procedures are cost effective, they could be applied in a wide range of settings to benefit children with craniofacial disorders and have applicability to other conditions and age groups in which facial expression is compromised (e.g., Mobius Syndrome, Bell's Palsy, injury/burns, and stroke). Project Narrative Craniofacial microsomia (CFM) is among the most common craniofacial anomalies. CFM impairs facial muscle movement, speech, and hearing, and compromises socio-emotional development. Using computer-vision based face analysis, statistical analysis (regression and ANOVA), and machine learning, we will investigate the relation among expressiveness, structural and functional asymmetry, and behavior problems in children with CFM.",Craniofacial Microsmia: Facial Expression from Ages 1 to 3 Years,9525940,R03DE026513,"['1 year old', '3 year old', 'Affective', 'Age', 'Analysis of Variance', 'Articulation', 'Attention', 'Behavior', 'Bell Palsy', 'Biological Neural Networks', 'Burn injury', 'Child', 'Child Behavior Checklist', 'Clinical Treatment', 'Clinical assessments', 'Communication', 'Computer Vision Systems', 'Cranial Nerves', 'Cranial nerve diseases', 'Craniofacial Abnormalities', 'Development', 'Emotional', 'Emotions', 'Face', 'Facial Expression', 'Facial Muscles', 'Facial asymmetry', 'Funding', 'Hearing', 'Impairment', 'Intervention', 'Linear Regressions', 'Link', 'Machine Learning', 'Malocclusion', 'Measurement', 'Measures', 'Mobius Syndrome', 'Modeling', 'Movement', 'National Institute of Dental and Craniofacial Research', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Play', 'Problem behavior', 'Regression Analysis', 'Risk', 'Role', 'Sampling', 'Signal Transduction', 'Skeleton', 'Speech', 'Statistical Data Interpretation', 'Stroke', 'Testing', 'Time', 'Training', 'Unilateral Hearing Loss', 'Validation', 'Video Recording', 'age group', 'base', 'behavioral outcome', 'cost effective', 'craniofacial', 'craniofacial disorder', 'craniofacial microsomia', 'design', 'innovation', 'longitudinal analysis', 'longitudinal design', 'malformation', 'outcome prediction', 'parent grant', 'peer', 'procedure cost', 'research clinical testing', 'social', 'social skills', 'soft tissue']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R03,2018,154777,0.21877424650743202
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9402599,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,318898,0.1751762766877908
"Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure,9524811,U01AA014809,"['3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Algorithmic Software', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Printing', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Screening procedure', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'learning strategy', 'maternal cigarette smoking', 'mouse model', 'neonatal period', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'prenatal testing', 'recruit', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure']",NIAAA,UNIVERSITY OF OXFORD,U01,2018,262337,0.0913413877217027
"Prefrontal-Amygdala Interactions in Social Learning PROJECT SUMMARY This R01 renewal application proposes functional neuroimaging studies with human subjects to elucidate the role of the prefrontal cortex and amygdala in the processing of facial identities and expressions that predict critical social outcomes. Presentations of facial expressions of emotion in neuroimaging studies have proven particularly robust stimuli for activating amygdala and prefrontal regions involved in processing biologically- relevant social cues. Here we propose to further develop our novel structural and functional neuroimaging methods to better understand how the amygdala interacts with reciprocally connected prefrontal areas when such expressions are encountered. Specifically, following up on our previous findings that the structural integrity of an amygdala-prefrontal pathway predicts individual differences in reported anxiety – we replicated this effect in > 250 subjects and observed an exciting sex difference; this effect is compellingly stronger in females than in males. Here we propose to follow up on this effect with higher resolution DTI methods and to extend it to functional resting state data to see if the same sex difference is observed functionally. In addition, we propose a new mathematical model where we believe we can disentangle the effects of valence from arousal in brain imaging data, a confound the field continues to struggle with. Finally, we propose the development of a new facial expression stimulus set where we record the psychological status of the models posing for the expressions so we can determine any interaction this might have with the psychological status of the our subjects of study. The field can then usefully compare these data to complementary developmental research (i.e., with children and adolescents) and will be amenable  to direct translation to clinical populations (e.g., anxiety and depression). The experiments proposed here will increase our understanding of the brain mechanisms involved in  this learning. A number of experiments highlight an important difference between men and women that  we discovered during our last grant and follow up on here. Specifically, brain connections with the  prefrontal cortex in females explain how anxious they report being but we do not see this effect in  males. With this information, we can then better understand what goes wrong in the brains of  individuals with major depression and anxiety disorders.",Prefrontal-Amygdala Interactions in Social Learning,9561940,R56MH080716,"['Adolescent', 'Affect', 'Affective', 'Amygdaloid structure', 'Anatomy', 'Anxiety', 'Anxiety Disorders', 'Area', 'Arousal', 'Attention', 'Award', 'Behavioral', 'Biological', 'Brain', 'Brain imaging', 'Child', 'Clinical', 'Cognitive', 'Collaborations', 'Complex', 'Cues', 'Data', 'Development', 'Emotional', 'Emotional disorder', 'Face', 'Facial Expression', 'Failure', 'Female', 'Friends', 'Grant', 'Human', 'Image', 'Individual', 'Individual Differences', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental Depression', 'Methods', 'Modeling', 'Outcome', 'Participant', 'Pathway interactions', 'Population', 'Prefrontal Cortex', 'Publishing', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Rest', 'Role', 'Same-sex', 'Sampling', 'Sex Characteristics', 'Signal Transduction', 'Social Behavior', 'Stimulus', 'Structure', 'Study Subject', 'Supervision', 'System', 'Techniques', 'Translations', 'Woman', 'Work', 'anxious', 'base', 'behavioral outcome', 'behavioral response', 'experimental study', 'follow-up', 'human subject', 'indexing', 'innovation', 'male', 'mathematical model', 'men', 'neuroimaging', 'novel', 'psychologic', 'relating to nervous system', 'response', 'showing emotion', 'social', 'social learning', 'social situation', 'two-dimensional', 'white matter']",NIMH,DARTMOUTH COLLEGE,R56,2018,405000,0.0785879364810626
"Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues. People signal their internal emotional state by a range of cues including facial expressions, non-verbal vocalizations and the tone and content of speech. Much work to date on emotional signaling has focused on a small number of emotions and has relied on stimulus sets with limited numbers of exemplars and poor representation of individuals of different ages and ethnicities. The computer vision literature has long recognized the need to be able to compare models, for example of face recognition, across complex, diverse, and naturalistic stimulus sets. Here, we argue that a parallel approach needs to be applied if we are to achieve a robust and generalizable understanding of how the human brain represents emotion and identity related information derived from facial and vocal cues. Three multi-session functional magnetic resonance imaging (fMRI) experiments are proposed. In the first, participants will view a large corpus (~2000) of faces of individuals varying in age, gender and ethnicity and showing a wide range of emotional expressions. In the second, participants will be presented with a large (~1000) and equally diverse set of emotional vocalizations. The third experiment will make use of an even more complex and naturalistic stimulus set comprising ~1000 video clips of individuals expressing emotions through facial expression, non-verbal vocalizations and emotion-laden speech. This set will be broken into three parts, with as closely matched content as possible. These will be presented to participants in audio only, visual only and audio-visual (bimodal) conditions, with the stimuli allocated to each condition balanced across participants. For each experiment, data collection will comprise separate Model Estimation and Model Validation periods with the majority of stimuli presented at Validation being distinct from those presented at Estimation. A range of models will be fit to the fMRI data acquired during Estimation runs and tested and compared using data acquired during Validation runs. These models contain sets of features that describe the emotional content of the stimuli presented in terms of either dimensional or categorical models of emotion. By comparing the fit of these models we can determine which models capture most variance in voxel response profiles and examine how this varies across brain regions. Across the three experiments, we also seek to establish whether there are regions where voxels show common coding of emotional state regardless of whether information is carried by facial or vocal cues or a combination of both. Further, by contrasting models with and without terms for characteristics such as age, gender and ethnicity we can also investigate the (in)dependence of the representation of emotion and identity-related features. The proposed research has the potential to greatly advance our understanding of how cues to others' emotional state are represented in the human brain and the extent to which this is influenced by the characteristics of the person we are interacting with. In the medium term, we plan to extend this to also model listener/ viewer characteristics (both demographics and predisposition to anxiety or depression) in a hope to advance our understanding of how biases in the interpretation of emotional signals can arise. Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial  and vocal cues. Individuals with psychiatric conditions ranging from Social Anxiety and Depression to Autism Spectrum Disorder and Schizophrenia struggle to correctly interpret others' emotional states. To understand how alterations in brain function can give rise to the misperception of emotion cues, we first need better normative models of how information about others' emotional state derived from facial and vocal cues is represented within the human brain. Hence, here we use large, diverse and naturalistic stimulus sets encompassing facial expressions, emotional vocalizations and multi-modal videos to investigate the extent to which consistent representation of emotional state is observed across stimulus modalities, and to explore the organizational principles that can best explain voxel response profiles or tuning patterns to facial and vocal emotion cues.",Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues,9545868,R01MH112541,"['Address', 'Age', 'Anxiety', 'Arousal', 'Auditory', 'Brain', 'Brain region', 'Categories', 'Characteristics', 'Clip', 'Code', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Decision Making', 'Dependence', 'Dimensions', 'Emotional', 'Emotions', 'Ethnic Origin', 'Expressed Emotion', 'Face', 'Facial Expression', 'Functional Magnetic Resonance Imaging', 'Gender', 'Human', 'Image', 'Individual', 'Label', 'Literature', 'Mental Depression', 'Mental disorders', 'Modality', 'Modeling', 'Participant', 'Pattern', 'Persons', 'Predisposition', 'Property', 'Research', 'Running', 'Schizophrenia', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Validation', 'Visual', 'Weight', 'Work', 'autism spectrum disorder', 'blood oxygen level dependent', 'data acquisition', 'data modeling', 'demographics', 'experimental study', 'imaging study', 'information model', 'neural model', 'novel', 'relating to nervous system', 'response', 'showing emotion', 'social anxiety', 'theories', 'trait', 'visual information', 'visual neuroscience', 'vocalization']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2018,125000,0.18303505052531757
"Craniofacial Microsmia: Facial Expression from Ages 1 to 3 Years Project Summary Significance. Craniofacial microsomia (CFM) impairs facial muscle movement, speech, and hearing, and compromises socio-emotional development. Children with CFM have elevated levels of internalizing behavior (shy, withdrawn) and reduced social competence and peer acceptance. Unknown at present are the mechanisms through which CFM and these social-emotional outcomes become linked. Facial asymmetries and cranial neuropathies associated with CFM likely play an important role in impairing socio-emotional outcomes. Asymmetries of the facial skeleton, soft tissue, and cranial nerve have both intra- and interpersonal effects. Intra-personally, they impact function (unilateral hearing loss, malocclusion, facial expressiveness) and form (noticeable craniofacial malformations), which can impair social signaling and responsiveness. Because asymmetry is negatively correlated with attractiveness, there may be non-specific social effects as well. Many surgical treatments for CFM are designed to restore facial symmetry in static pose (e.g., neutral expression). Less is known about restoring or even measuring spontaneous facial expressiveness. From a developmental perspective, one of the most important consequences of limitations in facial muscle movement is its potentially negative impact on affective communication. In a longitudinal design, we propose to test the hypothesis that deficits in facial expressiveness and structural and functional asymmetry increase risk for internalizing and externalizing problems. If supported, the findings would inform our understanding of socio-emotional development in children with CFM and contribute to clinical evaluation and treatment. Innovation. This is the first effort to 1) use automated, objective measurement of facial expressiveness of communicative behavior and functional asymmetry of children with CFM; 2) model change with development in these parameters and their relation to internalizing and externalizing problems; and 3) use machine learning to investigate the relation among dynamics of expressiveness and asymmetry in relation to CBCL. Approach. Children with and without CFM will be video-recorded at 1 and 3 years with an examiner. Age 1 is an interactive context intended to elicit positive and negative emotion. Age 3 is an interactive context to assess expressive speech and attention. Expressiveness and structural and functional asymmetry are assessed using automatic, objective computer-vision based measurement. Analyses include complementary approaches: statistical (regression and ANOVA) hypothesis testing and machine learning (convolutional neural networks). Relevance Using objective, automatic computer-vision-based measurements, we propose to test the hypothesis that deficits in facial expressiveness and structural and functional asymmetry among children with CFM increases their risk for internalizing and externalizing problems. If supported, clinical assessments of expressiveness and functional asymmetry could effectively target children for specialized interventions and be used to evaluate surgical interventions. Because the proposed procedures are cost effective, they could be applied in a wide range of settings to benefit children with craniofacial disorders and have applicability to other conditions and age groups in which facial expression is compromised (e.g., Mobius Syndrome, Bell's Palsy, injury/burns, and stroke). Project Narrative Craniofacial microsomia (CFM) is among the most common craniofacial anomalies. CFM impairs facial muscle movement, speech, and hearing, and compromises socio-emotional development. Using computer-vision based face analysis, statistical analysis (regression and ANOVA), and machine learning, we will investigate the relation among expressiveness, structural and functional asymmetry, and behavior problems in children with CFM.",Craniofacial Microsmia: Facial Expression from Ages 1 to 3 Years,9387016,R03DE026513,"['1 year old', '3 year old', 'Affective', 'Age', 'Articulation', 'Attention', 'Behavior', 'Bell Palsy', 'Biological Neural Networks', 'Burn injury', 'Child', 'Child Behavior Checklist', 'Clinical Treatment', 'Clinical assessments', 'Communication', 'Computer Vision Systems', 'Cranial Nerves', 'Cranial nerve diseases', 'Craniofacial Abnormalities', 'Development', 'Disease', 'Emotional', 'Emotions', 'Face', 'Facial Expression', 'Facial Muscles', 'Facial asymmetry', 'Funding', 'Hearing', 'Impairment', 'Intervention', 'Linear Regressions', 'Link', 'Machine Learning', 'Malocclusion', 'Measurement', 'Measures', 'Mobius Syndrome', 'Modeling', 'Movement', 'National Institute of Dental and Craniofacial Research', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Play', 'Problem behavior', 'Procedures', 'Risk', 'Role', 'Sampling', 'Signal Transduction', 'Skeleton', 'Speech', 'Statistical Data Interpretation', 'Stroke', 'Testing', 'Time', 'Training', 'Unilateral Hearing Loss', 'Validation', 'Video Recording', 'age group', 'base', 'behavioral outcome', 'cost effective', 'craniofacial', 'craniofacial microsomia', 'design', 'innovation', 'longitudinal analysis', 'longitudinal design', 'malformation', 'outcome prediction', 'parent grant', 'peer', 'research clinical testing', 'social', 'social skills', 'soft tissue']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R03,2017,168654,0.21877424650743202
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9199411,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2017,319382,0.1751762766877908
"Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure,9391198,U01AA014809,"['3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Algorithmic Software', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Printing', 'Recruitment Activity', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'learning strategy', 'maternal cigarette smoking', 'mouse model', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure', 'tool']",NIAAA,UNIVERSITY OF OXFORD,U01,2017,288909,0.0913413877217027
"A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery DESCRIPTION (provided by applicant): The number of patients suffering from craniomaxillofacial (CMF) deformities and requiring surgical correction is escalating. CMF deformities may involve skeleton, overlying soft-tissues, or the both. Patients with CMF deformities often have psychological problems. The goal of CMF surgery is to reconstruct a normal facial appearance and function, and the outcome of the surgery is judged as such. The current problem is that we do not have a reliable way of simulating the soft-tissue-change following skeletal reconstruction. In treating patients with isolated skeletal defects, the current practice is to normalize the skeleton, hoping for optimal facial appearance. However, because the thickness and contour of the soft-tissue envelope varies from patient to patient, this approach is not reliable. The problem is even bigger in patients with composite defects. For example, in the scenario of a patient with a skeletal deformity and a mild soft-tissue defect, a surgeon would have to know, before surgery, how to overcorrect the skeleton to camouflage the soft-tissue defect. But, this information can only be attained by having an accurate planning system to simulate soft-tissue changes. In addition, from patient's perspective, the final facial appearance is the most apparent to them. Therefore, it is extremely important, for both doctors and patients, to accurately simulate soft-tissue-deformation.  Simulation methods must be accurate and fast. Attaining both is difficult because these attributes are inversely related, the more accurate the model, the longer it takes to prepare and run. Among the most effective, they are empirical-based model, mass spring model, finite element model, and mass tensor model. Unfortunately they are either too inaccurate or too slow, and clinically unacceptable.  Our hypothesis is that facial soft-tissue changes following virtual osteotomy can be accurately simulated by our innovative approach using an anatomically detailed modeling and mapping routine, along with statistical modeling technique. To test our hypothesis, we propose to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual osteotomies, and thus to significantly improve the outcomes of patients undergoing facial reconstruction. This approach can not only maintain the integrity of complex facial anatomy to accurately simulate the facial soft tissue deformation, but also significantly improve the computational efficiency in order to fit the requirement for clinical use  This project presents an innovative approach to model the facial soft-tissue deformation. If successful, it will allow accurate simulation of soft-tissue changes after virtual osteotomy. Patients will also be able to foresee the postoperative face preoperatively (patient education) and regain their psychological confidence. Finally, eFace will have significant impact and applications in orthodontics, plastic surgery, general surgery, growth/aging prediction, and forensic science. PUBLIC HEALTH RELEVANCE: In the US and throughout the world, the number of patients requiring surgical correction for facial deformities, which involves skeleton, overlying soft tissu, or both, is escalating every year. 2. Currently, while surgeons are able to accurately plan bone reconstructive surgery, they have to use  their visual imagination with clinical experience to mentally predict the facial soft tissue changes  following the bone surgery because they do not have a reliable way of simulating the soft-tissue-change  that is resulted from skeletal reconstruction. 3. We are proposing to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual skeletal surgery and thus to significantly improve the outcomes of patients undergoing facial reconstruction.",A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery,9233988,R01DE021863,"['Address', 'Aging', 'Algorithms', 'Anatomy', 'Appearance', 'Clinical', 'Complex', 'Data', 'Defect', 'Deformity', 'Development', 'Elements', 'Face', 'Forensic Sciences', 'Goals', 'Growth', 'Imagination', 'Laboratories', 'Learning', 'Left', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Orthodontics', 'Osteotomy', 'Outcome', 'Patient Education', 'Patient-Focused Outcomes', 'Patients', 'Plastic Surgical Procedures', 'Plasticizers', 'Postoperative Period', 'Property', 'Psyche structure', 'Reconstructive Surgical Procedures', 'Reporting', 'Residual state', 'Risk', 'Running', 'Severities', 'Skeleton', 'Speed', 'Statistical Models', 'Surgeon', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Variant', 'Visual', 'balance testing', 'base', 'bone', 'craniomaxillofacial', 'experience', 'imaging informatics', 'improved', 'improved functioning', 'improved outcome', 'individual patient', 'innovation', 'mechanical properties', 'novel', 'open source', 'prevent', 'psychologic', 'public health relevance', 'reconstruction', 'simulation', 'skeletal', 'skeletal surgery', 'soft tissue', 'system architecture', 'virtual']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2017,393538,0.13432635026862433
"Prefrontal-Amygdala Interactions in Social Learning PROJECT SUMMARY This R01 renewal application proposes functional neuroimaging studies with human subjects to elucidate the role of the prefrontal cortex and amygdala in the processing of facial identities and expressions that predict critical social outcomes. Presentations of facial expressions of emotion in neuroimaging studies have proven particularly robust stimuli for activating amygdala and prefrontal regions involved in processing biologically- relevant social cues. Here we propose to further develop our novel structural and functional neuroimaging methods to better understand how the amygdala interacts with reciprocally connected prefrontal areas when such expressions are encountered. Specifically, following up on our previous findings that the structural integrity of an amygdala-prefrontal pathway predicts individual differences in reported anxiety – we replicated this effect in > 250 subjects and observed an exciting sex difference; this effect is compellingly stronger in females than in males. Here we propose to follow up on this effect with higher resolution DTI methods and to extend it to functional resting state data to see if the same sex difference is observed functionally. In addition, we propose a new mathematical model where we believe we can disentangle the effects of valence from arousal in brain imaging data, a confound the field continues to struggle with. Finally, we propose the development of a new facial expression stimulus set where we record the psychological status of the models posing for the expressions so we can determine any interaction this might have with the psychological status of the our subjects of study. The field can then usefully compare these data to complementary developmental research (i.e., with children and adolescents) and will be amenable  to direct translation to clinical populations (e.g., anxiety and depression). The experiments proposed here will increase our understanding of the brain mechanisms involved in  this learning. A number of experiments highlight an important difference between men and women that  we discovered during our last grant and follow up on here. Specifically, brain connections with the  prefrontal cortex in females explain how anxious they report being but we do not see this effect in  males. With this information, we can then better understand what goes wrong in the brains of  individuals with major depression and anxiety disorders.",Prefrontal-Amygdala Interactions in Social Learning,9499980,R56MH080716,"['Adolescent', 'Affect', 'Affective', 'Amygdaloid structure', 'Anatomy', 'Anxiety', 'Anxiety Disorders', 'Area', 'Arousal', 'Attention', 'Award', 'Behavioral', 'Biological', 'Brain', 'Brain imaging', 'Child', 'Clinical', 'Cognitive', 'Collaborations', 'Complex', 'Cues', 'Data', 'Development', 'Emotional', 'Emotional disorder', 'Face', 'Facial Expression', 'Failure', 'Female', 'Friends', 'Grant', 'Human', 'Image', 'Individual', 'Individual Differences', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental Depression', 'Methods', 'Modeling', 'Outcome', 'Participant', 'Pathway interactions', 'Population', 'Prefrontal Cortex', 'Publishing', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Rest', 'Role', 'Same-sex', 'Sampling', 'Sex Characteristics', 'Signal Transduction', 'Social Behavior', 'Stimulus', 'Structure', 'Study Subject', 'Supervision', 'System', 'Techniques', 'Translations', 'Woman', 'Work', 'anxious', 'base', 'behavioral outcome', 'behavioral response', 'experimental study', 'follow-up', 'human subject', 'indexing', 'innovation', 'male', 'mathematical model', 'men', 'neuroimaging', 'novel', 'psychologic', 'relating to nervous system', 'response', 'showing emotion', 'social', 'social learning', 'social situation', 'two-dimensional', 'white matter']",NIMH,DARTMOUTH COLLEGE,R56,2017,405000,0.0785879364810626
"Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues. People signal their internal emotional state by a range of cues including facial expressions, non-verbal vocalizations and the tone and content of speech. Much work to date on emotional signaling has focused on a small number of emotions and has relied on stimulus sets with limited numbers of exemplars and poor representation of individuals of different ages and ethnicities. The computer vision literature has long recognized the need to be able to compare models, for example of face recognition, across complex, diverse, and naturalistic stimulus sets. Here, we argue that a parallel approach needs to be applied if we are to achieve a robust and generalizable understanding of how the human brain represents emotion and identity related information derived from facial and vocal cues. Three multi-session functional magnetic resonance imaging (fMRI) experiments are proposed. In the first, participants will view a large corpus (~2000) of faces of individuals varying in age, gender and ethnicity and showing a wide range of emotional expressions. In the second, participants will be presented with a large (~1000) and equally diverse set of emotional vocalizations. The third experiment will make use of an even more complex and naturalistic stimulus set comprising ~1000 video clips of individuals expressing emotions through facial expression, non-verbal vocalizations and emotion-laden speech. This set will be broken into three parts, with as closely matched content as possible. These will be presented to participants in audio only, visual only and audio-visual (bimodal) conditions, with the stimuli allocated to each condition balanced across participants. For each experiment, data collection will comprise separate Model Estimation and Model Validation periods with the majority of stimuli presented at Validation being distinct from those presented at Estimation. A range of models will be fit to the fMRI data acquired during Estimation runs and tested and compared using data acquired during Validation runs. These models contain sets of features that describe the emotional content of the stimuli presented in terms of either dimensional or categorical models of emotion. By comparing the fit of these models we can determine which models capture most variance in voxel response profiles and examine how this varies across brain regions. Across the three experiments, we also seek to establish whether there are regions where voxels show common coding of emotional state regardless of whether information is carried by facial or vocal cues or a combination of both. Further, by contrasting models with and without terms for characteristics such as age, gender and ethnicity we can also investigate the (in)dependence of the representation of emotion and identity-related features. The proposed research has the potential to greatly advance our understanding of how cues to others' emotional state are represented in the human brain and the extent to which this is influenced by the characteristics of the person we are interacting with. In the medium term, we plan to extend this to also model listener/ viewer characteristics (both demographics and predisposition to anxiety or depression) in a hope to advance our understanding of how biases in the interpretation of emotional signals can arise. Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial  and vocal cues. Individuals with psychiatric conditions ranging from Social Anxiety and Depression to Autism Spectrum Disorder and Schizophrenia struggle to correctly interpret others' emotional states. To understand how alterations in brain function can give rise to the misperception of emotion cues, we first need better normative models of how information about others' emotional state derived from facial and vocal cues is represented within the human brain. Hence, here we use large, diverse and naturalistic stimulus sets encompassing facial expressions, emotional vocalizations and multi-modal videos to investigate the extent to which consistent representation of emotional state is observed across stimulus modalities, and to explore the organizational principles that can best explain voxel response profiles or tuning patterns to facial and vocal emotion cues.",Multi-feature modeling of the neural representation of emotion- and identity-related information derived from facial and vocal cues,9285649,R01MH112541,"['Address', 'Age', 'Anxiety', 'Arousal', 'Auditory', 'Brain', 'Brain region', 'Categories', 'Characteristics', 'Clip', 'Code', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Decision Making', 'Dependence', 'Dimensions', 'Emotional', 'Emotions', 'Ethnic Origin', 'Expressed Emotion', 'Face', 'Facial Expression', 'Functional Magnetic Resonance Imaging', 'Gender', 'Human', 'Image', 'Individual', 'Label', 'Literature', 'Mental Depression', 'Mental disorders', 'Modality', 'Modeling', 'Participant', 'Pattern', 'Persons', 'Predisposition', 'Property', 'Research', 'Running', 'Schizophrenia', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Validation', 'Visual', 'Weight', 'Work', 'autism spectrum disorder', 'blood oxygen level dependent', 'data acquisition', 'data modeling', 'demographics', 'experimental study', 'imaging study', 'information model', 'neural model', 'novel', 'relating to nervous system', 'response', 'showing emotion', 'social anxiety', 'theories', 'trait', 'visual information', 'visual neuroscience', 'vocalization']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2017,125000,0.18303505052531757
"Automated Facial Expression Analysis for Research and Clinical Use DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use. The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.",Automated Facial Expression Analysis for Research and Clinical Use,9029353,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,452541,0.26282874628934155
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand.         PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.            ",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9054574,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Educational process of instructing', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Joints', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'research study', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2016,331310,0.1751762766877908
"A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery DESCRIPTION (provided by applicant): The number of patients suffering from craniomaxillofacial (CMF) deformities and requiring surgical correction is escalating. CMF deformities may involve skeleton, overlying soft-tissues, or the both. Patients with CMF deformities often have psychological problems. The goal of CMF surgery is to reconstruct a normal facial appearance and function, and the outcome of the surgery is judged as such. The current problem is that we do not have a reliable way of simulating the soft-tissue-change following skeletal reconstruction. In treating patients with isolated skeletal defects, the current practice is to normalize the skeleton, hoping for optimal facial appearance. However, because the thickness and contour of the soft-tissue envelope varies from patient to patient, this approach is not reliable. The problem is even bigger in patients with composite defects. For example, in the scenario of a patient with a skeletal deformity and a mild soft-tissue defect, a surgeon would have to know, before surgery, how to overcorrect the skeleton to camouflage the soft-tissue defect. But, this information can only be attained by having an accurate planning system to simulate soft-tissue changes. In addition, from patient's perspective, the final facial appearance is the most apparent to them. Therefore, it is extremely important, for both doctors and patients, to accurately simulate soft-tissue-deformation.  Simulation methods must be accurate and fast. Attaining both is difficult because these attributes are inversely related, the more accurate the model, the longer it takes to prepare and run. Among the most effective, they are empirical-based model, mass spring model, finite element model, and mass tensor model. Unfortunately they are either too inaccurate or too slow, and clinically unacceptable.  Our hypothesis is that facial soft-tissue changes following virtual osteotomy can be accurately simulated by our innovative approach using an anatomically detailed modeling and mapping routine, along with statistical modeling technique. To test our hypothesis, we propose to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual osteotomies, and thus to significantly improve the outcomes of patients undergoing facial reconstruction. This approach can not only maintain the integrity of complex facial anatomy to accurately simulate the facial soft tissue deformation, but also significantly improve the computational efficiency in order to fit the requirement for clinical use  This project presents an innovative approach to model the facial soft-tissue deformation. If successful, it will allow accurate simulation of soft-tissue changes after virtual osteotomy. Patients will also be able to foresee the postoperative face preoperatively (patient education) and regain their psychological confidence. Finally, eFace will have significant impact and applications in orthodontics, plastic surgery, general surgery, growth/aging prediction, and forensic science. PUBLIC HEALTH RELEVANCE: In the US and throughout the world, the number of patients requiring surgical correction for facial deformities, which involves skeleton, overlying soft tissu, or both, is escalating every year. 2. Currently, while surgeons are able to accurately plan bone reconstructive surgery, they have to use  their visual imagination with clinical experience to mentally predict the facial soft tissue changes  following the bone surgery because they do not have a reliable way of simulating the soft-tissue-change  that is resulted from skeletal reconstruction. 3. We are proposing to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual skeletal surgery and thus to significantly improve the outcomes of patients undergoing facial reconstruction.",A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery,9017812,R01DE021863,"['Address', 'Aging', 'Algorithms', 'Anatomy', 'Appearance', 'Clinical', 'Complex', 'Data', 'Defect', 'Deformity', 'Development', 'Elements', 'Face', 'Figs - dietary', 'Forensic Sciences', 'Goals', 'Growth', 'Health', 'Histocompatibility Testing', 'Imagination', 'Laboratories', 'Learning', 'Left', 'Machine Learning', 'Maps', 'Mechanics', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Orthodontics', 'Osteotomy', 'Outcome', 'Patient Education', 'Patients', 'Plastic Surgical Procedures', 'Postoperative Period', 'Property', 'Reconstructive Surgical Procedures', 'Reporting', 'Residual state', 'Risk', 'Running', 'Severities', 'Skeleton', 'Speed', 'Statistical Models', 'Surgeon', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Variant', 'Visual', 'balance testing', 'base', 'bone', 'craniomaxillofacial', 'experience', 'imaging informatics', 'improved', 'improved functioning', 'improved outcome', 'individual patient', 'innovation', 'meetings', 'novel', 'open source', 'prevent', 'psychologic', 'reconstruction', 'simulation', 'skeletal', 'skeletal surgery', 'soft tissue', 'system architecture', 'virtual']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2016,393538,0.13432635026862433
"Face De-Identification for Research and Clinical Use DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis. PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.",Face De-Identification for Research and Clinical Use,8908047,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Health', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'sex', 'social stigma', 'targeted imaging', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2015,193512,0.16896606275560472
"Automated Facial Expression Analysis for Research and Clinical Use DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use. The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.",Automated Facial Expression Analysis for Research and Clinical Use,8816133,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,452541,0.26282874628934155
"A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery DESCRIPTION (provided by applicant): The number of patients suffering from craniomaxillofacial (CMF) deformities and requiring surgical correction is escalating. CMF deformities may involve skeleton, overlying soft-tissues, or the both. Patients with CMF deformities often have psychological problems. The goal of CMF surgery is to reconstruct a normal facial appearance and function, and the outcome of the surgery is judged as such. The current problem is that we do not have a reliable way of simulating the soft-tissue-change following skeletal reconstruction. In treating patients with isolated skeletal defects, the current practice is to normalize the skeleton, hoping for optimal facial appearance. However, because the thickness and contour of the soft-tissue envelope varies from patient to patient, this approach is not reliable. The problem is even bigger in patients with composite defects. For example, in the scenario of a patient with a skeletal deformity and a mild soft-tissue defect, a surgeon would have to know, before surgery, how to overcorrect the skeleton to camouflage the soft-tissue defect. But, this information can only be attained by having an accurate planning system to simulate soft-tissue changes. In addition, from patient's perspective, the final facial appearance is the most apparent to them. Therefore, it is extremely important, for both doctors and patients, to accurately simulate soft-tissue-deformation.  Simulation methods must be accurate and fast. Attaining both is difficult because these attributes are inversely related, the more accurate the model, the longer it takes to prepare and run. Among the most effective, they are empirical-based model, mass spring model, finite element model, and mass tensor model. Unfortunately they are either too inaccurate or too slow, and clinically unacceptable.  Our hypothesis is that facial soft-tissue changes following virtual osteotomy can be accurately simulated by our innovative approach using an anatomically detailed modeling and mapping routine, along with statistical modeling technique. To test our hypothesis, we propose to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual osteotomies, and thus to significantly improve the outcomes of patients undergoing facial reconstruction. This approach can not only maintain the integrity of complex facial anatomy to accurately simulate the facial soft tissue deformation, but also significantly improve the computational efficiency in order to fit the requirement for clinical use  This project presents an innovative approach to model the facial soft-tissue deformation. If successful, it will allow accurate simulation of soft-tissue changes after virtual osteotomy. Patients will also be able to foresee the postoperative face preoperatively (patient education) and regain their psychological confidence. Finally, eFace will have significant impact and applications in orthodontics, plastic surgery, general surgery, growth/aging prediction, and forensic science. PUBLIC HEALTH RELEVANCE: In the US and throughout the world, the number of patients requiring surgical correction for facial deformities, which involves skeleton, overlying soft tissu, or both, is escalating every year. 2. Currently, while surgeons are able to accurately plan bone reconstructive surgery, they have to use  their visual imagination with clinical experience to mentally predict the facial soft tissue changes  following the bone surgery because they do not have a reliable way of simulating the soft-tissue-change  that is resulted from skeletal reconstruction. 3. We are proposing to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual skeletal surgery and thus to significantly improve the outcomes of patients undergoing facial reconstruction.",A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery,8828669,R01DE021863,"['Address', 'Aging', 'Algorithms', 'Anatomy', 'Appearance', 'Clinical', 'Complex', 'Data', 'Defect', 'Deformity', 'Development', 'Elements', 'Face', 'Figs - dietary', 'Forensic Sciences', 'Goals', 'Growth', 'Health', 'Histocompatibility Testing', 'Imagination', 'Individual', 'Laboratories', 'Learning', 'Left', 'Machine Learning', 'Maps', 'Mechanics', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Orthodontics', 'Osteotomy', 'Outcome', 'Patient Education', 'Patients', 'Plastic Surgical Procedures', 'Plastics', 'Postoperative Period', 'Property', 'Reconstructive Surgical Procedures', 'Reporting', 'Residual state', 'Risk', 'Running', 'Severities', 'Skeleton', 'Speed', 'Statistical Models', 'Surgeon', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Variant', 'Visual', 'balance testing', 'base', 'bone', 'craniomaxillofacial', 'experience', 'imaging informatics', 'improved', 'improved functioning', 'innovation', 'meetings', 'novel', 'open source', 'prevent', 'psychologic', 'reconstruction', 'simulation', 'skeletal', 'skeletal surgery', 'soft tissue', 'system architecture', 'virtual']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2015,393538,0.13432635026862433
"Face De-Identification for Research and Clinical Use     DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis.         PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.            ",Face De-Identification for Research and Clinical Use,8772435,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'public health relevance', 'sex', 'social stigma', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2014,194915,0.16896606275560472
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.          The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8633060,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,452541,0.26282874628934155
"A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery     DESCRIPTION (provided by applicant): The number of patients suffering from craniomaxillofacial (CMF) deformities and requiring surgical correction is escalating. CMF deformities may involve skeleton, overlying soft-tissues, or the both. Patients with CMF deformities often have psychological problems. The goal of CMF surgery is to reconstruct a normal facial appearance and function, and the outcome of the surgery is judged as such. The current problem is that we do not have a reliable way of simulating the soft-tissue-change following skeletal reconstruction. In treating patients with isolated skeletal defects, the current practice is to normalize the skeleton, hoping for optimal facial appearance. However, because the thickness and contour of the soft-tissue envelope varies from patient to patient, this approach is not reliable. The problem is even bigger in patients with composite defects. For example, in the scenario of a patient with a skeletal deformity and a mild soft-tissue defect, a surgeon would have to know, before surgery, how to overcorrect the skeleton to camouflage the soft-tissue defect. But, this information can only be attained by having an accurate planning system to simulate soft-tissue changes. In addition, from patient's perspective, the final facial appearance is the most apparent to them. Therefore, it is extremely important, for both doctors and patients, to accurately simulate soft-tissue-deformation.  Simulation methods must be accurate and fast. Attaining both is difficult because these attributes are inversely related, the more accurate the model, the longer it takes to prepare and run. Among the most effective, they are empirical-based model, mass spring model, finite element model, and mass tensor model. Unfortunately they are either too inaccurate or too slow, and clinically unacceptable.  Our hypothesis is that facial soft-tissue changes following virtual osteotomy can be accurately simulated by our innovative approach using an anatomically detailed modeling and mapping routine, along with statistical modeling technique. To test our hypothesis, we propose to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual osteotomies, and thus to significantly improve the outcomes of patients undergoing facial reconstruction. This approach can not only maintain the integrity of complex facial anatomy to accurately simulate the facial soft tissue deformation, but also significantly improve the computational efficiency in order to fit the requirement for clinical use  This project presents an innovative approach to model the facial soft-tissue deformation. If successful, it will allow accurate simulation of soft-tissue changes after virtual osteotomy. Patients will also be able to foresee the postoperative face preoperatively (patient education) and regain their psychological confidence. Finally, eFace will have significant impact and applications in orthodontics, plastic surgery, general surgery, growth/aging prediction, and forensic science.         PUBLIC HEALTH RELEVANCE: In the US and throughout the world, the number of patients requiring surgical correction for facial deformities, which involves skeleton, overlying soft tissu, or both, is escalating every year. 2. Currently, while surgeons are able to accurately plan bone reconstructive surgery, they have to use  their visual imagination with clinical experience to mentally predict the facial soft tissue changes  following the bone surgery because they do not have a reliable way of simulating the soft-tissue-change  that is resulted from skeletal reconstruction. 3. We are proposing to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual skeletal surgery and thus to significantly improve the outcomes of patients undergoing facial reconstruction.            ",A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery,8656620,R01DE021863,"['Address', 'Aging', 'Algorithms', 'Anatomy', 'Appearance', 'Clinical', 'Complex', 'Data', 'Defect', 'Deformity', 'Development', 'Elements', 'Face', 'Figs - dietary', 'Forensic Sciences', 'Goals', 'Growth', 'Histocompatibility Testing', 'Imagination', 'Individual', 'Laboratories', 'Learning', 'Left', 'Machine Learning', 'Maps', 'Mechanics', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Orthodontics', 'Osteotomy', 'Outcome', 'Patient Education', 'Patients', 'Plastic Surgical Procedures', 'Plastics', 'Postoperative Period', 'Property', 'Reconstructive Surgical Procedures', 'Reporting', 'Residual state', 'Risk', 'Running', 'Severities', 'Simulate', 'Skeleton', 'Speed', 'Statistical Models', 'Surgeon', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Variant', 'Visual', 'balance testing', 'base', 'bone', 'craniomaxillofacial', 'experience', 'imaging informatics', 'improved', 'improved functioning', 'innovation', 'meetings', 'novel', 'open source', 'prevent', 'psychologic', 'public health relevance', 'reconstruction', 'simulation', 'skeletal', 'skeletal surgery', 'soft tissue', 'system architecture', 'virtual']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2014,393538,0.13432635026862433
"A Study of the Computational Space of Facial Expressions of Emotion  Project Summary Past research has been very successful in defining how facial expressions of emotion are produced, including which muscle movements create the most commonly seen expressions. These facial expressions of emotion are then interpreted by our visual system. Yet, little is known about how these facial expressions are recognized. The overarching goal of this proposal is to define the form and dimensions of the cognitive (computational) space used in this visual recognition. In particular, this proposal will study the following three hypotheses: Although facial expressions are produced by a complex set of muscle movements, expressions are generally easily identified at different spatial and time resolutions. However, it is not know what these limits are. Our first hypothesis (H1) is that recognition of facial expressions of emotion can be achieved at low resolutions and after short exposure times. In Aim 1, we define experiments to determine how many pixels and milliseconds (ms) are needed to successfully identify different emotions. The fact that expressions of emotion can be recognized quickly at low resolution indicates that simple features robust to image manipulation are employed. Our second hypothesis (H2) is that the recognition of facial expressions of emotion is partially accomplished by an analysis of configural features. Configural cues are known to play an important role in other face recognition tasks, but their role in the processing of expressions of emotion is not yet well understood. Aim 2 will identify a number of these configural cues. We will use real images of faces, manipulated versions of these face images, and schematic drawings. It is also known that shape features play a role in facial expressions (e.g., the curvature of the mouth in happiness). In Aim 3, we define a shape-based computational model. Our hypothesis (H3) is that the configural and shape features are defined as deviations from a mean (or norm) face as opposed to being described as a set of independent exemplars (Gnostic neurons). The importance of this computational space is not only to further justify the results of the previous aims, but to make new predictions that can be verified with additional experiments with human subjects.  Project Narrative Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.",A Study of the Computational Space of Facial Expressions of Emotion,8669977,R01EY020834,"['Acute', 'Address', 'Affect', 'Aging-Related Process', 'Anger', 'Arts', 'Autistic Disorder', 'Behavior', 'Child Abuse', 'Classification', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conscious', 'Cues', 'Depressed mood', 'Dimensions', 'Duchenne muscular dystrophy', 'Emotions', 'Evolution', 'Eye diseases', 'Face', 'Face Processing', 'Facial Expression', 'Facial Muscles', 'Fright', 'Goals', 'Happiness', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Lead', 'Movement', 'Muscle', 'Neurons', 'Oral cavity', 'Perception', 'Play', 'Positioning Attribute', 'Primates', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Social Interaction', 'System', 'Time', 'To specify', 'Visual', 'Visual impairment', 'Visual system structure', 'base', 'cognitive system', 'computer human interaction', 'computer studies', 'court', 'design', 'human subject', 'millisecond', 'psychologic', 'research study', 'showing emotion', 'visual process', 'visual processing']",NEI,OHIO STATE UNIVERSITY,R01,2014,358680,0.19971934764996818
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.          The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8464280,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2013,497842,0.26282874628934155
"A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery     DESCRIPTION (provided by applicant): The number of patients suffering from craniomaxillofacial (CMF) deformities and requiring surgical correction is escalating. CMF deformities may involve skeleton, overlying soft-tissues, or the both. Patients with CMF deformities often have psychological problems. The goal of CMF surgery is to reconstruct a normal facial appearance and function, and the outcome of the surgery is judged as such. The current problem is that we do not have a reliable way of simulating the soft-tissue-change following skeletal reconstruction. In treating patients with isolated skeletal defects, the current practice is to normalize the skeleton, hoping for optimal facial appearance. However, because the thickness and contour of the soft-tissue envelope varies from patient to patient, this approach is not reliable. The problem is even bigger in patients with composite defects. For example, in the scenario of a patient with a skeletal deformity and a mild soft-tissue defect, a surgeon would have to know, before surgery, how to overcorrect the skeleton to camouflage the soft-tissue defect. But, this information can only be attained by having an accurate planning system to simulate soft-tissue changes. In addition, from patient's perspective, the final facial appearance is the most apparent to them. Therefore, it is extremely important, for both doctors and patients, to accurately simulate soft-tissue-deformation.  Simulation methods must be accurate and fast. Attaining both is difficult because these attributes are inversely related, the more accurate the model, the longer it takes to prepare and run. Among the most effective, they are empirical-based model, mass spring model, finite element model, and mass tensor model. Unfortunately they are either too inaccurate or too slow, and clinically unacceptable.  Our hypothesis is that facial soft-tissue changes following virtual osteotomy can be accurately simulated by our innovative approach using an anatomically detailed modeling and mapping routine, along with statistical modeling technique. To test our hypothesis, we propose to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual osteotomies, and thus to significantly improve the outcomes of patients undergoing facial reconstruction. This approach can not only maintain the integrity of complex facial anatomy to accurately simulate the facial soft tissue deformation, but also significantly improve the computational efficiency in order to fit the requirement for clinical use  This project presents an innovative approach to model the facial soft-tissue deformation. If successful, it will allow accurate simulation of soft-tissue changes after virtual osteotomy. Patients will also be able to foresee the postoperative face preoperatively (patient education) and regain their psychological confidence. Finally, eFace will have significant impact and applications in orthodontics, plastic surgery, general surgery, growth/aging prediction, and forensic science.         PUBLIC HEALTH RELEVANCE: In the US and throughout the world, the number of patients requiring surgical correction for facial deformities, which involves skeleton, overlying soft tissu, or both, is escalating every year. 2. Currently, while surgeons are able to accurately plan bone reconstructive surgery, they have to use  their visual imagination with clinical experience to mentally predict the facial soft tissue changes  following the bone surgery because they do not have a reliable way of simulating the soft-tissue-change  that is resulted from skeletal reconstruction. 3. We are proposing to develop an open source novel imaging informatics platform, eFace system, to accurately simulate soft-tissue-change following virtual skeletal surgery and thus to significantly improve the outcomes of patients undergoing facial reconstruction.            ",A Novel eFace System to Prevent the Risks of Facial Distortion after CMF Surgery,8439794,R01DE021863,"['Address', 'Aging', 'Algorithms', 'Anatomy', 'Appearance', 'Clinical', 'Complex', 'Data', 'Defect', 'Deformity', 'Development', 'Elements', 'Face', 'Figs - dietary', 'Forensic Sciences', 'Goals', 'Growth', 'Histocompatibility Testing', 'Imagination', 'Individual', 'Laboratories', 'Learning', 'Left', 'Machine Learning', 'Maps', 'Mechanics', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Orthodontics', 'Osteotomy', 'Outcome', 'Patient Education', 'Patients', 'Plastic Surgical Procedures', 'Plastics', 'Postoperative Period', 'Property', 'Reconstructive Surgical Procedures', 'Reporting', 'Residual state', 'Risk', 'Running', 'Severities', 'Simulate', 'Skeleton', 'Speed', 'Statistical Models', 'Surgeon', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Variant', 'Visual', 'balance testing', 'base', 'bone', 'craniomaxillofacial', 'experience', 'imaging informatics', 'improved', 'improved functioning', 'innovation', 'meetings', 'novel', 'open source', 'prevent', 'psychologic', 'public health relevance', 'reconstruction', 'simulation', 'skeletal', 'skeletal surgery', 'soft tissue', 'system architecture', 'virtual']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2013,387788,0.13432635026862433
"A Study of the Computational Space of Facial Expressions of Emotion  Project Summary Past research has been very successful in defining how facial expressions of emotion are produced, including which muscle movements create the most commonly seen expressions. These facial expressions of emotion are then interpreted by our visual system. Yet, little is known about how these facial expressions are recognized. The overarching goal of this proposal is to define the form and dimensions of the cognitive (computational) space used in this visual recognition. In particular, this proposal will study the following three hypotheses: Although facial expressions are produced by a complex set of muscle movements, expressions are generally easily identified at different spatial and time resolutions. However, it is not know what these limits are. Our first hypothesis (H1) is that recognition of facial expressions of emotion can be achieved at low resolutions and after short exposure times. In Aim 1, we define experiments to determine how many pixels and milliseconds (ms) are needed to successfully identify different emotions. The fact that expressions of emotion can be recognized quickly at low resolution indicates that simple features robust to image manipulation are employed. Our second hypothesis (H2) is that the recognition of facial expressions of emotion is partially accomplished by an analysis of configural features. Configural cues are known to play an important role in other face recognition tasks, but their role in the processing of expressions of emotion is not yet well understood. Aim 2 will identify a number of these configural cues. We will use real images of faces, manipulated versions of these face images, and schematic drawings. It is also known that shape features play a role in facial expressions (e.g., the curvature of the mouth in happiness). In Aim 3, we define a shape-based computational model. Our hypothesis (H3) is that the configural and shape features are defined as deviations from a mean (or norm) face as opposed to being described as a set of independent exemplars (Gnostic neurons). The importance of this computational space is not only to further justify the results of the previous aims, but to make new predictions that can be verified with additional experiments with human subjects.  Project Narrative Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.",A Study of the Computational Space of Facial Expressions of Emotion,8494053,R01EY020834,"['Acute', 'Address', 'Affect', 'Aging-Related Process', 'Anger', 'Arts', 'Autistic Disorder', 'Behavior', 'Child Abuse', 'Classification', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conscious', 'Cues', 'Depressed mood', 'Dimensions', 'Duchenne muscular dystrophy', 'Emotions', 'Evolution', 'Eye diseases', 'Face', 'Face Processing', 'Facial Expression', 'Facial Muscles', 'Fright', 'Goals', 'Happiness', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Lead', 'Movement', 'Muscle', 'Neurons', 'Oral cavity', 'Perception', 'Play', 'Positioning Attribute', 'Primates', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Social Interaction', 'System', 'Time', 'To specify', 'Visual', 'Visual impairment', 'Visual system structure', 'base', 'cognitive system', 'computer human interaction', 'computer studies', 'court', 'design', 'human subject', 'millisecond', 'psychologic', 'research study', 'showing emotion', 'visual process', 'visual processing']",NEI,OHIO STATE UNIVERSITY,R01,2013,347700,0.19971934764996818
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.        PUBLIC HEALTH RELEVANCE: The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.              The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8270831,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2012,621438,0.23119857664186402
"A Study of the Computational Space of Facial Expressions of Emotion  Project Summary Past research has been very successful in defining how facial expressions of emotion are produced, including which muscle movements create the most commonly seen expressions. These facial expressions of emotion are then interpreted by our visual system. Yet, little is known about how these facial expressions are recognized. The overarching goal of this proposal is to define the form and dimensions of the cognitive (computational) space used in this visual recognition. In particular, this proposal will study the following three hypotheses: Although facial expressions are produced by a complex set of muscle movements, expressions are generally easily identified at different spatial and time resolutions. However, it is not know what these limits are. Our first hypothesis (H1) is that recognition of facial expressions of emotion can be achieved at low resolutions and after short exposure times. In Aim 1, we define experiments to determine how many pixels and milliseconds (ms) are needed to successfully identify different emotions. The fact that expressions of emotion can be recognized quickly at low resolution indicates that simple features robust to image manipulation are employed. Our second hypothesis (H2) is that the recognition of facial expressions of emotion is partially accomplished by an analysis of configural features. Configural cues are known to play an important role in other face recognition tasks, but their role in the processing of expressions of emotion is not yet well understood. Aim 2 will identify a number of these configural cues. We will use real images of faces, manipulated versions of these face images, and schematic drawings. It is also known that shape features play a role in facial expressions (e.g., the curvature of the mouth in happiness). In Aim 3, we define a shape-based computational model. Our hypothesis (H3) is that the configural and shape features are defined as deviations from a mean (or norm) face as opposed to being described as a set of independent exemplars (Gnostic neurons). The importance of this computational space is not only to further justify the results of the previous aims, but to make new predictions that can be verified with additional experiments with human subjects.  Project Narrative Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.",A Study of the Computational Space of Facial Expressions of Emotion,8266468,R01EY020834,"['Acute', 'Address', 'Affect', 'Aging-Related Process', 'Anger', 'Arts', 'Autistic Disorder', 'Behavior', 'Child Abuse', 'Classification', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conscious', 'Cues', 'Depressed mood', 'Dimensions', 'Duchenne muscular dystrophy', 'Emotions', 'Evolution', 'Eye diseases', 'Face', 'Face Processing', 'Facial Expression', 'Facial Muscles', 'Fright', 'Goals', 'Happiness', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Lead', 'Movement', 'Muscle', 'Neurons', 'Oral cavity', 'Perception', 'Play', 'Positioning Attribute', 'Primates', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Social Interaction', 'System', 'Time', 'To specify', 'Visual', 'Visual impairment', 'Visual system structure', 'base', 'cognitive system', 'computer human interaction', 'computer studies', 'court', 'design', 'human subject', 'millisecond', 'psychologic', 'research study', 'showing emotion', 'visual process', 'visual processing']",NEI,OHIO STATE UNIVERSITY,R01,2012,366000,0.19971934764996818
"Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies    DESCRIPTION (provided by applicant): Fetal alcohol syndrome (FAS) occurs in children born to women who drink alcohol heavily during pregnancy and is one of the leading non-hereditary causes of mental retardation in the Western World. It is estimated that the prevalence of FAS in the general U.S. population is between 0.5 and 2.0 per 1,000 births, while the undiagnosed population with variable facial and brain dysmorphology described as fetal alcohol spectrum disorder (FASD) is estimated to be 10 times higher. The difficulty in the diagnosis of FASD involves misdiagnosis due to the presence or absence of the typical facial dysmorphology in association with brain dysfunction. Accurate diagnosis is further complicated by the lack of information about the contribution of dose, frequency, and timing of alcohol exposure during pregnancy to variation in facial dysmorphology. In this project, a mouse model that models human consumption and is known to produce FAS-like features resulting from prenatal alcohol exposure, will be used to test the effects of differences in dose and timing of alcohol exposure on face and brain development. A combination of 3D imaging that includes Micro-video and micro-resonance imaging (MRI) will be used to capture the detailed facial structure, micro-computational tomography (Micro-CT) to capture the underlying facial bone, MRI for detailed brain dimensions, and diffusion tensor imaging (DTI) for nerve fiber tracks in the fetal period. A novel computational program will be compiled to detect features specifically as function of alcohol exposure. The association and dissociation of facial and brain dysmorphology as a function of dose and timing of alcohol exposure will be analyzed to better inform the diagnosis of FAS/ FASD. These studies will be a collaboration sharing resources and methods and will be performed across both Basic and Clinical Science components in consortium effort. To date there is no cure for FAS/FASD, which is a life long ordeal from the birth. Experimental tests, using the above model and setting, of trophic peptides which have been known to prevent neurodegeneration in trials for Alzheimer Disease and protect cell death in embryonic stage, have been partially tested in the embryonic period to show protection against the alcohol-induced retardation. The new studies will test whether the trophic peptides can prevent alcohol-induced brain and facial dysmorphology as well as behavioral impairment known to occur in FAS.          n/a",Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies,8125102,U01AA017123,"['Adopted', 'Alcohol consumption', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Basic Science', 'Birth', 'Blood alcohol level measurement', 'Brain', 'Brain imaging', 'C57BL/6 Mouse', 'Cartilage', 'Cell Death', 'Child', 'Clinical Sciences', 'Collaborations', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diet', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Dissociation', 'Dose', 'Dysmorphology', 'Early identification', 'Embryo', 'Evaluation', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Gestational Age', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Length', 'Life', 'Liquid substance', 'Machine Learning', 'Measurement', 'Measures', 'Mental Retardation', 'Methods', 'Modeling', 'Morphology', 'Mus', 'NAPVSIPQ peptide', 'Neonatal', 'Nerve Degeneration', 'Nerve Fibers', 'Neurons', 'Oral', 'Pathway interactions', 'Pattern', 'Pattern Recognition', 'Peptides', 'Phenotype', 'Population', 'Pregnancy', 'Prevalence', 'Principal Investigator', 'Resolution', 'Resource Sharing', 'Sampling', 'Sheep', 'Short-Term Memory', 'Skeleton', 'Source', 'Staging', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Therapeutic Agents', 'Three-Dimensional Imaging', 'Time', 'Variant', 'Vibrissae', 'Western World', 'Woman', 'X-Ray Computed Tomography', 'alcohol effect', 'alcohol exposure', 'behavioral impairment', 'bone', 'brain volume', 'clinical application', 'craniofacial', 'digital imaging', 'drinking', 'face bone structure', 'fetal', 'improved', 'in utero', 'longitudinal design', 'morphometry', 'morris water maze', 'mouse model', 'neurobehavioral', 'neurochemistry', 'neuroimaging', 'neurotrophic factor', 'novel', 'peptide analog', 'postnatal', 'pregnant', 'prenatal', 'prevent', 'programs', 'relating to nervous system', 'sensory cortex', 'tomography', 'translational study', 'young adult']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2011,240069,0.05519785806278161
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",8116049,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'offspring', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,CHILDREN'S HOSPITAL OF LOS ANGELES,U01,2011,437768,0.09348812482457577
"A Study of the Computational Space of Facial Expressions of Emotion    DESCRIPTION (provided by applicant): Past research has been very successful in defining how facial expressions of emotion are produced, including which muscle movements create the most commonly seen expressions. These facial expressions of emotion are then interpreted by our visual system. Yet, little is known about how these facial expressions are recognized. The overarching goal of this proposal is to define the form and dimensions of the cognitive (computational) space used in this visual recognition. In particular, this proposal will study the following three hypotheses: Although facial expressions are produced by a complex set of muscle movements, expressions are generally easily identified at different spatial and time resolutions. However, it is not know what these limits are. Our first hypothesis (H1) is that recognition of facial expressions of emotion can be achieved at low resolutions and after short exposure times. In Aim 1, we define experiments to determine how many pixels and milliseconds (ms) are needed to successfully identify different emotions. The fact that expressions of emotion can be recognized quickly at low resolution indicates that simple features robust to image manipulation are employed. Our second hypothesis (H2) is that the recognition of facial expressions of emotion is partially accomplished by an analysis of configural features. Configural cues are known to play an important role in other face recognition tasks, but their role in the processing of expressions of emotion is not yet well understood. Aim 2 will identify a number of these configural cues. We will use real images of faces, manipulated versions of these face images, and schematic drawings. It is also known that shape features play a role in facial expressions (e.g., the curvature of the mouth in happiness). In Aim 3, we define a shape-based computational model. Our hypothesis (H3) is that the configural and shape features are defined as deviations from a mean (or norm) face as opposed to being described as a set of independent exemplars (Gnostic neurons). The importance of this computational space is not only to further justify the results of the previous aims, but to make new predictions that can be verified with additional experiments with human subjects.      PUBLIC HEALTH RELEVANCE: Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.           Project Narrative Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.",A Study of the Computational Space of Facial Expressions of Emotion,8142075,R01EY020834,"['Acute', 'Address', 'Affect', 'Aging-Related Process', 'Anger', 'Arts', 'Autistic Disorder', 'Behavior', 'Child Abuse', 'Classification', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conscious', 'Cues', 'Depressed mood', 'Dimensions', 'Duchenne muscular dystrophy', 'Emotions', 'Evolution', 'Eye diseases', 'Face', 'Face Processing', 'Facial Expression', 'Facial Muscles', 'Fright', 'Goals', 'Happiness', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Lead', 'Movement', 'Muscle', 'Neurons', 'Oral cavity', 'Perception', 'Play', 'Positioning Attribute', 'Primates', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Social Interaction', 'System', 'Time', 'To specify', 'Visual', 'Visual impairment', 'Visual system structure', 'base', 'cognitive system', 'computer human interaction', 'computer studies', 'court', 'design', 'human subject', 'millisecond', 'psychologic', 'public health relevance', 'research study', 'showing emotion', 'visual process', 'visual processing']",NEI,OHIO STATE UNIVERSITY,R01,2011,366000,0.18047109680889198
"Sensorimotor learning of facial expressions: A novel intervention for autism    DESCRIPTION (provided by applicant): Sensorimotor learning of facial expressions: A novel intervention for autism Project Summary This application addresses broad Challenge Area (04): Clinical Research, and specific Challenge Topic 04-MH-101 Autism: Addressing the challenge: Novel interventions. Children with Autism Spectrum Disorders (ASD) are impaired in their ability to produce and perceive dynamic facial expressions (Adolphs, Sears, and Piven, 2001). Advanced computer vision technologies can now be leveraged in the investigation of issues such as the facial expression recognition and production deficits common to children with autism spectrum disorder (ASD). Not only can these technologies assist in quantifying these deficits, but they can also be used as part of interventions aimed at reducing deficit severity. In this project, automated facial expression recognition will be employed for the development of training exercises for facial expression production in children with ASD. Previous research by Tanaka and Schultz developed the Let's Face It! intervention tool shown to effectively improve the face processing abilities of children with ASD. Let's Face It! focused on perception but not production. Bartlett and Movellan have developed the Computer Expression Recognition Toolbox (CERT), a computer vision system which measures 37 facial expression dimensions in real-time. This project brings together these two research groups in order to develop a computer assisted intervention system to enhance the social communication skills of children with Autism Spectrum Disorder (ASD). The computer vision tool enables novel interventions that focus on facial expression production. Intervention games will be developed to provide automated feedback on facial expressions produced by children with ASD in an engaging and cost- effective manner. In addition to improving production skills, practice with facial expression production may also improve perception skills by linking motor production with perception. The intervention exercises developed here will include closed-loop sensorimotor expression training in which subjects both see and produce facial expressions, and then view the effects of their facial expressions in the games. This project will also characterize facial expression production of children with ASD in a battery of assessment tasks, including automated facial expression measurement with CERT. Upon completion, this project will contribute to our understanding of facial expression production in children with ASD, provide a new intervention tool for facial expression production, and provide data on the efficacy of the intervention. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning. Sensorimotor learning of facial expressions: A novel Intervention for autism Project Narrative Automated facial expression recognition technology opens new possibilities for clinical research, assessment, and intervention systems. Integration of such technology in clinical research is both timely and crucial. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning.               Sensorimotor learning of facial expressions: A novel  Intervention for autism Project Narrative Automated facial expression recognition technology opens new possibilities for clinical research, assessment, and intervention systems. Integration of such technology in clinical research is both timely and crucial. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning.",Sensorimotor learning of facial expressions: A novel intervention for autism,7940926,RC1MH088633,"['Address', 'Area', 'Attention Deficit Disorder', 'Autistic Disorder', 'Child', 'Clinical Research', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Dimensions', 'Disease', 'Educational Intervention', 'Empathy', 'Exercise', 'Face', 'Face Processing', 'Facial Expression', 'Facial Expression Perception', 'Facial Expression Recognition', 'Feedback', 'Galvanic Skin Response', 'Goals', 'Grant', 'Heart Rate', 'Intervention', 'Intervention Studies', 'Investigation', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Motor', 'Perception', 'Physiological', 'Production', 'Psychophysiology', 'Research', 'Research Personnel', 'Schizophrenia', 'Severities', 'Social Development', 'Social Functioning', 'Statistical Models', 'Stimulus', 'System', 'Technology', 'Time', 'Training', 'Treatment Efficacy', 'autism spectrum disorder', 'base', 'computer design', 'cost', 'cost effective', 'face perception', 'improved', 'intervention program', 'mimicry', 'motor skill learning', 'novel', 'patient population', 'post intervention', 'programs', 'response', 'skills', 'social communication', 'statistics', 'tool']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",RC1,2010,494454,0.10664534304628594
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",7900036,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'offspring', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2010,498276,0.09348812482457577
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",8134637,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'offspring', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2010,64956,0.09348812482457577
"Translational Studies of FASD Using a Sheep Model-U01    DESCRIPTION (provided by applicant):  The main goals of this consortium are to identify sources of variation in fetal alcohol spectrum disorder (FASD) phenotypes (facial dysmorphology, structural brain damage and neurobehavioral functional deficits), to advance understanding of structure-function relationships, to improve diagnosis and early identification of FASD, and to develop early interventions that may limit adverse outcomes in at-risk pregnancies. Animal models are essential to those goals. This project proposes a novel sheep model that is especially well suited for experimental translational studies of FASD. In utero brain development in sheep matches human brain development relatively well, and prenatal binge alcohol exposure in sheep produces brain and behavioral effects consistent with FASD. There are two long-term objectives for this project. The first is to use the sheep model to compare the effects of binge-like alcohol exposure during the period of brain development comparable to that of the human first trimester (1st-trimester mode/) with similar binge-like exposure that extends over the stages of brain development encompassing all three human trimesters (3-trimester model). These studies evaluate phenotypic measures used in the diagnosis of fetal alcohol syndrome-growth, facial dysmorphology, and brain and behavioral development-using methods derived explicitly from and collaboratively linked directly to approaches applied in the human components of the consortium. These studies test the general hypothesis that more pervasive effects on brain and neurobehavioral development will result from binge exposure that continues after the first trimester. Aim 1 will evaluate growth, facial morphometry, and effects on in vivo brain regional volumes using structural magnetic resonance imaging. Aim 2 will assess neurobehavioral outcomes using eyeblink classical conditioning and spatial working memory. Aim 3 will assess neuroanatomical effects via neuronal counts in the cerebellum, hippocampal formation, and brainstem serotonin system. These studies are designed to inter-relate with and reciprocally inform four of the human projects [Facial Imaging (Foroud), Brain Imaging (Sowell), Neurobehavioral project (Mattson), and the Risk Factors/Nutrition project (Chambers)] and the two mouse basic science projects (Zhou; Sulik). The second objective (Aim 4) is to test the hypothesis that choline supplementation initiated periconceptually will attenuate the adverse effects of alcohol exposure in the 3-trimester sheep model. This study was designed with explicit and complementary collaboration with the choline-supplementation projects in rats [the basic science developmental project using rats (Thomas)] and in humans [Risk Factor/Nutrition project of Chambers/Keen]. This sheep model provides a unique opportunity to bridge the basic and clinical arms of the consortium more closely than has been achieved in the past.           n/a",Translational Studies of FASD Using a Sheep Model-U01,7906056,U01AA017120,"['3-Dimensional', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Age', 'Age-Months', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Attenuated', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blinking', 'Brain', 'Brain Injuries', 'Brain Stem', 'Brain imaging', 'Brain region', 'Cells', 'Cerebellar Nuclei', 'Cerebellum', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'First Pregnancy Trimester', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Growth', 'Hippocampal Formation', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Life', 'Link', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Methods', 'Microcephaly', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Design', 'Research Project Grants', 'Resolution', 'Risk', 'Risk Factors', 'Rodent', 'Rodent Model', 'Role', 'Schools', 'Sensitivity and Specificity', 'Serotonin', 'Severities', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Staging', 'Structure', 'Structure-Activity Relationship', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'adverse outcome', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'arm', 'base', 'binge drinking', 'brain behavior', 'brain morphology', 'brain volume', 'classical conditioning', 'cognitive control', 'conditioning', 'critical period', 'data integration', 'dentate gyrus', 'design', 'drinking', 'fetal diagnosis', 'follow-up', 'granule cell', 'hippocampal pyramidal neuron', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'literacy', 'morphometry', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurobehavioral test', 'neuron loss', 'northern plains', 'novel', 'nutrition', 'offspring', 'postnatal', 'prenatal', 'prevent', 'prospective', 'research study', 'social', 'species difference', 'three dimensional structure', 'translational study']",NIAAA,TEXAS A&M AGRILIFE RESEARCH,U01,2010,272554,0.04993057353377974
"MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01 DESCRIPTION (provided by applicant): Fetal Alcohol Spectrum Disorders (FASD), significant components of which are Central Nervous System (CMS) and craniofacial abnormalities, are a major public health problem. While eliminating FASD is the ultimate goal for both clinical and basic FASD research, we recognize that in the near future, adverse effects from prenatal ethanol exposure will persist. To better diagnose and treat affected individuals, a more complete understanding of the full spectrum of the ethanol-induced abnormalities is needed. The proposed investigations are designed to integrate with those of other consortium members in meeting this need. For this work, both high resolution Magnetic Resonance Imaging (MRI), which can provide 29 micron (or less) isotropic scans and subsequent accurate 3-D reconstructions and segmental analyses, and Diffusion Tensor Imaging (DTI), which allows CMS fiber tract analyses, will be applied to the study of an FASD mouse model. Previous research utilizing this model has established critical exposure times that yield facial and CNS abnormalities that are consistent with full-blown Fetal Alcohol Syndrome, as well as other components of FASD. The proposed studies will employ this model and both acute and chronic ethanol treatment paradigms to test the overall hypothesis that in mice, ethanol induces structural abnormalities of the brain and face that are consistent with and informative for those in human FASD. To this end, utilizing MRI and DTI as high throughput screening platforms, we propose to address the following specific aims : 1) to provide comprehensive documentation and discovery of the ethanol-induced CNS dysmorphology that results from prenatal ethanol exposure at embryonic and early fetal stages of development; 2) to define the facial dysmorphology that results from prenatal ethanol exposure during embryonic and/or early fetal stages and to relate their character and severity to accompanying abnormalities of the brain; and 3) to identify regions other than the brain or face that may serve as diagnostic indicators of prenatal ethanol exposure. The results of the proposed studies will be compared to those of corresponding investigations by other consortium members. It is expected that the structural abnormalities of the brain and face that are induced by ethanol in mice will reflect the pattern of defects observed in children with FASD, will inform human diagnostic tests, and will provide new information that will be helpful in reducing the incidence of FASD. n/a",MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01,7900037,U01AA017124,"['3-Dimensional', 'A Mouse', 'Acoustic Nerve', 'Acute', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Back', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Consult', 'Craniofacial Abnormalities', 'Data', 'Data Files', 'Data Storage and Retrieval', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Diet', 'Dietary Intervention', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease model', 'Documentation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Embryo', 'Embryonic Development', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Female', 'Fertilization', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fetus', 'Fiber', 'First Pregnancy Trimester', 'Fostering', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Hearing Tests', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Indiana', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory Animals', 'Labyrinth', 'Language', 'Language Development', 'Life', 'Liquid substance', 'Literature', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Menstruation', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nasal septum structure', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neuraxis', 'Neurobiology', 'New Mexico', 'Optic Nerve', 'Optics', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Photography', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevention', 'Prosencephalon', 'Public Health', 'Publishing', 'Rattus', 'Recording of previous events', 'Reproduction', 'Request for Applications', 'Research', 'Research Design', 'Research Project Grants', 'Resolution', 'Resources', 'Retrieval', 'Role', 'Scanning', 'Schools', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staging', 'Structure', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'cognitive control', 'computer generated', 'craniofacial', 'critical period', 'data integration', 'design', 'dosage', 'drinking', 'fetal', 'follow-up', 'high throughput screening', 'human data', 'human subject', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'infancy', 'interest', 'intraperitoneal', 'literacy', 'malformation', 'meetings', 'member', 'membranous labyrinth', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'offspring', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'response', 'sensory system', 'social', 'symposium', 'three dimensional structure', 'web site']",NIAAA,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2010,242586,0.07256612661581606
"Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies    DESCRIPTION (provided by applicant): Fetal alcohol syndrome (FAS) occurs in children born to women who drink alcohol heavily during pregnancy and is one of the leading non-hereditary causes of mental retardation in the Western World. It is estimated that the prevalence of FAS in the general U.S. population is between 0.5 and 2.0 per 1,000 births, while the undiagnosed population with variable facial and brain dysmorphology described as fetal alcohol spectrum disorder (FASD) is estimated to be 10 times higher. The difficulty in the diagnosis of FASD involves misdiagnosis due to the presence or absence of the typical facial dysmorphology in association with brain dysfunction. Accurate diagnosis is further complicated by the lack of information about the contribution of dose, frequency, and timing of alcohol exposure during pregnancy to variation in facial dysmorphology. In this project, a mouse model that models human consumption and is known to produce FAS-like features resulting from prenatal alcohol exposure, will be used to test the effects of differences in dose and timing of alcohol exposure on face and brain development. A combination of 3D imaging that includes Micro-video and micro-resonance imaging (MRI) will be used to capture the detailed facial structure, micro-computational tomography (Micro-CT) to capture the underlying facial bone, MRI for detailed brain dimensions, and diffusion tensor imaging (DTI) for nerve fiber tracks in the fetal period. A novel computational program will be compiled to detect features specifically as function of alcohol exposure. The association and dissociation of facial and brain dysmorphology as a function of dose and timing of alcohol exposure will be analyzed to better inform the diagnosis of FAS/ FASD. These studies will be a collaboration sharing resources and methods and will be performed across both Basic and Clinical Science components in consortium effort. To date there is no cure for FAS/FASD, which is a life long ordeal from the birth. Experimental tests, using the above model and setting, of trophic peptides which have been known to prevent neurodegeneration in trials for Alzheimer Disease and protect cell death in embryonic stage, have been partially tested in the embryonic period to show protection against the alcohol-induced retardation. The new studies will test whether the trophic peptides can prevent alcohol-induced brain and facial dysmorphology as well as behavioral impairment known to occur in FAS.          n/a",Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies,7905111,U01AA017123,"['Address', 'Adolescent', 'Adopted', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blood alcohol level measurement', 'Brain', 'Brain imaging', 'C57BL/6 Mouse', 'Cartilage', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diet', 'Dietary Intervention', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Dissociation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Elements', 'Embryo', 'Emotional', 'Ethanol', 'Ethnic group', 'Evaluation', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Genetic Polymorphism', 'Gestational Age', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Inherited', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Length', 'Life', 'Liquid substance', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mental Retardation', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'NAPVSIPQ peptide', 'Neonatal', 'Nerve Degeneration', 'Nerve Fibers', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Oral', 'Outcome', 'Pathway interactions', 'Pattern', 'Pattern Recognition', 'Peptides', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevalence', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Role', 'Sampling', 'Schools', 'Sensitivity and Specificity', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skeleton', 'Source', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Surface', 'System', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Variant', 'Vibrissae', 'Western World', 'Woman', 'Work', 'X-Ray Computed Tomography', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'behavioral impairment', 'bone', 'brain behavior', 'brain morphology', 'brain volume', 'clinical application', 'cognitive control', 'craniofacial', 'critical period', 'data integration', 'digital imaging', 'drinking', 'face bone structure', 'fetal', 'follow-up', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'infancy', 'literacy', 'longitudinal design', 'morphometry', 'morris water maze', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurochemistry', 'neuroimaging', 'neurotrophic factor', 'northern plains', 'novel', 'offspring', 'peptide analog', 'postnatal', 'pregnant', 'prenatal', 'prevent', 'programs', 'prospective', 'relating to nervous system', 'sensory cortex', 'social', 'tomography', 'translational study', 'young adult']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2010,242494,0.05519785806278161
"A Study of the Computational Space of Facial Expressions of Emotion    DESCRIPTION (provided by applicant): Past research has been very successful in defining how facial expressions of emotion are produced, including which muscle movements create the most commonly seen expressions. These facial expressions of emotion are then interpreted by our visual system. Yet, little is known about how these facial expressions are recognized. The overarching goal of this proposal is to define the form and dimensions of the cognitive (computational) space used in this visual recognition. In particular, this proposal will study the following three hypotheses: Although facial expressions are produced by a complex set of muscle movements, expressions are generally easily identified at different spatial and time resolutions. However, it is not know what these limits are. Our first hypothesis (H1) is that recognition of facial expressions of emotion can be achieved at low resolutions and after short exposure times. In Aim 1, we define experiments to determine how many pixels and milliseconds (ms) are needed to successfully identify different emotions. The fact that expressions of emotion can be recognized quickly at low resolution indicates that simple features robust to image manipulation are employed. Our second hypothesis (H2) is that the recognition of facial expressions of emotion is partially accomplished by an analysis of configural features. Configural cues are known to play an important role in other face recognition tasks, but their role in the processing of expressions of emotion is not yet well understood. Aim 2 will identify a number of these configural cues. We will use real images of faces, manipulated versions of these face images, and schematic drawings. It is also known that shape features play a role in facial expressions (e.g., the curvature of the mouth in happiness). In Aim 3, we define a shape-based computational model. Our hypothesis (H3) is that the configural and shape features are defined as deviations from a mean (or norm) face as opposed to being described as a set of independent exemplars (Gnostic neurons). The importance of this computational space is not only to further justify the results of the previous aims, but to make new predictions that can be verified with additional experiments with human subjects.      PUBLIC HEALTH RELEVANCE: Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.           Project Narrative Understanding how facial expressions of emotion are processed by our cognitive system will be important for studies of abnormal face and emotion visual processing in schizophrenia, autism and Huntington's disease. Also, abused children are more acute at recognizing emotions, suggesting a higher degree of expertise to some image features. Identifying which features are used by the cognitive system will help develop protocols for reducing their unwanted effects. Understanding the limits in spatial and time resolution will also be important for studies of low vision (acuity), which are typical problems in several eye diseases and in the normal process of aging.",A Study of the Computational Space of Facial Expressions of Emotion,7946918,R01EY020834,"['Acute', 'Address', 'Affect', 'Aging-Related Process', 'Anger', 'Arts', 'Autistic Disorder', 'Behavior', 'Child Abuse', 'Classification', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conscious', 'Cues', 'Depressed mood', 'Dimensions', 'Duchenne muscular dystrophy', 'Emotions', 'Evolution', 'Eye diseases', 'Face', 'Face Processing', 'Facial Expression', 'Facial Muscles', 'Fright', 'Goals', 'Happiness', 'Human', 'Huntington Disease', 'Image', 'Individual', 'Lead', 'Movement', 'Muscle', 'Neurons', 'Oral cavity', 'Perception', 'Play', 'Positioning Attribute', 'Primates', 'Process', 'Protocols documentation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Social Interaction', 'System', 'Time', 'To specify', 'Visual', 'Visual impairment', 'Visual system structure', 'base', 'cognitive system', 'computer human interaction', 'computer studies', 'court', 'design', 'human subject', 'millisecond', 'psychologic', 'research study', 'showing emotion', 'visual process', 'visual processing']",NEI,OHIO STATE UNIVERSITY,R01,2010,285938,0.18047109680889198
"Sensorimotor learning of facial expressions: A novel intervention for autism    DESCRIPTION (provided by applicant): Sensorimotor learning of facial expressions: A novel intervention for autism Project Summary This application addresses broad Challenge Area (04): Clinical Research, and specific Challenge Topic 04-MH-101 Autism: Addressing the challenge: Novel interventions. Children with Autism Spectrum Disorders (ASD) are impaired in their ability to produce and perceive dynamic facial expressions (Adolphs, Sears, and Piven, 2001). Advanced computer vision technologies can now be leveraged in the investigation of issues such as the facial expression recognition and production deficits common to children with autism spectrum disorder (ASD). Not only can these technologies assist in quantifying these deficits, but they can also be used as part of interventions aimed at reducing deficit severity. In this project, automated facial expression recognition will be employed for the development of training exercises for facial expression production in children with ASD. Previous research by Tanaka and Schultz developed the Let's Face It! intervention tool shown to effectively improve the face processing abilities of children with ASD. Let's Face It! focused on perception but not production. Bartlett and Movellan have developed the Computer Expression Recognition Toolbox (CERT), a computer vision system which measures 37 facial expression dimensions in real-time. This project brings together these two research groups in order to develop a computer assisted intervention system to enhance the social communication skills of children with Autism Spectrum Disorder (ASD). The computer vision tool enables novel interventions that focus on facial expression production. Intervention games will be developed to provide automated feedback on facial expressions produced by children with ASD in an engaging and cost- effective manner. In addition to improving production skills, practice with facial expression production may also improve perception skills by linking motor production with perception. The intervention exercises developed here will include closed-loop sensorimotor expression training in which subjects both see and produce facial expressions, and then view the effects of their facial expressions in the games. This project will also characterize facial expression production of children with ASD in a battery of assessment tasks, including automated facial expression measurement with CERT. Upon completion, this project will contribute to our understanding of facial expression production in children with ASD, provide a new intervention tool for facial expression production, and provide data on the efficacy of the intervention. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning. Sensorimotor learning of facial expressions: A novel Intervention for autism Project Narrative Automated facial expression recognition technology opens new possibilities for clinical research, assessment, and intervention systems. Integration of such technology in clinical research is both timely and crucial. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning.               Sensorimotor learning of facial expressions: A novel  Intervention for autism Project Narrative Automated facial expression recognition technology opens new possibilities for clinical research, assessment, and intervention systems. Integration of such technology in clinical research is both timely and crucial. The intervention system proposed here could have tremendous impact on social development in any patient population with atypical facial expression production, including ASD, and attention deficit disorder. The project will also contribute to the understanding of the development and learning of motor skills essential to social functioning.",Sensorimotor learning of facial expressions: A novel intervention for autism,7829637,RC1MH088633,"['Address', 'Area', 'Attention Deficit Disorder', 'Autistic Disorder', 'Child', 'Clinical Research', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Dimensions', 'Disease', 'Educational Intervention', 'Empathy', 'Exercise', 'Face', 'Face Processing', 'Facial Expression', 'Facial Expression Perception', 'Facial Expression Recognition', 'Feedback', 'Galvanic Skin Response', 'Goals', 'Grant', 'Heart Rate', 'Intervention', 'Intervention Studies', 'Investigation', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Motor', 'Perception', 'Physiological', 'Production', 'Psychophysiology', 'Research', 'Research Personnel', 'Schizophrenia', 'Severities', 'Social Development', 'Social Functioning', 'Statistical Models', 'Stimulus', 'System', 'Technology', 'Time', 'Training', 'Treatment Efficacy', 'autism spectrum disorder', 'base', 'computer design', 'cost', 'cost effective', 'face perception', 'improved', 'intervention program', 'mimicry', 'motor skill learning', 'novel', 'patient population', 'post intervention', 'programs', 'response', 'skills', 'social communication', 'statistics', 'tool']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",RC1,2009,497336,0.10664534304628594
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",7668683,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'offspring', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2009,488655,0.09348812482457577
"Translational Studies of FASD Using a Sheep Model-U01    DESCRIPTION (provided by applicant):  The main goals of this consortium are to identify sources of variation in fetal alcohol spectrum disorder (FASD) phenotypes (facial dysmorphology, structural brain damage and neurobehavioral functional deficits), to advance understanding of structure-function relationships, to improve diagnosis and early identification of FASD, and to develop early interventions that may limit adverse outcomes in at-risk pregnancies. Animal models are essential to those goals. This project proposes a novel sheep model that is especially well suited for experimental translational studies of FASD. In utero brain development in sheep matches human brain development relatively well, and prenatal binge alcohol exposure in sheep produces brain and behavioral effects consistent with FASD. There are two long-term objectives for this project. The first is to use the sheep model to compare the effects of binge-like alcohol exposure during the period of brain development comparable to that of the human first trimester (1st-trimester mode/) with similar binge-like exposure that extends over the stages of brain development encompassing all three human trimesters (3-trimester model). These studies evaluate phenotypic measures used in the diagnosis of fetal alcohol syndrome-growth, facial dysmorphology, and brain and behavioral development-using methods derived explicitly from and collaboratively linked directly to approaches applied in the human components of the consortium. These studies test the general hypothesis that more pervasive effects on brain and neurobehavioral development will result from binge exposure that continues after the first trimester. Aim 1 will evaluate growth, facial morphometry, and effects on in vivo brain regional volumes using structural magnetic resonance imaging. Aim 2 will assess neurobehavioral outcomes using eyeblink classical conditioning and spatial working memory. Aim 3 will assess neuroanatomical effects via neuronal counts in the cerebellum, hippocampal formation, and brainstem serotonin system. These studies are designed to inter-relate with and reciprocally inform four of the human projects [Facial Imaging (Foroud), Brain Imaging (Sowell), Neurobehavioral project (Mattson), and the Risk Factors/Nutrition project (Chambers)] and the two mouse basic science projects (Zhou; Sulik). The second objective (Aim 4) is to test the hypothesis that choline supplementation initiated periconceptually will attenuate the adverse effects of alcohol exposure in the 3-trimester sheep model. This study was designed with explicit and complementary collaboration with the choline-supplementation projects in rats [the basic science developmental project using rats (Thomas)] and in humans [Risk Factor/Nutrition project of Chambers/Keen]. This sheep model provides a unique opportunity to bridge the basic and clinical   arms of the consortium more closely than has been achieved in the past.           n/a",Translational Studies of FASD Using a Sheep Model-U01,7669196,U01AA017120,"['3-Dimensional', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Age', 'Age-Months', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Attenuated', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blinking', 'Brain', 'Brain Injuries', 'Brain Stem', 'Brain imaging', 'Brain region', 'Cells', 'Cerebellar Nuclei', 'Cerebellum', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'First Pregnancy Trimester', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Growth', 'Hippocampal Formation', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Life', 'Link', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Methods', 'Microcephaly', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Design', 'Research Project Grants', 'Resolution', 'Risk', 'Risk Factors', 'Rodent', 'Rodent Model', 'Role', 'Schools', 'Sensitivity and Specificity', 'Serotonin', 'Severities', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Staging', 'Structure', 'Structure-Activity Relationship', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Upper arm', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'binge drinking', 'brain behavior', 'brain morphology', 'brain volume', 'classical conditioning', 'cognitive control', 'conditioning', 'critical period', 'data integration', 'dentate gyrus', 'design', 'drinking', 'fetal diagnosis', 'follow-up', 'granule cell', 'hippocampal pyramidal neuron', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'in vivo', 'infancy', 'literacy', 'morphometry', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurobehavioral test', 'neuron loss', 'northern plains', 'novel', 'nutrition', 'offspring', 'postnatal', 'prenatal', 'prevent', 'prospective', 'research study', 'social', 'species difference', 'three dimensional structure', 'translational study']",NIAAA,TEXAS A&M AGRILIFE RESEARCH,U01,2009,267924,0.04993057353377974
"MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01    DESCRIPTION (provided by applicant): Fetal Alcohol Spectrum Disorders (FASD), significant components of which are Central Nervous System (CMS) and craniofacial abnormalities, are a major public health problem. While eliminating FASD is the ultimate goal for both clinical and basic FASD research, we recognize that in the near future, adverse effects from prenatal ethanol exposure will persist. To better diagnose and treat affected individuals, a more complete understanding of the full spectrum of the ethanol-induced abnormalities is needed. The proposed investigations are designed to integrate with those of other consortium members in meeting this need. For this work, both high resolution Magnetic Resonance Imaging (MRI), which can provide 29 micron (or less) isotropic scans and subsequent accurate 3-D reconstructions and segmental analyses, and Diffusion Tensor Imaging (DTI), which allows CMS fiber tract analyses, will be applied to the study of an FASD mouse model. Previous research utilizing this model has established critical exposure times that yield facial and CNS abnormalities that are consistent with full-blown Fetal Alcohol Syndrome, as well as other components of FASD. The proposed studies will employ this model and both acute and chronic ethanol treatment paradigms to test the overall hypothesis that in mice, ethanol induces structural abnormalities of the brain and face that are consistent with and informative for those in human FASD. To this end, utilizing MRI and DTI as high throughput screening platforms, we propose to address the following specific aims : 1) to provide comprehensive documentation and discovery of the ethanol-induced CNS dysmorphology that results from prenatal ethanol exposure at embryonic and early fetal stages of development; 2) to define the facial dysmorphology that results from prenatal ethanol exposure during embryonic and/or early fetal stages and to relate their character and severity to accompanying abnormalities of the brain; and 3) to identify regions other than the brain or face that may serve as diagnostic indicators of prenatal ethanol exposure. The results of the proposed studies will be compared to those of corresponding investigations by other consortium members. It is expected that the structural abnormalities of the brain and face that are induced by ethanol in mice will reflect the pattern of defects observed in children with FASD, will inform human diagnostic tests, and will provide new information that will be helpful in reducing the incidence of FASD.           n/a",MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01,7668689,U01AA017124,"['3-Dimensional', 'A Mouse', 'Acoustic Nerve', 'Acute', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Back', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Consult', 'Craniofacial Abnormalities', 'Data', 'Data Files', 'Data Storage and Retrieval', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Diet', 'Dietary Intervention', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease model', 'Documentation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Embryo', 'Embryonic Development', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Female', 'Fertilization', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fetus', 'Fiber', 'First Pregnancy Trimester', 'Fostering', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Hearing Tests', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Indiana', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory Animals', 'Labyrinth', 'Language', 'Language Development', 'Life', 'Liquid substance', 'Literature', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Menstruation', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nasal septum structure', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neuraxis', 'Neurobiology', 'New Mexico', 'Optic Nerve', 'Optics', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Photography', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevention', 'Prosencephalon', 'Public Health', 'Publishing', 'Rattus', 'Recording of previous events', 'Reproduction', 'Request for Applications', 'Research', 'Research Design', 'Research Project Grants', 'Resolution', 'Resources', 'Retrieval', 'Role', 'Scanning', 'Schools', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staging', 'Structure', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'cognitive control', 'computer generated', 'craniofacial', 'critical period', 'data integration', 'design', 'dosage', 'drinking', 'fetal', 'follow-up', 'high throughput screening', 'human data', 'human subject', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'infancy', 'interest', 'intraperitoneal', 'literacy', 'malformation', 'meetings', 'member', 'membranous labyrinth', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'offspring', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'response', 'sensory system', 'social', 'symposium', 'three dimensional structure', 'web site']",NIAAA,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2009,237539,0.07256612661581606
"Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies    DESCRIPTION (provided by applicant): Fetal alcohol syndrome (FAS) occurs in children born to women who drink alcohol heavily during pregnancy and is one of the leading non-hereditary causes of mental retardation in the Western World. It is estimated that the prevalence of FAS in the general U.S. population is between 0.5 and 2.0 per 1,000 births, while the undiagnosed population with variable facial and brain dysmorphology described as fetal alcohol spectrum disorder (FASD) is estimated to be 10 times higher. The difficulty in the diagnosis of FASD involves misdiagnosis due to the presence or absence of the typical facial dysmorphology in association with brain dysfunction. Accurate diagnosis is further complicated by the lack of information about the contribution of dose, frequency, and timing of alcohol exposure during pregnancy to variation in facial dysmorphology. In this project, a mouse model that models human consumption and is known to produce FAS-like features resulting from prenatal alcohol exposure, will be used to test the effects of differences in dose and timing of alcohol exposure on face and brain development. A combination of 3D imaging that includes Micro-video and micro-resonance imaging (MRI) will be used to capture the detailed facial structure, micro-computational tomography (Micro-CT) to capture the underlying facial bone, MRI for detailed brain dimensions, and diffusion tensor imaging (DTI) for nerve fiber tracks in the fetal period. A novel computational program will be compiled to detect features specifically as function of alcohol exposure. The association and dissociation of facial and brain dysmorphology as a function of dose and timing of alcohol exposure will be analyzed to better inform the diagnosis of FAS/ FASD. These studies will be a collaboration sharing resources and methods and will be performed across both Basic and Clinical Science components in consortium effort. To date there is no cure for FAS/FASD, which is a life long ordeal from the birth. Experimental tests, using the above model and setting, of trophic peptides which have been known to prevent neurodegeneration in trials for Alzheimer Disease and protect cell death in embryonic stage, have been partially tested in the embryonic period to show protection against the alcohol-induced retardation. The new studies will test whether the trophic peptides can prevent alcohol-induced brain and facial dysmorphology as well as behavioral impairment known to occur in FAS.          n/a",Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies,7668687,U01AA017123,"['Address', 'Adolescent', 'Adopted', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blood alcohol level measurement', 'Brain', 'Brain imaging', 'C57BL/6 Mouse', 'Cartilage', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diet', 'Dietary Intervention', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Dissociation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Elements', 'Embryo', 'Emotional', 'Ethanol', 'Ethnic group', 'Evaluation', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Genetic Polymorphism', 'Gestational Age', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Inherited', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Length', 'Life', 'Liquid substance', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mental Retardation', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'NAPVSIPQ peptide', 'Neonatal', 'Nerve Degeneration', 'Nerve Fibers', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Oral', 'Outcome', 'Pathway interactions', 'Pattern', 'Pattern Recognition', 'Peptides', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevalence', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Role', 'Sampling', 'Schools', 'Sensitivity and Specificity', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skeleton', 'Source', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Surface', 'System', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Variant', 'Vibrissae', 'Western World', 'Woman', 'Work', 'X-Ray Computed Tomography', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'behavioral impairment', 'bone', 'brain behavior', 'brain morphology', 'brain volume', 'clinical application', 'cognitive control', 'craniofacial', 'critical period', 'data integration', 'digital imaging', 'drinking', 'face bone structure', 'fetal', 'follow-up', 'image reconstruction', 'imaging modality', 'improved', 'in utero', 'infancy', 'literacy', 'longitudinal design', 'morphometry', 'morris water maze', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurochemistry', 'neuroimaging', 'neurotrophic factor', 'northern plains', 'novel', 'offspring', 'peptide analog', 'postnatal', 'pregnant', 'prenatal', 'prevent', 'programs', 'prospective', 'relating to nervous system', 'sensory cortex', 'social', 'tomography', 'translational study', 'young adult']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2009,237808,0.05519785806278161
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7316099,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY,R01,2008,476784,0.254927587305704
"3D Facial Imaging in FASD (U01)    DESCRIPTION (provided by applicant): During the past three years, members of the Facial Imaging Core have worked with the Consortium to apply novel methods to more effectively diagnose FAS using 3D images from an ethnically diverse sample. These data and their subsequent analyses were used to identify features which consistently and reliably distinguished individuals with a clinical diagnosis of FAS from controls. Based on the initial success of the 'Facial Imaging Core', we now propose an expanded series of aims to be part of a clinical project named '3D Facial Imaging in FASD'. Subsequent work proposed in this study will build on the lessons learned in this first phase of research and utilize improved technology and sampling procedures to extend the diagnostic utility of these novel techniques to a wider range of individuals with prenatal alcohol exposure or FASD. In collaboration with several clinical projects, we will collect a longitudinal, multi-ethnic sample of individuals prenatally exposed to alcohol. This sample will allow us to reliably separate the effects of ethnic variation and developmental age from those due to alcohol exposure. We will also continue to work with the basic science projects to ensure that results in the different species (human, mouse, sheep) are used to inform analyses in each project. The overarching goals of this project are to: Goal 1: improve understanding of the dysmorphic features in FAS and FASD; Goal 2: enhance the capability for definitive diagnosis of FAS and the broader spectrum of FASD at different stages of the lifespan; and Goal 3: establish whether there is a relationship between FAS and FASD dysmorphic features and the specific underlying impairments in brain function.           n/a",3D Facial Imaging in FASD (U01),7678304,U01AA014809,"['Address', 'Adolescent', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ensure', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Lasers', 'Learning', 'Life', 'Longevity', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Principal Investigator', 'Procedures', 'Range', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sampling', 'Schools', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Translating', 'Ukraine', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'clinical Diagnosis', 'clinically relevant', 'cognitive control', 'craniofacial', 'critical developmental period', 'data integration', 'disorder control', 'drinking', 'follow-up', 'improved', 'in utero', 'infancy', 'literacy', 'member', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'social', 'success', 'three dimensional structure']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2008,153230,0.09953045352096099
"3D Facial Imaging in FASD (U01)    DESCRIPTION (provided by applicant): During the past three years, members of the Facial Imaging Core have worked with the Consortium to apply novel methods to more effectively diagnose FAS using 3D images from an ethnically diverse sample. These data and their subsequent analyses were used to identify features which consistently and reliably distinguished individuals with a clinical diagnosis of FAS from controls. Based on the initial success of the 'Facial Imaging Core', we now propose an expanded series of aims to be part of a clinical project named '3D Facial Imaging in FASD'. Subsequent work proposed in this study will build on the lessons learned in this first phase of research and utilize improved technology and sampling procedures to extend the diagnostic utility of these novel techniques to a wider range of individuals with prenatal alcohol exposure or FASD. In collaboration with several clinical projects, we will collect a longitudinal, multi-ethnic sample of individuals prenatally exposed to alcohol. This sample will allow us to reliably separate the effects of ethnic variation and developmental age from those due to alcohol exposure. We will also continue to work with the basic science projects to ensure that results in the different species (human, mouse, sheep) are used to inform analyses in each project. The overarching goals of this project are to: Goal 1: improve understanding of the dysmorphic features in FAS and FASD; Goal 2: enhance the capability for definitive diagnosis of FAS and the broader spectrum of FASD at different stages of the lifespan; and Goal 3: establish whether there is a relationship between FAS and FASD dysmorphic features and the specific underlying impairments in brain function.           n/a",3D Facial Imaging in FASD (U01),7502720,U01AA014809,"['Address', 'Adolescent', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ensure', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Lasers', 'Learning', 'Life', 'Longevity', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Principal Investigator', 'Procedures', 'Range', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sampling', 'Schools', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Translating', 'Ukraine', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'clinical Diagnosis', 'clinically relevant', 'cognitive control', 'craniofacial', 'critical developmental period', 'data integration', 'disorder control', 'drinking', 'follow-up', 'improved', 'in utero', 'infancy', 'literacy', 'member', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'social', 'success', 'three dimensional structure']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2008,341942,0.09953045352096099
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",7502725,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Infant Development', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Principal Investigator', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Score', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical developmental period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'human study', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2008,474412,0.09348812482457577
"Translational Studies of FASD Using a Sheep Model-U01    DESCRIPTION (provided by applicant):  The main goals of this consortium are to identify sources of variation in fetal alcohol spectrum disorder (FASD) phenotypes (facial dysmorphology, structural brain damage and neurobehavioral functional deficits), to advance understanding of structure-function relationships, to improve diagnosis and early identification of FASD, and to develop early interventions that may limit adverse outcomes in at-risk pregnancies. Animal models are essential to those goals. This project proposes a novel sheep model that is especially well suited for experimental translational studies of FASD. In utero brain development in sheep matches human brain development relatively well, and prenatal binge alcohol exposure in sheep produces brain and behavioral effects consistent with FASD. There are two long-term objectives for this project. The first is to use the sheep model to compare the effects of binge-like alcohol exposure during the period of brain development comparable to that of the human first trimester (1st-trimester mode/) with similar binge-like exposure that extends over the stages of brain development encompassing all three human trimesters (3-trimester model). These studies evaluate phenotypic measures used in the diagnosis of fetal alcohol syndrome-growth, facial dysmorphology, and brain and behavioral development-using methods derived explicitly from and collaboratively linked directly to approaches applied in the human components of the consortium. These studies test the general hypothesis that more pervasive effects on brain and neurobehavioral development will result from binge exposure that continues after the first trimester. Aim 1 will evaluate growth, facial morphometry, and effects on in vivo brain regional volumes using structural magnetic resonance imaging. Aim 2 will assess neurobehavioral outcomes using eyeblink classical conditioning and spatial working memory. Aim 3 will assess neuroanatomical effects via neuronal counts in the cerebellum, hippocampal formation, and brainstem serotonin system. These studies are designed to inter-relate with and reciprocally inform four of the human projects [Facial Imaging (Foroud), Brain Imaging (Sowell), Neurobehavioral project (Mattson), and the Risk Factors/Nutrition project (Chambers)] and the two mouse basic science projects (Zhou; Sulik). The second objective (Aim 4) is to test the hypothesis that choline supplementation initiated periconceptually will attenuate the adverse effects of alcohol exposure in the 3-trimester sheep model. This study was designed with explicit and complementary collaboration with the choline-supplementation projects in rats [the basic science developmental project using rats (Thomas)] and in humans [Risk Factor/Nutrition project of Chambers/Keen]. This sheep model provides a unique opportunity to bridge the basic and clinical   arms of the consortium more closely than has been achieved in the past.           n/a",Translational Studies of FASD Using a Sheep Model-U01,7503981,U01AA017120,"['3-Dimensional', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Age', 'Age-Months', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Attenuated', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blinking', 'Brain', 'Brain Injuries', 'Brain Stem', 'Brain imaging', 'Brain region', 'Cells', 'Cerebellar Nuclei', 'Cerebellum', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Condition', 'Count', 'Data', 'Depth', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'First Pregnancy Trimester', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Growth', 'Hippocampal Formation', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Life', 'Link', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Methods', 'Microcephaly', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Numbers', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Risk', 'Risk Factors', 'Rodent', 'Rodent Model', 'Role', 'Schools', 'Sensitivity and Specificity', 'Serotonin', 'Severities', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Staging', 'Structure', 'Structure-Activity Relationship', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Upper arm', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'binge drinking', 'brain behavior', 'brain morphology', 'brain volume', 'classical conditioning', 'cognitive control', 'conditioning', 'critical developmental period', 'data integration', 'dentate gyrus', 'design', 'drinking', 'fetal diagnosis', 'follow-up', 'granule cell', 'hippocampal pyramidal neuron', 'improved', 'in utero', 'in vivo', 'infancy', 'literacy', 'morphometry', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurobehavioral test', 'neuron loss', 'northern plains', 'novel', 'nutrition', 'postnatal', 'prenatal', 'prevent', 'programs', 'prospective', 'reconstruction', 'research study', 'social', 'species difference', 'three dimensional structure', 'translational study']",NIAAA,TEXAS A&M AGRILIFE RESEARCH,U01,2008,260772,0.04993057353377974
"MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01    DESCRIPTION (provided by applicant): Fetal Alcohol Spectrum Disorders (FASD), significant components of which are Central Nervous System (CMS) and craniofacial abnormalities, are a major public health problem. While eliminating FASD is the ultimate goal for both clinical and basic FASD research, we recognize that in the near future, adverse effects from prenatal ethanol exposure will persist. To better diagnose and treat affected individuals, a more complete understanding of the full spectrum of the ethanol-induced abnormalities is needed. The proposed investigations are designed to integrate with those of other consortium members in meeting this need. For this work, both high resolution Magnetic Resonance Imaging (MRI), which can provide 29 micron (or less) isotropic scans and subsequent accurate 3-D reconstructions and segmental analyses, and Diffusion Tensor Imaging (DTI), which allows CMS fiber tract analyses, will be applied to the study of an FASD mouse model. Previous research utilizing this model has established critical exposure times that yield facial and CNS abnormalities that are consistent with full-blown Fetal Alcohol Syndrome, as well as other components of FASD. The proposed studies will employ this model and both acute and chronic ethanol treatment paradigms to test the overall hypothesis that in mice, ethanol induces structural abnormalities of the brain and face that are consistent with and informative for those in human FASD. To this end, utilizing MRI and DTI as high throughput screening platforms, we propose to address the following specific aims : 1) to provide comprehensive documentation and discovery of the ethanol-induced CNS dysmorphology that results from prenatal ethanol exposure at embryonic and early fetal stages of development; 2) to define the facial dysmorphology that results from prenatal ethanol exposure during embryonic and/or early fetal stages and to relate their character and severity to accompanying abnormalities of the brain; and 3) to identify regions other than the brain or face that may serve as diagnostic indicators of prenatal ethanol exposure. The results of the proposed studies will be compared to those of corresponding investigations by other consortium members. It is expected that the structural abnormalities of the brain and face that are induced by ethanol in mice will reflect the pattern of defects observed in children with FASD, will inform human diagnostic tests, and will provide new information that will be helpful in reducing the incidence of FASD.           n/a",MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01,7502729,U01AA017124,"['3-Dimensional', 'A Mouse', 'Acoustic Nerve', 'Acute', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Back', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Consult', 'Craniofacial Abnormalities', 'Data', 'Data Files', 'Data Storage and Retrieval', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Diet', 'Dietary Intervention', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease model', 'Documentation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Embryo', 'Embryonic Development', 'Emotional', 'End Point', 'Ethanol', 'Ethnic group', 'Face', 'Female', 'Fertilization', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fetus', 'Fiber', 'First Pregnancy Trimester', 'Fostering', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Hearing Tests', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Indiana', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory Animals', 'Labyrinth', 'Language', 'Language Development', 'Life', 'Liquid substance', 'Literature', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Menstruation', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nasal septum structure', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neuraxis', 'Neurobiology', 'New Mexico', 'Optic Nerve', 'Optics', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Photography', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevention', 'Principal Investigator', 'Prosencephalon', 'Public Health', 'Publishing', 'Range', 'Rattus', 'Recording of previous events', 'Reproduction', 'Request for Applications', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Retrieval', 'Role', 'Scanning', 'Schools', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staging', 'Structure', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Week', 'Woman', 'Work', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'cognitive control', 'computer generated', 'craniofacial', 'critical developmental period', 'data integration', 'day', 'design', 'dosage', 'drinking', 'fetal', 'follow-up', 'high throughput screening', 'human data', 'human study', 'human subject', 'improved', 'in utero', 'infancy', 'interest', 'intraperitoneal', 'literacy', 'malformation', 'member', 'membranous labyrinth', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'response', 'sensory system', 'size', 'social', 'symposium', 'three dimensional structure']",NIAAA,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2008,234161,0.07256612661581606
"Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies    DESCRIPTION (provided by applicant): Fetal alcohol syndrome (FAS) occurs in children born to women who drink alcohol heavily during pregnancy and is one of the leading non-hereditary causes of mental retardation in the Western World. It is estimated that the prevalence of FAS in the general U.S. population is between 0.5 and 2.0 per 1,000 births, while the undiagnosed population with variable facial and brain dysmorphology described as fetal alcohol spectrum disorder (FASD) is estimated to be 10 times higher. The difficulty in the diagnosis of FASD involves misdiagnosis due to the presence or absence of the typical facial dysmorphology in association with brain dysfunction. Accurate diagnosis is further complicated by the lack of information about the contribution of dose, frequency, and timing of alcohol exposure during pregnancy to variation in facial dysmorphology. In this project, a mouse model that models human consumption and is known to produce FAS-like features resulting from prenatal alcohol exposure, will be used to test the effects of differences in dose and timing of alcohol exposure on face and brain development. A combination of 3D imaging that includes Micro-video and micro-resonance imaging (MRI) will be used to capture the detailed facial structure, micro-computational tomography (Micro-CT) to capture the underlying facial bone, MRI for detailed brain dimensions, and diffusion tensor imaging (DTI) for nerve fiber tracks in the fetal period. A novel computational program will be compiled to detect features specifically as function of alcohol exposure. The association and dissociation of facial and brain dysmorphology as a function of dose and timing of alcohol exposure will be analyzed to better inform the diagnosis of FAS/ FASD. These studies will be a collaboration sharing resources and methods and will be performed across both Basic and Clinical Science components in consortium effort. To date there is no cure for FAS/FASD, which is a life long ordeal from the birth. Experimental tests, using the above model and setting, of trophic peptides which have been known to prevent neurodegeneration in trials for Alzheimer Disease and protect cell death in embryonic stage, have been partially tested in the embryonic period to show protection against the alcohol-induced retardation. The new studies will test whether the trophic peptides can prevent alcohol-induced brain and facial dysmorphology as well as behavioral impairment known to occur in FAS.          n/a",Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies,7502713,U01AA017123,"['Address', 'Adolescent', 'Adopted', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blood alcohol level measurement', 'Bone and Cartilage Funding', 'Brain', 'Brain imaging', 'C57BL/6 Mouse', 'CDKN1A gene', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Consumption', 'Count', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diet', 'Dietary Intervention', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disruption', 'Dissociation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Elements', 'Embryo', 'Emotional', 'Ethanol', 'Ethnic group', 'Evaluation', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Genetic Polymorphism', 'Gestational Age', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Impairment', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Inherited', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Length', 'Life', 'Liquid substance', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mental Retardation', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'NAPVSIPQ peptide', 'Neonatal', 'Nerve Degeneration', 'Nerve Fibers', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Oral', 'Outcome', 'Pathway interactions', 'Patient currently pregnant', 'Pattern', 'Pattern Recognition', 'Peptides', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevalence', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Role', 'Sampling', 'Schools', 'Sensitivity and Specificity', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skeleton', 'Source', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Surface', 'System', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Variant', 'Vibrissae', 'Western World', 'Woman', 'Work', 'X-Ray Computed Tomography', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'brain volume', 'clinical application', 'cognitive control', 'craniofacial', 'critical developmental period', 'data integration', 'day', 'design', 'digital imaging', 'drinking', 'face bone structure', 'fetal', 'follow-up', 'human study', 'image reconstruction', 'improved', 'in utero', 'infancy', 'literacy', 'morphometry', 'morris water maze', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurochemistry', 'neuroimaging', 'neurotrophic factor', 'northern plains', 'novel', 'oncoprotein p21', 'peptide analog', 'postnatal', 'prenatal', 'prevent', 'programs', 'prospective', 'relating to nervous system', 'sensory cortex', 'social', 'tomography', 'translational study', 'young adult']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2008,235382,0.05519785806278161
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7151198,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2007,471644,0.254927587305704
"3D Facial Imaging in FASD (U01)    DESCRIPTION (provided by applicant): During the past three years, members of the Facial Imaging Core have worked with the Consortium to apply novel methods to more effectively diagnose FAS using 3D images from an ethnically diverse sample. These data and their subsequent analyses were used to identify features which consistently and reliably distinguished individuals with a clinical diagnosis of FAS from controls. Based on the initial success of the 'Facial Imaging Core', we now propose an expanded series of aims to be part of a clinical project named '3D Facial Imaging in FASD'. Subsequent work proposed in this study will build on the lessons learned in this first phase of research and utilize improved technology and sampling procedures to extend the diagnostic utility of these novel techniques to a wider range of individuals with prenatal alcohol exposure or FASD. In collaboration with several clinical projects, we will collect a longitudinal, multi-ethnic sample of individuals prenatally exposed to alcohol. This sample will allow us to reliably separate the effects of ethnic variation and developmental age from those due to alcohol exposure. We will also continue to work with the basic science projects to ensure that results in the different species (human, mouse, sheep) are used to inform analyses in each project. The overarching goals of this project are to: Goal 1: improve understanding of the dysmorphic features in FAS and FASD; Goal 2: enhance the capability for definitive diagnosis of FAS and the broader spectrum of FASD at different stages of the lifespan; and Goal 3: establish whether there is a relationship between FAS and FASD dysmorphic features and the specific underlying impairments in brain function.           n/a",3D Facial Imaging in FASD (U01),7342564,U01AA014809,"['Address', 'Adolescent', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ensure', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Lasers', 'Learning', 'Life', 'Longevity', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Principal Investigator', 'Procedures', 'Range', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sampling', 'Schools', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Translating', 'Ukraine', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'clinical Diagnosis', 'clinically relevant', 'cognitive control', 'craniofacial', 'critical developmental period', 'data integration', 'disorder control', 'drinking', 'follow-up', 'improved', 'in utero', 'infancy', 'literacy', 'member', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'social', 'success', 'three dimensional structure']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2007,359361,0.09953045352096099
"Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)    DESCRIPTION (provided by applicant): This new application is part of the competitive renewal for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)"". One of the overall goals of the entire CIFASD during this renewal period is to determine if innovative techniques can be used to identify brain alterations, neurobehavioral deficits and facial characteristics and relationships between these variables to help define prenatal alcohol spectrum disorders (FASD). To help address this overarching question, we will use quantitative brain mapping techniques with high-resolution structural and functional MRI collected both cross-sectionally and longitudinally from 80 FASD children evaluated across 3 multi-cultural data collection sites (San Diego, Los Angeles and Capetown, South Africa). While this brain imaging project can independently achieve some of the goals of the CIFASD by identifying brain structural and functional abnormalities across the broad spectrum of FASD, critically this funding opportunity will allow the assessment of relationships between the brain, neurocognitive deficits and facial dysmorphology through our active collaborations with the neurobehavioral project (Mattson PI), the facial imaging project (Foroud PI), and the dysmorphology core (Jones PI). Controlled animal studies are essential to determine timing and dosages of prenatal alcohol that result in FASD, but human imaging studies are essential to corroborate anatomical findings across species. Through our association with the UCLA Laboratory of Neuro Imaging, we have access to state-of-the-art brain mapping tools that allow the morphological evaluation of any brain structure that can be identified with MRI. Thus, we are in a unique position to allow findings in animal studies to drive hypothesis-based analyses in the human imaging data. The proposed longitudinal project will highlight how an integrated approach relating neurobehavioral, functional and structural brain imaging data, and measures of facial morphology might yield important new insights on the complex nature of brain-behavior interactions and how they are altered by prenatal alcohol exposure. To our knowledge, this will be the first study to undertake such challenges, and participation, in the CIFASD is essential to address our specific aims. Ultimately, as part of the CIFASD, this project will enhance the capability for definitive FASD diagnoses that, in turn, will help clinicians manage and treat neurobehavioral deficits and associated secondary disabilities.           n/a","Mapping the Brain, the Face and Neurocognitive Function in FASD (U01)",7343320,U01AA017122,"['Address', 'Adolescent', 'Adolescent Development', 'Affect', 'Africa', 'Age', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Calibration', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Choline', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Collection', 'Complex', 'Control Animal', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Disease', 'Disorder by Site', 'Dorsal', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ensure', 'Environment', 'Ethanol', 'Ethnic Origin', 'Ethnic group', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Opportunities', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Infant Development', 'Inferior', 'Informal Social Control', 'Informatics', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Lead', 'Length', 'Life', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nature', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurocognitive', 'Neurocognitive Deficit', 'New Mexico', 'Outcome', 'Parietal', 'Parietal Lobe', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Positioning Attribute', 'Pregnancy', 'Principal Investigator', 'Productivity', 'Rattus', 'Recording of previous events', 'Relative (related person)', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Schools', 'Score', 'Sensitivity and Specificity', 'Shapes', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'South Africa', 'Specificity', 'Structure', 'Sum', 'Supplementation', 'Surface', 'Techniques', 'Technology', 'Therapeutic', 'Thick', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Verbal Learning', 'Visual', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'brain size', 'cognitive control', 'cognitive function', 'critical developmental period', 'data integration', 'disability', 'dosage', 'drinking', 'follow-up', 'frontal lobe', 'gray matter', 'human study', 'improved', 'in utero', 'in vivo', 'infancy', 'innovation', 'insight', 'interest', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurodevelopment', 'northern plains', 'novel', 'postnatal', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'relating to nervous system', 'social', 'three dimensional structure', 'tool']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2007,496998,0.09348812482457577
"Translational Studies of FASD Using a Sheep Model-U01    DESCRIPTION (provided by applicant):  The main goals of this consortium are to identify sources of variation in fetal alcohol spectrum disorder (FASD) phenotypes (facial dysmorphology, structural brain damage and neurobehavioral functional deficits), to advance understanding of structure-function relationships, to improve diagnosis and early identification of FASD, and to develop early interventions that may limit adverse outcomes in at-risk pregnancies. Animal models are essential to those goals. This project proposes a novel sheep model that is especially well suited for experimental translational studies of FASD. In utero brain development in sheep matches human brain development relatively well, and prenatal binge alcohol exposure in sheep produces brain and behavioral effects consistent with FASD. There are two long-term objectives for this project. The first is to use the sheep model to compare the effects of binge-like alcohol exposure during the period of brain development comparable to that of the human first trimester (1st-trimester mode/) with similar binge-like exposure that extends over the stages of brain development encompassing all three human trimesters (3-trimester model). These studies evaluate phenotypic measures used in the diagnosis of fetal alcohol syndrome-growth, facial dysmorphology, and brain and behavioral development-using methods derived explicitly from and collaboratively linked directly to approaches applied in the human components of the consortium. These studies test the general hypothesis that more pervasive effects on brain and neurobehavioral development will result from binge exposure that continues after the first trimester. Aim 1 will evaluate growth, facial morphometry, and effects on in vivo brain regional volumes using structural magnetic resonance imaging. Aim 2 will assess neurobehavioral outcomes using eyeblink classical conditioning and spatial working memory. Aim 3 will assess neuroanatomical effects via neuronal counts in the cerebellum, hippocampal formation, and brainstem serotonin system. These studies are designed to inter-relate with and reciprocally inform four of the human projects [Facial Imaging (Foroud), Brain Imaging (Sowell), Neurobehavioral project (Mattson), and the Risk Factors/Nutrition project (Chambers)] and the two mouse basic science projects (Zhou; Sulik). The second objective (Aim 4) is to test the hypothesis that choline supplementation initiated periconceptually will attenuate the adverse effects of alcohol exposure in the 3-trimester sheep model. This study was designed with explicit and complementary collaboration with the choline-supplementation projects in rats [the basic science developmental project using rats (Thomas)] and in humans [Risk Factor/Nutrition project of Chambers/Keen]. This sheep model provides a unique opportunity to bridge the basic and clinical   arms of the consortium more closely than has been achieved in the past.           n/a",Translational Studies of FASD Using a Sheep Model-U01,7343058,U01AA017120,"['3-Dimensional', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Age', 'Age-Months', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Attenuated', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blinking', 'Brain', 'Brain Injuries', 'Brain Stem', 'Brain imaging', 'Brain region', 'Cells', 'Cerebellar Nuclei', 'Cerebellum', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Condition', 'Count', 'Data', 'Depth', 'Development', 'Diagnosis', 'Diagnostic', 'Dietary Intervention', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'First Pregnancy Trimester', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Growth', 'Hippocampal Formation', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Life', 'Link', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Methods', 'Microcephaly', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Numbers', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Risk', 'Risk Factors', 'Rodent', 'Rodent Model', 'Role', 'Schools', 'Sensitivity and Specificity', 'Serotonin', 'Severities', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Staging', 'Structure', 'Structure-Activity Relationship', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Upper arm', 'Variant', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'binge drinking', 'brain behavior', 'brain morphology', 'brain volume', 'classical conditioning', 'cognitive control', 'conditioning', 'critical developmental period', 'data integration', 'dentate gyrus', 'design', 'drinking', 'fetal diagnosis', 'follow-up', 'granule cell', 'hippocampal pyramidal neuron', 'improved', 'in utero', 'in vivo', 'infancy', 'literacy', 'morphometry', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurobehavioral test', 'neuron loss', 'northern plains', 'novel', 'nutrition', 'postnatal', 'prenatal', 'prevent', 'programs', 'prospective', 'reconstruction', 'research study', 'social', 'species difference', 'three dimensional structure', 'translational study']",NIAAA,TEXAS AGRILIFE RESEARCH,U01,2007,267087,0.04993057353377974
"MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01    DESCRIPTION (provided by applicant): Fetal Alcohol Spectrum Disorders (FASD), significant components of which are Central Nervous System (CMS) and craniofacial abnormalities, are a major public health problem. While eliminating FASD is the ultimate goal for both clinical and basic FASD research, we recognize that in the near future, adverse effects from prenatal ethanol exposure will persist. To better diagnose and treat affected individuals, a more complete understanding of the full spectrum of the ethanol-induced abnormalities is needed. The proposed investigations are designed to integrate with those of other consortium members in meeting this need. For this work, both high resolution Magnetic Resonance Imaging (MRI), which can provide 29 micron (or less) isotropic scans and subsequent accurate 3-D reconstructions and segmental analyses, and Diffusion Tensor Imaging (DTI), which allows CMS fiber tract analyses, will be applied to the study of an FASD mouse model. Previous research utilizing this model has established critical exposure times that yield facial and CNS abnormalities that are consistent with full-blown Fetal Alcohol Syndrome, as well as other components of FASD. The proposed studies will employ this model and both acute and chronic ethanol treatment paradigms to test the overall hypothesis that in mice, ethanol induces structural abnormalities of the brain and face that are consistent with and informative for those in human FASD. To this end, utilizing MRI and DTI as high throughput screening platforms, we propose to address the following specific aims : 1) to provide comprehensive documentation and discovery of the ethanol-induced CNS dysmorphology that results from prenatal ethanol exposure at embryonic and early fetal stages of development; 2) to define the facial dysmorphology that results from prenatal ethanol exposure during embryonic and/or early fetal stages and to relate their character and severity to accompanying abnormalities of the brain; and 3) to identify regions other than the brain or face that may serve as diagnostic indicators of prenatal ethanol exposure. The results of the proposed studies will be compared to those of corresponding investigations by other consortium members. It is expected that the structural abnormalities of the brain and face that are induced by ethanol in mice will reflect the pattern of defects observed in children with FASD, will inform human diagnostic tests, and will provide new information that will be helpful in reducing the incidence of FASD.           n/a",MAGNETIC RESONANCE AND DIFFUSION TENSOR IMAGING OF A MOUSE FASD MODEL U01,7343348,U01AA017124,"['3-Dimensional', 'A Mouse', 'Acoustic Nerve', 'Acute', 'Address', 'Adolescent', 'Adverse effects', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Back', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Complement', 'Consult', 'Craniofacial Abnormalities', 'Data', 'Data Files', 'Data Storage and Retrieval', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Diet', 'Dietary Intervention', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease model', 'Documentation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Embryo', 'Embryonic Development', 'Emotional', 'End Point', 'Ethanol', 'Ethnic group', 'Face', 'Female', 'Fertilization', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fetus', 'Fiber', 'First Pregnancy Trimester', 'Fostering', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Hearing Tests', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Indiana', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Intervention', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory Animals', 'Labyrinth', 'Language', 'Language Development', 'Life', 'Liquid substance', 'Literature', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Menstruation', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'Nasal septum structure', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neuraxis', 'Neurobiology', 'New Mexico', 'Optic Nerve', 'Optics', 'Outcome', 'Partner in relationship', 'Pattern', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Photography', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevention', 'Principal Investigator', 'Prosencephalon', 'Public Health', 'Publishing', 'Range', 'Rattus', 'Recording of previous events', 'Reproduction', 'Request for Applications', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Retrieval', 'Role', 'Scanning', 'Schools', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staging', 'Structure', 'Sum', 'Supplementation', 'System', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Week', 'Woman', 'Work', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'base', 'brain behavior', 'brain morphology', 'cognitive control', 'computer generated', 'craniofacial', 'critical developmental period', 'data integration', 'day', 'design', 'dosage', 'drinking', 'fetal', 'follow-up', 'high throughput screening', 'human data', 'human study', 'human subject', 'improved', 'in utero', 'infancy', 'interest', 'intraperitoneal', 'literacy', 'malformation', 'member', 'membranous labyrinth', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'prenatal exposure', 'programs', 'prospective', 'reconstruction', 'response', 'sensory system', 'size', 'social', 'symposium', 'three dimensional structure']",NIAAA,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2007,225000,0.07256612661581606
"Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies    DESCRIPTION (provided by applicant): Fetal alcohol syndrome (FAS) occurs in children born to women who drink alcohol heavily during pregnancy and is one of the leading non-hereditary causes of mental retardation in the Western World. It is estimated that the prevalence of FAS in the general U.S. population is between 0.5 and 2.0 per 1,000 births, while the undiagnosed population with variable facial and brain dysmorphology described as fetal alcohol spectrum disorder (FASD) is estimated to be 10 times higher. The difficulty in the diagnosis of FASD involves misdiagnosis due to the presence or absence of the typical facial dysmorphology in association with brain dysfunction. Accurate diagnosis is further complicated by the lack of information about the contribution of dose, frequency, and timing of alcohol exposure during pregnancy to variation in facial dysmorphology. In this project, a mouse model that models human consumption and is known to produce FAS-like features resulting from prenatal alcohol exposure, will be used to test the effects of differences in dose and timing of alcohol exposure on face and brain development. A combination of 3D imaging that includes Micro-video and micro-resonance imaging (MRI) will be used to capture the detailed facial structure, micro-computational tomography (Micro-CT) to capture the underlying facial bone, MRI for detailed brain dimensions, and diffusion tensor imaging (DTI) for nerve fiber tracks in the fetal period. A novel computational program will be compiled to detect features specifically as function of alcohol exposure. The association and dissociation of facial and brain dysmorphology as a function of dose and timing of alcohol exposure will be analyzed to better inform the diagnosis of FAS/ FASD. These studies will be a collaboration sharing resources and methods and will be performed across both Basic and Clinical Science components in consortium effort. To date there is no cure for FAS/FASD, which is a life long ordeal from the birth. Experimental tests, using the above model and setting, of trophic peptides which have been known to prevent neurodegeneration in trials for Alzheimer Disease and protect cell death in embryonic stage, have been partially tested in the embryonic period to show protection against the alcohol-induced retardation. The new studies will test whether the trophic peptides can prevent alcohol-induced brain and facial dysmorphology as well as behavioral impairment known to occur in FAS.          n/a",Mouse Model Neuro-Facial Dysmorphology: Tanslational and Treatment Studies,7343333,U01AA017123,"['Address', 'Adolescent', 'Adopted', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Birth', 'Blood alcohol level measurement', 'Bone and Cartilage Funding', 'Brain', 'Brain imaging', 'C57BL/6 Mouse', 'CDKN1A gene', 'Cell Death', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Consumption', 'Count', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diet', 'Dietary Intervention', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disruption', 'Dissociation', 'Dose', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Elements', 'Embryo', 'Emotional', 'Ethanol', 'Ethnic group', 'Evaluation', 'Experimental Animal Model', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Genetic Polymorphism', 'Gestational Age', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Impairment', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Inherited', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Length', 'Life', 'Liquid substance', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mental Retardation', 'Methods', 'Mission', 'Modeling', 'Morphology', 'Moscow', 'Mothers', 'Mus', 'NAPVSIPQ peptide', 'Neonatal', 'Nerve Degeneration', 'Nerve Fibers', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'Neurons', 'New Mexico', 'Oral', 'Outcome', 'Pathway interactions', 'Patient currently pregnant', 'Pattern', 'Pattern Recognition', 'Peptides', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Prevalence', 'Principal Investigator', 'Rattus', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resource Sharing', 'Role', 'Sampling', 'Schools', 'Sensitivity and Specificity', 'Sheep', 'Short-Term Memory', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skeleton', 'Source', 'Specificity', 'Staging', 'Structure', 'Sum', 'Supplementation', 'Surface', 'System', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Variant', 'Vibrissae', 'Western World', 'Woman', 'Work', 'X-Ray Computed Tomography', 'alcohol effect', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'brain volume', 'clinical application', 'cognitive control', 'craniofacial', 'critical developmental period', 'data integration', 'day', 'design', 'digital imaging', 'drinking', 'face bone structure', 'fetal', 'follow-up', 'human study', 'image reconstruction', 'improved', 'in utero', 'infancy', 'literacy', 'morphometry', 'morris water maze', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'neurochemistry', 'neuroimaging', 'neurotrophic factor', 'northern plains', 'novel', 'oncoprotein p21', 'peptide analog', 'postnatal', 'prenatal', 'prevent', 'programs', 'prospective', 'relating to nervous system', 'sensory cortex', 'social', 'tomography', 'translational study', 'young adult']",NIAAA,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,U01,2007,224838,0.05519785806278161
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6985348,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2006,475410,0.254927587305704
"Facial Expression Analysis by Image Processing    DESCRIPTION (provided by applicant): Facial expression provides cues about emotional response, regulates interpersonal behavior, and communicates aspects of psychopathology. Human-observer based methods for measuring facial expression are labor intensive, qualitative, and difficult to standardize. Our interdisciplinary team of computer and behavioral scientists has developed the CMU/Pitt Automated Facial Image Analysis (AFA) system that is capable of automatically recognizing facial action units and analyzing their timing in facial behavior. The quantitative measurement achieved by AFA represents a major advance over manual and subjective measurement without requiring the use of invasive sensors. We envision to use AFA's reliable, valid, and efficient measurement of emotion expression and related nonverbal behavior for assessment of symptom severity in depression. Current methods of clinical assessment of depression depend almost entirely on verbal report (clinical interview and/or questionnaire). They lack systematic and efficient ways of incorporating behavioral observations that are .strong indicators of depressive symptoms, especially those related to the timing of dyadic interaction between clinician and patient, much of which may occur outside the awareness of either individual. AFA is capable of extracting both the type and timing of nonverbal indicators of depression. Our hypothesis is that quantitative measures of the configuration and timing of facial expression, head motion, and gaze obtainable by AFA will improve clinical assessment of symptom severity and evaluation of treatment outcomes when combined with information from interviews and self-report questionnaires. We propose to test this hypothesis in 40 participants participating in a treatment intervention study for major depression. Interview, questionnaire, and video data will be collected at regular intervals over the course of treatment. To measure social dynamics, both patient and interviewer will be video recorded and processed using AFA. Longitudinal multilevel modeling will be used to test study hypotheses. We will improve further algorithms and capabilities of AFA to meet evaluation goals and prepare AFA for use by the scientific and clinical community.         n/a",Facial Expression Analysis by Image Processing,7049026,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2006,480876,0.1851400635708347
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6881434,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,358843,0.25148545884702767
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6841137,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2005,473795,0.254927587305704
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6907787,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,42260,0.25148545884702767
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6736314,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,305282,0.25148545884702767
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6733239,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2004,499766,0.254927587305704
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6639029,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,297999,0.25148545884702767
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6538699,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2002,290602,0.25148545884702767
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6287970,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,334747,0.25148545884702767
"COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR DESCRIPTION (Applicant's abstract): Facial expressions provide an important behavioral measure for the study of emotion, cognitive processes, and social interaction, and contain diagnostic information for neurological disorders and depression. Facial expression measurement from video is less intrusive than EEG, EMO, ANS or brain imaging measurements as an indicator of emotional activity. The measurement is presently performed by human experts. The goal of this research is to develop an automatic system for recognition, measurement, and coding of facial expressions from video using computer vision technology. This project will utilize probabilistic models of dynamical systems to mod& the facial behavior underlying the observed image sequences. These techniques include hidden Markov models, and a new stochastic modeling technique developed by Movellan and colleagues called diffusion networks [38]. Diffusion networks offer the advantage over traditional dynamical models of allowing continuous time dynamics and continuous states. An automated system would make facial expression measurement more widely accessible as a research tool in behavioral science and investigations of the neural substrates of emotion.  n/a",COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR,6391721,F32MH012417,"['behavior test', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' clinical research', ' cognition', ' computer assisted diagnosis', ' depression', ' emotions', ' face expression', ' human subject', ' image processing', ' mathematical model', ' social integration']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,F32,2001,41996,0.2210523073863182
"COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR DESCRIPTION (Applicant's abstract): Facial expressions provide an important behavioral measure for the study of emotion, cognitive processes, and social interaction, and contain diagnostic information for neurological disorders and depression. Facial expression measurement from video is less intrusive than EEG, EMO, ANS or brain imaging measurements as an indicator of emotional activity. The measurement is presently performed by human experts. The goal of this research is to develop an automatic system for recognition, measurement, and coding of facial expressions from video using computer vision technology. This project will utilize probabilistic models of dynamical systems to mod& the facial behavior underlying the observed image sequences. These techniques include hidden Markov models, and a new stochastic modeling technique developed by Movellan and colleagues called diffusion networks [38]. Diffusion networks offer the advantage over traditional dynamical models of allowing continuous time dynamics and continuous states. An automated system would make facial expression measurement more widely accessible as a research tool in behavioral science and investigations of the neural substrates of emotion.  n/a",COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR,6185479,F32MH012417,"['behavior test', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' clinical research', ' cognition', ' computer assisted diagnosis', ' depression', ' emotions', ' face expression', ' human subject', ' image processing', ' mathematical model', ' social integration']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,F32,2000,37516,0.2210523073863182
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING DESCRIPTION (Applicant's Abstract):  Facial expression communicates              information about emotional response and plays a critical role in the            regulation of interpersonal behavior.  Current human-observer based methods      for measuring facial expression are labor intensive, qualitative, and            difficult to standardize across laboratories and over time.  To make             feasible more rigorous, quantitative measurement of facial expression in         diverse applications, we formed an interdisciplinary research group which        covers expertise in facial expression analysis and image processing.  In the     funding period, we developed and demonstrated the first version of an            automated system for measuring facial expression in digitized images.  The       system can discriminate nine combinations of FACS action units in the upper      and lower face, quantity the timing and topography of action unit intensity      in the brow region; and geometrically normalize image sequences within a         range of plus or minus 20 degrees of out of-plane.                                                                                                                In the competing renewal, we will increase the number of action unit             combinations that are recognized, implement convergent methods of                quantifying action unit intensity, increase the generalizability of action       unit estimation to a wider range of image orientations, test facial image        processing (FIP) in image sequences from directed facial action tasks and        laboratory studies of emotion regulation, and facilitate the integration of      FIP into existing data management and statistical analysis software for use      by behavioral science researchers and clinicians.  With these goals              completed, FIP will eliminate the need for human observers in coding facial      expression, promote standardize measurement, make possible the collection        and processing of larger, more representative data sets, and open new areas      of investigation and clinical application.                                        n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6185949,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,MELLON PITTS CORPORATION (MPC CORP),R01,2000,233574,0.23425764794409876
"Bioethics of syndrome diagnosis using 3D image analysis Project Summary/Abstract This supplement will address the unintended consequences and collateral damage that arise when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. In Aim 1, we will determine whether the accuracy of this technology varies based on self-reported race, sex and age. In this aim, we examine our existing database for evidence of bias based on self-reported race, sex or age. We further determine the extent to which these variables influence classification performance. To the extent sample sizes allow, we will carry this analysis to the level of specific syndromes. Finally, we will use anonymized reference datasets of non-syndromic faces to compare false positive rates based on NIH race definitions, sex and age. The outcome of this aim is to objectively establish bias and estimate the effects of under-representation across race, age and sex categories within our data. In Aim 2, we will determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians. This aim will establish the extent to which the storing of large databases of facial images and the application of machine learning processes to them for diagnostic purposes may raise privacy concerns. The concerns investigated will include potential hacks into protected health information; fear relating to the bias in some facial recognition software (and, potentially, in the Facebase database); and fear of discrimination in the application of the technology, such as by insurers. The outcome will be a white paper that targets a high-profile journal, summarizing the findings and defining crucial issues that should guide the development of facial imaging for disease diagnosis and clinical usage. Project Narrative Our supplement application will address the important question of unintended consequences and collateral damage when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. The use of large facial recognition databases in medicine represents a frontier that arrives with tremendous potential but undeniable risks. Our central aims are: (1) determine whether the accuracy of this technology varies based on self-reported race, sex and age; and (2) determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians.",Bioethics of syndrome diagnosis using 3D image analysis,10132648,U01DE028729,"['3-Dimensional', 'Address', 'Age', 'Authoritarianism', 'Bioethical Issues', 'Bioethics', 'Biometry', 'Categories', 'Classification', 'Clinic', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Computational Biology', 'Country', 'Data', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Ethics', 'Face', 'FaceBase', 'Fright', 'Funding', 'General Hospitals', 'Generations', 'Genes', 'Genetic Diseases', 'Health', 'Hereditary Disease', 'Image', 'Image Analysis', 'Insurance Carriers', 'Journals', 'Libraries', 'Machine Learning', 'Medical', 'Medicine', 'Outcome', 'Paper', 'Pathology', 'Patient Self-Report', 'Patient imaging', 'Performance', 'Privacy', 'Private Sector', 'Process', 'Psychiatry', 'Public Sector', 'Race', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'San Francisco', 'Secure', 'Syndrome', 'Technology', 'Three-Dimensional Image', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'craniofacial', 'disease diagnosis', 'facial recognition software', 'frontier', 'human data', 'intervention cost', 'new technology', 'professor', 'repository', 'sex', 'tool']",NIDCR,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2020,152200,0.1563471763114331
"Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure,9927955,U01AA014809,"['3-Dimensional', '3D Print', '3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Screening procedure', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'algorithm development', 'automated image analysis', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'machine learning method', 'maternal cigarette smoking', 'mouse model', 'neonatal period', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'prenatal testing', 'recruit', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure']",NIAAA,UNIVERSITY OF OXFORD,U01,2020,234498,0.0913413877217027
