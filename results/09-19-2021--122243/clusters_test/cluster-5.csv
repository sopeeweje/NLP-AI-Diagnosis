text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,10111538,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2021,1354555
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10213202,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'dietary', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2021,981634
"Biomedical Data Translator Development of Autonomous Relay Agent: ARAX This project would continue collaborative work within the Translator consortium by a multi-site team (“Team X-ray”) at Oregon State University (PI Stephen Ramsey) and at two partner institutions, Pennsylvania State University (PI Koslicki) and the Institute for Systems Biology (PI Eric Deutsch; Co-I Jared Roach). Team X-ray was highly productive in Translator's feasibility assessment phase and the team brings critical expertise to Translator (see Resources). Component type: We propose to create, validate, and integrate an autonomous relay agent (ARA) called ARAX . ARAX will be a middleware component in the new Translator architecture that will extend significantly beyond the capabilities of the prototype reasoning tool (RTX) that we created in the feasibility assessment phase. Depending on the input request, ARAX's main output will be ranked subgraphs with clearly explained ranking basis. ARAX will leverage code and algorithms from RTX and will have an explicit application focus area, as described below. Main problems that ARAX is trying to address: Connections within a biomedical knowledge graph have highly variable degrees of (i) confidence (due to ambiguous predicates and/or due to highly variable degrees of reliability of knowledge types) and (ii) potential relevance to the user's query. Such edge-significance variability leads to both incorrect and difficult-to-interpret results which together pose a significant problem for creating broadly useful tools for computer-based biomedical reasoning. We propose to address this problem by explicitly accounting for these two types of edge variability in the reasoning algorithms–spanning a broad range of biomedical query types–that ARAX will provide to Translator. In addition to these broad capabilities, as described in the Project Plan, we will incorporate advanced algorithms in ARAX for responding to queries relating to disease therapy, including (1) drug repositioning for known disease, leveraging knowledge about the disease’s pathogenesis [1] ; and (2) therapeutic recommendations for rare diseases based on symptoms and the putative causal genetic variant. Plan for implementation of the project: In our Project Plan we describe a five-year timeline for creating, validating, and integrating ARAX within Translator, beginning with a three-month sprint leading to a prototype of ARAX by mid-March 2020. Key components of the plan include: (1) leveraging the BioThings Explorer software framework to enable ARAX to dynamically map between compounds, proteins, pathways, variants, phenotypes, and diseases based on knowledge source application programming interfaces in the Translator registry; (2) leveraging COHD and related Translator resources to obtain biomedical semantic distance information; (3) leveraging an application programming interface endpoint for the RTX biomedical knowledge graph, KG2; and (4) implementing probabilistic reasoning algorithms leveraging provenance information and dynamically determined edge relevance scores to improve reasoning. We will systematically use machine-learning to align ranking scores with measures of output quality. Collaboration strengths of our team include (i) developing technical standards for communications between Translator software agents (leveraging PI Deutsch’s extensive past experience); (ii) developing knowledge graph standards (leveraging PI Ramsey’s and PI Koslicki’s expertise); and (iii) deriving use-case vignettes that speak to the transformative potential of Translator (leveraging Co-I Roach’s and PI Ramsey’s expertise). In the development phase, our team would continue to collaborate with other teams and with NIH stakeholders in an adaptive, high-bandwidth, and team-boundary-agnostic fashion, as detailed in the Project Plan. Key challenges to building the proposed system are (1) the need to be able to ""chain"" together analytical steps between tools and (2) the need for cooperative development of standards that enable Translator components to interact; we address them in detail in the Project Plan. n/a",Biomedical Data Translator Development of Autonomous Relay Agent: ARAX,10333468,OT2TR003428,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Area', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disease', 'Institutes', 'Institution', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Oregon', 'Output', 'Pathogenesis', 'Pathway interactions', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Proteins', 'Rare Diseases', 'Recommendation', 'Registries', 'Resources', 'Roentgen Rays', 'Semantics', 'Site', 'Software Framework', 'Source', 'Symptoms', 'System', 'Systems Biology', 'Therapeutic', 'TimeLine', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'application programming interface', 'base', 'experience', 'genetic variant', 'improved', 'knowledge graph', 'middleware', 'prototype', 'tool']",NCATS,OREGON STATE UNIVERSITY,OT2,2021,897051
"Education Pathways for Biomedical Data Science (R25) Project Summary / Abstract This project brings together Drexel University and the Children’s Hospital of Philadelphia (CHOP) to create an adaptive Biomedical Data Science education program to empower researchers to learn and use emerging data science methods. We propose an in-line program to prepare researchers for data-driven work directly in their current field, while also identifying avenues for interdisciplinary collaboration. We will develop novel curricula pathways, leverage existing educational resources, create bridge materials, and provide practicum “lab” activities matching domain-specific projects to participants for hands-on experience. Educational Pathways in Biomedical Data Science will collaborate with the CHOP Office of Academic Training and Outreach Programs to engage a diverse learner audience in novel pedagogical research. Learners will be recruited from active participants in many existing CHOP training initiatives, including a novel data science education program, graduate student training, postdoc mentorship, physician fellowship research, and clinical research staff training. After enrollment, education program managers will cluster participants into collaborative communities of practice where they will receive mentorship and contribute to development of pathways. We acknowledge that we are still learning the most effective interventions for biomedical data science education, both within our specific communities and broadly within medical education (e.g. Federer et al., 2015; Rowhani-Faarid, Allen, and Barnett, 2017). We will develop new evidence of gaps in knowledge, skills, and attitudes among learners. We will develop and implement biomedical data science literacy instruments based on emerging scholarship. We will also gather learner feedback via mixed methods to adapt and evolve our modular resources, ensure robust learner outcomes, and align deliverables with the NIH Strategic Plan for Data Science. Data Science instruction for researchers outside of traditional computer and information sciences is a concrete step toward data-driven scientific literacy for all. We will ensure that participants emerge from this program with computational and algorithmic literacy solidified through hands-on experience. For non-computing researchers, we also will provide the foundational data fluencies necessary for individuals to contribute meaningfully to machine learning research, which will enable data-driven systems, insight-to-decision transformation, decision- making, and data-driven decision management. Finally, for all participants, we will strive to help individuals from a broad spectrum of backgrounds and identities identify new directions in which to develop their careers. Project Narrative “Educational Pathways in Biomedical Data Science” will create evidence-based pathways to guide and augment researcher skill in data-intensive science. Our learning pathways and supporting modules will equip researchers to perform nimble research with massive datasets that span institutional and disciplinary boundaries. We will model cross-disciplinary collaboration by building upon an existing partnership between the College of Computing and Informatics of Drexel University and the Research Institute of the Children’s Hospital of Philadelphia, grounding the project in both computing and biomedical research practice.",Education Pathways for Biomedical Data Science (R25),10199482,R25GM141501,"['Academic Training', 'Attitude', 'Biomedical Research', 'Certification', 'Clinical Research', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Community of Practice', 'Computational algorithm', 'Custom', 'Data', 'Data Science', 'Data Set', 'Decision Making', 'Degree program', 'Development', 'Discipline', 'Ecosystem', 'Education', 'Educational Curriculum', 'Effectiveness', 'Enrollment', 'Ensure', 'Feedback', 'Fellowship', 'Foundations', 'Goals', 'Grouping', 'Home environment', 'Individual', 'Informatics', 'Information Sciences', 'Instruction', 'Knowledge', 'Learning', 'Learning Module', 'Literature', 'Machine Learning', 'Medical Education', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Motivation', 'Outcome', 'Participant', 'Pathway interactions', 'Pediatric Hospitals', 'Peer Review', 'Philadelphia', 'Physicians', 'Plant Roots', 'Postdoctoral Fellow', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Scholarship', 'Science', 'Strategic Planning', 'System', 'Training', 'Training Programs', 'Translating', 'United States National Institutes of Health', 'Universities', 'Work', 'acronyms', 'base', 'biomedical data science', 'biomedical informatics', 'career', 'cohort', 'college', 'computer science', 'education pathway', 'education resources', 'effective intervention', 'evidence base', 'experience', 'formative assessment', 'graduate student', 'insight', 'instrument', 'interdisciplinary collaboration', 'interest', 'literacy', 'novel', 'online course', 'outreach program', 'pedagogy', 'programs', 'science education', 'scientific literacy', 'skills', 'statistics', 'student training', 'success', 'user centered design']",NIGMS,CHILDREN'S HOSP OF PHILADELPHIA,R25,2021,85673
"DOCKET: accelerating knowledge extraction from biomedical data sets Component type: This Knowledge Provider project will continue and significantly extend work done by the Translator Consortium Blue Team, focusing on deriving knowledge from real-world data through complex analytic workflows, integrated to the Translator Knowledge Graph, and served via tools like Big GIM and the Translator Standard API. The problem: We aim to solve the “first mile” problem of translational research: how to integrate the multitude of dynamic small-to-large data sets that have been produced by the research and clinical communities, but that are in different locations, processed in different ways, and in a variety of formats that may not be mutually interoperable. Integrating these data sets requires significant manual work downloading, reformatting, parsing, indexing and analyzing each data set in turn. The technical and ethical challenges of accessing diverse collections of big data, efficiently selecting information relevant to different users’ interests, and extracting the underlying knowledge are problems that remain unsolved. Here, we propose to leverage lessons distilled from our previous and ongoing big data analysis projects to develop a highly automated tool for removing these bottlenecks, enabling researchers to analyze and integrate many valuable data sets with ease and efficiency, and making the data FAIR [1]. Plan: (AIM 1) We will analyze and extract knowledge from rich real-world biomedical data sets (listed in the Resources page) in the domains of wellness, cancer, and large-scale clinical records. (AIM 2) We will formalize methods from Aim 1 to develop DOCKET, a novel tool for onboarding and integrating data from multiple domains. (AIM 3) We will work with other teams to adapt DOCKET to additional knowledge domains. ■ The DOCKET tool will offer 3 modules: (1) DOCKET Overview: Analysis of, and knowledge extraction from, an individual data set. (2) DOCKET Compare: Comparing versions of the same data set to compute confidence values, and comparing different data sets to find commonalities. (3) DOCKET Integrate: Deriving knowledge through integrating different data sets. ■ Researchers will be able to parameterize these functions, resolve inconsistencies, and derive knowledge through the command line, Jupyter notebooks, or other interfaces as specified by Translator Standards. ■ The outcome will be a collection of nodes and edges, richly annotated with context, provenance and confidence levels, ready for incorporation into the Translator Knowledge Graph (TKG). ■ All analyses and derived knowledge will be stored in standardized formats, enabling querying through the Reasoner Std API and ingestion into downstream AI assisted machine learning. ■ Example questions this will allow us to address include: (Wellness) Which clinical analytes, metabolites, proteins, microbiome taxa, etc. are significantly correlated, and which changing analytes predict transition to which disease? [2,3] (Cancer) Which gene mutations in any of X pathways are associated with sensitivity or resistance to any of Y drugs, in cell lines from Z tumor types? (All data sets) Which data set entities are similar to this one? Are there significant clusters? What distinguishes between the clusters? What significant correlations of attributes can be observed? How can this set of entities be expanded by adding similar ones? How do these N versions of this data set differ, and how stable is each knowledge edge as the data set changes over time? Collaboration strengths: Our team has extensive experience with biomedical and domain-agnostic data analytics, integrating multiple relevant data types: omics, clinical measurements and electronic health records (EHRs). We have participated in large collaborative consortia and have subject matter experts willing to advise on proper data interpretation. Our application synergizes with those of other Translator teams (see Letters of Collaboration). Challenges: Data can come in a bewildering diversity of formats. Our solution will be modular, will address the most common formats first, and will leverage established technologies like DataFrames and importers (like pandas.io) where possible. Mapping nodes and edge types onto standard ontologies is crucial for knowledge integration; we will collaborate with the Standards component to maximize success. n/a",DOCKET: accelerating knowledge extraction from biomedical data sets,10330627,OT2TR003443,"['Address', 'Big Data', 'Cell Line', 'Clinical', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Electronic Health Record', 'Ethics', 'FAIR principles', 'Gene Mutation', 'Individual', 'Ingestion', 'Knowledge', 'Knowledge Extraction', 'Letters', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Methods', 'Ontology', 'Outcome', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'Records', 'Research', 'Research Personnel', 'Resistance', 'Resources', 'Specific qualifier value', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Work', 'experience', 'indexing', 'interest', 'interoperability', 'knowledge graph', 'knowledge integration', 'large datasets', 'microbiome', 'novel', 'success', 'tool', 'tumor']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT2,2021,332969
"Tracking the dynamics of how schemas scaffold recall Project Summary Every new experience in our life takes place within the context of familiar environments and situations. However, most research on memory has focused on the artificial memorization of word lists, symbols or pictures; these studies do not meaningfully address how structured prior knowledge about the world (e.g., in the form of a familiar spatial map, or knowledge of how restaurant meals unfold over time) can scaffold new learning. In the proposed studies, I aim to precisely characterize how and where prior knowledge and new information are represented, how they get linked at encoding, and how they interact at recall to allow memories to be retrieved. In the first proposed study of my F99 phase, I test the hypothesis that hippocampal engagement at event boundaries during learning binds new information (i.e. objects) to the scaffold of existing knowledge (i.e. knowledge of a familiar location), and that hippocampal activation during recall mediates the successful retrieval of the bound object from the location in which it was stored. I also test the hypothesis that distinctive representations of spatial locations in the brain will reduce interference between objects stored in those locations. There is a potential downside to using prior knowledge as a scaffold: When there is too much information attached to one part of the scaffold, old and new memories will interfere with each other. How, then, could someone prioritize the retrieval of new memories over older (now-irrelevant) memories that were linked to the scaffold? Recent research on intentional forgetting suggests a solution to this limitation. Specifically, in my second proposed study, I test the hypothesis (supported by neurophysiological evidence, prior neuroimaging results, and computational models) that previously encoded memories can be weakened by moderately activating their neural representation, thereby “cleaning” the scaffold and reducing interference. In the K00 phase, I will extend my research to identify pathologies in how clinical populations use prior knowledge to interpret and remember their experiences, using tools from computational psychiatry; I also plan to design new technological tools to address these issues. Overall, the proposed project makes use of naturalistic and ecologically valid stimuli (in the form of continuous stimuli and immersive virtual reality) paired with advanced machine learning tools applied to brain imaging data, to study the fundamental nature of how new and old information are linked to allow learning. In the long-term, the findings from this project regarding how prior knowledge can be optimally leveraged to support new learning will lead to the development of tools to help memory-impaired individuals make better use of prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly. Project Narrative In my dissertation, I will use newly-developed machine learning techniques to study how the brain uses prior knowledge (about the spatial structure of an environment, or how certain types of events unfold in time) to scaffold new learning. By precisely characterizing how this scaffolding process works, my research will help to identify ways in which prior knowledge can be more optimally leveraged to support learning. This will lead to the development of tools to help memory-impaired individuals make better use of intact prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly.",Tracking the dynamics of how schemas scaffold recall,10156352,F99NS120644,"['Address', 'Behavioral', 'Binding', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Models', 'Cues', 'Data', 'Doctor of Philosophy', 'Environment', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'General Population', 'Goals', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Institution', 'Knowledge', 'Lead', 'Learning', 'Life', 'Link', 'Literature', 'Location', 'Machine Learning', 'Maps', 'Mediating', 'Memory', 'Memory impairment', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Participant', 'Pathology', 'Perception', 'Performance', 'Phase', 'Play', 'Population', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Psyche structure', 'Psychiatry', 'Research', 'Research Project Grants', 'Restaurants', 'Retrieval', 'Scanning', 'Scientist', 'Self-Help Devices', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'Work', 'computerized tools', 'design', 'experience', 'field study', 'forgetting', 'memory encoding', 'memory retrieval', 'neuroimaging', 'neurophysiology', 'phase 1 testing', 'prevent', 'relating to nervous system', 'scaffold', 'skills', 'statistics', 'tool', 'tool development', 'virtual', 'virtual reality', 'virtual reality environment', 'virtual world']",NINDS,PRINCETON UNIVERSITY,F99,2021,47036
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,10086862,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2021,171720
"The Metadata Powerwash - Integrated tools to make biomedical data FAIR Project Summary  The metadata that describe scientific data are fundamental resources to enable (1) the discovery and reuse of the data and (2) the reproducibility of the experiments that generated the data in the first place. Metadata are essential for scientists to understand the associated data and to reuse them, as well as for information technology to index the data, to make the data available, and to provide filters for scientists to search for the corresponding datasets. Currently, the scientific metadata hosted in public repositories suffer from multiple quality issues that limit scientists’ ability to find and reuse the experimental datasets to which they refer. It can take many weeks of a scientist’s time to identify a collection of datasets that fulfill specific criteria when the data are so poorly described—and the majority of the process is necessarily manual.  We propose to develop an end-to-end solution to standardize biomedical metadata with the help of ontologies—data structures that define the terms in an application domain and the relationships among them. There are hundreds of ontologies that provide standard terms for use in biomedicine, and they are essential resources to make biomedical metadata interoperable and reusable. Our approach also will build on the technology created by the Center for Expanded Data Annotation and Retrieval (CEDAR), which offers a library of building blocks and common data elements for defining computer-based metadata templates based on community standards.  Our plan involves three specific aims. First, we will develop a method and tool to standardize the multiple, ad hoc metadata field names that may appear in metadata to represent the same type of information by replacing those field names with the field names used in standard metadata templates or, if no appropriate template match is available, with terms from a relevant ontology. Second, we will develop methods and tools to standardize different types of metadata field values, for example, categorical values such as drugs or diseases, and numerical values such as age, or sample collection date. Third, we will evaluate the speed, precision, and recall of our metadata transformation pipeline—built out of the methods and tools to standardize field names and values—on a large corpus of metadata that we will manually curate based on existing public metadata. We will also carry out experiments to test the effect of the standardized metadata when biomedical scientists perform dataset search in the context of their work. Project Narrative Data that offer precise descriptions of data—metadata—are critical scientific resources that facilitate the discovery, reuse, and reproducibility of the data to which they refer. Our goal is to create methods and tools that improve the quality of scientific metadata hosted in public repositories, and thus enhance the discoverability and re-use of public biomedical datasets. Making data more accessible through scientifically rigorous metadata will accelerate the ability to make transformative data-driven biomedical discoveries using public data archives.",The Metadata Powerwash - Integrated tools to make biomedical data FAIR,10093841,R01LM013498,"['Age', 'Biological Specimen Banks', 'Categories', 'Collection', 'Common Data Element', 'Communities', 'Computers', 'Data', 'Data Science', 'Data Set', 'Disease', 'FAIR principles', 'Funding Agency', 'Goals', 'Gold', 'Information Technology', 'Knowledge', 'Libraries', 'Link', 'Manuals', 'Metadata', 'Methods', 'Names', 'Natural Language Processing', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Problem Solving', 'Process', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Sampling', 'Science', 'Scientist', 'Specific qualifier value', 'Speed', 'Standardization', 'Structure', 'Technology', 'Testing', 'Time', 'Variant', 'Work', 'base', 'biomedical scientist', 'data archive', 'data repository', 'data reuse', 'experimental study', 'improved', 'indexing', 'information organization', 'interoperability', 'metadata standards', 'public repository', 'repository', 'sample collection', 'search engine', 'secondary analysis', 'tool']",NLM,STANFORD UNIVERSITY,R01,2021,334847
"Knowledge Management Center for Illuminating the Druggable Genome The main goal of the Knowledge Management Center (KMC) for the Illuminating the Druggable Genome (IDG) program is to aggregate, update and articulate protein-centric data, information and knowledge for the entire human proteome with emphasis on understudied proteins from the 3 families that are the focus of the IDG (“IDG List”). The long-term objective of the KMC is to encourage and support biomedical research aimed at understudied proteins by providing an extensive resource of data, information, knowledge, methods and reagents for the entire human proteome, and to support the growing online community focused on understudied proteins. With focus on the IDG List and human proteins, the KMC will enable support for expanded coverage for non-human proteins of therapeutic interest and other associated human health data, in order to catalyze novel biomedical discoveries. To support the overall IDG objective, and to maintain, update and improve these integrated resources, the KMC draws upon expertise from multiple knowledge domains, specifically biology, chemistry and medicine, as well as computer science, graphic design and web programming. Specifically, for the Phase 2 of the IDG KMC we propose 4 Aims:1. Create an automated workflow that captures relevant public data for the entire proteome and manual annotations for the IDG list. The KMC knowledge management system will be built around knowledge graphs, focused on five major branches of the target knowledge tree, tkt: Genotype, Phenotype, Expression, Structure & Function, and Interactions & Pathways, respectively. Aim 2: Design, develop and implement a protein knowledgebase with Data Analytics support. Our protein-centric biomedical knowledge base, TCKB (Target Central Knowledgebase) will be comprised of the data, knowledge and information container, together with its codebase and software pipelines. TCKB will be the repository for experimental, processed and computed data and reagents originating from the IDG DRGCs (Data and Resource Generation Centers). We will provide informatics and modeling support for DRGC activities. Aim 3: We will expand, improve and maintain Pharos. Particularly “knowledge packages,” support automated data summaries for Protein Dossiers, and actively seek feedback from our community. Aim 4. Outreach to scientific community. We will support a series of activities that will leverage TCKB, Pharos and other IDG resources to increase adoption of IDG work, while observing FAIR (findable, accessible, interoperable, reusable) principles for our knowledgebase, portal and pipelines. The KMC will engage in community outreach by leading tutorials and feedback sessions and dissemination of the Pharos system. To meet its goals, the KMC will coordinate all core activities in close coordination with the IDG Steering Committee and IDG Project Scientists (PS), and include members of the IDG Consortium (IDG- C), other NIH Common Fund programs, NIH Commons, as well as other initiatives. The Knowledge Management Center (KMC) for the Illuminating the Druggable Genome (IDG) program plans to aggregate, update and articulate protein-centric data, information and knowledge for the entire human proteome with emphasis on understudied proteins from the 3 families that are the focus of the IDG. The KMC long-term objective is to encourage and support biomedical research aimed at understudied proteins by providing an extensive resource of data, information, knowledge, methods and reagents for the entire human proteome, and to support the growing online community focused on understudied proteins.",Knowledge Management Center for Illuminating the Druggable Genome,10073482,U24CA224370,"['Address', 'Adoption', 'Alleles', 'Archives', 'Basic Science', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Chemistry', 'Communities', 'Community Outreach', 'Computer software', 'Coupled', 'Data', 'Data Analytics', 'Data Element', 'Data Set', 'Databases', 'Dependence', 'Disease', 'Documentation', 'FAIR principles', 'Family', 'Feedback', 'Funding', 'Future', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genome Components', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Human', 'Informatics', 'Information Resources Management', 'International', 'Internet', 'Knowledge', 'Knowledge Portal', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Mutation', 'Non-Human Protein', 'Ontology', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Process', 'Protein Isoforms', 'Proteins', 'Proteome', 'Public Domains', 'Publications', 'Reagent', 'Resources', 'Scientist', 'Series', 'Services', 'Source', 'Structure', 'System', 'TRD@ gene cluster', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Update', 'Work', 'analytical method', 'computer science', 'data ecosystem', 'data resource', 'design', 'disease classification', 'experience', 'gender difference', 'genome resource', 'health data', 'improved', 'interest', 'knowledge base', 'knowledge graph', 'member', 'novel', 'online community', 'outreach', 'programs', 'public repository', 'repository', 'therapeutic protein', 'tool', 'web site']",NCI,UNIVERSITY OF NEW MEXICO HEALTH SCIS CTR,U24,2021,1037175
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10224845,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2021,388750
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"xARA: ARA through Explainable AI In response to the NIH FOA OTA-19009 “Biomedical Translator: Development” we propose to build an Autonomous Relay Agent (ARA) that can characterize and rate the quality of information returned from multiple multiscale heterogeneous knowledge providers (KPs). Biomedical researchers develop a trust relationship with a knowledge provider (KP) through frequent and continued use. Over time a familiarity develops that drives their understanding and insight on 1) how to structure and invoke more effective queries, 2) the quality of the results they may expect in response to different query parameters and feature values, and 3) how to assess the relevancy of a specific query’s results. Although this information retrieval paradigm has served the research community moderately well in the past it is not scalable and the number, scope and complexity of KPs is increasing at a dramatic pace (1,613 molecular biology databases reported as of Jan. 2019). Within this ever changing information landscape, a biomedical researcher now has two choices -- either continue using the few KPs they have learned to trust but remain limited in the actionable information they will receive, or invest the time and accept the risk of using a range of new information resources with little or no familiarity and thus uncertain effectiveness. If researchers are to benefit from the vast array of NIH and industry sponsored information assets now available and expanding new information retrieval and quality assessment technologies will be required. We propose to build an Explanatory Autonomous Relay Agent (xARA) that can characterize query results by rating the quality of information returned from multi-scale heterogeneous KPs. The xARA will utilize multiple information retrieval and explainable Artificial Intelligence (xAI) strategies to perform queries across multiple heterogeneous KPs and rank their results by quality and relevancy while also identifying and explaining any inconsistencies among databases for the same query response. To deliver on this promise, we will utilize case-based reasoning and language models trained with biomedical data (i.e., BioBERT and custom annotation embeddings through Reactome and UniProt) permitting a new level of query profiling and assessment. Our strategies will permit 1) information gaps to be filled by testing alternative query patterns that produce different surface syntax yet possess semantically related and actionable concepts, 2) inconsistencies to be identified for a given query feature value, and 3) the identification and elimination or merging of semantically redundant query results via similarity metrics enriched by case-based reasoning strategies employed in the explainable AI (xAI) community to identify machine learning model behavior and performance. The xARA capabilities proposed herein will be based on strategies developed in Dr. Weber’s lab for information retrieval where the desire for greater transparency when reasoning over experimental data is our primary aim. Our multi-institutional team is comprised of senior researchers and software engineers formally trained and experienced in the computer and data sciences, cheminformatics, bioinformatics, molecular biology, and biochemistry. Inherent risks in querying heterogeneous KPs include the presence of inconsistent labeling of the same biomedical concept within unique KP data structures. Manual engineering may be necessary to overcome such hurdles, but will not be a significant challenge for the initial prototype, since only two well documented KPs are being evaluated. Another noteworthy risk is that the quality of word embeddings generated from UniProt and Reactome may not be sufficient, requiring further textual analysis of biomedical text like PubMed, which is feasible within the timeframe of our project plan. n/a",xARA: ARA through Explainable AI,10330631,OT2TR003448,"['Artificial Intelligence', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Communities', 'Custom', 'Data', 'Data Science', 'Databases', 'Development', 'Effectiveness', 'Engineering', 'Familiarity', 'Industry', 'Information Resources', 'Information Retrieval', 'Knowledge', 'Label', 'Language', 'Machine Learning', 'Manuals', 'Modeling', 'Molecular Biology', 'Pattern', 'Performance', 'Provider', 'PubMed', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Software Engineering', 'Structure', 'Surface', 'Technology Assessment', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'base', 'case-based', 'cheminformatics', 'computer science', 'experience', 'insight', 'prototype', 'response', 'syntax']",NCATS,TUFTS MEDICAL CENTER,OT2,2021,736476
"Knowledge-Based Biomedical Data Science Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. Building on decades of work in biomedical ontology development, and exploiting the architectures supporting the Semantic Web, we have demonstrated methods that allow effective querying spanning any combination of data sources in purely biological terms, without the queries having to reflect anything about the structure or distribution of information among any of the sources. These methods are also capable of representing apparently conflicting information in a logically consistent manner, and tracking the provenance of all assertions in the knowledge-base. Perhaps the most important feature of these methods is that they scale to potentially include nearly all knowledge of molecular biology.  We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data. To test this hypothesis, we propose to address the following specific aims:  1. Identify representative and significant analytical needs in knowledge-based data science, and  refine and extend our knowledge-base to address those needs in three distinct domains: clinical  pharmacology, cardiovascular disease and rare genetic disease.  2. Develop novel and implement existing symbolic, statistical, network-based, machine learning  and hybrid approaches to goal-driven inference from very large knowledge-bases. Create a goal-  directed framework for selecting and combining these inference methods to address particular  analytical problems.  3. Overcome barriers to broad external adoption of developed methods by analyzing their  computational complexity, optimizing performance of knowledge-based querying and inference,  developing simplified, biology-focused query languages, lightweight packaging of knowledge  resources and systems, and addressing issues of licensing and data redistribution. Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data.",Knowledge-Based Biomedical Data Science,10197219,R01LM008111,"['Address', 'Adoption', 'Architecture', 'Area', 'Artificial Intelligence', 'Biological', 'Biology', 'Biomedical Research', 'Cardiovascular Diseases', 'Clinical Data', 'Clinical Pharmacology', 'Collaborations', 'Communities', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Duchenne muscular dystrophy', 'Fruit', 'Funding', 'Genomics', 'Goals', 'Heart failure', 'Hybrids', 'Information Distribution', 'Information Resources', 'Knowledge', 'Language', 'Licensing', 'Literature', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Network-based', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Publishing', 'Role', 'Semantics', 'Serum', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'biomedical data science', 'biomedical ontology', 'cohort', 'computer based Semantic Analysis', 'design and construction', 'health data', 'innovation', 'knowledge base', 'large scale data', 'light weight', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'online resource', 'ontology development', 'rare genetic disorder', 'tool', 'transcriptomics']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2021,506502
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),10145009,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2021,1210147
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,10149399,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,313018
"Unified Computation Tools for Natural Products Research Summary The overarching goal for this proposed renewal application will be to further advance tools that are in development and to effectively integrate several types of analytical data with biological assay data and genomic information. This will create a powerful set of tools for faster and even more accurate identification of new molecules, dereplication of known ones, and to directly infer biological activities from spectroscopic information. In the current period of support, we have made substantial progress in developing highly useful tools for automatic annotations and identifications of organic molecules, specifically focused on natural products. The Global Natural Products Social (GNPS) Molecular Networking analysis and knowledge dissemination ecosystem has processed almost 160,000 jobs in nearly 160 countries worldwide, has 4-6,000 new job submissions per month and is accessed over 200,000 times a month (majority accessions are for reference library access, inspection of public data and previous jobs that the community shares as hyperlinks in papers), and has become a mainstream tool for the annotation of organic molecules deriving from diverse sources, especially in metabolomics workflows. The public website for Small Molecule Accurate Recognition Technology (SMART), a deep learning model for providing candidate structures based on 1H-13C HSQC NMR data, went live in December 2019 and already has over 3000 jobs in 50 countries. All tools developed in this proposal will become part of this analysis ecosystem. The four laboratories contributing to this proposed research activity have created an open and integrated team that is continuing to creatively innovate new informatic tools to enhance small molecule structure annotations and inference of their chemical and biological properties. We have four specific aims: 1) To complete the development and evaluation of a set of new and innovative tools for natural products analysis, and deploy these as freely available resources for the worldwide community. 2) To refine the structural characterization of molecules through leveraging repository scale mass spectral information along with NMR data and genomic inputs. 3) To create a new SMART-based tool that integrates mass spectrometry and HSQC NMR data as the input for a new deep learning system with the goal of achieving more accurate predictions of structure. 4) To use deep learning to enhance SMART with bioactivity data so as to enable SMART to predict activities of molecules based on spectroscopic features. The data will also augment the GNPS database with biological assay binding data. An additional consequence of these goals will be the further digitization of natural products analytical data so that they can be used in the computational tools planned herein, as well as other tools in the future. Completion of these four specific aims will create new integrated tools for the precise identification of new natural product structures, and enable inference of their structural relatedness to other classes of organic molecules and their biological properties. Thus, these new informatic tools will have the potential to greatly enhance the small molecule drug discovery process.         Unified Computational Tools for Natural Products Research Approximately 50% of all FDA approved drugs trace their origins to natural products, either directly or through indirect routes of development. To accelerate and make more efficient the study of natural products, we are developing innovative computational tools for the rapid annotation of natural product structures and their associated chemical and biological properties.",Unified Computation Tools for Natural Products Research,10211176,R01GM107550,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Chemicals', 'Classification', 'Communities', 'Country', 'Cyanobacterium', 'Data', 'Data Analytics', 'Databases', 'Development', 'Ecosystem', 'Evaluation', 'FDA approved', 'Future', 'Genomics', 'Goals', 'Grant', 'Knowledge', 'Laboratories', 'Legal patent', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Natural Products', 'Noise', 'Nuclear Magnetic Resonance', 'Occupations', 'Organism', 'Paper', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Property', 'Publications', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Route', 'Source', 'Spectrometry', 'Structure', 'Students', 'System', 'Technology', 'Time', 'annotation  system', 'base', 'computerized tools', 'deep learning', 'drug discovery', 'genome sequencing', 'genomic data', 'informatics tool', 'innovation', 'marine natural product', 'metabolomics', 'quantum', 'repository', 'small molecule', 'social', 'tool', 'web site']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,547104
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227
"CSHL Network Biology Conference PROJECT SUMMARY This proposal seeks support for the conference on Network Biology, to take place March/April 2021 to 2025, at the Cold Spring Harbor Laboratory (CSHL). This meeting, held in biannual rotation on the CSHL campus in New York, brings together senior and junior scientists from both experimental and computational laboratories with common interests in network biology. The meeting will emphasize new discoveries and provide an open forum for the presentation of the latest research and results on molecular networks and their relevance to normal and abnormal cellular physiology. It will be essential for advancing knowledge in all aspects of the network modeling process, from data generation in experimental cell biology to data analysis and computer simulation and from the development and validation of network models describing these data to biological inferences made from the models. The conference will include platform sessions on interaction networks, signaling and network dynamics, regulatory networks, computational tools, artificial intelligence and big data, multi-scale networks, networks and disease, networks in differentiation, microbiome networks, network evolution, synthetic networks, network engineering and networks beyond biology though the exact program for the meeting will be assembled after the abstract submission deadline in February 2021 and adapted to ongoing developments in the field in subsequent years. This conference will include significant components designed to facilitate the active participation of younger scientists such as selection of platform speakers on the basis of the scientific merit of their submitted abstracts as well as poster presentations, round tables, lightning talks and poster prizes. Distinguished speakers will also be invited to give platform talks and interact with more junior scientists. The intimate environment at CSHL fosters social interactions and active participation by all. The majority of participants to the previous CSHL Network Biology meeting expressed that they were “very satisfied”. Speakers' panels have consisted of at least 50% women; the gender balance will be maintained in future meetings. In the 2019 iteration of the meeting, a panel discussion was established to address the challenges of Women in Network Science. We will continue to address big community challenges though panel discussions in this meeting. In 2021, we will discuss Applicability and Translatability of Network Biology with panelists including network biologists whose work is deeply influential throughout the ongoing covid-19 pandemic. PROJECT NARRATIVE Biological systems are functionally and structurally formed by complex networks of interacting molecular components, many of which are encoded in the genome. Elucidating the structure and function of these networks and understanding how their dysregulation causes disease are critical steps toward improving human health. This application seeks support for the conference on Network Biology to be held every two years in March/April 2021-25 at the Cold Spring Harbor Laboratory, to bring together experimental and computational biologists and discuss emerging trends and latest results in the field.",CSHL Network Biology Conference,10137390,R13HG011550,"['Address', 'Animals', 'Artificial Intelligence', 'Attention', 'Awareness', 'Big Data', 'Biochemistry', 'Biological', 'Biological Process', 'Biology', 'COVID-19 pandemic', 'Cell physiology', 'Cellular biology', 'Chalk', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Discipline', 'Disease', 'Engineering', 'Ensure', 'Environment', 'Equilibrium', 'Event', 'Evolution', 'Faculty', 'Fostering', 'Future', 'Gender', 'Gene Proteins', 'Generations', 'Genetic', 'Genome', 'Geography', 'Health', 'Human', 'Industrialization', 'Influentials', 'International', 'Intervention', 'Knowledge', 'Laboratories', 'Length of Stay', 'Lightning', 'Methodology', 'Microbe', 'Modeling', 'Molecular', 'Nationalities', 'New York', 'Normal Cell', 'Organism', 'Participant', 'Plants', 'Postdoctoral Fellow', 'Prize', 'Process', 'Property', 'Published Comment', 'RNA', 'Reagent', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Rotation', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Structure', 'Technology', 'Validation', 'Woman', 'Work', 'base', 'biological systems', 'career', 'computer science', 'computerized tools', 'data exchange', 'data reuse', 'design', 'graduate student', 'host-microbe interactions', 'improved', 'innovation', 'interdisciplinary collaboration', 'interest', 'meetings', 'microbiome', 'multidisciplinary', 'network models', 'posters', 'precision medicine', 'programs', 'senior faculty', 'social', 'symposium', 'trend', 'unpublished works']",NHGRI,COLD SPRING HARBOR LABORATORY,R13,2021,3000
"Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer Project Summary In 2010, Pittsburgh Supercomputing Center (PSC) and D.E. Shaw Research (DESRES) partnered to make the Anton special-purpose molecular dynamics (MD) supercomputer available to the national biomedical research community for the first time. Anton enabled researchers to simulate biomolecular systems two orders of magnitude faster than any conventional supercomputer, allowing researchers access to critical multi- microsecond and longer timescales on which most biologically-significant molecular processes take place. In 2016, with operational support from NIH, DESRES made available a next generation Anton 2 system at PSC at no cost. This multimillion-dollar gift from DESRES, with NIH support, provided a unique opportunity for researchers to tackle even more groundbreaking biological questions by simulating systems as large as 700,000 atoms at a rate of multiple microseconds per day. The goal of this renewal project is to provide the national biomedical research community with continued access to this unique and powerful Anton 2 resource and to maximize the benefit of this resource to the community. Since 2010, PSC has supported 589 research projects conducted by 202 unique PIs on the Anton systems hosted at PSC. So far, these projects have resulted in 292 publications, many of which have had significant impact on their fields of research. These fields cover the entire spectrum of biomolecular processes that form the fundamental underpinnings of biology, including protein folding, ion channel selectivity and gating, membrane dynamics and organization, protein- ligand binding, and many others. Demand for Anton 2 is quite high, with 2-3x higher demand than can be met each year. Given this, our goals are focused not only on providing continued access but also on maximizing the value of this limited resource to the community—recognizing that the creativity of the broad, diverse Anton 2 research community is one of our most powerful resources for innovation. Anton 2 will be integrated as an XSEDE service provider, and the accessibility and impact of Anton 2 will significantly increase by engaging in their extensive broadening participation, outreach, and training programs. Through these outreach efforts, researchers at many more institutions will have the opportunity to use Anton 2, especially researchers from traditionally underrepresented groups in biomedical research. The hundreds of long-timescale MD trajectories researchers generate on Anton 2 constitute a unique and valuable dataset that can be used to gain additional biomedical knowledge and advance the application of machine learning protocols to augment molecular dynamics simulations. This important dataset will be available to researchers and educators worldwide through a web portal and co-located on the PSC's Bridges-2 system for classroom instruction and research, including reanalysis, machine learning, and data mining. Project Narrative The Anton 2 supercomputer made available at Pittsburgh Supercomputing Center through this award will enable researchers to simulate biomolecular systems orders of magnitude faster than any conventional supercomputer. This powerful resource will enable biomedical researchers to better understand the fundamental biomolecular processes of biology, leading to better ways to treat disease and improve quality of life.",Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer,10211715,R01GM116961,"['Academy', 'Area', 'Award', 'Awareness', 'Binding Proteins', 'Biological', 'Biology', 'Biomedical Research', 'Collaborations', 'Communities', 'Community Health Education', 'Creativeness', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Disease', 'Evaluation Reports', 'FAIR principles', 'Funding', 'Gifts', 'Goals', 'Grant', 'Institution', 'Instruction', 'Ion Channel', 'Knowledge', 'Letters', 'Machine Learning', 'Membrane', 'Molecular', 'National Research Council', 'Process', 'Protocols documentation', 'Publications', 'Quality of life', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Running', 'Science', 'Secure', 'Supercomputing', 'System', 'Time', 'Training Programs', 'Underrepresented Populations', 'United States National Academy of Sciences', 'United States National Institutes of Health', 'Work', 'anxious', 'archive data', 'archived data', 'base', 'broadening participation research', 'computing resources', 'cost', 'data management', 'data mining', 'data sharing', 'improved', 'innovation', 'molecular dynamics', 'next generation', 'outreach', 'outreach program', 'price lists', 'protein folding', 'service providers', 'supercomputer', 'uptake', 'web portal']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,408856
