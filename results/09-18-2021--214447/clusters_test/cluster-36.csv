text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"COVID-19 detection through scent analysis with a compact GC device Recent studies, including ours, have suggested that breath may allow us to diagnose COVID-19 infection and even monitor its progress. As compared to immunological and genetic based methods using sample media like blood, nasopharyngeal swab, and saliva, breath analysis is non-invasive, simple, safe, and inexpensive; it allows a nearly infinite amount of sample volume and can be used at the point-of-care for rapid detection. Fundamentally, breath also provides critical metabolomics information regarding how human body responds to virus infection and medical intervention (such as drug treatment and mechanical ventilation). The objectives of the proposed SCENT project are: (1) to refine automated, portable, high-performance micro-gas chromatography (GC) device and related data analysis / biomarker identification algorithms for rapid (5-6 minutes), in-situ, and sensitive (down to ppt) breath analysis and (2) to conduct breath analysis on up to 760 patients, and identify and validate the COVID-19 biomarkers in breath. Thus, in coordination with the RADx-rad Data Coordination Center (DCC), we will complete the following specific aims. (1) Refine 5 automated micro-GC devices to achieve higher speed and better separation capability. We will construct 5 new automated and portable one-dimensional micro-GC devices that require only ~6 minutes of assay time (improved from current 20 minutes) at the ppt level sensitivity (Sub-Aim 1a). Then the devices will be upgraded to 2-dimensional micro-GC to significantly increase the separation capability (Sub-Aim 1b). In the meantime, we will optimize and automate our existing data processing and biomarker identification algorithms and codes to streamline the workflow so that the GC device can automatically process and analyze the data without human intervention (Sub-Aim 1c). (2) Identify breath biomarkers that distinguish COVID-19 positive (symptomatic and asymptomatic) and negative patients. We will recruit a training cohort of 380 participants, including 190 COVID-19 positive patients (95 symptomatic and 95 asymptomatic) and 190 COVID-19 negative patients from two hospitals (Michigan Medicine – Ann Arbor and the Henry Ford Hospital – Detroit). We will conduct breath analysis using machine learning to identify VOC patterns that match each COVID-19 diagnostic status. (3) Validate the COVID-19 biomarkers using our refined micro-GC devices. Using the refined 2-D micro-GC devices from Sub-Aim 1b, we will recruit a new validation cohort of 380 participants (190 COVID-19 positive patients and 190 COVID-19 negative patients) to validate the biomarkers identified in Aim 2.  We will leverage existing engineering, data science, clinical, regulatory, and commercialization resources throughout the project to hit our milestones, ensuring a high likelihood of rapid patient impact. Upon completion of this work, we will have a portable micro-GC device and accompanying automated algorithms that can detect and monitor COVID-19 status for people in a variety of clinical and community settings. Narrative  Our team of engineers, clinicians, and data scientists has developed a portable, high performance breath analyzer that can be used to detect certain diseases. In this project, we will adapt and refine our existing device and algorithms so they can be used for rapid, safe, and non- invasive COVID-19 detection. People will simply breath into the device and it will quickly provide results, meaning that it can be used in a variety of everyday settings to help fight against the COVID-19 pandemic.",COVID-19 detection through scent analysis with a compact GC device,10266206,U18TR003812,"['Acute', 'Agreement', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Biotechnology', 'Blood', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 monitoring', 'COVID-19 pandemic', 'COVID-19 patient', 'Cessation of life', 'Clinical', 'Code', 'Critical Care', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Scientist', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Ensure', 'Gas Chromatography', 'Genetic', 'Health', 'Hospitals', 'Human', 'Human body', 'Immunologics', 'In Situ', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Licensing', 'Machine Learning', 'Mechanical ventilation', 'Medical', 'Medicine', 'Methods', 'Michigan', 'Monitor', 'Participant', 'Patients', 'Pattern', 'Performance', 'Pharmacotherapy', 'Process', 'Production', 'RADx Radical', 'Research', 'Resources', 'Respiratory Failure', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Saliva', 'Sampling', 'Savings', 'Services', 'Severities', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Virus Diseases', 'Work', 'automated algorithm', 'base', 'biomarker identification', 'cohort', 'commercialization', 'community setting', 'computerized data processing', 'cost', 'design', 'fight against', 'fighting', 'global health', 'improved', 'metabolomics', 'multidisciplinary', 'nasopharyngeal swab', 'outcome forecast', 'pandemic disease', 'point of care', 'portability', 'rapid detection', 'recruit', 'respiratory hypoxia', 'screening', 'severe COVID-19', 'two-dimensional']",NCATS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U18,2021,999775
"Augmented Reality Platform for Telehealth Rehabilitiation Efforts to keep the most vulnerable individuals with chronic medical conditions from being exposed to COVID- 19 have triggered an unprecedented decline in the number of visits to ambulatory practices. The repercussions have impacted not only those with the disease, but the many millions of older persons in need of healthcare who forego in-person visits in fear of infection or for socioeconomic reasons. While the precipitating need for alternative healthcare delivery methods has hastened the adoption of software solutions, such as Zoom, traditional videoconferencing services fail to compensate for the lack of direct physical evaluations with a patient that is needed for evaluating musculoskeletal (MSK) deficits, planning therapeutic interventions, and guiding exercise compliance—essential components of evidence-based practice among rehabilitation practitioners. To overcome these shortcomings, our team of computer vision and human movement engineers is partnering with orthopedic rehabilitation specialists at Massachusetts General Hospital (MGH) to develop a telehealth platform that fuses high resolution RGB and Depth (RGD-D) video data readily obtainable from a modern smartphone to facilitate quantitative, MSK assessment. The innovation builds upon our work in computing movement outcome measures from vision-based body tracking algorithms, and our skills in augmented reality (AR) software development to enhance a clinician’s assessment and exercise instruction capabilities. Our pilot data demonstrate that accurate quantitative rehabilitation outcomes are obtainable using RGB-D body tracking algorithms during a sub-set of knee activities. Phase I will advance these capabilities by deriving and validating the accuracy of 3D body tracking and rehabilitation outcome measures during a wider set of activities used clinically for assessing knee mobility, alignment, posture, balance, strength, and function from depth enabled smartphone video recordings in control subjects (Aim 1). Aim 2 will develop a proof-of-concept AR telehealth platform with the help of the MGH team that delivers an enhanced telehealth experience through real-time synchronized audio-visual processing, real-time display of quantitative rehabilitation outcomes for the therapist to assess deficits or guide exercise compliance, and instructional animations for the patient to safely carry out the rehabilitation activities. The proof-of-concept prototype will undergo feasibility testing in Aim 3 among n=5 physical therapists and n=10 patients with knee OA during a simulated telehealth session to achieve high ratings for usability, accessibility, and effectiveness. The results will inform the user-requirements of a more complete Phase II telehealth platform designed in close collaboration with industry partners to provide secure cloud based communication for seamless interoperability between devices; additional examination tools (e.g. gait analysis); a broader range of baseline assessment and therapeutic exercise protocols for additional MSK conditions; and HIPAA-compliant deployment and electronic documentation management. The final prototype system will be evaluated during actual telehealth visits at multiple clinical sites to promote safe and effective clinical care. PROJECT NARRATIVE With the onset of the COVID-19 pandemic, clinical care has by necessity shifted towards telehealth delivery for people at risk due to age, who live in underserved communities or avoid in-person visits out of fear of viral transmission. Existing telehealth software platforms are generally supportive of videoconferencing but have yet to provide rehabilitation professionals with quantitative outcomes typically obtained from direct physical evaluations with a patient. To overcome this shortcoming, we are developing an augmented reality platform that fuses RGB and depth imaging from a patient’s smartphone to deliver quantitative outcomes of knee joint mobility, alignment, posture, balance, strength and function during a telehealth visit to support the mandate for more effective remote delivery of evidence-based rehabilitation during the global pandemics and beyond.",Augmented Reality Platform for Telehealth Rehabilitiation,10256844,R43AG072991,"['3-Dimensional', 'Adoption', 'Age', 'Algorithms', 'Architecture', 'Augmented Reality', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Cellular Phone', 'Chronic', 'Clinical', 'Collaborations', 'Communication', 'Computer Vision Systems', 'Computer software', 'Data', 'Devices', 'Disease', 'Documentation', 'Effectiveness', 'Elderly', 'Engineering', 'Ensure', 'Evaluation', 'Evidence based practice', 'Exercise', 'Exposure to', 'Feasibility Studies', 'Feedback', 'Focus Groups', 'Fright', 'General Hospitals', 'Goals', 'Gold', 'Health', 'Health Care Visit', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Image', 'Individual', 'Infection', 'Instruction', 'Intuition', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modality', 'Modernization', 'Motion', 'Movement', 'Musculoskeletal', 'Musculoskeletal Diseases', 'Musculoskeletal Equilibrium', 'Orthopedics', 'Outcome', 'Outcome Measure', 'Patient Self-Report', 'Patients', 'Persons', 'Phase', 'Physical Rehabilitation', 'Physical therapy', 'Protocols documentation', 'Quarantine', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Resolution', 'Risk', 'Secure', 'Services', 'Specialist', 'Supervision', 'System', 'Tablets', 'Technology', 'Testing', 'Therapeutic Intervention', 'Therapeutic exercise', 'Time', 'Validation', 'Video Recording', 'Videoconferencing', 'Virtual Tool', 'Vision', 'Visit', 'Visualization', 'Work', 'animation', 'base', 'clinical care', 'clinical practice', 'clinical research site', 'cloud based', 'design', 'evidence base', 'experience', 'feasibility testing', 'gait examination', 'health care delivery', 'industry partner', 'innovation', 'interoperability', 'joint mobilization', 'new technology', 'outpatient programs', 'pandemic disease', 'partial recovery', 'patient safety', 'physical therapist', 'prototype', 'remote delivery', 'skills', 'socioeconomics', 'software development', 'telehealth', 'tool', 'underserved community', 'usability', 'viral transmission', 'visual processing']",NIA,"ALTEC, INC.",R43,2021,286972
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10421230,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,138041
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000
"Novel Approaches to Advance Coordinated Registry Networks (CRNs). Project Summary The technological transformation of US health care with the explosion of new devices and iterative changes mandates the acquisition of real-world evidence (RWE) to study devices and technologies pragmatically. The US Food and Drug Administration (FDA) has spearheaded the RWE framework development in the pursuit of sufficient evidence that is required for regulatory decision-making such as device approvals and surveillance. With regulatory support since the launch of the National Medical Device Registry Task Force in 2015, the Medical Device Epidemiology Network (MDEpiNet) created 15 national and international coordinated registry networks (CRNs), which develop or link well-curated national RWE sources such as registries, administrative, and electronic health records (EHRs) data. The MDEpiNet is a key partner of the National Evaluation System of Technologies (NEST) coordinating center and is an international public-private partnership focusing on building global infrastructure and methodologies to advance the use of RWE for medical device evaluation. CRNs not only focus on prevention of harms but also the promotion of safer device innovation through the development of study designs that expedites patient recruitment at lower costs than traditional clinical research. MDEpiNet developed a maturity model for CRNs with various levels of achievements in seven key domains: 1) device identification, 2) quality improvement, 3) total product life-cycle, 4) data quality, 5) efficiency, 6) governance and sustainability, 7) patient engagement. This proposal focuses on the creation of innovative tools and methods necessary to achieve maturation of the networks through efficient curation of robust RWE. We will capitalize on established partnerships with registries, professional societies, integrated health systems, and many academic institutions to advance this critical national infrastructure as a foundational component of NEST. We will facilitate advancements of RWE through stakeholder roundtables, patient-facing mobile app development, and continued innovative methods development to link registries with Medicare, commercial, statewide, and EHR data to enable better research and surveillance for devices. Our specific aims facilitate stakeholder engagement for device-specific core minimum data development in women's health, prostate cancer, orthopedics, vascular disease, robot-assisted surgery, and temporomandibular joints. We will also advance and enrich linked data capacities in vascular disease, hernia repair, breast implant, prostate cancer, Women's Health, and gastrointestinal cancer CRNs. Finally, we conduct advanced analytics to determine gender disparities in device outcomes and use machine learning and active surveillance methods in hernia repair, orthopedics, stroke treatment, vascular disease, and Women's health CRNs. The CRN community of practice will enable centralized knowledge sharing to support cross-specialty and technology learning and applications. Through this, we advance the CRNs using innovative, scalable, and dynamic approaches and help them become foundational components of NEST. Narrative Medical Device Epidemiology Network will advance the research and surveillance capabilities of coordinated registry networks through stakeholder roundtables, patient-facing mobile app development, and linkages of real-world data sources. We will also conduct advanced analytics to determine gender disparities, use machine learning for risk predictions, and implement active surveillance for devices and technologies.",Novel Approaches to Advance Coordinated Registry Networks (CRNs).,10209943,U01FD006936,[' '],FDA,WEILL MEDICAL COLL OF CORNELL UNIV,U01,2021,50000
"Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods Implantable medical devices have revolutionized contemporary cardiovascular care, and are used in a wide spectrum of acute and chronic cardiovascular conditions. However, medical device design fault or incorrect use may lead to significant risk of patient injury and represents an important preventable public health risk in the United States. To help identify device-related safety issues, a strategy of active, prospective, post-market safety surveillance has been recommended by the FDA, and evaluated methodologically. This type of surveillance offers significant advantages over traditional adverse event reporting strategies. However, all such approaches are challenged by the need to incorporate learning effects into expectations regarding safety. These learning impacts been repeatedly shown to have dramatic impacts on outcomes during early device experience. Quantifying learning effects on the outcomes associated with high-risk cardiovascular devices will improve our understanding of intrinsic device performance, thereby identifying patient populations best treated with such devices while simultaneously providing necessary feedback to device manufacturers to support iterative improvement in device design. Separately, understanding the impacts of learning may identify opportunities for targeted training as well as help to tease apart institutional and operator characteristics that may accelerate the achievement of optimal outcomes in the use of the specific cardiovascular device.  This proposal seeks to extend the previously validated, open-source, active, prospective device safety surveillance tool, by developing and validating robust learning curve (LC) detection and quantification algorithms, designed to simultaneously account for the effects at the operator and institutional levels. We propose a “blinded” development strategy, in which one team will generate robust synthetic clinical data simulator with LC impacts, and the other team develops and applies LC detection and quantification algorithms, without knowledge of the underlying relationships, determine performance and accuracy through sequential refinement and validation steps. We propose to formally validate the optimized LC tools in real-world data through re-analysis of previously published LC effects on transcatheter valves and vascular closure devices using national cardiovascular registries. In addition, the LC tools will be incorporated into two active, prospective device safety surveillance studies of novel implantable cardiovascular devices using large clinical registries. This proposal seeks to understand the impact of institutional and physician learning on the safety of newly approved cardiovascular devices, and to use this knowledge to support and improve effective medical device safety surveillance. We propose a “blinded” strategy of separating simulated dataset generation from the learning effects detection and quantification algorithm development. Incorporating learning effects adjustment into a validated, prospective, near-real-time safety surveillance system, this research will improve public health by identifying poorer performing cardiovascular devices, and provide physicians, device manufacturers and public health officials with better information to optimize the use of medical devices, iteratively improve their design, and identify opportunities for enhanced training that will result in improved patient outcomes.",Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods,10088471,R01HL149948,"['Achievement', 'Acute', 'Address', 'Adverse event', 'Algorithm Design', 'Algorithms', 'Blinded', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Detection', 'Development', 'Device Designs', 'Device Safety', 'Devices', 'Early Diagnosis', 'Elements', 'Environment', 'Etiology', 'Evaluation', 'Event', 'Feedback', 'Generations', 'Implant', 'Injections', 'Injury', 'Institution', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Manufacturer Name', 'Medical Device', 'Medical Device Designs', 'Medical Device Safety', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Process', 'Provider', 'Public Health', 'Publishing', 'Registries', 'Reporting', 'Risk', 'Safety', 'Signal Transduction', 'Specific qualifier value', 'Statistical Models', 'Structure', 'Surveillance Methods', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'adverse outcome', 'algorithm development', 'cardiovascular risk factor', 'clinical heterogeneity', 'design', 'expectation', 'experience', 'high risk', 'implantable device', 'improved', 'novel', 'open source', 'patient population', 'post-market', 'prospective', 'safety outcomes', 'simulation', 'surveillance strategy', 'surveillance study', 'systems research', 'tool']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,768996
"BandPass: A Remote Monitoring System for Sarcopenia and Functional Decline ABSTRACT Clinical Need: As the US population ages, managing pathologies that largely affect older adults, including sarcopenia (e.g., loss of muscle mass and strength), represents a significant and growing clinical challenge. In addition to increased rates of sarcopenia with age, it is well-accepted that its incidence and impact increases after acute illness, placing persons at additional risk for functional decline, institutionalization, or death. Resistance-based exercises promote muscle regeneration and strength, and are an advised therapy for such patients. Yet, exercises are normally conducted either under direct clinical oversight, or unsupervised by patients at home, where compliance rates are low. Limitations: Current regimens rely on self-report diaries or verbal reports that may be inaccurate and subject to recall bias. Remote monitoring systems that measure, track, analyze, and provide patient-oriented feedback may overcome these limitations and enhance exercise regimen engagement. An at-home device that monitors and transmits exercise data to the user and clinician represents a potential solution to this clinical challenge. Our Product – BandPass is a remote-sensing, bluetooth-enabled resistance exercise band that will accurately gauge force through a potentiometric sensor rigidly fixed to elastic-tubing purposely designed for resistance training. The device is similar to currently available exercise bands familiar to clinicians and patients, with the significant novel addition of integrated force monitoring and internet-connectivity. A mobile app and cloud-based platform will provide computational resources for data visualization, storage and analysis, which will enable direct patient feedback, clinical monitoring of patient compliance and progress, and serve as a platform for more advanced operations such as automatic exercise-type classification to ease user burden (e.g., minimizing required interactions between the user and mobile device). We hypothesize that BandPass will provide clinically relevant data on compliance and use of exercise training with feedback that will be personalized. Specific Objectives: We specifically propose to design custom electronics and housing for BandPass and to perform in-lab validation studies of device accuracy, precision, and long-term stability. BandPass will be interfaced to a mobile app and cloud-based platform we will implement for data transmission, storage, and analysis. Finally, we will deploy BandPass in a human subjects pilot study to demonstrate usability and system stability in an at-home setting. Future Directions: SynchroHealth is a small company developing an mHealth platform that uses internet-connected devices to help improve quality of life in older adults. This device will complement our existing efforts. By the end of this Phase 1 effort, we will have demonstrated that BandPass is functional in a human population and we will have provided evidence that this approach can be deployed effectively in an at-home setting. This will position us for Phase 2 funding focused on optimizing our device for manufacturing, developing and optimizing a full suite of cloud-based analysis tools and mobile applications, conducting clinical trials aimed at demonstrating efficacy, and preparing to register this as a 510(k)-exempt device for marketing purposes and establishing Current Good Manufacturing Practices (CGMP). PROJECT NARRATIVE Clinical care for older adults that suffer from sarcopenia (e.g. loss of muscle mass and strength) typically involves the use of physical therapy regimens that rely on patients performing a series of at-home resistance-based exercises in order to retain or build muscle strength and prevent further atrophy. Resistance exercises using elastic bands has been a primary tool for clinicians, however remotely monitoring a patient’s compliance, confirming the quality of exercises performed, and tracking performance has been a significant challenge, with no tools currently available to provide this level of insight. Here, we propose to develop BandPass, an internet-enable resistance exercise band instrumented to automatically sense forces generated during exercise which will enable remote monitoring, compliance checking, and exercise classification and help to overcome the current shortcomings in clinical management of these patients.",BandPass: A Remote Monitoring System for Sarcopenia and Functional Decline,10152884,R41AG071290,"['Acute', 'Adult', 'Affect', 'Age', 'Algorithms', 'Android', 'Atrophic', 'Bluetooth', 'Boston', 'Businesses', 'Capital', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complement', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Devices', 'Disease', 'Drops', 'Elderly', 'Electronics', 'Equipment', 'Exercise', 'Faculty', 'Feedback', 'Funding', 'Future', 'Health', 'Home environment', 'Housing', 'Human', 'Incidence', 'Infrastructure', 'Injury', 'Inpatients', 'Institutionalization', 'Internet', 'Interview', 'Legal patent', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Monitor', 'Muscular Atrophy', 'Non-Invasive Cancer Detection', 'Orthopedics', 'Participant', 'Pathology', 'Patient Care', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Physical Function', 'Physical therapy', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Quality of life', 'Recovery', 'Regimen', 'Reporting', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Self-Help Devices', 'Series', 'Services', 'Small Business Technology Transfer Research', 'Students', 'Surveys', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Validation', 'Wireless Technology', 'acceptability and feasibility', 'age-related muscle loss', 'base', 'clinical care', 'clinical development', 'clinically relevant', 'cloud based', 'commercialization', 'compliance behavior', 'computerized data processing', 'computing resources', 'cost', 'data exchange', 'data visualization', 'design', 'diaries', 'exercise regimen', 'exercise training', 'functional decline', 'handheld mobile device', 'human subject', 'improved', 'insight', 'instrument', 'mHealth', 'meetings', 'mobile application', 'monitoring device', 'muscle form', 'muscle regeneration', 'muscle strength', 'novel', 'operation', 'patient oriented', 'prevent', 'remote monitoring', 'remote sensing', 'resistance exercise', 'sarcopenia', 'sensor', 'strength training', 'tool', 'transmission process', 'usability', 'validation studies']",NIA,SYNCHROHEALTH LLC,R41,2021,224700
"Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array PROJECT SUMMARY COVID-19 presents a public health emergency: There is a critical need for rapid, not reagent intensive, non- invasive testing technologies. This program will lead to the production of a prototype system to diagnose COVID-19 infection using the body odor signature of the disease. Our goal is to maximize societal impact by creating a validated prototype that can be used in a community or workplace setting by minimally trained personnel for low-cost, on-the-spot diagnosis within minutes. The system will be developed in a manner that puts it on a pathway for rapid FDA approval. The Research Aims are: Aim 1. Optimization, assembly, and integration of a prototype system with the ability to odor signature of COVID-19 in samples of body odor. The system will be simple to use, pose essentially zero risk to the operator and the test subject, and report a result within minutes. The production cost at scale will be approximately $9,000 for the complete measurement system, with a per test cost of approximately $0.50. The design and construction of the prototype will be conducted by Novo Engineering, a leading firm with extensive experience in medical device development. Aim 2. Software development. Software for the system from VOC sampling to final diagnostic result will be developed to ensure error-free operation of the device. Our preliminary results suggest that simple linear discriminant analysis (LDA) does an excellent job of classifying VOCs from human body odor as COVID-19 positive or negative (92% sensitivity and 87% specificity). Optimization of the sensor array (Aim 1) and use of richer feature sets in our classifier models will lead to further performance improvements in the prototype system. Aim 3. System Benchmarking and Validation. We will benchmark the full prototype system against a number of VOC mixtures, with and without in vitro skin models. The system will undergo extensive testing against body odor samples from individuals with pathological conditions other than COVID-19 and other sources of potentially confounding VOCs. The prototype will be validated against 1000 samples drawn from the COVID-SAFE program at Penn. The screening will include all members of the Penn community, and represents incredible racial and ethnic diversity as well as a wide variance in age, sex, and gender. Aim 4. Regulatory Approval Plan The plan will be developed under the direction of Sr/Key personnel John Fuson, JD, an attorney at Crowell & Moring LLP and a former Associate Chief Counsel at FDA. Novo Engineering has extensive experience in guiding prototype design in alignment with the requirements for FDA approval. The proposed COVID-19 VOC-based testing device will be regulated by the FDA, likely as a Class I or II medical device. Because there is no clear predicate device to reference in this case, we intend to submit a direct de novo petition to FDA asking the agency to categorize and clear the proposed COVID-19 testing device as Class I or Class II without reference to any predicate. PROJECT NARRATIVE This program addresses the critical unmet need of an effective means to screen for COVID-19 infection, and potentially other novel virus infections, in a community setting based upon the body odor signature of the disease. The program will result in a validated prototype system, with a test time of minutes, a test cost of approximately $0.50, on a path to rapid FDA approval.","Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array",10266403,U18TR003775,"['Address', 'Age', 'Astronomy', 'Benchmarking', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 screening', 'COVID-19 testing', 'Carbon Nanotubes', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Chemicals', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Counseling', 'DNA', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Discriminant Analysis', 'Disease', 'Engineering', 'Ensure', 'Florida', 'Future', 'Gender', 'Goals', 'Gold', 'Hand', 'Health', 'Housekeeping', 'Human', 'Human Resources', 'Human body', 'In Vitro', 'Individual', 'Information Sciences', 'International', 'Intuition', 'Laboratories', 'Lawyers', 'Mass Fragmentography', 'Measurement', 'Mechanics', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Nose', 'Occupations', 'Odors', 'Participant', 'Pathologic', 'Pathway interactions', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phase', 'Physics', 'Production', 'RADx', 'Reagent', 'Reporting', 'Research', 'Risk', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Sampling', 'Skin', 'Software Engineering', 'Solid', 'Source', 'Specificity', 'Spottings', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Viral', 'Virus Diseases', 'Visual', 'Workplace', 'animal care', 'artificial neural network', 'base', 'community setting', 'coronavirus disease', 'cost', 'design', 'design and construction', 'ethnic diversity', 'experience', 'high standard', 'machine learning algorithm', 'medical schools', 'member', 'multidisciplinary', 'nano', 'nanosensors', 'next generation', 'novel virus', 'operation', 'prevent', 'programs', 'prototype', 'public health emergency', 'racial diversity', 'sample collection', 'screening', 'screening program', 'sensor', 'sex', 'software development', 'software systems', 'vapor', 'volatile organic compound']",NCATS,UNIVERSITY OF PENNSYLVANIA,U18,2021,999830
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery Project Summary I am an assistant professor in the department of Otolaryngology-Head and Neck Surgery at the Johns Hopkins School of Medicine, where my practice is focused on neurotology and lateral skull base surgery. I am applying for a mentored surgeon-scientist career development award (CDA) to obtain further training in robotics, deep learning and computer vision. This will further my long-term career goals of improving neurotologic surgical outcomes through novel applications of engineering methods and ultimately to investigate semi-autonomous, robotic interventions in the inner ear and skull base which are beyond the limits of the human hand alone.  Operating in the temporal bone and lateral skull base is technically demanding due to complex three- dimensional anatomy, small working spaces and delicate neurovascular structures. Many of these challenges are ideally suited to semi-autonomous surgical platforms to augment a surgeon’s skills with robotic and image- guided assistance. Despite the widespread implementation of robotic surgery and image guidance in other areas of the body, the field of neurotology has had relatively little adoption of this technology. We believe one reason for this is the precise registration needed in this field, where millimeter differences differentiate a successful from a catastrophic result. This CDA proposes expanding on my prior work investigating cooperative control robotics and virtual safety barriers by using computer vision and deep learning networks to develop highly accurate surgical image registration. This CDA aims to provide me with multi-disciplinary training in the departments of Otolaryngology, Biomedical Engineering and Computer Science. Specific training goals include: (1) Training in robotics, statistical shape modeling and computer tomography landmark segmentation, (2) Training in deep learning networks and computer vision video image registration, (3) Integrating this training, with my knowledge of temporal bone and skull base surgery to develop into an independent investigator (4) Pursue additional training in the ethical and responsible conduct of research.  The research plan addresses the hypothesis that virtual safety barriers can be accurately enforced by a cooperative control robot, and computer vision methods can be used to automate accurate placement and registration of these safety barriers. I believe that the integration of these techniques will allow for semi- autonomous surgical methods resulting in improved surgical safety and efficiency. The specific aims of the proposal are to: (1) Develop and Validate Cooperative Control Robot Enforced Virtual Safety Barriers for Cortical Mastoidectomy (2) Develop and Test Autonomous Segmentation of Lateral Skull Base Anatomy (3) Develop Video-Based, Fiducial-less, Surgical Image Registration to Detect and Update the 3-D Position of Temporal Bone Anatomy from Intraoperative Stereoscopic Microscope Video. Project Narrative The research proposed here will investigate the feasibility of using novel applications of computer vision and cooperative control robotics to enforce virtual safety barriers in neurotologic surgery. Our long-term goal is to develop semi-autonomous, robotic methods to improve the safety and efficiency of neurotologic surgery, and open the possibilities for surgical interventions which currently are beyond the abilities of the human hand alone.",Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery,10283480,K08DC019708,"['3-Dimensional', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Automobiles', 'Biomedical Engineering', 'Cadaver', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Consumption', 'Data', 'Drug Delivery Systems', 'Dura Mater', 'Electromagnetics', 'Engineering', 'Equilibrium', 'Ethics', 'Facial nerve structure', 'Feedback', 'Future', 'Goals', 'Hand', 'Head and Neck Surgery', 'Hearing', 'Human', 'Image', 'Image-Guided Surgery', 'Intervention', 'Judgment', 'K-Series Research Career Programs', 'Knowledge', 'Labyrinth', 'Lateral', 'Left', 'Manuals', 'Mentors', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Otolaryngology', 'Outcome', 'Patients', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Safety', 'Scientist', 'Shapes', 'Sigmoid colon', 'Site', 'Speed', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'Surgical complication', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporal bone structure', 'Testing', 'Time', 'Training', 'Tremor', 'Update', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'career', 'computer science', 'deep learning', 'digital', 'digital imaging', 'image guided', 'image registration', 'improved', 'instrument', 'learning network', 'medical schools', 'microscopic imaging', 'millimeter', 'multidisciplinary', 'neurovascular', 'novel', 'professor', 'responsible research conduct', 'robot control', 'simulation', 'skills', 'skull base', 'stereoscopic', 'success', 'surgery outcome', 'three-dimensional modeling', 'virtual', 'vision development']",NIDCD,JOHNS HOPKINS UNIVERSITY,K08,2021,191792
"Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors ABSTRACT Aura is a digital health platform that uses Epilog™, a miniature, wireless, wearable EEG sensor worn on the scalp below hairline that can record clinical and subclinical seizures. After an initial diagnosis of epilepsy, an epileptologist will use known information about patients’ seizures to guide the best scalp location to place the Epilog EEG sensor (A). EEG data is continuously transferred (B) to the Aura app on a person’s smartphone (C) using secure BluetoothTM where it communicates over WiFi (D) to the Aura cloud platform (E). Epilog EEG is analyzed for seizures and a daily digital seizure diary is shared with epileptologists (F) and pushed back to the Aura app (G). Epilog is recharged daily, and reusable for a year. Epilog is designed to be discreet, allowing for continuous use in all facets of daily life. Data are a 10 s snippet of the beginning of a focal seizure with motor impairment and intact awareness (ILAE 1A1) recorded from Epitel’s single-channel Epilog sensor placed on the left forehead. The patient was admitted for video-EEG monitoring as standard-of-care. This seizure was verified independently by three epileptologists. In Phase I, automated, machine learning-based seizure detection algorithms will be designed to first work in the Aura cloud to detect seizures in Epilog EEG, including seizures a person may not consciously know they are having (>50% of all seizures), such as while sleeping. Aura will run these algorithms developed exclusively for Epilog’s single-channel of EEG to provide a daily digital seizure diary. In Phase II, the Aura system will enter clinical validation trials for FDA clearance as an EEG-based automated home seizure detection and alerting system. Early in Phase II Aura will be commercialized as a medical device-enabled-service business model. Out-of-pocket costs for a person living with epilepsy is an average of $380/year. Armed with long-term, reproducible EEG, epileptologists will now have a more precise, quantitative record of seizure counts, enabling them to adapt patient treatment more rapidly and successfully to improve quality of life. Aura will give people living with epilepsy their lives back. Aura provides certainty where you are and when you need it. Throughout Phase II, physiological, psychological, behavioral, and environmental factors will be combined in the Aura app to collect 27,000 days of multi-modal data from 300 patients to create an unprecedented dataset of features known to precipitate seizures. These data will be used in Phase III to create a robust, wearable seizure forecasting system using artificial intelligence that combines multi-modal seizure precipitating factors, creating an hourly seizure probability. Aura will profoundly disrupt how epilepsy is managed and improve the quality of life of people living with epilepsy. This grant proposal aims to create a digital health platform that includes a wearable medical device worn on the scalp below the hairline. The system detects and counts seizures, and alerts to seizures in real time. The goal is to empower people with epilepsy to take control of their seizure monitoring and help improve the treatment of epilepsy.",Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors,10200346,U44NS121562,"['Adoption', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Auras', 'Awareness', 'Back', 'Behavioral', 'Bluetooth', 'Businesses', 'Cellular Phone', 'Clinical', 'Community Hospitals', 'Consumption', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Emergency Medicine', 'Environment', 'Environmental Risk Factor', 'Epilepsy', 'Event', 'Family', 'Financial Hardship', 'Focal Seizure', 'Forehead', 'Freedom', 'Goals', 'Gold', 'Home environment', 'Hospitals', 'Hour', 'Left', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Paper', 'Patient Self-Report', 'Patients', 'Periodicity', 'Persons', 'Phase', 'Physiological', 'Precipitating Factors', 'Predisposition', 'Probability', 'Process', 'Quality of life', 'Reproducibility', 'Running', 'Scalp structure', 'Screening procedure', 'Secure', 'Seizures', 'Services', 'Sleep', 'Subclinical Seizures', 'System', 'Time', 'Validation', 'Wireless Technology', 'Work', 'base', 'cloud platform', 'cost', 'design', 'diaries', 'digital', 'digital health', 'effective therapy', 'encryption', 'improved', 'machine learning algorithm', 'motor impairment', 'multimodal data', 'multimodality', 'optimal treatments', 'programs', 'psychologic', 'remote monitoring', 'sensor', 'social', 'standard of care']",NINDS,"EPITEL, INC.",U44,2021,999853
"Portable GC detector for breath-based COVID diagnostics Project Summary/Abstract: This proposal has two major goals: 1) Define signature exhaled breath volatile organic compounds (VOCs) to diagnose SARS-CoV-2 infections, and 2) Develop a portable chemical sensing device that can capture and detect exhaled VOCs and includes machine learning algorithms for automated data processing and results interpretation. This project will bring a portable sensor forward into clinical use with the aim of supplementing COVID-19 diagnostics with a reagentless alternative. Breath testing of exhaled VOC biomarkers is a relatively new concept that has the potential to transform healthcare in the US and globally. Our overarching hypothesis is that a miniature breath analysis device can measure signatures of exhaled breath VOCs in real-time and correlate their profile to viral upper respiratory infections such as SARS-CoV-2, even asymptomatically. In Aim #1, we propose a prospective, observational study to analyze breath samples from COVID-19 positive and negative subjects, solely for the purpose of analysis through gold standard GC- MS to define breath VOC biomarkers of infection. We will recruit subjects at two local sites, the UC Davis Medical Center (Sacramento, CA) and VA Northern California Health Care System (Mather, CA), where MPI Dr. Kenyon and Co-Is Drs. Harper and Schivo have joint clinical appointments. Our group has a proven track record to conduct these types of clinical breath studies. In Aim #2, we will develop a portable breath analysis device using our novel miniature differential mobility spectrometry (DMS) detector, coupled with chip-based gas chromatography. DMS is a subset of ion mobility spectrometry and detects VOCs at ambient temperatures and pressures, making it highly appropriate for portable devices. This device would include our custom chip- based preconcentrator, which is packed with a chemical sorbent for extraction of VOCs from breath, and will compare functionality of a compact commercially available GC column to a micro-GC column chip from Deviant, a subcontractor in this work. Individual components of this device have already been developed, and under direction of MPI Prof. Davis, Chair of Mechanical and Aerospace Engineering, a team of research engineers would integrate these pieces together into a single unit. Collaborator Prof. Chuah would guide development of a custom software package for the device with machine learning and artificial intelligence capabilities for automated data processing and interpretation. The device would be placed in the hands of clinicians, who would provide feedback that engineers would immediately incorporate into the device and return to the clinicians for more testing. Under Aim #3, our team would process the GC-MS and GC-DMS data generated in this work, identifying a novel VOC profile for COVID-19 diagnostics. Aim #4 would initiate towards the end of this study to develop both a regulatory pathway & contract manufacturing plan for large scale production and deployment of the device for clinical approval. These efforts are supported by collaborator Dr. Nam Tran, Director of Clinical Pathology & Clinical Chemistry at the UC Davis Medical Center. Project Narrative: In the United States and worldwide, public health experts agree that nations must increase their capacity to test for COVID-19, yet global supplies for testing materials remain scarce. This project would lead to the development of an entirely new type of COVID-19 test, one that could diagnose infections with only a breath sample. Through this proposal, our team would develop a portable device that could identify people with COVID-19 infections by analyzing volatile organic compounds (VOCs) found in exhaled breath.",Portable GC detector for breath-based COVID diagnostics,10266337,U18TR003795,"['2019-nCoV', 'Aerospace Engineering', 'Appointment', 'Artificial Intelligence', 'Automatic Data Processing', 'Benchmarking', 'Biological Markers', 'Breath Tests', 'COVID diagnostic', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 test', 'California', 'Catalogs', 'Chemicals', 'Clinical', 'Clinical Chemistry', 'Clinical Pathology', 'Clinical Trials', 'Communities', 'Computer software', 'Consultations', 'Contact Tracing', 'Contracts', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Engineering', 'Environment', 'Exhalation', 'Feedback', 'Fingerprint', 'Flushing', 'Funding', 'Gas Chromatography', 'Gases', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heating', 'Human Resources', 'Individual', 'Industry', 'Infection', 'Intuition', 'Joints', 'Lead', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Maps', 'Mass Spectrum Analysis', 'Materials Testing', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical center', 'National Institute of Biomedical Imaging and Bioengineering', 'Observational Study', 'Output', 'Pattern', 'Polymerase Chain Reaction', 'Process', 'Production', 'Public Health', 'Publishing', 'Rapid diagnostics', 'Reagent', 'Regulatory Pathway', 'Research', 'SARS-CoV-2 infection', 'SARS-CoV-2 positive', 'Sampling', 'Sensitivity and Specificity', 'Site', 'Skin', 'Spectrometry', 'Standardization', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'United States National Institutes of Health', 'Upper Respiratory Infections', 'Viral', 'Work', 'base', 'biomarker signature', 'clinical care', 'detector', 'deviant', 'differential expression', 'disease transmission', 'graphical user interface', 'instrument', 'intelligent algorithm', 'ion mobility', 'large scale production', 'machine learning algorithm', 'metabolomics', 'novel', 'novel diagnostics', 'pandemic disease', 'portability', 'pressure', 'programs', 'prospective', 'prototype', 'recruit', 'risk mitigation', 'scale up', 'sensor', 'standard of care', 'volatile organic compound']",NCATS,UNIVERSITY OF CALIFORNIA AT DAVIS,U18,2021,975463
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10129965,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2021,403882
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10213005,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,915264
"Automating mosquito microdissection for a malaria PfSPZ vaccine ABSTRACT Despite annual investments of >$3 billion for intensive control measures, in 2018, the 228 million cases of malaria were an increase of ~16 million cases over 2015, and no decrease in number of deaths. The impact of available malaria control measure has plateaued. Moreover, WHO estimates deaths from malaria could double across sub-Saharan Africa this year due to disruptions in access to control measures due to the current global COVID-19 pandemic malaria. New tools, especially a vaccine, are needed. Only broad deployment of an effective vaccine holds the promise of true elimination or eradication, especially in the face of sudden developments like COVID-19. More than 98% of all deaths from malaria are caused by Plasmodium falciparum (Pf). Thus, a vaccine against Pf malaria is the priority. Sanaria is moving in 2021 to Phase 3 clinical trials of its Pf sporozoite (SPZ), PfSPZ Vaccine, and is planning for marketing authorization (licensure) from FDA and EMA in 2022/2023. Over the next 5-10 years we aim to decrease the cost of goods (COGs) and efficiency of production of PfSPZ vaccines so they can be used most effectively and economically by individuals who suffer the most from malaria. Microdissection of mosquitoes is a crucial step in extraction of PfSPZ vaccine products, and ensures a 10,000-fold purification away from irrelevant mosquito parts as the starting material for downstream purification procedures that then achieve a final product purity of 99.9%. To-date, mosquito salivary gland PfSPZ have demonstrated in vivo infectivity/potency superior to those extracted from whole mosquitoes, or grown outside a mosquito. However, extraction of mosquito salivary glands is a rate-limiting, labor-intensive, expensive step in production of PfSPZ-based vaccines. The overarching aim of this proposal is to enable implementation of an interim semi-automated dissection device in cGMP production of PfSPZ-based vaccines against malaria, and develop an integrated dissection system incorporating multiple automation steps downstream of mosquito orientation, for commercial-scale manufacturing. The unique application of robotic technology, state-of-the art computer vision and machine learning algorithms, and software systems to production-scale processing of very small insects in cleanrooms not only advances manufacturing capabilities, but also represents a spectrum of milestone innovations in automation. Success in this project involving a highly-skilled multi-disciplinary team of investigators, manufacturing and quality experts will decidedly lead to further streamlining and process optimization during the key step of isolating mosquito salivary glands for manufacture of our highly effective PfSPZ-based vaccines. The breakthroughs that initially defined a vaccine that is far superior to competing technologies in both safety and protective efficacy, will continue, as we advance in the proposed studies to make vaccine extraction more cost-effective due to greater efficiencies, mitigation of human error and operator fatigue, reduced timeframes, greatly reduced training periods, and increased product purity, towards deployment of a highly-impactful tool in the fight against malaria. Malaria claims upwards of 600,000 human lives each year, with more than 1,000 children succumbing every day. Sanaria’s Plasmodium falciparum (Pf) sporozoite (SPZ)-based vaccines against malaria have demonstrated outstanding safety and efficacy in numerous clinical trials. The manufacturing procedure for PfSPZ-based crucially involves a currently labor-intensive process of mosquito salivary gland extraction entirely by manual dissection. Our aim in this proposal is to first introduce an interim semi-automated dissection fixture for this process. In parallel efforts, incorporating automation in key steps of mosquito decapitation, and extraction of glands will lead to greater efficiencies, reduce timeframes, greatly reduce training times, mitigate human error and operator fatigue while maintaining product purity and quality that is thought to underlie an incredible safety record of Sanaria’s PfSPZ vaccines. These outcomes will accelerate Sanaria’s march to licensure and production of commercial-scale volumes required to meet demand for post-licensure distribution to populations with greatest need, world- wide.",Automating mosquito microdissection for a malaria PfSPZ vaccine,10258416,R44AI134500,"['Africa South of the Sahara', 'Authorization documentation', 'Automation', 'Body part', 'COVID-19', 'COVID-19 pandemic', 'Cessation of life', 'Characteristics', 'Chest', 'Child', 'Clinical Trials', 'Collection', 'Comb animal structure', 'Computer Vision Systems', 'Culicidae', 'Cyclic GMP', 'Decapitation', 'Development', 'Devices', 'Dissection', 'Ensure', 'Environment', 'Equipment', 'Falciparum Malaria', 'Fatigue', 'Feasibility Studies', 'Geometry', 'Gland', 'Goals', 'Head', 'Hour', 'Human', 'Human Resources', 'Individual', 'Injections', 'Insecta', 'Investments', 'Lead', 'Licensure', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Marketing', 'Measures', 'Methodology', 'Methods', 'Microdissection', 'Microscope', 'Modeling', 'Modification', 'Molds', 'Needles', 'Outcome', 'Output', 'Phase', 'Phase III Clinical Trials', 'Plasmodium falciparum', 'Plasmodium falciparum vaccine', 'Population', 'Procedures', 'Process', 'Production', 'Research Personnel', 'Robotics', 'Running', 'Safety', 'Salivary Glands', 'Scheme', 'Sporozoites', 'Stainless Steel', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Vaccines', 'Vision', 'base', 'cGMP production', 'commercialization', 'cost', 'cost effective', 'design', 'experience', 'feeding', 'fight against', 'human error', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning algorithm', 'manufacturing scale-up', 'multidisciplinary', 'operation', 'process optimization', 'protective efficacy', 'prototype', 'robotic system', 'software systems', 'success', 'tool']",NIAID,"SANARIA, INC.",R44,2021,1000000
"Portable Hearing Laboratory  - CRP In the parent Phase II project (R44DC016247; PI: C. Pavlovic) we successfully developed a portable platform for developing and testing new hearing aid technology. This Portable Hearing Laboratory, or PHL, has now been acquired and is being used by a number of leading university laboratories and other research centers and their feedback has been extremely positive. The device features a central unit (BatAndCat Box) which provides an appropriate and complete hearing aid ambient for developing new algorithms. A number of realistic interfaces has also been provided. This includes an extremely high quality BTE system we designed; an ITE system adapted by us, as well as an appropriate interface circuitry for typical wearables (e.g; headsets via the line input). Finally, a smart phone app features interfaces both for the researcher and the subject. The system runs the Master Hearing aid sweet developed concurrently in R01DC015429 (PIs Hohmann and Pavlovic). In this CRP renewal we will achieve the following goals: 1. Implement various Design for Excellence Measures (DFX) and super modern manufacturing  technology to obtain the highest product quality at the lowest product cost. This would make  the product affordable for large clinical studies and, potentially, for some consumer sales. 2. In response to the recent availability of, and the recent research demand for, a far greater  processing power to enable the development of algorithms which rely on machine learning,  we plan to increase the processing power of the device by at least 10 times, and likely 20  times, by changing the processor core to a multicore system. 3. Introduce modern low-latency BLE technology to enable efﬁcient noise reduction by utilizing  remote microphones and machine learning. 4. The other complementary requirement to extract speech from noise is being able to inform  the system whom the listener is actually listening to. This will be achieved by providing on  the PHL the interface means for external multi-sensor arrays such as EEG, OEG, etc. 5. Execute electrical and mechanical design changes dramatically reducing the size and  weight of the device. This would not only be a much more acceptable device for long clinical  trials, but would also open up a direct-to-consumer, secondary market for the device. 6. It is our strong determination to provide continuous support to the Beta sites for extensive  further testing of the device in a variety of settings. We consider this the best means to  reach the perfection. Portable Hearing Laboratory (PHL), developed in R44DC016247 has been deployed successfully at various research centers and it features a central unit connected to a number of realistic interfaces such as BTEs, ITEs, or typical wearables. In this CRP renewal we upgrade the technology to support demanding machine learning algorithms interfaced almost inconspicuously to a number of EEG and EOG electrodes to extract perfectly speech from noise. Simultaneously, we apply modern manufacturing technology to produce small, powerful and low cost devices.",Portable Hearing Laboratory  - CRP,10138807,R44DC016247,"['Acoustics', 'Algorithms', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Code', 'Communities', 'Data', 'Device or Instrument Development', 'Devices', 'Ear', 'Electrodes', 'Electroencephalography', 'Environment', 'Esthetics', 'Evaluation', 'Feedback', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Institution', 'Laboratories', 'Libraries', 'Life', 'Linux', 'Machine Learning', 'Measures', 'Mechanics', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Parents', 'Phase', 'Process', 'Reporting', 'Request for Applications', 'Research', 'Research Personnel', 'Running', 'Sales', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Source Code', 'Speech', 'System', 'Technology', 'Testing', 'Time', 'Transducers', 'Universities', 'Validation', 'Weight', 'Wireless Technology', 'Work', 'algorithm development', 'base', 'cost', 'design', 'improved', 'machine learning algorithm', 'man', 'manufacturing process', 'meter', 'microphone', 'new technology', 'open source', 'parent project', 'portability', 'response', 'sensor', 'signal processing', 'simulation', 'smartphone Application', 'sound', 'speech in noise', 'tool', 'virtual']",NIDCD,"BATANDCAT, INC.",R44,2021,837653
