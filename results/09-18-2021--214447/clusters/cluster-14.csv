text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9768545,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,383874,0.022059931157974718
"Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction Project Summary/Abstract Electronic Health Records (EHRs) contain significant information that can benefit many downstream uses. However, most of this information is in unstructured narrative form and is inaccessible to computerized methods that rely on structured representations for exploring, retrieving, and presenting the information. Natural language processing (NLP) and information extraction (IE) open this trove of information to studies that would otherwise be without. Over the past decades, many IE systems have been developed. These systems have typically focused on one task at a time. In addition, most have studied only specific types of records, e.g., discharge summaries, and addressed their task on data from a single institution. Performances achieved by the state-of-the-art IE systems developed under these conditions ranged from 44% F-measure to 99% F-measure. This observed variation can be attributed to the nature of the tasks: some target entities like dates tend to be better represented in the data and also more rigidly stick to known patterns of expression as opposed to reasons for medication administration which are relatively sparse in the data and can show wider linguistic diversity. However, this may not be the only reason: the data used can also explain the performance variation. Narratives of EHRs vary in their style, format, and content going from one department to another, from one hospital to another. Even the same record type in two different hospitals can be very different in narrative style and pose different challenges for IE. Understanding IE performance therefore requires studies of multiple tasks on multiple record types that come from multiple institutions. One major bottleneck for evaluation of IE systems on such a large scale is annotation. The same bottleneck also limits system development. This proposal aims to address this bottleneck for both evaluation and development. It first generates a multi-institution corpus consisting of multiple record types from five institutions. It studies four different IE tasks that broadly represent IE in clinical records and can inform the field of IE as a whole: de-identification, clinical concept extraction, medication extraction, and adverse drug event extraction. Within the context of these IE tasks, the proposal then puts forward methods that learn from unlabeled or pseudo data that can help alleviate reliance on annotated data for development. It evaluates these methods both for performance and generalizability on multiple types of records from multiple institutions. As a result of these activities, this proposal generates de-identified data, annotations, methods, software, and machine learning models which it then makes available to the research community. Project Narrative Information extraction (IE) systems, i.e., natural language processing (NLP) systems that enable creation of accurate semantic representations of narratives, rely heavily on the availability of gold standard annotated corpora and vary significantly in their performance from task to task, and from data set to data set. We propose methods that augment gold standard data with unlabeled data that are more easily available, and pseudo data which can be derived from gold standard data. We study IE within the context of four tasks and evaluate IE systems enhanced with unlabeled and pseudo data for generalizability on a heterogeneous data set consisting of multiple record types from five institutions.",Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction,9813134,R15LM013209,"['Accident and Emergency department', 'Address', 'Adverse drug event', 'Affect', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Discipline of Nursing', 'Electronic Health Record', 'Engineering', 'Evaluation', 'Frequencies', 'Gold', 'Growth', 'Healthcare', 'Hospitals', 'Institution', 'Israel', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nature', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Plant Roots', 'Procedures', 'Psychiatry', 'Publications', 'Records', 'Reporting', 'Research', 'Resources', 'Route', 'Sampling', 'Semantics', 'Signs and Symptoms', 'Social Work', 'Structure', 'Supervision', 'System', 'Systems Development', 'Task Performances', 'Telephone', 'Test Result', 'Testing', 'Text', 'Thinness', 'Time', 'Training', 'Universities', 'Variant', 'Virginia', 'Washington', 'computerized', 'deep learning', 'dosage', 'field study', 'improved', 'learning strategy', 'medication administration', 'novel', 'open source', 'response', 'supervised learning', 'tool']",NLM,GEORGE MASON UNIVERSITY,R15,2019,414798,0.018879098698976783
"Ethical Considerations for Language Modeling within Brain-Computer Interfaces Project Summary Machine learning (ML) and Natural Language Processing (NLP) have the potential to transform communication for patients with neurodegenerative disease through personalized and real-time augmentative and alternative communication (AAC) devices. Individuals with severe communication impairments who can no longer control their daily conversations or participate in previous life roles want AAC devices. And they want them to work – to be reliable, effective, and fast. ML and NLP are emerging as promising tools to bridge current technology and next generation devices for individuals with the most severe speech and physical impairments, like the RSVP Keyboard™, a brain-computer interface (BCI) being developed by the parent grant. BCI systems for communication are referred to as AAC-BCIs. NLP efforts to combine large public data sets with private data sets, such as personal email messages, promise to give individuals with communication impairments their own personalized language models, models that are sufficiently robust to get closer to real-time communication. The focus on getting AAC-BCIs to work with machine learning, however, has led to a critical oversight in the field: an inadequate understanding of why individuals want next-generation devices and what trade-offs they are willing to make for faster and more personalized communication. The turn to ML brings this oversight into sharp relief. Individuals should provide input about the data sets used to construct their personal language models, but this raises important ethical questions about what individuals value, how they understand their identity, and what trade-offs they are willing to make relative to their personalized communication data. The goal of this supplement is to fill this gap in understanding so that researchers can implement ML into next generation AAC-BCI systems in a way that is sensitive to the ethical concerns of future users. There are four components to this ethics supplement: (1) to design a toolbox of ethics vignettes tailored to ethical concerns raised by both BCI communication and ML; (2) to administer monthly vignette-based online ethics surveys to individuals with severe communication impairments due to motor neuron disease (e.g., ALS) (n=25) or movement disorders (e.g., Parkinson's disease) (n=25); (3) to conduct semi-structured vignette-based interviews with individuals with pre- clinical or mild communication impairment due to motor neuron disease (n=10) or movement disorder (n=10). Components (2) and (3) will employ an iterative, parallel mixed-method approach. Trends in Likert-style online responses to ethics vignettes in the severe communication impairment cohort will be used to inform and modify the semi-structured interview prompts asked of the pre-clinical or mild impairment cohort. In parallel, themes emerging from direct content analysis of interviews will be used to refine online survey questions. Results of this iterative, mix-methods approach will be used (4) to outline a framework of core ethical domains and preliminary tools (vignettes and discussion prompts) that AAC-BCI researchers can use to assess ethical concerns while developing and iteratively refining communication technology for personalized language models. Project Narrative The populations of US citizens with severe speech and physical impairments secondary to neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies. Bioethical issues about privacy, agency and identity must be included in technology development and implementation as the parent grant implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Ethical Considerations for Language Modeling within Brain-Computer Interfaces,9929337,R01DC009834,"['Address', 'Administrative Supplement', 'Affect', 'Attention', 'Attitude', 'Augmentative and Alternative Communication', 'Award', 'Bioethical Issues', 'Bioethics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Electronic Mail', 'Encapsulated', 'Engineering', 'Ensure', 'Ethical Analysis', 'Ethical Issues', 'Ethics', 'Foundations', 'Future', 'Goals', 'Home environment', 'Impairment', 'Individual', 'Informed Consent', 'Interview', 'Language', 'Letters', 'Life', 'Link', 'Literature', 'Locked-In Syndrome', 'Machine Learning', 'Medical', 'Medical Technology', 'Methods', 'Modeling', 'Monkeys', 'Motor Neuron Disease', 'Movement', 'Movement Disorders', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Oregon', 'Outcome', 'Parents', 'Parkinson Disease', 'Participant', 'Patient advocacy', 'Patients', 'Population', 'Privacy', 'Privatization', 'Public Health', 'Reporting', 'Research Personnel', 'Review Literature', 'Role', 'Secondary to', 'Self-Help Devices', 'Source', 'Speech', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Voice', 'Work', 'advocacy organizations', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'cohort', 'communication device', 'computer science', 'design', 'expectation', 'informant', 'neurophysiology', 'next generation', 'novel', 'parent grant', 'pre-clinical', 'recruit', 'research and development', 'response', 'signal processing', 'skills', 'spelling', 'technology development', 'technology validation', 'tool', 'trend', 'uptake']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,153834,-0.011933711674267466
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9774338,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2019,1521748,0.006535932008150556
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9759499,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2019,20000,0.01270682847110186
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9600692,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'automated speech recognition', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,568221,0.045041443950685434
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9771334,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2019,186473,0.05052412751075804
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9628032,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Guidelines', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intelligence', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Reaction', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'pharmacovigilance', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'supervised learning', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,809552,-0.0017700080410150319
"Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis PROJECT SUMMARY Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with chronic aphasia in a number of small studies, many of which did not include a control group. Although the treatment appears promising, data to date do not permit an adequate assessment of the utility of the technique. We propose to study the effects of TMS combined with Constraint Induced Language Therapy (CILT) in 75 subjects with chronic aphasia. Subjects will be randomized in a 2:1 ratio to TMS with CILT or sham TMS with CILT. One Hz TMS at 90% motor threshold will be delivered to the right inferior frontal gyrus for 20 minutes in 10 sessions over 2 weeks; language therapy will be provided for one hour immediately after the conclusion of each session of TMS. Change from baseline in the Western Aphasia Battery Aphasia Quotient at 6 months after the end of TMS treatment will serve as the primary outcome measure. A secondary aim is to identify anatomic and behavioral predictors of response to treatment. Finally, a third aim is to identify the mechanism underlying the beneficial effect of the treatment using a variety of imaging techniques. Subjects who have no contraindication to the MRI will undergo fMRI imaging prior to and at 6 months after therapy. Using modern network analyses and robust machine learning techniques we will identify changes in the strengths of connections between nodes in the language network to address specific hypotheses regarding the effects of TMS and CILT on brain organization that are associated with beneficial response to treatment. PROJECT NARRATIVE Although Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with aphasia in many small studies, its general clinical utility has not been established. We propose to study the effects of TMS combined with Constraint Induced Language Therapy in a double-blinded study of 75 subjects with chronic aphasia. Additional aims are to identify anatomic and behavioral predictors of response to treatment and identify the mechanisms underlying the beneficial effect of using modern neuroimaging techniques.",Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis,9785486,R01DC016800,"['Acquired Language Disorders', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Aphasia', 'Behavioral', 'Brain', 'Brain imaging', 'Chronic', 'Clinical', 'Control Groups', 'Data', 'Disease', 'Double-Blind Method', 'Functional Magnetic Resonance Imaging', 'Hour', 'Image', 'Imaging Techniques', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Investigation', 'Language', 'Language Therapy', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modernization', 'Motor', 'Neurosciences', 'Outcome Measure', 'Participant', 'Pathway Analysis', 'Performance', 'Persons', 'Prevalence', 'Procedures', 'Psycholinguistics', 'Randomized', 'Rehabilitation therapy', 'Research Design', 'Research Personnel', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Techniques', 'Testing', 'Therapeutic Effect', 'Transcranial magnetic stimulation', 'Work', 'aphasia recovery', 'behavioral neurology', 'clinical investigation', 'effective therapy', 'improved', 'insight', 'interest', 'neuroimaging', 'neuroregulation', 'predicting response', 'primary outcome', 'relating to nervous system', 'response', 'treatment effect', 'treatment response', 'white matter']",NIDCD,UNIVERSITY OF PENNSYLVANIA,R01,2019,583922,0.025170614964850332
"Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis PROJECT SUMMARY Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with chronic aphasia in a number of small studies, many of which did not include a control group. Although the treatment appears promising, data to date do not permit an adequate assessment of the utility of the technique. We propose to study the effects of TMS combined with Constraint Induced Language Therapy (CILT) in 75 subjects with chronic aphasia. Subjects will be randomized in a 2:1 ratio to TMS with CILT or sham TMS with CILT. One Hz TMS at 90% motor threshold will be delivered to the right inferior frontal gyrus for 20 minutes in 10 sessions over 2 weeks; language therapy will be provided for one hour immediately after the conclusion of each session of TMS. Change from baseline in the Western Aphasia Battery Aphasia Quotient at 6 months after the end of TMS treatment will serve as the primary outcome measure. A secondary aim is to identify anatomic and behavioral predictors of response to treatment. Finally, a third aim is to identify the mechanism underlying the beneficial effect of the treatment using a variety of imaging techniques. Subjects who have no contraindication to the MRI will undergo fMRI imaging prior to and at 6 months after therapy. Using modern network analyses and robust machine learning techniques we will identify changes in the strengths of connections between nodes in the language network to address specific hypotheses regarding the effects of TMS and CILT on brain organization that are associated with beneficial response to treatment. PROJECT NARRATIVE Although Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with aphasia in many small studies, its general clinical utility has not been established. We propose to study the effects of TMS combined with Constraint Induced Language Therapy in a double-blinded study of 75 subjects with chronic aphasia. Additional aims are to identify anatomic and behavioral predictors of response to treatment and identify the mechanisms underlying the beneficial effect of using modern neuroimaging techniques.",Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis,9852221,R01DC016800,"['Acquired Language Disorders', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Aphasia', 'Behavioral', 'Brain', 'Brain imaging', 'Chronic', 'Clinical', 'Control Groups', 'Data', 'Disease', 'Double-Blind Method', 'Functional Magnetic Resonance Imaging', 'Hour', 'Image', 'Imaging Techniques', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Investigation', 'Language', 'Language Therapy', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modernization', 'Motor', 'Neurosciences', 'Outcome Measure', 'Participant', 'Pathway Analysis', 'Performance', 'Persons', 'Prevalence', 'Procedures', 'Psycholinguistics', 'Randomized', 'Rehabilitation therapy', 'Research Design', 'Research Personnel', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Techniques', 'Testing', 'Therapeutic Effect', 'Transcranial magnetic stimulation', 'Work', 'aphasia recovery', 'behavioral neurology', 'clinical investigation', 'effective therapy', 'improved', 'insight', 'interest', 'neuroimaging', 'neuroregulation', 'predicting response', 'primary outcome', 'relating to nervous system', 'response', 'treatment effect', 'treatment response', 'white matter']",NIDCD,UNIVERSITY OF PENNSYLVANIA,R01,2019,402181,0.025170614964850332
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9738055,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,303944,-0.022754025585153485
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9607596,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Big Data Methods', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,762619,0.017291797957611314
"Exploring the evolving relationship between tobacco, marijuana and e-cigarettes Abstract The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana products (respectively). In order to understand this changing landscape we need new, ﬂexible, and responsive research methods capable of rapidly providing insights into product initiation patterns, use patterns, and cessation strategies. Social media — here deﬁned as including internet discussion forums — provides a ready-made source of abundant, naturalistic, longitudinal, publicly accessible, ﬁrst-person narratives with which to understand health behaviours and attitudes. We propose to use a combination of qualitative methods and automated natural language processing techniques to investigate online discussion forums devoted to tobacco, marijuana, and e-cigarettes in order to understand user trajectories through the three product categories. PROJECT NARRATIVE The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana (respectively). In order to make sense of this rapidly changing landscape, we need new, ﬂexible, and responsive research methods capable of providing insights into tobacco, marijuana, and e- cigarette product use patterns. We propose to use a combination of qualitative and automated natural language processing techniques to investigate online discussion forums related to tobacco, marijuana, and e-cigarettes in order to better understand user trajectories through these different product classes.","Exploring the evolving relationship between tobacco, marijuana and e-cigarettes",9788381,R21DA043775,"['Adolescent and Young Adult', 'Adult', 'Age', 'Algorithms', 'Attitude to Health', 'Categories', 'Chronic Bronchitis', 'Code', 'Consumption', 'Data', 'Data Science', 'Devices', 'Educational Status', 'Electronic cigarette', 'Health', 'Health behavior', 'High School Student', 'Individual', 'Internet', 'Manuals', 'Marijuana', 'Modeling', 'Multiple Marriages', 'Natural Language Processing', 'Pattern', 'Persons', 'Population', 'Qualitative Methods', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Role', 'Sampling', 'Smoking', 'Source', 'Surgeon', 'Techniques', 'Therapeutic', 'Tobacco', 'Tobacco use', 'Training', 'Work', 'base', 'cigarette smoking', 'combustible cigarette', 'electronic cigarette use', 'flexibility', 'high school', 'innovation', 'insight', 'man', 'marijuana use', 'nicotine replacement', 'smoking cessation', 'social media']",NIDA,UNIVERSITY OF UTAH,R21,2019,225147,0.024758290354589423
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9829606,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2019,34593,0.09711183279416773
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9660548,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2019,773968,0.09711183279416773
"Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence ABSTRACT  Approximately 15% of toddlers 18-36 months of age experience late language emergence (LLE; Paul, 1992; Singleton, 2018). These late talkers (LTs) have a reduced expressive vocabulary, but average non-linguistic abilities, in the absence of overt sensory or other developmental delays (Collisson, 2016; Paul & Jennings, 1992). Upwards of 16% of LTs prospectively meet criteria for language disorder (Rescorla, 2009), while others retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). LTs are at elevated risk for lifelong language and literacy impairments that negatively impact access to academic and vocational opportunities (Singleton, 2018; Paul, 1993), and even subclinical outcomes have pervasive negative impacts (Rescorla, 2002). This project addresses questions crucial for the early diagnosis of LTs and prerequisite to the applicant’s long-term goal of establishing an independent research program on LLE, aimed ultimately at identifying variation and distribution of behavioral phenotypes to provide a foundation for more targeted interventions for LTs. This project complements prior work on LLE focused on language production by evaluating the time course of word learning and spoken word recognition in LTs and 2 control groups (age- and language-matched typically developing peers), all of whom will complete standardized assessments of cognitive -linguistic abilities. In Expt. 1, participants will train on a simple selection task using 4 novel and 4 familiar words that overlap phonologically (e.g., at onset, BUNNY-BUTTON, or offset, KITTEN-MITTEN). We will use eye tracking to estimate group and individual differences in lexical activation and competition over time. In Expt. 2, we will record EEG (electroencephalography) in a passive listening task. Participants will watch a silent video as newly-learned and familiar words from Expt. 1 are repeated. ERP (event-related potential) analyses will examine individual and group differences in responses to newly-learned vs. familiar words. We will also use machine-learning (support vector machines, SVMs) to decode EEG responses to specific words for each participant, on the logic that fidelity and coherence of responses will determine SVM classification success. Group and individual differences in eye tracking, ERP, and/or EEG-decoding measures will provide new insights into receptive abilities of LTs, and provide a basis for future work aimed at identifying LTs with greatest risk for clinical or subclinical language outcomes. The project will take place at the U. of Connecticut and Haskins Labs. The applicant and sponsors have developed a training plan for the applicant focused on further developing her (1) EEG and statistical skills, (2) knowledge base of the cognitive neuroscience of typical and atypical language development, (3) dissemination skills, and (4) understanding of principles for the responsible conduct of research, with the aim of supporting her goal to be an independent researcher in a Research-1 environment. PROJECT NARRATIVE  Approximately 15% of toddlers meet criteria for being a late talker (LT) (Paul, 1993; Singleton, 2018;) and upwards of 16% of LTs prospectively meet criteria for spoken and/or written language disorder (Rescorla, 2009) while another subset will retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). Late language emergence (LLE) is associated with lifelong clinical and subclinical weaknesses in language and literacy that negatively impact access to academic and vocational opportunities (Paul, 1993; Singleton, 2018), and even subclinical outcomes have a negative impact on vocational and higher educational choices (Rescorla, 2002). The proposed research will address questions prerequisite to the applicant's long-term goal of establishing an independent research program aimed at (1) identifying early markers of chronic impact in order to optimally allocate scarce early intervention resources and (2) identifying variation and distribution of behavioral phenotypes which will provide the foundation for more focused and targeted forms of interventions for LTs with a range of clinical and subclinical language outcomes.",Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence,9836112,F31DC018220,"['3 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Behavioral', 'Child', 'Chronic', 'Classification', 'Clinical', 'Cognitive', 'Complement', 'Complex', 'Connecticut', 'Control Groups', 'Development', 'Developmental Delay Disorders', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Endowment', 'Environment', 'Evaluation', 'Event-Related Potentials', 'Exclusion', 'Eye', 'Foundations', 'Future', 'Goals', 'Grain', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Logic', 'Machine Learning', 'Measures', 'Morphology', 'Neurobiology', 'Outcome', 'Output', 'Participant', 'Phenotype', 'Population', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Risk', 'School-Age Population', 'Sensory', 'Signal Transduction', 'Speech', 'Speed', 'Standardization', 'Testing', 'Time', 'Toddler', 'Training', 'Variant', 'Visual', 'Vocabulary', 'Word Processing', 'Work', 'base', 'clinical risk', 'cognitive neuroscience', 'experience', 'experimental study', 'high risk', 'improved outcome', 'insight', 'knowledge base', 'language impairment', 'language outcome', 'language processing', 'lexical', 'lexical processing', 'literacy', 'multimodality', 'neural correlate', 'novel', 'peer', 'phonology', 'programs', 'prospective', 'reduce symptoms', 'relating to nervous system', 'response', 'responsible research conduct', 'skills', 'social', 'sound', 'success', 'trait', 'word learning']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,F31,2019,40450,0.0762582393759724
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9731439,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2019,39939,0.018288544732774845
"Hippocampal-cortical networks underlying memory retrieval of linguistic knowledge ABSTRACT Language and memory overlap heavily in brain circuitry and in our day-to-day lives. Both are also frequently disrupted in neurological conditions such as temporal lobe epilepsy and Alzheimer’s disease. We have a limited understanding of the mechanisms by which cortical language centers integrate with memory circuits; for example, to support the retrieval of linguistic knowledge. This limits our insight into disease pathophysiology and slows the development of more effective therapies for cognitive impairments. This K23 will support an investigation of how language and memory integrate in the human brain, by harnessing unique innovations and resources. First, we will use special high-density grid and depth electrodes to record from many hundreds of local neuronal populations distributed throughout memory and language centers, among patients undergoing intracranial monitoring for refractory epilepsy. Second, to target distinct moments of linguistic-mnemonic integration, we have customized an auditory naming behavioral task that combines controlled yet natural language stimuli with memory retrieval of linguistic knowledge. Third, I will apply state-of-the-art analyses with pattern classifiers and computational linguistics, an approach that could improve the framework of how we understand neural representations of deep language processing. I will first evaluate whether the activity patterns in cortical language centers and the hippocampus reveal neural signatures of dynamic integration during knowledge retrieval, and whether their activity patterns reflect mutual information sufficient to predict the linguistic content of task trials (Aim 1). I will then use electrical stimulation to selectively disrupt neural processing in these regions, to determine if and how they contribute to distinct stages of language and memory integration (Aim 2). This approach will also allow us to probe whether the hippocampus is required for semantic memory, a long-debated question arising from classic literature. My mentorship team has a constellation of expertise aligning with my training plan and the goals of this investigation, including cortical language neurophysiology, hippocampal memory neurophysiology, and investigative neurostimulation. This proposal builds upon my prior expertise in translational intracranial recordings and neural signal processing, and my long-term career goal of understanding and improving treatments for cognitive impairments in epilepsy. I will receive training, coursework, and direct mentorship in skillsets that I will continue to use throughout my scientific career, including language and memory neurophysiology, human neurostimulation, neuroethics, machine learning, computational linguistics, scientific communication, and independent laboratory management. The knowledge and training acquired during this award period will allow me to establish an independent laboratory and emerge as a leader in human intracranial neurophysiology, applying my expertise to unmet needs in epilepsy. NARRATIVE Memory and language functions can be devastatingly impaired by neurological diseases such as temporal lobe epilepsy and Alzheimer’s disease. This investigation seeks to understand how the neural circuits that underlie these functions work together to retrieve knowledge from memory, a precious human ability used in our day-to- day lives. This will have important relevance for basic neuroscience, clinical pathophysiology, and the development of future therapeutics for cognitive impairments.",Hippocampal-cortical networks underlying memory retrieval of linguistic knowledge,9720728,K23NS110920,"['Address', 'Alzheimer&apos', 's Disease', 'Animal Experimentation', 'Animals', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Clinical', 'Cognition', 'Communication', 'Comprehension', 'Computational Linguistics', 'Custom', 'Data', 'Data Analyses', 'Dementia', 'Development', 'Disease', 'Electric Stimulation', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Etiology', 'Event', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Hippocampus (Brain)', 'Human', 'Impaired cognition', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Memory', 'Mentorship', 'Methods', 'Monitor', 'Names', 'Neurologic', 'Neurons', 'Neurosciences', 'Paper', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Population', 'Refractory', 'Resources', 'Retrieval', 'Role', 'Sampling', 'Semantic memory', 'Semantics', 'Site', 'Stereotyping', 'Stimulus', 'Structure', 'Structure of middle temporal gyrus', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Training', 'Work', 'awake', 'base', 'behavior measurement', 'brain circuitry', 'career', 'cognitive function', 'density', 'effective therapy', 'improved', 'innovation', 'insight', 'language processing', 'memory retrieval', 'multidisciplinary', 'natural language', 'nervous system disorder', 'neural circuit', 'neuroethics', 'neurophysiology', 'neurotransmission', 'relating to nervous system', 'semantic processing', 'signal processing', 'syntax', 'theories', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K23,2019,200178,0.028928836324320143
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'learning strategy', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,-0.03618426259890054
"Statistical approaches to linguistic pattern learning PROJECT SUMMARY The long-term aim of the proposed research is to provide an account of how children learn the grammatical structure of their native language from distributional information in linguistic input, and also how these learning mechanisms may differ from those of adult learners. Distributional information is the patterning of elements in a large corpus of sentences. We hypothesize that learners acquire aspects of language structure from the statistics arising from this distributional information, such as which elements co-occur, what positions they regularly occupy in a word or sentence, and with what neighboring elements they frequently occur. Our program of research to date has focused on word segmentation (how learners determine which sound sequences form words) and on word categories (how learners determine which words form grammatical categories such as noun and verb). This work has documented the power and robustness of infants’, children’s, and adults’ ability to use complex distributional information to discover these aspects of language. We now propose to extend our research in new directions, to examine two crucial aspects of learning higher- level linguistic structure. In Part 1 we study the factors that lead learners to generalize a novel inflectional morpheme (like –s for noun plurals) to novel words. In Part 2 we examine how learners acquire phrases and simple hierarchical structure in sentences, and we ask what leads learners to prefer the types of phrase and hierarchical structures that are most common in natural languages.  In our proposed studies we test our hypotheses using miniature artificial language paradigms that afford control over the distributional cues in the input, something that is virtually impossible using only data from natural language learning. In each experiment, participants listen to utterances in a miniature language and then produce their own utterances or make judgments about their acceptability. Crucially, during the learning phase they hear only a sample of the possible utterances that are legal in the artificial language; some are withheld for use in a later post-test, to determine whether learners generalize what they have observed to novel instances (and if so, to which types of novel instances). We have developed highly successful paradigms for engaging young children in miniature language studies, and we have demonstrated important differences between child and adult language learners in these studies. We will also present children and adults with comparable learning paradigms in the visual-motor domain, to assess the time-course of the learning process and the specificity or generality of the results using auditory linguistic materials. Taken together, the results of these studies will document the key variables that enable a distributional learning mechanism to acquire the structure of words (inflectional morphology) and sentences (phrase and hierarchical structure) and will highlight the ways these mechanisms may differ over age and stimulus domain. PROJECT NARRATIVE  The study of age effects in language acquisition can help to determine the timing of optimal language input for bilingual children, deaf children, and children with communicative disabilities. Our findings on statistical learning of words, word categories, morphology, and sentence structure are also highly relevant to understanding language disorders, and our paradigms are widely used for identifying and treating children with difficulties, delays, and disorders of language acquisition. As research in language acquisition has moved from measuring stages of acquisition to understanding the processes by which languages are learned, our proposed studies will make important contributions to understanding where these processes break down and how principles of statistical learning can be used for treatment and rehabilitation.",Statistical approaches to linguistic pattern learning,9607105,R01HD037082,"['Adult', 'Age', 'Auditory', 'Categories', 'Child', 'Clinic', 'Complex', 'Cues', 'Data', 'Diagnostic tests', 'Elements', 'Goals', 'Hearing', 'Infant', 'Information Distribution', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Production', 'Productivity', 'Property', 'Rehabilitation therapy', 'Research', 'Sampling', 'Scheme', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Variant', 'Weight', 'Work', 'age effect', 'base', 'bilingualism', 'deaf', 'disability', 'experimental study', 'innovation', 'interest', 'lexical', 'natural language', 'novel', 'phrases', 'programs', 'sound', 'statistics', 'virtual', 'visual motor', 'word learning']",NICHD,GEORGETOWN UNIVERSITY,R01,2019,580188,0.0538099740090381
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9674437,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,557010,0.023671225958405855
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9665255,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Infrastructure', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,461012,0.02440719796815058
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9684602,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,608110,0.07499281276017103
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9753018,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'language outcome', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2019,268205,0.04882547898952155
"Probabilistic learning in developmental language disorder Project Summary/Abstract Currently, we lack an understanding of why grammatical deficits, particularly, are the primary deficit in developmental language disorder in children, and we also lack effective clinical treatment for these deficits. Recent studies have suggested that grammar may be impaired because of its statistical properties, which may be difficult for children with this disorder to learn or attend to. However, we do not yet understand what exactly about statistical input is difficult, and therefore face a gap in determining theoretical mechanisms that can explain the profile of developmental language disorder. In the proposed research, we explore the hypothesis that manipulations in the statistical properties of linguistic input may facilitate grammar learning in children with developmental language disorder. We will test this hypothesis through the following aims: We will compare learning for deterministic versus probabilistic statistical information to determine which type is more easily learned by children with developmental language disorder. We will compare learning for dependencies at different distributions to determine if children with developmental language disorder benefit from certain statistical structures. We will address these aims through two studies: an artificial grammar learning task and a sentence processing task with eye-tracking. These studies are innovative because they use tasks from basic research on language acquisition and processing to isolate aspects of linguistic input that could improve learning in developmental language disorder. Identifying the characteristics of linguistic information that are particularly problematic or relatively helpful for children with developmental language disorder as they learn grammar can help us understand where and how grammatical deficits in this population arise. Findings will be impactful because they may lead to more effective treatment through control of variables that can be simply managed in clinical settings, e.g. how often a word appears in one grammatical structure compared with another. The training provided in this proposal will provide theoretical and technical training in intervention research, working with individuals with developmental language disorder, and using real-time technologies to study language. Project Narrative Language development plays a critical role in a child’s ultimate academic and social success. A lack of effective treatment for the most prominent deficits in children with developmental language disorder represents a critical barrier to these children reaching their full potential as adults. By identifying and distinguishing the properties of language that are particularly effortful as well as those that are relatively easy for these children to learn, we can develop our understanding of learning in this disorder, and potentially make language treatment more effective.",Probabilistic learning in developmental language disorder,9788034,F32DC017373,"['Address', 'Adult', 'Basic Science', 'Characteristics', 'Child', 'Clinical', 'Clinical Treatment', 'Communication', 'Cues', 'Dependence', 'Disease', 'Exposure to', 'Eye', 'Face', 'Impairment', 'Individual', 'Intervention Studies', 'Laboratories', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Outcome', 'Outcome Measure', 'Participant', 'Pattern', 'Play', 'Population', 'Process', 'Property', 'Research', 'Role', 'Science', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'clinically significant', 'design', 'educational atmosphere', 'effective intervention', 'effective therapy', 'farmer', 'improved', 'innovation', 'insight', 'language comprehension', 'language processing', 'peer', 'preservation', 'social', 'specific language impairment', 'statistics', 'success', 'theories']",NIDCD,UNIVERSITY OF ARIZONA,F32,2019,22217,0.025979789059684736
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9603758,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'deaf', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'learning ability', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2019,340010,0.08649717265731167
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9729661,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect', 'treatment optimization']",NIDCD,UNIVERSITY OF ARIZONA,R01,2019,606922,0.028692101656762472
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9613837,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Infrastructure', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2019,268961,0.04795808047106805
"Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods No abstract available Narrative Prescription Medication (PM) abuse is a major epidemic in the United States, and monitoring and studying the characteristics of the PM abuse problem requires the development of novel approaches. Social media encapsulates an abundance of data about PM abuse from different demographics, but extracting that data and converting it to knowledge requires advanced natural language processing and data-centric artificial intelligence systems. Our proposed social media mining framework will automate the process of big data to knowledge conversion for PM abuse, providing crucial insights to toxicologists about targeted populations and enabling the future development of directed intervention strategies.",Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods,10001871,R01DA046619,[' '],NIDA,EMORY UNIVERSITY,R01,2019,347317,-0.025621047443339113
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9650545,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Infrastructure', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Text Messaging', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,655251,-0.011145393531976808
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9716468,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'learning strategy', 'longitudinal design', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2019,619763,0.06052222238243745
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9445485,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'patient subsets', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'readmission risk', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,376490,0.0669781854688351
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9579181,R01LM012918,"['Adult', 'Adverse drug event', 'Adverse effects', 'Algorithms', 'Apache', 'Area', 'Biological Neural Networks', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'Supervision', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'new technology', 'news', 'novel', 'open source', 'point of care', 'social media', 'software systems', 'statistics', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2018,416066,0.022059931157974718
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9547946,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2018,1542081,0.006535932008150556
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9534183,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2018,387966,0.023896295021919662
"Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance PROJECT SUMMARY The Center for Medicare and Medicaid Services Quality Payment Program is designed to motivate healthcare providers to adhere to best practices in clinical healthcare and patient safety. Unfortunately, extracting quality measures data from the clinical record is burdensome and as such, participation among clinical healthcare providers is suboptimal. Our aim is to develop a system to facilitate automatic extraction of quality data. This will reduce the burden of data collection and help remove the barrier to participation that keeps more providers from participating in the program. The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. We envision this to be an effective research partnership that leverages the complementary assets of SaferMD, a small business unit, and the University of Michigan, a non-profit research institution, to develop and evaluate a prototype tool to extract clinical quality measures data, and increase participation in the Quality Payment Program. PROJECT NARRATIVE The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. The project will develop algorithms to identify fields relevant for quality measures and develop tools to extract and analyze these data elements from large sets of radiology reports. Finally, the proposed work will initiate the extracted measures into existing quality service offerings by SaferMD. Successful completion of this project will advance the tools available for CMS clients to achieve higher adherence and compliance to the quality payment initiatives and help public health officials and policy developers advance the meaningful use of electronic health records.",Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance,9677579,R41LM013050,"['Address', 'Adherence', 'Algorithms', 'Benchmarking', 'Businesses', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Development', 'Disease', 'Documentation', 'Electronic Health Record', 'Elements', 'Experimental Models', 'Funding', 'Goals', 'Guidelines', 'Health Personnel', 'Healthcare', 'Human', 'Incentives', 'Institution', 'Label', 'Leadership', 'Manuals', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Policies', 'Procedures', 'Process', 'Production', 'Provider', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Role', 'Running', 'Semantics', 'Services', 'System', 'Techniques', 'Technology', 'Telephone', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Work', 'analytical tool', 'base', 'clinical practice', 'clinically relevant', 'computerized data processing', 'dashboard', 'deep neural network', 'design', 'improved', 'interest', 'novel', 'novel strategies', 'patient safety', 'payment', 'programs', 'prototype', 'success', 'technological innovation', 'tool']",NLM,"SAFERMED, LLC",R41,2018,149953,0.047285903451623264
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9418526,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,16608,-0.0017700080410150319
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9698030,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,874586,-0.0017700080410150319
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9390046,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,578454,0.045041443950685434
"Bio Text NLP ﻿    DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9477110,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2018,548298,0.04438837117050075
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9530276,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2018,221909,0.05052412751075804
NIST Assistance with NTP SR Automation NIEHS seeks advice from NIST in the areas of human language technology and natural language processing component evaluations that support the measurement of systems that automatically extract toxicology information from publications to support the complex human task of systematic review of literature. NIST is positioned to assist NIEHS building upon existing test and evaluation infrastructure through its Text Analysis Conference (TAC) program. NIST is coordinating the 2019 Systematic Review Information Extraction evaluation (SRIE 2019) task for NIEHS as part of the Retrieval Group’s Text Analysis Conference (TAC) program. This coordination includes advising NIEHS on developing annotation guidelines; advising NIEHS on dataset construction and distribution; writing guidelines for the evaluation task; developing scoring methods and supporting software; including the evaluation task as part of the TAC program and call for participation; accepting participant submissions in the evaluation; evaluating those submissions; and reporting results of the evaluation. NIST and NIH will design an evaluation task in this domain. n/a,NIST Assistance with NTP SR Automation,9794240,ES18001002,"['Advertisements', 'Area', 'Automation', 'Complex', 'Computer software', 'Data Set', 'Development', 'Evaluation', 'Guidelines', 'Human', 'Language', 'Measurement', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Participant', 'Positioning Attribute', 'Preparation', 'Publications', 'Reporting', 'Research', 'Research Infrastructure', 'Retrieval', 'Review Literature', 'Scoring Method', 'System', 'Technology', 'Testing', 'Text', 'Toxicology', 'United States National Institutes of Health', 'Writing', 'biomedical informatics', 'design', 'programs', 'symposium', 'systematic review']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2018,200000,0.037623582586440614
"Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis PROJECT SUMMARY Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with chronic aphasia in a number of small studies, many of which did not include a control group. Although the treatment appears promising, data to date do not permit an adequate assessment of the utility of the technique. We propose to study the effects of TMS combined with Constraint Induced Language Therapy (CILT) in 75 subjects with chronic aphasia. Subjects will be randomized in a 2:1 ratio to TMS with CILT or sham TMS with CILT. One Hz TMS at 90% motor threshold will be delivered to the right inferior frontal gyrus for 20 minutes in 10 sessions over 2 weeks; language therapy will be provided for one hour immediately after the conclusion of each session of TMS. Change from baseline in the Western Aphasia Battery Aphasia Quotient at 6 months after the end of TMS treatment will serve as the primary outcome measure. A secondary aim is to identify anatomic and behavioral predictors of response to treatment. Finally, a third aim is to identify the mechanism underlying the beneficial effect of the treatment using a variety of imaging techniques. Subjects who have no contraindication to the MRI will undergo fMRI imaging prior to and at 6 months after therapy. Using modern network analyses and robust machine learning techniques we will identify changes in the strengths of connections between nodes in the language network to address specific hypotheses regarding the effects of TMS and CILT on brain organization that are associated with beneficial response to treatment. PROJECT NARRATIVE Although Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with aphasia in many small studies, its general clinical utility has not been established. We propose to study the effects of TMS combined with Constraint Induced Language Therapy in a double-blinded study of 75 subjects with chronic aphasia. Additional aims are to identify anatomic and behavioral predictors of response to treatment and identify the mechanisms underlying the beneficial effect of using modern neuroimaging techniques.",Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis,9596726,R01DC016800,"['Acquired Language Disorders', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Aphasia', 'Behavioral', 'Brain', 'Brain imaging', 'Chronic', 'Clinical', 'Control Groups', 'Data', 'Disease', 'Double-Blind Method', 'Functional Magnetic Resonance Imaging', 'Hour', 'Image', 'Imaging Techniques', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Investigation', 'Language', 'Language Therapy', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modernization', 'Motor', 'Neurosciences', 'Outcome Measure', 'Participant', 'Pathway Analysis', 'Performance', 'Persons', 'Prevalence', 'Procedures', 'Psycholinguistics', 'Randomized', 'Rehabilitation therapy', 'Research Design', 'Research Personnel', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Techniques', 'Testing', 'Therapeutic Effect', 'Transcranial magnetic stimulation', 'Work', 'aphasia recovery', 'behavioral neurology', 'clinical investigation', 'effective therapy', 'improved', 'insight', 'interest', 'neuroimaging', 'neuroregulation', 'predicting response', 'primary outcome', 'relating to nervous system', 'response', 'treatment effect', 'treatment response', 'white matter']",NIDCD,UNIVERSITY OF PENNSYLVANIA,R01,2018,609151,0.025170614964850332
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9421556,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,793522,0.017291797957611314
"Exploring the evolving relationship between tobacco, marijuana and e-cigarettes Abstract The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana products (respectively). In order to understand this changing landscape we need new, ﬂexible, and responsive research methods capable of rapidly providing insights into product initiation patterns, use patterns, and cessation strategies. Social media — here deﬁned as including internet discussion forums — provides a ready-made source of abundant, naturalistic, longitudinal, publicly accessible, ﬁrst-person narratives with which to understand health behaviours and attitudes. We propose to use a combination of qualitative methods and automated natural language processing techniques to investigate online discussion forums devoted to tobacco, marijuana, and e-cigarettes in order to understand user trajectories through the three product categories. PROJECT NARRATIVE The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana (respectively). In order to make sense of this rapidly changing landscape, we need new, ﬂexible, and responsive research methods capable of providing insights into tobacco, marijuana, and e- cigarette product use patterns. We propose to use a combination of qualitative and automated natural language processing techniques to investigate online discussion forums related to tobacco, marijuana, and e-cigarettes in order to better understand user trajectories through these different product classes.","Exploring the evolving relationship between tobacco, marijuana and e-cigarettes",9530020,R21DA043775,"['Adolescent and Young Adult', 'Adult', 'Age', 'Algorithms', 'Attitude to Health', 'Categories', 'Chronic Bronchitis', 'Code', 'Data', 'Data Science', 'Devices', 'Educational Status', 'Electronic cigarette', 'Health', 'Health behavior', 'High School Student', 'Individual', 'Internet', 'Manuals', 'Marijuana', 'Modeling', 'Multiple Marriages', 'Natural Language Processing', 'Pattern', 'Persons', 'Population', 'Qualitative Methods', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Role', 'Sampling', 'Smoking', 'Source', 'Surgeon', 'Techniques', 'Therapeutic', 'Tobacco', 'Tobacco use', 'Training', 'Work', 'base', 'cigarette smoking', 'combustible cigarette', 'electronic cigarette use', 'flexibility', 'high school', 'innovation', 'insight', 'man', 'marijuana use', 'nicotine replacement', 'smoking cessation', 'social media']",NIDA,UNIVERSITY OF UTAH,R21,2018,201771,0.024758290354589423
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9522332,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2018,666236,0.09711183279416773
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9612777,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2018,39939,0.018288544732774845
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9461502,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,607626,0.023671225958405855
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9470863,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,606853,0.07499281276017103
"Statistical approaches to linguistic pattern learning PROJECT SUMMARY The long-term aim of the proposed research is to provide an account of how children learn the grammatical structure of their native language from distributional information in linguistic input, and also how these learning mechanisms may differ from those of adult learners. Distributional information is the patterning of elements in a large corpus of sentences. We hypothesize that learners acquire aspects of language structure from the statistics arising from this distributional information, such as which elements co-occur, what positions they regularly occupy in a word or sentence, and with what neighboring elements they frequently occur. Our program of research to date has focused on word segmentation (how learners determine which sound sequences form words) and on word categories (how learners determine which words form grammatical categories such as noun and verb). This work has documented the power and robustness of infants’, children’s, and adults’ ability to use complex distributional information to discover these aspects of language. We now propose to extend our research in new directions, to examine two crucial aspects of learning higher- level linguistic structure. In Part 1 we study the factors that lead learners to generalize a novel inflectional morpheme (like –s for noun plurals) to novel words. In Part 2 we examine how learners acquire phrases and simple hierarchical structure in sentences, and we ask what leads learners to prefer the types of phrase and hierarchical structures that are most common in natural languages.  In our proposed studies we test our hypotheses using miniature artificial language paradigms that afford control over the distributional cues in the input, something that is virtually impossible using only data from natural language learning. In each experiment, participants listen to utterances in a miniature language and then produce their own utterances or make judgments about their acceptability. Crucially, during the learning phase they hear only a sample of the possible utterances that are legal in the artificial language; some are withheld for use in a later post-test, to determine whether learners generalize what they have observed to novel instances (and if so, to which types of novel instances). We have developed highly successful paradigms for engaging young children in miniature language studies, and we have demonstrated important differences between child and adult language learners in these studies. We will also present children and adults with comparable learning paradigms in the visual-motor domain, to assess the time-course of the learning process and the specificity or generality of the results using auditory linguistic materials. Taken together, the results of these studies will document the key variables that enable a distributional learning mechanism to acquire the structure of words (inflectional morphology) and sentences (phrase and hierarchical structure) and will highlight the ways these mechanisms may differ over age and stimulus domain. PROJECT NARRATIVE  The study of age effects in language acquisition can help to determine the timing of optimal language input for bilingual children, deaf children, and children with communicative disabilities. Our findings on statistical learning of words, word categories, morphology, and sentence structure are also highly relevant to understanding language disorders, and our paradigms are widely used for identifying and treating children with difficulties, delays, and disorders of language acquisition. As research in language acquisition has moved from measuring stages of acquisition to understanding the processes by which languages are learned, our proposed studies will make important contributions to understanding where these processes break down and how principles of statistical learning can be used for treatment and rehabilitation.",Statistical approaches to linguistic pattern learning,9471944,R01HD037082,"['Adult', 'Age', 'Auditory', 'Categories', 'Child', 'Clinic', 'Complex', 'Cues', 'Data', 'Diagnostic tests', 'Elements', 'Goals', 'Hearing', 'Hearing Impaired Persons', 'Infant', 'Information Distribution', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Production', 'Productivity', 'Property', 'Rehabilitation therapy', 'Research', 'Sampling', 'Scheme', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Variant', 'Weight', 'Work', 'age effect', 'base', 'bilingualism', 'disability', 'experimental study', 'innovation', 'interest', 'lexical', 'natural language', 'novel', 'phrases', 'programs', 'sound', 'statistics', 'virtual', 'visual motor', 'word learning']",NICHD,GEORGETOWN UNIVERSITY,R01,2018,594063,0.0538099740090381
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9533881,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2018,266324,0.04882547898952155
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9454246,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,461012,0.02440719796815058
"Probabilistic learning in developmental language disorder Project Summary/Abstract Currently, we lack an understanding of why grammatical deficits, particularly, are the primary deficit in developmental language disorder in children, and we also lack effective clinical treatment for these deficits. Recent studies have suggested that grammar may be impaired because of its statistical properties, which may be difficult for children with this disorder to learn or attend to. However, we do not yet understand what exactly about statistical input is difficult, and therefore face a gap in determining theoretical mechanisms that can explain the profile of developmental language disorder. In the proposed research, we explore the hypothesis that manipulations in the statistical properties of linguistic input may facilitate grammar learning in children with developmental language disorder. We will test this hypothesis through the following aims: We will compare learning for deterministic versus probabilistic statistical information to determine which type is more easily learned by children with developmental language disorder. We will compare learning for dependencies at different distributions to determine if children with developmental language disorder benefit from certain statistical structures. We will address these aims through two studies: an artificial grammar learning task and a sentence processing task with eye-tracking. These studies are innovative because they use tasks from basic research on language acquisition and processing to isolate aspects of linguistic input that could improve learning in developmental language disorder. Identifying the characteristics of linguistic information that are particularly problematic or relatively helpful for children with developmental language disorder as they learn grammar can help us understand where and how grammatical deficits in this population arise. Findings will be impactful because they may lead to more effective treatment through control of variables that can be simply managed in clinical settings, e.g. how often a word appears in one grammatical structure compared with another. The training provided in this proposal will provide theoretical and technical training in intervention research, working with individuals with developmental language disorder, and using real-time technologies to study language. Project Narrative Language development plays a critical role in a child’s ultimate academic and social success. A lack of effective treatment for the most prominent deficits in children with developmental language disorder represents a critical barrier to these children reaching their full potential as adults. By identifying and distinguishing the properties of language that are particularly effortful as well as those that are relatively easy for these children to learn, we can develop our understanding of learning in this disorder, and potentially make language treatment more effective.",Probabilistic learning in developmental language disorder,9609288,F32DC017373,"['Address', 'Adult', 'Basic Science', 'Characteristics', 'Child', 'Clinical', 'Clinical Treatment', 'Communication', 'Cues', 'Dependence', 'Disease', 'Exposure to', 'Eye', 'Face', 'Impairment', 'Individual', 'Intervention Studies', 'Laboratories', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Outcome', 'Outcome Measure', 'Participant', 'Pattern', 'Play', 'Population', 'Process', 'Property', 'Research', 'Role', 'Science', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'clinically significant', 'design', 'educational atmosphere', 'effective intervention', 'effective therapy', 'farmer', 'improved', 'innovation', 'insight', 'language comprehension', 'language processing', 'peer', 'social', 'specific language impairment', 'statistics', 'success', 'theories']",NIDCD,UNIVERSITY OF ARIZONA,F32,2018,58282,0.025979789059684736
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9379468,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2018,340010,0.08649717265731167
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9506574,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect', 'treatment optimization']",NIDCD,UNIVERSITY OF ARIZONA,R01,2018,606922,0.028692101656762472
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9393259,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2018,268713,0.04795808047106805
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9432500,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,651980,-0.011145393531976808
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9337267,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face Processing', 'Goals', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability', 'word learning']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,463061,0.020495642744223882
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9254614,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,377260,0.0669781854688351
"IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP n/a","IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP",9581371,61201400011I,"['Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N01,2017,9923,0.09426594481079512
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9385056,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Biological Preservation', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2017,1589604,0.006535932008150556
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9325065,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2017,387966,0.023896295021919662
"From genomics to natural language processing: A protected environment for research computing in the health science NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Health sciences researchers are often required to manage, mine, and analyze restricted patient data (Protected Health Information, PHI) to facilitate and advance their research aims. They are often required to do this without access to central information technology expertise or resources to facilitate their research aims. These researchers are often left to their own devices to “solve” their research compute and data needs and are challenged due to lack of available resources, barriers from central IT, and/or lack of knowledge of available resources. A further challenge is that “small” data sets— data that researchers could formerly handle on office resources—have morphed and grown into the big data domain through the explosion of technical advances and significant expansion in various research directions. Examples include: genomics research, image analysis, simulation, natural language processing, and mining of EMRs. Therefore, the need exists to develop a framework for managing and processing this data securely and reliably. This S10 equipment proposal is to replace the “protected environment” (PE) prototype the University of Utah’s Center for High Performance Computing (CHPC) and Department of Biomedical Informatics built six years ago and has operated since. The PE consists of both high performance computing and virtual machine (VM) components and associated storage sufficient to manage, protect and analyze HIPAA protected health information. This environment has been very successful and has grown significantly in scope. CHPC isolated this protected environment in the secured University of Utah Downtown Data Center and setup a network protected logical partition that provided research groups specific access to individual data sets. As the environment and technology developed, CHPC added additional security features such as two-factor authentication for entry and audit/monitoring. Unfortunately, the prototype has reached the point where demand is surpassing capability and all the hardware is aged and off-warranty. To give an idea of users of the virtual machine farm component, the Biomedical Informatics Core (BMIC) REDCap (Research Electronic Data Capture) environment for data collection has over 2,500 users in 1,500 projects supporting over $25M in NIH funding at the University of Utah, including support for more than 25 active NIH R-01 grants. Moreover, the HIPAA compliant protected environment was a key factor that aided passing the recent University of Utah HIPAA audit. The “protected environment” also helped the University of Utah Health Sciences Center and the BMIC justify the NCATS Center Clinical and Translational Science award (1ULTR001067). NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Project Narrative: The proposed “Protected Environment” instrument will provide research computing and data management capabilities for health sciences researchers to properly manage, secure, and analyze HIPAA regulated protected health information. The technology will not only support a large number of clinical trials, but also enable research in Human Genetics and Natural Language Processing of electronic health records.",From genomics to natural language processing: A protected environment for research computing in the health science,9274445,S10OD021644,"['Award', 'Big Data', 'Clinical Sciences', 'Data', 'Data Collection', 'Data Set', 'Devices', 'Environment', 'Equipment', 'Explosion', 'Farming environment', 'Funding', 'Genomics', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'High Performance Computing', 'Image Analysis', 'Individual', 'Information Technology', 'Knowledge', 'Left', 'Mining', 'Monitor', 'Natural Language Processing', 'Patients', 'Research', 'Research Personnel', 'Resources', 'Secure', 'Security', 'Technology', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Utah', 'aged', 'biomedical informatics', 'computerized data processing', 'electronic data', 'prototype', 'simulation', 'virtual']",OD,UNIVERSITY OF UTAH,S10,2017,493595,0.02987123498651862
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9190384,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'cost', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,1177432,-0.0017700080410150319
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9191358,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,602469,0.045041443950685434
"Bio Text NLP ﻿    DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9442241,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2017,57870,0.04438837117050075
"Bio Text NLP ﻿    DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9266490,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2017,552544,0.04438837117050075
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9199581,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Injectable', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,798827,0.017291797957611314
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9311162,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,608789,0.023671225958405855
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9313700,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2017,267749,0.04882547898952155
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9249484,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,461012,0.02440719796815058
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9307257,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,636163,0.07499281276017103
"Distributional Learning in Children with Language Impairment Project Summary/Abstract Statistical learning experiments have demonstrated that children and infants are sensitive to the types of statistical regularities found in natural language. These experiments often rely on statistical information based on linear dependencies, e.g. that x predicts y either immediately or after some intervening items, whereas learning to creatively use language relies on the ability to form grammatical categories (e.g. verbs, nouns) that share distributions. Distributional learning has not been explored in children or individuals with language impairment. The proposed research can reveal new findings regarding language acquisition and use in these populations. Proposed statistical learning deficits in individuals with language impairment (LI) are thought to have downstream effects causing poorer comprehension, but this relationship has not been experimentally shown. In this project, children with and without LI and their typically developing (TD) peers will complete an online comprehension task that employs natural language and an artificial grammar learning task that employs a made-up language. In the online comprehension task, participants use a computer mouse to choose a preferred interpretation of a sentence that is ambiguous, but that most adults would interpret a certain way due to the distributional properties of the verb, an effect termed verb bias. It has not been shown whether individuals LI are sensitive to verb bias effects, but we predict children with LI will be less sensitive than peers on the basis of previous work showing deficits with verb use and overall poorer linguistic experience in this population. In the artificial grammar learning task, participants will be tested to determine if they have learned the statistical regularities of trained stimuli and formed categories based upon these regularities. We predict TD participants will form more robust categories. It has not been shown whether individuals with LI are worse at utilizing distributional information from novel input, but poor performance on other statistical learning tasks by this population suggests a deficit. We will use measurements from both tasks to verify a relationship between them, for the additional goal of showing that language comprehension and statistical learning are related. This study will provide information about differences between children with LI and their TD peers in the ability to use distributional information from both accumulated and novel input. To this end, we will discover the role of input and experience in using distributional information in linguistic environments. Project Narrative The proposed project will provide information about the extent to which children with and without language impairment utilize distributional information in the input, specifically as regards to language. Problems with language learning are correlated with long-term academic and social difficulties, and a better understanding of how statistical information like words’ distribution is processed and utilized by individuals with language impairment can shed insight into the role of the input in language learning and use. This information could lead to intervention techniques that manipulate distributional information in order to facilitate language development and improve comprehension in children with language impairment.",Distributional Learning in Children with Language Impairment,9352674,F31DC015370,"['Adult', 'Categories', 'Cereals', 'Child', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Cues', 'Dependency', 'Development', 'Eating', 'Environment', 'Eye', 'Failure', 'Future', 'Goals', 'Hearing', 'Individual', 'Infant', 'Information Distribution', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mus', 'Nursery Schools', 'Participant', 'Performance', 'Persons', 'Population', 'Probability', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'base', 'comprehension deficit', 'experience', 'experimental study', 'farmer', 'improved', 'insight', 'language comprehension', 'language impairment', 'natural language', 'novel', 'peer', 'social', 'sound', 'syntax', 'teacher', 'therapy design']",NIDCD,UNIVERSITY OF IOWA,F31,2017,24909,0.07130540630731344
"""Mechanisms of Early Bilingual Language Acquisition"" ﻿    DESCRIPTION (provided by applicant): A majority of children worldwide learn more than one language (Grosjean, 2010), yet theories of language acquisition treat monolingualism as the standard learning model. Bilingualism is highly common, but the mechanisms that drive bilingual learning are not yet well understood. In order to develop rich theories of language acquisition, it is necessary to include a full consideration of the demands of bilingual learning environments and how learners cope with these demands.  The proposed research project seeks to fill this theoretical gap by investigating bilingual statistical learning at the very early stages of languag acquisition. Statistical learning entails discovering structure by tracking patterns that are preset in the input. Statistical learning is a popular framework that has received a great deal of attention for its potential to explain how infants and children acquire many dimensions of linguistic structure. Infants are remarkably skilled at tracking regularities. However, the literatre has not yet addressed how bilingualism affects the ability to extract statistical regularities in linguistic input. The demands are substantially greater for bilinguals than for monolinguals. They must track two separate sets of regularities for every aspect of linguistic structure, from sounds to words to grammar. This research will examine two processes that are fundamental for early language acquisition, the ability to detect words in fluent speech and the ability to associate word forms with meanings. The experiments will address how dual language input affects infants' ability to perform these tasks. In addition, both monolingual and bilingual infants will participate, providing a window on how bilingual experience affects infants' tracking of regularities in dual languages. The project will also explore what cognitive processes support bilingual infants' ability to learn effectively in two immensely complex linguistic systems, focusig on how cognitive control and vocabulary composition relate to statistical learning skills in the laboratory.  In addressing a theoretical gap, the proposed research also has substantial significance for public health. This work will reveal mechanisms that infants use to learn and the conditions that support or hinder bilingual learning. These contributions have potential to affect the design and implementation of early bilingual education programs. In addition, this work will elucidate the mechanisms that typically developing infants use to acquire language, which has applied value for the study of language impairments. Understanding the underlying processes of typical development is crucial for understanding the development of populations who are not acquiring language on a typical course. It is important to know how learning typically proceeds in order to identify potential underlying deficits in learning impairments. PUBLIC HEALTH RELEVANCE: A majority of children worldwide are bilingual, yet there is limited understanding of how bilinguals learn. This work addresses a crucial gap in accounts of language acquisition and will inform programs for bilingual education. In addition, the research will support the search for underlying deficits in children with language impairments by characterizing the mechanisms that drive typical development.","""Mechanisms of Early Bilingual Language Acquisition""",9242682,R03HD084941,"['Address', 'Affect', 'Attention', 'Child', 'Complex', 'Conflict (Psychology)', 'Controlled Vocabulary', 'Cues', 'Development', 'Dimensions', 'Education', 'Environment', 'Future', 'Impairment', 'Infant', 'Information Distribution', 'Knowledge', 'Label', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Learning Skill', 'Linguistics', 'Machine Learning', 'Modeling', 'Nature', 'Pattern', 'Performance', 'Population', 'Process', 'Public Health', 'Research', 'Research Project Grants', 'Shapes', 'Speech', 'Stream', 'Structure', 'System', 'Testing', 'Text', 'Vocabulary', 'Work', 'base', 'bilingualism', 'cognitive control', 'cognitive development', 'cognitive function', 'cognitive process', 'cognitive system', 'design', 'developmental psychology', 'educational atmosphere', 'executive function', 'experience', 'experimental study', 'heuristics', 'infancy', 'language impairment', 'novel', 'phonology', 'programs', 'public health relevance', 'sound', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2017,78500,0.06753778325828017
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9297279,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect']",NIDCD,UNIVERSITY OF ARIZONA,R01,2017,606922,0.028692101656762472
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9178665,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2017,340010,0.08649717265731167
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9234982,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2017,293203,0.04795808047106805
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9233069,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,652111,-0.011145393531976808
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustics', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Models', 'Birds', 'Categories', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computational Technique', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrophysiology (science)', 'Elements', 'Environment', 'Failure', 'Foundations', 'Goals', 'Heart', 'Human', 'Individual', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Nuclear', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Population Dynamics', 'Process', 'Property', 'Quality of life', 'Research', 'Role', 'Services', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Structure', 'Sturnus vulgaris', 'Superior temporal gyrus', 'System', 'Systems Development', 'Techniques', 'Testing', 'Time', 'Training', 'Transition Elements', 'Work', 'auditory processing', 'bird song', 'cognitive process', 'experimental study', 'hearing impairment', 'improved', 'language processing', 'microstimulation', 'model development', 'neural circuit', 'neural patterning', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,-0.056822800582467664
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9132834,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model building', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,463405,0.020495642744223882
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions.         PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.            ",Natural language processing for characterizing psychopathology,9105846,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronics', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Process', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Severities', 'Stratification', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'cohort', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2016,413500,0.0669781854688351
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9115996,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'profiles in patients', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2016,387966,0.023896295021919662
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9275795,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,305257,-0.0017700080410150319
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,8976618,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,832278,-0.0017700080410150319
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment.         PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.                ",Automatic Voice-Based Assessment of Language Abilities,9020029,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Only Child', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Sign Language', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'Writing', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'follow-up', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'research study', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,638494,0.045041443950685434
"Bio Text NLP ﻿    DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9065611,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Process', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'abstracting', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'meetings', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2016,548438,0.04438837117050075
"Dynamic behavioral and neural effects of cognitive control on language processing DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications. PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.",Dynamic behavioral and neural effects of cognitive control on language processing,9116243,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2016,60210,0.05300624278778934
"Utilizing social media as a resource for mental health surveillance DESCRIPTION (provided by applicant):  Major depressive disorder is one of the most common debilitating illnesses in the United States, with a lifetime prevalence of 16.2%. Currently, nationwide mental health surveillance takes the form of large-scale telephone- based surveys. These surveys have high running costs and require teams of human telephone operators. Even the largest system, the Behavioral Risk Factor Surveillance System, reaches only 0.13% of the US population. Twitter (and other microblog services) offers a rich, if terse, multilingual source of real time data for public health surveillance. Natural Language Processing (NLP) provides techniques and resources to ""unlock"" data from text. We propose using Twitter and NLP as a cost-effective and flexible approach to augmenting current telephone- based surveillance methods for population level depression monitoring.         This grant application has two major strands. First, investigating ethical issues and challenges to privacy that emerge with the use of Twitter data for public health surveillance (Aim One). Second, developing techniques and resources for real-time public health surveillance for mental illness from Twitter (Aim Two &Aim Three). Aim One seeks to investigate and codify our responsibilities as researchers towards Twitter users by engaging with those users directly. With Aim Two, we will build and evaluate Natural Language Processing resources - algorithms, lexicons and taxonomies - to support the identification of depression symptoms in Twitter data. For Aim Three, we will build and evaluate Natural Language Processing modules and services that use Twitter as a data source for monitoring depression levels in the community. The significance of the proposed work lies in three areas. First, our investigations - both empirical and theoretical - will explore ethical issues in the use of Twitter for public health surveillance. This work has the potential to guide future research in the area. Second, in developing and evaluating algorithms and resources for identifying depression from tweets, we are contributing foundational work to the field of NLP. Third, developing these algorithms and resources will provide the bedrock for building social media based surveillance systems which will provide a cost effective means of augmenting current mental health surveillance practice. This proposal is innovative in both its application area (microblogs have not been used before for mental health surveillance), its focus on using NLP to identify depressive symptoms for public health, and in the central role that qualitative bioethical research will play in guiding the work. Project Narrative The proposed research focuses on using advanced Natural Language Processing methods to mine microblog data - in this case, Twitter - for mental health surveillance (specifically, depression surveillance), in order to augment current telephone-based mental health surveillance systems. The research has public health at its core.",Utilizing social media as a resource for mental health surveillance,9127812,R00LM011393,"['Algorithms', 'Applications Grants', 'Area', 'Attitude', 'Behavioral Risk Factor Surveillance System', 'Broadcast Media', 'Cities', 'Cognitive', 'Communities', 'County', 'Data', 'Data Sources', 'Dental', 'Development', 'Disasters', 'Earthquakes', 'Electronic Health Record', 'Epidemiology', 'Ethical Issues', 'Ethics', 'Exercise', 'Guidelines', 'Health', 'Human', 'Influenza A Virus, H1N1 Subtype', 'Interview', 'Investigation', 'Linguistics', 'Location', 'Major Depressive Disorder', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Mining', 'Monitor', 'Natural Language Processing', 'Participant', 'Phase', 'Play', 'Population', 'Population Surveillance', 'Prevalence', 'Privacy', 'Process', 'Psyche structure', 'Public Health', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Scheme', 'Services', 'Smoking Status', 'Source', 'Surveillance Methods', 'Surveys', 'System', 'Taxonomy', 'Techniques', 'Telephone', 'Text', 'Time', 'United States', 'Update', 'Work', 'base', 'center for epidemiological studies depression scale', 'cost', 'cost effective', 'depressive symptoms', 'flexibility', 'innovation', 'lexical', 'social media', 'syndromic surveillance', 'text searching', 'tool', 'ward']",NLM,UNIVERSITY OF UTAH,R00,2016,225884,0.025232819513963896
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9029656,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Process', 'Public Health', 'Research', 'Semantics', 'Solid', 'Stream', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,844963,0.017291797957611314
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9116242,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Phonetics', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'Variant', 'clinical application', 'clinical practice', 'coping', 'critical developmental period', 'design', 'evidence base', 'experience', 'hearing impairment', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'research study', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2016,263788,0.04882547898952155
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk.         PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.                ",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9065021,R01AI117011,"['Accounting', 'Animals', 'Applied Research', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Taxon', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'improved', 'information model', 'interest', 'journal article', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2016,479735,0.02440719796815058
"A Shared Database for the Study of Phonological Development DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",A Shared Database for the Study of Phonological Development,8984169,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Apraxias', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Discourse analysis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2016,270581,0.05527032703554753
"""Mechanisms of Early Bilingual Language Acquisition"" ﻿    DESCRIPTION (provided by applicant): A majority of children worldwide learn more than one language (Grosjean, 2010), yet theories of language acquisition treat monolingualism as the standard learning model. Bilingualism is highly common, but the mechanisms that drive bilingual learning are not yet well understood. In order to develop rich theories of language acquisition, it is necessary to include a full consideration of the demands of bilingual learning environments and how learners cope with these demands.  The proposed research project seeks to fill this theoretical gap by investigating bilingual statistical learning at the very early stages of languag acquisition. Statistical learning entails discovering structure by tracking patterns that are preset in the input. Statistical learning is a popular framework that has received a great deal of attention for its potential to explain how infants and children acquire many dimensions of linguistic structure. Infants are remarkably skilled at tracking regularities. However, the literatre has not yet addressed how bilingualism affects the ability to extract statistical regularities in linguistic input. The demands are substantially greater for bilinguals than for monolinguals. They must track two separate sets of regularities for every aspect of linguistic structure, from sounds to words to grammar. This research will examine two processes that are fundamental for early language acquisition, the ability to detect words in fluent speech and the ability to associate word forms with meanings. The experiments will address how dual language input affects infants' ability to perform these tasks. In addition, both monolingual and bilingual infants will participate, providing a window on how bilingual experience affects infants' tracking of regularities in dual languages. The project will also explore what cognitive processes support bilingual infants' ability to learn effectively in two immensely complex linguistic systems, focusig on how cognitive control and vocabulary composition relate to statistical learning skills in the laboratory.  In addressing a theoretical gap, the proposed research also has substantial significance for public health. This work will reveal mechanisms that infants use to learn and the conditions that support or hinder bilingual learning. These contributions have potential to affect the design and implementation of early bilingual education programs. In addition, this work will elucidate the mechanisms that typically developing infants use to acquire language, which has applied value for the study of language impairments. Understanding the underlying processes of typical development is crucial for understanding the development of populations who are not acquiring language on a typical course. It is important to know how learning typically proceeds in order to identify potential underlying deficits in learning impairments.         PUBLIC HEALTH RELEVANCE: A majority of children worldwide are bilingual, yet there is limited understanding of how bilinguals learn. This work addresses a crucial gap in accounts of language acquisition and will inform programs for bilingual education. In addition, the research will support the search for underlying deficits in children with language impairments by characterizing the mechanisms that drive typical development.        ","""Mechanisms of Early Bilingual Language Acquisition""",9112198,R03HD084941,"['Accounting', 'Address', 'Affect', 'Attention', 'Child', 'Complex', 'Conflict (Psychology)', 'Controlled Vocabulary', 'Cues', 'Development', 'Dimensions', 'Education', 'Environment', 'Exhibits', 'Future', 'Impairment', 'Infant', 'Knowledge', 'Label', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Learning Skill', 'Linguistics', 'Machine Learning', 'Modeling', 'Nature', 'Pattern', 'Performance', 'Population', 'Process', 'Public Health', 'Research', 'Research Project Grants', 'Shapes', 'Speech', 'Staging', 'Stream', 'Structure', 'System', 'Testing', 'Text', 'Vocabulary', 'Work', 'base', 'bilingualism', 'cognitive control', 'cognitive development', 'cognitive function', 'cognitive process', 'cognitive system', 'coping', 'design', 'developmental psychology', 'educational atmosphere', 'executive function', 'experience', 'heuristics', 'infancy', 'language impairment', 'novel', 'phonology', 'programs', 'public health relevance', 'research study', 'sound', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2016,78438,0.06753778325828017
"Distributional Learning in Children with Language Impairment Project Summary/Abstract Statistical learning experiments have demonstrated that children and infants are sensitive to the types of statistical regularities found in natural language. These experiments often rely on statistical information based on linear dependencies, e.g. that x predicts y either immediately or after some intervening items, whereas learning to creatively use language relies on the ability to form grammatical categories (e.g. verbs, nouns) that share distributions. Distributional learning has not been explored in children or individuals with language impairment. The proposed research can reveal new findings regarding language acquisition and use in these populations. Proposed statistical learning deficits in individuals with language impairment (LI) are thought to have downstream effects causing poorer comprehension, but this relationship has not been experimentally shown. In this project, children with and without LI and their typically developing (TD) peers will complete an online comprehension task that employs natural language and an artificial grammar learning task that employs a made-up language. In the online comprehension task, participants use a computer mouse to choose a preferred interpretation of a sentence that is ambiguous, but that most adults would interpret a certain way due to the distributional properties of the verb, an effect termed verb bias. It has not been shown whether individuals LI are sensitive to verb bias effects, but we predict children with LI will be less sensitive than peers on the basis of previous work showing deficits with verb use and overall poorer linguistic experience in this population. In the artificial grammar learning task, participants will be tested to determine if they have learned the statistical regularities of trained stimuli and formed categories based upon these regularities. We predict TD participants will form more robust categories. It has not been shown whether individuals with LI are worse at utilizing distributional information from novel input, but poor performance on other statistical learning tasks by this population suggests a deficit. We will use measurements from both tasks to verify a relationship between them, for the additional goal of showing that language comprehension and statistical learning are related. This study will provide information about differences between children with LI and their TD peers in the ability to use distributional information from both accumulated and novel input. To this end, we will discover the role of input and experience in using distributional information in linguistic environments. Project Narrative The proposed project will provide information about the extent to which children with and without language impairment utilize distributional information in the input, specifically as regards to language. Problems with language learning are correlated with long-term academic and social difficulties, and a better understanding of how statistical information like words’ distribution is processed and utilized by individuals with language impairment can shed insight into the role of the input in language learning and use. This information could lead to intervention techniques that manipulate distributional information in order to facilitate language development and improve comprehension in children with language impairment.",Distributional Learning in Children with Language Impairment,9255906,F31DC015370,"['Accounting', 'Adult', 'Categories', 'Cereals', 'Child', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Cues', 'Dependency', 'Development', 'Eating', 'Environment', 'Eye', 'Failure', 'Future', 'Goals', 'Hearing', 'Individual', 'Infant', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mus', 'Nursery Schools', 'Participant', 'Performance', 'Persons', 'Population', 'Probability', 'Process', 'Property', 'Qualifying', 'Research', 'Role', 'Semantics', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'abstracting', 'base', 'comprehension deficit', 'experience', 'farmer', 'improved', 'insight', 'language comprehension', 'language impairment', 'natural language', 'novel', 'peer', 'research study', 'social', 'sound', 'syntax', 'teacher', 'therapy design']",NIDCD,UNIVERSITY OF IOWA,F31,2016,31612,0.07130540630731344
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9172394,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'theories', 'treatment effect']",NIDCD,UNIVERSITY OF ARIZONA,R01,2016,606922,0.028692101656762472
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8976620,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Health', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2016,336609,0.08649717265731167
"Challenges in Natural Language Processing in Clinical Text No abstract available Challenges in Natural Language Processing for Clinical Narratives Narrative: This project aims to organize a series of shared task challenges that open electronic health records to the research community for advancing the state of the art in natural language processing in clinical records. The proposed shared tasks are complemented by workshops, conference proceedings, and journal special issues that aim to disseminate the knowledge generated by the challenges.",Challenges in Natural Language Processing in Clinical Text,9597333,R13LM011411,[' '],NLM,GEORGE MASON UNIVERSITY,R13,2016,20000,0.08363200633462482
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9038348,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,652362,-0.011145393531976808
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,9142280,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,491053,0.024941932616306277
"Neural Systems For Infant Sensitivity to Phonological Rhythmic-Temporal Patterning No abstract available PROJECT NARRATIVE  The goal of this research is to understand how all infants discover the finite set of language units in their native language from the infinite combinations of sensory stimuli around them. Specifically, we explore whether infants are sensitive to the pure timing of the stimuli (the frequency), or whether they also are sensitive to linguistic information within the stimuli (alternation of phonetic-syllabic units). The findings will help us better understand [[on a modality-free level]] how infants begin life with brain mechanisms predisposed for discovering the core [[phonological]] parts of their languages, and how we can support clinicians in identifying infants at risk for phonology-based language and reading disorders.",Neural Systems For Infant Sensitivity to Phonological Rhythmic-Temporal Patterning,9193903,F31HD087085,"['Address', 'Adult', 'Age', 'Attention', 'Auditory', 'Beginning of Life', 'Bilateral', 'Brain', 'Cell Nucleus', 'Child', 'Code', 'Cognitive', 'Complex', 'Data', 'Development', 'Elements', 'Equation', 'Eye', 'Frequencies', 'Goals', 'Growth', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Learning', 'Left', 'Life', 'Light', 'Linguistics', 'Link', 'Machine Learning', 'Modality', 'Nature', 'Near-Infrared Spectroscopy', 'Neurobiology', 'Outcome', 'Pattern', 'Phonetics', 'Play', 'Process', 'Property', 'Reading', 'Reading Disorder', 'Recruitment Activity', 'Research', 'Risk', 'Role', 'Sign Language', 'Signal Transduction', 'Site', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Superior temporal gyrus', 'System', 'Testing', 'Time', 'Tissues', 'Vision', 'Visual', 'Vocabulary', 'adjudicate', 'base', 'cognitive neuroscience', 'experience', 'gaze', 'hemodynamics', 'infancy', 'insight', 'language perception', 'neural circuit', 'novel', 'phonology', 'reading difficulties', 'relating to nervous system', 'response', 'sensory stimulus', 'social', 'sound', 'success', 'syntax']",NICHD,GALLAUDET UNIVERSITY,F31,2016,43576,0.050042786986110255
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8936515,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model building', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,448348,0.020495642744223882
"IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015. MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015 n/a","IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015.",9162846,61201400011I,"['Educational workshop', 'Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N03,2015,16100,0.11462780984579873
"Challenges in Natural Language Processing for Clinical Narratives DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges. Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8913773,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2015,19800,0.03151413032487872
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8928647,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2015,376327,0.023896295021919662
"EHR Anticoagulants Pharmacovigilance     DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page         PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.            ",EHR Anticoagulants Pharmacovigilance,8791564,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2015,864744,-0.0017700080410150319
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC). The overarching goal of this research proposal is to develop and validate Natural Language Processing (NLP) algorithms for ascertainment of use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC cases.  Successful achievement of this goal will occur through the accomplishment of the study objectives outlined below.  Objectives: 1)	 Develop Natural Language Processing (NLP) algorithms to ascertain use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC registry cases diagnosed between 09/01/2011 and 12/31/2013. 2)	Conduct a multiphase validation study of NLP algorithms for ascertainment of EGFR and ALK testing initially involving cases included in the Seattle Puget-Sound SEER registry, and posteriorly validating the NLP algorithms in the Kentucky SEER registry. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC).,9161888,61201300012I,"['Achievement', 'Algorithms', 'Cells', 'Diagnosis', 'Electronics', 'Epidermal Growth Factor Receptor', 'Goals', 'Kentucky', 'Lung', 'Molecular Profiling', 'Natural Language Processing', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Registries', 'Research Proposals', 'Staging', 'Techniques', 'Testing', 'neoplasm registry', 'sound', 'validation studies']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,N01,2015,156435,0.0269734467732626
"Bio Text NLP ﻿    DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.             Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,8819017,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Process', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'abstracting', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'meetings', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2015,548439,0.04438837117050075
"Utilizing social media as a resource for mental health surveillance DESCRIPTION (provided by applicant):  Major depressive disorder is one of the most common debilitating illnesses in the United States, with a lifetime prevalence of 16.2%. Currently, nationwide mental health surveillance takes the form of large-scale telephone- based surveys. These surveys have high running costs and require teams of human telephone operators. Even the largest system, the Behavioral Risk Factor Surveillance System, reaches only 0.13% of the US population. Twitter (and other microblog services) offers a rich, if terse, multilingual source of real time data for public health surveillance. Natural Language Processing (NLP) provides techniques and resources to ""unlock"" data from text. We propose using Twitter and NLP as a cost-effective and flexible approach to augmenting current telephone- based surveillance methods for population level depression monitoring.         This grant application has two major strands. First, investigating ethical issues and challenges to privacy that emerge with the use of Twitter data for public health surveillance (Aim One). Second, developing techniques and resources for real-time public health surveillance for mental illness from Twitter (Aim Two &Aim Three). Aim One seeks to investigate and codify our responsibilities as researchers towards Twitter users by engaging with those users directly. With Aim Two, we will build and evaluate Natural Language Processing resources - algorithms, lexicons and taxonomies - to support the identification of depression symptoms in Twitter data. For Aim Three, we will build and evaluate Natural Language Processing modules and services that use Twitter as a data source for monitoring depression levels in the community. The significance of the proposed work lies in three areas. First, our investigations - both empirical and theoretical - will explore ethical issues in the use of Twitter for public health surveillance. This work has the potential to guide future research in the area. Second, in developing and evaluating algorithms and resources for identifying depression from tweets, we are contributing foundational work to the field of NLP. Third, developing these algorithms and resources will provide the bedrock for building social media based surveillance systems which will provide a cost effective means of augmenting current mental health surveillance practice. This proposal is innovative in both its application area (microblogs have not been used before for mental health surveillance), its focus on using NLP to identify depressive symptoms for public health, and in the central role that qualitative bioethical research will play in guiding the work. Project Narrative The proposed research focuses on using advanced Natural Language Processing methods to mine microblog data - in this case, Twitter - for mental health surveillance (specifically, depression surveillance), in order to augment current telephone-based mental health surveillance systems. The research has public health at its core.",Utilizing social media as a resource for mental health surveillance,8911360,R00LM011393,"['Algorithms', 'Applications Grants', 'Area', 'Attitude', 'Behavioral Risk Factor Surveillance System', 'Broadcast Media', 'Cities', 'Cognitive', 'Communities', 'County', 'Data', 'Data Sources', 'Dental', 'Development', 'Disasters', 'Earthquakes', 'Electronic Health Record', 'Epidemiology', 'Ethical Issues', 'Ethics', 'Exercise', 'Guidelines', 'Health', 'Human', 'Influenza A Virus, H1N1 Subtype', 'Interview', 'Investigation', 'Linguistics', 'Location', 'Major Depressive Disorder', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Mining', 'Monitor', 'Natural Language Processing', 'Participant', 'Phase', 'Play', 'Population', 'Population Surveillance', 'Prevalence', 'Privacy', 'Process', 'Psyche structure', 'Public Health', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Scheme', 'Services', 'Smoking Status', 'Source', 'Surveillance Methods', 'Surveys', 'System', 'Taxonomy', 'Techniques', 'Telephone', 'Text', 'Time', 'United States', 'Update', 'Work', 'base', 'center for epidemiological studies depression scale', 'cost', 'cost effective', 'depressive symptoms', 'flexibility', 'innovation', 'lexical', 'social', 'syndromic surveillance', 'text searching', 'tool', 'ward']",NLM,UNIVERSITY OF UTAH,R00,2015,217377,0.025232819513963896
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8850708,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2015,60542,0.05300624278778934
"Computational characterization of language use in autism spectrum disorder DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features. Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.",Computational characterization of language use in autism spectrum disorder,9085493,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,99966,-0.001534272634441019
"Computational characterization of language use in autism spectrum disorder DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features. Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.",Computational characterization of language use in autism spectrum disorder,8913119,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,692720,-0.001534272634441019
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8804856,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2015,217500,0.03077222715141556
"Neurocognitive determinants of adolescent second language literacy development DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment. The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.",Neurocognitive determinants of adolescent second language literacy development,8852664,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'English Learner', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'bilingualism', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'learning ability', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2015,576358,0.11134435526479357
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods.         PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.            ","Infant statistical learning: Resilience, longevity, and specificity",8984582,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Phonetics', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'Variant', 'clinical application', 'clinical practice', 'coping', 'critical developmental period', 'design', 'evidence base', 'experience', 'hearing impairment', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'research study', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2015,241243,0.04882547898952155
"Statistical learning of multiple patterns in infants, adults, and monkeys DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.","Statistical learning of multiple patterns in infants, adults, and monkeys",8851635,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Health', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Manufactured football', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Soccer', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2015,208800,0.024349310733643877
"A Shared Database for the Study of Phonological Development DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",A Shared Database for the Study of Phonological Development,8787131,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2015,268514,0.05527032703554753
"Co-construction of lexica in primary progressive aphasia DESCRIPTION (provided by applicant): Individuals with primary progressive aphasia (PPA) present with an insidious onset and gradual loss of word finding, object naming, or word-comprehension skills which profoundly affect their verbal participation in daily activities. The overall goal of this innovative research is to take an initial step toward the creation of adaptive language prostheses that augment lexical access and word use in PPA as skills are lost. The short term objective is to determine whether individuals with mild-to-moderate PPA improve or maintain word finding skills during conversation when provided with a novel intervention tool, namely a mobile technology application called CO-CHAT that automatically presents related vocabulary to them as needed. CO-CHAT is a simulated social media app for research which creates lexical displays synthesized from a user's self-generated photos, comments from social network contacts, the device's metadata, and a curated list of key words generated with Natural Language Processing (NLP) techniques. Aim 1 addresses development of the simulated social media app with NLP applications. Aim 2 proposes a research study to determine whether people with PPA can use the CO-CHAT lexical displays to improve or maintain word finding skills in conversation. Two hypotheses will be tested: (1) The number (and percentage) of target words spoken by participants during conversations will increase when the CO-CHAT lexical displays are available~ (2) The number (and percentage) of questions needed by conversation partners to obtain information from participants about daily activities will decrease when the CO-CHAT lexical displays are available. Participants are 10 individuals with mild-to-moderate PPA (agrammatic or semantic variants) recruited from the Oregon Alzheimer's Disease Center. A withdrawal ABAB design with intra-subject and inter-subject replication is proposed. Each participant engages in community- based activities, taking photos and sending them to a simulated social network for comment. By relying on the technology's automatic manipulation of language, photos comments then are analyzed. Related words that are mined from large lexical semantic databases are placed in the lexical displays with the original photo. Participants describe the community activities to familiar partners in 5-minute conversations without technology (baseline phase A) and with CO- CHAT (experimental phase B). Visual analysis of changes across conditions and repeated measures ANOVAs evaluate intervention effects. The proposed research addresses the need to identify effective language compensation strategies to treat individuals experiencing PPA, a relatively new diagnosis for which compensatory treatment paradigms are yet to be developed. Results will support a larger research agenda to further develop adaptive assistive technologies for intervention, and to implement outcomes-based clinical studies that determine the efficacy of a stage-based longitudinal AAC/NLP intervention for patients with PPA in order to maintain vocabulary access, communication functions and social networks with mobile technology over the course of language degeneration. PUBLIC HEALTH RELEVANCE: The population of adults presenting with dementia syndromes and degenerative language disorders is increasing exponentially in the U.S., in the absence of clinical guidelines for effective language intervention. This research will provide evidence to support intervention standards with assistive technologies for persons with primary progressive aphasia, as well as provide scientific data to justify medical insurance reimbursement, and help family members advocate for increases in standard clinical care.",Co-construction of lexica in primary progressive aphasia,8852594,R21DC014099,"['Address', 'Adult', 'Advocate', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Apple', 'Clinical', 'Clinical Research', 'Cognitive', 'Communication', 'Communication Aids for Disabled', 'Communities', 'Computer software', 'Data', 'Databases', 'Dementia', 'Development', 'Devices', 'Diagnosis', 'Electronics', 'Experimental Designs', 'Family member', 'Financial compensation', 'Goals', 'Guidelines', 'Health', 'Image', 'Impairment', 'Individual', 'Insurance', 'Intervention', 'Intervention Studies', 'Language', 'Language Disorders', 'Measures', 'Medical', 'Metadata', 'Mining', 'Names', 'Natural Language Processing', 'Oregon', 'Outcome', 'Participant', 'Patients', 'Persons', 'Phase', 'Pilot Projects', 'Population', 'Primary Progressive Aphasia', 'Prosthesis', 'Published Comment', 'Recruitment Activity', 'Research', 'Research Project Grants', 'Secondary to', 'Self-Help Devices', 'Semantics', 'Social Network', 'Sodium Chloride', 'Staging', 'Structure', 'Syndrome', 'Tablets', 'Techniques', 'Technology', 'Testing', 'Transcript', 'Variant', 'Visual', 'Vocabulary', 'Withdrawal', 'alternative communication', 'base', 'clinical care', 'comprehension skill', 'computer science', 'design', 'digital', 'experience', 'handheld mobile device', 'improved', 'innovation', 'innovative technologies', 'intervention effect', 'lexical', 'mobile application', 'novel', 'research study', 'skills', 'social', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2015,194301,0.035214353003070485
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8797383,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Health', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2015,340010,0.08649717265731167
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002).         PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.                ",Clinic Interactions of a Brain-Computer Interface for Communication,8876473,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'improved', 'innovation', 'intervention program', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,665012,-0.011145393531976808
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,8920540,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,488893,0.024941932616306277
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery. PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8793776,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Health', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'behavioral outcome', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2015,386939,0.06292788483094604
"Interactive machine learning methods for clinical natural language processing     DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3.             Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8818096,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,558372,0.020495642744223882
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8669161,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2014,212994,0.027220794276146185
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8722030,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2014,260727,0.018763057928554497
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                 Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8722031,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2014,19998,0.03151413032487872
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification     DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts.         PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.                ",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8811565,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'public health relevance', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2014,460688,0.023896295021919662
"Utilizing social media as a resource for mental health surveillance DESCRIPTION (provided by applicant):  Major depressive disorder is one of the most common debilitating illnesses in the United States, with a lifetime prevalence of 16.2%. Currently, nationwide mental health surveillance takes the form of large-scale telephone- based surveys. These surveys have high running costs and require teams of human telephone operators. Even the largest system, the Behavioral Risk Factor Surveillance System, reaches only 0.13% of the US population. Twitter (and other microblog services) offers a rich, if terse, multilingual source of real time data for public health surveillance. Natural Language Processing (NLP) provides techniques and resources to ""unlock"" data from text. We propose using Twitter and NLP as a cost-effective and flexible approach to augmenting current telephone- based surveillance methods for population level depression monitoring.         This grant application has two major strands. First, investigating ethical issues and challenges to privacy that emerge with the use of Twitter data for public health surveillance (Aim One). Second, developing techniques and resources for real-time public health surveillance for mental illness from Twitter (Aim Two &Aim Three). Aim One seeks to investigate and codify our responsibilities as researchers towards Twitter users by engaging with those users directly. With Aim Two, we will build and evaluate Natural Language Processing resources - algorithms, lexicons and taxonomies - to support the identification of depression symptoms in Twitter data. For Aim Three, we will build and evaluate Natural Language Processing modules and services that use Twitter as a data source for monitoring depression levels in the community. The significance of the proposed work lies in three areas. First, our investigations - both empirical and theoretical - will explore ethical issues in the use of Twitter for public health surveillance. This work has the potential to guide future research in the area. Second, in developing and evaluating algorithms and resources for identifying depression from tweets, we are contributing foundational work to the field of NLP. Third, developing these algorithms and resources will provide the bedrock for building social media based surveillance systems which will provide a cost effective means of augmenting current mental health surveillance practice. This proposal is innovative in both its application area (microblogs have not been used before for mental health surveillance), its focus on using NLP to identify depressive symptoms for public health, and in the central role that qualitative bioethical research will play in guiding the work. Project Narrative The proposed research focuses on using advanced Natural Language Processing methods to mine microblog data - in this case, Twitter - for mental health surveillance (specifically, depression surveillance), in order to augment current telephone-based mental health surveillance systems. The research has public health at its core.",Utilizing social media as a resource for mental health surveillance,8894203,R00LM011393,"['Algorithms', 'Applications Grants', 'Area', 'Attitude', 'Behavioral Risk Factor Surveillance System', 'Broadcast Media', 'Cities', 'Cognitive', 'Communities', 'County', 'Data', 'Data Sources', 'Dental', 'Development', 'Disasters', 'Earthquakes', 'Electronic Health Record', 'Epidemiology', 'Ethical Issues', 'Ethics', 'Exercise', 'Guidelines', 'Health', 'Human', 'Influenza A Virus, H1N1 Subtype', 'Interview', 'Investigation', 'Linguistics', 'Location', 'Major Depressive Disorder', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Mining', 'Monitor', 'Natural Language Processing', 'Participant', 'Phase', 'Play', 'Population', 'Population Surveillance', 'Prevalence', 'Privacy', 'Process', 'Psyche structure', 'Public Health', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Scheme', 'Services', 'Smoking Status', 'Source', 'Surveillance Methods', 'Surveys', 'System', 'Taxonomy', 'Techniques', 'Telephone', 'Text', 'Time', 'United States', 'Update', 'Work', 'base', 'center for epidemiological studies depression scale', 'cost', 'cost effective', 'depressive symptoms', 'flexibility', 'innovation', 'lexical', 'social', 'syndromic surveillance', 'text searching', 'tool', 'ward']",NLM,UNIVERSITY OF UTAH,R00,2014,224100,0.025232819513963896
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8714196,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2014,57782,0.05300624278778934
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8714052,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,UNIVERSITY OF UTAH,R01,2014,579144,0.010732466707766892
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8708017,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2014,712942,-0.001534272634441019
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8687699,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'learning ability', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2014,596034,0.11134435526479357
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8635902,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2014,257300,0.03077222715141556
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.       PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8644282,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Manufactured football', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Soccer', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2014,208309,0.024349310733643877
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.        The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8601309,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2014,269616,0.05527032703554753
"Artificial Grammar Learning in Aphasia: An Implicit Learning Approach     DESCRIPTION (provided by applicant): Implicit learning procedures have the potential to greatly enhance language training, and yet have received little attention in the aphasia rehabilitation literature. Preliminary evidence of implicit learning ability in individuals with aphasia suggests that this approach could lead to less effortful language rehabilitation strategies, which may be used in combination with established methods of explicit treatment of grammatical ability. The long-term goal of the proposed work is to further the understanding of learning processes in aphasia, and to use that knowledge to engage patients in language learning strategies that will be most beneficial for language recovery. The specific objective of the proposed project is to test an implicit approach to artificial grammar learning in healthy and agrammatic aphasic individuals using a statistical learning paradigm. The central hypothesis is that implicit learning mechanisms, which are effective in deriving grammatical structure from statistical relationships in language, remain intact in individuals with aphasia, and that grammar learning is enhanced when passive language exposure is combined with active practice. The proposed research will be the first to test learning and short-term retention of an artificial phrae structure grammar under implicit learning conditions in individuals with agrammatic aphasia and healthy age-matched adults. Participants in this study will receive repeated passive exposure to the grammar on two consecutive days, and their acquisition and 24-hour retention of the grammatical rules will be evaluated by grammaticality judgment tests. The proposed research will also use the artificial grammar learning task with healthy young adults to test the relative effects of passive exposure to the grammar compared to active practice with feedback and a combination of both approaches. These contributions are significant because they are the first steps toward evaluation of an approach that utilizes patients' retained learning abilities and hence can improve the quality of life of individuals with aphasia.         PUBLIC HEALTH RELEVANCE: The proposed research aims to further the understanding of language learning strategies that are effective and efficient for healthy adults and for individual with impaired language as a result of brain damage. The successful completion of this project will promote innovative treatments that advance the recovery of communication abilities and hence improve the quality of life of individuals with acquired language disorders.                ",Artificial Grammar Learning in Aphasia: An Implicit Learning Approach,8642022,F31DC013204,"['Acquired Language Disorders', 'Activities of Daily Living', 'Adult', 'Affect', 'Age', 'Agrammatism', 'Aphasia', 'Attention', 'Brain Injuries', 'Child', 'Chronic', 'Communication', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Goals', 'Hour', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Literature', 'Machine Learning', 'Methods', 'Outcome', 'Participant', 'Patients', 'Perceptual learning', 'Procedures', 'Process', 'Property', 'Quality of life', 'Reaction Time', 'Recovery', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Staging', 'Stimulus', 'Stroke', 'Structure', 'Task Performances', 'Testing', 'Training', 'Work', 'aphasia rehabilitation', 'aphasic', 'base', 'design', 'improved', 'innovation', 'language training', 'learning ability', 'novel', 'public health relevance', 'rehabilitation strategy', 'sequence learning', 'young adult']",NIDCD,NORTHWESTERN UNIVERSITY,F31,2014,35352,0.06224046748270945
"Co-construction of lexica in primary progressive aphasia     DESCRIPTION (provided by applicant): Individuals with primary progressive aphasia (PPA) present with an insidious onset and gradual loss of word finding, object naming, or word-comprehension skills which profoundly affect their verbal participation in daily activities. The overall goal of this innovative research is to take an initial step toward the creation of adaptive language prostheses that augment lexical access and word use in PPA as skills are lost. The short term objective is to determine whether individuals with mild-to-moderate PPA improve or maintain word finding skills during conversation when provided with a novel intervention tool, namely a mobile technology application called CO-CHAT that automatically presents related vocabulary to them as needed. CO-CHAT is a simulated social media app for research which creates lexical displays synthesized from a user's self-generated photos, comments from social network contacts, the device's metadata, and a curated list of key words generated with Natural Language Processing (NLP) techniques. Aim 1 addresses development of the simulated social media app with NLP applications. Aim 2 proposes a research study to determine whether people with PPA can use the CO-CHAT lexical displays to improve or maintain word finding skills in conversation. Two hypotheses will be tested: (1) The number (and percentage) of target words spoken by participants during conversations will increase when the CO-CHAT lexical displays are available~ (2) The number (and percentage) of questions needed by conversation partners to obtain information from participants about daily activities will decrease when the CO-CHAT lexical displays are available. Participants are 10 individuals with mild-to-moderate PPA (agrammatic or semantic variants) recruited from the Oregon Alzheimer's Disease Center. A withdrawal ABAB design with intra-subject and inter-subject replication is proposed. Each participant engages in community- based activities, taking photos and sending them to a simulated social network for comment. By relying on the technology's automatic manipulation of language, photos comments then are analyzed. Related words that are mined from large lexical semantic databases are placed in the lexical displays with the original photo. Participants describe the community activities to familiar partners in 5-minute conversations without technology (baseline phase A) and with CO- CHAT (experimental phase B). Visual analysis of changes across conditions and repeated measures ANOVAs evaluate intervention effects. The proposed research addresses the need to identify effective language compensation strategies to treat individuals experiencing PPA, a relatively new diagnosis for which compensatory treatment paradigms are yet to be developed. Results will support a larger research agenda to further develop adaptive assistive technologies for intervention, and to implement outcomes-based clinical studies that determine the efficacy of a stage-based longitudinal AAC/NLP intervention for patients with PPA in order to maintain vocabulary access, communication functions and social networks with mobile technology over the course of language degeneration.         PUBLIC HEALTH RELEVANCE: The population of adults presenting with dementia syndromes and degenerative language disorders is increasing exponentially in the U.S., in the absence of clinical guidelines for effective language intervention. This research will provide evidence to support intervention standards with assistive technologies for persons with primary progressive aphasia, as well as provide scientific data to justify medical insurance reimbursement, and help family members advocate for increases in standard clinical care.            ",Co-construction of lexica in primary progressive aphasia,8764466,R21DC014099,"['Address', 'Adult', 'Advocate', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Apple', 'Clinical', 'Clinical Research', 'Cognitive', 'Communication', 'Communication Aids for Disabled', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Databases', 'Dementia', 'Development', 'Devices', 'Diagnosis', 'Electronics', 'Experimental Designs', 'Family member', 'Financial compensation', 'Goals', 'Guidelines', 'Image', 'Impairment', 'Individual', 'Insurance', 'Intervention', 'Intervention Studies', 'Language', 'Language Disorders', 'Measures', 'Medical', 'Metadata', 'Mining', 'Names', 'Natural Language Processing', 'Oregon', 'Outcome', 'Participant', 'Patients', 'Persons', 'Phase', 'Pilot Projects', 'Population', 'Primary Progressive Aphasia', 'Prosthesis', 'Published Comment', 'Recruitment Activity', 'Research', 'Research Project Grants', 'Secondary to', 'Self-Help Devices', 'Semantics', 'Simulate', 'Social Network', 'Sodium Chloride', 'Staging', 'Structure', 'Syndrome', 'Tablets', 'Techniques', 'Technology', 'Testing', 'Transcript', 'Variant', 'Visual', 'Vocabulary', 'Withdrawal', 'alternative communication', 'base', 'clinical care', 'computer science', 'design', 'digital', 'experience', 'handheld mobile device', 'improved', 'innovation', 'innovative technologies', 'intervention effect', 'lexical', 'mobile application', 'novel', 'public health relevance', 'research study', 'skills', 'social', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2014,234765,0.035214353003070485
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.       PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).         ",Statistical Learning in Language Acquisition,8604165,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2014,281519,0.08649717265731167
"Encoding and Processing Patient Allergy Information in EHRs     DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use.         PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.            ",Encoding and Processing Patient Allergy Information in EHRs,8741955,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2014,489854,0.024941932616306277
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453          PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8722026,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2014,342375,0.06410712345341048
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.        PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8606352,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2014,392213,0.06292788483094604
"Statistical learning, memory systems, and sleep-based memory consolidation No abstract available PUBLIC HEALTH RELEVANCE:  Difficulties with language acquisition are characteristic of a wide range of disorders, such as specific language impairment and autism, and present a major barrier to normal functioning. Statistical learning, the process of extracting complex patterns from the environment, is thought to play a critical role in language acquisition, with deficits in statistical learning potentially contributing to language-related disorders. The current proposal aims to understand how learning mode influences the memory and consolidation processes that underlie statistical learning and may ultimately inform treatments for those with language-related disorders.                ","Statistical learning, memory systems, and sleep-based memory consolidation",8783740,F32HD078223,"['Area', 'Autistic Disorder', 'Awareness', 'Basal Ganglia', 'Behavioral', 'Cerebellum', 'Characteristics', 'Cognitive', 'Conscious', 'Corpus striatum structure', 'Crude Extracts', 'Cues', 'Disease', 'Dissociation', 'Electroencephalography', 'Environment', 'Event', 'Familiarity', 'Fellowship', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Image Analysis', 'Individual', 'Instruction', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Light', 'Link', 'Machine Learning', 'Measures', 'Medial', 'Memory', 'Napping', 'Neocortex', 'Neurobiology', 'Participant', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Reaction Time', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Role', 'Sensory', 'Sleep', 'Slow-Wave Sleep', 'Speech', 'Stream', 'Structure', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Work', 'base', 'behavior measurement', 'career', 'density', 'implicit memory', 'insight', 'memory retrieval', 'operation', 'public health relevance', 'relating to nervous system', 'response', 'social', 'specific language impairment']",NICHD,NORTHWESTERN UNIVERSITY,F32,2014,51530,0.043951998994251805
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8484438,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2013,202118,0.027220794276146185
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8532984,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2013,247288,0.018763057928554497
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8538500,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2013,18400,0.03151413032487872
"Utilizing social media as a resource for mental health surveillance     DESCRIPTION (provided by applicant):  Major depressive disorder is one of the most common debilitating illnesses in the United States, with a lifetime prevalence of 16.2%. Currently, nationwide mental health surveillance takes the form of large-scale telephone- based surveys. These surveys have high running costs and require teams of human telephone operators. Even the largest system, the Behavioral Risk Factor Surveillance System, reaches only 0.13% of the US population. Twitter (and other microblog services) offers a rich, if terse, multilingual source of real time data for public health surveillance. Natural Language Processing (NLP) provides techniques and resources to ""unlock"" data from text. We propose using Twitter and NLP as a cost-effective and flexible approach to augmenting current telephone- based surveillance methods for population level depression monitoring.         This grant application has two major strands. First, investigating ethical issues and challenges to privacy that emerge with the use of Twitter data for public health surveillance (Aim One). Second, developing techniques and resources for real-time public health surveillance for mental illness from Twitter (Aim Two &Aim Three). Aim One seeks to investigate and codify our responsibilities as researchers towards Twitter users by engaging with those users directly. With Aim Two, we will build and evaluate Natural Language Processing resources - algorithms, lexicons and taxonomies - to support the identification of depression symptoms in Twitter data. For Aim Three, we will build and evaluate Natural Language Processing modules and services that use Twitter as a data source for monitoring depression levels in the community. The significance of the proposed work lies in three areas. First, our investigations - both empirical and theoretical - will explore ethical issues in the use of Twitter for public health surveillance. This work has the potential to guide future research in the area. Second, in developing and evaluating algorithms and resources for identifying depression from tweets, we are contributing foundational work to the field of NLP. Third, developing these algorithms and resources will provide the bedrock for building social media based surveillance systems which will provide a cost effective means of augmenting current mental health surveillance practice. This proposal is innovative in both its application area (microblogs have not been used before for mental health surveillance), its focus on using NLP to identify depressive symptoms for public health, and in the central role that qualitative bioethical research will play in guiding the work.              Project Narrative The proposed research focuses on using advanced Natural Language Processing methods to mine microblog data - in this case, Twitter - for mental health surveillance (specifically, depression surveillance), in order to augment current telephone-based mental health surveillance systems. The research has public health at its core.",Utilizing social media as a resource for mental health surveillance,8510292,K99LM011393,"['Algorithms', 'Applications Grants', 'Area', 'Attitude', 'Behavioral Risk Factor Surveillance System', 'Broadcast Media', 'Cities', 'Cognitive', 'Communities', 'County', 'Data', 'Data Sources', 'Dental', 'Development', 'Disasters', 'Earthquakes', 'Electronic Health Record', 'Epidemiology', 'Ethical Issues', 'Ethics', 'Exercise', 'Guidelines', 'Health', 'Human', 'Influenza A Virus, H1N1 Subtype', 'Interview', 'Investigation', 'Linguistics', 'Location', 'Major Depressive Disorder', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Mining', 'Monitor', 'Natural Language Processing', 'Participant', 'Phase', 'Play', 'Population', 'Population Surveillance', 'Prevalence', 'Privacy', 'Process', 'Psyche structure', 'Public Health', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Scheme', 'Services', 'Smoking Status', 'Source', 'Surveillance Methods', 'Surveys', 'System', 'Taxonomy', 'Techniques', 'Telephone', 'Text', 'Time', 'United States', 'Update', 'Work', 'base', 'center for epidemiological studies depression scale', 'cost', 'cost effective', 'depressive symptoms', 'flexibility', 'innovation', 'lexical', 'social', 'syndromic surveillance', 'text searching', 'tool', 'ward']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2013,82800,0.025232819513963896
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.       PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.         ","Annotation, development and evaluation for clinical information extraction",8501543,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,370221,-0.020219065889395472
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8529484,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2013,692911,-0.001534272634441019
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.        Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8733018,UH3HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH3,2013,500000,0.01896313692771208
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8465250,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2013,583762,0.11134435526479357
"Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses     DESCRIPTION (provided by applicant): Phylogeography of zoonotic viruses studies the geographical spread and genetic lineages of viruses that are transmittable between animals and humans such as avian influenza and rabies. This science can help state public health and agriculture agencies identify the animal hosts that most impact virus propagation in a particular geographic region, the migration path of the virus including its origin, and the patterns of infection in various host populations, including humans, over time. The National Center for Biotechnology Information (NCBI), specifically GenBank, provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. However, geospatial metadata such as host location is inconsistently represented and sparse across GenBank entries, with our preliminary studies showing only about 20% of the GenBank records contain specific information such as a county, town, or region within a state. While this detailed geospatial information might be included in the corresponding journal article, it is not available for immediate use in a bioinformatics or GIS application unless it is manually extracted and linked back to the appropriate sequence. Absence of precise sampling locations from easily-computable secondary data sources such as GenBank increases the difficulty of achieving accurate phylogeographic models of virus migration. We propose an infrastructure to improve phylogeographic models of virus migration by linking relevant geospatial data from the literature. This work represents the first effort to use automatically extracted geospatial data present in journal articles corresponding to GenBank records in order to enhance modeling of virus migration. Our research will extend phylogeography and zoonotic surveillance by: creating a Natural Language Processing (NLP) infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the data extracted in Aim 1 with adequate biostatistical models (Aim 2), and evaluating the impact of our approach for phylogeography and surveillance of zoonotic viruses (Aim 3). Thus, this work will provide researchers with a framework for population surveillance using an integrated biomedical informatics approach including NLP, biostatistics, bioinformatics, and database design.           We will create Natural Language Processing Infrastructure and novel phylogeographic models of zoonotic viruses that will allow state public health and agriculture agencies and other researchers to study virus migration. This will enhance population health surveillance including identification of the animal hosts that most impact virus propagation in a particular geographic region, the migration path of zoonotic pathogens, and the patterns of infection in various host populations over time, including humans. This resource will enable state agencies to implement improved public health control measures that will reduce morbidity and mortality of animals and humans from zoonotic diseases.                ",Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses,8698542,R56AI102559,"['Accounting', 'Address', 'Agriculture', 'Animals', 'Applied Research', 'Avian Influenza', 'Back', 'Bioinformatics', 'Biometry', 'Biotechnology', 'China', 'Computer software', 'Country', 'County', 'Data', 'Data Sources', 'Databases', 'Development', 'Disease', 'Epidemiologist', 'Evaluation', 'Event', 'Foundations', 'Funding', 'Genbank', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Geographic Locations', 'Goals', 'Gold', 'Habitats', 'Hantavirus', 'Human', 'Infection', 'Influenza', 'Information Systems', 'Label', 'Link', 'Literature', 'Location', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Pattern', 'Population', 'Population Surveillance', 'Process', 'Public Health', 'Publications', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Solutions', 'Surveillance Modeling', 'System', 'Techniques', 'Text', 'Time', 'Trees', 'Uncertainty', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'Work', 'animal mortality', 'biomedical informatics', 'data modeling', 'database design', 'disease transmission', 'improved', 'journal article', 'migration', 'mortality', 'novel', 'pathogen', 'population health', 'web site']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R56,2013,451478,0.01610559321487526
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.       PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8448772,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2013,203525,0.024349310733643877
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.        The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8409787,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2013,265030,0.05527032703554753
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8536940,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2013,292186,0.0259352271339346
"Artificial Grammar Learning in Aphasia: An Implicit Learning Approach     DESCRIPTION (provided by applicant): Implicit learning procedures have the potential to greatly enhance language training, and yet have received little attention in the aphasia rehabilitation literature. Preliminary evidence of implicit learning ability in individuals with aphasia suggests that this approach could lead to less effortful language rehabilitation strategies, which may be used in combination with established methods of explicit treatment of grammatical ability. The long-term goal of the proposed work is to further the understanding of learning processes in aphasia, and to use that knowledge to engage patients in language learning strategies that will be most beneficial for language recovery. The specific objective of the proposed project is to test an implicit approach to artificial grammar learning in healthy and agrammatic aphasic individuals using a statistical learning paradigm. The central hypothesis is that implicit learning mechanisms, which are effective in deriving grammatical structure from statistical relationships in language, remain intact in individuals with aphasia, and that grammar learning is enhanced when passive language exposure is combined with active practice. The proposed research will be the first to test learning and short-term retention of an artificial phrae structure grammar under implicit learning conditions in individuals with agrammatic aphasia and healthy age-matched adults. Participants in this study will receive repeated passive exposure to the grammar on two consecutive days, and their acquisition and 24-hour retention of the grammatical rules will be evaluated by grammaticality judgment tests. The proposed research will also use the artificial grammar learning task with healthy young adults to test the relative effects of passive exposure to the grammar compared to active practice with feedback and a combination of both approaches. These contributions are significant because they are the first steps toward evaluation of an approach that utilizes patients' retained learning abilities and hence can improve the quality of life of individuals with aphasia.         PUBLIC HEALTH RELEVANCE: The proposed research aims to further the understanding of language learning strategies that are effective and efficient for healthy adults and for individual with impaired language as a result of brain damage. The successful completion of this project will promote innovative treatments that advance the recovery of communication abilities and hence improve the quality of life of individuals with acquired language disorders.                ",Artificial Grammar Learning in Aphasia: An Implicit Learning Approach,8522948,F31DC013204,"['Acquired Language Disorders', 'Activities of Daily Living', 'Adult', 'Affect', 'Age', 'Agrammatism', 'Aphasia', 'Attention', 'Brain Injuries', 'Child', 'Chronic', 'Communication', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Goals', 'Hour', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Literature', 'Machine Learning', 'Methods', 'Outcome', 'Participant', 'Patients', 'Perceptual learning', 'Procedures', 'Process', 'Property', 'Quality of life', 'Reaction Time', 'Recovery', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Staging', 'Stimulus', 'Stroke', 'Structure', 'Task Performances', 'Testing', 'Training', 'Work', 'aphasia rehabilitation', 'aphasic', 'base', 'design', 'improved', 'innovation', 'language training', 'novel', 'public health relevance', 'rehabilitation strategy', 'sequence learning', 'young adult']",NIDCD,NORTHWESTERN UNIVERSITY,F31,2013,34908,0.06224046748270945
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8511737,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2013,289147,0.09176440928060035
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.       PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).         ",Statistical Learning in Language Acquisition,8402391,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2013,274858,0.08649717265731167
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.          An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8496045,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2013,148223,0.010702448728229523
"Annotation, development and evaluation for clinical information extraction (transfer) Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible. In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction (transfer)",8868500,R01GM090187,[' '],NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2013,297936,-0.020519895066101697
"Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral No abstract available  Project narrative Enormous amounts of biomedical information are now available in the PubMedCentral database, but computers cannot work with it because it is in the form of human-language text and humans can't read it all due to its large volume. The goal of this project is to harvest large amounts of that information automatically, making it available to humans in summarized form and to computers in computer-readable form.",Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral,8528719,R01LM009254,"['Biological', 'Collection', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Evaluation Research', 'Funding', 'Gene Chips', 'Genes', 'Goals', 'Harvest', 'Health', 'High Performance Computing', 'Human', 'Imagery', 'Journals', 'Knowledge', 'Language', 'Linguistics', 'Literature', 'Methods', 'Molecular', 'Natural Language Processing', 'Nature', 'Pharmaceutical Preparations', 'Process', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Staging', 'System', 'Techniques', 'Technology', 'Text', 'Work', 'biomedical ontology', 'clinically relevant', 'genome analysis', 'information organization', 'knowledge base', 'language processing', 'scale up', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2013,526738,0.030538206983073503
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.        PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8411996,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2013,377739,0.06292788483094604
"Improving access to multi-lingual health information through machine translation No abstract available  PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8517814,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2013,323176,0.08499346730884254
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,8324662,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2012,745770,0.024193789270647817
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8471822,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2012,224100,0.027220794276146185
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8345041,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2012,318849,0.018763057928554497
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8400218,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2012,20000,0.03151413032487872
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,8309419,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2012,596909,0.027871582085367348
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8333306,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,592423,0.010732466707766892
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8288078,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,663130,-0.016255613376885327
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.        Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8303361,UH2HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH2,2012,516448,0.01896313692771208
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8320877,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,738723,-0.001534272634441019
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8308379,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2012,636949,0.11134435526479357
"Measurement of the time course of statistical learning in word segmentation    DESCRIPTION (provided by applicant): Statistical learning refers to a wide variety of phenomena, many of which have been argued to be related to language acquisition. However, there is little agreement on the process that underlies statistical learning. Several different accounts have been proposed, but it has been difficult to differentiate between these accounts as many converge on the same end result of learning. To identify the process responsible for statistical learning, it is necessary to more closely examine behavioral data that can characterize the dynamic characteristics of learning over the course of exposure. The objective of the current project is to develop and apply a novel method for examining statistical learning of linguistic materials. This method will provide more comprehensive and sensitive results than prior methods, which will enable these experiments to distinguish between theories of statistical learning in a way that has not been previously possible. In these experiments, participants will be exposed to a stream of syllables made up for nonsense words. Within this stream, words consistently co-occur, while syllable conjunctions formed across word boundaries are less predictable. Participants will be asked to listen for a particular syllable within the speech stream, and respond with a button press when they hear it. For some of these participants, the syllable will occur in an unpredictable location (for example, go in golabu is relatively unpredictable, because it can occur after the end of any word in the speech stream). For other participants, the syllable will occur in a predictable location (for example, bu in golabu is consistently signaled by the presence of both go and la). The experiments outlined in this proposal are a first step towards a process-based, mechanistic account of statistical learning. The first experiment demonstrates that this novel methodology is feasible, and will assess the extent to which the serial reaction time measure correlates with more standard post-test measures. The second and third experiments seek to test process-level predictions of a theory of statistical learning. Experiment 2 assesses the extent to which working memory is related to performance in the task, especially on different word lengths. Experiment 3 assesses a proposal about how chunking might be supplemented by processes of comparison to make learning of non-adjacent regularities possible. Finally, Experiment 4 asks how multiple cues to segmentation are integrated while learning is occurring in real time. By identifying the dynamic characteristics of learning over the course of exposure to the input, this research will test and refine theories of statistical learning in ways that have not previously been possible.       This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.         ",Measurement of the time course of statistical learning in word segmentation,8326039,R03HD069733,"['Accounting', 'Adult', 'Agreement', 'Architecture', 'Auditory', 'Behavioral', 'Categories', 'Characteristics', 'Child', 'Cues', 'Data', 'Detection', 'Elements', 'Entropy', 'Exposure to', 'Frequencies', 'Grouping', 'Hearing', 'Human', 'Individual Differences', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Length', 'Linguistics', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neurologic', 'Outcome', 'Participant', 'Performance', 'Positioning Attribute', 'Probability', 'Process', 'Reaction Time', 'Recurrence', 'Research', 'Research Proposals', 'Shapes', 'Short-Term Memory', 'Signal Transduction', 'Simulate', 'Speech', 'Statistical sensitivity', 'Stream', 'Structure', 'Testing', 'Time', 'Visual', 'Work', 'Yang', 'auditory stimulus', 'base', 'diene', 'improved', 'insight', 'lexical', 'novel', 'phrases', 'research study', 'statistics', 'theories', 'therapy design']",NICHD,CARNEGIE-MELLON UNIVERSITY,R03,2012,78350,-0.00555829590456443
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.      PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.","Statistical learning of multiple patterns in infants, adults, and monkeys",8246395,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2012,217762,0.03362406465568631
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.      PUBLIC HEALTH RELEVANCE: The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.           The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8234545,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2012,292839,0.06696687029820378
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8326648,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2012,318393,0.0259352271339346
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8304226,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2012,302966,0.09176440928060035
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8206716,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2012,289629,0.05960343716974709
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.        PUBLIC HEALTH RELEVANCE: An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.              An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8354008,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2012,149342,0.006628216533862713
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8319670,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2012,352514,0.06410712345341048
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.       PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.           Impact/Health Relevance: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8223215,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Health', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2012,395174,0.04909803904682211
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,8138604,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2011,695125,0.024193789270647817
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,8120220,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2011,161797,0.016401628643326973
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence    DESCRIPTION (provided by applicant): Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.           Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8190163,K99LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2011,89802,0.028422225873028374
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,8144459,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2011,147161,0.04407800243999932
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,8117587,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2011,597135,0.027871582085367348
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.      PUBLIC HEALTH RELEVANCE: Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.           Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8145134,UH2HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH2,2011,540294,0.022727518411122683
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.      PUBLIC HEALTH RELEVANCE: Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.              Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8185086,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2011,759606,-0.0033559598268232743
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8133360,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,664617,-0.016255613376885327
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8022026,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,591195,0.010732466707766892
"Linking Statistical Learning to Vocabulary Development    DESCRIPTION (provided by applicant): The research proposed in this application will investigate the connection between statistical learning and vocabulary development. Statistical learning refers to the process of detecting structure in the environment by tracking patterns present in the input. Recent experiments have revealed that infants possess remarkable statistical learning capabilities. Statistical learning may play a significant role in the precocious development of native language sound structure that occurs during the first year of life. During the second year, vocabulary development accelerates. The proposed experiments are motivated by the hypothesis that statistical learning about sounds lays a foundation for word learning. Thus, infants' ability to track statistical regularities may affect the ability to build a vocabulary. This research will examine the relation between individual differences in infants' vocabulary development and individual differences in statistical learning. The experiments will use measures of listening time and looking time to test infants' detection of novel statistical regularities, and to test their knowledge of native-language statistical regularities. Infants will participate speech, non-speech auditory, and visual statistical learning tasks in order to evaluate the coherence of statistical learning across domains. A label-learning task will also tap infants' ability to use native language statistical regularities to acquire new lexical items. In each experiment, infants' performance on experimental tasks will be integrated with measures of their real-world vocabulary development. This findings of this research promise to inform understanding of the underlying mechanism that contribute to individual differences in language acquisition.      PUBLIC HEALTH RELEVANCE: The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.           Relevance The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.",Linking Statistical Learning to Vocabulary Development,8106300,R03HD062755,"['Address', 'Affect', 'Auditory', 'Child', 'Cognitive', 'Cues', 'Detection', 'Development', 'Disadvantaged', 'Environment', 'Foundations', 'Future', 'Impairment', 'Individual Differences', 'Infant', 'Infant Development', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Pattern', 'Performance', 'Play', 'Process', 'Research', 'Risk', 'Role', 'Services', 'Signal Transduction', 'Specificity', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'Visual', 'Vocabulary', 'base', 'expectation', 'lexical', 'novel', 'prospective', 'public health relevance', 'research study', 'skills', 'sound']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2011,73680,0.05465636319064443
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,8097952,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Beryllium', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2011,14727,0.11197018900836271
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.      PUBLIC HEALTH RELEVANCE: The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.           The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8186590,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2011,690049,0.1145250230455619
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.      PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.           Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8116119,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2011,221561,0.03341265206816564
"Measurement of the time course of statistical learning in word segmentation    DESCRIPTION (provided by applicant): Statistical learning refers to a wide variety of phenomena, many of which have been argued to be related to language acquisition. However, there is little agreement on the process that underlies statistical learning. Several different accounts have been proposed, but it has been difficult to differentiate between these accounts as many converge on the same end result of learning. To identify the process responsible for statistical learning, it is necessary to more closely examine behavioral data that can characterize the dynamic characteristics of learning over the course of exposure. The objective of the current project is to develop and apply a novel method for examining statistical learning of linguistic materials. This method will provide more comprehensive and sensitive results than prior methods, which will enable these experiments to distinguish between theories of statistical learning in a way that has not been previously possible. In these experiments, participants will be exposed to a stream of syllables made up for nonsense words. Within this stream, words consistently co-occur, while syllable conjunctions formed across word boundaries are less predictable. Participants will be asked to listen for a particular syllable within the speech stream, and respond with a button press when they hear it. For some of these participants, the syllable will occur in an unpredictable location (for example, go in golabu is relatively unpredictable, because it can occur after the end of any word in the speech stream). For other participants, the syllable will occur in a predictable location (for example, bu in golabu is consistently signaled by the presence of both go and la). The experiments outlined in this proposal are a first step towards a process-based, mechanistic account of statistical learning. The first experiment demonstrates that this novel methodology is feasible, and will assess the extent to which the serial reaction time measure correlates with more standard post-test measures. The second and third experiments seek to test process-level predictions of a theory of statistical learning. Experiment 2 assesses the extent to which working memory is related to performance in the task, especially on different word lengths. Experiment 3 assesses a proposal about how chunking might be supplemented by processes of comparison to make learning of non-adjacent regularities possible. Finally, Experiment 4 asks how multiple cues to segmentation are integrated while learning is occurring in real time. By identifying the dynamic characteristics of learning over the course of exposure to the input, this research will test and refine theories of statistical learning in ways that have not previously been possible.      PUBLIC HEALTH RELEVANCE:This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.          This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.         ",Measurement of the time course of statistical learning in word segmentation,8176333,R03HD069733,"['Accounting', 'Adult', 'Agreement', 'Architecture', 'Auditory', 'Behavioral', 'Categories', 'Characteristics', 'Child', 'Cues', 'Data', 'Detection', 'Elements', 'Entropy', 'Exposure to', 'Frequencies', 'Grouping', 'Hearing', 'Human', 'Individual Differences', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Length', 'Linguistics', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neurologic', 'Outcome', 'Participant', 'Performance', 'Positioning Attribute', 'Probability', 'Process', 'Reaction Time', 'Recurrence', 'Research', 'Research Proposals', 'Shapes', 'Short-Term Memory', 'Signal Transduction', 'Simulate', 'Speech', 'Statistical sensitivity', 'Stream', 'Structure', 'Testing', 'Time', 'Visual', 'Work', 'Yang', 'auditory stimulus', 'base', 'diene', 'improved', 'insight', 'lexical', 'novel', 'phrases', 'research study', 'statistics', 'theories', 'therapy design']",NICHD,CARNEGIE-MELLON UNIVERSITY,R03,2011,78350,0.01873835465111206
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8182025,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2011,325163,0.0259352271339346
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8101854,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2011,302966,0.09176440928060035
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8015278,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2011,289629,0.05960343716974709
"Functional neuroimaging of language processing in primary progressive aphasia No abstract available  PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8207220,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Aphasias', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Progressive Aphasias', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'relating to nervous system', 'syntax']",NIDCD,UNIVERSITY OF ARIZONA,R03,2011,121967,0.0670652289897927
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8138590,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2011,356340,0.06410712345341048
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.       PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.           More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8132735,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2011,397750,0.0494255932273462
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,7983243,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2010,775112,0.024193789270647817
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,7991498,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2010,223207,0.016401628643326973
"A Hybrid General Natural Language Processing Architecture    DESCRIPTION (provided by applicant): Electronic medical records and exchanges offer new opportunities for the analysis of population health data; however, new methods in natural language processing (NLP) must first be developed to structure and codify these records, since most medical data is in the form of free text which cannot be stored and manipulated by computers. Once this is accomplished, population health data can be analyzed which will lead to better treatment guidelines, targeted drug therapy, and more cost effective care. Logical Semantics, Inc. (LSI) proposes to develop new statistical NLP methods for analyzing large scale medical domains. These methods will leverage LSI's semantic annotation technology, which has created the largest semantically annotated clinical corpus in the world. LSI's goal is to semantically index large medical record repositories accurately against propositions arranged in knowledge ontologies and make these indices available for text mining applications. The phase one research is focused on three specific aims that will lead to breakthroughs in the science of NLP: (1) Develop new statistical NLP algorithms employing a large semantically annotated medical corpus, (2) Semi-automate knowledge ontology generation, and (3) Develop and combine rule based with statistical NLP algorithms to create a superior hybrid NLP system. The achievement of these aims will result in computer systems that can extract the meaning from free text medical records so researchers, policy makers, and clinicians can use health analytics to improve healthcare.      PUBLIC HEALTH RELEVANCE: Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.           Project Narrative Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.",A Hybrid General Natural Language Processing Architecture,7996937,R43LM010846,"['Achievement', 'Address', 'Algorithms', 'Architecture', 'Businesses', 'Caring', 'Clinical', 'Communities', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Diagnosis', 'Discipline', 'Generations', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Hybrids', 'Knowledge', 'Lead', 'Legal patent', 'Linguistics', 'Logic', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Mining', 'Natural Language Processing', 'Ontology', 'Pattern', 'Pharmacotherapy', 'Phase', 'Policy Maker', 'Process', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cost effective', 'improved', 'indexing', 'knowledge base', 'operation', 'phrases', 'population health', 'public health relevance', 'repository', 'stem', 'success', 'text searching', 'tool']",NLM,"LOGICAL SEMANTICS, INC.",R43,2010,148180,0.0070943197946975916
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7936999,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Epidemiology', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Mental Depression', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2010,499697,-0.011642219487700648
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7921455,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2010,148350,0.04407800243999932
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7944035,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Epidemiology', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2010,494477,-0.004859650709980749
"Shared Task 2010 - Analysis of Suicide  Notes for Subjective Information    DESCRIPTION (provided by applicant):      The objective of this virtual-conference is to conduct a shared task dedicated to developing and evaluating natural language processing methods that identify emotional language in suicide notes. Developing natural language processing methods that identify emotional language in suicide notes is an important responsibility. A responsibility that, as we will show, can immediately affect the care of suicidal patients. Additionally, these methods may be used by computers to understand other types of emotionally laden text. Shared tasks have a long history of contributing to the advancement of science. They are an efficient way of bringing together the efforts of large numbers of research groups to bear on important problems; they are, in fact, a virtual scientific conference. Our specific aims are 1) Select and develop methods for identifying emotional language in suicide notes; 2) Evaluate the accuracy of these methods; 3) Publish the results of the findings in an open-access journal.            Project Narrative The objective of this virtual-conference is to conduct a shared task dedicated to developing and evaluating natural language processing methods that identify emotional language in suicide notes. Applying the results of this shared task toward understand the suicidal mind may have tremendous affect on the care of the suicidal person.",Shared Task 2010 - Analysis of Suicide  Notes for Subjective Information,7917882,R13LM010743,"['Affect', 'Caring', 'Computers', 'Emotional', 'Journals', 'Language', 'Methods', 'Mind', 'Natural Language Processing', 'Persons', 'Publishing', 'Recording of previous events', 'Research', 'Science', 'Suicide', 'Text', 'Ursidae Family', 'suicidal', 'suicidal patient', 'symposium', 'virtual']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R13,2010,19600,-0.11054608637299879
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,8142701,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,10000,0.008651514380180974
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7828239,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,531496,0.008651514380180974
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7908806,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2010,618469,0.027871582085367348
"Functional neuroimaging of language processing in primary progressive aphasia    DESCRIPTION (provided by applicant): Primary progressive aphasia (PPA) is a clinical syndrome in which degeneration of language regions in the dominant hemisphere is associated with progressive deficits in speech and/or language function. The overall goals of this project are to use functional magnetic resonance imaging (fMRI) to investigate neural changes underlying linguistic deficits in PPA, and to use this information to better discriminate patients with variants of PPA from each other and from normal aging. Recent studies have identified three clinical variants of PPA: progressive non-fluent aphasia (PNFA), semantic dementia (SD) and logopenic progressive aphasia (LPA). Each variant is associated with characteristic linguistic features, distinct patterns of brain atrophy, and different likelihoods of particular underlying pathogenic processes, making correct differential diagnosis highly relevant. We will recruit 48 patients with PPA (16 of each variant) and 24 normal controls over a three year period, and acquire fMRI data along with structural MRI, linguistic and cognitive measures. The fMRI paradigm consists of a syntactic processing task with seven conditions parametrically varying in syntactic complexity. The research will address two specific aims. The first is to identify the relationships between volume loss, changes in functional MRI activation, and linguistic deficits, in the different PPA variants. The second aim is to improve differential diagnosis of PPA variants using machine learning algorithms incorporating both structural and functional imaging measures.      PUBLIC HEALTH RELEVANCE: PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.              PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,7882100,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Receptive aphasia', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'public health relevance', 'relating to nervous system', 'syntax']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R03,2010,23807,0.018462353355833714
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7942766,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2010,320155,0.02373866436945747
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",7985218,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,1,-0.016255613376885327
"Linking Statistical Learning to Vocabulary Development    DESCRIPTION (provided by applicant): The research proposed in this application will investigate the connection between statistical learning and vocabulary development. Statistical learning refers to the process of detecting structure in the environment by tracking patterns present in the input. Recent experiments have revealed that infants possess remarkable statistical learning capabilities. Statistical learning may play a significant role in the precocious development of native language sound structure that occurs during the first year of life. During the second year, vocabulary development accelerates. The proposed experiments are motivated by the hypothesis that statistical learning about sounds lays a foundation for word learning. Thus, infants' ability to track statistical regularities may affect the ability to build a vocabulary. This research will examine the relation between individual differences in infants' vocabulary development and individual differences in statistical learning. The experiments will use measures of listening time and looking time to test infants' detection of novel statistical regularities, and to test their knowledge of native-language statistical regularities. Infants will participate speech, non-speech auditory, and visual statistical learning tasks in order to evaluate the coherence of statistical learning across domains. A label-learning task will also tap infants' ability to use native language statistical regularities to acquire new lexical items. In each experiment, infants' performance on experimental tasks will be integrated with measures of their real-world vocabulary development. This findings of this research promise to inform understanding of the underlying mechanism that contribute to individual differences in language acquisition.      PUBLIC HEALTH RELEVANCE: The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.           Relevance The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.",Linking Statistical Learning to Vocabulary Development,7990457,R03HD062755,"['Address', 'Affect', 'Auditory', 'Child', 'Cognitive', 'Cues', 'Detection', 'Development', 'Disadvantaged', 'Disease', 'Environment', 'Foundations', 'Future', 'Impairment', 'Individual Differences', 'Infant', 'Infant Development', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Pattern', 'Performance', 'Play', 'Process', 'Research', 'Risk', 'Role', 'Services', 'Signal Transduction', 'Specificity', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'Visual', 'Vocabulary', 'base', 'expectation', 'lexical', 'novel', 'prospective', 'public health relevance', 'research study', 'skills', 'sound']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2010,76500,0.05465636319064443
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,7908812,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Future', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2010,29034,0.11197018900836271
"Social and Statistical Mechanisms of Prelinguistic Vocal Learning    DESCRIPTION (provided by applicant): How do infants learn to produce the sounds of their language? The vocal abilities of infants change dramatically over the first year of life. Beginning with the earliest, immature vocalizations, infants make rapid progress, typically producing their first words by 12 months of age. Along the way, they begin to produce speech-like syllables and to structure sequences of syllables in accordance with the phonological rules of their language environment. While the vocal achievements of the first year are well-described, not nearly as much is known about the mechanisms of change that drive vocal development. Most work focuses on the maturation of the vocal tract, but studies of vocal development in songbirds found that there are also social sources of developmental change. For example, young male cowbirds (Molothrus ater) rely on the reactions of females to shape their immature sounds into functional song. Based on the avian work, the investigators' preliminary studies have shown that infants can learn new patterns of vocalizing from caregivers' reactions to their babbling. How do infants use social feedback to create new, more developmentally advanced, vocalizations? The goal of the proposed research is to understand the mechanisms by which infants incorporate the phonological patterns of their language into their vocal repertoires. Based on preliminary studies, the investigators hypothesize that the contingent responses of caregivers to babbling facilitate infants' statistical learning of the phonological patterns of their language. To investigate this hypothesis, the variability and temporal contingency of speech to 9-month-old infants will be manipulated to assess their effects on vocal learning. The proposed research has important implications for educating parents in providing optimal learning environments for their infants. An understanding of the role of socially guided learning in speech and language could be used to help parents to be more sensitive to their infants' behavior in ways that would facilitate development. Investigating social influences on phonological development can also contribute to the study of speech-language pathology and of processes underlying both successful and disordered communicative development.      PUBLIC HEALTH RELEVANCE: By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).           Project Relevance By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).",Social and Statistical Mechanisms of Prelinguistic Vocal Learning,7897740,R03HD061524,"['Achievement', 'Age-Months', 'Attention', 'Birds', 'Caregivers', 'Characteristics', 'Child', 'Child Care', 'Communication', 'Communication impairment', 'Crying', 'Development', 'Down Syndrome', 'Environment', 'Feedback', 'Female', 'Fostering', 'Goals', 'Growth', 'Infant', 'Infant Behavior', 'Intervention', 'Knowledge', 'Language', 'Language Delays', 'Language Development Disorders', 'Learning', 'Life', 'Light', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mechanics', 'Motor', 'Movement', 'Nature', 'Outcome', 'Parents', 'Pathology processes', 'Pattern', 'Phonetics', 'Play', 'Preventive', 'Production', 'Provider', 'Reaction', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Snow', 'Social Environment', 'Songbirds', 'Source', 'Speech', 'Speech Perception', 'Speech-Language Pathology', 'Structure', 'Time', 'Work', 'base', 'design', 'high risk', 'insight', 'male', 'phonology', 'programs', 'public health relevance', 'response', 'social', 'sound', 'vocal learning', 'vocalization']",NICHD,CORNELL UNIVERSITY,R03,2010,78705,-0.019892290424496903
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7911611,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2010,312811,0.09176440928060035
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,7782012,R01HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2010,301697,0.05960343716974709
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7935475,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2010,50100,0.0140440739009108
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8231171,R01GM090187,[' '],NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,642650,-0.016255613376885327
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,7946175,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Arts', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2010,370693,0.06410712345341048
"Functional neuroimaging of language processing in primary progressive aphasia    DESCRIPTION (provided by applicant): Primary progressive aphasia (PPA) is a clinical syndrome in which degeneration of language regions in the dominant hemisphere is associated with progressive deficits in speech and/or language function. The overall goals of this project are to use functional magnetic resonance imaging (fMRI) to investigate neural changes underlying linguistic deficits in PPA, and to use this information to better discriminate patients with variants of PPA from each other and from normal aging. Recent studies have identified three clinical variants of PPA: progressive non-fluent aphasia (PNFA), semantic dementia (SD) and logopenic progressive aphasia (LPA). Each variant is associated with characteristic linguistic features, distinct patterns of brain atrophy, and different likelihoods of particular underlying pathogenic processes, making correct differential diagnosis highly relevant. We will recruit 48 patients with PPA (16 of each variant) and 24 normal controls over a three year period, and acquire fMRI data along with structural MRI, linguistic and cognitive measures. The fMRI paradigm consists of a syntactic processing task with seven conditions parametrically varying in syntactic complexity. The research will address two specific aims. The first is to identify the relationships between volume loss, changes in functional MRI activation, and linguistic deficits, in the different PPA variants. The second aim is to improve differential diagnosis of PPA variants using machine learning algorithms incorporating both structural and functional imaging measures.      PUBLIC HEALTH RELEVANCE: PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.              PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8203671,R03DC010878,[' '],NIDCD,UNIVERSITY OF ARIZONA,R03,2010,115612,0.018462353355833714
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7933293,R01LM006910,"['Address', 'Area', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Machine Learning', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'clinical care', 'data mining', 'improved', 'knowledge base', 'natural language', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,152617,0.04248200735298457
"Construction of a Full Text Corpus for Biomedical Text Mining    DESCRIPTION (provided by applicant):       There is a demonstrated community need for an annotated corpus consisting of the full texts of biomedical journal articles. There are many reasons to believe that the rate-limiting factor impeding progress in biomedical language processing today is the lack of availability of the right kind of expertly annotated data. An annotated corpus is a collection of texts with information about the meaning or structure associated with particular textual elements. Annotated corpora are a critical component of biomedical natural language processing research in two ways. First, most contemporary approaches to language processing rely at least in part on machine learning or statistical models. Such systems must be ""trained"" on sets of examples with known outputs, so annotated corpora provide the training data vital to the construction of modern NLP systems. Second, annotated corpora provide the gold standard by which various approaches to particular text mining tasks are evaluated. Due to their central roles in training and testing language processing systems, the quality of the design and operational creation of annotated corpora place fundamental limits on what can be accomplished with such systems. Although there has been valuable work done on annotating abstracts, there are important differences between abstracts and full-text articles from a text mining perspective, and annotation of full-text journal articles has been negligible. Workers in both the biological (especially model organism database curation) community and the text mining community have independently pointed out the importance of processing the full text of scientific publications if the biomedical world is to be able to fully utilize text mining. We propose to build a large, fully annotated corpus consisting of full texts of biomedical journal articles. Additionally, previous biomedical corpus annotation efforts have often utilized ad hoc ontologies that have limited their utility outside of the groups that created them. We will ensure community acceptability by annotating with respect to community-consensus ontologies such as the Gene Ontology and the UMLS. Since the task involves expensive human labor, efficiency is a key issue in creating corpora. For this reason, we propose to build a team that includes the builder of the largest semantically annotated corpus to date, one of the pioneers of the model organism databases, and an already-assembled cadre of experienced linguistic and domain-expert annotators.             n/a",Construction of a Full Text Corpus for Biomedical Text Mining,7872692,G08LM009639,"['Address', 'Agreement', 'Biological', 'Biology', 'Body of uterus', 'Collection', 'Communities', 'Consensus', 'Data', 'Databases', 'Development', 'Elements', 'Ensure', 'Feedback', 'Genes', 'Gold', 'Growth', 'Human', 'Light', 'Linguistics', 'Literature', 'MEDLINE', 'Machine Learning', 'Manuals', 'Measures', 'Metric', 'Monitor', 'Natural Language Processing', 'Nature', 'Ontology', 'Output', 'Problem Solving', 'Procedures', 'Process', 'Publications', 'Published Comment', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scheme', 'Series', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'Training', 'Unified Medical Language System', 'Work', 'abstracting', 'base', 'design', 'experience', 'indexing', 'information organization', 'innovation', 'journal article', 'language processing', 'model organisms databases', 'programs', 'quality assurance', 'text searching', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,G08,2009,66015,0.02762293907860695
"Construction of a Full Text Corpus for Biomedical Text Mining    DESCRIPTION (provided by applicant):       There is a demonstrated community need for an annotated corpus consisting of the full texts of biomedical journal articles. There are many reasons to believe that the rate-limiting factor impeding progress in biomedical language processing today is the lack of availability of the right kind of expertly annotated data. An annotated corpus is a collection of texts with information about the meaning or structure associated with particular textual elements. Annotated corpora are a critical component of biomedical natural language processing research in two ways. First, most contemporary approaches to language processing rely at least in part on machine learning or statistical models. Such systems must be ""trained"" on sets of examples with known outputs, so annotated corpora provide the training data vital to the construction of modern NLP systems. Second, annotated corpora provide the gold standard by which various approaches to particular text mining tasks are evaluated. Due to their central roles in training and testing language processing systems, the quality of the design and operational creation of annotated corpora place fundamental limits on what can be accomplished with such systems. Although there has been valuable work done on annotating abstracts, there are important differences between abstracts and full-text articles from a text mining perspective, and annotation of full-text journal articles has been negligible. Workers in both the biological (especially model organism database curation) community and the text mining community have independently pointed out the importance of processing the full text of scientific publications if the biomedical world is to be able to fully utilize text mining. We propose to build a large, fully annotated corpus consisting of full texts of biomedical journal articles. Additionally, previous biomedical corpus annotation efforts have often utilized ad hoc ontologies that have limited their utility outside of the groups that created them. We will ensure community acceptability by annotating with respect to community-consensus ontologies such as the Gene Ontology and the UMLS. Since the task involves expensive human labor, efficiency is a key issue in creating corpora. For this reason, we propose to build a team that includes the builder of the largest semantically annotated corpus to date, one of the pioneers of the model organism databases, and an already-assembled cadre of experienced linguistic and domain-expert annotators.             n/a",Construction of a Full Text Corpus for Biomedical Text Mining,7673720,G08LM009639,"['Address', 'Agreement', 'Biological', 'Biology', 'Body of uterus', 'Collection', 'Communities', 'Consensus', 'Data', 'Databases', 'Development', 'Elements', 'Ensure', 'Feedback', 'Genes', 'Gold', 'Growth', 'Human', 'Light', 'Linguistics', 'Literature', 'MEDLINE', 'Machine Learning', 'Manuals', 'Measures', 'Metric', 'Monitor', 'Natural Language Processing', 'Nature', 'Ontology', 'Output', 'Problem Solving', 'Procedures', 'Process', 'Publications', 'Published Comment', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scheme', 'Series', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'Training', 'Unified Medical Language System', 'Work', 'abstracting', 'base', 'design', 'experience', 'indexing', 'information organization', 'innovation', 'journal article', 'language processing', 'model organisms databases', 'programs', 'quality assurance', 'text searching', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,G08,2009,142851,0.02762293907860695
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7554153,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'clinical care', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2009,422728,0.014637123689031861
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7834605,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'depression', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2009,499818,-0.011642219487700648
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7693117,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2009,145926,0.04407800243999932
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7839706,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2009,497857,-0.004859650709980749
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7668609,R01LM008111,"['Address', 'Biomedical Research', 'Body of uterus', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2009,613451,0.027871582085367348
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7672256,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Readability', 'Reader', 'Reading', 'Self Care', 'Self Management', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'fourth grade', 'improved', 'instrument', 'literacy', 'ninth grade', 'patient oriented', 'prevent', 'programs', 'tenth grade', 'tool', 'web site']",NIDDK,UNIVERSITY OF UTAH,R01,2009,398216,0.03662615929610259
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7691699,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,311821,0.02373866436945747
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7908950,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,17240,0.02373866436945747
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7727710,R01LM010140,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Case Study', 'Cells', 'Clinical', 'Code', 'Computer software', 'Curiosities', 'Data', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Electronics', 'Environmental Risk Factor', 'Evaluation', 'Frequencies', 'Goals', 'Hand', 'Hospitals', 'Immunocompromised Host', 'Incidence', 'Individual', 'Inequality', 'Informatics', 'Information Theory', 'Kaposi Sarcoma', 'Kidney Diseases', 'Laboratories', 'Link', 'Literature', 'Liver diseases', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Pattern', 'Persons', 'Population', 'Presbyterian Church', 'Process', 'PubMed', 'Rare Diseases', 'Records', 'Reporting', 'Research', 'Source', 'Statistical Methods', 'Stratification', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Text', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Virus', 'Work', 'Writing', 'abstracting', 'base', 'blind', 'data mining', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'novel', 'pathogen', 'repository', 'research study', 'statistics', 'text searching', 'tool', 'virology', 'web site']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,533007,0.008651514380180974
"The Role of Statistical Learning in Acquiring Syntactic Categories    DESCRIPTION (provided by applicant): The proposed experiments will investigate the role of statistical learning in the acquisition of syntactic categories such as ""noun"" and ""verb"". The role of syntactic category knowledge in language acquisition is pervasive; for example, category knowledge both facilitates learning grammatical patterns and facilitates early word learning. While many aspects of language acquisition rely on syntactic category knowledge, the process by which these categories are learned is unclear. The goal of the proposed research is to test the hypothesis that statistical learning plays a role in acquiring syntactic categories. Words from different syntactic categories are distinguishable by statistical cues, such as their distributional properties (i.e., cooccurrence with other words), and their phonological properties (i.e., their sound structure), the first specific aim is to assess infants' sensitivity to these cues in the acquisition of noun and verb categories. If words' statistical properties are used in category learning, infants should be able to use these properties to identify novel category members in the early stages of category acquisition. Moreover, infants' ability to determine the category of novel words should reflect the degree to which they conform to the predominant statistical characteristics of the category, and training on these statistical properties should facilitate their use at younger ages. Infants' ability to categorize novel words will be assessed by testing whether they are mapped to object or action referents. The second specific aim is to test infants' ability to integrate statistical and semantic information in category learning. Acquisition of syntactic categories encompasses learning about both statistical properties and semantic properties, and these cues are correlated in natural language. If infants can integrate these cues, correlations between them should facilitate learning. Infants will be familiarized with an artificial language containing novel categories, and the correlations between statistical and semantic cues will be manipulated. If infants can integrate these cues, they should be better able to detect commonalities in the meanings of words within a category, and to learn the grammatical structures in which these words can occur, when cues are correlated than when they are not. Future studies will test children with Specific Language Impairment and other developmental language disorders (e.g., late talkers), who exhibit impaired word learning abilities and reduced sensitivity to distributional cues identifying syntactic categories. Testing children on these tasks will address the extent to which impaired statistical learning is a contributing factor in these disorders.          n/a",The Role of Statistical Learning in Acquiring Syntactic Categories,7583888,F32HD057698,"['Address', 'Age', 'Categories', 'Characteristics', 'Child', 'Cues', 'Disease', 'Exhibits', 'Future', 'Goals', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Learning', 'Machine Learning', 'Maps', 'Pattern', 'Play', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Staging', 'Structure', 'Testing', 'Training', 'member', 'natural language', 'novel', 'phonology', 'research study', 'sound', 'specific language impairment', 'syntax']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2009,50054,0.05787671569799698
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7932637,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2009,64856,0.08353823579288656
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7531059,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2009,269938,0.08353823579288656
"Constraints on Learning from Inconsistent Input All human learners with normal cognitive capacities who are exposed to language input in childhood  manage to acquire a language that looks very much like their input. However, at present we have little  idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning  mechanisms that underlie and support language learning. This is the focus of the research in this  proposal. Three general questions guide the research.(1) What are the constraints on language learning  mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or  are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if  'so, how? The proposed research examines these questions by investigating the learning of probabilistic  and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique  view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned.  Previous work has shown that learners can acquire probabilistic patterns, however they sometimes  impose consistency on variation. Moreover, children are more likely to change such patterns than are  adults. The present research expands on the earlier results, asking about the nature of the interaction  between learners and input. Series 1 asks about the nature of the input that makes some inconstancy  learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in  languages, asking questions about the specificity of computations learners can perform, the  representations over which such computations can be performed, and the effect of prior domain-specific  knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over  inconsistency at all.In particular, the studies examine whether working memory constraints, rather than  constraints stemming directly from the learning mechanisms themselves, are an important factor  influencing whether learners acquire the variation or instead impose regularity. Both series will be  conducted with adults and children to examine how learning changes over development. Although the  input in the proposed studies is somewhat atypical, the results from these studies will contribute to our  understanding of the learning mechanisms involved in language acquisition more generally, and  ultimately, this increases our understanding of both normal and disordered acquisition. n/a",Constraints on Learning from Inconsistent Input,7560411,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'information processing', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2009,177315,0.05374041923637342
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7908946,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'meetings', 'natural language', 'population based', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2009,71200,0.029158106002143407
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,7678067,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Body of uterus', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Future', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2009,28830,0.11197018900836271
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7600444,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'natural language', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2009,22393,0.02195367360654671
"Tools for Automated Assessment of Language    DESCRIPTION (provided by applicant): Language and communication problems critically characterize a number of neurodevelopmental disorders including Developmental Language Disorders (DLD) and Autism Spectrum Disorders (ASD). It is increasingly recognized that assessment should include spontaneous natural language samples. There are measures, such as the Index of Productive Syntax (IPSyn), which are laborious to apply, since they require manual analysis of a corpus of sentences collected from the child. There is therefore a strong need for automated tools to aid clinicians in this task, and to provide more robust analyses for assessment. Many widely-used commercial software packages, such as the Systematic Analysis of Language Transcripts (SALT) do little more than count linguistic features, and still require someone to code those features. Fully automated systems, such as Computerized Profiling (CP) do exist, but reports vary on how well they work. However, recent advances in natural language processing, in particular in the realm of grammar adaptation, mean that we are now able to produce high-quality commercial software that can be used by clinical practitioners in their assessment of child language. This project will build a commercially viable suite of fully automated, software-based tools, requiring no special equipment beyond a standard personal computer, targeted at clinicians who work with children with neurodevelopmental disorders. The system will have been evaluated not only with children with Typical Development (TD), but with data from children with ASD and DLD. The system will include the following components: (1) text normalization tools to help with the clean up and normalization of transcriptions; (2) a state -of-the-art part-of-speech tagger; (3) a state-of-the-art morphological analyzer; (4) a state-of-the-art syntactic parser; (5) a dependency analyzer and semantic-role labeler, (6) a scoring module to take the output of the language analysis, and map this to the IPSyn or other scales. The software will be written in C++ and Java, and will adopt a rigorous industrial coding style, namely the Google style guide, which is in the public domain. As part of an NIH-funded project on Autism, the Center for Spoken Language Understanding, in collaboration with colleagues at Yale University, has collected a corpus of video and audio recorded interactions of children with ASD and DLD, as well as TD children ages 4-8. In this STTR-funded project, we will perform a manual IPSyn assessment on these data and provide the results as a benchmark on how well the system will perform in the field. While the target language for the initial development will be English, the software will be written in a fully language-independent fashion, in that no properties of English will be hard-coded into the system. All that would be required to 'port' the system to a new language would be appropriate training material for the language.      PUBLIC HEALTH RELEVANCE: Language and communication problems critically characterize a number of neurodevelopmental disorders, and it is increasingly recognized that assessment should involve the analysis of spontaneous language samples. This project will develop a package of software programs for the automatic analysis of spontaneous language samples from children with neurodevelopmental disorders. The program will be usable directly by clinicians in their assessment of patients.          n/a",Tools for Automated Assessment of Language,7800817,R41DC010502,"['Adopted', 'Age', 'Arts', 'Autistic Disorder', 'Benchmarking', 'Body of uterus', 'Child', 'Child Development', 'Child Language', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Data', 'Dependency', 'Development', 'Funding', 'Genetic Transcription', 'Java', 'Language', 'Language Development Disorders', 'Linguistics', 'Manuals', 'Maps', 'Measures', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Output', 'Patients', 'Personal Computers', 'Property', 'Public Domains', 'Reporting', 'Role', 'Sampling', 'Semantics', 'Special Equipment', 'Speech', 'System', 'Text', 'Training', 'Transcript', 'Universities', 'Work', 'Writing', 'autism spectrum disorder', 'base', 'computerized', 'indexing', 'natural language', 'programs', 'public health relevance', 'syntax', 'tool']",NIDCD,"BIOSPEECH, INC.",R41,2009,198687,0.038203755221783126
"Social and Statistical Mechanisms of Prelinguistic Vocal Learning    DESCRIPTION (provided by applicant): How do infants learn to produce the sounds of their language? The vocal abilities of infants change dramatically over the first year of life. Beginning with the earliest, immature vocalizations, infants make rapid progress, typically producing their first words by 12 months of age. Along the way, they begin to produce speech-like syllables and to structure sequences of syllables in accordance with the phonological rules of their language environment. While the vocal achievements of the first year are well-described, not nearly as much is known about the mechanisms of change that drive vocal development. Most work focuses on the maturation of the vocal tract, but studies of vocal development in songbirds found that there are also social sources of developmental change. For example, young male cowbirds (Molothrus ater) rely on the reactions of females to shape their immature sounds into functional song. Based on the avian work, the investigators' preliminary studies have shown that infants can learn new patterns of vocalizing from caregivers' reactions to their babbling. How do infants use social feedback to create new, more developmentally advanced, vocalizations? The goal of the proposed research is to understand the mechanisms by which infants incorporate the phonological patterns of their language into their vocal repertoires. Based on preliminary studies, the investigators hypothesize that the contingent responses of caregivers to babbling facilitate infants' statistical learning of the phonological patterns of their language. To investigate this hypothesis, the variability and temporal contingency of speech to 9-month-old infants will be manipulated to assess their effects on vocal learning. The proposed research has important implications for educating parents in providing optimal learning environments for their infants. An understanding of the role of socially guided learning in speech and language could be used to help parents to be more sensitive to their infants' behavior in ways that would facilitate development. Investigating social influences on phonological development can also contribute to the study of speech-language pathology and of processes underlying both successful and disordered communicative development.      PUBLIC HEALTH RELEVANCE: By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).           Project Relevance By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).",Social and Statistical Mechanisms of Prelinguistic Vocal Learning,7712197,R03HD061524,"['Achievement', 'Age-Months', 'Attention', 'Birds', 'Caregivers', 'Characteristics', 'Child', 'Child Care', 'Communication', 'Communication impairment', 'Crying', 'Development', 'Down Syndrome', 'Environment', 'Feedback', 'Female', 'Fostering', 'Goals', 'Growth', 'Infant', 'Infant Behavior', 'Intervention', 'Knowledge', 'Language', 'Language Delays', 'Language Development Disorders', 'Learning', 'Life', 'Light', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mechanics', 'Motor', 'Movement', 'Nature', 'Outcome', 'Parents', 'Pathology processes', 'Pattern', 'Phonetics', 'Play', 'Preventive', 'Production', 'Provider', 'Reaction', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Snow', 'Social Environment', 'Songbirds', 'Source', 'Speech', 'Speech Perception', 'Speech-Language Pathology', 'Structure', 'Time', 'Work', 'base', 'design', 'high risk', 'insight', 'male', 'phonology', 'programs', 'public health relevance', 'response', 'social', 'sound', 'vocal learning', 'vocalization']",NICHD,CORNELL UNIVERSITY,R03,2009,79500,-0.019892290424496903
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7932503,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Body of uterus', 'Categories', 'Child', 'Classification', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2009,70754,0.09176440928060035
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7728608,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Body of uterus', 'Categories', 'Child', 'Classification', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2009,300672,0.09176440928060035
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7908086,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,130902,-0.01844034714043575
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7660312,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,362514,-0.01844034714043575
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7774682,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2009,48782,0.0140440739009108
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7495030,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,338600,0.04248200735298457
"Construction of a Full Text Corpus for Biomedical Text Mining    DESCRIPTION (provided by applicant):       There is a demonstrated community need for an annotated corpus consisting of the full texts of biomedical journal articles. There are many reasons to believe that the rate-limiting factor impeding progress in biomedical language processing today is the lack of availability of the right kind of expertly annotated data. An annotated corpus is a collection of texts with information about the meaning or structure associated with particular textual elements. Annotated corpora are a critical component of biomedical natural language processing research in two ways. First, most contemporary approaches to language processing rely at least in part on machine learning or statistical models. Such systems must be ""trained"" on sets of examples with known outputs, so annotated corpora provide the training data vital to the construction of modern NLP systems. Second, annotated corpora provide the gold standard by which various approaches to particular text mining tasks are evaluated. Due to their central roles in training and testing language processing systems, the quality of the design and operational creation of annotated corpora place fundamental limits on what can be accomplished with such systems. Although there has been valuable work done on annotating abstracts, there are important differences between abstracts and full-text articles from a text mining perspective, and annotation of full-text journal articles has been negligible. Workers in both the biological (especially model organism database curation) community and the text mining community have independently pointed out the importance of processing the full text of scientific publications if the biomedical world is to be able to fully utilize text mining. We propose to build a large, fully annotated corpus consisting of full texts of biomedical journal articles. Additionally, previous biomedical corpus annotation efforts have often utilized ad hoc ontologies that have limited their utility outside of the groups that created them. We will ensure community acceptability by annotating with respect to community-consensus ontologies such as the Gene Ontology and the UMLS. Since the task involves expensive human labor, efficiency is a key issue in creating corpora. For this reason, we propose to build a team that includes the builder of the largest semantically annotated corpus to date, one of the pioneers of the model organism databases, and an already-assembled cadre of experienced linguistic and domain-expert annotators.             n/a",Construction of a Full Text Corpus for Biomedical Text Mining,7495148,G08LM009639,"['Address', 'Agreement', 'Biological', 'Biology', 'Body of uterus', 'Collection', 'Communities', 'Consensus', 'Data', 'Databases', 'Development', 'Elements', 'Ensure', 'Facility Construction Funding Category', 'Feedback', 'Genes', 'Gold', 'Growth', 'Human', 'Light', 'Linguistics', 'Literature', 'MEDLINE', 'Machine Learning', 'Manuals', 'Measures', 'Metric', 'Monitor', 'Natural Language Processing', 'Nature', 'Numbers', 'Ontology', 'Output', 'Problem Solving', 'Procedures', 'Process', 'Publications', 'Published Comment', 'Rate', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scheme', 'Series', 'Standards of Weights and Measures', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'Today', 'Training', 'Unified Medical Language System', 'Work', 'abstracting', 'base', 'design', 'experience', 'indexing', 'information organization', 'innovation', 'journal article', 'language processing', 'model organisms databases', 'programs', 'quality assurance', 'text searching', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,G08,2008,132030,0.02762293907860695
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7394699,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Reporting', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Thinking', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2008,429955,0.014637123689031861
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7478824,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,177729,0.007545422258958811
"When cues converge: multiple regularities in language acquisition    DESCRIPTION (provided by applicant): The goal of this research project is to employ behavioral and computational methods to better understand how infants use multiple regularities when learning language. Many researchers have posited that infants use statistical learning mechanisms to extract these regularities. However, the majority of this work focuses on infants' abilities to exploit a single regularity. In their natural environment, infants receive input that contains many overlapping regularities of varying consistency. Little research has focused on how infants process this type of input. In order to make use of the cues available in natural input, infants must be able to exploit these overlapping probabilistic regularities. The first aim of this grant is to explore how infants use multiple regularities to find words in fluent speech. By 9 months, infants are able to robustly use both lexical stress and sequential statistics to segment words. However, prior research has focused on how infants use these regularities in isolation, or how weighting of the cues changes developmentally. We hypothesize that infants can use these cues for word segmentation when they are probabilistic and overlapping, as they are in natural languages such as English. The second aim is to investigate the effect of multiple regularities on word learning. As a child's vocabulary grows, regularities arise among the labels and referents they know, as well as within the mappings between labels and referents. These regularities may affect the acquisition of new words. However, their potential role in subsequent word learning has not been carefully explored. Using computational models, we can examine these issues by carefully controlling regularities that exist within a vocabulary and by exploring how different types of regularities may affect word learning. These models can lead to a deeper understanding of these processing mechanisms and to novel predictions, which can then be tested in behavioral experiments.    Public Health Interests:  The goal of this research is to better understand how typically developing infants learn language - in particular, how they use the many patterns that exist in natural languages to do so. The ability to make use of multiple regularities likely affects infants' skills at language learning. By better understanding how this process unfolds in typically developing infants, researchers will be able to investigate how children with language delays and disabilities may differ in their ability to integrate multiple cues. In the future, this information will be useful for developing treatment plans.           n/a",When cues converge: multiple regularities in language acquisition,7488931,F31DC008737,"['Adherence', 'Affect', 'Behavioral', 'Body of uterus', 'Child', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Cues', 'Depth', 'Educational process of instructing', 'Environment', 'Face', 'Future', 'Goals', 'Grant', 'Infant', 'Label', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Maps', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Numbers', 'Pattern', 'Probability', 'Process', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Speech', 'Stress', 'System', 'Testing', 'Vocabulary', 'Weight', 'Work', 'design', 'disability', 'experience', 'interest', 'lexical', 'novel', 'research study', 'simulation', 'skills', 'sound', 'statistics', 'tool', 'treatment planning']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2008,31498,0.038643684999738304
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7488396,R01LM009254,"['Adoption', 'Affect', 'Agreement', 'Arts', 'Biomedical Research', 'Body of uterus', 'Collection', 'Computational Technique', 'Data', 'Development', 'Evaluation', 'Gold', 'Growth', 'Human', 'Judgment', 'Language', 'Lead', 'Literature', 'Machine Learning', 'Memory', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular Biology', 'Numbers', 'Pattern', 'Peer Review', 'Performance', 'Play', 'Process', 'Public Health', 'Publishing', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Retrieval', 'Review Literature', 'Role', 'Sampling', 'Scheme', 'Scientist', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'Work', 'abstracting', 'base', 'concept', 'improved', 'information organization', 'interest', 'journal article', 'language processing', 'novel strategies', 'prototype', 'size', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2008,268713,0.03600258246345253
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7677599,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2008,20000,0.049944278012232154
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7474790,R01LM008111,"['Address', 'Biomedical Research', 'Body of uterus', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Numbers', 'Ontology', 'Phenotype', 'Rate', 'Readiness', 'Representations, Knowledge (Computer)', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'concept', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2008,614419,0.027871582085367348
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7475712,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,438476,0.03662615929610259
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7671784,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,48482,0.03662615929610259
"The Role of Statistical Learning in Acquiring Syntactic Categories    DESCRIPTION (provided by applicant): The proposed experiments will investigate the role of statistical learning in the acquisition of syntactic categories such as ""noun"" and ""verb"". The role of syntactic category knowledge in language acquisition is pervasive; for example, category knowledge both facilitates learning grammatical patterns and facilitates early word learning. While many aspects of language acquisition rely on syntactic category knowledge, the process by which these categories are learned is unclear. The goal of the proposed research is to test the hypothesis that statistical learning plays a role in acquiring syntactic categories. Words from different syntactic categories are distinguishable by statistical cues, such as their distributional properties (i.e., cooccurrence with other words), and their phonological properties (i.e., their sound structure), the first specific aim is to assess infants' sensitivity to these cues in the acquisition of noun and verb categories. If words' statistical properties are used in category learning, infants should be able to use these properties to identify novel category members in the early stages of category acquisition. Moreover, infants' ability to determine the category of novel words should reflect the degree to which they conform to the predominant statistical characteristics of the category, and training on these statistical properties should facilitate their use at younger ages. Infants' ability to categorize novel words will be assessed by testing whether they are mapped to object or action referents. The second specific aim is to test infants' ability to integrate statistical and semantic information in category learning. Acquisition of syntactic categories encompasses learning about both statistical properties and semantic properties, and these cues are correlated in natural language. If infants can integrate these cues, correlations between them should facilitate learning. Infants will be familiarized with an artificial language containing novel categories, and the correlations between statistical and semantic cues will be manipulated. If infants can integrate these cues, they should be better able to detect commonalities in the meanings of words within a category, and to learn the grammatical structures in which these words can occur, when cues are correlated than when they are not. Future studies will test children with Specific Language Impairment and other developmental language disorders (e.g., late talkers), who exhibit impaired word learning abilities and reduced sensitivity to distributional cues identifying syntactic categories. Testing children on these tasks will address the extent to which impaired statistical learning is a contributing factor in these disorders.          n/a",The Role of Statistical Learning in Acquiring Syntactic Categories,7408311,F32HD057698,"['Address', 'Age', 'Categories', 'Characteristics', 'Child', 'Cues', 'Disease', 'Exhibits', 'Future', 'Goals', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Learning', 'Machine Learning', 'Maps', 'Pattern', 'Play', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Staging', 'Structure', 'Testing', 'Training', 'member', 'novel', 'phonology', 'research study', 'sound', 'specific language impairment', 'syntax']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2008,46826,0.05787671569799698
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7579478,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computational Technique', 'Computerized Medical Record', 'Count', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Medical Surveillance', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'Numbers', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Pliability', 'Population', 'Positioning Attribute', 'Practice based research', 'Primary Health Care', 'Procedures', 'Process', 'Purpose', 'Range', 'Reaction', 'Records', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Role', 'Safety', 'Score', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'concept', 'data mining', 'design', 'experience', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2008,299619,0.02373866436945747
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7336359,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2008,270051,0.08353823579288656
"Constraints on Learning from Inconsistent Input All human learners with normal cognitive capacities who are exposed to language input in childhood  manage to acquire a language that looks very much like their input. However, at present we have little  idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning  mechanisms that underlie and support language learning. This is the focus of the research in this  proposal. Three general questions guide the research.(1) What are the constraints on language learning  mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or  are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if  'so, how? The proposed research examines these questions by investigating the learning of probabilistic  and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique  view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned.  Previous work has shown that learners can acquire probabilistic patterns, however they sometimes  impose consistency on variation. Moreover, children are more likely to change such patterns than are  adults. The present research expands on the earlier results, asking about the nature of the interaction  between learners and input. Series 1 asks about the nature of the input that makes some inconstancy  learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in  languages, asking questions about the specificity of computations learners can perform, the  representations over which such computations can be performed, and the effect of prior domain-specific  knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over  inconsistency at all.In particular, the studies examine whether working memory constraints, rather than  constraints stemming directly from the learning mechanisms themselves, are an important factor  influencing whether learners acquire the variation or instead impose regularity. Both series will be  conducted with adults and children to examine how learning changes over development. Although the  input in the proposed studies is somewhat atypical, the results from these studies will contribute to our  understanding of the learning mechanisms involved in language acquisition more generally, and  ultimately, this increases our understanding of both normal and disordered acquisition. n/a",Constraints on Learning from Inconsistent Input,7390362,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Computer information processing', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Numbers', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,180295,0.05374041923637342
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7414601,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2008,142400,0.029158106002143407
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7486009,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Numbers', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2008,49646,0.02195367360654671
"Linking Language Comprehension to Production Patterns    DESCRIPTION (provided by applicant): This project tests specific hypotheses about dependencies between language comprehension and production, which are typically studied independently. The PI's production-distribution-comprehension (PDC) account holds that utterance planning choices during language production yield distributional patterns in the language, in which certain syntactic structures co-vary with particular word choices, messages, and discourse environments. Comprehenders, through statistical learning during prior comprehension experiences, become highly sensitive to these patterns, and this sensitivity guides comprehension processes. Thus, many aspects of comprehension can ultimately be traced to task demands related to language production. Specific aims of the project include: (1) Link syntactic structure choice in production to mechanisms of sentence planning. (2) Compare the PDC account of comprehension to alternative views of relative clause interpretation. (3) Test the causal relations between production constraints, distributional patterns in the language, and comprehension performance. (4) Relate adult sentence comprehension to statistical learning. (5) Test the current limits of constraint-based models of language comprehension. The PDC approach offers a significant alternative to other views and also may inform language acquisition research by illuminating the role of distributional patterns in child language acquisition. The work also can inform language therapies for brain injured patients in several ways. First, sources of production difficulty are precisely investigated, as are accommodations that unimpaired speakers make in the face of this difficulty. Second, the project investigates the relationship between prior experience with a syntactic construction and comprehension difficulty, which can have implications for the amount and nature of practice that should be provided to patients to improve their comprehension of certain sentence types.         n/a",Linking Language Comprehension to Production Patterns,7426941,R01HD047425,"['Accounting', 'Address', 'Adult', 'Affect', 'Back', 'Brain', 'Brain Injuries', 'Characteristics', 'Child Language', 'Collaborations', 'Comprehension', 'Data', 'Dependence', 'Dependency', 'Depth', 'Disease', 'Environment', 'Face', 'Facility Construction Funding Category', 'Foxes', 'Human Characteristics', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Therapy', 'Learning', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Nature', 'Patients', 'Pattern', 'Performance', 'Play', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Short-Term Memory', 'Source', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Work', 'base', 'experience', 'feeding', 'improved', 'infancy', 'injured', 'insight', 'neuropathology', 'novel', 'preference', 'research study', 'statistics', 'stem', 'syntax', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2008,164747,0.10543934621995864
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7469551,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Condition', 'Constitutional', 'Depth', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Medical Surveillance', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'concept', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,392337,-0.01844034714043575
"Statistical NLP Analysis of Cross-discipline Clinical Text emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical inforrnatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6944955,F38LM008478,"['Categories', 'Clinical', 'Clinical Pathology', 'Computers', 'Coupled', 'Diagnosis', 'Discipline', 'Event', 'Fellowship', 'Goals', 'Human', 'Inpatients', 'Linguistics', 'Machine Learning', 'Medical', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Procedures', 'Radiology Specialty', 'Research', 'Statistical Study', 'Text', 'Training', 'Work', 'Writing', 'design', 'experience', 'knowledge base', 'skills', 'syntax', 'theories', 'tool', 'trend', 'ward']",NLM,UNIVERSITY OF UTAH,F38,2007,38768,0.02762303123605668
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7288319,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,345833,0.04248200735298457
"Construction of a Full Text Corpus for Biomedical Text Mining    DESCRIPTION (provided by applicant):       There is a demonstrated community need for an annotated corpus consisting of the full texts of biomedical journal articles. There are many reasons to believe that the rate-limiting factor impeding progress in biomedical language processing today is the lack of availability of the right kind of expertly annotated data. An annotated corpus is a collection of texts with information about the meaning or structure associated with particular textual elements. Annotated corpora are a critical component of biomedical natural language processing research in two ways. First, most contemporary approaches to language processing rely at least in part on machine learning or statistical models. Such systems must be ""trained"" on sets of examples with known outputs, so annotated corpora provide the training data vital to the construction of modern NLP systems. Second, annotated corpora provide the gold standard by which various approaches to particular text mining tasks are evaluated. Due to their central roles in training and testing language processing systems, the quality of the design and operational creation of annotated corpora place fundamental limits on what can be accomplished with such systems. Although there has been valuable work done on annotating abstracts, there are important differences between abstracts and full-text articles from a text mining perspective, and annotation of full-text journal articles has been negligible. Workers in both the biological (especially model organism database curation) community and the text mining community have independently pointed out the importance of processing the full text of scientific publications if the biomedical world is to be able to fully utilize text mining. We propose to build a large, fully annotated corpus consisting of full texts of biomedical journal articles. Additionally, previous biomedical corpus annotation efforts have often utilized ad hoc ontologies that have limited their utility outside of the groups that created them. We will ensure community acceptability by annotating with respect to community-consensus ontologies such as the Gene Ontology and the UMLS. Since the task involves expensive human labor, efficiency is a key issue in creating corpora. For this reason, we propose to build a team that includes the builder of the largest semantically annotated corpus to date, one of the pioneers of the model organism databases, and an already-assembled cadre of experienced linguistic and domain-expert annotators.             n/a",Construction of a Full Text Corpus for Biomedical Text Mining,7301251,G08LM009639,"['Address', 'Agreement', 'Biological', 'Biology', 'Body of uterus', 'Collection', 'Communities', 'Consensus', 'Data', 'Databases', 'Development', 'Elements', 'Ensure', 'Facility Construction Funding Category', 'Feedback', 'Genes', 'Gold', 'Growth', 'Human', 'Light', 'Linguistics', 'Literature', 'MEDLINE', 'Machine Learning', 'Manuals', 'Measures', 'Metric', 'Monitor', 'Natural Language Processing', 'Nature', 'Numbers', 'Ontology', 'Output', 'Problem Solving', 'Procedures', 'Process', 'Publications', 'Published Comment', 'Rate', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scheme', 'Series', 'Standards of Weights and Measures', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'Today', 'Training', 'Unified Medical Language System', 'Work', 'abstracting', 'base', 'design', 'experience', 'indexing', 'information organization', 'innovation', 'journal article', 'language processing', 'model organisms databases', 'programs', 'quality assurance', 'text searching', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,G08,2007,130432,0.02762293907860695
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7305430,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,229030,0.007545422258958811
"When cues converge: multiple regularities in language acquisition    DESCRIPTION (provided by applicant): The goal of this research project is to employ behavioral and computational methods to better understand how infants use multiple regularities when learning language. Many researchers have posited that infants use statistical learning mechanisms to extract these regularities. However, the majority of this work focuses on infants' abilities to exploit a single regularity. In their natural environment, infants receive input that contains many overlapping regularities of varying consistency. Little research has focused on how infants process this type of input. In order to make use of the cues available in natural input, infants must be able to exploit these overlapping probabilistic regularities. The first aim of this grant is to explore how infants use multiple regularities to find words in fluent speech. By 9 months, infants are able to robustly use both lexical stress and sequential statistics to segment words. However, prior research has focused on how infants use these regularities in isolation, or how weighting of the cues changes developmentally. We hypothesize that infants can use these cues for word segmentation when they are probabilistic and overlapping, as they are in natural languages such as English. The second aim is to investigate the effect of multiple regularities on word learning. As a child's vocabulary grows, regularities arise among the labels and referents they know, as well as within the mappings between labels and referents. These regularities may affect the acquisition of new words. However, their potential role in subsequent word learning has not been carefully explored. Using computational models, we can examine these issues by carefully controlling regularities that exist within a vocabulary and by exploring how different types of regularities may affect word learning. These models can lead to a deeper understanding of these processing mechanisms and to novel predictions, which can then be tested in behavioral experiments.    Public Health Interests:  The goal of this research is to better understand how typically developing infants learn language - in particular, how they use the many patterns that exist in natural languages to do so. The ability to make use of multiple regularities likely affects infants' skills at language learning. By better understanding how this process unfolds in typically developing infants, researchers will be able to investigate how children with language delays and disabilities may differ in their ability to integrate multiple cues. In the future, this information will be useful for developing treatment plans.           n/a",When cues converge: multiple regularities in language acquisition,7286034,F31DC008737,"['Adherence', 'Affect', 'Behavioral', 'Body of uterus', 'Child', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Cues', 'Depth', 'Educational process of instructing', 'Environment', 'Face', 'Future', 'Goals', 'Grant', 'Infant', 'Label', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Maps', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Numbers', 'Pattern', 'Probability', 'Process', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Speech', 'Stress', 'System', 'Testing', 'Vocabulary', 'Weight', 'Work', 'design', 'disability', 'experience', 'interest', 'lexical', 'novel', 'research study', 'simulation', 'skills', 'sound', 'statistics', 'tool', 'treatment planning']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2007,31498,0.038643684999738304
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7287359,R01LM009254,"['Adoption', 'Affect', 'Agreement', 'Arts', 'Biomedical Research', 'Body of uterus', 'Collection', 'Computational Technique', 'Data', 'Development', 'Evaluation', 'Gold', 'Growth', 'Human', 'Judgment', 'Language', 'Lead', 'Literature', 'Machine Learning', 'Memory', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular Biology', 'Numbers', 'Pattern', 'Peer Review', 'Performance', 'Play', 'Process', 'Public Health', 'Publishing', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Retrieval', 'Review Literature', 'Role', 'Sampling', 'Scheme', 'Scientist', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'Work', 'abstracting', 'base', 'concept', 'improved', 'information organization', 'interest', 'journal article', 'language processing', 'novel strategies', 'prototype', 'size', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2007,350638,0.03600258246345253
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7326883,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2007,99773,0.049944278012232154
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7303652,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,435682,0.03662615929610259
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance  existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of  health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted  readability levels with no critical information loss, using statistical natural language processing  techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive  impact on reader comprehension. We will use as a test bed for our system a general internal medicine  clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public. n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7492453,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,47853,0.03534916803375353
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7144995,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2007,275672,0.08353823579288656
"Constraints on Learning from Inconsistent Input    DESCRIPTION (provided by applicant): All human learners with normal cognitive capacities who are exposed to language input in childhood manage to acquire a language that looks very much like their input. However, at present we have little idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning mechanisms that underlie and support language learning. This is the focus of the research in this proposal. Three general questions guide the research. (1) What are the constraints on language learning mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if 'so, how? The proposed research examines these questions by investigating the learning of probabilistic and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned. Previous work has shown that learners can acquire probabilistic patterns, however they sometimes impose consistency on variation. Moreover, children are more likely to change such patterns than are adults. The present research expands on the earlier results, asking about the nature of the interaction between learners and input. Series 1 asks about the nature of the input that makes some inconstancy learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in languages, asking questions about the specificity of computations learners can perform, the representations over which such computations can be performed, and the effect of prior domain-specific knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over inconsistency at all. In particular, the studies examine whether working memory constraints, rather than constraints stemming directly from the learning mechanisms themselves, are an important factor influencing whether learners acquire the variation or instead impose regularity. Both series will be conducted with adults and children to examine how learning changes over development. Although the input in the proposed studies is somewhat atypical, the results from these studies will contribute to our understanding of the learning mechanisms involved in language acquisition more generally, and ultimately, this increases our understanding of both normal and disordered acquisition.         n/a",Constraints on Learning from Inconsistent Input,7212176,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Computer information processing', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Numbers', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,186741,0.05441182900953423
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7195053,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2007,145510,0.029158106002143407
"Linking Language Comprehension to Production Patterns    DESCRIPTION (provided by applicant): This project tests specific hypotheses about dependencies between language comprehension and production, which are typically studied independently. The PI's production-distribution-comprehension (PDC) account holds that utterance planning choices during language production yield distributional patterns in the language, in which certain syntactic structures co-vary with particular word choices, messages, and discourse environments. Comprehenders, through statistical learning during prior comprehension experiences, become highly sensitive to these patterns, and this sensitivity guides comprehension processes. Thus, many aspects of comprehension can ultimately be traced to task demands related to language production. Specific aims of the project include: (1) Link syntactic structure choice in production to mechanisms of sentence planning. (2) Compare the PDC account of comprehension to alternative views of relative clause interpretation. (3) Test the causal relations between production constraints, distributional patterns in the language, and comprehension performance. (4) Relate adult sentence comprehension to statistical learning. (5) Test the current limits of constraint-based models of language comprehension. The PDC approach offers a significant alternative to other views and also may inform language acquisition research by illuminating the role of distributional patterns in child language acquisition. The work also can inform language therapies for brain injured patients in several ways. First, sources of production difficulty are precisely investigated, as are accommodations that unimpaired speakers make in the face of this difficulty. Second, the project investigates the relationship between prior experience with a syntactic construction and comprehension difficulty, which can have implications for the amount and nature of practice that should be provided to patients to improve their comprehension of certain sentence types.         n/a",Linking Language Comprehension to Production Patterns,7226029,R01HD047425,"['Accounting', 'Address', 'Adult', 'Affect', 'Back', 'Brain', 'Brain Injuries', 'Characteristics', 'Child Language', 'Collaborations', 'Comprehension', 'Data', 'Dependence', 'Dependency', 'Depth', 'Disease', 'Environment', 'Face', 'Facility Construction Funding Category', 'Foxes', 'Human Characteristics', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Therapy', 'Learning', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Nature', 'Patients', 'Pattern', 'Performance', 'Play', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Short-Term Memory', 'Source', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Work', 'base', 'experience', 'feeding', 'improved', 'infancy', 'injured', 'insight', 'neuropathology', 'novel', 'preference', 'research study', 'statistics', 'stem', 'syntax', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2007,168217,0.10543934621995864
Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing No abstract available n/a,Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing,8449372,R01PH000022,[' '],PHPPO,MAYO CLINIC ROCHESTER,R01,2007,157257,0.09444373726465335
"Analysis and Remediation of Language Production DESCRIPTION (provided by applicant): Aphasia strikes approximately one in 250 Americans. The reduced ability to communicate with language represents, in most cases, a catastrophic loss of self-sufficiency and a source of profound social isolation. No treatment for aphasia reported to date has reliably brought about changes in language production that migrate from highly constrained laboratory tasks such as single picture description to more challenging and socially functional tasks such as the production of entire narratives. The current climate in health care limits access to speech therapy, and thus it is imperative to develop approaches to treatment which allow patients to supplement 1:1 clinical treatment with intensive independent home practice. We have developed two computer programs to address the need for effective aphasia treatments that can be used semi-independently. One is a communication system (CS), which allows aphasic users to record spoken sentences a single word or phrase at a time, to replay these words or phrases, and to build them into sentences and narratives by manipulating visual icons on a computer screen. The other program is a language therapy system (TS) incorporating speech recognition and natural language understanding technology, which allows the computer to 'understand' the patient's spoken sentence and to provide feedback about whether it correctly describes a picture on the screen. This allows independent home practice of spoken language. The goals of this project are: (1) to replicate pilot results showing measurably more structured language production by aphasic patients using the CS, and to link these effects to characteristics of subjects' language processing impairments (Exp. 1); (2) to assess the impact of enhancing the CS with word-finding support for more severely impaired patients (Exp. 2); (3) to replicate the positive outcomes in pilot studies which used the TS and CS to improve aphasic patients' spoken language production, and to use the TS to train subjects on grammatical structures that provide tests of specific hypotheses about the impact of impaired short term memory on aphasic production (Exp. 3); and (4) to use data automatically collected by the CS to investigate the nature of the underlying disruption and to motivate the most effective approaches to remediation (Exp. 4). Information obtained from these studies will provide a basis for the further development of novel, theoretically motivated approaches to aphasia treatment. n/a",Analysis and Remediation of Language Production,7188572,R01DC005629,"['Address', 'American', 'Aphasia', 'Characteristics', 'Climate', 'Clinical Treatment', 'Communication', 'Computer software', 'Computers', 'Condition', 'Data', 'Development', 'Disruption', 'Elements', 'Employee Strikes', 'Evaluation', 'Facility Construction Funding Category', 'Feedback', 'Funding', 'Goals', 'Head', 'Healthcare', 'Home environment', 'Impairment', 'Knowledge', 'Laboratories', 'Language', 'Language Therapy', 'Linguistics', 'Link', 'Measures', 'Monitor', 'Natural Language Processing', 'Nature', 'Numbers', 'Outcome', 'Patients', 'Performance', 'Pilot Projects', 'Play', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reporting', 'Role', 'Semantics', 'Short-Term Memory', 'Social isolation', 'Source', 'Speech', 'Speech Therapy', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Visual', 'analytical method', 'aphasic', 'base', 'computer program', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'novel', 'phonology', 'programs', 'remediation', 'size', 'speech recognition', 'syntax', 'treatment effect']",NIDCD,UNIVERSITY OF MARYLAND BALTIMORE,R01,2007,337888,0.024354698745851826
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,7076099,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2006,162000,0.06111420360846526
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7147611,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372106,0.04248200735298457
Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing No abstract available n/a,Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing,7119574,R01PH000022,[' '],PHPPO,MAYO CLINIC,R01,2006,834535,0.09444373726465335
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7019753,G08LM008983,"['clinical research', 'public health']",NLM,SYRACUSE UNIVERSITY,G08,2006,149472,0.029158106002143407
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,7007660,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2006,29424,0.08775341199833171
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7135482,R01LM009254,"['abstracting', 'human', 'language', 'performance', 'training']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2006,369593,0.03600258246345253
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6898458,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2005,162000,0.06111420360846526
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6892934,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,384538,0.029304551001837608
"Biomedical Ontology and Tools for Database Curation DESCRIPTION (provided by applicant): This proposal describes a new tool for text data mining-a biomedical language ontology and integrated natural-language-processing methods. Our long-term goal is to provide resources for biomedical knowledge discovery from text. Our immediate goal is to provide a knowledge discovery tool for the curation of organism databases such as the Genome Database (SGD). The proposed research not only serves the research needs of the SGD community, it also helps the broader biomedical community exploit the strengths of the comparative approach to biological research. The hypothesis of this proposal is that knowledge discovery from biomedical text requires a knowledge base that integrates both genomic and linguistic information. This hypothesis is based on two observations: (a) the language of biomedicine, like all natural language, is complex in structure and morphology (the basic units of meaning) and poses problems of synonymy (several terms having the same meaning), polysemy (a term having more than one meaning), hypernymy (one term being more general than another), hyponymy (one term being more specific than another), denotation (what a term refers to in contrast to what it means), and denotation and description (different ways of referring to the same thing); and (b) important biomedical knowledge sources, such as the Gene Ontology (GO), are expressed in natural language. The specific aims of the proposed project are to: 1. Extend an existing biomedical language ontology to include genomic and linguistic data from SGD; 2. Use this ontology to discover, in full-text articles made available by SGD, information about the molecular function of yeast gene products that can be inferred from direct experimental assays; 3. Evaluate the effectiveness of the new tool and methods by comparing its results to those of the SGD curators for gene products that have GO functional annotations with evidence code IDA (Inferred from Direct Assay). n/a",Biomedical Ontology and Tools for Database Curation,6885487,R43HG003600,"['computer program /software', 'computer system design /evaluation', 'fungal genetics', 'information retrieval', 'information system analysis', 'molecular biology information system', 'yeasts']",NHGRI,"CONVERSPEECH, LLC",R43,2005,99250,0.02898657990343854
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6902613,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2005,220725,0.07392929781606039
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6847778,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2005,29424,0.08775341199833171
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6768325,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2004,135000,0.06111420360846526
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6782636,F32HD042927,"['artificial intelligence', 'auditory stimulus', 'behavior test', 'behavioral /social science research tag', 'child (0-11)', 'clinical research', 'comprehension', 'computer simulation', 'cues', 'developmental neurobiology', 'human subject', 'language development', 'neural information processing', 'postdoctoral investigator', 'syntax', 'verbal learning', 'visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2004,47296,-0.00337144149444565
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6754395,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,380979,0.029304551001837608
"Statistical NLP Analysis of Cross-discipline Clinical Text DESCRIPTION (provided by applicant):     An emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical informatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6836781,F38LM008478,"['bioinformatics', 'clinical research', 'computational biology', 'human data', 'library', 'mathematical model', 'public health', 'statistics /biometry']",NLM,UNIVERSITY OF UTAH,F38,2004,94545,0.025232369598941207
"Early Language Intervention via the Internet    DESCRIPTION (provided by applicant): This proposal requests SBIR Phase II support to complete and field test an Internet-based language intervention system designed to promote language development in preschool children with language disorders. Language delays are pervasive among school-age children. Early intervention is crucial since the consequences of language delay can be serious and cumulative. Yet research shows that most children with language delays never receive language intervention services during their preschool years. We propose to complete an Internet-based early language intervention system designed specifically for the remediation of language disorders in 3-5 year old children with language function in the range of 24-42 months. The curricular design will be guided by contemporary linguistic research. Online delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks performance and adjusts instructional support. By combining easy access via the Internet with centralized data collection and curricular control, it will become possible to implement and easily manage coordinated school and home language intervention strategies, and to provide services to more children without further taxing limited professional resources. In Phase I we tested the feasibility and technical merit of this objective. A prototype program module was developed and tested with 23 students who were enrolled in an Early Essential Education program, including 19 preschoolers with language delays. Data were collected over the Internet while testing six of these children. In Phase II we plan to fully develop and field-test this Internet-based language intervention system.         n/a",Early Language Intervention via the Internet,6795077,R44DC004487,"['Internet', 'behavioral /social science research tag', 'clinical research', 'computer assisted instruction', 'computer program /software', 'computer system design /evaluation', 'curriculum', 'data collection', 'education evaluation /planning', 'educational resource design /development', 'human subject', 'language development', 'language disorders', 'preschool child (1-5)', 'sociolinguistics', 'speech disorders', 'speech therapy', 'syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2004,606618,0.03410357294146539
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6754401,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2004,220725,0.07392929781606039
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6743829,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2004,29424,0.08775341199833171
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6647078,F32HD042927,"['artificial intelligence', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' clinical research', ' comprehension', ' computer simulation', ' cues', ' developmental neurobiology', ' human subject', ' language development', ' neural information processing', ' postdoctoral investigator', ' syntax', ' verbal learning', ' visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2003,41608,-0.00337144149444565
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6630735,R01LM006910,"['artificial intelligence', ' classification', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information system analysis', ' method development', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,377617,0.029304551001837608
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6657426,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2003,369494,0.0363180561527238
"Early Language Intervention via the Internet    DESCRIPTION (provided by applicant): This proposal requests SBIR Phase II support to complete and field test an Internet-based language intervention system designed to promote language development in preschool children with language disorders. Language delays are pervasive among school-age children. Early intervention is crucial since the consequences of language delay can be serious and cumulative. Yet research shows that most children with language delays never receive language intervention services during their preschool years. We propose to complete an Internet-based early language intervention system designed specifically for the remediation of language disorders in 3-5 year old children with language function in the range of 24-42 months. The curricular design will be guided by contemporary linguistic research. Online delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks performance and adjusts instructional support. By combining easy access via the Internet with centralized data collection and curricular control, it will become possible to implement and easily manage coordinated school and home language intervention strategies, and to provide services to more children without further taxing limited professional resources. In Phase I we tested the feasibility and technical merit of this objective. A prototype program module was developed and tested with 23 students who were enrolled in an Early Essential Education program, including 19 preschoolers with language delays. Data were collected over the Internet while testing six of these children. In Phase II we plan to fully develop and field-test this Internet-based language intervention system.         n/a",Early Language Intervention via the Internet,6644533,R44DC004487,"['Internet', ' behavioral /social science research tag', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' curriculum', ' data collection', ' education evaluation /planning', ' educational resource design /development', ' human subject', ' language development', ' language disorders', ' preschool child (1-5)', ' sociolinguistics', ' speech disorders', ' speech therapy', ' syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2003,819451,0.03410357294146539
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6615572,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2003,114544,0.08049041201868734
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6679518,R01MH066228,"['behavioral /social science research tag', ' clinical research', ' computational neuroscience', ' human middle age (35-64)', ' human subject', ' language', ' neural information processing', ' neuropsychology', ' psychopathology', ' schizophrenia', ' short term memory', ' young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2003,220725,0.07392929781606039
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6622537,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2003,28193,0.11670713077788006
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6551481,F32HD042927,"['artificial intelligence', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' clinical research', ' comprehension', ' computer simulation', ' cues', ' developmental neurobiology', ' human subject', ' language development', ' neural information processing', ' postdoctoral investigator', ' syntax', ' verbal learning', ' visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2002,36592,-0.00337144149444565
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6528316,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2002,360015,0.0363180561527238
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,1,0.02438128287591328
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6539200,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2002,152849,0.08049041201868734
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6450183,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2002,26141,0.11670713077788006
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6528412,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2002,325555,-0.004073268999739123
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6490773,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2002,288252,-0.0108191094074158
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6448720,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2001,356099,0.0363180561527238
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6399830,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2001,145788,0.08049041201868734
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6404288,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2001,673495,-0.004073268999739123
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6095940,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2001,303860,-0.0108191094074158
"IMIA WG6 CONFERENCE The basic science of representing patient events, findings, interventions, and outcomes in a semantically consistent and logically reproducible way is medical concept representation.  It embodies principles of linguistics, logic, computer science, cognition, biology and clinical medicine to undertake this highly multidisciplinary activity. Much of this work is undertaken in experimental settings, which hypothesize practical extensions to existing models, and test their utility against standardized retrieval sets or clinical usability environments. The proposed conference intends to continue the tradition of the International Medical Informatics Association (IMIA), Working Group 6 on Medical Concept Representation, to provide a forum for the academic discussion of problems, issues, theories, and applications of natural language processing, knowledge representation, terminology development, and concept coordination to biomedicine and healthcare.  the proposed tracks at this time are: 1. Natural Language Processing  2. Clinical Classifications 3. Cognitive Evaluations  4. Terminology Models  5. Maintenance and Uptake Strategies.  n/a",IMIA WG6 CONFERENCE,6027283,R13LM006899,"['informatics', ' international health /scientific organization', ' meeting /conference /symposium', ' travel']",NLM,MAYO CLINIC ROCHESTER,R13,2000,20000,0.03872971030581999
"EARLY LANGUAGE INTERVENTION VIA THE INTERNET Language delay is pervasive among preschool children. Early intervention is crucial since the consequences of language delay can be serious and cumulative, yet research shows that most preschoolers do not receive language intervention services. We propose to develop an Internet-based early language intervention system designed specifically for the remediation of language disorders in three to five-year-old children with language function in the range of 24 to 42 months. The curricular design will be based on contemporary linguistic research. On-line delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks ongoing performance. By combining Internet accessibility with centralized curricular control and data collection, it will become possible to implement and easily manage coordinated school and home language intervention strategies. It will also be possible to provide services to more children without further taxing limited professional resources. Our Phase I goal is to test the feasibility and technical merit of our plans. A prototype internet-based language intervention system will be developed and placed on- line in an Early Essential Education classroom, and students with language delays will be given an opportunity to use the system. PROPOSED COMMERCIAL APPLICATIONS: Speech-language pathologists, teachers, and parents recognize the importance of early intervention when a child's language status is impaired, and Federal law mandates such intervention. We anticipate that a highly accessible Internet-based language intervention system for three to five year olds will fulfill an unmet need for individualized services and will be a commercial success.  n/a",EARLY LANGUAGE INTERVENTION VIA THE INTERNET,6142025,R43DC004487,"['Internet', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' curriculum', ' early experience', ' educational resource design /development', ' elementary school', ' human subject', ' language development', ' language disorders', ' online computer', ' preschool child (1-5)']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R43,2000,117683,0.05399082406124207
"A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications PROJECT SUMMARY/ABSTRACT  In radiology practices, timely and accurate formulation of reports is closely linked to patient satisfaction, physician productivity, and reimbursement. While the American College of Radiology and the Radiological Soci- ety of North America have recommended implementation of structured reporting to facilitate clear and consistent communication between radiologists and referring clinicians, cumbersome nature of current structured reporting systems made them unpopular amongst their users. Recently, the emerging techniques of deep learning have been widely and successfully applied in many different natural language processing tasks (NLP). However, when adopted in a certain speciﬁc domain, such as radiology, these techniques should be combined with extensive domain knowledge to improve efﬁciency and accuracy. There is, therefore, a critical need to take advantage of clinical NLP and deep learning to fundamentally change the radiology reporting. The long-term goal in this appli- cation is to improve the form, content, and quality of radiology reports and to facilitate rapid generation of radiol- ogy reports with consistent organization and standardized texts. The overall objective is to use radiology-speciﬁc ontology, NLP and computer vision techniques, and deep learning to construct a radiology-speciﬁc knowledge graph, which will then be used to build a reporting system that can assist radiologists to quickly generate struc- tured and standardized text reports. The rationale for this project is that through integration of new clinical NLP technologies, radiology-speciﬁc knowledge graphs, and development of new reporting system, we can build au- tomatous systems with a higher-level understanding of the radiological world. The speciﬁc aims of this project are to: (1) recognize and normalize named entities in radiology reports; (2) construct a radiology-speciﬁc knowledge graph from free-text and images; and (3) build a reporting system that can dynamically adjust templates based on radiologists' prior entries. The research proposed in this application is innovative, in the applicant's opinion, because it combines deep learning, NLP techniques, and domain knowledge in a single framework to construct comprehensive and accurate knowledge graphs that will enhance the workﬂow of the current reporting systems. The proposed research is signiﬁcant because a novel reporting system can expedite radiologists' workﬂow and acquire well-annotated datasets that facilitate machine learning and data science. To develop such a method, the candidate, Dr. Yifan Peng, requires additional training and mentoring in clinical NLP and radiology. During the K99 phase, Dr. Peng will conduct this research as a research fellow at the National Center for Biotechnology Information. He will be mentored by Dr. Zhiyong Lu, a leading text mining and deep learning researcher, and co- mentored by Dr. Ronald M. Summers, a leading radiologist and clinical informatics researcher. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Peng to achieve the career goals of becoming an independent investigator and leader in the study of clinical NLP. PROJECT NARRATIVE The proposed research is relevant to public health because it entails a new strategy to construct a radiology- speciﬁc knowledge graph to facilitate the development of a new reporting system that enables rapid generation of structured radiology reports. The proposed knowledge graph and reporting system will contribute to advancement in understanding of the radiological world, and promise to enhance clinical communication and patient-centric care. Thus, the proposed research is relevant to the part of the NLM's mission that pertains to applying deep knowledge of clinical terminology and natural language processing to improve clinical data science and health services.",A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications,10197509,R00LM013001,"['Address', 'Adopted', 'American College of Radiology', 'Award', 'Biotechnology', 'Caring', 'Client satisfaction', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communication', 'Complex', 'Computer Vision Systems', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Formulation', 'Generations', 'Goals', 'Health Services', 'Hospitals', 'Hybrids', 'Image', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Mission', 'Modeling', 'Mus', 'Names', 'Natural Language Processing', 'Nature', 'Nomenclature', 'North America', 'Ontology', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Physicians', 'Picture Archiving and Communication System', 'Process', 'Productivity', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resort', 'Societies', 'Standardization', 'Structure', 'System', 'Systems Development', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Voice', 'Writing', 'base', 'career', 'career development', 'convolutional neural network', 'deep learning', 'deep neural network', 'impression', 'improved', 'innovation', 'knowledge graph', 'lexical', 'long short term memory', 'neural network', 'neural network architecture', 'novel', 'radiologist', 'repository', 'response', 'syntax', 'text searching']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,R00,2020,236549,0.011965471983681333
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10011177,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2020,503546,0.022935755267114742
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9986899,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Information Retrieval', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'adaptation algorithm', 'base', 'case finding', 'improved', 'machine learning method', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'structured data', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,383874,0.022059931157974718
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,9998610,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,855710,0.0016143210157460678
"Natural Language Processing and Machine Learning for Cancer Surveillance The purpose of this call order is to provide support in the area of quality control and improvement of cancer data, specifically for Clinical Document Annotation and Processing Pipeline (CDAP), LabKey Software, and the development of annotation schema. n/a",Natural Language Processing and Machine Learning for Cancer Surveillance,10281318,6116004B91020F00002,"['Area', 'Automated Annotation', 'Clinical', 'Data', 'Machine Learning', 'Malignant Neoplasms', 'Natural Language Processing', 'Quality Control', 'software development']",NCI,"WESTAT, INC.",N02,2020,149865,0.009410258888147813
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,9957898,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2020,271250,0.019517579560529325
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,10005506,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Pooling', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data infrastructure', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phenotyping algorithm', 'phrases', 'portability', 'preservation', 'privacy preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2020,1500847,0.006535932008150556
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,9906653,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Behavior', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2020,45016,0.015907885155326908
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9930152,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2020,20000,0.01270682847110186
"Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App PROJECT SUMMARY Background: Depression during pregnancy and the postpartum period affects up to 15% of US mothers, imposing costs on mother, child, and society. Early detection can significantly reduce the incidence of depression, yet depressive symptoms are often missed during prenatal visits, which tend to focus on maternal and fetal physical health, leaving less time for maternal mental health. Even if mental health is addressed during prenatal care, women may not feel comfortable answering questions that are perceived to be embarrassing or invasive. Failing to detect depression is even more likely during the postpartum period due to infrequent physician visits once the baby has been born. Measurement in the form of daily journals, which can be analyzed using natural language processing, can promote early and more frequent detection of depression during pregnancy and the postpartum period. Study Aims: 1) Model which dynamic features of language used over time best predict changes in depression status in the pregnancy and postpartum periods, creating phenotypes of depression risk; 2) examine how the language patterns that predict depression differ for African-American and Caucasian women; and 3) identify the relationship between the characteristics of what depressed peripartum women say and their treatment-seeking behavior. Innovation: The proposed research is innovative in its use of high frequency natural language measurements, captured in daily journals using a smartphone app, combined with advances in natural language processing models, to assess the onset and trajectory of depression during pregnancy and the postpartum period. This is the first prospective longitudinal study using natural language collection for risk prediction in a clinical population and the first to: 1) characterize the critical topics women discuss during the peripartum period over time using open-ended journals; 2) evaluate multiple facets of language to gain a more comprehensive understanding of the relationship between language and depression; 3) use a longitudinal design approach allowing for optimal modeling of language changes associated with depression onset. Methodology and Expected Results: Monthly depression risk identified from the Edinburgh Postnatal Depression Scale. will be collected through the MyHealthyPregnancy smartphone app, a mobile health application developed through close collaboration between decision scientists, clinicians, statisticians, and local peripartum women. A daily journal embedded in the MyHealthyPregnancy app will collect natural language text from the participants for 10 months (from their first prenatal visit through two months postpartum). Using three distinct natural language processing algorithmic approaches, this study will characterize how the natural language used by peripartum women in their daily journal entries is connected to the onset and experience of peripartum depression, as measured through monthly-administered depression scales. Group- based trajectory modeling will then classify women according to the patterns in their depression scores over time. Potential Impact: This work lays the foundation for developing and evaluating real-time interventions that could be deployed at scale to women who are using language that signals high depression risk. PROJECT NARRATIVE This research will examine how the topics (the people and events mentioned), sentiment (the positive, negative, and neutral affect), and other aspects of language expressed in daily journal entries correspond to diagnostic measures of depression and treatment-seeking in a peripartum clinical population. Psychometric and daily journal entry data will be gathered through an existing smartphone app, MyHealthyPregnancy, which monitors risk and delivers actionable information as part of routine prenatal care provided to the pregnant members of a large regional healthcare system.",Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App,9892136,R21MH119450,"['Address', 'Affect', 'African American', 'Algorithms', 'Appointment', 'Behavior', 'Behavioral Sciences', 'Birth', 'Caring', 'Caucasians', 'Characteristics', 'Child', 'Childbirth', 'Clinical', 'Collaborations', 'Collection', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Developmental Delay Disorders', 'Diagnostic', 'Disclosure', 'Early Diagnosis', 'Early treatment', 'Emotions', 'Environment', 'Event', 'Failure to Thrive', 'Feeling', 'Foundations', 'Frequencies', 'Healthcare Systems', 'Incidence', 'Infant', 'Intervention', 'Journals', 'Language', 'Longitudinal observational study', 'Longitudinal prospective study', 'Measurable', 'Measurement', 'Measures', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Moods', 'Mothers', 'National Institute of Mental Health', 'Natural Language Processing', 'Participant', 'Patients', 'Pattern', 'Perinatal', 'Phenotype', 'Physicians', 'Population', 'Postpartum Depression', 'Postpartum Period', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Prenatal care', 'Psychometrics', 'Race', 'Reporting', 'Research', 'Risk', 'Risk Assessment', 'Scientist', 'Signal Transduction', 'Societies', 'Source', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Visit', 'Voice', 'Well in self', 'Woman', 'Work', 'antepartum depression', 'base', 'cohort', 'cost', 'depression model', 'depressive symptoms', 'experience', 'fetal', 'health assessment', 'improved', 'innovation', 'longitudinal design', 'machine learning algorithm', 'member', 'motherhood', 'natural language', 'patient subsets', 'peripartum depression', 'physical conditioning', 'pregnant', 'racial disparity', 'response', 'routine screening', 'smartphone Application', 'social culture', 'sociodemographics', 'statistical and machine learning', 'time use', 'vector']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,233832,0.04162384492509497
"SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement.  Many clinical trials fail to meet their accrual and retention goals, which leads to delays, early termination, or inability to draw conclusions at trial completion due to loss of statistical power. NCI wants to enhance clinical trials recruitment and retention by developing tools that could enhance communication between participants and study staff. In this Phase 1 tool development application we address the NCI interest in simplified informed consent documents that enhance personal communication during the informed consent process. In this Phase I proposal we leverage natural language processing technology and our teams prior work on the Informed Consent Ontology (ICO) to improve the language in consent documents related specifically to permissions granted by a research participant. n/a",SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement. ,10265762,5N91020C00017,"['Address', 'Authorization documentation', 'Clinical Trials', 'Communication', 'Comprehension', 'Consent Forms', 'Goals', 'Grant', 'Health', 'Informed Consent', 'Language', 'Natural Language Processing', 'Ontology', 'Participant', 'Personal Communication', 'Phase', 'Process', 'Research', 'Small Business Innovation Research Grant', 'Technology', 'Work', 'base', 'cancer clinical trial', 'improved', 'interest', 'prototype', 'recruit', 'tool', 'tool development', 'user-friendly']",NCI,"MELAX TECHNOLOGIES, INC.",N43,2020,400000,0.038370330369608345
"Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence ABSTRACT  Approximately 15% of toddlers 18-36 months of age experience late language emergence (LLE; Paul, 1992; Singleton, 2018). These late talkers (LTs) have a reduced expressive vocabulary, but average non-linguistic abilities, in the absence of overt sensory or other developmental delays (Collisson, 2016; Paul & Jennings, 1992). Upwards of 16% of LTs prospectively meet criteria for language disorder (Rescorla, 2009), while others retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). LTs are at elevated risk for lifelong language and literacy impairments that negatively impact access to academic and vocational opportunities (Singleton, 2018; Paul, 1993), and even subclinical outcomes have pervasive negative impacts (Rescorla, 2002). This project addresses questions crucial for the early diagnosis of LTs and prerequisite to the applicant’s long-term goal of establishing an independent research program on LLE, aimed ultimately at identifying variation and distribution of behavioral phenotypes to provide a foundation for more targeted interventions for LTs. This project complements prior work on LLE focused on language production by evaluating the time course of word learning and spoken word recognition in LTs and 2 control groups (age- and language-matched typically developing peers), all of whom will complete standardized assessments of cognitive -linguistic abilities. In Expt. 1, participants will train on a simple selection task using 4 novel and 4 familiar words that overlap phonologically (e.g., at onset, BUNNY-BUTTON, or offset, KITTEN-MITTEN). We will use eye tracking to estimate group and individual differences in lexical activation and competition over time. In Expt. 2, we will record EEG (electroencephalography) in a passive listening task. Participants will watch a silent video as newly-learned and familiar words from Expt. 1 are repeated. ERP (event-related potential) analyses will examine individual and group differences in responses to newly-learned vs. familiar words. We will also use machine-learning (support vector machines, SVMs) to decode EEG responses to specific words for each participant, on the logic that fidelity and coherence of responses will determine SVM classification success. Group and individual differences in eye tracking, ERP, and/or EEG-decoding measures will provide new insights into receptive abilities of LTs, and provide a basis for future work aimed at identifying LTs with greatest risk for clinical or subclinical language outcomes. The project will take place at the U. of Connecticut and Haskins Labs. The applicant and sponsors have developed a training plan for the applicant focused on further developing her (1) EEG and statistical skills, (2) knowledge base of the cognitive neuroscience of typical and atypical language development, (3) dissemination skills, and (4) understanding of principles for the responsible conduct of research, with the aim of supporting her goal to be an independent researcher in a Research-1 environment. PROJECT NARRATIVE  Approximately 15% of toddlers meet criteria for being a late talker (LT) (Paul, 1993; Singleton, 2018;) and upwards of 16% of LTs prospectively meet criteria for spoken and/or written language disorder (Rescorla, 2009) while another subset will retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). Late language emergence (LLE) is associated with lifelong clinical and subclinical weaknesses in language and literacy that negatively impact access to academic and vocational opportunities (Paul, 1993; Singleton, 2018), and even subclinical outcomes have a negative impact on vocational and higher educational choices (Rescorla, 2002). The proposed research will address questions prerequisite to the applicant's long-term goal of establishing an independent research program aimed at (1) identifying early markers of chronic impact in order to optimally allocate scarce early intervention resources and (2) identifying variation and distribution of behavioral phenotypes which will provide the foundation for more focused and targeted forms of interventions for LTs with a range of clinical and subclinical language outcomes.",Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence,9975626,F31DC018220,"['3 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Behavioral', 'Child', 'Chronic', 'Classification', 'Clinical', 'Cognitive', 'Complement', 'Complex', 'Connecticut', 'Control Groups', 'Development', 'Developmental Delay Disorders', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Endowment', 'Environment', 'Evaluation', 'Event-Related Potentials', 'Exclusion', 'Foundations', 'Future', 'Goals', 'Grain', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Logic', 'Machine Learning', 'Measures', 'Morphology', 'Neurobiology', 'Outcome', 'Output', 'Participant', 'Phenotype', 'Population', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Risk', 'School-Age Population', 'Sensory', 'Signal Transduction', 'Speech', 'Speed', 'Standardization', 'Testing', 'Time', 'Toddler', 'Training', 'Variant', 'Visual', 'Vocabulary', 'Word Processing', 'Work', 'base', 'behavioral phenotyping', 'clinical risk', 'cognitive neuroscience', 'experience', 'experimental study', 'high risk', 'improved outcome', 'insight', 'knowledge base', 'language impairment', 'language outcome', 'language processing', 'lexical', 'lexical processing', 'literacy', 'multimodality', 'neural correlate', 'novel', 'peer', 'phonology', 'programs', 'prospective', 'reduce symptoms', 'relating to nervous system', 'response', 'responsible research conduct', 'skills', 'social', 'sound', 'success', 'support vector machine', 'trait', 'visual tracking', 'word learning']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,F31,2020,15602,0.0762582393759724
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9825536,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'automated speech recognition', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,574747,0.045041443950685434
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9894782,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,517151,0.023671225958405855
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9895715,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,583798,0.07499281276017103
"Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis PROJECT SUMMARY Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with chronic aphasia in a number of small studies, many of which did not include a control group. Although the treatment appears promising, data to date do not permit an adequate assessment of the utility of the technique. We propose to study the effects of TMS combined with Constraint Induced Language Therapy (CILT) in 75 subjects with chronic aphasia. Subjects will be randomized in a 2:1 ratio to TMS with CILT or sham TMS with CILT. One Hz TMS at 90% motor threshold will be delivered to the right inferior frontal gyrus for 20 minutes in 10 sessions over 2 weeks; language therapy will be provided for one hour immediately after the conclusion of each session of TMS. Change from baseline in the Western Aphasia Battery Aphasia Quotient at 6 months after the end of TMS treatment will serve as the primary outcome measure. A secondary aim is to identify anatomic and behavioral predictors of response to treatment. Finally, a third aim is to identify the mechanism underlying the beneficial effect of the treatment using a variety of imaging techniques. Subjects who have no contraindication to the MRI will undergo fMRI imaging prior to and at 6 months after therapy. Using modern network analyses and robust machine learning techniques we will identify changes in the strengths of connections between nodes in the language network to address specific hypotheses regarding the effects of TMS and CILT on brain organization that are associated with beneficial response to treatment. PROJECT NARRATIVE Although Transcranial Magnetic Stimulation (TMS) has been demonstrated to improve language function in subjects with aphasia in many small studies, its general clinical utility has not been established. We propose to study the effects of TMS combined with Constraint Induced Language Therapy in a double-blinded study of 75 subjects with chronic aphasia. Additional aims are to identify anatomic and behavioral predictors of response to treatment and identify the mechanisms underlying the beneficial effect of using modern neuroimaging techniques.",Transcranial Magnetic Stimulation for Aphasia: Efficacy and Neural Basis,10000088,R01DC016800,"['Acquired Language Disorders', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Aphasia', 'Behavioral', 'Brain', 'Brain imaging', 'Chronic', 'Clinical', 'Control Groups', 'Data', 'Disease', 'Double-Blind Method', 'Functional Magnetic Resonance Imaging', 'Hour', 'Image', 'Imaging Techniques', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Investigation', 'Language', 'Language Therapy', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modernization', 'Motor', 'Neurosciences', 'Outcome Measure', 'Participant', 'Pathway Analysis', 'Performance', 'Persons', 'Prevalence', 'Procedures', 'Psycholinguistics', 'Randomized', 'Rehabilitation therapy', 'Research Design', 'Research Personnel', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Techniques', 'Testing', 'Therapeutic Effect', 'Transcranial magnetic stimulation', 'Work', 'aphasia recovery', 'behavioral neurology', 'clinical investigation', 'effective therapy', 'improved', 'insight', 'interest', 'neuroimaging', 'neuroregulation', 'predicting response', 'primary outcome', 'relating to nervous system', 'response', 'treatment effect', 'treatment response', 'white matter']",NIDCD,UNIVERSITY OF PENNSYLVANIA,R01,2020,581446,0.025170614964850332
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,-0.03618426259890054
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9997876,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,283332,-0.022754025585153485
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9944489,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2020,39939,0.018288544732774845
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9875268,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach', 'visual tracking']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2020,585545,0.09711183279416773
"Hippocampal-cortical networks underlying memory retrieval of linguistic knowledge ABSTRACT Language and memory overlap heavily in brain circuitry and in our day-to-day lives. Both are also frequently disrupted in neurological conditions such as temporal lobe epilepsy and Alzheimer’s disease. We have a limited understanding of the mechanisms by which cortical language centers integrate with memory circuits; for example, to support the retrieval of linguistic knowledge. This limits our insight into disease pathophysiology and slows the development of more effective therapies for cognitive impairments. This K23 will support an investigation of how language and memory integrate in the human brain, by harnessing unique innovations and resources. First, we will use special high-density grid and depth electrodes to record from many hundreds of local neuronal populations distributed throughout memory and language centers, among patients undergoing intracranial monitoring for refractory epilepsy. Second, to target distinct moments of linguistic-mnemonic integration, we have customized an auditory naming behavioral task that combines controlled yet natural language stimuli with memory retrieval of linguistic knowledge. Third, I will apply state-of-the-art analyses with pattern classifiers and computational linguistics, an approach that could improve the framework of how we understand neural representations of deep language processing. I will first evaluate whether the activity patterns in cortical language centers and the hippocampus reveal neural signatures of dynamic integration during knowledge retrieval, and whether their activity patterns reflect mutual information sufficient to predict the linguistic content of task trials (Aim 1). I will then use electrical stimulation to selectively disrupt neural processing in these regions, to determine if and how they contribute to distinct stages of language and memory integration (Aim 2). This approach will also allow us to probe whether the hippocampus is required for semantic memory, a long-debated question arising from classic literature. My mentorship team has a constellation of expertise aligning with my training plan and the goals of this investigation, including cortical language neurophysiology, hippocampal memory neurophysiology, and investigative neurostimulation. This proposal builds upon my prior expertise in translational intracranial recordings and neural signal processing, and my long-term career goal of understanding and improving treatments for cognitive impairments in epilepsy. I will receive training, coursework, and direct mentorship in skillsets that I will continue to use throughout my scientific career, including language and memory neurophysiology, human neurostimulation, neuroethics, machine learning, computational linguistics, scientific communication, and independent laboratory management. The knowledge and training acquired during this award period will allow me to establish an independent laboratory and emerge as a leader in human intracranial neurophysiology, applying my expertise to unmet needs in epilepsy. NARRATIVE Memory and language functions can be devastatingly impaired by neurological diseases such as temporal lobe epilepsy and Alzheimer’s disease. This investigation seeks to understand how the neural circuits that underlie these functions work together to retrieve knowledge from memory, a precious human ability used in our day-to- day lives. This will have important relevance for basic neuroscience, clinical pathophysiology, and the development of future therapeutics for cognitive impairments.",Hippocampal-cortical networks underlying memory retrieval of linguistic knowledge,9906282,K23NS110920,"['Address', 'Alzheimer&apos', 's Disease', 'Animal Experimentation', 'Animals', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Clinical', 'Cognition', 'Communication', 'Comprehension', 'Computational Linguistics', 'Custom', 'Data', 'Data Analyses', 'Dementia', 'Development', 'Disease', 'Electric Stimulation', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Etiology', 'Event', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Hippocampus (Brain)', 'Human', 'Impaired cognition', 'Impairment', 'Individual', 'Inferior frontal gyrus', 'Intractable Epilepsy', 'Investigation', 'Knowledge', 'Laboratories', 'Language', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Memory', 'Mentorship', 'Methods', 'Monitor', 'Names', 'Neurologic', 'Neurons', 'Neurosciences', 'Paper', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Population', 'Resources', 'Retrieval', 'Role', 'Sampling', 'Semantic memory', 'Semantics', 'Site', 'Stereotyping', 'Stimulus', 'Structure', 'Structure of middle temporal gyrus', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Training', 'Work', 'awake', 'base', 'behavior measurement', 'brain circuitry', 'career', 'cognitive function', 'density', 'effective therapy', 'improved', 'innovation', 'insight', 'language processing', 'memory retrieval', 'multidisciplinary', 'natural language', 'nervous system disorder', 'neural circuit', 'neuroethics', 'neurophysiology', 'neurotransmission', 'relating to nervous system', 'semantic processing', 'signal processing', 'syntax', 'theories', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K23,2020,200178,0.028928836324320143
"Administrative Supplement to The When to Worry about Language Study (W2W-L) PROJECT SUMMARY – Original Submission Primary language impairment (PLI) begins early in life and affects 6-8% of children. Although language intervention is maximally effective the earlier it is delivered, normative variation in language acquisition across toddlerhood (here 24-36 months) impedes accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model to identify PLI as early as possible. Our developmentally- sensitive, translational approach introduces multiple innovations including: (1) characterizing the developmental patterning of toddler emergent language beginning at 24 mos. using state-of-the-art methods, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language into PLI risk assessment; (3) using a novel paradigm to assess the protective effects of both behavioral and neural synchronization within parent-child language transactions; and (4) consideration of irritability, a robust developmental marker of early mental health risk, to enhance identification of those language delayed toddlers at highest risk for persistence. For the proposed When to Worry about Language Study (W2W-L), we capitalize on our funded study of 350 infants (50% irritable and 50% non-irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24-month-olds. Our key predictors will be toddler emergent language patterns (24-36 months), their neural biomarkers and synchrony within the transactional language environment. Our central outcome is primary language impairment (PLI) status at preschool age (54 mos., when PLI can be reliably evaluated), assessed via clinical gold standard expressive and receptive language abilities. SPECIFIC AIMS: AIM 1a. Evaluate accuracy of PLI prediction based on multi-component measures of language including intensive longitudinal assessments of toddler developmental precursors of key language functions at older ages, neural biomarkers. We will assess neural and linguistic processing via quantitative EEG during parent-child interaction and ERPs to speech sounds as well as during eye tracking tasks and 1b. Evaluate feasibility of creating an algorithm for early identification of PLI that can be applied in clinical practice, using cross-validation and machine learning. AIM 2: Test the hypothesis that parent-child dyadic synchrony buffers PLI risk For the first time, we combine behavioral and novel social EEG measures of parent-child synchrony during natural interaction and a custom-designed word learning task to directly test how observed (behavioral) and neural (EEG) dyadic synchrony impact word learning. AIM 3: Test whether consideration of toddler irritability enhances PLI prediction. In sum, PLI confers sustained negative effects on a variety of personal-social and academic outcomes. Pinpointing children at highest risk for PLI is critical for reducing the public health burden of PLI for children, families, and the systems supporting them, and enhancing targeted allocation of resources. PROJECT NARRATIVE Primary language impairment emerges early and is responsive to intervention; however, many toddlers with early language delays recover naturally, and others who appear to be developing typically show signs of impairment by preschool age. We use a novel, theoretically-grounded, multi-level neurodevelopmental approach to characterize emergent language patterns from 24- 36 mos. along with the influence of neural and linguistic processing and transactional processes within the child's broader language environment. We also test whether PLI prediction is enhanced via consideration of irritability, a robust predictor of early mental health risk. Drawing on findings from our predictive models, we will also examine feasibility of developing a clinical algorithm from this scientifically-validated toolkit. Generating reliable methods for accurate identification of young children at highest risk for language impairment lays the foundation for optimizing early intervention and preventing developmentally-cascading effects on academic and adaptive functioning.",Administrative Supplement to The When to Worry about Language Study (W2W-L),10162280,R01DC016273,"['Address', 'Administrative Supplement', 'Adverse effects', 'Affect', 'African American', 'Age', 'Algorithms', 'Behavioral', 'Biological Markers', 'Buffers', 'COVID-19', 'COVID-19 pandemic', 'Caregivers', 'Child', 'Child Language', 'Child Rearing', 'Clinical', 'Communities', 'Custom', 'Data', 'Data Collection', 'Development', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Environment', 'Family', 'Family member', 'Foundations', 'Funding', 'Goals', 'Gold', 'Hispanics', 'Home environment', 'Human Subject Research', 'Illinois', 'Impairment', 'Individual', 'Infant', 'Institutes', 'Interruption', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Linguistics', 'Machine Learning', 'Measures', 'Mediating', 'Mental Health', 'Methods', 'Modeling', 'Nursery Schools', 'Outcome', 'Parent-Child Relations', 'Parents', 'Participant', 'Pattern', 'Pediatric Hospitals', 'Personal Satisfaction', 'Persons', 'Process', 'Protocols documentation', 'Public Health', 'Race', 'Research Activity', 'Resource Allocation', 'Risk', 'Risk Assessment', 'Sampling', 'Siblings', 'Speech Sound', 'Stress', 'Sum', 'Support System', 'Surveys', 'Testing', 'Time', 'Toddler', 'Transact', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visit', 'base', 'clinical practice', 'cohort', 'coronavirus disease', 'design', 'experience', 'high risk', 'innovation', 'language impairment', 'negative affect', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'protective effect', 'recruit', 'relating to nervous system', 'sex', 'social', 'standard measure', 'stress reduction', 'translational approach', 'tv watching', 'visual tracking', 'word learning']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2020,197084,0.061071529409998236
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9913498,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'longitudinal design', 'machine learning method', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2020,592142,0.06052222238243745
