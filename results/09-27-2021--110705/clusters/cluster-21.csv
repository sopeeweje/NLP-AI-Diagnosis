text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9783881,U01EB029373,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIBIB,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2019,611358,0.023296430452689476
"Functional Cancer Cell Maps FUNCTIONAL CANCER CELL MAPS SUMMARY I am currently an Academic Program Officer in Prof. Trey Ideker’s lab at UC San Diego. My title reflects the varied roles I play in the Ideker Lab, both scientifically and administratively, as I also serve as the Assistant Director of the Cancer Cell Map Initiative (CCMI) and the San Diego Center for Systems Biology (SDCSB). I am involved in a wide range of research projects, both within the Ideker Lab and across the various Centers. Central though to many of these efforts is the role I play supervising a number of projects using the CRISPR/Cas9­based approach to map genetic interactions in cancer cells. These functional maps can be used to identify protein complexes and pathways in cancer cells and to reveal genetic dependencies that might be therapeutically tractable. These studies will also provide us with the necessary training data to build “visible” AIs, machine learning models that not only make accurate predictions but also provide mechanistic insights. FUNCTIONAL CANCER CELL MAPS NARRATIVE Many cancers in adults are caused by mutations acquired over time. Research in both the Ideker Lab and the Cancer Cell Map Initiative seek to understand how these mutations alter the function of proteins leading to cancer using a variety of biochemical, genetic and computational approaches. We are particularly interested in understanding how combinations of mutated genes can disrupt normal cell physiology as knowing about these mechanisms can help us identify new drug targets or biomarkers.",Functional Cancer Cell Maps,9849989,R50CA243885,"['Adult', 'Biochemical Genetics', 'Biological Markers', 'CRISPR/Cas technology', 'Cell physiology', 'Data', 'Dependence', 'Genes', 'Genetic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Play', 'Research', 'Research Project Grants', 'Role', 'Supervision', 'Systems Biology', 'Therapeutic', 'Time', 'Training', 'academic program', 'base', 'cancer cell', 'insight', 'interest', 'new therapeutic target', 'protein complex', 'protein function']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R50,2019,126633,-0.004216827073439662
"Development of New Genome Editing Agents Using RNA Modifying Enzymes Komor – Project Summary/Abstract - “Development of New Genome Editing Agents Using RNA Modifying Enzymes”  While targeted genome editing, the introduction of a specific modification in genomic DNA, has the potential to allow researchers to study and better understand mechanisms of human genetic diseases, traditional genome editing methods (including CRISPR-Cas9) that rely on the initial introduction of double stranded DNA breaks (DSB) suffer from modest genome editing efficiencies as well as unwanted gene alterations (indels), particularly when attempting to correct point mutations. Recently, a class of genome editing agents called single base editors was developed that does not involve DSBs, but rather uses a dCas9-tethered single-stranded DNA (ssDNA) modifying enzyme to directly chemically modify target nucleobases within a ~5 nucleotide window determined by the protospacer. Two classes of editors have been developed that use cytosine and adenine deamination chemistries to catalyze the conversion of C•G base pairs to T•A (CBEs), and A•T base pairs to G•C (ABEs), respectively. Here we propose the development and characterization of new base editors capable of facilitating new point mutations using methylation chemistry. We have use a bioinformatic approach to identify RNA modifying enzymes that have the potential to be repurposed into new base editors, and have rationally designed mutant libraries to use with directed evolution to convert these enzymes into base editors (Aim 1). Concurrently, we are developing a machine learning program that utilizes existing ssDNA modifying enzymes to identify putative mutations that will expand the substrate scope of the identified methyltransferases to ssDNA (Aim 2). Mutations identified from both strategies will then be tested and characterized for base editing in multiple orthogonal systems (Aim 3). The successful completion of the proposed work will represent a significant addition to existing base editing technologies, and will enable researchers to cleanly and efficiently install two additional types of point mutations into the genome of living cells, allowing researchers to quickly and effectively general model systems for the study of human genetic diseases. Komor – Project Narrative - “Development of New Genome Editing Agents Using RNA Modifying Enzymes” Base editing enables high efficiency genomic point mutation introduction in a variety of cell types and has the potential to allow researchers to better study human genetic diseases. We propose transformative improvements to current base editing technologies that will expand the types of point mutations that can be introduced by base editors. The tools developed here will enable researchers to cleanly and efficiently install additional types of point mutations into the genome of living cells for the study and potential treatment of human genetic diseases.",Development of New Genome Editing Agents Using RNA Modifying Enzymes,9876634,R21GM135736,"['Adenine', 'Adoption', 'Algorithms', 'Base Pairing', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'CRISPR/Cas technology', 'Case Study', 'Cell Line', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'Deamination', 'Development', 'Directed Molecular Evolution', 'Engineering', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Mutation', 'Generations', 'Genetic Diseases', 'Genome', 'Genomic DNA', 'Genomics', 'Human', 'Human Genetics', 'In Vitro', 'Individual', 'Inosine', 'Lesion', 'Libraries', 'Link', 'Machine Learning', 'Mammalian Cell', 'Measures', 'Mediating', 'Methods', 'Methylation', 'Methyltransferase', 'Modification', 'Mutation', 'Nucleotides', 'Pathogenicity', 'Point Mutation', 'Program Development', 'Proteins', 'Purines', 'Pyrimidine', 'RNA', 'Research Personnel', 'Single-Stranded DNA', 'Site', 'Specificity', 'System', 'Technology', 'Testing', 'Transfer RNA', 'Uracil', 'Variant', 'Work', 'adenosine deaminase', 'base', 'cell type', 'combat', 'design', 'genome editing', 'insertion/deletion mutation', 'machine learning algorithm', 'molecular dynamics', 'mutant', 'novel', 'nucleobase', 'preference', 'programs', 'tool', 'transition mutation', 'transversion mutation']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,205479,-0.00297062924619091
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9751141,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2019,1186500,0.015384111805926338
"Multi-scale data integration frameworks to improve cancer outcomes ﻿    DESCRIPTION (provided by applicant)    The purpose of this K01 proposal is to develop innovative Big Data methodologies to improve cancer outcomes. I am a board-certified hematologist-oncologist completing a PhD in biomedical informatics at Stanford University. This proposal builds on my background and research in developing integrative analysis methods for multi-scale data. It also leverages the exceptional environment at Stanford for advanced training in machine learning, distributed computing, and longitudinal study analysis. Under the mentorship of my team of experts I will enhance my methodologies for improving knowledge discovery in cancer. Cancer research abounds with multi-scale data, from imaging to multi-modal molecular data, such as genomic, epigenomic, transcriptomic, and proteomic. Prediction models of clinical outcomes, including survival and therapeutic response, could capitalize on the richness of information that the data embody. In practice, however, the lack of effective methods for data integrative analysis leaves much of the latent knowledge untapped. For example, imaging data are routinely obtained for diagnostic purposes, but often underutilized in integrative analysis of cancer outcomes. By establishing inter-data correlations, imaging data have the potential to become noninvasive proxies for biopsy-acquired molecular data. Furthermore, traditional methods of data analysis have limited ability to extract knowledge from multi-scale data, which are large, heterogeneous, and exhibit complex inter-data interactions. This project outlines specific approaches to enhance knowledge extraction through integrative analyses that: (1) directly relates imaging data to molecular data, and (2) provides biomedical decision support (prediction of clinical outcomes) from multi-scale data. It applies these approaches to the analysis of brain and colorectal cancers. The training aims of the proposal are designed to further the research objectives by: (1) incorporating advanced machine learning skills to enhance information capture from each data source, (2) boosting computational efficiency and overall performance of the developed methodologies to ensure scalability, and (3) adapting methodologies to a longitudinal clinical study. The proposed project has the capacity to make a significant clinical impact by establishing the role of imaging data as a surrogate for molecular data, delineating potential therapeutic targets, and generating predictive markers for clinical outcomes. Importantly, these methodologies have a high potential to be generalizable to other cancers. Data from this project will cumulatively form the basis for an R01 proposal aimed at examining the optimal analysis of longitudinal multi-scale data to determine the minimum set of data needed to achieve maximum knowledge. The proposed work, designed for completion within the award period, will build on my research skills, generate preliminary data, forge productive collaborative relationships, and enable me to compete for R01 funding. In summary, this K01 will accelerate my career development and support launching my career as an independent physician-scientist in cancer data science research. PUBLIC HEALTH RELEVANCE    If successful, this study of brain and colon cancers will produce new ways of analyzing biomedical data that researchers can apply to other cancers to discover better diagnostic and outcome prediction tools, as well as treatments. One method uses imaging data to infer molecular information, including potential therapies, without biopsy. Another analyzes many different sources of biomedical data to find markers that indicate onset, survival likelihood, and treatment response in cancer.",Multi-scale data integration frameworks to improve cancer outcomes,9613818,K01ES026832,"['Applied Research', 'Award', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Biology', 'Biopsy', 'Cancer Diagnostics', 'Cause of Death', 'Clinical', 'Clinical Informatics', 'Clinical Markers', 'Clinical Research', 'Colon Carcinoma', 'Colorectal Cancer', 'Complex', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Data Sources', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Doctor of Philosophy', 'Ensure', 'Environment', 'Exhibits', 'Family-Based Registry', 'Funding', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Hematologist', 'Heterogeneity', 'Image', 'Informatics', 'Institution', 'Intuition', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Learning Skill', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Oncologist', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Proteomics', 'Proxy', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Scientist', 'Site', 'Source', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Universities', 'Variant', 'Work', 'anticancer research', 'base', 'biomedical informatics', 'cancer genetics', 'cancer subtypes', 'career', 'career development', 'cluster computing', 'cohort', 'colon cancer patients', 'computer framework', 'data integration', 'design', 'epigenomics', 'falls', 'follow-up', 'genetic epidemiology', 'improved', 'improved outcome', 'innovation', 'learning strategy', 'longitudinal analysis', 'molecular imaging', 'multimodality', 'new therapeutic target', 'novel', 'oncology', 'outcome prediction', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'skills', 'statistics', 'stem', 'supervised learning', 'targeted treatment', 'therapeutic target', 'tool', 'transcriptomics', 'treatment response']",NIEHS,STANFORD UNIVERSITY,K01,2019,188952,0.003068576870314365
"Integrative miRNA data analysis for clinical cancer genomics PROJECT SUMMARY The proposed research has two broad, long-term objectives. First, it seeks to shift medical practice toward more personalized treatments, by applying innovative methods to analyze and integrate DNA, RNA and protein data generated by a large network of GDAN researchers in a miRNA-centric framework. Analyses will identify cancer subtypes, and individual patients within a subtype, in which alterations in the expression of certain miRNAs influence cancer pathogenesis and drug response. Second, the proposed research seeks to shift cancer genomics research by allowing a diverse group of cancer researchers to flexibly access and use the project’s cancer genomics data, and microRNA-centric results and methods, through a cloud computing framework. The proposed research has three specific aims: 1) Build a computational pipeline for processing and analysis of miRNA data, 2) Elucidate the regulation of and by miRNAs through integrative analysis, and 3) Delineate the role of miRNAs in cancer progression and treatment using predictive modeling. Research design and methods: 1) Processing and analysis of miRNA data. We will process total RNA sequence data to identify expressed miRNAs, and extend the current processing pipeline to identify potentially functional miRNA sequence variants. We will apply our miRNA-centric analyses developed for The Cancer Genome Atlas project to identify: subtypes within a cancer, miRNAs that are associated with survival, miRNA targeting effects on gene and protein expression, and cis-effects of copy number and DNA methylation on miRNA abundances. 2) Regulation of and by miRNAs. Collaborating within the research network, we will extend our analysis methods to take into account additional datatypes and functional contexts that influence how miRNAs are regulated, and how they regulate genes and their products. 3) Predictive modeling. As the research network will have detailed clinical data and multiplatform genomic data, we will apply machine learning algorithms in a novel context to key sets of genes, proteins and miRNAs that predict clinical outcomes like survival and drug response. 4) Cloud computing. We will make our data, analysis methods and results readily available to a broad group of researchers within a cloud computing framework. NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,9778767,U24CA210952,"['3&apos', ' Untranslated Regions', 'Affect', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'Statistical Data Interpretation', 'The Cancer Genome Atlas', 'Variant', 'analysis pipeline', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'individual patient', 'innovation', 'insight', 'machine learning algorithm', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,PROVINCIAL HEALTH SERVICES AUTHORITY,U24,2019,386440,0.020079073820523218
"Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation PROJECT SUMMARY It has become feasible to generate deep quantitative data for many of the molecules that are functional in cells, making it possible to survey a large number of tumors measuring genomic alterations and changes to transcripts, proteins and metabolites. It is, however, not clear what is the best way to integrate these data sets to extract as much information as possible about the biology that drives the cancer and how to best disrupt the tumor growth. Our proposed Proteogenomic Data Analysis Center for Cancer Systems Biology and Clinical Translation will develop new methods for better analyzing and integrating these data sets. In addition to developing statistical and machine learning methods, we also emphasize visual exploration of the data, and we will implement interactive web browser based visualization that will allow researchers to easily explore these vast data sets and gain novel insights by being able to quickly switch between summary information and details of the raw data. PROJECT NARRATIVE The mission of the proposed data analysis center is to leverage high dimensional large-scale data from tumor samples to identify new avenues for the development of clinical prognostics and therapeutics for cancer. This mission will be realized through analysis, integration and visualization of multi-omic datasets including genomic, transcriptomic, and proteomic data collected from patient samples to develop predictive models, and during drug treatment of patient derived xenografts and cell lines to validate mechanisms.",Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation,9768977,U24CA210972,"['Amino Acid Sequence Databases', 'Amino Acids', 'Architecture', 'Biological', 'Biology', 'Cancer Center', 'Cell Line', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Consensus', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Experimental Designs', 'Formulation', 'Gene Expression', 'Gene Family', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Imagery', 'Individual', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Mutation', 'Neoplasm Metastasis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Phosphoproteins', 'Phosphorylation', 'Primary Neoplasm', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Surveys', 'Systems Biology', 'Therapeutic', 'Time', 'Transcript', 'Variant', 'Visual', 'Work', 'Xenograft procedure', 'actionable mutation', 'assay development', 'base', 'candidate identification', 'candidate marker', 'causal variant', 'clinical development', 'clinical phenotype', 'clinical translation', 'cohort', 'computerized data processing', 'computerized tools', 'data pipeline', 'experimental study', 'genomic data', 'high dimensionality', 'insight', 'learning strategy', 'multiple omics', 'novel', 'outcome forecast', 'personalized medicine', 'precision medicine', 'precision oncology', 'predictive modeling', 'prognostic', 'protein biomarkers', 'protein kinase inhibitor', 'protein metabolite', 'proteogenomics', 'response', 'tool', 'tool development', 'trait', 'transcriptome', 'transcriptomics', 'treatment choice', 'tumor', 'tumor growth']",NCI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U24,2019,602582,0.02239162154828406
"UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network The “UCSC-Buck Genome Data Analysis Center for the Genomic Data Analysis Network” will develop state-of-the-art methods for integrating various types of data to discover the genetic pathways, the microenvironment, the originating cells, and the oncogenic processes driving the initiation and progression of tumors. The long term goals of the project are to identify highly accurate models detailing the faulty genetic circuitry at work in each subclone of a patient’s tumor, as well as any “normal” cells acting as accomplices by supporting the cancer microenvironment. The ultimate objective is to encode computer algorithms that can search a patient’s individual pathway diagram for the best combination of interventions to eliminate every tumor cell, while preserving the health of every normal cell, in their body. Integrative pathway analysis methods will be developed to reveal signatures of tumor subtypes from Pan-Cancer and external datasets. New technologies will be established for uncovering network models tailored to individual patients. The tools will be deployed as part of an active collaboration to support the specific projects of the Genome Data Analysis Network. Novel probabilistic graphical models will be used to infer disrupted signaling. Cellular signatures will be collected from the analysis of normal cells, cancer cell line models, and Pan-Cancer investigations. Novel machine-learning methods, guided by pathway mechanisms, will be established to identify cell state signatures in heterogeneous patient samples. This work will reveal rare mutations driving metastatic transformation that are currently of unknown significance. New clues about the genetic circuitry promoting response and resistance to treatment will be established. Finally, cross-tumor connections that relate tumors of one type to a different type will suggest new avenues for treatment. Computational strategies for interpreting the results of cancer genome sequencing projects are in  desperate need. To select appropriate treatment strategies for a patient, an accurate model of the  altered genetic wiring in the tumor is needed as well as how that wiring relates to other tumors  and to other normal cells at various stages of differentiation. The research will establish  resources and software to contribute such methodologies for the Genome Data Analysis Network  projects that will subsequently be released into the public domain to benefit the entire scientific  community.",UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network,9763504,U24CA210990,"['Automobile Driving', 'Awareness', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer cell line', 'Cells', 'Cisplatin', 'Clinical', 'Collaborations', 'Communities', 'Competence', 'Computational algorithm', 'Computer software', 'DNA Sequence Alteration', 'DNA copy number', 'Data', 'Data Set', 'Development', 'Epigenetic Process', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Goals', 'Health', 'Institutes', 'Intervention', 'Investigation', 'Leadership', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Normal Cell', 'North Carolina', 'Oncogenic', 'Output', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Process', 'Protein Isoforms', 'Proteomics', 'Public Domains', 'RNA', 'RNA Splicing', 'Research', 'Resistance', 'Resources', 'Sampling', 'Series', 'Signal Transduction', 'Structure', 'The Cancer Genome Atlas', 'Time', 'Treatment Protocols', 'Tumor Subtype', 'University of Texas M D Anderson Cancer Center', 'Untranslated RNA', 'Variant', 'Work', 'bioinformatics tool', 'cancer genome', 'cancer genomics', 'computerized tools', 'data pipeline', 'exceptional responders', 'experience', 'genome analysis', 'genome sequencing', 'genomic data', 'individual patient', 'learning strategy', 'mRNA Expression', 'member', 'neoplastic cell', 'network models', 'new technology', 'novel', 'patient response', 'preservation', 'response', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment', 'tumor progression']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2019,368332,0.012499872700383842
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9626416,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Infrastructure', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2019,2000000,0.022591645221123984
"Accelerating Cancer Genomics with Cloud-scale Bioconductor PROJECT SUMMARY  The Bioconductor project is rooted in recognition that efﬁcient, rigorous, and reproducible analysis of high- dimensional data can be achieved when statisticians, biologists, and computer scientists federate efforts in a transparent and carefully engineered way. The project Accelerating Cancer Genomics with Cloud-scale Bio- conductor devises new approaches to carrying out genome-scale analysis of cancer data using cloud computing environments. The proposal is based on strategies that have proven highly effective in ﬁfteen years of supporting collaborative and carefully engineered software for genome scale analysis in computational biology in the Biocon- ductor project, based on the highly portable and widely adopted R language and environment for data analysis. In Aim 1 we develop architecture and infrastructure for scalably harvesting cloud-based representations of large- scale cancer genome studies such as The Cancer Genome Atlas, creating formal high-performance workﬂows for processing and interpreting cancer genome analyses, and providing packaging and data distribution schemes for moving data to the cloud for scalable analysis there. In Aim 2 we create and support independent creation of intuitive and cancer-relevant interface components supporting reproducible interactive exploration and analysis using the facilities of Rstudio. In Aim 3 we update and generalize the Bioconductor MLInterfaces metapackage to support advanced machine learning using the cancer-oriented strategies and facilities devised in Aims 1 and 2. Our proposal will beneﬁt large numbers of cancer researchers who will be taking advantage of cloud resources, probably with R close to hand, by marrying strengths of cloud-centric strategies for data archiving and query resolution, to the strengths of Bioconductor development and analysis capabilities. We have letters of support from the leadership of the three NCI Cancer Cloud Pilot projects for this project. PROJECT NARRATIVE  Despite major advances in elucidating mechanisms of tumor initiation and proliferation, treatment strategies for many cancers are ineffective, and patient-to-patient variation in treatment response suggests that personal targeting of cancer based on tumor molecular proﬁles will be necessary. This proposal takes a design and architecture approach from a widely used project for analyzing general data arising in genome-scale biology, and adapts it to new NCI-supported cloud-based data archives and analysis environments. The proposal will accelerate identiﬁcation of sources of variation of tumor responsiveness to treatment and will aid physicians in devising personalized antitumor strategies.",Accelerating Cancer Genomics with Cloud-scale Bioconductor,9677124,U01CA214846,"['Acceleration', 'Achievement', 'Address', 'Adopted', 'Animal Cancer Model', 'Architecture', 'Awareness', 'Base Sequence', 'Bioconductor', 'Bioinformatics', 'Biological Assay', 'Biology', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Collaborations', 'Collection', 'Computational Biology', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Analytics', 'Data Storage and Retrieval', 'Development', 'Ecosystem', 'Engineering', 'Environment', 'Eye', 'Fostering', 'Foundations', 'Genomic Data Commons', 'Genomics', 'Goals', 'Hand', 'Harvest', 'Informatics', 'Infrastructure', 'Institutes', 'Intuition', 'Language', 'Leadership', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modality', 'Molecular', 'Molecular Profiling', 'Motivation', 'Mutation Spectra', 'Neural Network Simulation', 'Outcome', 'Output', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Process', 'Publications', 'Published Comment', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Scheme', 'Scientist', 'Software Engineering', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Systems Biology', 'TensorFlow', 'Testing', 'The Cancer Genome Atlas', 'Time', 'Update', 'Validation', 'Variant', 'Work', 'actionable mutation', 'analytical method', 'application programming interface', 'base', 'cancer genome', 'cancer genomics', 'cancer subtypes', 'cancer type', 'cloud based', 'computing resources', 'data archive', 'data format', 'data submission', 'design', 'experimental study', 'flexibility', 'genome analysis', 'genome-wide', 'genomic data', 'genomics cloud', 'multidimensional data', 'multiple omics', 'novel strategies', 'patient variability', 'portability', 'prototype', 'response', 'software development', 'spelling', 'tool', 'treatment response', 'treatment strategy', 'tumor', 'tumor initiation', 'usability']",NCI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2019,425494,0.019092042866412626
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9785353,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Structure', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'nonsynonymous mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,ALBERT EINSTEIN COLLEGE OF MEDICINE,K99,2019,135945,0.01417662018691182
"Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data Limitless replicative potential is a key hallmark of cancer and critically depends on telomere maintenance. Many cancers thus aberrantly reactivate the telomerase reverse transcriptase (TERT), a catalytic subunit of the telomerase complex that elongates telomere. It has been recently discovered that this common path to immortality in multiple cancers is through two activating point mutations in the TERT promoter (TERTp), found in more than 50 different cancer types, often at strikingly high frequencies, e.g. roughly 83% in glioblastomas (GBM) and 71% in melanomas. In the previous funding period, the PI has identified the molecular function of these highly recurrent mutations, demonstrating that the transcription factor (TF) GABP binds the mutant TERTp with exquisite specificity, but not the wild-type TERTp. The high prevalence of TERTp mutations across multiple cancer types and the selectivity of GABP recruitment to mutant TERTp thus provide an unprecedented opportunity for treating a large number of cancer patients with minimal toxicity to healthy cells. Despite the clear significance of this opportunity, however, several important questions surrounding the molecular functions and modulators of TERTp mutations remain poorly understood, hindering the development of effective and safe therapeutic strategies.  Our long-term goal is to establish a rigorous computational framework for understanding the aberrant transcriptional and epigenetic networks in cancers and to apply the resulting knowledge to devise novel therapeutic strategies that account for the genetic background of individual patients and that can a priori predict and avoid potential resistance mechanisms. The objective of our current renewal proposal is to develop powerful computational methods for transforming our knowledge about the non-coding TERTp mutations into an effective and safe molecular target. At the same time, the resulting methods will help resolve several outstanding challenges in the field of transcriptional gene regulation and have broad applications in cancer genomics. We will accomplish our objective my pursuing the following Aims: (1) Develop and test a computational framework for inferring sequence features that determine the distinct and shared binding patterns of paralogous TFs; (2) Develop and validate integrative tools for discovering the molecular basis of genetic interactions between germline variations and oncogenic mutations; (3) Develop and apply computational methods for studying the role of DNA helical phase between adjacent binding motifs in recruiting ETS factors to chromatin; (4) Perform a systematic genomic characterization of the effects of knocking out GABPB1L in TERTp-mutant cancer cells and healthy cells. The results of this proposal will have a broad impact on cancer research by providing powerful tools for studying paralogous oncogenic TFs and revealing novel insights into a highly promising therapeutic strategy. The proposed research will provide computational and bioinformatic resources for studying the binding pattern of paralogous oncogenic transcription factors. It will provide a computational framework for inferring the function of non-coding regulatory mutations and studying their interaction with common genetic variants. As an important application, we will systematically analyze a novel therapeutic strategy that has the potential to treat effectively a large number of patients across multiple cancer types harboring the recently discovered TERT promoter mutations.",Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data,9609431,R01CA163336,"['Address', 'Binding', 'Binding Sites', 'Cancer Patient', 'Cells', 'Chromatin', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Sequence Alteration', 'Data', 'Development', 'Drug resistance', 'Epigenetic Process', 'Family', 'Family member', 'Frequencies', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Glioblastoma', 'Goals', 'High Prevalence', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Molecular', 'Molecular Target', 'Mutation', 'Nature', 'Oncogenic', 'Patients', 'Pattern', 'Phase', 'Point Mutation', 'Protein Isoforms', 'RNA-Directed DNA Polymerase', 'Recurrence', 'Research', 'Role', 'Somatic Mutation', 'Specificity', 'TERT gene', 'Techniques', 'Telomerase', 'Telomere Maintenance', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Transcriptional Regulation', 'Untranslated RNA', 'Validation', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics resource', 'c-myc Genes', 'cancer cell', 'cancer genomics', 'cancer type', 'computer framework', 'computing resources', 'deep learning', 'dimer', 'genetic variant', 'genome-wide', 'individual patient', 'insight', 'knowledge of results', 'melanoma', 'member', 'mutant', 'novel', 'novel therapeutics', 'promoter', 'recruit', 'resistance mechanism', 'telomere', 'therapeutic target', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2019,317385,0.022017811949646367
"Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different cancer phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. We have identified 4 large, multi- generational kindreds with a founder CDKN2A deleterious mutation (L16R, 47T>G). Our preliminary observations demonstrate that this mutant has lower expression and decreased ability to regulate cell cycle progression compared to wild type protein. Our sequencing studies of kindred members with different cancer phenotypes have identified potential variants in novel genes that modify risk (LGR6, a co-receptor of Wnt signaling and COL11A1, which participates in oncogenic signaling, including TGFbeta). We will determine the ability of the p16 mutant to promote transformation and how it is influenced by interaction with the above candidate modifier genes, LGR6 or COL11A1, in pancreatic cancer and melanoma. We will also develop novel computational models using machine deep learning, to generate networks that capture high dimensional features to integrate gene, biology, and cancer phenotype. This approach will be extended to kindreds with other CDKN2A mutations. Our Specific Aims are to: (1) Identify genotypes of potential modifier genes in multiple kindreds that feature pancreatic cancer and melanoma and known to carry CDKN2A germline mutations. We will use genome wide variant coverage of germline DNA from CDKN2A carriers from the 4 large L16R kindreds, plus additional members in 42 other similar CDKN2A kindreds. We will identify candidate modifier genes in the kindreds by rule-based statistical genetic analysis of genotypes. (2) Define the impact of CDKN2A L16R mutation on the function of p16 and its interplay with candidate modifier genes. We will elucidate the biological significance of mutations in CDKN2A and candidate modifier genes using functional and high throughput methodologies by analyzing the mechanism underlying the interplay between p16 and modifier genes; define new pathways cooperating with this interplay using a combination of genome wide studies to assess transformation in cells carrying p16 mutant or wild-type background using well established in vitro and in vivo models. (3) Develop a deep learning network model to integrate genetic, biological and epidemiological data to accurately infer pancreatic cancer and melanoma phenotypes and age of onset in mutation carriers. We will apply a convolutional neural network, a deep learning algorithm in the training dataset, develop a back-propagation algorithm to fine tune “weights,” and construct mutation-gene networks to capture high-dimensional features for each disease subclass. We will acquire and disseminate new knowledge and tools to the scientific community. Our integrated methods and approach will bring insight into how different cancer phenotypes can occur with identical predisposing mutations, which can be applied to other cancer syndromes with similar challenges. PROJECT NARRATIVE This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. Using 4 large, multi-generational kindreds with a founder CDKN2A deleterious mutation and other kindreds, we will define the mechanism underlying the interplay between CDKN2A and other factors. We will develop novel computational models using machine deep learning, that integrate gene, biology, and cancer phenotype. We will share our new knowledge and tools with the scientific community, and bring insights to apply to other challenging cancer syndromes.",Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds,9741068,R01CA208517,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Alleles', 'Alzheimer&apos', 's Disease', 'Back', 'Biological', 'Biology', 'Brain Neoplasms', 'CDKN2A gene', 'Cancer Gene Mutation', 'Cancer-Predisposing Gene', 'Cell Cycle Progression', 'Cells', 'Code', 'Communities', 'Computer Simulation', 'Cyclin-Dependent Kinase Inhibitor 2A', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Environmental Exposure', 'Etiology', 'Gene Expression', 'Gene Frequency', 'Gene Mutation', 'Gene-Modified', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Germ-Line Mutation', 'In Vitro', 'Individual', 'Inherited', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measures', 'Methodology', 'Methods', 'Minor', 'Modeling', 'Molecular', 'Mutation', 'Oncogenic', 'Pathway interactions', 'Pattern', 'Penetrance', 'Performance', 'Phenotype', 'Process', 'Proteins', 'Proteomics', 'Risk', 'Signal Transduction', 'Smoking', 'Sun Exposure', 'Syndrome', 'Testing', 'Training', 'Transforming Growth Factor beta', 'Variant', 'WNT Signaling Pathway', 'Weight', 'base', 'bead chip', 'cancer genome', 'cell growth', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disease phenotype', 'epidemiologic data', 'epigenomics', 'feeding', 'genetic analysis', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'in vivo', 'in vivo Model', 'innovation', 'insight', 'interest', 'kindred', 'leukemia', 'melanoma', 'member', 'metaplastic cell transformation', 'mutant', 'mutation carrier', 'network models', 'non-genetic', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'overexpression', 'protein expression', 'receptor', 'tool', 'transcriptome sequencing', 'transmission process', 'tumorigenesis']",NCI,MAYO CLINIC ROCHESTER,R01,2019,583253,0.02338963750219676
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9765970,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Simulation', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2019,433604,-0.0018012863565510533
"Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation Summary Most variants obtained from tumor whole-genome sequences (WGS) occur in non- coding regions of the genome. Although variants in protein-coding regions have received the majority of attention, numerous studies have now noted the importance of non- coding variants in cancer. Identification of functional non-coding variants that drive tumor growth remains a challenge and a bottleneck for the use of whole-genome sequencing in the clinic. Cancer drivers are generally identified by the high frequency at which their mutations occur across patients. However, mutation rate is highly heterogeneous in non- coding regions and many non-driver elements show higher mutation frequency than others, such as regions bound by transcription factors in melanoma or regions replicating late during cell division in colon cancer. In this proposal, we will use high- throughput pooled CRISPR screen and novel computational methods to predict non- coding cancer drivers. We will quantitatively measure the impact of thousands of non- coding mutations using our innovative high-throughput CRISPR screen that directly ties modifications in the native context of the non-coding genome (i.e. not a reporter assay) to a cancer relevant phenotype (cell growth). The results of the screen will be used as training data for the development of NC_Driver, a computational cancer driver prediction tool. NC_Driver will integrate the signals of high functional impact with the recurrence of variants across multiple tumor samples to identify the non-coding mutations under positive selection in cancer. We will identify drivers in promoters, enhancers and CTCF insulators. CTCF insulators are the most mutated yet least studied regulatory elements in the cancer genome. Using this integrative experimental and computational approach, we will identify high-confidence candidate drivers. Finally, we will perform functional evaluation of prioritized non-coding drivers in colorectal and prostate cancers. We will use CRISPR/Cas9 genome editing in patient-derived cell cultures to test 20 high-ranking candidate driver promoter/enhancer/insulator mutations. Overall, this proposal addresses the critical need to identify drivers in the non-coding genome and over long- term enable the maximal benefit of genome sequencing for each patient. Project Narrative Cancer genomes contain thousands of mutations but only a few of them play an important role in cancer proliferation and are called drivers. Most of the mutations occur in regions of the genome that do not make proteins, yet the majority of previous studies have focused on protein-coding regions. In this proposal, we will use integrative computational and experimental approaches to identify drivers in the non-protein-coding regions of the genome.",Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation,9831005,R01CA218668,"['Accounting', 'Address', 'Attention', 'Benchmarking', 'Biological Assay', 'CRISPR screen', 'CRISPR/Cas technology', 'Cancer Patient', 'Catalogs', 'Cell Culture Techniques', 'Cell Line', 'Cell Survival', 'Cell division', 'Cells', 'Chromatin', 'Clinic', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Colon', 'Colon Carcinoma', 'Colorectal Cancer', 'Computer Simulation', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Dissection', 'Elements', 'Enhancers', 'Evaluation', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Heterogeneity', 'Institutes', 'Knock-in', 'Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methods', 'Modification', 'Molecular Conformation', 'Mutagenesis', 'Mutate', 'Mutation', 'Nature', 'Open Reading Frames', 'Parents', 'Patients', 'Phenotype', 'Play', 'Prostate', 'Proteins', 'Recurrence', 'Regulatory Element', 'Reporter', 'Research', 'Role', 'Running', 'Sampling', 'Screening Result', 'Signal Transduction', 'Somatic Mutation', 'Statistical Algorithm', 'Structure', 'Targeted Resequencing', 'Testing', 'Training', 'Transcript', 'Untranslated RNA', 'Validation', 'Variant', 'Xenograft procedure', 'actionable mutation', 'base', 'biobank', 'cancer genome', 'cancer type', 'cell growth', 'cohort', 'colon cancer cell line', 'deep learning', 'genome editing', 'genome sequencing', 'genome-wide', 'high throughput screening', 'innovation', 'knock-down', 'melanoma', 'novel', 'precision medicine', 'promoter', 'tool', 'transcription factor', 'tumor', 'tumor growth', 'tumor heterogeneity', 'tumor microenvironment', 'tumorigenesis', 'tumorigenic', 'whole genome']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,113967,0.03299311522654287
"Reverse Sensitivity Analysis for Identifying Predictive Proteomics Signatures of Cancer Title: Reverse Sensitivity Analysis for Identifying Proteomics Signatures of Cancer Abstract Cancer is a complex disease in which genetic disruptions in cell signaling networks are known to play a significant role. A major aim of cancer systems biology is to build models that can predict the impact of these genetic disruptions to guide therapeutic interventions (i.e. personalized medicine). A prominent driver of cancer cell growth is signaling pathway deregulation from mutations in key regulatory nodes and loss/gain in gene copy number (CNV). However, current mathematical modeling approaches do not adequately capture the impact of these genetic changes. Reasons for this include the poorly understood layers of regulation between gene expression and protein activity, and limitations in most modeling and protein measurement technologies. In addition, there is a paucity of overarching hypotheses that can link specific gene expression or mutation patterns to the cancer phenotype. Recent work by our group has resolved some of the technical challenges that have hindered the application of proteomics technologies to cancer systems biology research. It has also suggested a new approach for using quantitative proteomics data to understand mechanisms driving cancer cell behavior. Using an ultrasensitive, targeted proteomics platform that can measure both abundance and phosphorylation of proteins present at only hundreds of copies per cell, we found that signaling pathways appeared to be controlled by only a limited number of key nodes whose activity is tightly regulated through low abundance and feedback phosphorylation. We propose to build on these findings by critically testing the hypothesis that CNV and genetic mutations dysregulate signaling pathways in cancer by shifting control from tightly regulated nodes to poorly regulated ones. This will be done by systematically identifying key regulatory nodes of normal and cancer cells using CRISPRa/i screens, determine the relationship between protein abundance and signaling pathway activities using ultrasensitive targeted proteomics and phosphoproteomics and then use these data to semi-automatically generate mathematical models of the functional topology of the signaling pathways. Specifically, we propose to: 1) Use targeted CRISPR gene perturbation libraries to identify the regulatory topologies of signaling pathways important in cancer and how they are disrupted by common cancer mutations, 2) Use the CRISPR perturbation and proteomics data to semi-automatically build predictive models of cancer cell signaling pathways, and 3) Combine modeling and perturbation screens to understand how feedback regulation in cancer contributes to drug resistance. This work will result in simplified, computationally tractable yet mechanistic models of signaling pathways and provide network maps of feedback and crosstalk circuits that can be used to rapidly map the regulatory state of cells. Most important, it will provide a generic platform for translating protein abundance and phosphorylation patterns into a “state” snapshot of cancers that can lead to predicting their response to specific drugs. Narrative Cancer is an extremely complex disease which is frequently caused by signaling pathway deregulation from genetic mutation or loss/gain in gene copy number. Modern analytical techniques have provided a wealth of data on the molecular changes associated with cancer mutations, but it has been extremely difficult to use this information to design targeted therapies. We propose a new methodology that combines CRISPR-based targeted screens, advanced proteomics technologies, and a new mathematical modeling approach for identifying proteomics signatures of altered signaling pathways in cancer that can be used to build predictive models and explore mechanisms of drug resistance.",Reverse Sensitivity Analysis for Identifying Predictive Proteomics Signatures of Cancer,9731187,U01CA227544,"['Address', 'Affect', 'Automobile Driving', 'Behavior', 'Biological Models', 'Breast Cancer cell line', 'Breast Epithelial Cells', 'CRISPR library', 'Cancer Cell Growth', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Computer Simulation', 'DNA Sequence Alteration', 'Data', 'Development', 'Disease', 'Drug resistance', 'Feedback', 'Flow Cytometry', 'Gene Dosage', 'Gene Expression', 'Gene Mutation', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Play', 'Predictive Cancer Model', 'Proteins', 'Proteomics', 'Proto-Oncogene Proteins c-akt', 'Reagent', 'Regulation', 'Research', 'Resistance', 'Role', 'Signal Pathway', 'Signal Transduction', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Translating', 'Work', 'base', 'cancer cell', 'cancer type', 'cell behavior', 'design', 'experimental study', 'mathematical model', 'melanoma', 'novel strategies', 'personalized medicine', 'phosphoproteomics', 'predictive modeling', 'proteomic signature', 'response', 'screening', 'targeted treatment', 'tool']",NCI,BATTELLE PACIFIC NORTHWEST LABORATORIES,U01,2019,608348,-0.005767562652985118
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9825986,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Simulation', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'actionable mutation', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2019,232291,0.04385430501321971
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9737246,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Stem cells', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2019,336177,-0.007401657601220273
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9729028,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2019,1002519,0.015217281060631563
"Transforming family dogs into a powerful and accessible model for human cancer ABSTRACT There is an unmet need for novel approaches to cancer research, including improved model systems. Pet dogs are among the most promising natural models for translational cancer research​. They share our environment and develop cancers with clear clinical, histological, and genomic similarities to human cancer. We propose to use new genomic technology and a direct-to-dog-owner approach to overcome existing limitations of the canine model. To accomplish this, we will use new liquid biopsy technology, which makes it possible to sequence ​tumor exomes in circulating cell-free DNA from a blood sample, and thus achieve deeper understanding of tumor genomics without invasive biopsies. The power of these minimally invasive sampling technologies is greatest in application to very large sets of clinical samples. Family dogs, whose environments are shared with humans and for which tumor genomics are similar to human cancers, offer an unparalleled model in which to assemble clinical sets of size sufficient both to confirm the relevance of known genetic pathways, and to identify new ones. We propose to combine the power of cell-free DNA sequencing, ​the enthusiasm of citizen-scientist pet owners, and the clinical experience of veterinarians. We will create a research portal for collection of information on diagnosis, treatment, and outcome for thousands of dogs with cancer, as well as their environment and lifestyle. W​e will also develop new computational methodologies to identify genomic similarities between canine and human cancers. Comparison of these canine and human mutational profiles will enable matching of canine cancer subtypes with human cancer subtypes based on genetic pathways, facilitating canine trials to advance human clinical studies. We aim to:  Aim 1. ​Develop software to Identify canine models for human cancers using genomic data and  comprehensive, histology-blind analysis approach.  Aim 2. Develop and optimize ​cell-free DNA sampling and sequencing methods in dogs, including  ultra-low-pass whole genome sequencing and whole exome sequencing.  Aim 3. Implement a ​direct-to-dog-owner smartphone app to collect and validate detailed clinical, and  environmental data, paired with blood samples, for thousands of dogs. By combining the power of genome sequencing and new liquid biopsy technology with the opportunity to collect large sets of samples from a species whose cancers are genomically reflective of those in humans, our project​ will​ transform​ the scale and scope of translational cancer research and precision medicine. Project Narrative Pet dogs live in the same environments that we do, suggesting that profiling mutations in dog tumors could guide treatment of human cancers. With the help of veterinarians and citizen-scientist dog owners, we will build tools and resources needed to study cancer in thousands of dogs at once. This will help scientists find important genetic features of canine cancers, match them to specific human cancers, and translate what we learn into new cancer therapeutics.",Transforming family dogs into a powerful and accessible model for human cancer,9671372,R37CA218570,"['Address', 'Benchmarking', 'Biological Models', 'Biopsy', 'Blood', 'Blood specimen', 'Canis familiaris', 'Catalogs', 'Chemical Exposure', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Code', 'Collection', 'Community Clinical Oncology Program', 'Computer software', 'Computing Methodologies', 'DNA sequencing', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dog family', 'Environment', 'Evolution', 'Gene Mutation', 'Genes', 'Genetic', 'Genomics', 'Gold', 'Histologic', 'Histology', 'Human', 'Inherited', 'Institutes', 'Learning', 'Life Style', 'Longitudinal Studies', 'Malignant Neoplasms', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Molecular Profiling', 'Mutate', 'Mutation', 'Operative Surgical Procedures', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Records', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Scientist', 'Silicones', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Translating', 'Treatment outcome', 'United States', 'Untranslated RNA', 'Veterinarians', 'actionable mutation', 'analysis pipeline', 'anticancer research', 'base', 'blind', 'cancer genomics', 'cancer subtypes', 'cell free DNA', 'chemotherapy', 'citizen science', 'classifier algorithm', 'cohort', 'comparative', 'comparative genomics', 'exome', 'exome sequencing', 'experience', 'genetic risk factor', 'genome sequencing', 'genomic data', 'genomic platform', 'human data', 'human model', 'improved', 'liquid biopsy', 'minimally invasive', 'new technology', 'novel strategies', 'oncology', 'open source', 'precision medicine', 'predicting response', 'programs', 'response', 'smartphone Application', 'software development', 'supervised learning', 'targeted treatment', 'tool', 'translational cancer research', 'translational model', 'tumor', 'whole genome']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R37,2019,634586,0.009189801426895426
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell- based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off- target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9678132,U01HL145793,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety testing', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NHLBI,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2018,651251,0.023296430452689476
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9562959,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2018,1186500,0.015384111805926338
"Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation PROJECT SUMMARY It has become feasible to generate deep quantitative data for many of the molecules that are functional in cells, making it possible to survey a large number of tumors measuring genomic alterations and changes to transcripts, proteins and metabolites. It is, however, not clear what is the best way to integrate these data sets to extract as much information as possible about the biology that drives the cancer and how to best disrupt the tumor growth. Our proposed Proteogenomic Data Analysis Center for Cancer Systems Biology and Clinical Translation will develop new methods for better analyzing and integrating these data sets. In addition to developing statistical and machine learning methods, we also emphasize visual exploration of the data, and we will implement interactive web browser based visualization that will allow researchers to easily explore these vast data sets and gain novel insights by being able to quickly switch between summary information and details of the raw data. PROJECT NARRATIVE The mission of the proposed data analysis center is to leverage high dimensional large-scale data from tumor samples to identify new avenues for the development of clinical prognostics and therapeutics for cancer. This mission will be realized through analysis, integration and visualization of multi-omic datasets including genomic, transcriptomic, and proteomic data collected from patient samples to develop predictive models, and during drug treatment of patient derived xenografts and cell lines to validate mechanisms.",Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation,9547344,U24CA210972,"['Amino Acid Sequence Databases', 'Amino Acids', 'Architecture', 'Biological', 'Biology', 'Cancer Center', 'Cell Line', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Consensus', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Experimental Designs', 'Formulation', 'Gene Expression', 'Gene Family', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Imagery', 'Individual', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Mutation', 'Neoplasm Metastasis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Phosphoproteins', 'Phosphorylation', 'Primary Neoplasm', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Surveys', 'Systems Biology', 'Therapeutic', 'Time', 'Transcript', 'Variant', 'Visual', 'Work', 'Xenograft procedure', 'actionable mutation', 'assay development', 'base', 'candidate identification', 'candidate marker', 'clinical development', 'clinical phenotype', 'clinical translation', 'cohort', 'computerized data processing', 'computerized tools', 'experimental study', 'genomic data', 'high dimensionality', 'insight', 'learning strategy', 'multiple omics', 'novel', 'outcome forecast', 'personalized medicine', 'precision medicine', 'precision oncology', 'predictive modeling', 'prognostic', 'protein biomarkers', 'protein kinase inhibitor', 'protein metabolite', 'proteogenomics', 'response', 'tool', 'tool development', 'trait', 'transcriptome', 'transcriptomics', 'treatment choice', 'tumor', 'tumor growth']",NCI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U24,2018,803184,0.02239162154828406
"Accelerating Cancer Genomics with Cloud-scale Bioconductor PROJECT SUMMARY  The Bioconductor project is rooted in recognition that efﬁcient, rigorous, and reproducible analysis of high- dimensional data can be achieved when statisticians, biologists, and computer scientists federate efforts in a transparent and carefully engineered way. The project Accelerating Cancer Genomics with Cloud-scale Bio- conductor devises new approaches to carrying out genome-scale analysis of cancer data using cloud computing environments. The proposal is based on strategies that have proven highly effective in ﬁfteen years of supporting collaborative and carefully engineered software for genome scale analysis in computational biology in the Biocon- ductor project, based on the highly portable and widely adopted R language and environment for data analysis. In Aim 1 we develop architecture and infrastructure for scalably harvesting cloud-based representations of large- scale cancer genome studies such as The Cancer Genome Atlas, creating formal high-performance workﬂows for processing and interpreting cancer genome analyses, and providing packaging and data distribution schemes for moving data to the cloud for scalable analysis there. In Aim 2 we create and support independent creation of intuitive and cancer-relevant interface components supporting reproducible interactive exploration and analysis using the facilities of Rstudio. In Aim 3 we update and generalize the Bioconductor MLInterfaces metapackage to support advanced machine learning using the cancer-oriented strategies and facilities devised in Aims 1 and 2. Our proposal will beneﬁt large numbers of cancer researchers who will be taking advantage of cloud resources, probably with R close to hand, by marrying strengths of cloud-centric strategies for data archiving and query resolution, to the strengths of Bioconductor development and analysis capabilities. We have letters of support from the leadership of the three NCI Cancer Cloud Pilot projects for this project. PROJECT NARRATIVE  Despite major advances in elucidating mechanisms of tumor initiation and proliferation, treatment strategies for many cancers are ineffective, and patient-to-patient variation in treatment response suggests that personal targeting of cancer based on tumor molecular proﬁles will be necessary. This proposal takes a design and architecture approach from a widely used project for analyzing general data arising in genome-scale biology, and adapts it to new NCI-supported cloud-based data archives and analysis environments. The proposal will accelerate identiﬁcation of sources of variation of tumor responsiveness to treatment and will aid physicians in devising personalized antitumor strategies.",Accelerating Cancer Genomics with Cloud-scale Bioconductor,9478159,U01CA214846,"['Acceleration', 'Achievement', 'Address', 'Adopted', 'Animal Cancer Model', 'Architecture', 'Awareness', 'Base Sequence', 'Bioconductor', 'Bioinformatics', 'Biological Assay', 'Biology', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Collaborations', 'Collection', 'Computational Biology', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Analytics', 'Data Storage and Retrieval', 'Development', 'Ecosystem', 'Engineering', 'Environment', 'Eye', 'Fostering', 'Foundations', 'Genomic Data Commons', 'Genomics', 'Goals', 'Hand', 'Harvest', 'Informatics', 'Institutes', 'Intuition', 'Language', 'Leadership', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modality', 'Molecular', 'Molecular Profiling', 'Motivation', 'Mutation Spectra', 'Neural Network Simulation', 'Outcome', 'Output', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Process', 'Publications', 'Published Comment', 'Recurrence', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Scheme', 'Scientist', 'Software Engineering', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Systems Biology', 'TensorFlow', 'Testing', 'The Cancer Genome Atlas', 'Time', 'Update', 'Validation', 'Variant', 'Work', 'actionable mutation', 'analytical method', 'application programming interface', 'base', 'cancer genome', 'cancer genomics', 'cancer subtypes', 'cancer type', 'cloud based', 'computing resources', 'data archive', 'data format', 'data submission', 'design', 'experimental study', 'flexibility', 'genome analysis', 'genome-wide', 'genomic data', 'genomics cloud', 'high dimensionality', 'novel strategies', 'patient variability', 'portability', 'prototype', 'response', 'software development', 'spelling', 'tool', 'treatment response', 'treatment strategy', 'tumor', 'tumor initiation', 'usability']",NCI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2018,438654,0.019092042866412626
"UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network The “UCSC-Buck Genome Data Analysis Center for the Genomic Data Analysis Network” will develop state-of-the-art methods for integrating various types of data to discover the genetic pathways, the microenvironment, the originating cells, and the oncogenic processes driving the initiation and progression of tumors. The long term goals of the project are to identify highly accurate models detailing the faulty genetic circuitry at work in each subclone of a patient’s tumor, as well as any “normal” cells acting as accomplices by supporting the cancer microenvironment. The ultimate objective is to encode computer algorithms that can search a patient’s individual pathway diagram for the best combination of interventions to eliminate every tumor cell, while preserving the health of every normal cell, in their body. Integrative pathway analysis methods will be developed to reveal signatures of tumor subtypes from Pan-Cancer and external datasets. New technologies will be established for uncovering network models tailored to individual patients. The tools will be deployed as part of an active collaboration to support the specific projects of the Genome Data Analysis Network. Novel probabilistic graphical models will be used to infer disrupted signaling. Cellular signatures will be collected from the analysis of normal cells, cancer cell line models, and Pan-Cancer investigations. Novel machine-learning methods, guided by pathway mechanisms, will be established to identify cell state signatures in heterogeneous patient samples. This work will reveal rare mutations driving metastatic transformation that are currently of unknown significance. New clues about the genetic circuitry promoting response and resistance to treatment will be established. Finally, cross-tumor connections that relate tumors of one type to a different type will suggest new avenues for treatment. Computational strategies for interpreting the results of cancer genome sequencing projects are in  desperate need. To select appropriate treatment strategies for a patient, an accurate model of the  altered genetic wiring in the tumor is needed as well as how that wiring relates to other tumors  and to other normal cells at various stages of differentiation. The research will establish  resources and software to contribute such methodologies for the Genome Data Analysis Network  projects that will subsequently be released into the public domain to benefit the entire scientific  community.",UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network,9549013,U24CA210990,"['Automobile Driving', 'Awareness', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer cell line', 'Cells', 'Cisplatin', 'Clinical', 'Collaborations', 'Communities', 'Competence', 'Computational algorithm', 'Computer software', 'DNA Sequence Alteration', 'DNA copy number', 'Data', 'Data Set', 'Development', 'Epigenetic Process', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Goals', 'Health', 'Institutes', 'Intervention', 'Investigation', 'Leadership', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Normal Cell', 'North Carolina', 'Oncogenic', 'Output', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Process', 'Protein Isoforms', 'Proteomics', 'Public Domains', 'RNA', 'RNA Splicing', 'Research', 'Resistance', 'Resources', 'Sampling', 'Series', 'Signal Transduction', 'Structure', 'The Cancer Genome Atlas', 'Time', 'Treatment Protocols', 'Tumor Subtype', 'University of Texas M D Anderson Cancer Center', 'Untranslated RNA', 'Variant', 'Work', 'cancer genome', 'cancer genomics', 'computerized tools', 'exceptional responders', 'experience', 'genome analysis', 'genome sequencing', 'genomic data', 'individual patient', 'learning strategy', 'mRNA Expression', 'member', 'neoplastic cell', 'network models', 'new technology', 'novel', 'patient response', 'response', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment', 'tumor progression']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2018,449240,0.012499872700383842
"Multi-scale data integration frameworks to improve cancer outcomes ﻿    DESCRIPTION (provided by applicant)    The purpose of this K01 proposal is to develop innovative Big Data methodologies to improve cancer outcomes. I am a board-certified hematologist-oncologist completing a PhD in biomedical informatics at Stanford University. This proposal builds on my background and research in developing integrative analysis methods for multi-scale data. It also leverages the exceptional environment at Stanford for advanced training in machine learning, distributed computing, and longitudinal study analysis. Under the mentorship of my team of experts I will enhance my methodologies for improving knowledge discovery in cancer. Cancer research abounds with multi-scale data, from imaging to multi-modal molecular data, such as genomic, epigenomic, transcriptomic, and proteomic. Prediction models of clinical outcomes, including survival and therapeutic response, could capitalize on the richness of information that the data embody. In practice, however, the lack of effective methods for data integrative analysis leaves much of the latent knowledge untapped. For example, imaging data are routinely obtained for diagnostic purposes, but often underutilized in integrative analysis of cancer outcomes. By establishing inter-data correlations, imaging data have the potential to become noninvasive proxies for biopsy-acquired molecular data. Furthermore, traditional methods of data analysis have limited ability to extract knowledge from multi-scale data, which are large, heterogeneous, and exhibit complex inter-data interactions. This project outlines specific approaches to enhance knowledge extraction through integrative analyses that: (1) directly relates imaging data to molecular data, and (2) provides biomedical decision support (prediction of clinical outcomes) from multi-scale data. It applies these approaches to the analysis of brain and colorectal cancers. The training aims of the proposal are designed to further the research objectives by: (1) incorporating advanced machine learning skills to enhance information capture from each data source, (2) boosting computational efficiency and overall performance of the developed methodologies to ensure scalability, and (3) adapting methodologies to a longitudinal clinical study. The proposed project has the capacity to make a significant clinical impact by establishing the role of imaging data as a surrogate for molecular data, delineating potential therapeutic targets, and generating predictive markers for clinical outcomes. Importantly, these methodologies have a high potential to be generalizable to other cancers. Data from this project will cumulatively form the basis for an R01 proposal aimed at examining the optimal analysis of longitudinal multi-scale data to determine the minimum set of data needed to achieve maximum knowledge. The proposed work, designed for completion within the award period, will build on my research skills, generate preliminary data, forge productive collaborative relationships, and enable me to compete for R01 funding. In summary, this K01 will accelerate my career development and support launching my career as an independent physician-scientist in cancer data science research. PUBLIC HEALTH RELEVANCE    If successful, this study of brain and colon cancers will produce new ways of analyzing biomedical data that researchers can apply to other cancers to discover better diagnostic and outcome prediction tools, as well as treatments. One method uses imaging data to infer molecular information, including potential therapies, without biopsy. Another analyzes many different sources of biomedical data to find markers that indicate onset, survival likelihood, and treatment response in cancer.",Multi-scale data integration frameworks to improve cancer outcomes,9428444,K01ES026832,"['Applied Research', 'Award', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Biology', 'Biopsy', 'Cancer Diagnostics', 'Cause of Death', 'Clinical', 'Clinical Informatics', 'Clinical Markers', 'Clinical Research', 'Colon Carcinoma', 'Colorectal Cancer', 'Complex', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Data Sources', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Doctor of Philosophy', 'Ensure', 'Environment', 'Exhibits', 'Family-Based Registry', 'Funding', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Hematologist', 'Heterogeneity', 'Image', 'Informatics', 'Institution', 'Intuition', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Learning Skill', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Oncologist', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Proteomics', 'Proxy', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Scientist', 'Site', 'Source', 'Supervision', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Universities', 'Variant', 'Work', 'anticancer research', 'base', 'biomedical informatics', 'cancer genetics', 'cancer subtypes', 'career', 'career development', 'cluster computing', 'cohort', 'colon cancer patients', 'computer framework', 'data integration', 'design', 'epigenomics', 'falls', 'follow-up', 'genetic epidemiology', 'improved', 'improved outcome', 'innovation', 'learning strategy', 'longitudinal analysis', 'molecular imaging', 'new therapeutic target', 'novel', 'oncology', 'outcome prediction', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'skills', 'statistics', 'stem', 'targeted treatment', 'therapeutic target', 'tool', 'transcriptomics', 'treatment response']",NIEHS,STANFORD UNIVERSITY,K01,2018,188952,0.003068576870314365
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9420662,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2018,2000000,0.022591645221123984
"Integrative miRNA data analysis for clinical cancer genomics PROJECT SUMMARY The proposed research has two broad, long-term objectives. First, it seeks to shift medical practice toward more personalized treatments, by applying innovative methods to analyze and integrate DNA, RNA and protein data generated by a large network of GDAN researchers in a miRNA-centric framework. Analyses will identify cancer subtypes, and individual patients within a subtype, in which alterations in the expression of certain miRNAs influence cancer pathogenesis and drug response. Second, the proposed research seeks to shift cancer genomics research by allowing a diverse group of cancer researchers to flexibly access and use the project’s cancer genomics data, and microRNA-centric results and methods, through a cloud computing framework. The proposed research has three specific aims: 1) Build a computational pipeline for processing and analysis of miRNA data, 2) Elucidate the regulation of and by miRNAs through integrative analysis, and 3) Delineate the role of miRNAs in cancer progression and treatment using predictive modeling. Research design and methods: 1) Processing and analysis of miRNA data. We will process total RNA sequence data to identify expressed miRNAs, and extend the current processing pipeline to identify potentially functional miRNA sequence variants. We will apply our miRNA-centric analyses developed for The Cancer Genome Atlas project to identify: subtypes within a cancer, miRNAs that are associated with survival, miRNA targeting effects on gene and protein expression, and cis-effects of copy number and DNA methylation on miRNA abundances. 2) Regulation of and by miRNAs. Collaborating within the research network, we will extend our analysis methods to take into account additional datatypes and functional contexts that influence how miRNAs are regulated, and how they regulate genes and their products. 3) Predictive modeling. As the research network will have detailed clinical data and multiplatform genomic data, we will apply machine learning algorithms in a novel context to key sets of genes, proteins and miRNAs that predict clinical outcomes like survival and drug response. 4) Cloud computing. We will make our data, analysis methods and results readily available to a broad group of researchers within a cloud computing framework. NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,9538631,U24CA210952,"['Affect', 'Algorithms', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'Statistical Data Interpretation', 'The Cancer Genome Atlas', 'Untranslated Regions', 'Variant', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'individual patient', 'innovation', 'insight', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,BRITISH COLUMBIA CANCER AGENCY,U24,2018,1,0.020079073820523218
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9527264,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell Count', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",K99,2018,40760,0.01417662018691182
"Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data Limitless replicative potential is a key hallmark of cancer and critically depends on telomere maintenance. Many cancers thus aberrantly reactivate the telomerase reverse transcriptase (TERT), a catalytic subunit of the telomerase complex that elongates telomere. It has been recently discovered that this common path to immortality in multiple cancers is through two activating point mutations in the TERT promoter (TERTp), found in more than 50 different cancer types, often at strikingly high frequencies, e.g. roughly 83% in glioblastomas (GBM) and 71% in melanomas. In the previous funding period, the PI has identified the molecular function of these highly recurrent mutations, demonstrating that the transcription factor (TF) GABP binds the mutant TERTp with exquisite specificity, but not the wild-type TERTp. The high prevalence of TERTp mutations across multiple cancer types and the selectivity of GABP recruitment to mutant TERTp thus provide an unprecedented opportunity for treating a large number of cancer patients with minimal toxicity to healthy cells. Despite the clear significance of this opportunity, however, several important questions surrounding the molecular functions and modulators of TERTp mutations remain poorly understood, hindering the development of effective and safe therapeutic strategies.  Our long-term goal is to establish a rigorous computational framework for understanding the aberrant transcriptional and epigenetic networks in cancers and to apply the resulting knowledge to devise novel therapeutic strategies that account for the genetic background of individual patients and that can a priori predict and avoid potential resistance mechanisms. The objective of our current renewal proposal is to develop powerful computational methods for transforming our knowledge about the non-coding TERTp mutations into an effective and safe molecular target. At the same time, the resulting methods will help resolve several outstanding challenges in the field of transcriptional gene regulation and have broad applications in cancer genomics. We will accomplish our objective my pursuing the following Aims: (1) Develop and test a computational framework for inferring sequence features that determine the distinct and shared binding patterns of paralogous TFs; (2) Develop and validate integrative tools for discovering the molecular basis of genetic interactions between germline variations and oncogenic mutations; (3) Develop and apply computational methods for studying the role of DNA helical phase between adjacent binding motifs in recruiting ETS factors to chromatin; (4) Perform a systematic genomic characterization of the effects of knocking out GABPB1L in TERTp-mutant cancer cells and healthy cells. The results of this proposal will have a broad impact on cancer research by providing powerful tools for studying paralogous oncogenic TFs and revealing novel insights into a highly promising therapeutic strategy. The proposed research will provide computational and bioinformatic resources for studying the binding pattern of paralogous oncogenic transcription factors. It will provide a computational framework for inferring the function of non-coding regulatory mutations and studying their interaction with common genetic variants. As an important application, we will systematically analyze a novel therapeutic strategy that has the potential to treat effectively a large number of patients across multiple cancer types harboring the recently discovered TERT promoter mutations.",Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data,9472091,R01CA163336,"['Address', 'Binding', 'Binding Sites', 'Cancer Patient', 'Cells', 'Chromatin', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Sequence Alteration', 'Data', 'Development', 'Drug resistance', 'Epigenetic Process', 'Family', 'Family member', 'Frequencies', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Glioblastoma', 'Goals', 'High Prevalence', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Molecular', 'Molecular Target', 'Mutation', 'Nature', 'Oncogenic', 'Patients', 'Pattern', 'Phase', 'Point Mutation', 'Protein Isoforms', 'RNA-Directed DNA Polymerase', 'Recurrence', 'Research', 'Role', 'Somatic Mutation', 'Specificity', 'TERT gene', 'Techniques', 'Telomerase', 'Telomere Maintenance', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Transcriptional Regulation', 'Untranslated RNA', 'Validation', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics resource', 'c-myc Genes', 'cancer cell', 'cancer genomics', 'cancer type', 'computer framework', 'computing resources', 'deep learning', 'dimer', 'genetic variant', 'genome-wide', 'individual patient', 'insight', 'knowledge of results', 'melanoma', 'member', 'mutant', 'novel', 'novel therapeutics', 'promoter', 'recruit', 'resistance mechanism', 'telomere', 'therapeutic target', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2018,327546,0.022017811949646367
"Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different cancer phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. We have identified 4 large, multi- generational kindreds with a founder CDKN2A deleterious mutation (L16R, 47T>G). Our preliminary observations demonstrate that this mutant has lower expression and decreased ability to regulate cell cycle progression compared to wild type protein. Our sequencing studies of kindred members with different cancer phenotypes have identified potential variants in novel genes that modify risk (LGR6, a co-receptor of Wnt signaling and COL11A1, which participates in oncogenic signaling, including TGFbeta). We will determine the ability of the p16 mutant to promote transformation and how it is influenced by interaction with the above candidate modifier genes, LGR6 or COL11A1, in pancreatic cancer and melanoma. We will also develop novel computational models using machine deep learning, to generate networks that capture high dimensional features to integrate gene, biology, and cancer phenotype. This approach will be extended to kindreds with other CDKN2A mutations. Our Specific Aims are to: (1) Identify genotypes of potential modifier genes in multiple kindreds that feature pancreatic cancer and melanoma and known to carry CDKN2A germline mutations. We will use genome wide variant coverage of germline DNA from CDKN2A carriers from the 4 large L16R kindreds, plus additional members in 42 other similar CDKN2A kindreds. We will identify candidate modifier genes in the kindreds by rule-based statistical genetic analysis of genotypes. (2) Define the impact of CDKN2A L16R mutation on the function of p16 and its interplay with candidate modifier genes. We will elucidate the biological significance of mutations in CDKN2A and candidate modifier genes using functional and high throughput methodologies by analyzing the mechanism underlying the interplay between p16 and modifier genes; define new pathways cooperating with this interplay using a combination of genome wide studies to assess transformation in cells carrying p16 mutant or wild-type background using well established in vitro and in vivo models. (3) Develop a deep learning network model to integrate genetic, biological and epidemiological data to accurately infer pancreatic cancer and melanoma phenotypes and age of onset in mutation carriers. We will apply a convolutional neural network, a deep learning algorithm in the training dataset, develop a back-propagation algorithm to fine tune “weights,” and construct mutation-gene networks to capture high-dimensional features for each disease subclass. We will acquire and disseminate new knowledge and tools to the scientific community. Our integrated methods and approach will bring insight into how different cancer phenotypes can occur with identical predisposing mutations, which can be applied to other cancer syndromes with similar challenges. PROJECT NARRATIVE This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. Using 4 large, multi-generational kindreds with a founder CDKN2A deleterious mutation and other kindreds, we will define the mechanism underlying the interplay between CDKN2A and other factors. We will develop novel computational models using machine deep learning, that integrate gene, biology, and cancer phenotype. We will share our new knowledge and tools with the scientific community, and bring insights to apply to other challenging cancer syndromes.",Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds,9518680,R01CA208517,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Alleles', 'Alzheimer&apos', 's Disease', 'Back', 'Biological', 'Biological Neural Networks', 'Biology', 'Brain Neoplasms', 'CDKN2A gene', 'Cancer Gene Mutation', 'Cancer-Predisposing Gene', 'Cell Cycle Progression', 'Cells', 'Code', 'Communities', 'Computer Simulation', 'Cyclin-Dependent Kinase Inhibitor 2A', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Environmental Exposure', 'Etiology', 'Gene Expression', 'Gene Frequency', 'Gene Mutation', 'Gene-Modified', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Germ-Line Mutation', 'In Vitro', 'Individual', 'Inherited', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measures', 'Methodology', 'Methods', 'Minor', 'Modeling', 'Molecular', 'Mutation', 'Oncogenic', 'Pathway interactions', 'Pattern', 'Penetrance', 'Performance', 'Phenotype', 'Process', 'Proteins', 'Proteomics', 'Risk', 'Signal Transduction', 'Smoking', 'Sun Exposure', 'Syndrome', 'Testing', 'Training', 'Transforming Growth Factor beta', 'Variant', 'WNT Signaling Pathway', 'Weight', 'base', 'bead chip', 'cancer genome', 'cell growth', 'deep learning', 'disease phenotype', 'epidemiologic data', 'epigenomics', 'feeding', 'genetic analysis', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'in vivo', 'in vivo Model', 'innovation', 'insight', 'interest', 'kindred', 'leukemia', 'melanoma', 'member', 'metaplastic cell transformation', 'mutant', 'mutation carrier', 'network models', 'non-genetic', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'overexpression', 'protein expression', 'receptor', 'tool', 'transcriptome sequencing', 'transmission process', 'tumorigenesis']",NCI,MAYO CLINIC ROCHESTER,R01,2018,601292,0.02338963750219676
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9416160,R00HG008171,"['Advisory Committees', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Code', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'cancer drug resistance', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'targeted nucleases', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2018,242325,0.022801133578265062
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9548692,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2018,1002519,0.015217281060631563
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9536132,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Comorbidity', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Electrophysiology (science)', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Mood Disorders', 'National Human Genome Research Institute', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phenotype', 'Population', 'Prosencephalon', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Standardization', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'experimental study', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'insight', 'interest', 'molecular phenotype', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'public health relevance', 'relating to nervous system', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2018,3291017,0.001954397871649832
"Integrative miRNA data analysis for clinical cancer genomics No abstract available NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,9811609,U24CA210952,"['Affect', 'Algorithms', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'Statistical Data Interpretation', 'The Cancer Genome Atlas', 'Untranslated Regions', 'Variant', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'individual patient', 'innovation', 'insight', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,PROVINCIAL HEALTH SERVICES AUTHORITY,U24,2018,397386,-0.0007491639384651622
"Integrative approach for predicting cancer driver genes ﻿    DESCRIPTION (provided by applicant): Carcinogenesis, progression of normal cells to malignant cancer, derives from hallmark capabilities of cancer driven by acquiring (somatic) mutations in ""driver genes"" with a selective advantage for cellular proliferation and potentially metastasis. A major motivation for modern cancer genomics studies is to decipher the genetic architecture of cancer by discovering new driver genes. The most widely-used approaches to predict and prioritize driver genes are based on statistics of mutation frequencies. Several methods have been proposed to identify genes with an excessive number of somatic mutations [9-11], known as significantly mutated genes. I propose to address two major limitations of this approach. First, these methods are insufficiently statistically powered given the amount of sequencing data currently available [15]. I will improve statistical power by leveraging diverse information in cancer genomics currently available into a developed machine learning method. Second, there is little objective clarity about the true effectiveness of these methods [11, 14], since there is no agreed-upon gold standard of driver genes, with the exception of a few well-known drivers. I will develop a framework to compare the effectiveness of driver gene prediction methods, in the absence of a gold standard. Both effectively and efficiently identifying cancer driver genes is a matter of great importance to science funding policy towards cancer genomics. PUBLIC HEALTH RELEVANCE: Large sequencing studies have revolutionized our capability to identify the genetic architecture of cancer. However, effectively integrating this stream of big data to identify specific driver genes has remained troublesome. My proposed research project aims to develop an integrative machine learning method that leverages diverse features in cancer genomics to improve predictions of cancer driver genes, and to utilize a principled approach for evaluating the performance of any such method.",Integrative approach for predicting cancer driver genes,9322626,F31CA200266,"['Address', 'Algorithms', 'Architecture', 'Big Data', 'Cell Proliferation', 'Characteristics', 'Data', 'Effectiveness', 'Evaluation', 'Frequencies', 'Funding', 'Gene Mutation', 'Genes', 'Genetic', 'Gold', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methods', 'Modernization', 'Motivation', 'Mutate', 'Mutation', 'Neoplasm Metastasis', 'Normal Cell', 'Pattern', 'Performance', 'Play', 'Policies', 'Property', 'Research Project Grants', 'Sampling', 'Scheme', 'Science', 'Somatic Mutation', 'Stream', 'Supervision', 'Tumor Biology', 'Tumor Suppressor Genes', 'base', 'cancer genomics', 'carcinogenesis', 'compare effectiveness', 'improved', 'learning strategy', 'novel', 'public health relevance', 'statistics', 'transcriptome']",NCI,JOHNS HOPKINS UNIVERSITY,F31,2017,44044,0.012485150251964713
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9344966,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Molecular Profiling', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2017,1186500,0.015384111805926338
"Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation PROJECT SUMMARY It has become feasible to generate deep quantitative data for many of the molecules that are functional in cells, making it possible to survey a large number of tumors measuring genomic alterations and changes to transcripts, proteins and metabolites. It is, however, not clear what is the best way to integrate these data sets to extract as much information as possible about the biology that drives the cancer and how to best disrupt the tumor growth. Our proposed Proteogenomic Data Analysis Center for Cancer Systems Biology and Clinical Translation will develop new methods for better analyzing and integrating these data sets. In addition to developing statistical and machine learning methods, we also emphasize visual exploration of the data, and we will implement interactive web browser based visualization that will allow researchers to easily explore these vast data sets and gain novel insights by being able to quickly switch between summary information and details of the raw data. PROJECT NARRATIVE The mission of the proposed data analysis center is to leverage high dimensional large-scale data from tumor samples to identify new avenues for the development of clinical prognostics and therapeutics for cancer. This mission will be realized through analysis, integration and visualization of multi-omic datasets including genomic, transcriptomic, and proteomic data collected from patient samples to develop predictive models, and during drug treatment of patient derived xenografts and cell lines to validate mechanisms.",Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation,9353354,U24CA210972,"['Amino Acid Sequence Databases', 'Amino Acids', 'Architecture', 'Biological', 'Biology', 'Cancer Center', 'Cell Line', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Consensus', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Experimental Designs', 'Formulation', 'Gene Expression', 'Gene Family', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Imagery', 'Individual', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Mutation', 'Neoplasm Metastasis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Phosphoproteins', 'Phosphorylation', 'Primary Neoplasm', 'Procedures', 'Process', 'Protein Kinase Inhibitors', 'Proteins', 'Proteome', 'Proteomics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Surveys', 'Systems Biology', 'Therapeutic', 'Time', 'Transcript', 'Variant', 'Visual', 'Work', 'Xenograft procedure', 'actionable mutation', 'assay development', 'base', 'candidate identification', 'candidate marker', 'clinical development', 'clinical phenotype', 'clinical translation', 'cohort', 'computerized data processing', 'computerized tools', 'experimental study', 'genomic data', 'high dimensionality', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'personalized medicine', 'precision medicine', 'precision oncology', 'predictive modeling', 'prognostic', 'protein biomarkers', 'protein kinase inhibitor', 'protein metabolite', 'proteogenomics', 'response', 'tool', 'tool development', 'trait', 'transcriptome', 'transcriptomics', 'treatment choice', 'tumor', 'tumor growth']",NCI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U24,2017,624613,0.02239162154828406
"Multi-scale data integration frameworks to improve cancer outcomes ﻿    DESCRIPTION (provided by applicant)    The purpose of this K01 proposal is to develop innovative Big Data methodologies to improve cancer outcomes. I am a board-certified hematologist-oncologist completing a PhD in biomedical informatics at Stanford University. This proposal builds on my background and research in developing integrative analysis methods for multi-scale data. It also leverages the exceptional environment at Stanford for advanced training in machine learning, distributed computing, and longitudinal study analysis. Under the mentorship of my team of experts I will enhance my methodologies for improving knowledge discovery in cancer. Cancer research abounds with multi-scale data, from imaging to multi-modal molecular data, such as genomic, epigenomic, transcriptomic, and proteomic. Prediction models of clinical outcomes, including survival and therapeutic response, could capitalize on the richness of information that the data embody. In practice, however, the lack of effective methods for data integrative analysis leaves much of the latent knowledge untapped. For example, imaging data are routinely obtained for diagnostic purposes, but often underutilized in integrative analysis of cancer outcomes. By establishing inter-data correlations, imaging data have the potential to become noninvasive proxies for biopsy-acquired molecular data. Furthermore, traditional methods of data analysis have limited ability to extract knowledge from multi-scale data, which are large, heterogeneous, and exhibit complex inter-data interactions. This project outlines specific approaches to enhance knowledge extraction through integrative analyses that: (1) directly relates imaging data to molecular data, and (2) provides biomedical decision support (prediction of clinical outcomes) from multi-scale data. It applies these approaches to the analysis of brain and colorectal cancers. The training aims of the proposal are designed to further the research objectives by: (1) incorporating advanced machine learning skills to enhance information capture from each data source, (2) boosting computational efficiency and overall performance of the developed methodologies to ensure scalability, and (3) adapting methodologies to a longitudinal clinical study. The proposed project has the capacity to make a significant clinical impact by establishing the role of imaging data as a surrogate for molecular data, delineating potential therapeutic targets, and generating predictive markers for clinical outcomes. Importantly, these methodologies have a high potential to be generalizable to other cancers. Data from this project will cumulatively form the basis for an R01 proposal aimed at examining the optimal analysis of longitudinal multi-scale data to determine the minimum set of data needed to achieve maximum knowledge. The proposed work, designed for completion within the award period, will build on my research skills, generate preliminary data, forge productive collaborative relationships, and enable me to compete for R01 funding. In summary, this K01 will accelerate my career development and support launching my career as an independent physician-scientist in cancer data science research. PUBLIC HEALTH RELEVANCE    If successful, this study of brain and colon cancers will produce new ways of analyzing biomedical data that researchers can apply to other cancers to discover better diagnostic and outcome prediction tools, as well as treatments. One method uses imaging data to infer molecular information, including potential therapies, without biopsy. Another analyzes many different sources of biomedical data to find markers that indicate onset, survival likelihood, and treatment response in cancer.",Multi-scale data integration frameworks to improve cancer outcomes,9147605,K01ES026832,"['Applied Research', 'Award', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Biology', 'Biopsy', 'Cancer Diagnostics', 'Cause of Death', 'Clinical', 'Clinical Informatics', 'Clinical Markers', 'Clinical Research', 'Colon Carcinoma', 'Colorectal Cancer', 'Complex', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Data Sources', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Doctor of Philosophy', 'Ensure', 'Environment', 'Exhibits', 'Family-Based Registry', 'Funding', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Hematologist', 'Heterogeneity', 'Image', 'Informatics', 'Institution', 'Intuition', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Learning Skill', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Oncologist', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Proteomics', 'Proxy', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Scientist', 'Site', 'Source', 'Supervision', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Universities', 'Variant', 'Work', 'anticancer research', 'base', 'biomedical informatics', 'cancer genetics', 'cancer subtypes', 'career', 'career development', 'cluster computing', 'cohort', 'colon cancer patients', 'computer framework', 'data integration', 'design', 'epigenomics', 'falls', 'follow-up', 'genetic epidemiology', 'improved', 'improved outcome', 'innovation', 'learning strategy', 'longitudinal analysis', 'molecular imaging', 'new therapeutic target', 'novel', 'oncology', 'outcome prediction', 'predict clinical outcome', 'predictive marker', 'public health relevance', 'quantitative imaging', 'response biomarker', 'skills', 'statistics', 'stem', 'targeted treatment', 'therapeutic target', 'tool', 'transcriptomics', 'treatment response']",NIEHS,STANFORD UNIVERSITY,K01,2017,188952,0.003068576870314365
"Accelerating Cancer Genomics with Cloud-scale Bioconductor PROJECT SUMMARY  The Bioconductor project is rooted in recognition that efﬁcient, rigorous, and reproducible analysis of high- dimensional data can be achieved when statisticians, biologists, and computer scientists federate efforts in a transparent and carefully engineered way. The project Accelerating Cancer Genomics with Cloud-scale Bio- conductor devises new approaches to carrying out genome-scale analysis of cancer data using cloud computing environments. The proposal is based on strategies that have proven highly effective in ﬁfteen years of supporting collaborative and carefully engineered software for genome scale analysis in computational biology in the Biocon- ductor project, based on the highly portable and widely adopted R language and environment for data analysis. In Aim 1 we develop architecture and infrastructure for scalably harvesting cloud-based representations of large- scale cancer genome studies such as The Cancer Genome Atlas, creating formal high-performance workﬂows for processing and interpreting cancer genome analyses, and providing packaging and data distribution schemes for moving data to the cloud for scalable analysis there. In Aim 2 we create and support independent creation of intuitive and cancer-relevant interface components supporting reproducible interactive exploration and analysis using the facilities of Rstudio. In Aim 3 we update and generalize the Bioconductor MLInterfaces metapackage to support advanced machine learning using the cancer-oriented strategies and facilities devised in Aims 1 and 2. Our proposal will beneﬁt large numbers of cancer researchers who will be taking advantage of cloud resources, probably with R close to hand, by marrying strengths of cloud-centric strategies for data archiving and query resolution, to the strengths of Bioconductor development and analysis capabilities. We have letters of support from the leadership of the three NCI Cancer Cloud Pilot projects for this project. PROJECT NARRATIVE  Despite major advances in elucidating mechanisms of tumor initiation and proliferation, treatment strategies for many cancers are ineffective, and patient-to-patient variation in treatment response suggests that personal targeting of cancer based on tumor molecular proﬁles will be necessary. This proposal takes a design and architecture approach from a widely used project for analyzing general data arising in genome-scale biology, and adapts it to new NCI-supported cloud-based data archives and analysis environments. The proposal will accelerate identiﬁcation of sources of variation of tumor responsiveness to treatment and will aid physicians in devising personalized antitumor strategies.",Accelerating Cancer Genomics with Cloud-scale Bioconductor,9295396,U01CA214846,"['Acceleration', 'Achievement', 'Address', 'Adopted', 'Animal Cancer Model', 'Architecture', 'Awareness', 'Base Sequence', 'Bioconductor', 'Bioinformatics', 'Biological Assay', 'Biology', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Collaborations', 'Collection', 'Computational Biology', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Analytics', 'Data Storage and Retrieval', 'Development', 'Ecosystem', 'Engineering', 'Environment', 'Eye', 'Fostering', 'Foundations', 'Genomic Data Commons', 'Genomics', 'Goals', 'Hand', 'Harvest', 'Informatics', 'Institutes', 'Intuition', 'Language', 'Leadership', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modality', 'Molecular', 'Molecular Profiling', 'Motivation', 'Mutation Spectra', 'Neural Network Simulation', 'Outcome', 'Output', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Process', 'Publications', 'Published Comment', 'Recurrence', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Retrieval', 'Scheme', 'Scientist', 'Software Engineering', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Systems Biology', 'Testing', 'The Cancer Genome Atlas', 'Time', 'Update', 'Validation', 'Variant', 'Work', 'actionable mutation', 'analytical method', 'application programming interface', 'base', 'cancer genome', 'cancer genomics', 'cancer subtypes', 'cancer type', 'cloud based', 'computing resources', 'data archive', 'data format', 'design', 'experimental study', 'flexibility', 'genome analysis', 'genome-wide', 'genomic data', 'genomics cloud', 'high dimensionality', 'novel strategies', 'portability', 'prototype', 'response', 'software development', 'spelling', 'tool', 'treatment response', 'treatment strategy', 'tumor', 'tumor initiation', 'usability']",NCI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2017,458029,0.019092042866412626
"UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network The “UCSC-Buck Genome Data Analysis Center for the Genomic Data Analysis Network” will develop state-of-the-art methods for integrating various types of data to discover the genetic pathways, the microenvironment, the originating cells, and the oncogenic processes driving the initiation and progression of tumors. The long term goals of the project are to identify highly accurate models detailing the faulty genetic circuitry at work in each subclone of a patient’s tumor, as well as any “normal” cells acting as accomplices by supporting the cancer microenvironment. The ultimate objective is to encode computer algorithms that can search a patient’s individual pathway diagram for the best combination of interventions to eliminate every tumor cell, while preserving the health of every normal cell, in their body. Integrative pathway analysis methods will be developed to reveal signatures of tumor subtypes from Pan-Cancer and external datasets. New technologies will be established for uncovering network models tailored to individual patients. The tools will be deployed as part of an active collaboration to support the specific projects of the Genome Data Analysis Network. Novel probabilistic graphical models will be used to infer disrupted signaling. Cellular signatures will be collected from the analysis of normal cells, cancer cell line models, and Pan-Cancer investigations. Novel machine-learning methods, guided by pathway mechanisms, will be established to identify cell state signatures in heterogeneous patient samples. This work will reveal rare mutations driving metastatic transformation that are currently of unknown significance. New clues about the genetic circuitry promoting response and resistance to treatment will be established. Finally, cross-tumor connections that relate tumors of one type to a different type will suggest new avenues for treatment. Computational strategies for interpreting the results of cancer genome sequencing projects are in  desperate need. To select appropriate treatment strategies for a patient, an accurate model of the  altered genetic wiring in the tumor is needed as well as how that wiring relates to other tumors  and to other normal cells at various stages of differentiation. The research will establish  resources and software to contribute such methodologies for the Genome Data Analysis Network  projects that will subsequently be released into the public domain to benefit the entire scientific  community.",UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network,9353344,U24CA210990,"['Alpha Cell', 'Automobile Driving', 'Awareness', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer cell line', 'Cells', 'Cisplatin', 'Clinical', 'Collaborations', 'Communities', 'Competence', 'Computational algorithm', 'Computer software', 'DNA Sequence Alteration', 'DNA copy number', 'Data', 'Data Set', 'Development', 'Epigenetic Process', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Goals', 'Health', 'Institutes', 'Intervention', 'Investigation', 'Leadership', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Normal Cell', 'North Carolina', 'Oncogenic', 'Output', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Process', 'Protein Isoforms', 'Proteomics', 'Public Domains', 'RNA', 'RNA Splicing', 'Research', 'Resistance', 'Resources', 'Sampling', 'Series', 'Signal Transduction', 'Structure', 'The Cancer Genome Atlas', 'Time', 'Treatment Protocols', 'Tumor Subtype', 'University of Texas M D Anderson Cancer Center', 'Untranslated RNA', 'Variant', 'Work', 'cancer genome', 'cancer genomics', 'computerized tools', 'exceptional responders', 'experience', 'genome analysis', 'genome sequencing', 'genomic data', 'individual patient', 'learning strategy', 'mRNA Expression', 'member', 'neoplastic cell', 'network models', 'new technology', 'novel', 'response', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment', 'tumor progression']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2017,452649,0.012499872700383842
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9248178,U24HG009446,"['ATAC-seq', 'Alleles', 'Alpha Cell', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2017,2000000,0.022591645221123984
"Integrative miRNA data analysis for clinical cancer genomics PROJECT SUMMARY The proposed research has two broad, long-term objectives. First, it seeks to shift medical practice toward more personalized treatments, by applying innovative methods to analyze and integrate DNA, RNA and protein data generated by a large network of GDAN researchers in a miRNA-centric framework. Analyses will identify cancer subtypes, and individual patients within a subtype, in which alterations in the expression of certain miRNAs influence cancer pathogenesis and drug response. Second, the proposed research seeks to shift cancer genomics research by allowing a diverse group of cancer researchers to flexibly access and use the project’s cancer genomics data, and microRNA-centric results and methods, through a cloud computing framework. The proposed research has three specific aims: 1) Build a computational pipeline for processing and analysis of miRNA data, 2) Elucidate the regulation of and by miRNAs through integrative analysis, and 3) Delineate the role of miRNAs in cancer progression and treatment using predictive modeling. Research design and methods: 1) Processing and analysis of miRNA data. We will process total RNA sequence data to identify expressed miRNAs, and extend the current processing pipeline to identify potentially functional miRNA sequence variants. We will apply our miRNA-centric analyses developed for The Cancer Genome Atlas project to identify: subtypes within a cancer, miRNAs that are associated with survival, miRNA targeting effects on gene and protein expression, and cis-effects of copy number and DNA methylation on miRNA abundances. 2) Regulation of and by miRNAs. Collaborating within the research network, we will extend our analysis methods to take into account additional datatypes and functional contexts that influence how miRNAs are regulated, and how they regulate genes and their products. 3) Predictive modeling. As the research network will have detailed clinical data and multiplatform genomic data, we will apply machine learning algorithms in a novel context to key sets of genes, proteins and miRNAs that predict clinical outcomes like survival and drug response. 4) Cloud computing. We will make our data, analysis methods and results readily available to a broad group of researchers within a cloud computing framework. NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,9352805,U24CA210952,"['Affect', 'Algorithms', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'Statistical Data Interpretation', 'The Cancer Genome Atlas', 'Untranslated Regions', 'Variant', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'individual patient', 'innovation', 'insight', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,BRITISH COLUMBIA CANCER AGENCY,U24,2017,398402,0.020079073820523218
"Pilot for Creating Reproducible Workflows Using Docker Containers for NIH Commons DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the world, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.",Pilot for Creating Reproducible Workflows Using Docker Containers for NIH Commons,9275674,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Docking', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Intuition', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Privatization', 'Property', 'Regulator Genes', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome-wide', 'genome-wide analysis', 'genomic data', 'hackathon', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'online resource', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'webinar', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2017,119777,0.03830693958187535
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the world, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9301573,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Intuition', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Privatization', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transact', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome-wide', 'genome-wide analysis', 'genomic data', 'hackathon', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'online resource', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'webinar', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2017,216422,0.042388962433961126
"Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc DESCRIPTION (provided by applicant):  Cancer genomics resources are growing at an unprecedented pace. However, a comprehensive analysis of the cancer genome still remains a daunting challenge. This is in part due to the difficulties in visualizing, integrating, and analyzng cancer genomics data with current technologies. We propose to develop a cloud-based platform to empower researchers with the ability to host, visualize and analyze their own data. The platform is composed of a set of Cancer Analytics Virtual Machines (CAVMs). The main component of each CAVM is a data server which functions to store and serve user data to applications, such as the UCSC Cancer Genomics Browser, to provide data visualization. The second component is a modified Galaxy workflow system to provide data analysis capability. UCSC's suite of analysis tools for nextgen sequencing data analysis and pathway inference will be prepackaged with the system. The two components will be highly integrated to allow tightly coupled cycles of data visualization and analysis. The data server component will be modular such that it can provide data independently to applications besides the Cancer Browser and Galaxy. We will deliver virtual machine images that can be easily initiated in a commercial cloud such as Amazon, or can be installed within a user's own institution. The CAVM also functions as a way for users to Integrate with external large-scale databases. We will deliver a UCSC CAVM that other CAVM instances can connect to, to provide authorized data access from the UCSC cancer genomics data repository. The system allows the dynamic formation of new datasets composed of data slices from multiple sources. This ability to combine data into larger samples will provide the statistical power to allow discoveries that would otherwise not be possible. We aim to eliminate, or significantly reduce, the overhead of system configuration and software installation. Our tools will provide users the capability to access a cloud-based cluster computing environment, which will make sophisticated, computationally intensive analyses accessible to researchers who might not, have access to compute servers. The software platform we develop can be used by individual bench biologists, and also by large projects to serve data to individual users or to other projects. This design has the potential to form an expansive federated database accessible through the same software interface.         RELEVANCE: Currently, clinicians and bench biologists typically depend on external collaborators for data analysis. The proposed system will provide these scientists with data analysis and visualization methods that are both powerful and easy to use. This will accelerate research in the understanding and treatment of cancer, the second-leading cause of death in the U.S. n/a","Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc",9330115,U24CA180951,"['Cause of Death', 'Classification', 'Clinical', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ecosystem', 'Environment', 'Galaxy', 'Genomics', 'Image', 'Imagery', 'Individual', 'Institution', 'Intuition', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Online Systems', 'Pathway interactions', 'Principal Investigator', 'Privatization', 'Publications', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Savings', 'Science', 'Scientist', 'Slice', 'Source', 'Synapses', 'System', 'Technology', 'The Cancer Genome Atlas', 'Update', 'Work', 'application programming interface', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cluster computing', 'data access', 'data hosting', 'data integration', 'data resource', 'data sharing', 'data visualization', 'design', 'federated computing', 'genome browser', 'genomic data', 'genomic signature', 'large-scale database', 'next generation sequencing', 'predictive signature', 'reference genome', 'repository', 'tool', 'virtual', 'web interface']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2017,640037,0.02167008149480635
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9250803,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'experimental study', 'genomic data', 'hazard', 'high dimensionality', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,66026,0.014968816960760016
"BIGDATA: Mid-Scale DCM: DA: ESCE: Discovering Molecular Processes DESCRIPTION (provided by applicant): Cancer is a disease of the genome, caused by disruptions in a person's DNA. Orders of magnitude decreases in price and increases in sequencing throughput enabled sequencing of hundreds of genomes. This will launch a new phase bf ""Precision Medicine,"" where molecular markers can guide therapies tailored to patients. The genomics revolution is now systematically characterizing every somatic change in every tumor for large cohorts (>300 patients). Despite some successes, predicting cancer outcomes based on molecular signatures remains a major challenge. This proposal aims at obliterating several key roadblocks stymieing progress. First, the raw sequence data is not particularly well-suited for use in developing predictive models. Therefore, gene- and pathway-level evidence will be derived from CGHub to significantly increase the utility of the information for biomedical discovery. The information will be collected in a Social Graph technology framework like Facebook to scale to billions of interconnected objects called the Biomedical Evidence Graph (BMEG). Second, the datasets are so large they are impractical to move around on the internet. Thus, an environment will be created within which researchers can move their code to the vast amounts of data within the BMEG. Third, prediction challenges will be created based on cancer genomics datasets and patient outcomes. While there have been a few successes in predicting outcomes, current approaches suffer from reproducibility and robustness when applied to unseen data. This activity will reach a broad community of algorithm developers, promote transparency and sharing of bioinformatics code, and create a strong network effect to crowd-source the development of the best models for biological discovery. The system constructed will be focused around the investigation of cancer outcomes but the entire pipeline will be of general utility for any number of genome-based projects including investigating any number of disease, stem cell properties, model organisms, and genome-wide association studies. RELEVANCE (See instructions): While we are accumulating vast amounts of information on cancer cells, we are still searching in the dark for clues about predicting treatment strategies. It is of paramount importance to accelerate computational discovery. The creation of the BMEG will catalyze community participation to uncover novel relationships to elucidate new fundamental biology on oncogenesis and therapeutic directions for treating this disease. n/a",BIGDATA: Mid-Scale DCM: DA: ESCE: Discovering Molecular Processes,9292292,R01CA180778,"['Algorithms', 'Animal Model', 'Area', 'Automation', 'Back', 'Bioinformatics', 'Biological Models', 'Biology', 'Code', 'Collaborations', 'Communities', 'Community Participation', 'DNA', 'Darkness', 'Data', 'Data Analytics', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Disease', 'Environment', 'Gene Expression', 'Genes', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Human', 'Internet', 'Investigation', 'Level of Evidence', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Outcome', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Plug-in', 'Population', 'Price', 'Probability', 'Process', 'Property', 'Psychological Techniques', 'Reproducibility', 'Research Personnel', 'Resources', 'Running', 'Sampling', 'Stem cells', 'Structure', 'System', 'Technology', 'Therapeutic', 'Work', 'base', 'cancer cell', 'cancer genomics', 'cloud based', 'cohort', 'crowdsourcing', 'data management', 'e-science', 'genome wide association study', 'molecular marker', 'new technology', 'novel', 'online resource', 'open source', 'outcome prediction', 'precision medicine', 'predictive modeling', 'social', 'success', 'treatment strategy', 'tumor', 'tumorigenesis', 'virtual']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2017,643668,0.020132563813182385
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9258454,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2017,244439,0.022801133578265062
"Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different cancer phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. We have identified 4 large, multi- generational kindreds with a founder CDKN2A deleterious mutation (L16R, 47T>G). Our preliminary observations demonstrate that this mutant has lower expression and decreased ability to regulate cell cycle progression compared to wild type protein. Our sequencing studies of kindred members with different cancer phenotypes have identified potential variants in novel genes that modify risk (LGR6, a co-receptor of Wnt signaling and COL11A1, which participates in oncogenic signaling, including TGFbeta). We will determine the ability of the p16 mutant to promote transformation and how it is influenced by interaction with the above candidate modifier genes, LGR6 or COL11A1, in pancreatic cancer and melanoma. We will also develop novel computational models using machine deep learning, to generate networks that capture high dimensional features to integrate gene, biology, and cancer phenotype. This approach will be extended to kindreds with other CDKN2A mutations. Our Specific Aims are to: (1) Identify genotypes of potential modifier genes in multiple kindreds that feature pancreatic cancer and melanoma and known to carry CDKN2A germline mutations. We will use genome wide variant coverage of germline DNA from CDKN2A carriers from the 4 large L16R kindreds, plus additional members in 42 other similar CDKN2A kindreds. We will identify candidate modifier genes in the kindreds by rule-based statistical genetic analysis of genotypes. (2) Define the impact of CDKN2A L16R mutation on the function of p16 and its interplay with candidate modifier genes. We will elucidate the biological significance of mutations in CDKN2A and candidate modifier genes using functional and high throughput methodologies by analyzing the mechanism underlying the interplay between p16 and modifier genes; define new pathways cooperating with this interplay using a combination of genome wide studies to assess transformation in cells carrying p16 mutant or wild-type background using well established in vitro and in vivo models. (3) Develop a deep learning network model to integrate genetic, biological and epidemiological data to accurately infer pancreatic cancer and melanoma phenotypes and age of onset in mutation carriers. We will apply a convolutional neural network, a deep learning algorithm in the training dataset, develop a back-propagation algorithm to fine tune “weights,” and construct mutation-gene networks to capture high-dimensional features for each disease subclass. We will acquire and disseminate new knowledge and tools to the scientific community. Our integrated methods and approach will bring insight into how different cancer phenotypes can occur with identical predisposing mutations, which can be applied to other cancer syndromes with similar challenges. PROJECT NARRATIVE This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. Using 4 large, multi-generational kindreds with a founder CDKN2A deleterious mutation and other kindreds, we will define the mechanism underlying the interplay between CDKN2A and other factors. We will develop novel computational models using machine deep learning, that integrate gene, biology, and cancer phenotype. We will share our new knowledge and tools with the scientific community, and bring insights to apply to other challenging cancer syndromes.",Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds,9334146,R01CA208517,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Alleles', 'Alzheimer&apos', 's Disease', 'Back', 'Biological', 'Biological Neural Networks', 'Biology', 'Brain Neoplasms', 'CDKN2A gene', 'Cancer-Predisposing Gene', 'Cell Cycle Progression', 'Cells', 'Code', 'Communities', 'Computer Simulation', 'Cyclin-Dependent Kinase Inhibitor 2A', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Environmental Exposure', 'Etiology', 'Gene Expression', 'Gene Frequency', 'Gene Mutation', 'Gene-Modified', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Germ-Line Mutation', 'In Vitro', 'Individual', 'Inherited', 'Knowledge', 'Learning', 'Light', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measures', 'Methodology', 'Methods', 'Minor', 'Modeling', 'Molecular', 'Mutation', 'Oncogenic', 'Pathway interactions', 'Pattern', 'Penetrance', 'Performance', 'Phenotype', 'Process', 'Proteins', 'Proteomics', 'Risk', 'Signal Transduction', 'Smoking', 'Sun Exposure', 'Syndrome', 'Testing', 'Training', 'Transforming Growth Factor beta', 'Variant', 'WNT Signaling Pathway', 'Weight', 'base', 'bead chip', 'cancer genome', 'cell growth', 'disease phenotype', 'epidemiologic data', 'epigenomics', 'feeding', 'genetic analysis', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'in vivo', 'in vivo Model', 'innovation', 'insight', 'interest', 'kindred', 'learning network', 'leukemia', 'melanoma', 'member', 'metaplastic cell transformation', 'mutant', 'mutation carrier', 'network models', 'non-genetic', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'overexpression', 'protein expression', 'receptor', 'tool', 'transcriptome sequencing', 'transmission process', 'tumorigenesis']",NCI,MAYO CLINIC ROCHESTER,R01,2017,590577,0.02338963750219676
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9228843,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2017,1002725,0.015217281060631563
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9320861,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Comorbidity', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electrophysiology (science)', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Human Genome Research Institute', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Standardization', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'experimental study', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'insight', 'interest', 'molecular phenotype', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'public health relevance', 'relating to nervous system', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2017,2548493,0.001954397871649832
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,9015770,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'genomic data', 'heuristics', 'mathematical analysis']",NCI,BROWN UNIVERSITY,R01,2016,71329,0.03640779988996115
"Integrative approach for predicting cancer driver genes ﻿    DESCRIPTION (provided by applicant): Carcinogenesis, progression of normal cells to malignant cancer, derives from hallmark capabilities of cancer driven by acquiring (somatic) mutations in ""driver genes"" with a selective advantage for cellular proliferation and potentially metastasis. A major motivation for modern cancer genomics studies is to decipher the genetic architecture of cancer by discovering new driver genes. The most widely-used approaches to predict and prioritize driver genes are based on statistics of mutation frequencies. Several methods have been proposed to identify genes with an excessive number of somatic mutations [9-11], known as significantly mutated genes. I propose to address two major limitations of this approach. First, these methods are insufficiently statistically powered given the amount of sequencing data currently available [15]. I will improve statistical power by leveraging diverse information in cancer genomics currently available into a developed machine learning method. Second, there is little objective clarity about the true effectiveness of these methods [11, 14], since there is no agreed-upon gold standard of driver genes, with the exception of a few well-known drivers. I will develop a framework to compare the effectiveness of driver gene prediction methods, in the absence of a gold standard. Both effectively and efficiently identifying cancer driver genes is a matter of great importance to science funding policy towards cancer genomics.         PUBLIC HEALTH RELEVANCE: Large sequencing studies have revolutionized our capability to identify the genetic architecture of cancer. However, effectively integrating this stream of big data to identify specific driver genes has remained troublesome. My proposed research project aims to develop an integrative machine learning method that leverages diverse features in cancer genomics to improve predictions of cancer driver genes, and to utilize a principled approach for evaluating the performance of any such method.            ",Integrative approach for predicting cancer driver genes,9152184,F31CA200266,"['Address', 'Algorithms', 'Architecture', 'Big Data', 'Cell Proliferation', 'Characteristics', 'Data', 'Effectiveness', 'Evaluation', 'Frequencies', 'Funding', 'Genes', 'Genetic', 'Gold', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methods', 'Motivation', 'Mutate', 'Mutation', 'Neoplasm Metastasis', 'Normal Cell', 'Pattern', 'Performance', 'Play', 'Policies', 'Property', 'Research Project Grants', 'Sampling', 'Scheme', 'Science', 'Somatic Mutation', 'Statistical Bias', 'Stream', 'Tumor Biology', 'Tumor Suppressor Genes', 'base', 'cancer genomics', 'carcinogenesis', 'compare effectiveness', 'improved', 'learning strategy', 'novel', 'public health relevance', 'statistics', 'transcriptome']",NCI,JOHNS HOPKINS UNIVERSITY,F31,2016,43576,0.012485150251964713
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,9268117,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost effectiveness', 'cost efficient', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2016,1378926,0.04196591504272969
"Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation PROJECT SUMMARY It has become feasible to generate deep quantitative data for many of the molecules that are functional in cells, making it possible to survey a large number of tumors measuring genomic alterations and changes to transcripts, proteins and metabolites. It is, however, not clear what is the best way to integrate these data sets to extract as much information as possible about the biology that drives the cancer and how to best disrupt the tumor growth. Our proposed Proteogenomic Data Analysis Center for Cancer Systems Biology and Clinical Translation will develop new methods for better analyzing and integrating these data sets. In addition to developing statistical and machine learning methods, we also emphasize visual exploration of the data, and we will implement interactive web browser based visualization that will allow researchers to easily explore these vast data sets and gain novel insights by being able to quickly switch between summary information and details of the raw data.  PROJECT NARRATIVE The mission of the proposed data analysis center is to leverage high dimensional large-scale data from tumor samples to identify new avenues for the development of clinical prognostics and therapeutics for cancer. This mission will be realized through analysis, integration and visualization of multi-omic datasets including genomic, transcriptomic, and proteomic data collected from patient samples to develop predictive models, and during drug treatment of patient derived xenografts and cell lines to validate mechanisms.",Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation,9210808,U24CA210972,"['Amino Acid Sequence Databases', 'Amino Acids', 'Architecture', 'Biological', 'Biological Markers', 'Biology', 'Cancer Center', 'Cell Line', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Consensus', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Experimental Designs', 'Formulation', 'Gene Expression', 'Gene Family', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Imagery', 'Individual', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Mutation', 'Neoplasm Metastasis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Phosphoproteins', 'Phosphorylation', 'Primary Neoplasm', 'Procedures', 'Process', 'Protein Kinase Inhibitors', 'Proteins', 'Proteomics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Surveys', 'Systems Biology', 'Therapeutic', 'Time', 'Transcript', 'Translations', 'Variant', 'Visual', 'Work', 'Xenograft procedure', 'actionable mutation', 'assay development', 'base', 'candidate identification', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'genomic data', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'personalized medicine', 'precision medicine', 'precision oncology', 'predictive modeling', 'prognostic', 'protein biomarkers', 'protein kinase inhibitor', 'protein metabolite', 'proteogenomics', 'research study', 'response', 'tool', 'tool development', 'trait', 'transcriptome', 'transcriptomics', 'treatment choice', 'tumor', 'tumor growth']",NCI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U24,2016,659453,0.02239162154828406
"UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network The “UCSC-Buck Genome Data Analysis Center for the Genomic Data Analysis Network” will develop state-of-the-art methods for integrating various types of data to discover the genetic pathways, the microenvironment, the originating cells, and the oncogenic processes driving the initiation and progression of tumors. The long term goals of the project are to identify highly accurate models detailing the faulty genetic circuitry at work in each subclone of a patient’s tumor, as well as any “normal” cells acting as accomplices by supporting the cancer microenvironment. The ultimate objective is to encode computer algorithms that can search a patient’s individual pathway diagram for the best combination of interventions to eliminate every tumor cell, while preserving the health of every normal cell, in their body. Integrative pathway analysis methods will be developed to reveal signatures of tumor subtypes from Pan-Cancer and external datasets. New technologies will be established for uncovering network models tailored to individual patients. The tools will be deployed as part of an active collaboration to support the specific projects of the Genome Data Analysis Network. Novel probabilistic graphical models will be used to infer disrupted signaling. Cellular signatures will be collected from the analysis of normal cells, cancer cell line models, and Pan-Cancer investigations. Novel machine-learning methods, guided by pathway mechanisms, will be established to identify cell state signatures in heterogeneous patient samples. This work will reveal rare mutations driving metastatic transformation that are currently of unknown significance. New clues about the genetic circuitry promoting response and resistance to treatment will be established. Finally, cross-tumor connections that relate tumors of one type to a different type will suggest new avenues for treatment. Computational strategies for interpreting the results of cancer genome sequencing projects are in  desperate need. To select appropriate treatment strategies for a patient, an accurate model of the  altered genetic wiring in the tumor is needed as well as how that wiring relates to other tumors  and to other normal cells at various stages of differentiation. The research will establish  resources and software to contribute such methodologies for the Genome Data Analysis Network  projects that will subsequently be released into the public domain to benefit the entire scientific  community.",UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network,9210974,U24CA210990,"['Automobile Driving', 'Bioinformatics', 'Biological', 'Cancer cell line', 'Cells', 'Cisplatin', 'Clinical', 'Collaborations', 'Communities', 'Computational algorithm', 'Computer software', 'DNA Sequence Alteration', 'DNA copy number', 'Data', 'Data Set', 'Development', 'Epigenetic Process', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Goals', 'Health', 'Institutes', 'Intervention', 'Investigation', 'Leadership', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Normal Cell', 'North Carolina', 'Oncogenic', 'Output', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Process', 'Protein Isoforms', 'Proteomics', 'Public Domains', 'RNA', 'RNA Splicing', 'Research', 'Resistance', 'Resources', 'Sampling', 'Series', 'Signal Transduction', 'Staging', 'Structure', 'The Cancer Genome Atlas', 'Treatment Protocols', 'Tumor Subtype', 'University of Texas M D Anderson Cancer Center', 'Untranslated RNA', 'Variant', 'Work', 'cancer genome', 'cancer genomics', 'computerized tools', 'exceptional responders', 'experience', 'genome analysis', 'genome sequencing', 'genomic data', 'individual patient', 'learning strategy', 'member', 'neoplastic cell', 'network models', 'new technology', 'novel', 'response', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment', 'tumor progression']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2016,469457,0.012499872700383842
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC) DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies. The UCSC-Buck Institute Cancer Genome Data Analysis Center aims to analyze the TCGA project data to  identify (1) cancer-associated molecular alterations; (2) dysregulated pathway signatures that can be used in  clinical diagnosis, prognosis, and drug response prediction; and (3) candidate gene targets for the  development of novel therapeutics. Insights learned from this endeavor will advance the knowledge of  cancer and human biology, and will enhance cancer treatment and prevention by personalizing it to the  genetic background of the patient and the mutations present in the tumor.",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),9195878,U24CA143858,"['Animals', 'Biological', 'Biology', 'Cancer Biology', 'Candidate Disease Gene', 'Categories', 'Cell Line', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genomics', 'Glean', 'Goals', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Prevention strategy', 'Prognostic Marker', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer prevention', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'diagnostic biomarker', 'epigenomics', 'genome annotation', 'genome browser', 'genomic data', 'insight', 'meetings', 'next generation sequencing', 'novel therapeutics', 'outcome forecast', 'patient stratification', 'predicting response', 'prevent', 'research study', 'tool', 'transcriptome', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2016,143442,0.05301908478756442
"Integrative miRNA data analysis for clinical cancer genomics PROJECT SUMMARY The proposed research has two broad, long-term objectives. First, it seeks to shift medical practice toward more personalized treatments, by applying innovative methods to analyze and integrate DNA, RNA and protein data generated by a large network of GDAN researchers in a miRNA-centric framework. Analyses will identify cancer subtypes, and individual patients within a subtype, in which alterations in the expression of certain miRNAs influence cancer pathogenesis and drug response. Second, the proposed research seeks to shift cancer genomics research by allowing a diverse group of cancer researchers to flexibly access and use the project’s cancer genomics data, and microRNA-centric results and methods, through a cloud computing framework. The proposed research has three specific aims: 1) Build a computational pipeline for processing and analysis of miRNA data, 2) Elucidate the regulation of and by miRNAs through integrative analysis, and 3) Delineate the role of miRNAs in cancer progression and treatment using predictive modeling. Research design and methods: 1) Processing and analysis of miRNA data. We will process total RNA sequence data to identify expressed miRNAs, and extend the current processing pipeline to identify potentially functional miRNA sequence variants. We will apply our miRNA-centric analyses developed for The Cancer Genome Atlas project to identify: subtypes within a cancer, miRNAs that are associated with survival, miRNA targeting effects on gene and protein expression, and cis-effects of copy number and DNA methylation on miRNA abundances. 2) Regulation of and by miRNAs. Collaborating within the research network, we will extend our analysis methods to take into account additional datatypes and functional contexts that influence how miRNAs are regulated, and how they regulate genes and their products. 3) Predictive modeling. As the research network will have detailed clinical data and multiplatform genomic data, we will apply machine learning algorithms in a novel context to key sets of genes, proteins and miRNAs that predict clinical outcomes like survival and drug response. 4) Cloud computing. We will make our data, analysis methods and results readily available to a broad group of researchers within a cloud computing framework. NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,9210297,U24CA210952,"['Accounting', 'Affect', 'Algorithms', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'The Cancer Genome Atlas', 'Untranslated Regions', 'Variant', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'individual patient', 'innovation', 'insight', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,BRITISH COLUMBIA CANCER AGENCY,U24,2016,394335,0.020079073820523218
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9096856,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2016,2201640,0.043522668617870984
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9288931,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2016,224176,0.043522668617870984
"Integrative Cancer Genomics: Drivers, Pathways and Drugs DESCRIPTION (provided by applicant): The emergence of cancer genomics, combined with increased understanding of the molecular basis of oncogenesis, has stimulated hope that treatment will improve by becoming more targeted and individualized in nature. Cancer genomics studies established a number of critical cancer genes, leading to a number of successful targeted therapies (e.g. Gleevec, Herceptin and Plexxikon). Despite these successes, most cancers do not have a targeted therapy and when one exists, response is highly variable, even among patients that share the targeted mutation and tumor type. To move cancer into the era of personalized therapies, it becomes important to identify the alterations driving tumor progression in each tumor, determine the network that links these aberrations, and identify factors that predict sensitivity to targeted therapies. As projects such as The Cancer Genome Atlas (TCGA) amass cancer cell genomes at a breathtaking pace, a staggering genetic complexity is revealed. To interpret cancer genomes, a key computational challenge is to separate the wheat from the chaff and define both what are the key alterations likely to be functionally driving cancer and then, after defining such genes, begin to identify mechanisms of action and therapeutic implications. Leveraging components from our published methods, CONEXIC (Akavia et.al Cell 2010) and LirNet (Lee et.al, PLOS Gen 2009), we will develop machine-learning algorithms that integrate cancer genomic data to do just that. We will apply the methods we develop to melanoma, glioblastoma, ovarian, breast and colon cancer and experimentally follow up on our computational findings, towards a better understanding of each of these deadly cancers. The approaches developed in this grant will accelerate discovery to rapidly extract the maximal value from modern genomic studies and help carry cancer genomics from the diagnostic to the therapeutic realm. This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.","Integrative Cancer Genomics: Drivers, Pathways and Drugs",9091484,R01CA164729,"['AKT inhibition', 'Algorithms', 'Antineoplastic Agents', 'Automobile Driving', 'Biological Assay', 'Breast Cancer cell line', 'Candidate Disease Gene', 'Cell physiology', 'Cells', 'Collaborations', 'Colon Carcinoma', 'Computer Simulation', 'Computing Methodologies', 'DNA copy number', 'Data', 'Diagnostic', 'Drug resistance', 'FRAP1 gene', 'Feedback', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genomics', 'Gleevec', 'Glioblastoma', 'Grant', 'Growth', 'Heterogeneity', 'Individual', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Oncogenes', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Play', 'Proteins', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'RNA interference screen', 'Resistance', 'Role', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Trastuzumab', 'Validation', 'Work', 'arm', 'base', 'cancer genome', 'cancer genomics', 'computerized tools', 'follow-up', 'genomic data', 'improved', 'malignant breast neoplasm', 'melanoma', 'novel', 'personalized cancer therapy', 'personalized medicine', 'response', 'success', 'targeted treatment', 'tool', 'tumor', 'tumor progression', 'tumorigenesis', 'tumorigenic']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2016,464984,0.002763403616648827
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9041640,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'genomic data', 'hazard', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,255295,0.014968816960760016
"Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc DESCRIPTION (provided by applicant):  Cancer genomics resources are growing at an unprecedented pace. However, a comprehensive analysis of the cancer genome still remains a daunting challenge. This is in part due to the difficulties in visualizing, integrating, and analyzng cancer genomics data with current technologies. We propose to develop a cloud-based platform to empower researchers with the ability to host, visualize and analyze their own data. The platform is composed of a set of Cancer Analytics Virtual Machines (CAVMs). The main component of each CAVM is a data server which functions to store and serve user data to applications, such as the UCSC Cancer Genomics Browser, to provide data visualization. The second component is a modified Galaxy workflow system to provide data analysis capability. UCSC's suite of analysis tools for nextgen sequencing data analysis and pathway inference will be prepackaged with the system. The two components will be highly integrated to allow tightly coupled cycles of data visualization and analysis. The data server component will be modular such that it can provide data independently to applications besides the Cancer Browser and Galaxy. We will deliver virtual machine images that can be easily initiated in a commercial cloud such as Amazon, or can be installed within a user's own institution. The CAVM also functions as a way for users to Integrate with external large-scale databases. We will deliver a UCSC CAVM that other CAVM instances can connect to, to provide authorized data access from the UCSC cancer genomics data repository. The system allows the dynamic formation of new datasets composed of data slices from multiple sources. This ability to combine data into larger samples will provide the statistical power to allow discoveries that would otherwise not be possible. We aim to eliminate, or significantly reduce, the overhead of system configuration and software installation. Our tools will provide users the capability to access a cloud-based cluster computing environment, which will make sophisticated, computationally intensive analyses accessible to researchers who might not, have access to compute servers. The software platform we develop can be used by individual bench biologists, and also by large projects to serve data to individual users or to other projects. This design has the potential to form an expansive federated database accessible through the same software interface.         RELEVANCE: Currently, clinicians and bench biologists typically depend on external collaborators for data analysis. The proposed system will provide these scientists with data analysis and visualization methods that are both powerful and easy to use. This will accelerate research in the understanding and treatment of cancer, the second-leading cause of death in the U.S. n/a","Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc",9126449,U24CA180951,"['Cause of Death', 'Classification', 'Clinical', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ecosystem', 'Environment', 'Galaxy', 'Genomics', 'Image', 'Imagery', 'Individual', 'Institution', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Online Systems', 'Pathway interactions', 'Principal Investigator', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Second Primary Cancers', 'Slice', 'Source', 'Synapses', 'System', 'Technology', 'The Cancer Genome Atlas', 'Update', 'Work', 'application programming interface', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cluster computing', 'data access', 'data hosting', 'data integration', 'data sharing', 'data visualization', 'design', 'empowered', 'federated computing', 'genome browser', 'genomic data', 'genomic signature', 'large-scale database', 'next generation sequencing', 'predictive signature', 'reference genome', 'repository', 'text searching', 'tool', 'virtual', 'web interface']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2016,447746,0.02167008149480635
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,8974432,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",K99,2016,25020,0.022801133578265062
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9242250,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2016,246031,0.022801133578265062
"Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different cancer phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. We have identified 4 large, multi- generational kindreds with a founder CDKN2A deleterious mutation (L16R, 47T>G). Our preliminary observations demonstrate that this mutant has lower expression and decreased ability to regulate cell cycle progression compared to wild type protein. Our sequencing studies of kindred members with different cancer phenotypes have identified potential variants in novel genes that modify risk (LGR6, a co-receptor of Wnt signaling and COL11A1, which participates in oncogenic signaling, including TGFbeta). We will determine the ability of the p16 mutant to promote transformation and how it is influenced by interaction with the above candidate modifier genes, LGR6 or COL11A1, in pancreatic cancer and melanoma. We will also develop novel computational models using machine deep learning, to generate networks that capture high dimensional features to integrate gene, biology, and cancer phenotype. This approach will be extended to kindreds with other CDKN2A mutations. Our Specific Aims are to: (1) Identify genotypes of potential modifier genes in multiple kindreds that feature pancreatic cancer and melanoma and known to carry CDKN2A germline mutations. We will use genome wide variant coverage of germline DNA from CDKN2A carriers from the 4 large L16R kindreds, plus additional members in 42 other similar CDKN2A kindreds. We will identify candidate modifier genes in the kindreds by rule-based statistical genetic analysis of genotypes. (2) Define the impact of CDKN2A L16R mutation on the function of p16 and its interplay with candidate modifier genes. We will elucidate the biological significance of mutations in CDKN2A and candidate modifier genes using functional and high throughput methodologies by analyzing the mechanism underlying the interplay between p16 and modifier genes; define new pathways cooperating with this interplay using a combination of genome wide studies to assess transformation in cells carrying p16 mutant or wild-type background using well established in vitro and in vivo models. (3) Develop a deep learning network model to integrate genetic, biological and epidemiological data to accurately infer pancreatic cancer and melanoma phenotypes and age of onset in mutation carriers. We will apply a convolutional neural network, a deep learning algorithm in the training dataset, develop a back-propagation algorithm to fine tune “weights,” and construct mutation-gene networks to capture high-dimensional features for each disease subclass. We will acquire and disseminate new knowledge and tools to the scientific community. Our integrated methods and approach will bring insight into how different cancer phenotypes can occur with identical predisposing mutations, which can be applied to other cancer syndromes with similar challenges. PROJECT NARRATIVE This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. Using 4 large, multi-generational kindreds with a founder CDKN2A deleterious mutation and other kindreds, we will define the mechanism underlying the interplay between CDKN2A and other factors. We will develop novel computational models using machine deep learning, that integrate gene, biology, and cancer phenotype. We will share our new knowledge and tools with the scientific community, and bring insights to apply to other challenging cancer syndromes.",Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds,9172003,R01CA208517,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Alleles', 'Alzheimer&apos', 's Disease', 'Back', 'Biological', 'Biological Neural Networks', 'Brain Neoplasms', 'CDKN2A gene', 'Cancer Biology', 'Cancer Gene Mutation', 'Cell Cycle Progression', 'Cells', 'Code', 'Communities', 'Computer Simulation', 'Cyclin-Dependent Kinase Inhibitor 2A', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Environmental Exposure', 'Epidemiology', 'Etiology', 'Gene Expression', 'Gene Frequency', 'Gene Mutation', 'Gene-Modified', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Germ-Line Mutation', 'Group Processes', 'In Vitro', 'Individual', 'Inherited', 'Knowledge', 'Learning', 'Light', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measures', 'Methodology', 'Methods', 'Minor', 'Modeling', 'Molecular', 'Mutation', 'Oncogenic', 'Pathway interactions', 'Pattern', 'Penetrance', 'Performance', 'Phenotype', 'Processed Genes', 'Proteins', 'Proteomics', 'Risk', 'Signal Transduction', 'Smoking', 'Sun Exposure', 'Syndrome', 'Testing', 'Training', 'Transforming Growth Factor beta', 'Variant', 'Weight', 'base', 'bead chip', 'cancer genome', 'cell growth', 'disease phenotype', 'epigenomics', 'feeding', 'genetic analysis', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'in vivo', 'in vivo Model', 'innovation', 'insight', 'interest', 'kindred', 'learning network', 'leukemia', 'melanoma', 'member', 'metaplastic cell transformation', 'mutant', 'mutation carrier', 'network models', 'non-genetic', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'overexpression', 'protein expression', 'receptor', 'tool', 'transcriptome sequencing', 'transmission process', 'tumorigenesis']",NCI,MAYO CLINIC ROCHESTER,R01,2016,578620,0.02338963750219676
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9114170,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Health', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Mood Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2016,2560433,0.001954397871649832
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,8825472,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics', 'mathematical analysis', 'transcriptome sequencing']",NCI,BROWN UNIVERSITY,R01,2015,71329,0.03640779988996115
"Integrative approach for predicting cancer driver genes ﻿    DESCRIPTION (provided by applicant): Carcinogenesis, progression of normal cells to malignant cancer, derives from hallmark capabilities of cancer driven by acquiring (somatic) mutations in ""driver genes"" with a selective advantage for cellular proliferation and potentially metastasis. A major motivation for modern cancer genomics studies is to decipher the genetic architecture of cancer by discovering new driver genes. The most widely-used approaches to predict and prioritize driver genes are based on statistics of mutation frequencies. Several methods have been proposed to identify genes with an excessive number of somatic mutations [9-11], known as significantly mutated genes. I propose to address two major limitations of this approach. First, these methods are insufficiently statistically powered given the amount of sequencing data currently available [15]. I will improve statistical power by leveraging diverse information in cancer genomics currently available into a developed machine learning method. Second, there is little objective clarity about the true effectiveness of these methods [11, 14], since there is no agreed-upon gold standard of driver genes, with the exception of a few well-known drivers. I will develop a framework to compare the effectiveness of driver gene prediction methods, in the absence of a gold standard. Both effectively and efficiently identifying cancer driver genes is a matter of great importance to science funding policy towards cancer genomics.         PUBLIC HEALTH RELEVANCE: Large sequencing studies have revolutionized our capability to identify the genetic architecture of cancer. However, effectively integrating this stream of big data to identify specific driver genes has remained troublesome. My proposed research project aims to develop an integrative machine learning method that leverages diverse features in cancer genomics to improve predictions of cancer driver genes, and to utilize a principled approach for evaluating the performance of any such method.            ",Integrative approach for predicting cancer driver genes,8982803,F31CA200266,"['Address', 'Algorithms', 'Architecture', 'Big Data', 'Cell Proliferation', 'Characteristics', 'Data', 'Effectiveness', 'Evaluation', 'Frequencies', 'Funding', 'Gene Expression Profile', 'Genes', 'Genetic', 'Gold', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methods', 'Motivation', 'Mutate', 'Mutation', 'Neoplasm Metastasis', 'Normal Cell', 'Pattern', 'Performance', 'Play', 'Policies', 'Property', 'Research Project Grants', 'Sampling', 'Scheme', 'Science', 'Somatic Mutation', 'Statistical Bias', 'Stream', 'Tumor Biology', 'Tumor Suppressor Genes', 'base', 'cancer genomics', 'carcinogenesis', 'compare effectiveness', 'improved', 'novel', 'public health relevance', 'statistics']",NCI,JOHNS HOPKINS UNIVERSITY,F31,2015,43120,0.012485150251964713
"Informatics Tools for High-Throughput Sequences Data Analysis DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK. The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.",Informatics Tools for High-Throughput Sequences Data Analysis,8788050,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2015,967608,0.003666860457918453
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy. PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8931936,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Untranslated RNA', 'Variant', 'Vision', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2015,116122,0.02634378688126063
"Multi-scale data integration frameworks to improve cancer outcomes ﻿    DESCRIPTION (provided by applicant)    The purpose of this K01 proposal is to develop innovative Big Data methodologies to improve cancer outcomes. I am a board-certified hematologist-oncologist completing a PhD in biomedical informatics at Stanford University. This proposal builds on my background and research in developing integrative analysis methods for multi-scale data. It also leverages the exceptional environment at Stanford for advanced training in machine learning, distributed computing, and longitudinal study analysis. Under the mentorship of my team of experts I will enhance my methodologies for improving knowledge discovery in cancer. Cancer research abounds with multi-scale data, from imaging to multi-modal molecular data, such as genomic, epigenomic, transcriptomic, and proteomic. Prediction models of clinical outcomes, including survival and therapeutic response, could capitalize on the richness of information that the data embody. In practice, however, the lack of effective methods for data integrative analysis leaves much of the latent knowledge untapped. For example, imaging data are routinely obtained for diagnostic purposes, but often underutilized in integrative analysis of cancer outcomes. By establishing inter-data correlations, imaging data have the potential to become noninvasive proxies for biopsy-acquired molecular data. Furthermore, traditional methods of data analysis have limited ability to extract knowledge from multi-scale data, which are large, heterogeneous, and exhibit complex inter-data interactions. This project outlines specific approaches to enhance knowledge extraction through integrative analyses that: (1) directly relates imaging data to molecular data, and (2) provides biomedical decision support (prediction of clinical outcomes) from multi-scale data. It applies these approaches to the analysis of brain and colorectal cancers. The training aims of the proposal are designed to further the research objectives by: (1) incorporating advanced machine learning skills to enhance information capture from each data source, (2) boosting computational efficiency and overall performance of the developed methodologies to ensure scalability, and (3) adapting methodologies to a longitudinal clinical study. The proposed project has the capacity to make a significant clinical impact by establishing the role of imaging data as a surrogate for molecular data, delineating potential therapeutic targets, and generating predictive markers for clinical outcomes. Importantly, these methodologies have a high potential to be generalizable to other cancers. Data from this project will cumulatively form the basis for an R01 proposal aimed at examining the optimal analysis of longitudinal multi-scale data to determine the minimum set of data needed to achieve maximum knowledge. The proposed work, designed for completion within the award period, will build on my research skills, generate preliminary data, forge productive collaborative relationships, and enable me to compete for R01 funding. In summary, this K01 will accelerate my career development and support launching my career as an independent physician-scientist in cancer data science research.         PUBLIC HEALTH RELEVANCE    If successful, this study of brain and colon cancers will produce new ways of analyzing biomedical data that researchers can apply to other cancers to discover better diagnostic and outcome prediction tools, as well as treatments. One method uses imaging data to infer molecular information, including potential therapies, without biopsy. Another analyzes many different sources of biomedical data to find markers that indicate onset, survival likelihood, and treatment response in cancer.                ",Multi-scale data integration frameworks to improve cancer outcomes,9044512,K01ES026832,"['Applied Research', 'Award', 'Big Data', 'Biological Markers', 'Biology', 'Biopsy', 'Cancer Diagnostics', 'Cancer Family', 'Cause of Death', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Colorectal', 'Colorectal Cancer', 'Complex', 'Data', 'Data Analyses', 'Data Correlations', 'Data Set', 'Data Sources', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Doctor of Philosophy', 'Ensure', 'Environment', 'Exhibits', 'Family-Based Registry', 'Funding', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Hematologist', 'Heterogeneity', 'Image', 'Informatics', 'Institution', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Lead', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Oncologist', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Proteomics', 'Proxy', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Science', 'Scientist', 'Site', 'Solutions', 'Source', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Universities', 'Variant', 'Work', 'anticancer research', 'base', 'biomedical informatics', 'cancer genetics', 'career', 'career development', 'cluster computing', 'cohort', 'computer framework', 'data integration', 'design', 'epigenomics', 'falls', 'follow-up', 'forging', 'genetic epidemiology', 'improved', 'innovation', 'longitudinal analysis', 'model building', 'molecular imaging', 'new therapeutic target', 'novel', 'novel therapeutics', 'oncology', 'predictive marker', 'public health relevance', 'quantitative imaging', 'response', 'skills', 'statistics', 'stem', 'targeted treatment', 'therapeutic target', 'tool', 'transcriptomics', 'treatment response']",NIEHS,STANFORD UNIVERSITY,K01,2015,198952,0.003068576870314365
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8889700,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2015,2005492,0.04196591504272969
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9147033,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Health', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2015,489338,0.043522668617870984
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",8935854,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2015,2116462,0.043522668617870984
"Integrative Cancer Genomics: Drivers, Pathways and Drugs DESCRIPTION (provided by applicant): The emergence of cancer genomics, combined with increased understanding of the molecular basis of oncogenesis, has stimulated hope that treatment will improve by becoming more targeted and individualized in nature. Cancer genomics studies established a number of critical cancer genes, leading to a number of successful targeted therapies (e.g. Gleevec, Herceptin and Plexxikon). Despite these successes, most cancers do not have a targeted therapy and when one exists, response is highly variable, even among patients that share the targeted mutation and tumor type. To move cancer into the era of personalized therapies, it becomes important to identify the alterations driving tumor progression in each tumor, determine the network that links these aberrations, and identify factors that predict sensitivity to targeted therapies. As projects such as The Cancer Genome Atlas (TCGA) amass cancer cell genomes at a breathtaking pace, a staggering genetic complexity is revealed. To interpret cancer genomes, a key computational challenge is to separate the wheat from the chaff and define both what are the key alterations likely to be functionally driving cancer and then, after defining such genes, begin to identify mechanisms of action and therapeutic implications. Leveraging components from our published methods, CONEXIC (Akavia et.al Cell 2010) and LirNet (Lee et.al, PLOS Gen 2009), we will develop machine-learning algorithms that integrate cancer genomic data to do just that. We will apply the methods we develop to melanoma, glioblastoma, ovarian, breast and colon cancer and experimentally follow up on our computational findings, towards a better understanding of each of these deadly cancers. The approaches developed in this grant will accelerate discovery to rapidly extract the maximal value from modern genomic studies and help carry cancer genomics from the diagnostic to the therapeutic realm. This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.","Integrative Cancer Genomics: Drivers, Pathways and Drugs",8913905,R01CA164729,"['AKT inhibition', 'Algorithms', 'Antineoplastic Agents', 'Automobile Driving', 'Biological Assay', 'Breast Cancer cell line', 'Candidate Disease Gene', 'Cell physiology', 'Cells', 'Collaborations', 'Colon Carcinoma', 'Computer Simulation', 'Computing Methodologies', 'DNA copy number', 'Data', 'Diagnostic', 'Drug resistance', 'Feedback', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genomics', 'Gleevec', 'Glioblastoma', 'Grant', 'Growth', 'Heterogeneity', 'Individual', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Oncogenes', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Proteins', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'RNA Interference', 'Resistance', 'Roche brand of trastuzumab', 'Role', 'Solutions', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Validation', 'Work', 'arm', 'base', 'cancer genome', 'cancer genomics', 'computerized tools', 'follow-up', 'human FRAP1 protein', 'improved', 'malignant breast neoplasm', 'melanoma', 'novel', 'personalized cancer therapy', 'personalized medicine', 'response', 'success', 'targeted treatment', 'tool', 'tumor', 'tumor progression', 'tumorigenesis', 'tumorigenic']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2015,554295,0.002763403616648827
"Developing integrative approaches for identifying disease-causing genes and dysfunctional networks ﻿    DESCRIPTION: Cancer is a consequence of the accumulation of genetic alterations. Large whole-genome scale resequencing projects such as The Cancer Genome Atlas (TCGA) have been launched in an effort to comprehensively catalog the genomic mutations and epigenetic modifications that are associated with cancer. It is essential to identify cancer-causing genes and pathways to gain insight into the disease mechanisms and hence facilitate early diagnosis and optimal treatment. However, identifying cancer-causing genes and their functional pathways remains challenging due to the complex biological interactions and the heterogeneity of diseases. Genetic mutations in disease-causing genes can disturb signaling pathways that impact the expression of a set of genes performing certain biological functions. We refer to a set of such genes as a functional module. We hypothesize that driver mutations, that is, mutations that lead to cancer progression, are likely to affect common disease-associated functional modules, and the causal relationship between the mutations and the perturbed signals of the modules can be reconstructed from gene expression data and protein interaction data. In this project, we will develop a novel approach to infer disease-causing genes and networks by integrating information from multiple types of data including genomic variations, gene expression and protein interactions. We first dynamically identify disease-associated modules that consist of a set of interacting genes, then develop a Bayesian-based approach to infer causative genes from the disease-associated modules. Then, by developing a stochastic search based method, we can determine the paths connecting causative genes and gene modules. As a result, disease- related pathways are inferred from the paths. Furthermore, we will integrate those pathways with the human interactome to discover higher-level disease-associated networks. In addition, we will develop machine learning based classifiers to predict disease types and clinical outcomes utilizing the molecular signatures identified in this project, such as differentially expressed gene modules and causative genes. Our computational framework and classifiers will be made available to the research community via a webserver. The PI serves as the university bioinformatics program director and has extensive teaching and research experience. A goal of this project is also to provide scientific research training to students and o help students to gain biological insight through their involvement with the project. Students will learn practical scientific computing skills from the PI and develop their own computational approaches to solving specific biomedical problems under the guidance of the PI. Thus the project will serve as an effective learning-research model in bioinformatics.         PUBLIC HEALTH RELEVANCE: In this project, we will develop and implement a novel framework to identify causative mutations and pathways and study cancer disease mechanisms by reconstructing signaling pathways. This will help to advance personalized medicine and lead to a greater understanding of cancer mechanisms, which can lay the foundation for improving early diagnosis and treatment planning, as well as the discovery of new therapeutic targets.            ",Developing integrative approaches for identifying disease-causing genes and dysfunctional networks,8880075,R15GM114739,"['Affect', 'Bioinformatics', 'Biological', 'Biological Process', 'Cancer Etiology', 'Cataloging', 'Catalogs', 'Clinical', 'Clinical Data', 'Communities', 'Complex', 'DNA', 'DNA Resequencing', 'DNA Sequence Alteration', 'DNA-Protein Interaction', 'Data', 'Disease', 'Drug Targeting', 'Early Diagnosis', 'Early treatment', 'Educational process of instructing', 'Epigenetic Process', 'Foundations', 'Gene Cluster', 'Gene Expression', 'Gene Mutation', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human', 'Investigation', 'Lead', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Mutation', 'Outcome', 'Pathway interactions', 'Performance', 'Phosphorylation', 'Population', 'Proteins', 'Recurrent disease', 'Research', 'Research Training', 'Resources', 'Role', 'Sampling', 'Signal Pathway', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Models', 'Students', 'System', 'Technology', 'The Cancer Genome Atlas', 'Universities', 'base', 'computer based statistical methods', 'computer framework', 'differential expression', 'disease diagnosis', 'disorder risk', 'experience', 'genome wide association study', 'genome-wide', 'genomic variation', 'heuristics', 'improved', 'innovation', 'insight', 'knowledge base', 'new therapeutic target', 'next generation sequencing', 'novel', 'novel strategies', 'personalized medicine', 'predictive modeling', 'programs', 'promoter', 'prospective', 'protein protein interaction', 'public health relevance', 'scientific computing', 'skills', 'treatment planning', 'tumor progression']",NIGMS,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R15,2015,373520,-0.0011929763826862218
"Human-Specific Gain and Loss of Function DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university. PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.",Human-Specific Gain and Loss of Function,8796200,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomic Segment', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2015,54194,0.01305639178135322
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,8858662,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,248912,0.014968816960760016
"Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc DESCRIPTION (provided by applicant):  Cancer genomics resources are growing at an unprecedented pace. However, a comprehensive analysis of the cancer genome still remains a daunting challenge. This is in part due to the difficulties in visualizing, integrating, and analyzng cancer genomics data with current technologies. We propose to develop a cloud-based platform to empower researchers with the ability to host, visualize and analyze their own data. The platform is composed of a set of Cancer Analytics Virtual Machines (CAVMs). The main component of each CAVM is a data server which functions to store and serve user data to applications, such as the UCSC Cancer Genomics Browser, to provide data visualization. The second component is a modified Galaxy workflow system to provide data analysis capability. UCSC's suite of analysis tools for nextgen sequencing data analysis and pathway inference will be prepackaged with the system. The two components will be highly integrated to allow tightly coupled cycles of data visualization and analysis. The data server component will be modular such that it can provide data independently to applications besides the Cancer Browser and Galaxy. We will deliver virtual machine images that can be easily initiated in a commercial cloud such as Amazon, or can be installed within a user's own institution. The CAVM also functions as a way for users to Integrate with external large-scale databases. We will deliver a UCSC CAVM that other CAVM instances can connect to, to provide authorized data access from the UCSC cancer genomics data repository. The system allows the dynamic formation of new datasets composed of data slices from multiple sources. This ability to combine data into larger samples will provide the statistical power to allow discoveries that would otherwise not be possible. We aim to eliminate, or significantly reduce, the overhead of system configuration and software installation. Our tools will provide users the capability to access a cloud-based cluster computing environment, which will make sophisticated, computationally intensive analyses accessible to researchers who might not, have access to compute servers. The software platform we develop can be used by individual bench biologists, and also by large projects to serve data to individual users or to other projects. This design has the potential to form an expansive federated database accessible through the same software interface.         RELEVANCE: Currently, clinicians and bench biologists typically depend on external collaborators for data analysis. The proposed system will provide these scientists with data analysis and visualization methods that are both powerful and easy to use. This will accelerate research in the understanding and treatment of cancer, the second-leading cause of death in the U.S. n/a","Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc",8889644,U24CA180951,"['Cause of Death', 'Classification', 'Clinical', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ecosystem', 'Environment', 'Galaxy', 'Genome', 'Genomics', 'Image', 'Imagery', 'Individual', 'Institution', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Online Systems', 'Pathway interactions', 'Principal Investigator', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Second Primary Cancers', 'Slice', 'Source', 'Synapses', 'System', 'Technology', 'The Cancer Genome Atlas', 'Update', 'Work', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cluster computing', 'data hosting', 'data integration', 'data sharing', 'data visualization', 'design', 'empowered', 'federated computing', 'large-scale database', 'next generation sequencing', 'programs', 'repository', 'text searching', 'tool', 'virtual', 'web interface']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2015,556381,0.02167008149480635
"Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci DESCRIPTION (provided by applicant): Colorectal carcinoma (CRC) arises from multiple mutations and genomic aberrations in distinct driver cancer genes that that in concert to spur neoplastic development and phenotype. This inherent genetic complexity greatly complicates both personalized diagnosis and treatment. Previously published studies have confined that large numbers of genes will be mutated or subject to genomic aberrations in CRC. A significant and emerging challenge for the post-genomic era is to identify which of these mutated genes are ""driver"" loci that functionally drive colon cancer development, versus ""passenger"" loci without functional relevance. Finally, it is of the highest priority that one forges these genetic observations with correlations of prognosis and clinical outcome. This can only be done if we better understand the unified biological ramifications of the combined and diverse multigenic driver background which act synergistically to promote CRC tumorigenesis. This proposal details an integrated analysis that will rely on the CRC genomic data generated by the Cancer Genome Atlas Project (TCGA) to discover novel candidate CRC genes and study multigenic CRC driver gene co-mutated / dysregulated modules within the genetic context of other drivers and provide biological validation in a powerful in vitro primary culture CRC model which can be engineered for multiple genetic events.  To accomplish these goals, we will develop and implement novel statistical methodologies for the integrative analysis of multiple TCGA genomic and clinical data sets. The goal is to identify and prioritize novel CRC genes either singly or as co-mutated modules in combination with other known ""driver"" CRC genes. We will use the rich TCGA data set to conduct an integrated CRC genomic analysis of point mutations, gene expression, copy number aberrations and methylation data. We will prioritize the discovery of mutations and other genomic aberrations of these novel CRC genes that are associated with specific clinical stages of disease and other clinical parameters.  These statistical and computational studies will then be directly coupled to rapid and robust functional target validation of candidate loci using our rigorously characterized in vitro primary intestinal culture methodology (Gotani et al, Nature Medicine, 2009), in which we have recently established the transforming activity of established CRC loci such as APC, KRAS and TP53. Genetic deletion and retroviral expression of shRNA, cDNA or mutants thereof will be utilized to evaluate putative individual driver loci, as well as combinatorial oncogene modules. This proposal directly addresses fundamental problems in the exploration and translation of novel colorectal cancer gene discovery in the context of clinical data which is available from TCGA. RELEVANCE (See instructions): Colorectal cancer (CRC) represents the third most commonly diagnosed cancer in the United States. This proposal utilizes a fusion of genomic analysis of a large population of patients, mathematical modeling and culture of intestinal fragments to functionally identify genes that are critical for colon cancer development. These studies have implications for generation of novel diagnostic and therapeutic strategies for colon cancer. n/a",Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci,8916038,U01CA151920,"['Address', 'Algorithm Design', 'Algorithms', 'Atlases', 'Bayesian Analysis', 'Biological', 'Biology', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Colorectal Cancer', 'Complementary DNA', 'Copy Number Polymorphism', 'Coupled', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Engineering', 'Evaluation', 'Event', 'Future', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Goals', 'In Vitro', 'Individual', 'Instruction', 'Intestines', 'KRAS2 gene', 'Large Intestine Carcinoma', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Oncogenes', 'Oncologist', 'Outcome', 'Phenotype', 'Point Mutation', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Somatic Mutation', 'Staging', 'Statistical Study', 'Surveys', 'Systems Biology', 'TP53 gene', 'Technology', 'The Cancer Genome Atlas', 'Translations', 'United States', 'Validation', 'Variant', 'authority', 'cancer diagnosis', 'cancer genome', 'cancer genomics', 'candidate validation', 'clinical phenotype', 'combinatorial', 'computer studies', 'exome', 'exome sequencing', 'experience', 'forging', 'gene discovery', 'genome-wide', 'intestinal epithelium', 'mathematical model', 'mutant', 'neoplastic', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'outcome forecast', 'patient population', 'segregation', 'small hairpin RNA', 'statistics', 'tumorigenesis']",NCI,STANFORD UNIVERSITY,U01,2015,538250,0.027352194914964566
"Informatics Tools for High-throughput Analysis of Cancer Mutations DESCRIPTION (provided by applicant): Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics). PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.",Informatics Tools for High-throughput Analysis of Cancer Mutations,8910262,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Health', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'next generation sequencing', 'novel strategies', 'personalized diagnostics', 'prognostic', 'protein function', 'protein structure', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2015,315948,0.024678527696556676
"Genome engineering tools for functional screening of non-coding elements     DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root).         PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.                ",Genome engineering tools for functional screening of non-coding elements,8804084,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Laboratories', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Relative (related person)', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",K99,2015,99937,0.022801133578265062
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8840551,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'genetic variant', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,219004,0.0073228516792840734
"Informatics to enable routine personalized cancer therapy     DESCRIPTION (provided by applicant): Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. However, even highly-specialized physicians at leading academic centers are not equipped to apply genomic information available in publically available sources to clinical- decision-making concerning individual patients. Our central hypothesis is that we can develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exceptions. We will: 1) implement a bioinformatics pipeline for processing molecular data into actionable profiles, 2) create and maintain a database of therapeutic implications of common genomic aberrations using automated processing of publically-available sources and 3) develop tools to summarize and present patient-specific advice to clinicians. These tools will be based on existing technologies and publicly available data sources. Once tested, we will make these tools available via appropriate open source license.          PUBLIC HEALTH RELEVANCE: Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. In this project, we will develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exception.             ",Informatics to enable routine personalized cancer therapy,8904309,U01CA180964,"['Address', 'Adoption', 'Algorithms', 'Bioinformatics', 'Biological Factors', 'Cancer Biology', 'Cancer Center', 'Cancer Patient', 'Cataloging', 'Catalogs', 'Characteristics', 'Classification', 'Clinical', 'Clinical Medicine', 'Clinical Trials', 'DNA Sequence Alteration', 'Data', 'Data Sources', 'Databases', 'Drug Compounding', 'Enrollment', 'Evaluation', 'FDA approved', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hot Spot', 'Human', 'Individual', 'Informatics', 'Institutes', 'Internet', 'Ions', 'Licensing', 'Link', 'Literature', 'MEDLINE', 'Malignant Neoplasms', 'Manuals', 'Molecular', 'Molecular Profiling', 'Mutation', 'Natural Language Processing', 'Nucleotides', 'Oncogenes', 'Oncologist', 'PTPRC gene', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Review Literature', 'Source', 'Source Code', 'Technology', 'Testing', 'Therapeutic', 'Therapy trial', 'Time', 'Update', 'Validation', 'Variant', 'base', 'biomedical informatics', 'clinical decision-making', 'clinically relevant', 'exome sequencing', 'open source', 'personalized cancer therapy', 'personalized medicine', 'programs', 'public health relevance', 'standard of care', 'success', 'targeted treatment', 'tool', 'tumor', 'tumor DNA', 'usability', 'web site']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U01,2015,316190,0.004144403928865004
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9117098,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,194377,0.001954397871649832
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8929310,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,2563635,0.001954397871649832
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,-0.00987169161344297
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,8685211,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics', 'mathematical analysis']",NCI,BROWN UNIVERSITY,R01,2014,69189,0.03658028605643679
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8601147,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2014,989800,0.003666860457918453
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions     DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy.         PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.        The written critiques of individual reviewers are provided in essentially unedited form in this section. Please note that these critiques and criteria scores were prepared prior to the meeting and may not have been revised subsequent to any discussions at the review meeting. The ""Resume and Summary of Discussion"" section above summarizes the final opinions of the committee.                ","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8805723,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'Critiques', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Functional RNA', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Variant', 'Vision', 'Writing', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'meetings', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'public health relevance', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2014,116122,0.026174617781009307
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8725717,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2014,2015775,0.04196591504272969
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC) DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies. The UCSC-Buck Institute Cancer Genome Data Analysis Center aims to analyze the TCGA project data to  identify (1) cancer-associated molecular alterations; (2) dysregulated pathway signatures that can be used in  clinical diagnosis, prognosis, and drug response prediction; and (3) candidate gene targets for the  development of novel therapeutics. Insights learned from this endeavor will advance the knowledge of  cancer and human biology, and will enhance cancer treatment and prevention by personalizing it to the  genetic background of the patient and the mutations present in the tumor.",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8925188,U24CA143858,"['Animals', 'Biological', 'Biology', 'Cancer Biology', 'Candidate Disease Gene', 'Categories', 'Cell Line', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Glean', 'Goals', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer prevention', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'genome annotation', 'insight', 'meetings', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2014,1000000,0.05301908478756442
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC) DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies. The UCSC-Buck Institute Cancer Genome Data Analysis Center aims to analyze the TCGA project data to  identify (1) cancer-associated molecular alterations; (2) dysregulated pathway signatures that can be used in  clinical diagnosis, prognosis, and drug response prediction; and (3) candidate gene targets for the  development of novel therapeutics. Insights learned from this endeavor will advance the knowledge of  cancer and human biology, and will enhance cancer treatment and prevention by personalizing it to the  genetic background of the patient and the mutations present in the tumor.",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8827877,U24CA143858,"['Animals', 'Biological', 'Biology', 'Cancer Biology', 'Candidate Disease Gene', 'Categories', 'Cell Line', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Glean', 'Goals', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer prevention', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'genome annotation', 'insight', 'meetings', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2014,316000,0.05301908478756442
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",8774407,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2014,1623265,0.043522668617870984
"Integrative Cancer Genomics: Drivers, Pathways and Drugs     DESCRIPTION (provided by applicant): The emergence of cancer genomics, combined with increased understanding of the molecular basis of oncogenesis, has stimulated hope that treatment will improve by becoming more targeted and individualized in nature. Cancer genomics studies established a number of critical cancer genes, leading to a number of successful targeted therapies (e.g. Gleevec, Herceptin and Plexxikon). Despite these successes, most cancers do not have a targeted therapy and when one exists, response is highly variable, even among patients that share the targeted mutation and tumor type. To move cancer into the era of personalized therapies, it becomes important to identify the alterations driving tumor progression in each tumor, determine the network that links these aberrations, and identify factors that predict sensitivity to targeted therapies. As projects such as The Cancer Genome Atlas (TCGA) amass cancer cell genomes at a breathtaking pace, a staggering genetic complexity is revealed. To interpret cancer genomes, a key computational challenge is to separate the wheat from the chaff and define both what are the key alterations likely to be functionally driving cancer and then, after defining such genes, begin to identify mechanisms of action and therapeutic implications. Leveraging components from our published methods, CONEXIC (Akavia et.al Cell 2010) and LirNet (Lee et.al, PLOS Gen 2009), we will develop machine-learning algorithms that integrate cancer genomic data to do just that. We will apply the methods we develop to melanoma, glioblastoma, ovarian, breast and colon cancer and experimentally follow up on our computational findings, towards a better understanding of each of these deadly cancers. The approaches developed in this grant will accelerate discovery to rapidly extract the maximal value from modern genomic studies and help carry cancer genomics from the diagnostic to the therapeutic realm.          This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.            ","Integrative Cancer Genomics: Drivers, Pathways and Drugs",8685909,R01CA164729,"['AKT inhibition', 'Algorithms', 'Antineoplastic Agents', 'Automobile Driving', 'Biological Assay', 'Breast Cancer Cell', 'Cancer cell line', 'Candidate Disease Gene', 'Cell physiology', 'Cells', 'Collaborations', 'Colon Carcinoma', 'Computer Simulation', 'Computing Methodologies', 'DNA copy number', 'Data', 'Diagnostic', 'Drug resistance', 'Feedback', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Gleevec', 'Glioblastoma', 'Grant', 'Growth', 'Heterogeneity', 'Individual', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Oncogenes', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Proteins', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'RNA Interference', 'Resistance', 'Roche brand of trastuzumab', 'Role', 'Solutions', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Validation', 'Work', 'arm', 'base', 'cancer cell', 'cancer genome', 'cancer genomics', 'cancer therapy', 'computerized tools', 'follow-up', 'human FRAP1 protein', 'improved', 'malignant breast neoplasm', 'melanoma', 'novel', 'response', 'success', 'tool', 'tumor', 'tumor progression', 'tumorigenesis', 'tumorigenic']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2014,101640,0.002763403616648827
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8635216,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2014,51530,0.01305639178135322
"Heterogeneous and Robust Survival Analysis in Genomic Studies     DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed.         PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.            ",Heterogeneous and Robust Survival Analysis in Genomic Studies,8696520,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,255295,0.014968816960760016
"Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc     DESCRIPTION (provided by applicant):  Cancer genomics resources are growing at an unprecedented pace. However, a comprehensive analysis of the cancer genome still remains a daunting challenge. This is in part due to the difficulties in visualizing, integrating, and analyzng cancer genomics data with current technologies. We propose to develop a cloud-based platform to empower researchers with the ability to host, visualize and analyze their own data. The platform is composed of a set of Cancer Analytics Virtual Machines (CAVMs). The main component of each CAVM is a data server which functions to store and serve user data to applications, such as the UCSC Cancer Genomics Browser, to provide data visualization. The second component is a modified Galaxy workflow system to provide data analysis capability. UCSC's suite of analysis tools for nextgen sequencing data analysis and pathway inference will be prepackaged with the system. The two components will be highly integrated to allow tightly coupled cycles of data visualization and analysis. The data server component will be modular such that it can provide data independently to applications besides the Cancer Browser and Galaxy. We will deliver virtual machine images that can be easily initiated in a commercial cloud such as Amazon, or can be installed within a user's own institution. The CAVM also functions as a way for users to Integrate with external large-scale databases. We will deliver a UCSC CAVM that other CAVM instances can connect to, to provide authorized data access from the UCSC cancer genomics data repository. The system allows the dynamic formation of new datasets composed of data slices from multiple sources. This ability to combine data into larger samples will provide the statistical power to allow discoveries that would otherwise not be possible. We aim to eliminate, or significantly reduce, the overhead of system configuration and software installation. Our tools will provide users the capability to access a cloud-based cluster computing environment, which will make sophisticated, computationally intensive analyses accessible to researchers who might not, have access to compute servers. The software platform we develop can be used by individual bench biologists, and also by large projects to serve data to individual users or to other projects. This design has the potential to form an expansive federated database accessible through the same software interface.         RELEVANCE: Currently, clinicians and bench biologists typically depend on external collaborators for data analysis. The proposed system will provide these scientists with data analysis and visualization methods that are both powerful and easy to use. This will accelerate research in the understanding and treatment of cancer, the second-leading cause of death in the U.S.              n/a","Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc",8735909,U24CA180951,"['Cause of Death', 'Classification', 'Clinical', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ecosystem', 'Environment', 'Galaxy', 'Genome', 'Genomics', 'Image', 'Imagery', 'Individual', 'Institution', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Online Systems', 'Pathway interactions', 'Principal Investigator', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Second Primary Cancers', 'Slice', 'Source', 'Synapses', 'System', 'Technology', 'The Cancer Genome Atlas', 'Update', 'Work', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cluster computing', 'data hosting', 'data integration', 'data sharing', 'design', 'empowered', 'federated computing', 'large-scale database', 'programs', 'repository', 'text searching', 'tool', 'virtual', 'web interface']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2014,674379,0.02167008149480635
"Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci    DESCRIPTION (provided by applicant): Colorectal carcinoma (CRC) arises from multiple mutations and genomic aberrations in distinct driver cancer genes that that in concert to spur neoplastic development and phenotype. This inherent genetic complexity greatly complicates both personalized diagnosis and treatment. Previously published studies have confined that large numbers of genes will be mutated or subject to genomic aberrations in CRC. A significant and emerging challenge for the post-genomic era is to identify which of these mutated genes are ""driver"" loci that functionally drive colon cancer development, versus ""passenger"" loci without functional relevance. Finally, it is of the highest priority that one forges these genetic observations with correlations of prognosis and clinical outcome. This can only be done if we better understand the unified biological ramifications of the combined and diverse multigenic driver background which act synergistically to promote CRC tumorigenesis. This proposal details an integrated analysis that will rely on the CRC genomic data generated by the Cancer Genome Atlas Project (TCGA) to discover novel candidate CRC genes and study multigenic CRC driver gene co-mutated / dysregulated modules within the genetic context of other drivers and provide biological validation in a powerful in vitro primary culture CRC model which can be engineered for multiple genetic events.  To accomplish these goals, we will develop and implement novel statistical methodologies for the integrative analysis of multiple TCGA genomic and clinical data sets. The goal is to identify and prioritize novel CRC genes either singly or as co-mutated modules in combination with other known ""driver"" CRC genes. We will use the rich TCGA data set to conduct an integrated CRC genomic analysis of point mutations, gene expression, copy number aberrations and methylation data. We will prioritize the discovery of mutations and other genomic aberrations of these novel CRC genes that are associated with specific clinical stages of disease and other clinical parameters.  These statistical and computational studies will then be directly coupled to rapid and robust functional target validation of candidate loci using our rigorously characterized in vitro primary intestinal culture methodology (Gotani et al, Nature Medicine, 2009), in which we have recently established the transforming activity of established CRC loci such as APC, KRAS and TP53. Genetic deletion and retroviral expression of shRNA, cDNA or mutants thereof will be utilized to evaluate putative individual driver loci, as well as combinatorial oncogene modules. This proposal directly addresses fundamental problems in the exploration and translation of novel colorectal cancer gene discovery in the context of clinical data which is available from TCGA. RELEVANCE (See instructions): Colorectal cancer (CRC) represents the third most commonly diagnosed cancer in the United States. This proposal utilizes a fusion of genomic analysis of a large population of patients, mathematical modeling and culture of intestinal fragments to functionally identify genes that are critical for colon cancer development. These studies have implications for generation of novel diagnostic and therapeutic strategies for colon cancer.           n/a",Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci,8727268,U01CA151920,"['Address', 'Algorithm Design', 'Algorithms', 'Atlases', 'Bayesian Analysis', 'Biological', 'Biology', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Colorectal Cancer', 'Complementary DNA', 'Copy Number Polymorphism', 'Coupled', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Engineering', 'Evaluation', 'Event', 'Future', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'In Vitro', 'Individual', 'Instruction', 'Intestines', 'KRAS2 gene', 'Large Intestine Carcinoma', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Oncogenes', 'Oncologist', 'Outcome', 'Phenotype', 'Point Mutation', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Somatic Mutation', 'Staging', 'Statistical Study', 'Surveys', 'Systems Biology', 'TP53 gene', 'Technology', 'The Cancer Genome Atlas', 'Translations', 'United States', 'Validation', 'Variant', 'authority', 'cancer diagnosis', 'cancer genome', 'cancer genomics', 'candidate validation', 'clinical phenotype', 'combinatorial', 'computer studies', 'exome', 'exome sequencing', 'experience', 'forging', 'gene discovery', 'intestinal epithelium', 'mathematical model', 'mutant', 'neoplastic', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'outcome forecast', 'patient population', 'segregation', 'small hairpin RNA', 'statistics', 'tumorigenesis']",NCI,STANFORD UNIVERSITY,U01,2014,523201,0.027352194914964566
"Informatics Tools for High-throughput Analysis of Cancer Mutations     DESCRIPTION (provided by applicant): Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics).         PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.            ",Informatics Tools for High-throughput Analysis of Cancer Mutations,8735910,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'microbial alkaline proteinase inhibitor', 'next generation sequencing', 'novel strategies', 'prognostic', 'protein function', 'protein structure', 'public health relevance', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2014,317146,0.024678527696556676
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8642168,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,207764,0.0073228516792840734
"Informatics to enable routine personalized cancer therapy     DESCRIPTION (provided by applicant): Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. However, even highly-specialized physicians at leading academic centers are not equipped to apply genomic information available in publically available sources to clinical- decision-making concerning individual patients. Our central hypothesis is that we can develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exceptions. We will: 1) implement a bioinformatics pipeline for processing molecular data into actionable profiles, 2) create and maintain a database of therapeutic implications of common genomic aberrations using automated processing of publically-available sources and 3) develop tools to summarize and present patient-specific advice to clinicians. These tools will be based on existing technologies and publicly available data sources. Once tested, we will make these tools available via appropriate open source license.          PUBLIC HEALTH RELEVANCE: Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. In this project, we will develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exception.             ",Informatics to enable routine personalized cancer therapy,8741711,U01CA180964,"['Address', 'Adoption', 'Algorithms', 'Bioinformatics', 'Biological Factors', 'Cancer Biology', 'Cancer Center', 'Cancer Patient', 'Cataloging', 'Catalogs', 'Characteristics', 'Classification', 'Clinical', 'Clinical Medicine', 'Clinical Trials', 'DNA', 'Data', 'Data Sources', 'Databases', 'Drug Compounding', 'Enrollment', 'Evaluation', 'FDA approved', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hot Spot', 'Human', 'Individual', 'Informatics', 'Institutes', 'Internet', 'Ions', 'Licensing', 'Link', 'Literature', 'MEDLINE', 'Malignant Neoplasms', 'Manuals', 'Metric', 'Molecular', 'Molecular Profiling', 'Mutation', 'Natural Language Processing', 'Nucleotides', 'Oncogenes', 'Oncologist', 'PTPRC gene', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Review Literature', 'Source', 'Source Code', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Update', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cancer therapy', 'clinical decision-making', 'clinically relevant', 'exome sequencing', 'open source', 'programs', 'public health relevance', 'standard of care', 'success', 'tool', 'tumor', 'usability', 'web site']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U01,2014,312379,0.004144403928865004
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8699810,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic DNA', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,641093,0.01968839094166246
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8698507,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Clinical Trials', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Functional RNA', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2014,2625284,0.001954397871649832
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,-0.00987169161344297
"Analytical Approaches to Massive Data Computation with Applications to Genomics     DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.              n/a",Analytical Approaches to Massive Data Computation with Applications to Genomics,8599823,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics']",NCI,BROWN UNIVERSITY,R01,2013,71329,0.03658028605643679
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8416349,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2013,964551,0.003666860457918453
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8722983,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,115680,0.04196591504272969
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8548395,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,1871839,0.04196591504272969
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC) DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies. The UCSC-Buck Institute Cancer Genome Data Analysis Center aims to analyze the TCGA project data to  identify (1) cancer-associated molecular alterations; (2) dysregulated pathway signatures that can be used in  clinical diagnosis, prognosis, and drug response prediction; and (3) candidate gene targets for the  development of novel therapeutics. Insights learned from this endeavor will advance the knowledge of  cancer and human biology, and will enhance cancer treatment and prevention by personalizing it to the  genetic background of the patient and the mutations present in the tumor.",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8537845,U24CA143858,"['Animals', 'Biological', 'Biology', 'Cancer Biology', 'Candidate Disease Gene', 'Categories', 'Cell Line', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Glean', 'Goals', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer prevention', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'genome annotation', 'insight', 'meetings', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2013,900000,0.05301908478756442
"Second generation sequencing and analysis for cancer    DESCRIPTION (provided by applicant): Kevin Squire is a PhD in Electrical Engineering and former Computer Science professor with a strong interest in bioinformatics and human genetics. To this end, he joined Dr. Stanley F. Nelson's laboratory as a Postdoctoral Fellow in Human Genetics at UCLA one year ago, in order to retrain in bioinformatics and sequencing. Kevin's background in machine learning gives him a good foundation for a career in bioinformatics. What he needs, and what obtaining this grant will give him, is a good background in basic biology, biochemistry, and genetics, in order to better understand the biological processes behind the data he is working with. Kevin explorations in genetics have inspired him to make his career in this field. He hopes to gain a much better understanding of biology in order to ask and answer research questions relevant to the biology of cancer using second (and later) generation sequencing and through the use and development of relevant tools and analysis. As part of the research development plan, Kevin will complete a didactic coursework component in the first 2 years, to fill in the gaps in biology and bioinformatics in his background. During and after that, his research will focus on giving him a better understanding the genetics of cancer, attempting to answer relevant research questions from high throughput genomic sequencing data, through the use and creation of sequence analysis tools and other bioinformatics tools. Through his coursework and research, Kevin will attain the necessary skills to become an independent researcher in bioinformatics and genetics.       PUBLIC HEALTH RELEVANCE: Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.         ",Second generation sequencing and analysis for cancer,8471121,K25GM097097,"['Address', 'Affect', 'Aftercare', 'Algorithms', 'Alternative Splicing', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Biological Process', 'Biology', 'Cancer Biology', 'Cells', 'Collaborations', 'Complex', 'DNA', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Electrical Engineering', 'Exons', 'Fellowship', 'Foundations', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Glioblastoma', 'Glioma', 'Grant', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Laboratories', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measurement', 'Mentors', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Mutation', 'Normal tissue morphology', 'Nucleotides', 'Other Genetics', 'Patients', 'Postdoctoral Fellow', 'Prevention strategy', 'Process', 'Production', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Sequences', 'Radiation therapy', 'Recording of previous events', 'Recurrence', 'Recurrent tumor', 'Relapse', 'Research', 'Research Personnel', 'Salvage Therapy', 'Sampling', 'Sequence Analysis', 'Spliced Genes', 'Techniques', 'Technology', 'Training Programs', 'Tumor Cell Biology', 'Tumor Tissue', 'Variant', 'Work', 'anticancer research', 'base', 'bevacizumab', 'cancer genetics', 'cancer genomics', 'career', 'computer science', 'disease-causing mutation', 'exome', 'exome sequencing', 'expectation', 'experience', 'genetic selection', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'methylome', 'next generation sequencing', 'professor', 'programs', 'public health relevance', 'research and development', 'resistance mechanism', 'skills', 'temozolomide', 'tool', 'tumor']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2013,123483,0.012783993823754952
"Integrative Cancer Genomics: Drivers, Pathways and Drugs     DESCRIPTION (provided by applicant): The emergence of cancer genomics, combined with increased understanding of the molecular basis of oncogenesis, has stimulated hope that treatment will improve by becoming more targeted and individualized in nature. Cancer genomics studies established a number of critical cancer genes, leading to a number of successful targeted therapies (e.g. Gleevec, Herceptin and Plexxikon). Despite these successes, most cancers do not have a targeted therapy and when one exists, response is highly variable, even among patients that share the targeted mutation and tumor type. To move cancer into the era of personalized therapies, it becomes important to identify the alterations driving tumor progression in each tumor, determine the network that links these aberrations, and identify factors that predict sensitivity to targeted therapies. As projects such as The Cancer Genome Atlas (TCGA) amass cancer cell genomes at a breathtaking pace, a staggering genetic complexity is revealed. To interpret cancer genomes, a key computational challenge is to separate the wheat from the chaff and define both what are the key alterations likely to be functionally driving cancer and then, after defining such genes, begin to identify mechanisms of action and therapeutic implications. Leveraging components from our published methods, CONEXIC (Akavia et.al Cell 2010) and LirNet (Lee et.al, PLOS Gen 2009), we will develop machine-learning algorithms that integrate cancer genomic data to do just that. We will apply the methods we develop to melanoma, glioblastoma, ovarian, breast and colon cancer and experimentally follow up on our computational findings, towards a better understanding of each of these deadly cancers. The approaches developed in this grant will accelerate discovery to rapidly extract the maximal value from modern genomic studies and help carry cancer genomics from the diagnostic to the therapeutic realm.          This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.            ","Integrative Cancer Genomics: Drivers, Pathways and Drugs",8534063,R01CA164729,"['AKT inhibition', 'Algorithms', 'Antineoplastic Agents', 'Automobile Driving', 'Biological Assay', 'Breast Cancer Cell', 'Cancer cell line', 'Candidate Disease Gene', 'Cell physiology', 'Cells', 'Collaborations', 'Colon Carcinoma', 'Computer Simulation', 'Computing Methodologies', 'DNA copy number', 'Data', 'Diagnostic', 'Drug resistance', 'Feedback', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Gleevec', 'Glioblastoma', 'Grant', 'Growth', 'Heterogeneity', 'Individual', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Oncogenes', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Proteins', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'RNA Interference', 'Resistance', 'Roche brand of trastuzumab', 'Role', 'Solutions', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Validation', 'Work', 'arm', 'base', 'cancer cell', 'cancer genome', 'cancer genomics', 'cancer therapy', 'computerized tools', 'follow-up', 'human FRAP1 protein', 'improved', 'malignant breast neoplasm', 'melanoma', 'novel', 'response', 'success', 'tool', 'tumor', 'tumor progression', 'tumorigenesis', 'tumorigenic']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2013,358131,0.002763403616648827
"Machine Learning Prediction of Cancer Susceptibility No abstract available  PROJECT NARRATIVE The technology to measure information about the human genome is advancing at a rapid pace. Despite these advance, the computational methods for analyzing the data have not kept pace. We will develop new computer algorithms and software that can be used to identify genetic biomarkers of common human diseases. We will then apply these new computational methods to identifying genetic biomarkers of bladder cancer in an epidemiological study from New Hampshire.",Machine Learning Prediction of Cancer Susceptibility,8528718,R01LM009012,"['Age', 'Algorithms', 'Architecture', 'Characteristics', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data Analyses', 'Detection', 'Development', 'Environmental Exposure', 'Epidemiologic Studies', 'Evaluation', 'Family', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Goals', 'Human Genome', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Measures', 'Methods', 'Modeling', 'Modification', 'New Hampshire', 'Predisposition', 'Research', 'Single Nucleotide Polymorphism', 'Susceptibility Gene', 'Technology', 'Testing', 'Validation', 'analytical method', 'base', 'cancer type', 'combinatorial', 'gene environment interaction', 'genome wide association study', 'genome-wide', 'heuristics', 'human disease', 'improved', 'novel', 'novel strategies', 'open source', 'population based', 'programs', 'statistics']",NLM,DARTMOUTH COLLEGE,R01,2013,339879,0.005058259484138915
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8457179,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2013,47114,0.01305639178135322
"Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc     DESCRIPTION (provided by applicant):  Cancer genomics resources are growing at an unprecedented pace. However, a comprehensive analysis of the cancer genome still remains a daunting challenge. This is in part due to the difficulties in visualizing, integrating, and analyzng cancer genomics data with current technologies. We propose to develop a cloud-based platform to empower researchers with the ability to host, visualize and analyze their own data. The platform is composed of a set of Cancer Analytics Virtual Machines (CAVMs). The main component of each CAVM is a data server which functions to store and serve user data to applications, such as the UCSC Cancer Genomics Browser, to provide data visualization. The second component is a modified Galaxy workflow system to provide data analysis capability. UCSC's suite of analysis tools for nextgen sequencing data analysis and pathway inference will be prepackaged with the system. The two components will be highly integrated to allow tightly coupled cycles of data visualization and analysis. The data server component will be modular such that it can provide data independently to applications besides the Cancer Browser and Galaxy. We will deliver virtual machine images that can be easily initiated in a commercial cloud such as Amazon, or can be installed within a user's own institution. The CAVM also functions as a way for users to Integrate with external large-scale databases. We will deliver a UCSC CAVM that other CAVM instances can connect to, to provide authorized data access from the UCSC cancer genomics data repository. The system allows the dynamic formation of new datasets composed of data slices from multiple sources. This ability to combine data into larger samples will provide the statistical power to allow discoveries that would otherwise not be possible. We aim to eliminate, or significantly reduce, the overhead of system configuration and software installation. Our tools will provide users the capability to access a cloud-based cluster computing environment, which will make sophisticated, computationally intensive analyses accessible to researchers who might not, have access to compute servers. The software platform we develop can be used by individual bench biologists, and also by large projects to serve data to individual users or to other projects. This design has the potential to form an expansive federated database accessible through the same software interface.         RELEVANCE: Currently, clinicians and bench biologists typically depend on external collaborators for data analysis. The proposed system will provide these scientists with data analysis and visualization methods that are both powerful and easy to use. This will accelerate research in the understanding and treatment of cancer, the second-leading cause of death in the U.S.              n/a","Cloud Based Resource for Data Hosting, Visualization and Analysis Using UCSC Canc",8607380,U24CA180951,"['Cause of Death', 'Classification', 'Clinical', 'Collection', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ecosystem', 'Environment', 'Galaxy', 'Genome', 'Genomics', 'Image', 'Imagery', 'Individual', 'Institution', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Online Systems', 'Pathway interactions', 'Principal Investigator', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Second Primary Cancers', 'Slice', 'Source', 'Synapses', 'System', 'Technology', 'The Cancer Genome Atlas', 'Update', 'Work', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cluster computing', 'data integration', 'data sharing', 'design', 'empowered', 'federated computing', 'large-scale database', 'programs', 'repository', 'text searching', 'tool', 'virtual', 'web interface']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2013,621154,0.02167008149480635
"Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci    DESCRIPTION (provided by applicant): Colorectal carcinoma (CRC) arises from multiple mutations and genomic aberrations in distinct driver cancer genes that that in concert to spur neoplastic development and phenotype. This inherent genetic complexity greatly complicates both personalized diagnosis and treatment. Previously published studies have confined that large numbers of genes will be mutated or subject to genomic aberrations in CRC. A significant and emerging challenge for the post-genomic era is to identify which of these mutated genes are ""driver"" loci that functionally drive colon cancer development, versus ""passenger"" loci without functional relevance. Finally, it is of the highest priority that one forges these genetic observations with correlations of prognosis and clinical outcome. This can only be done if we better understand the unified biological ramifications of the combined and diverse multigenic driver background which act synergistically to promote CRC tumorigenesis. This proposal details an integrated analysis that will rely on the CRC genomic data generated by the Cancer Genome Atlas Project (TCGA) to discover novel candidate CRC genes and study multigenic CRC driver gene co-mutated / dysregulated modules within the genetic context of other drivers and provide biological validation in a powerful in vitro primary culture CRC model which can be engineered for multiple genetic events.  To accomplish these goals, we will develop and implement novel statistical methodologies for the integrative analysis of multiple TCGA genomic and clinical data sets. The goal is to identify and prioritize novel CRC genes either singly or as co-mutated modules in combination with other known ""driver"" CRC genes. We will use the rich TCGA data set to conduct an integrated CRC genomic analysis of point mutations, gene expression, copy number aberrations and methylation data. We will prioritize the discovery of mutations and other genomic aberrations of these novel CRC genes that are associated with specific clinical stages of disease and other clinical parameters.  These statistical and computational studies will then be directly coupled to rapid and robust functional target validation of candidate loci using our rigorously characterized in vitro primary intestinal culture methodology (Gotani et al, Nature Medicine, 2009), in which we have recently established the transforming activity of established CRC loci such as APC, KRAS and TP53. Genetic deletion and retroviral expression of shRNA, cDNA or mutants thereof will be utilized to evaluate putative individual driver loci, as well as combinatorial oncogene modules. This proposal directly addresses fundamental problems in the exploration and translation of novel colorectal cancer gene discovery in the context of clinical data which is available from TCGA. RELEVANCE (See instructions): Colorectal cancer (CRC) represents the third most commonly diagnosed cancer in the United States. This proposal utilizes a fusion of genomic analysis of a large population of patients, mathematical modeling and culture of intestinal fragments to functionally identify genes that are critical for colon cancer development. These studies have implications for generation of novel diagnostic and therapeutic strategies for colon cancer.           n/a",Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci,8534039,U01CA151920,"['Address', 'Algorithms', 'Atlases', 'Bayesian Analysis', 'Biological', 'Biology', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Colorectal Cancer', 'Complementary DNA', 'Copy Number Polymorphism', 'Coupled', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Engineering', 'Evaluation', 'Event', 'Future', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'In Vitro', 'Individual', 'Instruction', 'Intestines', 'KRAS2 gene', 'Large Intestine Carcinoma', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Oncogenes', 'Oncologist', 'Outcome', 'Phenotype', 'Point Mutation', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Somatic Mutation', 'Staging', 'Statistical Study', 'Surveys', 'Systems Biology', 'TP53 gene', 'Technology', 'The Cancer Genome Atlas', 'Translations', 'United States', 'Validation', 'Variant', 'authority', 'cancer diagnosis', 'cancer genome', 'cancer genomics', 'candidate validation', 'clinical phenotype', 'combinatorial', 'computer studies', 'design', 'exome', 'exome sequencing', 'experience', 'forging', 'gene discovery', 'intestinal epithelium', 'mathematical model', 'mutant', 'neoplastic', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'outcome forecast', 'patient population', 'segregation', 'small hairpin RNA', 'statistics', 'tumorigenesis']",NCI,STANFORD UNIVERSITY,U01,2013,507962,0.027352194914964566
"Informatics Tools for High-throughput Analysis of Cancer Mutations  PROJECT SUMMARY  Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics). PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.            ",Informatics Tools for High-throughput Analysis of Cancer Mutations,8606625,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'microbial alkaline proteinase inhibitor', 'next generation sequencing', 'novel strategies', 'prognostic', 'protein function', 'protein structure', 'public health relevance', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2013,289971,0.024678527696556676
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8599826,R01CA180777,"['Bees', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,214832,0.0073228516792840734
"Informatics to enable routine personalized cancer therapy  Program Director/Principal Investigator (Bernstam, Elmer Victor) Abstract Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. However, even highly-specialized physicians at leading academic centers are not equipped to apply genomic information available in publically available sources to clinical- decision-making concerning individual patients. Our central hypothesis is that we can develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exceptions. We will: 1) implement a bioinformatics pipeline for processing molecular data into actionable profiles, 2) create and maintain a database of therapeutic implications of common genomic aberrations using automated processing of publically-available sources and 3) develop tools to summarize and present patient-specific advice to clinicians. These tools will be based on existing technologies and publicly available data sources. Once tested, we will make these tools available via appropriate open source license. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: Genomic analysis of individual patients is now affordable and therapies targeted to specific molecular aberrations are being tested in clinical trials. In this project, we will develop informatics tools to support personalized cancer treatment as ""standard of care"" rather than ""one off"" exception.             ",Informatics to enable routine personalized cancer therapy,8607017,U01CA180964,"['Address', 'Adoption', 'Algorithms', 'Bioinformatics', 'Biological Factors', 'Cancer Biology', 'Cancer Center', 'Cancer Patient', 'Cataloging', 'Catalogs', 'Characteristics', 'Classification', 'Clinical', 'Clinical Medicine', 'Clinical Trials', 'DNA', 'Data', 'Data Sources', 'Databases', 'Drug Compounding', 'Enrollment', 'Evaluation', 'FDA approved', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hot Spot', 'Human', 'Individual', 'Informatics', 'Institutes', 'Internet', 'Ions', 'Licensing', 'Link', 'Literature', 'MEDLINE', 'Malignant Neoplasms', 'Manuals', 'Metric', 'Molecular', 'Molecular Profiling', 'Mutation', 'Natural Language Processing', 'Nucleotides', 'Oncogenes', 'Oncologist', 'PTPRC gene', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Review Literature', 'Source', 'Source Code', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Update', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cancer therapy', 'clinical decision-making', 'clinically relevant', 'exome sequencing', 'open source', 'programs', 'public health relevance', 'standard of care', 'success', 'tool', 'tumor', 'usability', 'web site']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U01,2013,335040,0.0032918961048579477
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8537965,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,624741,0.01968839094166246
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.      PUBLIC HEALTH RELEVANCE: The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.              The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8237596,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Delivery Systems', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2012,1010000,-0.008379761875958227
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8494858,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2012,371054,0.054291423690877
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8402447,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Set', 'Development', 'Disease', 'Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2012,2460045,0.04196591504272969
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8228154,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,323572,0.011565450000378712
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC) DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies. The UCSC-Buck Institute Cancer Genome Data Analysis Center aims to analyze the TCGA project data to  identify (1) cancer-associated molecular alterations; (2) dysregulated pathway signatures that can be used in  clinical diagnosis, prognosis, and drug response prediction; and (3) candidate gene targets for the  development of novel therapeutics. Insights learned from this endeavor will advance the knowledge of  cancer and human biology, and will enhance cancer treatment and prevention by personalizing it to the  genetic background of the patient and the mutations present in the tumor.",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8309386,U24CA143858,"['Animals', 'Biological', 'Biology', 'Cancer Biology', 'Candidate Disease Gene', 'Categories', 'Cell Line', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Expression Profile', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Glean', 'Goals', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer prevention', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'insight', 'meetings', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2012,1309530,0.05301908478756442
"Second generation sequencing and analysis for cancer    DESCRIPTION (provided by applicant): Kevin Squire is a PhD in Electrical Engineering and former Computer Science professor with a strong interest in bioinformatics and human genetics. To this end, he joined Dr. Stanley F. Nelson's laboratory as a Postdoctoral Fellow in Human Genetics at UCLA one year ago, in order to retrain in bioinformatics and sequencing. Kevin's background in machine learning gives him a good foundation for a career in bioinformatics. What he needs, and what obtaining this grant will give him, is a good background in basic biology, biochemistry, and genetics, in order to better understand the biological processes behind the data he is working with. Kevin explorations in genetics have inspired him to make his career in this field. He hopes to gain a much better understanding of biology in order to ask and answer research questions relevant to the biology of cancer using second (and later) generation sequencing and through the use and development of relevant tools and analysis. As part of the research development plan, Kevin will complete a didactic coursework component in the first 2 years, to fill in the gaps in biology and bioinformatics in his background. During and after that, his research will focus on giving him a better understanding the genetics of cancer, attempting to answer relevant research questions from high throughput genomic sequencing data, through the use and creation of sequence analysis tools and other bioinformatics tools. Through his coursework and research, Kevin will attain the necessary skills to become an independent researcher in bioinformatics and genetics.      PUBLIC HEALTH RELEVANCE: Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.           Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.         ",Second generation sequencing and analysis for cancer,8242400,K25GM097097,"['Address', 'Affect', 'Aftercare', 'Algorithms', 'Alternative Splicing', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Biological Process', 'Biology', 'Cancer Biology', 'Cells', 'Collaborations', 'Complex', 'DNA', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Electrical Engineering', 'Exons', 'Fellowship', 'Foundations', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Glioblastoma', 'Glioma', 'Grant', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Laboratories', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measurement', 'Mentors', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Mutation', 'Normal tissue morphology', 'Nucleotides', 'Other Genetics', 'Patients', 'Postdoctoral Fellow', 'Prevention strategy', 'Process', 'Production', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Sequences', 'Radiation therapy', 'Recording of previous events', 'Recurrence', 'Recurrent tumor', 'Relapse', 'Research', 'Research Personnel', 'Salvage Therapy', 'Sampling', 'Sequence Analysis', 'Spliced Genes', 'Techniques', 'Technology', 'Training Programs', 'Tumor Cell Biology', 'Tumor Tissue', 'Variant', 'Work', 'anticancer research', 'base', 'bevacizumab', 'cancer genetics', 'cancer genomics', 'career', 'computer science', 'disease-causing mutation', 'exome', 'expectation', 'experience', 'genetic selection', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'next generation', 'professor', 'programs', 'research and development', 'resistance mechanism', 'skills', 'temozolomide', 'tool', 'tumor']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2012,123483,0.013631391409290271
"Integrative Cancer Genomics: Drivers, Pathways and Drugs     DESCRIPTION (provided by applicant): The emergence of cancer genomics, combined with increased understanding of the molecular basis of oncogenesis, has stimulated hope that treatment will improve by becoming more targeted and individualized in nature. Cancer genomics studies established a number of critical cancer genes, leading to a number of successful targeted therapies (e.g. Gleevec, Herceptin and Plexxikon). Despite these successes, most cancers do not have a targeted therapy and when one exists, response is highly variable, even among patients that share the targeted mutation and tumor type. To move cancer into the era of personalized therapies, it becomes important to identify the alterations driving tumor progression in each tumor, determine the network that links these aberrations, and identify factors that predict sensitivity to targeted therapies. As projects such as The Cancer Genome Atlas (TCGA) amass cancer cell genomes at a breathtaking pace, a staggering genetic complexity is revealed. To interpret cancer genomes, a key computational challenge is to separate the wheat from the chaff and define both what are the key alterations likely to be functionally driving cancer and then, after defining such genes, begin to identify mechanisms of action and therapeutic implications. Leveraging components from our published methods, CONEXIC (Akavia et.al Cell 2010) and LirNet (Lee et.al, PLOS Gen 2009), we will develop machine-learning algorithms that integrate cancer genomic data to do just that. We will apply the methods we develop to melanoma, glioblastoma, ovarian, breast and colon cancer and experimentally follow up on our computational findings, towards a better understanding of each of these deadly cancers. The approaches developed in this grant will accelerate discovery to rapidly extract the maximal value from modern genomic studies and help carry cancer genomics from the diagnostic to the therapeutic realm.        PUBLIC HEALTH RELEVANCE: This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.              This work aims to develop methods that help dissect the genetic complexity of individual cancers. For each tumor we aim to identify which mutations arm a cell with the abilities to abnormally grow or evade drug treatment, providing a foundation of tools towards personalized cancer treatment. We will apply these methods for discovery in some of the most aggressive cancers that currently lack good therapeutic solutions including glioblastoma, ovarian cancer and melanoma.            ","Integrative Cancer Genomics: Drivers, Pathways and Drugs",8371751,R01CA164729,"['AKT inhibition', 'Algorithms', 'Antineoplastic Agents', 'Automobile Driving', 'Biological Assay', 'Breast Cancer Cell', 'Cancer cell line', 'Candidate Disease Gene', 'Cell physiology', 'Cells', 'Collaborations', 'Colon Carcinoma', 'Computer Simulation', 'Computing Methodologies', 'DNA copy number', 'Data', 'Diagnostic', 'Drug resistance', 'Feedback', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Gleevec', 'Glioblastoma', 'Grant', 'Growth', 'Heterogeneity', 'Individual', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Measures', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Oncogenes', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Proteins', 'Proto-Oncogene Proteins c-akt', 'Publishing', 'RNA Interference', 'Resistance', 'Roche brand of trastuzumab', 'Role', 'Solutions', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Validation', 'Work', 'arm', 'base', 'cancer cell', 'cancer genome', 'cancer genomics', 'cancer therapy', 'computerized tools', 'follow-up', 'human FRAP1 protein', 'improved', 'malignant breast neoplasm', 'melanoma', 'novel', 'response', 'success', 'tool', 'tumor', 'tumor progression', 'tumorigenesis', 'tumorigenic']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2012,399632,0.000725178324699059
"Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci    DESCRIPTION (provided by applicant): Colorectal carcinoma (CRC) arises from multiple mutations and genomic aberrations in distinct driver cancer genes that that in concert to spur neoplastic development and phenotype. This inherent genetic complexity greatly complicates both personalized diagnosis and treatment. Previously published studies have confined that large numbers of genes will be mutated or subject to genomic aberrations in CRC. A significant and emerging challenge for the post-genomic era is to identify which of these mutated genes are ""driver"" loci that functionally drive colon cancer development, versus ""passenger"" loci without functional relevance. Finally, it is of the highest priority that one forges these genetic observations with correlations of prognosis and clinical outcome. This can only be done if we better understand the unified biological ramifications of the combined and diverse multigenic driver background which act synergistically to promote CRC tumorigenesis. This proposal details an integrated analysis that will rely on the CRC genomic data generated by the Cancer Genome Atlas Project (TCGA) to discover novel candidate CRC genes and study multigenic CRC driver gene co-mutated / dysregulated modules within the genetic context of other drivers and provide biological validation in a powerful in vitro primary culture CRC model which can be engineered for multiple genetic events.  To accomplish these goals, we will develop and implement novel statistical methodologies for the integrative analysis of multiple TCGA genomic and clinical data sets. The goal is to identify and prioritize novel CRC genes either singly or as co-mutated modules in combination with other known ""driver"" CRC genes. We will use the rich TCGA data set to conduct an integrated CRC genomic analysis of point mutations, gene expression, copy number aberrations and methylation data. We will prioritize the discovery of mutations and other genomic aberrations of these novel CRC genes that are associated with specific clinical stages of disease and other clinical parameters.  These statistical and computational studies will then be directly coupled to rapid and robust functional target validation of candidate loci using our rigorously characterized in vitro primary intestinal culture methodology (Gotani et al, Nature Medicine, 2009), in which we have recently established the transforming activity of established CRC loci such as APC, KRAS and TP53. Genetic deletion and retroviral expression of shRNA, cDNA or mutants thereof will be utilized to evaluate putative individual driver loci, as well as combinatorial oncogene modules. This proposal directly addresses fundamental problems in the exploration and translation of novel colorectal cancer gene discovery in the context of clinical data which is available from TCGA. RELEVANCE (See instructions): Colorectal cancer (CRC) represents the third most commonly diagnosed cancer in the United States. This proposal utilizes a fusion of genomic analysis of a large population of patients, mathematical modeling and culture of intestinal fragments to functionally identify genes that are critical for colon cancer development. These studies have implications for generation of novel diagnostic and therapeutic strategies for colon cancer.           n/a",Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci,8329613,U01CA151920,"['Address', 'Algorithms', 'Atlases', 'Bayesian Analysis', 'Biological', 'Biology', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Colorectal Cancer', 'Complementary DNA', 'Copy Number Polymorphism', 'Coupled', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Engineering', 'Evaluation', 'Event', 'Future', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'In Vitro', 'Individual', 'Instruction', 'Intestines', 'KRAS2 gene', 'Large Intestine Carcinoma', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Oncogenes', 'Oncologist', 'Outcome', 'Phenotype', 'Point Mutation', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Somatic Mutation', 'Staging', 'Statistical Study', 'Surveys', 'Systems Biology', 'TP53 gene', 'Technology', 'The Cancer Genome Atlas', 'Translations', 'United States', 'Validation', 'Variant', 'authority', 'cancer diagnosis', 'cancer genome', 'cancer genomics', 'candidate validation', 'clinical phenotype', 'combinatorial', 'computer studies', 'design', 'exome', 'experience', 'forging', 'gene discovery', 'intestinal epithelium', 'mathematical model', 'mutant', 'neoplastic', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'outcome forecast', 'patient population', 'segregation', 'small hairpin RNA', 'statistics', 'tumorigenesis']",NCI,STANFORD UNIVERSITY,U01,2012,541494,0.027352194914964566
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.        PUBLIC HEALTH RELEVANCE: Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.              Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8373752,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,654177,0.020721516232360383
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8107695,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2011,108418,0.054291423690877
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,8134360,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait', 'treatment strategy']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2011,342569,0.007458825247780459
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC)    DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies.              n/a",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8117695,U24CA143858,"['Animals', 'Biological', 'Cancer Biology', 'Categories', 'Cell Line', 'Clinical Data', 'Clinical Trials', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Targeting', 'Genes', 'Genome', 'Genomics', 'Glean', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genomics', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'insight', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2011,1312129,0.057238664291879474
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8035949,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,321670,0.011565450000378712
"Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci    DESCRIPTION (provided by applicant): Colorectal carcinoma (CRC) arises from multiple mutations and genomic aberrations in distinct driver cancer genes that that in concert to spur neoplastic development and phenotype. This inherent genetic complexity greatly complicates both personalized diagnosis and treatment. Previously published studies have confined that large numbers of genes will be mutated or subject to genomic aberrations in CRC. A significant and emerging challenge for the post-genomic era is to identify which of these mutated genes are ""driver"" loci that functionally drive colon cancer development, versus ""passenger"" loci without functional relevance. Finally, it is of the highest priority that one forges these genetic observations with correlations of prognosis and clinical outcome. This can only be done if we better understand the unified biological ramifications of the combined and diverse multigenic driver background which act synergistically to promote CRC tumorigenesis. This proposal details an integrated analysis that will rely on the CRC genomic data generated by the Cancer Genome Atlas Project (TCGA) to discover novel candidate CRC genes and study multigenic CRC driver gene co-mutated / dysregulated modules within the genetic context of other drivers and provide biological validation in a powerful in vitro primary culture CRC model which can be engineered for multiple genetic events.  To accomplish these goals, we will develop and implement novel statistical methodologies for the integrative analysis of multiple TCGA genomic and clinical data sets. The goal is to identify and prioritize novel CRC genes either singly or as co-mutated modules in combination with other known ""driver"" CRC genes. We will use the rich TCGA data set to conduct an integrated CRC genomic analysis of point mutations, gene expression, copy number aberrations and methylation data. We will prioritize the discovery of mutations and other genomic aberrations of these novel CRC genes that are associated with specific clinical stages of disease and other clinical parameters.  These statistical and computational studies will then be directly coupled to rapid and robust functional target validation of candidate loci using our rigorously characterized in vitro primary intestinal culture methodology (Gotani et al, Nature Medicine, 2009), in which we have recently established the transforming activity of established CRC loci such as APC, KRAS and TP53. Genetic deletion and retroviral expression of shRNA, cDNA or mutants thereof will be utilized to evaluate putative individual driver loci, as well as combinatorial oncogene modules. This proposal directly addresses fundamental problems in the exploration and translation of novel colorectal cancer gene discovery in the context of clinical data which is available from TCGA. RELEVANCE (See instructions): Colorectal cancer (CRC) represents the third most commonly diagnosed cancer in the United States. This proposal utilizes a fusion of genomic analysis of a large population of patients, mathematical modeling and culture of intestinal fragments to functionally identify genes that are critical for colon cancer development. These studies have implications for generation of novel diagnostic and therapeutic strategies for colon cancer.           n/a",Integrated Genomic Discovery and Functional Validation of Colorectal Cancer Loci,8178935,U01CA151920,"['Address', 'Algorithms', 'Atlases', 'Bayesian Analysis', 'Biological', 'Biology', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Colorectal Cancer', 'Complementary DNA', 'Copy Number Polymorphism', 'Coupled', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Engineering', 'Evaluation', 'Event', 'Future', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'In Vitro', 'Individual', 'Instruction', 'Intestines', 'KRAS2 gene', 'Large Intestine Carcinoma', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Oncogenes', 'Oncologist', 'Outcome', 'Phenotype', 'Point Mutation', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Somatic Mutation', 'Staging', 'Statistical Study', 'Surveys', 'Systems Biology', 'TP53 gene', 'Technology', 'The Cancer Genome Atlas', 'Translations', 'United States', 'Validation', 'Variant', 'authority', 'cancer diagnosis', 'cancer genome', 'cancer genomics', 'candidate validation', 'clinical phenotype', 'combinatorial', 'computer studies', 'design', 'exome', 'experience', 'forging', 'gene discovery', 'intestinal epithelium', 'mathematical model', 'mutant', 'neoplastic', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'outcome forecast', 'patient population', 'segregation', 'small hairpin RNA', 'statistics', 'tumorigenesis']",NCI,STANFORD UNIVERSITY,U01,2011,537462,0.027352194914964566
"Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform    DESCRIPTION (provided by applicant): DNAnexus proposes to develop a complete solution for the identification and stratification of personal genetic variation from ultra-high-throughput sequencing projects. The solution will be implemented as a Web 2.0 service and online browsing tool that will integrate public data sources such as the 1000 genomes project, comparative information, and the ENCODE II project data. Users will be able to browse and stratify the identified variation in the context of these genomic annotations, and according to the likely functional impact. In Phase I of our project, we will develop a basic browser for displaying sequence reads that are mapped to a reference genome with our state-of-the-art read mapper. The browser will support viewing mate paired reads as well as display of the variation between these reads and the reference genome. It will facilitate the algorithmic development that we will perform during Phase II, and it will be the foundation for the more sophisticated variation browser also proposed in Phase II. In Phase II, we will develop algorithms for detecting genomic variation, and a state-of-the-art browser for viewing variation in the context of existing genome annotations, functional genomic and comparative genomic data. Our algorithms for detecting variation will support all major types of genomic variation, including SNPs, microindels, larger insertions and deletions, duplications, copy number variations, inversions, and translocations. Our algorithms will be based on state-of-the-art statistical and machine learning methodology for human genome resequencing. The DNAnexus browser will have two components: a list browser that displays variation as a list filtered and stratified by criteria that a user chooses, and a powerful GUI whose navigation capabilities are inspired by modern online tools such as Google Maps.      PUBLIC HEALTH RELEVANCE: DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.           Project Narrative DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.",Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform,7909096,R43HG005794,"['Algorithms', 'Architecture', 'Arts', 'Code', 'Copy Number Polymorphism', 'DNA Resequencing', 'Data', 'Data Display', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Environment', 'Foundations', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Human Genome', 'Imagery', 'Individual', 'Internet', 'Machine Learning', 'Maps', 'Methodology', 'Partner in relationship', 'Phase', 'Point Mutation', 'Reading', 'Services', 'Solutions', 'Statistical Methods', 'Stratification', 'Technology', 'Variant', 'base', 'comparative', 'comparative genomics', 'cost', 'flexibility', 'functional genomics', 'genome sequencing', 'graphical user interface', 'insertion/deletion mutation', 'public health relevance', 'tool']",NHGRI,"DNANEXUS, INC.",R43,2010,74477,-0.004928243141310387
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7882364,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2010,199526,0.021387440116429943
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7913074,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,1248287,0.054291423690877
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8121894,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,300000,0.054291423690877
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8144973,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,113520,0.054291423690877
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8147585,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,151816,0.054291423690877
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7902231,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2010,346884,0.007458825247780459
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC)    DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies.              n/a",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),7942768,U24CA143858,"['Animals', 'Atlases', 'Biological', 'Cancer Biology', 'Categories', 'Cell Line', 'Clinical Data', 'Clinical Trials', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Targeting', 'Genes', 'Genome', 'Genomics', 'Glean', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'insight', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2010,1084905,0.057238664291879474
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC)    DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies.              n/a",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),8142561,U24CA143858,"['Animals', 'Atlases', 'Biological', 'Cancer Biology', 'Categories', 'Cell Line', 'Clinical Data', 'Clinical Trials', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Targeting', 'Genes', 'Genome', 'Genomics', 'Glean', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'insight', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2010,829118,0.057238664291879474
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7795846,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,326175,0.011565450000378712
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7661365,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2009,199526,0.021387440116429943
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7622614,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2009,1224323,0.054291423690877
"Cancer Genome Characterization Center at Johns Hopkins    DESCRIPTION (provided by applicant):  This proposal describes a detailed plan for a Cancer Genome Characterization Center (CGCC) to act as part of The Cancer Genome Atlas (TCGA) project. This CGCC will contribute two platforms to accurately analyze over 1,000 cancer genomes per year using two of the most efficient and informative technologies currently available. In Specific Aim 1 we propose the first platform, a whole genome analysis of copy number changes using Illumina BeadArray(tm) technology. The Illumina 550,000 SNP BeadChip will be used to create high- resolution copy number maps of whole cancer genomes. Our side-by- side comparison of the current 300,000 SNP BeadChip to Digital Karyotyping shows that it provides higher resolution at a dramatically lower cost. Our data show that this technology can be used to accurately detect deletions and amplifications, powerful indicators of genes of interest. Specific Aim 2 will characterize the CpG island hypermethylome in human cancer. Leading experts in the field of cancer epigenetics have a proven approach to define the set of possible genes that have expression silencing as a result of hypermethylation. This assay will again use the Illumina technology for high-throughput and accurate assay of functionally selected 5' CpG islands across the genome, as well as all CpG islands located on chromosomes 21 and 22, and a random selection of non- CpG island CpG sites located on these two chromosomes. In addition to DNA mutations and structural changes, DNA methylation is a significant cause of abnormal gene silencing linked to the development of cancer. In the informatics and data verification proposed in Specific Aim 3 we have developed an integrated approach to organized transmission of raw and verified data to the NCICB Data Coordinating Center using CaBIG-compliant data feeds. We will also make available data analysis tools developed as part of this project. These include means to integrate diverse genomic data from normal and cancer genomes, user- friendly visualization tools, web portals for data sharing, and use machine learning to derive systems biology correlates among available TCGA data, all designed for CaBIG silver or better compliance. Upon successful completion of these aims, we will have a rapid and efficient means to assay tens of thousands of cancer genomes, and rapidly produce biologically meaningful data on copy number changes and hypermethylation. This project has direct relevance to public health. Precise knowledge of the type and frequency of the major cancer causing alterations will allow the best molecular targets to be selected for new therapy development.             n/a",Cancer Genome Characterization Center at Johns Hopkins,7910931,U24CA126561,"['Atlases', 'Biological Assay', 'Cancer Etiology', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'CpG Islands', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Development', 'Epigenetic Process', 'Feeds', 'Frequencies', 'Gene Mutation', 'Gene Silencing', 'Genes', 'Genome', 'Genomics', 'Human', 'Hypermethylation', 'Imagery', 'Informatics', 'Internet', 'Karyotype determination procedure', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Molecular Target', 'Public Health', 'Random Allocation', 'Resolution', 'Side', 'Silver', 'Site', 'Systems Biology', 'Technology', 'cancer genome', 'cost', 'data portal', 'data sharing', 'design', 'digital', 'high throughput technology', 'interest', 'therapy development', 'tool', 'transmission process', 'user-friendly']",NCI,JOHNS HOPKINS UNIVERSITY,U24,2009,523967,0.028628966172574277
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7681225,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2009,351164,0.007458825247780459
"Visualization and Analysis of the TCGA Data Using the UCSC Cancer Genomics Browse    DESCRIPTION (provided by applicant):    The Cancer Genome Atlas (TCGA) project aims to determine the feasibility of identifying and cataloging the genomic-level alterations associated with human cancers, including alterations in DNA copy number and transcript levels, epigenetic modifications, cancer somatic mutations, and inherited genetic variance that contribute to cancer susceptibility. As experimental techniques for a comprehensive survey of the cancer landscape mature, there is a great demand in the cancer research field to develop advanced analysis and visualization tools for the characterization and integrative analysis of the large, complex genomic datasets arising from different technology platforms.    The proposed UCSC Cancer Genomics Browser is a suite of web-based tools designed to integrate, visualize and analyze genomic and clinical data generated by the TCGA project. The browser, which will be available at https://cancer.cse.ucsc.edu/, currently consists of three major components: hgHeatmap, hgFeatureSorter and hgPathSorter. The main panel, hgHeatmap, displays a whole-genome-oriented view of genome-wide experimental measurements for individual and sets of samples/patients along with their clinical information. hgFeatureSorter and hgPathSorter together enable investigators to order, filter, aggregate and display data interactively based on any given feature set ranging from clinical features to annotated biological pathways to user-edited collections of genes. Standard and advanced statistical tools will be installed on the server's side through a caBIG-compatible mechanism to provide quantitative analysis of the whole genomic data or any of its subsets. The UCSC Cancer Genomics Browser is an extension of the UCSC Genome Browser; thus it inherits and integrates the Genome Browser's existing rich set of human biology and genetics data to enhance the interpretability of the cancer genomic data. A pathway- centric, multi-layer machine learning algorithm, BioIntegrator, will be built on top of the UCSC Cancer Genomics Browser for the integration of cancer genomics and clinical data to assess the levels of perturbation of biological pathways in cancers and during the course of therapy, and to predict clinical outcomes.    Collectively, these proposed tools will facilitate a synergistic interaction among clinicians, experimental biologists and bioinformaticians. They will enable cancer researchers to better explore the breadth and depth of the TCGA cancer genomics data resources, and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools may advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, as well as the development of therapeutic and prevention strategies.           n/a",Visualization and Analysis of the TCGA Data Using the UCSC Cancer Genomics Browse,7692314,R21CA135937,"['Algorithms', 'Atlases', 'Biological', 'Cancer Biology', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Collection', 'Complex', 'DNA copy number', 'Data', 'Data Analyses', 'Data Display', 'Data Set', 'Databases', 'Decision Making', 'Diagnostic', 'Epigenetic Process', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Inherited', 'Intention', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Metadata', 'Modification', 'Molecular', 'Online Systems', 'Outcome', 'Output', 'Pathway interactions', 'Patients', 'Plug-in', 'Predisposition', 'Prevention strategy', 'Process', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Secure', 'Side', 'Site', 'Somatic Mutation', 'Sorting - Cell Movement', 'Surveys', 'System', 'Techniques', 'Technology', 'Transcript', 'Work', 'anticancer research', 'base', 'cancer Biomedical Informatics Grid', 'cancer genome', 'cancer genomics', 'design', 'genome-wide', 'insight', 'malignant breast neoplasm', 'prognostic', 'therapeutic development', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2009,180460,0.02255619612952324
"UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC)    DESCRIPTION (provided by applicant): The Cancer Genome Atlas (TCGA) project holds promise for a comprehensive understanding of human cancer through the application of genomic technologies. However, current cancer genomic analytical and visualization technologies still have many limitations that will likely prevent investigators from taking full advantage of this resource. The proposed UCSC-Buck Institute Genome Data Analysis Center will support an integrative analysis of TCGA data for all surveyed cancer types throughout the project. The major components of the pipeline are a pathway-centric multi-layer machine learning tool called Biolntegrator, a genome rearrangement detector for next-gen sequencing data, and the tightly coupled UCSC browser tool suite. We aim to detect cancer-associated molecular alterations and the biological pathways that are perturbed by them in tumor samples. Samples will then be classified into clinically relevant categories based on pathway perturbations rather than perturbations of individual genes, which we believe will be more robust, biologically meaningful and clinically accurate. Using Biolntegrator and the associated tools, we will further integrate TCGA data with datasets from external studies, including cell line studies, animal studies and clinical trials, to identify (1) cancer-associated molecular alterations; (2) dysregulated pathways and signatures useful in clinical diagnosis, prognosis, and drug response prediction; and (3) gene targets for the development of novel therapeutics. These results will provide the basis for a refined patient stratification in therapy and will generate new hypotheses for translational research. The tightly coupled UCSC browser suite, which will be enhanced to accommodate the needs of the TCGA project, includes the UCSC Cancer Genomics Browser for visualizing TCGA cancer genomics, clinical data, and analysis results; the UCSC Tumor Browser for displaying tumor genome rearrangements and other tumor mutations; and the UCSC Human Genome Browser for integrating the data with human genome annotations and information gleaned from other projects such as ENCODE and the NIH Epigenomics Roadmap Initiative. The browser resource, hosting this rapidly growing body of cancer genomics data, will enable investigators to perform interactive in-silico experiments to test new hypotheses derived from the TCGA data. Collectively, these proposed tools will enable cancer researchers to better explore the breadth and depth of the TCGA resources and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools will advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, leading to new therapeutic and preventative strategies.              n/a",UCSC-Buck Inst. Genome Data Analysis Center for TCGA Research Network (GDAC),7789014,U24CA143858,"['Animals', 'Atlases', 'Biological', 'Cancer Biology', 'Categories', 'Cell Line', 'Clinical Data', 'Clinical Trials', 'Computer Simulation', 'Coupled', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Gene Targeting', 'Genes', 'Genome', 'Genomics', 'Glean', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Molecular', 'Mutation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Stratification', 'Surveys', 'Technology', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'cancer genome', 'cancer genomics', 'cancer type', 'clinical Diagnosis', 'clinically relevant', 'detector', 'epigenomics', 'insight', 'novel therapeutics', 'outcome forecast', 'prevent', 'prognostic', 'research study', 'response', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2009,1000000,0.057238664291879474
"A Functional Census of p53 Cancer and Suppressor Mutants DESCRIPTION (provided by applicant):  The broad, long-term objectives are (1) demonstrate computational and experimental methods cooperating to achieve a functional census of a large mutation sequence space of great medical importance; (2) contribute to our knowledge of p53 functional rescue mechanisms, and so facilitate the search for a small molecule cancer drug that effects an analogous functional rescue of p53; and (3) elucidate part of the systems biology of cancer by characterizing the spectrum of p53 cancer and suppressor mutants across known downstream p53 DNA binding sites. Mutations to the tumor suppressor protein p53 occur in approximately half of all human cancers, and restoring function to a mutationally defective p53 protein is a long-held medical goal. Biological precedence for rescuing p53 cancer mutations is found in second-site p53 cancer suppressor mutations. The analogous p53 pharmacological rescue would save hundreds of thousands of lives annually. Understanding and predicting p53 rescue is an important step toward that goal.      The specific aims are (1) computationally predict all single suppressor mutations for p53 cancer mutants and validate the results experimentally, (2) optimize the rescue effects of known and putative p53 suppressor regions through two or more coordinated mutation changes, and (3) predict and experimentally validate the DNA binding specificity of p53 cancer and suppressor mutants for known p53 DNA binding sites. Our broad strategy is a coordinated computational and experimental attack. We already have experimental p53 functional assays and computational predictors of p53 activity, developed as part of our Preliminary Studies. Computational predictors will be used to focus experimental work into the highest priority areas. Experimental validation of the predictions will lead to a larger training set for machine learning techniques. The larger training set will lead to even more accurate predictions, thus even more focused experimentation. Thus, the interplay between computation and experiment will become ever more efficient as the project progresses. Variations of this basic strategy apply to each of our Specific Aims, which all rely on closely coordinated experiment and computation. n/a",A Functional Census of p53 Cancer and Suppressor Mutants,7613343,R01CA112560,"['Affect', 'Amino Acids', 'Antineoplastic Agents', 'Apoptosis', 'Area', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cancerous', 'Cataloging', 'Catalogs', 'Cell Cycle Arrest', 'Cells', 'Censuses', 'Consensus', 'DNA Binding', 'Data Sources', 'Engineering', 'Gene Targeting', 'Genomics', 'Goals', 'Human', 'Knowledge', 'Lead', 'Letters', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Medical', 'Methodology', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular Conformation', 'Mutation', 'Positioning Attribute', 'Proliferating', 'Protein p53', 'Research Personnel', 'Signal Transduction', 'Site', 'Source Code', 'Specificity', 'Stress', 'Suppressor Mutations', 'Surveys', 'Systems Biology', 'TP53 gene', 'Techniques', 'Training', 'Tumor Suppressor Proteins', 'Validation', 'Variant', 'Work', 'Yeasts', 'base', 'cancer therapy', 'computerized tools', 'design', 'functional restoration', 'interest', 'killings', 'mutant', 'programs', 'repaired', 'research study', 'small molecule', 'transcription factor', 'tumor', 'web site']",NCI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2009,342292,0.017607353613001888
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7635337,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2009,330660,0.011565450000378712
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7477758,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'response', 'tool', 'transcription factor']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2008,363604,0.021387440116429943
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7499147,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Depth', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Numbers', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'foot', 'insight', 'member', 'novel', 'quality assurance', 'scale up', 'size', 'symposium', 'theories', 'tool']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2008,1200000,0.054291423690877
"Cancer Genome Characterization Center at Johns Hopkins    DESCRIPTION (provided by applicant):  This proposal describes a detailed plan for a Cancer Genome Characterization Center (CGCC) to act as part of The Cancer Genome Atlas (TCGA) project. This CGCC will contribute two platforms to accurately analyze over 1,000 cancer genomes per year using two of the most efficient and informative technologies currently available. In Specific Aim 1 we propose the first platform, a whole genome analysis of copy number changes using Illumina BeadArray(tm) technology. The Illumina 550,000 SNP BeadChip will be used to create high- resolution copy number maps of whole cancer genomes. Our side-by- side comparison of the current 300,000 SNP BeadChip to Digital Karyotyping shows that it provides higher resolution at a dramatically lower cost. Our data show that this technology can be used to accurately detect deletions and amplifications, powerful indicators of genes of interest. Specific Aim 2 will characterize the CpG island hypermethylome in human cancer. Leading experts in the field of cancer epigenetics have a proven approach to define the set of possible genes that have expression silencing as a result of hypermethylation. This assay will again use the Illumina technology for high-throughput and accurate assay of functionally selected 5' CpG islands across the genome, as well as all CpG islands located on chromosomes 21 and 22, and a random selection of non- CpG island CpG sites located on these two chromosomes. In addition to DNA mutations and structural changes, DNA methylation is a significant cause of abnormal gene silencing linked to the development of cancer. In the informatics and data verification proposed in Specific Aim 3 we have developed an integrated approach to organized transmission of raw and verified data to the NCICB Data Coordinating Center using CaBIG-compliant data feeds. We will also make available data analysis tools developed as part of this project. These include means to integrate diverse genomic data from normal and cancer genomes, user- friendly visualization tools, web portals for data sharing, and use machine learning to derive systems biology correlates among available TCGA data, all designed for CaBIG silver or better compliance. Upon successful completion of these aims, we will have a rapid and efficient means to assay tens of thousands of cancer genomes, and rapidly produce biologically meaningful data on copy number changes and hypermethylation. This project has direct relevance to public health. Precise knowledge of the type and frequency of the major cancer causing alterations will allow the best molecular targets to be selected for new therapy development.             n/a",Cancer Genome Characterization Center at Johns Hopkins,7499105,U24CA126561,"['Atlases', 'Biological Assay', 'Cancer Etiology', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'CpG Islands', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Development', 'Epigenetic Process', 'Feeds', 'Frequencies', 'Gene Mutation', 'Gene Silencing', 'Genes', 'Genome', 'Genomics', 'Human', 'Hypermethylation', 'Imagery', 'Informatics', 'Internet', 'Karyotype determination procedure', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Molecular Target', 'Numbers', 'Public Health', 'Random Allocation', 'Resolution', 'Side', 'Silver', 'Site', 'Systems Biology', 'Technology', 'cancer genome', 'cost', 'design', 'digital', 'high throughput technology', 'interest', 'therapy development', 'tool', 'transmission process', 'user-friendly']",NCI,JOHNS HOPKINS UNIVERSITY,U24,2008,773823,0.028628966172574277
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7522602,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Class', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pan troglodytes', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Rate', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2008,369424,0.007458825247780459
"Visualization and Analysis of the TCGA Data Using the UCSC Cancer Genomics Browse    DESCRIPTION (provided by applicant):    The Cancer Genome Atlas (TCGA) project aims to determine the feasibility of identifying and cataloging the genomic-level alterations associated with human cancers, including alterations in DNA copy number and transcript levels, epigenetic modifications, cancer somatic mutations, and inherited genetic variance that contribute to cancer susceptibility. As experimental techniques for a comprehensive survey of the cancer landscape mature, there is a great demand in the cancer research field to develop advanced analysis and visualization tools for the characterization and integrative analysis of the large, complex genomic datasets arising from different technology platforms.    The proposed UCSC Cancer Genomics Browser is a suite of web-based tools designed to integrate, visualize and analyze genomic and clinical data generated by the TCGA project. The browser, which will be available at https://cancer.cse.ucsc.edu/, currently consists of three major components: hgHeatmap, hgFeatureSorter and hgPathSorter. The main panel, hgHeatmap, displays a whole-genome-oriented view of genome-wide experimental measurements for individual and sets of samples/patients along with their clinical information. hgFeatureSorter and hgPathSorter together enable investigators to order, filter, aggregate and display data interactively based on any given feature set ranging from clinical features to annotated biological pathways to user-edited collections of genes. Standard and advanced statistical tools will be installed on the server's side through a caBIG-compatible mechanism to provide quantitative analysis of the whole genomic data or any of its subsets. The UCSC Cancer Genomics Browser is an extension of the UCSC Genome Browser; thus it inherits and integrates the Genome Browser's existing rich set of human biology and genetics data to enhance the interpretability of the cancer genomic data. A pathway- centric, multi-layer machine learning algorithm, BioIntegrator, will be built on top of the UCSC Cancer Genomics Browser for the integration of cancer genomics and clinical data to assess the levels of perturbation of biological pathways in cancers and during the course of therapy, and to predict clinical outcomes.    Collectively, these proposed tools will facilitate a synergistic interaction among clinicians, experimental biologists and bioinformaticians. They will enable cancer researchers to better explore the breadth and depth of the TCGA cancer genomics data resources, and to further characterize molecular pathways that influence cellular dynamics and stability in cancer. Ultimately, insights gained by applying these tools may advance our knowledge of human cancer biology and stimulate the discovery of new prognostic and diagnostic markers, as well as the development of therapeutic and prevention strategies.           n/a",Visualization and Analysis of the TCGA Data Using the UCSC Cancer Genomics Browse,7539926,R21CA135937,"['Algorithms', 'Atlases', 'Biological', 'Cancer Biology', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Collection', 'Compatible', 'Complex', 'DNA copy number', 'Data', 'Data Analyses', 'Data Display', 'Data Set', 'Databases', 'Decision Making', 'Depth', 'Development', 'Diagnostic', 'Epigenetic Process', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Inherited', 'Intention', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Metadata', 'Modification', 'Molecular', 'Online Systems', 'Outcome', 'Output', 'Pathway interactions', 'Patients', 'Plug-in', 'Predisposition', 'Prevention strategy', 'Process', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Secure', 'Side', 'Site', 'Somatic Mutation', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'Surveys', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Transcript', 'Work', 'anticancer research', 'base', 'cancer Biomedical Informatics Grid', 'cancer genome', 'cancer genomics', 'design', 'insight', 'malignant breast neoplasm', 'prognostic', 'tool', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2008,215094,0.02255619612952324
"A Functional Census of p53 Cancer and Suppressor Mutants DESCRIPTION (provided by applicant):  The broad, long-term objectives are (1) demonstrate computational and experimental methods cooperating to achieve a functional census of a large mutation sequence space of great medical importance; (2) contribute to our knowledge of p53 functional rescue mechanisms, and so facilitate the search for a small molecule cancer drug that effects an analogous functional rescue of p53; and (3) elucidate part of the systems biology of cancer by characterizing the spectrum of p53 cancer and suppressor mutants across known downstream p53 DNA binding sites. Mutations to the tumor suppressor protein p53 occur in approximately half of all human cancers, and restoring function to a mutationally defective p53 protein is a long-held medical goal. Biological precedence for rescuing p53 cancer mutations is found in second-site p53 cancer suppressor mutations. The analogous p53 pharmacological rescue would save hundreds of thousands of lives annually. Understanding and predicting p53 rescue is an important step toward that goal.      The specific aims are (1) computationally predict all single suppressor mutations for p53 cancer mutants and validate the results experimentally, (2) optimize the rescue effects of known and putative p53 suppressor regions through two or more coordinated mutation changes, and (3) predict and experimentally validate the DNA binding specificity of p53 cancer and suppressor mutants for known p53 DNA binding sites. Our broad strategy is a coordinated computational and experimental attack. We already have experimental p53 functional assays and computational predictors of p53 activity, developed as part of our Preliminary Studies. Computational predictors will be used to focus experimental work into the highest priority areas. Experimental validation of the predictions will lead to a larger training set for machine learning techniques. The larger training set will lead to even more accurate predictions, thus even more focused experimentation. Thus, the interplay between computation and experiment will become ever more efficient as the project progresses. Variations of this basic strategy apply to each of our Specific Aims, which all rely on closely coordinated experiment and computation. n/a",A Functional Census of p53 Cancer and Suppressor Mutants,7426313,R01CA112560,"['Affect', 'Amino Acids', 'Antineoplastic Agents', 'Apoptosis', 'Area', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cancerous', 'Cataloging', 'Catalogs', 'Cell Cycle Arrest', 'Cells', 'Censuses', 'Consensus', 'DNA Binding', 'Data', 'Engineering', 'Gene Targeting', 'Genomics', 'Goals', 'Human', 'Knowledge', 'Lead', 'Letters', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Medical', 'Methodology', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular Conformation', 'Mutation', 'Numbers', 'Positioning Attribute', 'Proliferating', 'Protein p53', 'Research Personnel', 'Signal Transduction', 'Site', 'Source Code', 'Specificity', 'Stress', 'Suppressor Mutations', 'Surveys', 'Systems Biology', 'TP53 gene', 'Techniques', 'Training', 'Tumor Suppressor Proteins', 'Validation', 'Variant', 'Work', 'Yeasts', 'base', 'cancer therapy', 'computerized tools', 'design', 'functional restoration', 'interest', 'killings', 'mutant', 'programs', 'repaired', 'research study', 'small molecule', 'transcription factor', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2008,335397,0.017607353613001888
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7291530,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'response', 'tool', 'transcription factor']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,439085,0.021387440116429943
"Cancer Genome Characterization Center at Johns Hopkins    DESCRIPTION (provided by applicant):  This proposal describes a detailed plan for a Cancer Genome Characterization Center (CGCC) to act as part of The Cancer Genome Atlas (TCGA) project. This CGCC will contribute two platforms to accurately analyze over 1,000 cancer genomes per year using two of the most efficient and informative technologies currently available. In Specific Aim 1 we propose the first platform, a whole genome analysis of copy number changes using Illumina BeadArray(tm) technology. The Illumina 550,000 SNP BeadChip will be used to create high- resolution copy number maps of whole cancer genomes. Our side-by- side comparison of the current 300,000 SNP BeadChip to Digital Karyotyping shows that it provides higher resolution at a dramatically lower cost. Our data show that this technology can be used to accurately detect deletions and amplifications, powerful indicators of genes of interest. Specific Aim 2 will characterize the CpG island hypermethylome in human cancer. Leading experts in the field of cancer epigenetics have a proven approach to define the set of possible genes that have expression silencing as a result of hypermethylation. This assay will again use the Illumina technology for high-throughput and accurate assay of functionally selected 5' CpG islands across the genome, as well as all CpG islands located on chromosomes 21 and 22, and a random selection of non- CpG island CpG sites located on these two chromosomes. In addition to DNA mutations and structural changes, DNA methylation is a significant cause of abnormal gene silencing linked to the development of cancer. In the informatics and data verification proposed in Specific Aim 3 we have developed an integrated approach to organized transmission of raw and verified data to the NCICB Data Coordinating Center using CaBIG-compliant data feeds. We will also make available data analysis tools developed as part of this project. These include means to integrate diverse genomic data from normal and cancer genomes, user- friendly visualization tools, web portals for data sharing, and use machine learning to derive systems biology correlates among available TCGA data, all designed for CaBIG silver or better compliance. Upon successful completion of these aims, we will have a rapid and efficient means to assay tens of thousands of cancer genomes, and rapidly produce biologically meaningful data on copy number changes and hypermethylation. This project has direct relevance to public health. Precise knowledge of the type and frequency of the major cancer causing alterations will allow the best molecular targets to be selected for new therapy development.             n/a",Cancer Genome Characterization Center at Johns Hopkins,7294347,U24CA126561,"['Atlases', 'Biological Assay', 'Cancer Etiology', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'CpG Islands', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Development', 'Epigenetic Process', 'Feeds', 'Frequencies', 'Gene Mutation', 'Gene Silencing', 'Genes', 'Genome', 'Genomics', 'Human', 'Hypermethylation', 'Imagery', 'Informatics', 'Internet', 'Karyotype determination procedure', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Molecular Target', 'Numbers', 'Public Health', 'Random Allocation', 'Resolution', 'Side', 'Silver', 'Site', 'Systems Biology', 'Technology', 'cancer genome', 'cost', 'design', 'digital', 'high throughput technology', 'interest', 'therapy development', 'tool', 'transmission process', 'user-friendly']",NCI,JOHNS HOPKINS UNIVERSITY,U24,2007,766160,0.028628966172574277
"A Functional Census of p53 Cancer and Suppressor Mutants DESCRIPTION (provided by applicant):  The broad, long-term objectives are (1) demonstrate computational and experimental methods cooperating to achieve a functional census of a large mutation sequence space of great medical importance; (2) contribute to our knowledge of p53 functional rescue mechanisms, and so facilitate the search for a small molecule cancer drug that effects an analogous functional rescue of p53; and (3) elucidate part of the systems biology of cancer by characterizing the spectrum of p53 cancer and suppressor mutants across known downstream p53 DNA binding sites. Mutations to the tumor suppressor protein p53 occur in approximately half of all human cancers, and restoring function to a mutationally defective p53 protein is a long-held medical goal. Biological precedence for rescuing p53 cancer mutations is found in second-site p53 cancer suppressor mutations. The analogous p53 pharmacological rescue would save hundreds of thousands of lives annually. Understanding and predicting p53 rescue is an important step toward that goal.      The specific aims are (1) computationally predict all single suppressor mutations for p53 cancer mutants and validate the results experimentally, (2) optimize the rescue effects of known and putative p53 suppressor regions through two or more coordinated mutation changes, and (3) predict and experimentally validate the DNA binding specificity of p53 cancer and suppressor mutants for known p53 DNA binding sites. Our broad strategy is a coordinated computational and experimental attack. We already have experimental p53 functional assays and computational predictors of p53 activity, developed as part of our Preliminary Studies. Computational predictors will be used to focus experimental work into the highest priority areas. Experimental validation of the predictions will lead to a larger training set for machine learning techniques. The larger training set will lead to even more accurate predictions, thus even more focused experimentation. Thus, the interplay between computation and experiment will become ever more efficient as the project progresses. Variations of this basic strategy apply to each of our Specific Aims, which all rely on closely coordinated experiment and computation. n/a",A Functional Census of p53 Cancer and Suppressor Mutants,7253241,R01CA112560,"['Affect', 'Amino Acids', 'Antineoplastic Agents', 'Apoptosis', 'Area', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cancerous', 'Cataloging', 'Catalogs', 'Cell Cycle Arrest', 'Cells', 'Censuses', 'Consensus', 'DNA Binding', 'Data', 'Engineering', 'Gene Targeting', 'Genomics', 'Goals', 'Human', 'Knowledge', 'Lead', 'Letters', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Medical', 'Methodology', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular Conformation', 'Mutation', 'Numbers', 'Positioning Attribute', 'Proliferating', 'Protein p53', 'Research Personnel', 'Signal Transduction', 'Site', 'Source Code', 'Specificity', 'Stress', 'Suppressor Mutations', 'Surveys', 'Systems Biology', 'TP53 gene', 'Techniques', 'Training', 'Tumor Suppressor Proteins', 'Validation', 'Variant', 'Work', 'Yeasts', 'base', 'cancer therapy', 'computerized tools', 'design', 'functional restoration', 'interest', 'killings', 'mutant', 'programs', 'repaired', 'research study', 'small molecule', 'transcription factor', 'tumor']",NCI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2007,333814,0.017607353613001888
"Genetical Genomics Analysis Software    DESCRIPTION (provided by applicant): Response to drug treatment is thought dependent upon genotype for many modern therapies. Knowledge of how each genotype responds to a particular therapy is bene?cial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that this information will lead to new drug targets and better therapies that benefit a larger portion of the population. The goal of this proposal is to provide a suite of software tools for genetic and genomic scientists performing gene mapping experiments with genomic data as the response variable. These tools will ideally provide functionality for 1) detecting polymorphic regions of the genome that con- fer transcript expression differences, 2) identify polymorphic regions of the genome that impart expression differences in genes located elsewhere in the genome, and 3) detecting interactions between loci that may correspond to epistatic effects on transcription. Some software already exists to perform each of these tasks as distinct independent solutions. This proposal intends to produce an integrated solution, S+EQTL (S-PLUS for expression quantitative trait loci mapping), that utilizes the power of S-PLUS and both incorporates and extends the functionality of an exist- ing genetics suite. By providing scientists with an integrated set of tools for genomics experiments with a genetic component, more productive time can be spent interpreting the results rather than transforming data into different formats to be processed by multiple software analysis packages. This software should also address one of the most dif?cult aspects of genetical genomics exper- iments, the so called curse of dimensionality. As the genomics community continues gathering knowledge of transcripts in various organisms, the arrays that interrogate transcript abundance only grow larger in the number of transcript species included. In the absence of tools designed for this purpose, the research scientist is left with the option of either focusing on a narrow set of previously known genes or performing a grid-wise search on all genes in the array. The former is not interesting as these genes are likely well studied and may provide little novel insight. The latter is computationally demanding and may not be possible on the new, larger arrays. A recent publication presents a novel solution that may be enhanced to gain both power and scale using Bayesian methodology. Knowledge of how each genotype responds to a particular drug therapy is beneficial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that the development of analytic tools for gene mapping experiments to identify this information will lead to new drug targets and better therapies that benefit a larger portion of the population.          n/a",Genetical Genomics Analysis Software,7216142,R43GM079852,"['Address', 'Air', 'Algorithms', 'Animal Genetics', 'Anus', 'Arizona', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biometry', 'Biotechnology', 'Bovine Spongiform Encephalopathy', 'Cations', 'Cattle', 'Chromosome Mapping', 'Code', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Con-fer', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Development', 'Diagnostic', 'Disease', 'Disease regression', 'Doctor of Philosophy', 'Drug Delivery Systems', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Exons', 'Family suidae', 'Fatty acid glycerol esters', 'Foundations', 'Gene Combinations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Research', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Government', 'Government Agencies', 'Graph', 'Imagery', 'Individual', 'Industry', 'Institution', 'International', 'Investments', 'Iowa', 'Knowledge', 'Lead', 'Left', 'Libraries', 'Literature', 'Liver', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular Genetics', 'Mus', 'Nebraska', 'North Carolina', 'Numbers', 'Obese Mice', 'Obesity', 'Organism', 'Output', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Pharmaceutical Services', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Process', 'Publications', 'Purpose', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Single Nucleotide Polymorphism', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Solutions', 'Standards of Weights and Measures', 'Sus scrofa', 'Techniques', 'Telecommunications', 'Testing', 'Therapeutic', 'Thermogenesis', 'Thinking', 'Time', 'Time Series Analysis', 'Tissues', 'Training', 'Transcript', 'Treatment Protocols', 'United States National Aeronautics and Space Administration', 'United States National Institutes of Health', 'Universities', 'Washington', 'Work', 'animal breeding', 'base', 'design', 'experience', 'expression vector', 'genetic pedigree', 'hazard', 'improved', 'insight', 'interest', 'lecturer', 'novel', 'professor', 'programs', 'prototype', 'research and development', 'research study', 'response', 'skills', 'software development', 'success', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,101707,-2.7162783263653222e-05
"A Functional Census of p53 Cancer and Suppressor Mutants DESCRIPTION (provided by applicant):  The broad, long-term objectives are (1) demonstrate computational and experimental methods cooperating to achieve a functional census of a large mutation sequence space of great medical importance; (2) contribute to our knowledge of p53 functional rescue mechanisms, and so facilitate the search for a small molecule cancer drug that effects an analogous functional rescue of p53; and (3) elucidate part of the systems biology of cancer by characterizing the spectrum of p53 cancer and suppressor mutants across known downstream p53 DNA binding sites. Mutations to the tumor suppressor protein p53 occur in approximately half of all human cancers, and restoring function to a mutationally defective p53 protein is a long-held medical goal. Biological precedence for rescuing p53 cancer mutations is found in second-site p53 cancer suppressor mutations. The analogous p53 pharmacological rescue would save hundreds of thousands of lives annually. Understanding and predicting p53 rescue is an important step toward that goal.      The specific aims are (1) computationally predict all single suppressor mutations for p53 cancer mutants and validate the results experimentally, (2) optimize the rescue effects of known and putative p53 suppressor regions through two or more coordinated mutation changes, and (3) predict and experimentally validate the DNA binding specificity of p53 cancer and suppressor mutants for known p53 DNA binding sites. Our broad strategy is a coordinated computational and experimental attack. We already have experimental p53 functional assays and computational predictors of p53 activity, developed as part of our Preliminary Studies. Computational predictors will be used to focus experimental work into the highest priority areas. Experimental validation of the predictions will lead to a larger training set for machine learning techniques. The larger training set will lead to even more accurate predictions, thus even more focused experimentation. Thus, the interplay between computation and experiment will become ever more efficient as the project progresses. Variations of this basic strategy apply to each of our Specific Aims, which all rely on closely coordinated experiment and computation. n/a",A Functional Census of p53 Cancer and Suppressor Mutants,7103691,R01CA112560,"['DNA binding protein', 'artificial intelligence', 'binding sites', 'computational biology', 'gene induction /repression', 'gene mutation', 'genetic screening', 'genetic transcription', 'mathematical model', 'model design /development', 'molecular biology information system', 'neoplasm /cancer genetics', 'neoplasm /cancer pharmacology', 'p53 gene /protein', 'protein sequence', 'recombinant proteins', 'small molecule', 'tumor suppressor genes', 'yeast two hybrid system']",NCI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2006,356838,0.017607353613001888
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7213111,R01CA116778,"['bioinformatics', 'clinical research', 'genetics', 'neoplasm /cancer']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,274238,0.021387440116429943
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,7120160,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2006,414036,0.012280402004506375
"Cancer Genome Characterization Center at Johns Hopkins    DESCRIPTION (provided by applicant):  This proposal describes a detailed plan for a Cancer Genome Characterization Center (CGCC) to act as part of The Cancer Genome Atlas (TCGA) project. This CGCC will contribute two platforms to accurately analyze over 1,000 cancer genomes per year using two of the most efficient and informative technologies currently available. In Specific Aim 1 we propose the first platform, a whole genome analysis of copy number changes using Illumina BeadArray(tm) technology. The Illumina 550,000 SNP BeadChip will be used to create high- resolution copy number maps of whole cancer genomes. Our side-by- side comparison of the current 300,000 SNP BeadChip to Digital Karyotyping shows that it provides higher resolution at a dramatically lower cost. Our data show that this technology can be used to accurately detect deletions and amplifications, powerful indicators of genes of interest. Specific Aim 2 will characterize the CpG island hypermethylome in human cancer. Leading experts in the field of cancer epigenetics have a proven approach to define the set of possible genes that have expression silencing as a result of hypermethylation. This assay will again use the Illumina technology for high-throughput and accurate assay of functionally selected 5' CpG islands across the genome, as well as all CpG islands located on chromosomes 21 and 22, and a random selection of non- CpG island CpG sites located on these two chromosomes. In addition to DNA mutations and structural changes, DNA methylation is a significant cause of abnormal gene silencing linked to the development of cancer. In the informatics and data verification proposed in Specific Aim 3 we have developed an integrated approach to organized transmission of raw and verified data to the NCICB Data Coordinating Center using CaBIG-compliant data feeds. We will also make available data analysis tools developed as part of this project. These include means to integrate diverse genomic data from normal and cancer genomes, user- friendly visualization tools, web portals for data sharing, and use machine learning to derive systems biology correlates among available TCGA data, all designed for CaBIG silver or better compliance. Upon successful completion of these aims, we will have a rapid and efficient means to assay tens of thousands of cancer genomes, and rapidly produce biologically meaningful data on copy number changes and hypermethylation. This project has direct relevance to public health. Precise knowledge of the type and frequency of the major cancer causing alterations will allow the best molecular targets to be selected for new therapy development.             n/a",Cancer Genome Characterization Center at Johns Hopkins,7233923,U24CA126561,"['CpG islands', 'clinical research', 'genome', 'neoplasm /cancer']",NCI,JOHNS HOPKINS UNIVERSITY,U24,2006,781539,0.028628966172574277
"A Functional Census of p53 Cancer and Suppressor Mutants DESCRIPTION (provided by applicant):  The broad, long-term objectives are (1) demonstrate computational and experimental methods cooperating to achieve a functional census of a large mutation sequence space of great medical importance; (2) contribute to our knowledge of p53 functional rescue mechanisms, and so facilitate the search for a small molecule cancer drug that effects an analogous functional rescue of p53; and (3) elucidate part of the systems biology of cancer by characterizing the spectrum of p53 cancer and suppressor mutants across known downstream p53 DNA binding sites. Mutations to the tumor suppressor protein p53 occur in approximately half of all human cancers, and restoring function to a mutationally defective p53 protein is a long-held medical goal. Biological precedence for rescuing p53 cancer mutations is found in second-site p53 cancer suppressor mutations. The analogous p53 pharmacological rescue would save hundreds of thousands of lives annually. Understanding and predicting p53 rescue is an important step toward that goal.      The specific aims are (1) computationally predict all single suppressor mutations for p53 cancer mutants and validate the results experimentally, (2) optimize the rescue effects of known and putative p53 suppressor regions through two or more coordinated mutation changes, and (3) predict and experimentally validate the DNA binding specificity of p53 cancer and suppressor mutants for known p53 DNA binding sites. Our broad strategy is a coordinated computational and experimental attack. We already have experimental p53 functional assays and computational predictors of p53 activity, developed as part of our Preliminary Studies. Computational predictors will be used to focus experimental work into the highest priority areas. Experimental validation of the predictions will lead to a larger training set for machine learning techniques. The larger training set will lead to even more accurate predictions, thus even more focused experimentation. Thus, the interplay between computation and experiment will become ever more efficient as the project progresses. Variations of this basic strategy apply to each of our Specific Aims, which all rely on closely coordinated experiment and computation. n/a",A Functional Census of p53 Cancer and Suppressor Mutants,6989008,R01CA112560,"['DNA binding protein', 'artificial intelligence', 'binding sites', 'computational biology', 'gene induction /repression', 'gene mutation', 'genetic screening', 'genetic transcription', 'mathematical model', 'model design /development', 'molecular biology information system', 'neoplasm /cancer genetics', 'neoplasm /cancer pharmacology', 'p53 gene /protein', 'protein sequence', 'recombinant proteins', 'small molecule', 'tumor suppressor genes', 'yeast two hybrid system']",NCI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2005,363175,0.017607353613001888
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6952028,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2005,412000,0.012280402004506375
"EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA    DESCRIPTION  (Applicant's  Description):    The  cell  lineages  in neoplastic       tissues are evolving under the twin dynamics of mutation and clonal expansion.       This  is the basis for both its virulence and our difficulties in treating it.       We  hypothesize  that a subset of the mutations observed in the progression to       cancer  confer  beneficial  selective  effects  on  the cell.  Furthermore, we       hypothesize  that  the  interactions  between  these clonal populations in and       around  the neoplastic tissue determine the progression to cancer.  The aim of       this  project  is  to  identify  these  selective  mutations  and to infer the       interactions  between the mutant clones in Barrett's Esophagus that eventually       lead  to  the development of esophageal adenocarcinoma.  This analysis will be       based  on loss of heterozygosity data, promoter methylation, single nucleotide       polymorphisms,  and  gene  expression  data  for homogeneous subpopulations of       cells  sampled  from  neoplastic  tissue in patients with Barrett's Esophagus.       The  tissue  samples  come  from  biopsies of selected patients in the Seattle       Barrett's  Esophagus  Project  (N=285).   Data mining will be used to identify       mutations  that  are associated with clonal expansion as well as inhibition of       neighboring  clones.    The  order  of  genetic  events  in the progression to       esophageal adenocarcinoma will be determined by phylogenetic reconstruction of       the  cell lineages in the neoplastic tissue of each patient.  Machine learning       techniques,  such  as the EM algorithm, will be employed to infer missing data       and the effects of unsampled mutations. Computational modeling will be used to       generate   comparison  data  for  null  hypotheses  as  well  as  to  generate       experimental  predictions from our understanding of the progression to cancer.       This  is  the first step in my long-term career goal to contribute to medicine       through the use of computational and theoretical methods.  Working at the Fred       Hutchinson  Cancer  Research  Center  will  facilitate  the transition from my       background  in  computer  science  and  evolutionary theory, to an independent       research  program  based on the analysis of cellular and molecular dynamics of       cancer.  The challenge of this project is the integration of diverse molecular       and  epidemiological  data  into  a coherent and detailed understanding of the       progression to cancer in the neoplasm of a model system.                                                                                                                                                                                                       n/a",EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA,6886821,K01CA089267,"['Barretts esophagus', 'adenocarcinoma', 'cell cell interaction', 'clinical research', 'gene expression', 'gene mutation', 'human subject', 'loss of heterozygosity', 'mathematical model', 'microarray technology', 'model design /development', 'neoplasm /cancer genetics', 'neoplastic growth', 'neoplastic process', 'telomere']",NCI,WISTAR INSTITUTE,K01,2005,158490,0.016586940193659173
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6737944,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2004,400000,0.012280402004506375
"EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA    DESCRIPTION  (Applicant's  Description):    The  cell  lineages  in neoplastic       tissues are evolving under the twin dynamics of mutation and clonal expansion.       This  is the basis for both its virulence and our difficulties in treating it.       We  hypothesize  that a subset of the mutations observed in the progression to       cancer  confer  beneficial  selective  effects  on  the cell.  Furthermore, we       hypothesize  that  the  interactions  between  these clonal populations in and       around  the neoplastic tissue determine the progression to cancer.  The aim of       this  project  is  to  identify  these  selective  mutations  and to infer the       interactions  between the mutant clones in Barrett's Esophagus that eventually       lead  to  the development of esophageal adenocarcinoma.  This analysis will be       based  on loss of heterozygosity data, promoter methylation, single nucleotide       polymorphisms,  and  gene  expression  data  for homogeneous subpopulations of       cells  sampled  from  neoplastic  tissue in patients with Barrett's Esophagus.       The  tissue  samples  come  from  biopsies of selected patients in the Seattle       Barrett's  Esophagus  Project  (N=285).   Data mining will be used to identify       mutations  that  are associated with clonal expansion as well as inhibition of       neighboring  clones.    The  order  of  genetic  events  in the progression to       esophageal adenocarcinoma will be determined by phylogenetic reconstruction of       the  cell lineages in the neoplastic tissue of each patient.  Machine learning       techniques,  such  as the EM algorithm, will be employed to infer missing data       and the effects of unsampled mutations. Computational modeling will be used to       generate   comparison  data  for  null  hypotheses  as  well  as  to  generate       experimental  predictions from our understanding of the progression to cancer.       This  is  the first step in my long-term career goal to contribute to medicine       through the use of computational and theoretical methods.  Working at the Fred       Hutchinson  Cancer  Research  Center  will  facilitate  the transition from my       background  in  computer  science  and  evolutionary theory, to an independent       research  program  based on the analysis of cellular and molecular dynamics of       cancer.  The challenge of this project is the integration of diverse molecular       and  epidemiological  data  into  a coherent and detailed understanding of the       progression to cancer in the neoplasm of a model system.                                                                                                                                                                                                       n/a",EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA,6751681,K01CA089267,"['Barretts esophagus', 'adenocarcinoma', 'cell cell interaction', 'clinical research', 'gene expression', 'gene mutation', 'human subject', 'loss of heterozygosity', 'mathematical model', 'microarray technology', 'model design /development', 'neoplasm /cancer genetics', 'neoplastic growth', 'neoplastic process', 'telomere']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,K01,2004,126767,0.016586940193659173
"EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA    DESCRIPTION  (Applicant's  Description):    The  cell  lineages  in neoplastic       tissues are evolving under the twin dynamics of mutation and clonal expansion.       This  is the basis for both its virulence and our difficulties in treating it.       We  hypothesize  that a subset of the mutations observed in the progression to       cancer  confer  beneficial  selective  effects  on  the cell.  Furthermore, we       hypothesize  that  the  interactions  between  these clonal populations in and       around  the neoplastic tissue determine the progression to cancer.  The aim of       this  project  is  to  identify  these  selective  mutations  and to infer the       interactions  between the mutant clones in Barrett's Esophagus that eventually       lead  to  the development of esophageal adenocarcinoma.  This analysis will be       based  on loss of heterozygosity data, promoter methylation, single nucleotide       polymorphisms,  and  gene  expression  data  for homogeneous subpopulations of       cells  sampled  from  neoplastic  tissue in patients with Barrett's Esophagus.       The  tissue  samples  come  from  biopsies of selected patients in the Seattle       Barrett's  Esophagus  Project  (N=285).   Data mining will be used to identify       mutations  that  are associated with clonal expansion as well as inhibition of       neighboring  clones.    The  order  of  genetic  events  in the progression to       esophageal adenocarcinoma will be determined by phylogenetic reconstruction of       the  cell lineages in the neoplastic tissue of each patient.  Machine learning       techniques,  such  as the EM algorithm, will be employed to infer missing data       and the effects of unsampled mutations. Computational modeling will be used to       generate   comparison  data  for  null  hypotheses  as  well  as  to  generate       experimental  predictions from our understanding of the progression to cancer.       This  is  the first step in my long-term career goal to contribute to medicine       through the use of computational and theoretical methods.  Working at the Fred       Hutchinson  Cancer  Research  Center  will  facilitate  the transition from my       background  in  computer  science  and  evolutionary theory, to an independent       research  program  based on the analysis of cellular and molecular dynamics of       cancer.  The challenge of this project is the integration of diverse molecular       and  epidemiological  data  into  a coherent and detailed understanding of the       progression to cancer in the neoplasm of a model system.                                                                                                                                                                                                       n/a",EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA,6633897,K01CA089267,"['Barretts esophagus', ' adenocarcinoma', ' cell cell interaction', ' clinical research', ' gene expression', ' gene mutation', ' human subject', ' loss of heterozygosity', ' mathematical model', ' microarray technology', ' model design /development', ' neoplasm /cancer genetics', ' neoplastic growth', ' neoplastic process', ' telomere']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,K01,2003,123974,0.016586940193659173
"EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA    DESCRIPTION  (Applicant's  Description):    The  cell  lineages  in neoplastic       tissues are evolving under the twin dynamics of mutation and clonal expansion.       This  is the basis for both its virulence and our difficulties in treating it.       We  hypothesize  that a subset of the mutations observed in the progression to       cancer  confer  beneficial  selective  effects  on  the cell.  Furthermore, we       hypothesize  that  the  interactions  between  these clonal populations in and       around  the neoplastic tissue determine the progression to cancer.  The aim of       this  project  is  to  identify  these  selective  mutations  and to infer the       interactions  between the mutant clones in Barrett's Esophagus that eventually       lead  to  the development of esophageal adenocarcinoma.  This analysis will be       based  on loss of heterozygosity data, promoter methylation, single nucleotide       polymorphisms,  and  gene  expression  data  for homogeneous subpopulations of       cells  sampled  from  neoplastic  tissue in patients with Barrett's Esophagus.       The  tissue  samples  come  from  biopsies of selected patients in the Seattle       Barrett's  Esophagus  Project  (N=285).   Data mining will be used to identify       mutations  that  are associated with clonal expansion as well as inhibition of       neighboring  clones.    The  order  of  genetic  events  in the progression to       esophageal adenocarcinoma will be determined by phylogenetic reconstruction of       the  cell lineages in the neoplastic tissue of each patient.  Machine learning       techniques,  such  as the EM algorithm, will be employed to infer missing data       and the effects of unsampled mutations. Computational modeling will be used to       generate   comparison  data  for  null  hypotheses  as  well  as  to  generate       experimental  predictions from our understanding of the progression to cancer.       This  is  the first step in my long-term career goal to contribute to medicine       through the use of computational and theoretical methods.  Working at the Fred       Hutchinson  Cancer  Research  Center  will  facilitate  the transition from my       background  in  computer  science  and  evolutionary theory, to an independent       research  program  based on the analysis of cellular and molecular dynamics of       cancer.  The challenge of this project is the integration of diverse molecular       and  epidemiological  data  into  a coherent and detailed understanding of the       progression to cancer in the neoplasm of a model system.                                                                                                                                                                                                       n/a",EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA,6514835,K01CA089267,"['Barretts esophagus', ' adenocarcinoma', ' cell cell interaction', ' clinical research', ' gene expression', ' gene mutation', ' human subject', ' loss of heterozygosity', ' mathematical model', ' microarray technology', ' model design /development', ' neoplasm /cancer genetics', ' neoplastic growth', ' neoplastic process', ' telomere']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,K01,2002,121263,0.016586940193659173
"EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA    DESCRIPTION  (Applicant's  Description):    The  cell  lineages  in neoplastic       tissues are evolving under the twin dynamics of mutation and clonal expansion.       This  is the basis for both its virulence and our difficulties in treating it.       We  hypothesize  that a subset of the mutations observed in the progression to       cancer  confer  beneficial  selective  effects  on  the cell.  Furthermore, we       hypothesize  that  the  interactions  between  these clonal populations in and       around  the neoplastic tissue determine the progression to cancer.  The aim of       this  project  is  to  identify  these  selective  mutations  and to infer the       interactions  between the mutant clones in Barrett's Esophagus that eventually       lead  to  the development of esophageal adenocarcinoma.  This analysis will be       based  on loss of heterozygosity data, promoter methylation, single nucleotide       polymorphisms,  and  gene  expression  data  for homogeneous subpopulations of       cells  sampled  from  neoplastic  tissue in patients with Barrett's Esophagus.       The  tissue  samples  come  from  biopsies of selected patients in the Seattle       Barrett's  Esophagus  Project  (N=285).   Data mining will be used to identify       mutations  that  are associated with clonal expansion as well as inhibition of       neighboring  clones.    The  order  of  genetic  events  in the progression to       esophageal adenocarcinoma will be determined by phylogenetic reconstruction of       the  cell lineages in the neoplastic tissue of each patient.  Machine learning       techniques,  such  as the EM algorithm, will be employed to infer missing data       and the effects of unsampled mutations. Computational modeling will be used to       generate   comparison  data  for  null  hypotheses  as  well  as  to  generate       experimental  predictions from our understanding of the progression to cancer.       This  is  the first step in my long-term career goal to contribute to medicine       through the use of computational and theoretical methods.  Working at the Fred       Hutchinson  Cancer  Research  Center  will  facilitate  the transition from my       background  in  computer  science  and  evolutionary theory, to an independent       research  program  based on the analysis of cellular and molecular dynamics of       cancer.  The challenge of this project is the integration of diverse molecular       and  epidemiological  data  into  a coherent and detailed understanding of the       progression to cancer in the neoplasm of a model system.                                                                                                                                                                                                       n/a",EVOLUTIONARY DYNAMICS OF BARRETT'S ESOPHAGUS NEOPLASIA,6229855,K01CA089267,"['Barretts esophagus', ' adenocarcinoma', ' cell cell interaction', ' clinical research', ' gene expression', ' gene mutation', ' human subject', ' loss of heterozygosity', ' mathematical model', ' microarray technology', ' model design /development', ' neoplasm /cancer genetics', ' neoplastic growth', ' neoplastic process', ' telomere']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,K01,2001,118630,0.016586940193659173
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,10016298,U01AI157189,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Bar Codes', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'machine learning method', 'next generation', 'novel', 'novel therapeutics', 'off-target mutation', 'off-target site', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2020,610710,0.023296430452689476
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10049219,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2020,391250,-0.015734675363084327
"Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different cancer phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. We have identified 4 large, multi- generational kindreds with a founder CDKN2A deleterious mutation (L16R, 47T>G). Our preliminary observations demonstrate that this mutant has lower expression and decreased ability to regulate cell cycle progression compared to wild type protein. Our sequencing studies of kindred members with different cancer phenotypes have identified potential variants in novel genes that modify risk (LGR6, a co-receptor of Wnt signaling and COL11A1, which participates in oncogenic signaling, including TGFbeta). We will determine the ability of the p16 mutant to promote transformation and how it is influenced by interaction with the above candidate modifier genes, LGR6 or COL11A1, in pancreatic cancer and melanoma. We will also develop novel computational models using machine deep learning, to generate networks that capture high dimensional features to integrate gene, biology, and cancer phenotype. This approach will be extended to kindreds with other CDKN2A mutations. Our Specific Aims are to: (1) Identify genotypes of potential modifier genes in multiple kindreds that feature pancreatic cancer and melanoma and known to carry CDKN2A germline mutations. We will use genome wide variant coverage of germline DNA from CDKN2A carriers from the 4 large L16R kindreds, plus additional members in 42 other similar CDKN2A kindreds. We will identify candidate modifier genes in the kindreds by rule-based statistical genetic analysis of genotypes. (2) Define the impact of CDKN2A L16R mutation on the function of p16 and its interplay with candidate modifier genes. We will elucidate the biological significance of mutations in CDKN2A and candidate modifier genes using functional and high throughput methodologies by analyzing the mechanism underlying the interplay between p16 and modifier genes; define new pathways cooperating with this interplay using a combination of genome wide studies to assess transformation in cells carrying p16 mutant or wild-type background using well established in vitro and in vivo models. (3) Develop a deep learning network model to integrate genetic, biological and epidemiological data to accurately infer pancreatic cancer and melanoma phenotypes and age of onset in mutation carriers. We will apply a convolutional neural network, a deep learning algorithm in the training dataset, develop a back-propagation algorithm to fine tune “weights,” and construct mutation-gene networks to capture high-dimensional features for each disease subclass. We will acquire and disseminate new knowledge and tools to the scientific community. Our integrated methods and approach will bring insight into how different cancer phenotypes can occur with identical predisposing mutations, which can be applied to other cancer syndromes with similar challenges. PROJECT NARRATIVE This proposal addresses Provocative Question #2. We will use innovative approaches to investigate how CDKN2A (which encodes p16) mutation carriers develop different phenotypes (pancreatic cancer vs melanoma vs no cancer), and include both genetic and non-genetic factors. Using 4 large, multi-generational kindreds with a founder CDKN2A deleterious mutation and other kindreds, we will define the mechanism underlying the interplay between CDKN2A and other factors. We will develop novel computational models using machine deep learning, that integrate gene, biology, and cancer phenotype. We will share our new knowledge and tools with the scientific community, and bring insights to apply to other challenging cancer syndromes.",Determinants of pancreatic cancer and malignant melanoma phenotypes in CDKN2A hereditary kindreds,9978727,R01CA208517,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Alleles', 'Alzheimer&apos', 's disease brain', 'Back', 'Biological', 'Biology', 'Brain Neoplasms', 'CDKN2A gene', 'Cancer Gene Mutation', 'Cancer-Predisposing Gene', 'Cell Cycle Progression', 'Cells', 'Code', 'Communities', 'Computer Models', 'Cyclin-Dependent Kinase Inhibitor 2A', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Environmental Exposure', 'Etiology', 'Gene Expression', 'Gene Frequency', 'Gene Mutation', 'Gene-Modified', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Germ-Line Mutation', 'In Vitro', 'Individual', 'Inherited', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Measures', 'Methodology', 'Methods', 'Minor', 'Modeling', 'Molecular', 'Mutation', 'Oncogenic', 'Pathway interactions', 'Pattern', 'Penetrance', 'Performance', 'Phenotype', 'Process', 'Proteins', 'Proteomics', 'Risk', 'Signal Transduction', 'Smoking', 'Sun Exposure', 'Syndrome', 'Testing', 'Training', 'Transforming Growth Factor beta', 'Variant', 'WNT Signaling Pathway', 'Weight', 'base', 'bead chip', 'cancer genome', 'cell growth', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disease phenotype', 'epidemiologic data', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'in vivo', 'in vivo Model', 'innovation', 'insight', 'interest', 'kindred', 'leukemia', 'melanoma', 'member', 'metaplastic cell transformation', 'mutant', 'mutation carrier', 'network models', 'non-genetic', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'overexpression', 'protein expression', 'receptor', 'tool', 'transcriptome sequencing', 'transmission process', 'tumorigenesis']",NCI,MAYO CLINIC ROCHESTER,R01,2020,590577,0.02338963750219676
"Multi-scale data integration frameworks to improve cancer outcomes ﻿    DESCRIPTION (provided by applicant)    The purpose of this K01 proposal is to develop innovative Big Data methodologies to improve cancer outcomes. I am a board-certified hematologist-oncologist completing a PhD in biomedical informatics at Stanford University. This proposal builds on my background and research in developing integrative analysis methods for multi-scale data. It also leverages the exceptional environment at Stanford for advanced training in machine learning, distributed computing, and longitudinal study analysis. Under the mentorship of my team of experts I will enhance my methodologies for improving knowledge discovery in cancer. Cancer research abounds with multi-scale data, from imaging to multi-modal molecular data, such as genomic, epigenomic, transcriptomic, and proteomic. Prediction models of clinical outcomes, including survival and therapeutic response, could capitalize on the richness of information that the data embody. In practice, however, the lack of effective methods for data integrative analysis leaves much of the latent knowledge untapped. For example, imaging data are routinely obtained for diagnostic purposes, but often underutilized in integrative analysis of cancer outcomes. By establishing inter-data correlations, imaging data have the potential to become noninvasive proxies for biopsy-acquired molecular data. Furthermore, traditional methods of data analysis have limited ability to extract knowledge from multi-scale data, which are large, heterogeneous, and exhibit complex inter-data interactions. This project outlines specific approaches to enhance knowledge extraction through integrative analyses that: (1) directly relates imaging data to molecular data, and (2) provides biomedical decision support (prediction of clinical outcomes) from multi-scale data. It applies these approaches to the analysis of brain and colorectal cancers. The training aims of the proposal are designed to further the research objectives by: (1) incorporating advanced machine learning skills to enhance information capture from each data source, (2) boosting computational efficiency and overall performance of the developed methodologies to ensure scalability, and (3) adapting methodologies to a longitudinal clinical study. The proposed project has the capacity to make a significant clinical impact by establishing the role of imaging data as a surrogate for molecular data, delineating potential therapeutic targets, and generating predictive markers for clinical outcomes. Importantly, these methodologies have a high potential to be generalizable to other cancers. Data from this project will cumulatively form the basis for an R01 proposal aimed at examining the optimal analysis of longitudinal multi-scale data to determine the minimum set of data needed to achieve maximum knowledge. The proposed work, designed for completion within the award period, will build on my research skills, generate preliminary data, forge productive collaborative relationships, and enable me to compete for R01 funding. In summary, this K01 will accelerate my career development and support launching my career as an independent physician-scientist in cancer data science research. PUBLIC HEALTH RELEVANCE    If successful, this study of brain and colon cancers will produce new ways of analyzing biomedical data that researchers can apply to other cancers to discover better diagnostic and outcome prediction tools, as well as treatments. One method uses imaging data to infer molecular information, including potential therapies, without biopsy. Another analyzes many different sources of biomedical data to find markers that indicate onset, survival likelihood, and treatment response in cancer.",Multi-scale data integration frameworks to improve cancer outcomes,9841402,K01ES026832,"['Applied Research', 'Award', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Biology', 'Biopsy', 'Cancer Diagnostics', 'Cause of Death', 'Clinical', 'Clinical Informatics', 'Clinical Markers', 'Clinical Research', 'Colon Carcinoma', 'Colorectal Cancer', 'Complex', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Data Sources', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Doctor of Philosophy', 'Ensure', 'Environment', 'Exhibits', 'Family-Based Registry', 'Funding', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Hematologist', 'Heterogeneity', 'Image', 'Informatics', 'Institution', 'Intuition', 'Investments', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Learning Skill', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Oncologist', 'Oncology', 'Outcome', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Proteomics', 'Proxy', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Scientist', 'Site', 'Source', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Universities', 'Variant', 'Work', 'anticancer research', 'base', 'biomedical informatics', 'cancer genetics', 'cancer subtypes', 'career', 'career development', 'cluster computing', 'cohort', 'colon cancer patients', 'computer framework', 'data integration', 'design', 'epigenomics', 'falls', 'follow-up', 'genetic epidemiology', 'improved', 'improved outcome', 'innovation', 'longitudinal analysis', 'machine learning method', 'molecular imaging', 'multimodality', 'multiscale data', 'new therapeutic target', 'novel', 'outcome prediction', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'skills', 'statistics', 'stem', 'supervised learning', 'targeted treatment', 'therapeutic target', 'tool', 'transcriptomics', 'treatment response']",NIEHS,STANFORD UNIVERSITY,K01,2020,188952,0.003068576870314365
"Functional Cancer Cell Maps FUNCTIONAL CANCER CELL MAPS SUMMARY I am currently an Academic Program Officer in Prof. Trey Ideker’s lab at UC San Diego. My title reflects the varied roles I play in the Ideker Lab, both scientifically and administratively, as I also serve as the Assistant Director of the Cancer Cell Map Initiative (CCMI) and the San Diego Center for Systems Biology (SDCSB). I am involved in a wide range of research projects, both within the Ideker Lab and across the various Centers. Central though to many of these efforts is the role I play supervising a number of projects using the CRISPR/Cas9­based approach to map genetic interactions in cancer cells. These functional maps can be used to identify protein complexes and pathways in cancer cells and to reveal genetic dependencies that might be therapeutically tractable. These studies will also provide us with the necessary training data to build “visible” AIs, machine learning models that not only make accurate predictions but also provide mechanistic insights. FUNCTIONAL CANCER CELL MAPS NARRATIVE Many cancers in adults are caused by mutations acquired over time. Research in both the Ideker Lab and the Cancer Cell Map Initiative seek to understand how these mutations alter the function of proteins leading to cancer using a variety of biochemical, genetic and computational approaches. We are particularly interested in understanding how combinations of mutated genes can disrupt normal cell physiology as knowing about these mechanisms can help us identify new drug targets or biomarkers.",Functional Cancer Cell Maps,10016231,R50CA243885,"['Adult', 'Biochemical Genetics', 'Biological Markers', 'CRISPR/Cas technology', 'Cell physiology', 'Data', 'Dependence', 'Genes', 'Genetic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Play', 'Research', 'Research Project Grants', 'Role', 'Supervision', 'Systems Biology', 'Therapeutic', 'Time', 'Training', 'academic program', 'base', 'cancer cell', 'insight', 'interest', 'new therapeutic target', 'protein complex', 'protein function']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R50,2020,126700,-0.004216827073439662
"Identification of Transposable Element Insertions in the Kids First Data Project Summary Insertion of transposable elements (TEs, sometimes referred to as “jumping genes”) into the human genome can be pathogenic. Our aim in this project is to use sophisticated computational approaches to characterize TE insertions in the whole-genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program and identify any insertional mutations that may disrupt gene function. The large scale of the Kids First program provides an unprecedented opportunity to investigate the role of TE insertions in childhood cancers and structural birth defects, as well as to create a resource of reference TE maps that will be important for all other TE studies. We will first modify our existing algorithm called xTEA for the trio design of the Kids First studies and increase the accuracy and efficiency of the algorithm. Then, we will apply it to the thousands of trios that have been profiled in the Kids First program, using a pipeline optimized for the cloud environment. The resulting set of TE insertions (especially L1, Alu, SVA, and HERV insertions) will be curated with all relevant features and be made into a database for the community. We will also apply machine learning methods to improve the calls once a sufficient amount of training data have been obtained. To investigate the potential pathogenicity of the mutation, we will first focus on insertions within genes, but we will also explore those in regulatory elements inferred from epigenetic profiling data. PROJECT NARRATIVE Transposable elements, or “jumping genes”, are genetic elements that can alter the DNA of an individual. We aim to utilize a computational method to identify such elements in the genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program. Our analysis will identify transposable elements that may be causal for a disease phenotype.",Identification of Transposable Element Insertions in the Kids First Data,9957262,R03CA249364,"['Algorithms', 'Communities', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Insertion Elements', 'DNA Transposable Elements', 'Data', 'Data Set', 'Databases', 'Disease', 'Elements', 'Endogenous Retroviruses', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Human Genome', 'Individual', 'Inherited', 'Insertion Mutation', 'Jumping Genes', 'Length', 'Location', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Maps', 'Mendelian disorder', 'Methods', 'Modeling', 'Mutation', 'Neurons', 'Output', 'Parents', 'Paste substance', 'Pathogenicity', 'Pediatric Research', 'Play', 'Population', 'Regulatory Element', 'Reporting', 'Resources', 'Retrotransposon', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Speed', 'Structural Congenital Anomalies', 'Training', 'base', 'cloud based', 'cohort', 'design', 'disease phenotype', 'epigenetic profiling', 'gene function', 'genetic element', 'genome sequencing', 'improved', 'machine learning method', 'proband', 'programs', 'transcriptome sequencing', 'whole genome']",NCI,HARVARD MEDICAL SCHOOL,R03,2020,169041,-0.014416158387186323
"Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation PROJECT SUMMARY It has become feasible to generate deep quantitative data for many of the molecules that are functional in cells, making it possible to survey a large number of tumors measuring genomic alterations and changes to transcripts, proteins and metabolites. It is, however, not clear what is the best way to integrate these data sets to extract as much information as possible about the biology that drives the cancer and how to best disrupt the tumor growth. Our proposed Proteogenomic Data Analysis Center for Cancer Systems Biology and Clinical Translation will develop new methods for better analyzing and integrating these data sets. In addition to developing statistical and machine learning methods, we also emphasize visual exploration of the data, and we will implement interactive web browser based visualization that will allow researchers to easily explore these vast data sets and gain novel insights by being able to quickly switch between summary information and details of the raw data. PROJECT NARRATIVE The mission of the proposed data analysis center is to leverage high dimensional large-scale data from tumor samples to identify new avenues for the development of clinical prognostics and therapeutics for cancer. This mission will be realized through analysis, integration and visualization of multi-omic datasets including genomic, transcriptomic, and proteomic data collected from patient samples to develop predictive models, and during drug treatment of patient derived xenografts and cell lines to validate mechanisms.",Proteogenomic Data Analysis for Cancer Systems Biology and Clinical Translation,9998919,U24CA210972,"['Amino Acid Sequence Databases', 'Amino Acids', 'Architecture', 'Biological', 'Biology', 'Cancer Center', 'Cell Line', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Consensus', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Experimental Designs', 'Formulation', 'Gene Expression', 'Gene Family', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Individual', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Mutation', 'Neoplasm Metastasis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Phosphoproteins', 'Phosphorylation', 'Primary Neoplasm', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Surveys', 'Systems Biology', 'Therapeutic', 'Time', 'Transcript', 'Variant', 'Visual', 'Visualization', 'Work', 'Xenograft procedure', 'actionable mutation', 'assay development', 'base', 'candidate identification', 'candidate marker', 'causal variant', 'clinical development', 'clinical phenotype', 'clinical translation', 'cohort', 'computerized data processing', 'computerized tools', 'data analysis pipeline', 'data exploration', 'experimental study', 'genomic data', 'high dimensionality', 'insight', 'large scale data', 'machine learning method', 'multiple data types', 'multiple omics', 'novel', 'outcome forecast', 'personalized medicine', 'precision medicine', 'precision oncology', 'predictive modeling', 'prognostic', 'protein biomarkers', 'protein kinase inhibitor', 'protein metabolite', 'proteogenomics', 'response', 'statistical and machine learning', 'tool', 'tool development', 'trait', 'transcriptome', 'transcriptomics', 'treatment choice', 'tumor', 'tumor growth']",NCI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U24,2020,619256,0.02239162154828406
"SimBioSys PhenoScope: A Cloud-Enabled, Web-Based Portal for Raw and Processed Cancer Phenotype Data Spanning Scales from Genomes to Tissues While genomic methods yield a plethora of information on the underlying cause and variety of cancers, genotype is only one factor contributing to the observed phenotype of a tumor. Heterogeneity among cancers and differences within individual tumors continue to challenge the efforts to develop effective therapies. A multitude of data such as single cell sequencing, digital pathology, and medical imaging are being generated that captures heterogeneity across multiple scales. However, data is siloed and connections between scales remains elusive. We propose the development of SimBioSys PhenoScope, a novel research tool to harmonize these disparate data types and provide connections between the genomic, cellular/pathway, microscopic tissue environment, and tissue scales. Combining state-of-the art machine learning, dimensionality reduction techniques, novel spatio-temporal simulation algorithms, and support for public data repositories, PhenoScope will provide a new means of assessing factors contributing to a cancer's phenotypical behavior. As an exploratory data platform, the tool will provide novel multi-scale visualizations by relying on the novel analyses between scales, that could be used by academic and pharmaceutical researchers alike to generate hypotheses for new drug targets, dosing regimens, and research targets. This technology enables researchers and clinicians to study cancer in a new light, and lead the way in to the upcoming phenomics era. n/a","SimBioSys PhenoScope: A Cloud-Enabled, Web-Based Portal for Raw and Processed Cancer Phenotype Data Spanning Scales from Genomes to Tissues",10269327,5N91020C00013,"['Algorithms', 'Data', 'Development', 'Dimensions', 'Dose', 'Environment', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Lead', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Microscopic', 'Online Systems', 'Pathway interactions', 'Pharmacologic Substance', 'Phenotype', 'Process', 'Regimen', 'Research', 'Research Personnel', 'Targeted Research', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Visualization', 'behavioral phenotyping', 'data integration', 'data warehouse', 'digital pathology', 'effective therapy', 'genome-wide', 'new therapeutic target', 'novel', 'pathology imaging', 'phenomics', 'phenotypic data', 'prototype', 'simulation', 'single cell sequencing', 'spatiotemporal', 'tool', 'tumor', 'web portal']",NCI,"SIMBIOSYS, INC.",N01,2020,400000,-0.008355648767494568
"Contextualizing Chaotic Metabolic Networks and Their Regulation Project Summary/Abstract Cancer metabolism is a complex network of perturbations to essential chemical and enzymatic reactions; however, the past century has seen a largely reductionist approach to understanding this system. While previously this approach was necessary due to technological limitations, current computer age technological advances allow us to survey, model, and explore the biological details of individual cells and populations of cells. Scientific fields, such as RNA biology and metabolism, have experienced massive strides in recent decades with the advent of RNA-seq and mass spectrometry-based metabolomics, yet our ability to contextualize and extract the full extent of these enormous datasets continues to lag and often results in focusing on only a handful of entities from a dataset. This effectively causes “big data” to become “little data”. This is problematic as these experiments are often expensive and time-consuming to produce, yet we only use a fraction of the total data produced by a given experiment. For the F99 phase of my proposal, I will address these limitations by leading the development of Metaboverse, a multi-omic computational analysis framework built upon our previous work to contextualize -omics datasets within customizable and global metabolic network representations. This framework will lay the foundation allowing for the exploration of complex forms of metabolic regulation in cancer. For example, we will analyze the ability of metabolic networks to undergo dispersed and low-magnitude regulation, where, rather than one or two components acting as the core regulatory actors, regulation is performed by dispersed groups of genes, proteins, or metabolites. This framework and related regulatory research will revolutionize our ability to more holistically understand temporal metabolic shifts and gene-metabolite intra-cooperativity, as well as ensure we obtain the maximum amount of information from our data. For the K00 phase of my proposal, I will work with a postdoctoral mentor at an NCI-Designated Cancer Center or affiliated institution that will supplement my training in machine learning and network biology to develop models that improve our ability to predict metabolic state from transcriptomic state. Doing so will allow us to harness the vast transcriptomics databases in cancer biology to better understand the role of metabolism across heterogeneous tumor cell populations. My ultimate goal is to become a tenured professor and run an independent, NIH-funded research lab that focuses on computational cancer metabolism research and that develops methods for interrogating this emerging domain of biology. Project Narrative While cancer metabolism is a robust and well-developed research field, approaches to its holistic understanding are still under-developed and hinder our ability to contextualize these complex metabolic states and their consequences. During the F99 phase, I will develop tools and methods that allow researchers to explore data in a more holistic manner than previously possible, which will be essential to elucidating more complicated regulatory mechanisms within cancer metabolism. During the K00 phase, I will develop novel machine learning algorithms that will improve our ability to predict the metabolic state from the transcriptional state, allowing us to harness the rich transcription datasets found in cancer biology for therapeutic benefit.",Contextualizing Chaotic Metabolic Networks and Their Regulation,10065368,F99CA253744,"['Address', 'Age', 'Algorithms', 'Behavior', 'Big Data', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Availability', 'Biology', 'Cancer Biology', 'Cells', 'Complex', 'Computer Analysis', 'Computer software', 'Computers', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Ensure', 'Event', 'Foundations', 'Funding', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Goals', 'Individual', 'Institution', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mentors', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Multiomic Data', 'NCI-Designated Cancer Center', 'Noise', 'Outcome', 'Output', 'Pathway interactions', 'Pattern', 'Phase', 'Population', 'Post-Transcriptional Regulation', 'Predictive Cancer Model', 'Process', 'Proteins', 'RNA', 'Reaction', 'Regulation', 'Research', 'Research Personnel', 'Research Project Grants', 'Ribosomal RNA', 'Role', 'Running', 'Signal Transduction', 'Statistical Methods', 'Surveys', 'System', 'Therapeutic', 'Time', 'Training', 'Transcript', 'United States National Institutes of Health', 'Universities', 'Utah', 'Work', 'base', 'chemical reaction', 'computerized tools', 'experience', 'experimental study', 'improved', 'interest', 'learning network', 'machine learning algorithm', 'metabolomics', 'multiple omics', 'neglect', 'neoplastic cell', 'novel', 'predictive modeling', 'professor', 'ribosome profiling', 'tool', 'transcriptome sequencing', 'transcriptomics', 'tumor metabolism', 'tumorigenesis']",NCI,UNIVERSITY OF UTAH,F99,2020,36742,-0.008985375090498982
"Integrative miRNA data analysis for clinical cancer genomics PROJECT SUMMARY The proposed research has two broad, long-term objectives. First, it seeks to shift medical practice toward more personalized treatments, by applying innovative methods to analyze and integrate DNA, RNA and protein data generated by a large network of GDAN researchers in a miRNA-centric framework. Analyses will identify cancer subtypes, and individual patients within a subtype, in which alterations in the expression of certain miRNAs influence cancer pathogenesis and drug response. Second, the proposed research seeks to shift cancer genomics research by allowing a diverse group of cancer researchers to flexibly access and use the project’s cancer genomics data, and microRNA-centric results and methods, through a cloud computing framework. The proposed research has three specific aims: 1) Build a computational pipeline for processing and analysis of miRNA data, 2) Elucidate the regulation of and by miRNAs through integrative analysis, and 3) Delineate the role of miRNAs in cancer progression and treatment using predictive modeling. Research design and methods: 1) Processing and analysis of miRNA data. We will process total RNA sequence data to identify expressed miRNAs, and extend the current processing pipeline to identify potentially functional miRNA sequence variants. We will apply our miRNA-centric analyses developed for The Cancer Genome Atlas project to identify: subtypes within a cancer, miRNAs that are associated with survival, miRNA targeting effects on gene and protein expression, and cis-effects of copy number and DNA methylation on miRNA abundances. 2) Regulation of and by miRNAs. Collaborating within the research network, we will extend our analysis methods to take into account additional datatypes and functional contexts that influence how miRNAs are regulated, and how they regulate genes and their products. 3) Predictive modeling. As the research network will have detailed clinical data and multiplatform genomic data, we will apply machine learning algorithms in a novel context to key sets of genes, proteins and miRNAs that predict clinical outcomes like survival and drug response. 4) Cloud computing. We will make our data, analysis methods and results readily available to a broad group of researchers within a cloud computing framework. NARRATIVE MicroRNAs (miRNAs) are small (~22 nt) RNAs that post-transcriptionally regulate levels of gene products, including proteins that are drug targets in cancer. In order to shift medical practice towards personalized treatments, the proposed research will apply innovative analysis methods to understand the role of miRNA expression on survival and drug response, within the context of DNA, RNA and protein data generated in a large research network. This will help identify cancer subtypes, and individual patient phenotypes, in which alterations in miRNA expression can lead to particular cancer progression pathways and treatment responses, in order to inform disease management.",Integrative miRNA data analysis for clinical cancer genomics,10011765,U24CA210952,"['3&apos', ' Untranslated Regions', 'Affect', 'Award', 'Biogenesis', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease Management', 'Drug Targeting', 'Event', 'Gene Dosage', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic Transcription', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Genomic Data Commons', 'Genomics', 'Goals', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'MicroRNAs', 'Modeling', 'Molecular', 'Mutate', 'Pathogenesis', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Process', 'Property', 'Proteins', 'RNA', 'RNA Editing', 'RNA Sequences', 'Regulation', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Role', 'Sampling', 'Statistical Data Interpretation', 'The Cancer Genome Atlas', 'Variant', 'analysis pipeline', 'anticancer research', 'base', 'cancer genomics', 'cancer subtypes', 'cancer therapy', 'computational pipelines', 'flexibility', 'gene product', 'genome-wide analysis', 'genomic data', 'heterogenous data', 'individual patient', 'innovation', 'insight', 'machine learning algorithm', 'member', 'novel', 'outcome forecast', 'personalized medicine', 'predict clinical outcome', 'predictive modeling', 'programs', 'protein expression', 'response', 'targeted treatment', 'therapy outcome', 'transcriptome sequencing', 'treatment response', 'tumor progression', 'working group']",NCI,PROVINCIAL HEALTH SERVICES AUTHORITY,U24,2020,398334,0.020079073820523218
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9928344,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2020,1186500,0.015384111805926338
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9858390,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2020,2000000,0.022591645221123984
"UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network The “UCSC-Buck Genome Data Analysis Center for the Genomic Data Analysis Network” will develop state-of-the-art methods for integrating various types of data to discover the genetic pathways, the microenvironment, the originating cells, and the oncogenic processes driving the initiation and progression of tumors. The long term goals of the project are to identify highly accurate models detailing the faulty genetic circuitry at work in each subclone of a patient’s tumor, as well as any “normal” cells acting as accomplices by supporting the cancer microenvironment. The ultimate objective is to encode computer algorithms that can search a patient’s individual pathway diagram for the best combination of interventions to eliminate every tumor cell, while preserving the health of every normal cell, in their body. Integrative pathway analysis methods will be developed to reveal signatures of tumor subtypes from Pan-Cancer and external datasets. New technologies will be established for uncovering network models tailored to individual patients. The tools will be deployed as part of an active collaboration to support the specific projects of the Genome Data Analysis Network. Novel probabilistic graphical models will be used to infer disrupted signaling. Cellular signatures will be collected from the analysis of normal cells, cancer cell line models, and Pan-Cancer investigations. Novel machine-learning methods, guided by pathway mechanisms, will be established to identify cell state signatures in heterogeneous patient samples. This work will reveal rare mutations driving metastatic transformation that are currently of unknown significance. New clues about the genetic circuitry promoting response and resistance to treatment will be established. Finally, cross-tumor connections that relate tumors of one type to a different type will suggest new avenues for treatment. Computational strategies for interpreting the results of cancer genome sequencing projects are in  desperate need. To select appropriate treatment strategies for a patient, an accurate model of the  altered genetic wiring in the tumor is needed as well as how that wiring relates to other tumors  and to other normal cells at various stages of differentiation. The research will establish  resources and software to contribute such methodologies for the Genome Data Analysis Network  projects that will subsequently be released into the public domain to benefit the entire scientific  community.",UCSC-Buck Specialized Genomic Data Analysis Center for the Genomic Data Analysis Network,10001323,U24CA210990,"['Automobile Driving', 'Awareness', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer cell line', 'Cells', 'Cisplatin', 'Clinical', 'Collaborations', 'Communities', 'Competence', 'Computational algorithm', 'Computer software', 'DNA Sequence Alteration', 'DNA copy number', 'Data', 'Data Set', 'Development', 'Epigenetic Process', 'Genetic', 'Genome', 'Genome Data Analysis Center', 'Genome Data Analysis Network', 'Goals', 'Health', 'Institutes', 'Intervention', 'Investigation', 'Leadership', 'Libraries', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Normal Cell', 'North Carolina', 'Oncogenic', 'Output', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Process', 'Protein Isoforms', 'Proteomics', 'Public Domains', 'RNA', 'RNA Splicing', 'Research', 'Resistance', 'Resources', 'Sampling', 'Series', 'Signal Transduction', 'Structure', 'The Cancer Genome Atlas', 'Time', 'Treatment Protocols', 'Tumor Subtype', 'University of Texas M D Anderson Cancer Center', 'Untranslated RNA', 'Variant', 'Work', 'bioinformatics tool', 'cancer genome', 'cancer genomics', 'computerized tools', 'data pipeline', 'exceptional responders', 'experience', 'genome analysis', 'genome sequencing', 'genomic data', 'individual patient', 'mRNA Expression', 'machine learning method', 'member', 'neoplastic cell', 'network models', 'new technology', 'novel', 'patient response', 'preservation', 'response', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment', 'tumor progression']",NCI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,U24,2020,442117,0.012499872700383842
"Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data Limitless replicative potential is a key hallmark of cancer and critically depends on telomere maintenance. Many cancers thus aberrantly reactivate the telomerase reverse transcriptase (TERT), a catalytic subunit of the telomerase complex that elongates telomere. It has been recently discovered that this common path to immortality in multiple cancers is through two activating point mutations in the TERT promoter (TERTp), found in more than 50 different cancer types, often at strikingly high frequencies, e.g. roughly 83% in glioblastomas (GBM) and 71% in melanomas. In the previous funding period, the PI has identified the molecular function of these highly recurrent mutations, demonstrating that the transcription factor (TF) GABP binds the mutant TERTp with exquisite specificity, but not the wild-type TERTp. The high prevalence of TERTp mutations across multiple cancer types and the selectivity of GABP recruitment to mutant TERTp thus provide an unprecedented opportunity for treating a large number of cancer patients with minimal toxicity to healthy cells. Despite the clear significance of this opportunity, however, several important questions surrounding the molecular functions and modulators of TERTp mutations remain poorly understood, hindering the development of effective and safe therapeutic strategies.  Our long-term goal is to establish a rigorous computational framework for understanding the aberrant transcriptional and epigenetic networks in cancers and to apply the resulting knowledge to devise novel therapeutic strategies that account for the genetic background of individual patients and that can a priori predict and avoid potential resistance mechanisms. The objective of our current renewal proposal is to develop powerful computational methods for transforming our knowledge about the non-coding TERTp mutations into an effective and safe molecular target. At the same time, the resulting methods will help resolve several outstanding challenges in the field of transcriptional gene regulation and have broad applications in cancer genomics. We will accomplish our objective my pursuing the following Aims: (1) Develop and test a computational framework for inferring sequence features that determine the distinct and shared binding patterns of paralogous TFs; (2) Develop and validate integrative tools for discovering the molecular basis of genetic interactions between germline variations and oncogenic mutations; (3) Develop and apply computational methods for studying the role of DNA helical phase between adjacent binding motifs in recruiting ETS factors to chromatin; (4) Perform a systematic genomic characterization of the effects of knocking out GABPB1L in TERTp-mutant cancer cells and healthy cells. The results of this proposal will have a broad impact on cancer research by providing powerful tools for studying paralogous oncogenic TFs and revealing novel insights into a highly promising therapeutic strategy. The proposed research will provide computational and bioinformatic resources for studying the binding pattern of paralogous oncogenic transcription factors. It will provide a computational framework for inferring the function of non-coding regulatory mutations and studying their interaction with common genetic variants. As an important application, we will systematically analyze a novel therapeutic strategy that has the potential to treat effectively a large number of patients across multiple cancer types harboring the recently discovered TERT promoter mutations.",Predicting Transcriptional and Epigenetic Networks in Cancer from Sequencing Data,9831048,R01CA163336,"['Address', 'Binding', 'Binding Sites', 'Cancer Patient', 'Cells', 'Chromatin', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Sequence Alteration', 'Data', 'Development', 'Drug resistance', 'Epigenetic Process', 'Family', 'Family member', 'Frequencies', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Glioblastoma', 'Goals', 'High Prevalence', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Molecular', 'Molecular Target', 'Mutation', 'Nature', 'Oncogenic', 'Patients', 'Pattern', 'Phase', 'Point Mutation', 'Protein Isoforms', 'RNA-Directed DNA Polymerase', 'Recurrence', 'Research', 'Role', 'Somatic Mutation', 'Specificity', 'TERT gene', 'Techniques', 'Telomerase', 'Telomere Maintenance', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Transcriptional Regulation', 'Untranslated RNA', 'Validation', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics resource', 'c-myc Genes', 'cancer cell', 'cancer genomics', 'cancer type', 'computer framework', 'computing resources', 'deep learning', 'dimer', 'genetic variant', 'genome-wide', 'individual patient', 'insight', 'knowledge of results', 'melanoma', 'member', 'mutant', 'novel', 'novel therapeutics', 'promoter', 'recruit', 'resistance mechanism', 'telomere', 'therapeutic target', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2020,326848,0.022017811949646367
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9902467,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'stem cells', 'tissue stem cells', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2020,324350,-0.007401657601220273
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9959498,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2020,360268,-0.0018012863565510533
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,10260680,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,177000,0.04385430501321971
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9957082,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,193576,0.04385430501321971
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,9970939,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2020,523409,-0.002450738970982922
"Reverse Sensitivity Analysis for Identifying Predictive Proteomics Signatures of Cancer Title: Reverse Sensitivity Analysis for Identifying Proteomics Signatures of Cancer Abstract Cancer is a complex disease in which genetic disruptions in cell signaling networks are known to play a significant role. A major aim of cancer systems biology is to build models that can predict the impact of these genetic disruptions to guide therapeutic interventions (i.e. personalized medicine). A prominent driver of cancer cell growth is signaling pathway deregulation from mutations in key regulatory nodes and loss/gain in gene copy number (CNV). However, current mathematical modeling approaches do not adequately capture the impact of these genetic changes. Reasons for this include the poorly understood layers of regulation between gene expression and protein activity, and limitations in most modeling and protein measurement technologies. In addition, there is a paucity of overarching hypotheses that can link specific gene expression or mutation patterns to the cancer phenotype. Recent work by our group has resolved some of the technical challenges that have hindered the application of proteomics technologies to cancer systems biology research. It has also suggested a new approach for using quantitative proteomics data to understand mechanisms driving cancer cell behavior. Using an ultrasensitive, targeted proteomics platform that can measure both abundance and phosphorylation of proteins present at only hundreds of copies per cell, we found that signaling pathways appeared to be controlled by only a limited number of key nodes whose activity is tightly regulated through low abundance and feedback phosphorylation. We propose to build on these findings by critically testing the hypothesis that CNV and genetic mutations dysregulate signaling pathways in cancer by shifting control from tightly regulated nodes to poorly regulated ones. This will be done by systematically identifying key regulatory nodes of normal and cancer cells using CRISPRa/i screens, determine the relationship between protein abundance and signaling pathway activities using ultrasensitive targeted proteomics and phosphoproteomics and then use these data to semi-automatically generate mathematical models of the functional topology of the signaling pathways. Specifically, we propose to: 1) Use targeted CRISPR gene perturbation libraries to identify the regulatory topologies of signaling pathways important in cancer and how they are disrupted by common cancer mutations, 2) Use the CRISPR perturbation and proteomics data to semi-automatically build predictive models of cancer cell signaling pathways, and 3) Combine modeling and perturbation screens to understand how feedback regulation in cancer contributes to drug resistance. This work will result in simplified, computationally tractable yet mechanistic models of signaling pathways and provide network maps of feedback and crosstalk circuits that can be used to rapidly map the regulatory state of cells. Most important, it will provide a generic platform for translating protein abundance and phosphorylation patterns into a “state” snapshot of cancers that can lead to predicting their response to specific drugs. Narrative Cancer is an extremely complex disease which is frequently caused by signaling pathway deregulation from genetic mutation or loss/gain in gene copy number. Modern analytical techniques have provided a wealth of data on the molecular changes associated with cancer mutations, but it has been extremely difficult to use this information to design targeted therapies. We propose a new methodology that combines CRISPR-based targeted screens, advanced proteomics technologies, and a new mathematical modeling approach for identifying proteomics signatures of altered signaling pathways in cancer that can be used to build predictive models and explore mechanisms of drug resistance.",Reverse Sensitivity Analysis for Identifying Predictive Proteomics Signatures of Cancer,9923630,U01CA227544,"['Address', 'Affect', 'Automobile Driving', 'Behavior', 'Biological Models', 'Breast Cancer cell line', 'Breast Epithelial Cells', 'CRISPR library', 'Cancer Cell Growth', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Computer Models', 'DNA Sequence Alteration', 'Data', 'Development', 'Disease', 'Drug resistance', 'Feedback', 'Flow Cytometry', 'Gene Dosage', 'Gene Expression', 'Gene Mutation', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Play', 'Predictive Cancer Model', 'Proteins', 'Proteomics', 'Proto-Oncogene Proteins c-akt', 'Reagent', 'Regulation', 'Research', 'Resistance', 'Role', 'Signal Pathway', 'Signal Transduction', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Translating', 'Work', 'base', 'cancer cell', 'cancer type', 'cell behavior', 'design', 'experimental study', 'mathematical model', 'melanoma', 'novel strategies', 'personalized medicine', 'phosphoproteomics', 'predictive modeling', 'proteomic signature', 'response', 'screening', 'targeted treatment', 'tool']",NCI,BATTELLE PACIFIC NORTHWEST LABORATORIES,U01,2020,715682,-0.005767562652985118
"Transforming family dogs into a powerful and accessible model for human cancer ABSTRACT There is an unmet need for novel approaches to cancer research, including improved model systems. Pet dogs are among the most promising natural models for translational cancer research​. They share our environment and develop cancers with clear clinical, histological, and genomic similarities to human cancer. We propose to use new genomic technology and a direct-to-dog-owner approach to overcome existing limitations of the canine model. To accomplish this, we will use new liquid biopsy technology, which makes it possible to sequence ​tumor exomes in circulating cell-free DNA from a blood sample, and thus achieve deeper understanding of tumor genomics without invasive biopsies. The power of these minimally invasive sampling technologies is greatest in application to very large sets of clinical samples. Family dogs, whose environments are shared with humans and for which tumor genomics are similar to human cancers, offer an unparalleled model in which to assemble clinical sets of size sufficient both to confirm the relevance of known genetic pathways, and to identify new ones. We propose to combine the power of cell-free DNA sequencing, ​the enthusiasm of citizen-scientist pet owners, and the clinical experience of veterinarians. We will create a research portal for collection of information on diagnosis, treatment, and outcome for thousands of dogs with cancer, as well as their environment and lifestyle. W​e will also develop new computational methodologies to identify genomic similarities between canine and human cancers. Comparison of these canine and human mutational profiles will enable matching of canine cancer subtypes with human cancer subtypes based on genetic pathways, facilitating canine trials to advance human clinical studies. We aim to:  Aim 1. ​Develop software to Identify canine models for human cancers using genomic data and  comprehensive, histology-blind analysis approach.  Aim 2. Develop and optimize ​cell-free DNA sampling and sequencing methods in dogs, including  ultra-low-pass whole genome sequencing and whole exome sequencing.  Aim 3. Implement a ​direct-to-dog-owner smartphone app to collect and validate detailed clinical, and  environmental data, paired with blood samples, for thousands of dogs. By combining the power of genome sequencing and new liquid biopsy technology with the opportunity to collect large sets of samples from a species whose cancers are genomically reflective of those in humans, our project​ will​ transform​ the scale and scope of translational cancer research and precision medicine. Project Narrative Pet dogs live in the same environments that we do, suggesting that profiling mutations in dog tumors could guide treatment of human cancers. With the help of veterinarians and citizen-scientist dog owners, we will build tools and resources needed to study cancer in thousands of dogs at once. This will help scientists find important genetic features of canine cancers, match them to specific human cancers, and translate what we learn into new cancer therapeutics.",Transforming family dogs into a powerful and accessible model for human cancer,9891974,R37CA218570,"['Address', 'Benchmarking', 'Biological Models', 'Biopsy', 'Blood', 'Blood specimen', 'Canis familiaris', 'Catalogs', 'Chemical Exposure', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Code', 'Collection', 'Community Clinical Oncology Program', 'Computer software', 'Computing Methodologies', 'DNA sequencing', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dog family', 'Environment', 'Evolution', 'Gene Mutation', 'Genes', 'Genetic', 'Genomics', 'Gold', 'Histologic', 'Histology', 'Human', 'Inherited', 'Institutes', 'Learning', 'Life Style', 'Longitudinal Studies', 'Malignant Neoplasms', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Molecular Profiling', 'Mutate', 'Mutation', 'Oncology', 'Operative Surgical Procedures', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Records', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Scientist', 'Silicones', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Translating', 'Treatment outcome', 'United States', 'Untranslated RNA', 'Veterinarians', 'analysis pipeline', 'anticancer research', 'base', 'blind', 'cancer genomics', 'cancer subtypes', 'cell free DNA', 'chemotherapy', 'citizen science', 'classifier algorithm', 'cohort', 'comparative', 'comparative genomics', 'driver mutation', 'exome', 'exome sequencing', 'experience', 'genetic risk factor', 'genome sequencing', 'genomic data', 'genomic platform', 'human data', 'human model', 'improved', 'liquid biopsy', 'minimally invasive', 'new technology', 'novel strategies', 'open source', 'precision medicine', 'predicting response', 'programs', 'response', 'smartphone Application', 'software development', 'supervised learning', 'targeted treatment', 'tool', 'translational cancer research', 'translational model', 'tumor', 'whole genome']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R37,2020,653673,0.009189801426895426
