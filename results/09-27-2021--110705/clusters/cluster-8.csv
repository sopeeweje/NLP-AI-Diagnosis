text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,0.02114427832371207
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,9733308,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2019,388750,0.013767492593632474
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.020416337361181876
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,9835005,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'human model', 'interest', 'learning strategy', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2019,61610,0.0013952612322983174
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9772541,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,264255,0.02283770411693198
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,0.006937790720457774
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9671422,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Ingestion', 'Kinetics', 'Laboratories', 'Locomotion', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'automated image analysis', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'machine learning algorithm', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2019,475637,0.010128932316208327
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9654021,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2019,1354555,0.05162380155511625
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9823400,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2019,583885,0.05162380155511625
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9855180,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Awareness', 'Basic Science', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathogenicity', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacology', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2019,702655,0.013066987901127116
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9694688,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'connectome data', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genetic architecture', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,450954,0.008499231432157516
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design New technologies afford the acquisition of dense “data clouds” of individual humans. However, heterogeneity, dimensionality and multi-scale nature of such data (genomes, transcriptomes, clinical variables, etc.) pose a new challenge: How can one query such dense data clouds of mixed data as an integrated set (as opposed to variable by variable) against multiple knowledge bases, and translate the joint molecular information into the clinical realm? Current lexical mapping and brute-force data mining seek to make heterogeneous data interoperable and accessible but their output is fragmented and requires expertise to assemble into coherent actionable information. We propose DeepTranslate, an innovative approach that incorporates the known actual physical organization of biological entities that are the substrate of pathogenesis into (i) networks (data graphs) and (ii) hierarchies of concepts that span the multiscale space from molecule to clinic. Organizing data sources along such natural structures will allow translation of burgeoning high-dimensional data sets into concepts familiar to clinicians, while capturing mechanistic relationships. DeepTranslate will take a hybrid approach to learn and organize its content from both (i) existing generic comprehensive knowledge sources (GO, KEGG, IDC, etc.) and (ii) newly measured instances of individual data clouds from two demonstration projects: (1) ISB’s Pioneer 100 and (2) St. Jude Lifetime cancer survivors. We will focus on diabetes as test case. These two studies cover a deep biological scale-space and thus can test the full extent of the multiscale capacity of DeepTranslate in a focused application. 1. TYPES OF RESEARCH QUESTION ENABLED. How can a clinician find out that the dozens of “out of range” variables observed in a patient’s data cloud, form a connected set with respect to pathophysiology pathways, from gene to clinical variable? How can the high-dimensional data of studies that measure for each individual 100+ data points of various types (“personal data clouds”) be analyzed as one set in an integrated fashion (as opposed to variable by variable) against existing knowledge bases and also be used to improve the databases? DeepTranslate addresses these two types of questions and thereby will accelerate translation of future personal data clouds into (A) care decisions and (B) hypotheses on new disease mechanisms / treatments, thereby benefiting providers as well as researchers. 2. USE OF EXPERTISE AND RESOURCES. • ISB: pioneer in personalized, big-data driven medicine (Demo Project 1); biomedical content expertise; multiscale omics and molecular pathogenesis, big data analysis, housing of databases for public access; query engine designs, GUI. • UCSD: leader in biomedical data integration; automated assembly of molecular and clinical data into hierarchical structures; translation between data types • U Montreal: biomedical database curation from literature and construction of gene/protein/drug interaction networks; machine learning, open resource database • St Jude CRH: Cancer monitoring Demo Project 2, cancer patient data analytics. 3. POTENTIAL DATA AND INFRASTRUCTURE CHALLENGES. (a) Existing comprehensive clinical data sources are not uniform and not explicitly based on biological networks; cross-mapping is being performed at NLM based on lexical relationships: HPO (phenotypes) vs. SNOMED CT (for EMR) vs. IDC or Merck Manual (for diseases). Careful selection of these sources in close collaboration with NLM is needed. (b) Existing molecular pathway databases are static, based on averages of heterogeneous non-stratified populations, while the newly measured high-dimensional data clouds are varied due to intra-individual temporal fluctuation and inter-individual variation. How this will affect building of ontotypes in our hybrid approach, and how large cohorts of data clouds must be to offer statistical power is yet to be determined. Our two Demonstration Projects with their uniquely deep (high-dimensional and multiscale) data in cohorts of limited but growing size are thus crucial first steps in a long journey of collective learning in the TRANSLATOR community. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9853317,OT3TR002026,"['Address', 'Affect', 'Architecture', 'Big Data', 'Biological', 'CRH gene', 'Cancer Patient', 'Cancer Survivor', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Drug Interactions', 'Functional disorder', 'Future', 'Gene Proteins', 'Genes', 'Genome', 'Graph', 'Heterogeneity', 'Housing', 'Human', 'Hybrids', 'Individual', 'Infrastructure', 'Joints', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medicine', 'Molecular', 'Monitor', 'Nature', 'Output', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Provider', 'Research', 'Research Personnel', 'Resources', 'SNOMED Clinical Terms', 'Saint Jude Children&apos', 's Research Hospital', 'Source', 'Structure', 'Testing', 'Translating', 'Translations', 'base', 'cohort', 'data integration', 'data mining', 'design', 'high dimensionality', 'improved', 'innovation', 'inter-individual variation', 'interoperability', 'knowledge base', 'lexical', 'molecular assembly/self assembly', 'multidimensional data', 'new technology', 'transcriptome']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT3,2019,855741,0.026939851862267064
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,9744013,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Algorithms', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelium', 'Esophageal', 'Esophageal Adenocarcinoma', 'Esophagitis', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Intelligence', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stem cells', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2019,171720,0.007741017554063494
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9690782,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Dysregulation', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'bioinformatics tool', 'circadian', 'circadian regulation', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'informatics\xa0tool', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2019,328155,0.015887793761347527
"Development of dictyBase, an online informatics resource PROJECT SUMMARY dictyBase is the model organism database (MOD) for the eukaryote Dictyostelium discoideum and related species. A community resource, widely supported by the research community, dictyBase contains gold standard expert literature curation of genes, functional annotations using the Gene Ontology and a wide range of genomic resources. Dictyostelium is widely used to study cellular processes such as cell motility, chemotaxis, signal transduction, cellular response to drugs, and host-pathogen interactions. Dictyostelium's genome contains significant orthologs of vertebrate, yeast and microbial genes, attracting researchers interested in a wide variety of biological topics including human disease, multicellular differentiation and comparative genomics. dictyBase enables researchers to search, view and download up-to-date genomic, functional and technical information. It is also widely used by teachers/instructors due to the wealth of available teaching materials and research protocols. Dictyostelium investigators depend on dictyBase as their primary community resource, where help from dictyBase staff (dictyBase help line) or from other users (Dicty ListServ, moderated by dictyBase) is available. We are in the final stages of deploying our completely new technology stack. By the end of this year dictyBase will be run entirely as a cloud-based application. This propoal seeks support to continue operating and expanding this important community resource. Our goals for this proposal are: (Aim 1) To continue (a) expert curation by dictyBase curators and enable (b) Community curation leveraging our strong relationship with the community. We will use additional sequence data to (c) update the AX4 reference genome sequence and improve the efficiency of curation by using (d) Deep learning-based linking of papers to genes prioritizing them for further analysis and curation. (Aim 2) We will improve dictyBase utility and usability by implementing (a) Bulk annotation methods for importing large-scale data sets using both (i) a web interface and (ii) a script/command line method. (b) We will add 10 additional Dictyostelid genomes using automated methods to annotate them. We will improve usability by implementing a (c) concurrent blast search with a new user interface and integrate this with the JBrowse display. (Aim 3) To expand the data and increase the richness of annotations available in dictyBase we will implement mechanisms to capture, store and display: (a) additional context to GO annotations (i) using existing GO extensions and (ii) annotating and displaying biological pathways using GO CAM models; (b) integrate and display genome wide insertion mutant information for over 20 thousand insertional mutants; and (c) develop a graphical display of spatial expression data using Dictyostelium anatomy ontology terms (i) by adding a track in JBrowse for genes annotated with spatial / anatomy expression terms, and (ii) creating a graphical display of these annotations via our Circos-based dashboard tool. As other data sets become available we will add them to dictyBase and develop methods to display the data and make it searchable. PROJECT NARRATIVE dictyBase is the model organism database (MOD) for the eukaryote Dictyostelium discoideum and related species, Dictyostelium is widely used for research in the biomedical, genetic, and environmental domains. The database uses the genome of Dictyostelium to organize biological knowledge developed using this experimental system, and dictyBase is manually curated and up-to-date with current literature. This application proposes capturing new types of data and providing tools to search and visualize that data.","Development of dictyBase, an online informatics resource",9738586,R01GM064426,"['Anatomy', 'Animals', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Cell physiology', 'Chemotaxis', 'Code', 'Collaborations', 'Communities', 'DNA sequencing', 'Data', 'Data Display', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Dictyostelium', 'Dictyostelium discoideum', 'Disease', 'Engineering', 'Eukaryota', 'FAIR principles', 'Funding', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Gold', 'Information Resources', 'Investments', 'Knowledge', 'Link', 'Literature', 'Manuals', 'Methods', 'Modeling', 'Names', 'Nomenclature', 'Ontology', 'Orthologous Gene', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Plants', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Resource Informatics', 'Resources', 'Running', 'Signal Transduction', 'Site', 'Students', 'Supervision', 'System', 'Teaching Materials', 'United States National Institutes of Health', 'Update', 'Work', 'Yeasts', 'analytical tool', 'base', 'cell motility', 'cloud based', 'comparative genomics', 'contig', 'dashboard', 'data warehouse', 'deep learning', 'experimental study', 'genome annotation', 'genome-wide', 'human disease', 'improved', 'instructor', 'interest', 'microbial', 'model organisms databases', 'mutant', 'new technology', 'novel', 'pathogen', 'reference genome', 'response', 'teacher', 'tool', 'usability', 'web interface']",NIGMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,506287,0.015762810555131505
"Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome PROJECT SUMMARY/ABSTRACT  The major goal of this RC2 proposal is to generate the first, multi-omics translational study capturing the sum of environmental exposures (i.e. the exposome) and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without effective medical therapy. PSC shortens survival, is associated with inflammatory bowel disease (IBD) and strongly predisposes to cholangiocarcinoma (i.e. bile duct cancer) and colon cancer. Our recent genome wide association studies (GWAS) revealed the significant role of genetic variation in PSC, while also re-emphasizing the importance of environmental factors and gene-environment interactions in PSC pathogenesis. To further elucidate the role of exposures from our external environment and lifestyle (e.g., diet, stress, toxins, drugs, microbes), we have assembled a world-class, multi-disciplinary team that synergizes expertise and resources across four institutions: Mayo Clinic, Emory University, University of Illinois Urbana-Champaign (UIUC), and University of Oslo, Norway. Our collaborative team will leverage large clinical databases and biorepositories, as well as expertise in PSC and related conditions, exposomics, metabolomics, methylomics, transcriptomics, metagenomics, genomics, and data analytics to develop the PSC Scientific Community Resource for hypothesis-generating science and simultaneously uncover factors contributing to PSC.  We now seek to define the bigger-picture cellular networks, rather than individual genes, driving disease processes. To do so, we will use unbiased network-based approaches designed to integrate multiple layers of omics data. Our proposal is predicated on the hypothesis that multi-omics analyses of data capturing environmental exposures and the associated biological responses, including the effect on the genome, will reveal networks or pathways influencing PSC pathogenesis and outcomes. To test this hypothesis, we will perform a series of sophisticated analyses to identify PSC-associated changes in and across the exposome, metabolome, methylome, and transcriptome in blood as well as the gut metagenome, exposome and metabolome.  Our collaboration and data generation are already underway with pilot studies demonstrating differences in blood exposomes and metabolomes and stool metagenomes between PSC patients and controls. Using a suite of bioinformatic tools and available genetic variation data, we aim to discover stable, detectable, omics-based disease signatures in blood (Aim 1) and stool (Aim 2) that when integrated with clinical data (Aim 3) will reveal biological pathways driving disease pathogenesis and outcomes. All data, residual specimens, and analytical details will be made freely available to the research community in accordance with NIDDK's mission. Furthermore, this effort responds to the NIDDK's call “to better understand the role of the microbiome, genetics, and exposome.” PROJECT NARRATIVE We seek to generate the first, multi-omics translational study and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without medical therapy. We will define the bigger-picture cellular networks and gene-environment interactions driving PSC by integrating multiple layers of -omics data. In so doing, we will identify molecular disease signatures, including environmental toxins, metabolism-related chemicals and gut bacteria, unique to PSC patients.",Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome,9773075,RC2DK118619,"['Accounting', 'Address', 'Age', 'Automobile Driving', 'Bile duct carcinoma', 'Biological', 'Blood', 'Chemical Exposure', 'Chemicals', 'Childhood', 'Cholangiocarcinoma', 'Cholestasis', 'Chronic', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Colon Carcinoma', 'Communities', 'DNA Methylation', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Analytics', 'Diet', 'Disease', 'Environment', 'Environmental Exposure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feces', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Graph', 'High Performance Computing', 'Illinois', 'Individual', 'Inflammatory Bowel Diseases', 'Inflammatory disease of the intestine', 'Institution', 'Life Style', 'Light', 'Link', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Medical', 'Metagenomics', 'Microbe', 'Mission', 'Modeling', 'Molecular Disease', 'Multiomic Data', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Network-based', 'Norway', 'Onset of illness', 'Outcome', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Research', 'Residual state', 'Resolution', 'Resources', 'Role', 'Science', 'Series', 'Shotguns', 'Specimen', 'Stress', 'Sum', 'Systems Biology', 'Taxonomy', 'Testing', 'Toxic Environmental Substances', 'Toxin', 'Universities', 'base', 'biobank', 'bioinformatics tool', 'clinical database', 'data integration', 'data resource', 'design', 'gene environment interaction', 'genome wide association study', 'genomic data', 'gut bacteria', 'gut metagenome', 'gut microbiota', 'improved', 'innovation', 'liver transplantation', 'metabolome', 'metabolomics', 'metagenome', 'methylation pattern', 'methylome', 'methylomics', 'microbial', 'microbiome', 'multidisciplinary', 'multiple omics', 'novel', 'patient population', 'peripheral blood', 'personalized approach', 'pollutant', 'primary outcome', 'primary sclerosing cholangitis', 'programs', 'response', 'sex', 'toxin metabolism', 'transcriptome', 'transcriptomics', 'translational study']",NIDDK,MAYO CLINIC ROCHESTER,RC2,2019,1566059,0.0018562664859371645
"Learning Dynamics of Biological Processes from Time Course Omics Datasets Complex biological processes, including organ development, immune response and disease progression, are inherently dynamic. Learning their regulatory architecture requires understanding how components of a large system dynamically interact with each other and give rise to emergent behavior. Recent experimental advances have made ii possible to investigate these biological systems in a data-driven fashion al high temporal resolution, allowing identification of new genes and their regulatory interactions. Longitudinal omics data sets are becoming increasingly common in clinical practice as well. Information on these collections of interacting genes can be integrated to gain systems-level insights into the roles of biological pathways and processes, including progression of diseases. Consequently, developing interpretable methods for learning functional relationships among genes, proteins or metabolites from high-dimensional time series data has become a timely research problem. The nature of these time-course data sets presents exciting opportunities and interesting challenges from a statistical perspective. Typical time-course omics data sets are challenging because of their high-dimensionality and non-linear relationships among system components. To tackle these challenges, one needs sophisticated dimension-reduction techniques that are biologically meaningful, computationally efficient and allow uncertainty quantification. Methods that incorporate prior biological information (e.g., pathway membership, protein-protein interactions) into the data analysis are good candidates for analyzing such high-dimensional systems using small samples. Here, we will develop three core methods to address the above challenges - (Aim 1): an empirical Bayes framework for clustering high-dimensional omics time-course data using prior biological knowledge; (Aim 2): a quantile-based Granger causality framework for learning interactions among genes or metabolites from their lead-lag relationships; and (Aim 3): a decision tree ensemble framework for searching cascades of interactions among genes from their temporal expression profiles. Our interdisciplinary team of statisticians and scientists will analyze time-course omics data from three research projects: (i) innate immune response systems in Drosophila, (ii) developmental process in mouse models, and (ii) longitudinal metabolite profiling of TB patients. These insights will be used to build and validate our methodology, which will be implemented in a publicly available software. This proposal is innovative in its incorporation of prior biological knowledge in the framework of novel dimension reduction techniques for interrogating high-dimensional time-course omics data. This research is significant in that it will impact basic sciences by elucidating data-driven, testable hypotheses on the regulatory architecture of biological processes, and clinical practice by monitoring disease progression and prognosis. n/a",Learning Dynamics of Biological Processes from Time Course Omics Datasets,9903643,R01GM135926,"['Biological Process', 'Data Set', 'Instruction', 'Learning', 'Time']",NIGMS,CORNELL UNIVERSITY,R01,2019,351443,0.012049302550707786
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9650596,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2019,472976,0.004719087116445649
"lntegration and Visualization of Diverse Biological Data PROJECT SUMMARY The onset of most human disease involves numerous molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway, and treatment contexts. This system is probed by thousands of functional genomics and quantitative genetic studies, and integrative analysis of these data can generate testable hypotheses identifying causal genetic variants and linking them to network level changes in cells to disease phenotypes. This can enable deeper molecular-level understanding of pathophysiology, paving the way to genome-based precision medicine.  The long term goal of this project is to enable such discoveries through integrative analysis of high- throughput biological data in a disease context. In the previous funding periods, we developed accurate data integration methods, created algorithms for the prediction of disease genes through context-specific and mechanistic network models and analysis of quantitative genetics data, and made novel insights into important biological processes and diseases. We further enabled experimental biological discovery by building public interactive systems capable of real-time user-driven integration that are popular among experimental biologists.  We now propose to connect these gene-level functional network approaches with the underlying genomic variation by deciphering how genomic variants lead to specific transcriptional and posttranscriptional effects. We propose to develop ab initio sequence-level models capable of predicting biochemical effects of any genomic variant (including rare or never observed) on chromatin state and RNA regulation, then link these effects with gene-level regulatory consequences (including tissue-specific transcription and RNA splicing), and finally put genomic sequence directly into the network context via a statistical approach for detecting genes and network neighborhoods with a significantly elevated mutational burden in disease. Our key deliverable will be a user- friendly, interactive web-based framework enabling systems-level variant impact analysis in a network context and an open source library for computational scientists. In addition to systematic analysis across contexts and diseases, we will collaborate with experimentalists to apply our methods to Alzheimer’s, autism spectrum disorders, chronic kidney disease, immune diseases, and congenital heart defects as case studies for the iterative improvement of our methods and to directly contribute to better understanding of these diseases. PROJECT NARRATIVE To pave the way for mechanistic interpretation of disease in the genomic context and eventually, precision medicine, we will develop algorithms for de novo prediction of functional biochemical effects of noncoding variants at the DNA regulation and RNA processing levels and then build frameworks for sequence-based prediction of tissue-specific transcription and post-transcriptional RNA processes (starting with splicing). To facilitate discovery of disease mechanisms, we will develop approaches for analyzing these variant effects in a network context, including those developed in the previous grant period (mechanistic and functional networks) and novel network models that integrate exon usage information or enhancer-gene interactions. In addition to verifying top predictions experimentally in our group or by our collaborators in case study areas of neurodegenerative disease, chronic kidney disease, ASD, and congenital heart disease, we will make our methods available to the broader biomedical community through public, interactive user interfaces and open source libraries.",lntegration and Visualization of Diverse Biological Data,9740445,R01GM071966,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Base Sequence', 'Binding', 'Biochemical', 'Biological', 'Biological Process', 'Case Study', 'Cell Lineage', 'Cells', 'Chromatin', 'Chronic Kidney Failure', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Congenital Heart Defects', 'DNA', 'Data', 'Data Analyses', 'Deoxyribonucleases', 'Disease', 'Enhancers', 'Exons', 'Feedback', 'Functional disorder', 'Funding', 'Genes', 'Genetic Transcription', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Grant', 'Histones', 'Hypersensitivity', 'Imagery', 'Immune System Diseases', 'Immunology', 'Knowledge', 'Laboratories', 'Lead', 'Letters', 'Libraries', 'Link', 'Measurement', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Neighborhoods', 'Nephrology', 'Network-based', 'Neurobiology', 'Neurodegenerative Disorders', 'Online Systems', 'Pathway Analysis', 'Pathway interactions', 'Post-Transcriptional Regulation', 'Process', 'Proteins', 'Quantitative Genetics', 'RNA', 'RNA Processing', 'RNA Splicing', 'RNA-Binding Proteins', 'Regulation', 'Research', 'Research Personnel', 'Scientist', 'System', 'Time', 'Tissue-Specific Gene Expression', 'Tissues', 'Untranslated RNA', 'Variant', 'autism spectrum disorder', 'base', 'biomedical scientist', 'causal variant', 'cell type', 'congenital heart disorder', 'crosslinking and immunoprecipitation sequencing', 'data integration', 'deep learning', 'disease phenotype', 'epigenomics', 'functional genomics', 'gene interaction', 'genetic variant', 'genome wide association study', 'genomic variation', 'high throughput analysis', 'human disease', 'improved', 'in vivo', 'insight', 'network models', 'novel', 'open source', 'precision medicine', 'prediction algorithm', 'predictive modeling', 'transcription factor', 'user-friendly']",NIGMS,PRINCETON UNIVERSITY,R01,2019,440312,-0.025713484735596454
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,9573854,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2018,388750,0.013767492593632474
"Machine Learning for Generalized Multiscale Modeling Project Summary/Abstract  This project develops machine learning approaches that describe statistical systems in biology. By combining analytic results calculated from the exact probabilistic description of the system with machine learning inference, our new methods present exciting opportunities to model previously inaccessible complex dynamics. The resulting Boltzmann machine-like learning algorithms present a new class of modeling techniques based on the powerful in- ference of arti cial neural networks. Further development of this approach will bring the groundbreaking advances from the surge of recent interest in machine learning into the biological modeling eld. The mathematical methods we develop will be used to derive e cient algorithms for multiscale simulation, directly applicable to large scale biological modeling. In particular, the algorithms will be used to study the dynamics of stochastic biochemistry at synapses, with direct relevance to learning and memory formation in the brain. Current studies of these processes are limited by the long timescales involved and the highly spatially organized structures featured. In addition to leveraging the machine learning expertise we are developing, we also employ new electron microscopy datasets to produce 3D reconstructions of neural tissue with unprecedented accuracy. Consequentially, we will be able to study the fundamental mechanisms underlying synaptic plasticity, as well as the biochemical basis of oscillatory behavior in networks of neurons that occurs during sleep. Furthermore, the interactions of these highly stochastic ion channels with electrical in neurons will be explored through groundbreaking hybrid simulation environments. The software that we will develop combines existing popular simulation tools into multiscale approaches, and will be distributed as a powerful tool to the broader biological modeling community. Its usage in further computational experiments can present a key advancement in the development of pharmaceuticals, allowing the direct study of the interactions of biochemistry and whole neuron electrophysiology without making limiting assumptions to sim- plify the simulations. This has promising implications for intervening in age-related learning de cits, as well as in neurological disorders such as Alzheimers. Finally, this proposal will bring together our existing multiscale modeling community, the National Center for Multi-scale Modeling of Biological Systems (MMBioS), with the MSM consortium. The interactions of these organizations and their communities of expert researchers will foster new collaborative work on exciting multiscale problems in biology, including applications of the machine learning frameworks and software we are developing. 1 Project Narrative  A wide variety of biological systems can be described statistically, from molecular biochemistry up to the network level activity of neurons. This work develops machine learning approaches to approximate these systems, enabling new simulation methods that bridge di erent levels of description. The resulting computational studies aim to shed light on the basis of learning and computation in the brain, and will enable the development of pharmaceutical targets for learning de cits associated with aging and neurological disorders such as Alzheimers. 1",Machine Learning for Generalized Multiscale Modeling,9791802,R56AG059602,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Area', 'Behavior', 'Biochemical', 'Biochemistry', 'Biological Models', 'Biological Neural Networks', 'Biology', 'Brain', 'Calcium', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consequentialism', 'Coupling', 'Data Set', 'Development', 'Dimensions', 'Electron Microscopy', 'Electrophysiology (science)', 'Environment', 'Equation', 'Equilibrium', 'Evolution', 'Fostering', 'Hybrids', 'Image', 'Investigation', 'Ion Channel', 'Learning', 'Libraries', 'Light', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'National Institute of General Medical Sciences', 'Neurons', 'Neuropil', 'Neurosciences', 'Pharmacologic Substance', 'Physics', 'Population', 'Potassium Channel', 'Process', 'Pythons', 'Reaction', 'Research Personnel', 'Sleep', 'Structure', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Time', 'Tissues', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'age related', 'base', 'biological systems', 'calmodulin-dependent protein kinase II', 'computer studies', 'experimental study', 'information processing', 'insight', 'interest', 'mathematical methods', 'men who have sex with men', 'microscopic imaging', 'multi-scale modeling', 'nervous system disorder', 'particle', 'postsynaptic', 'reconstruction', 'relating to nervous system', 'simulation', 'software development', 'success', 'tool', 'working group']",NIA,UNIVERSITY OF CALIFORNIA-IRVINE,R56,2018,619053,-0.003981391721788785
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.02221064280456422
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.020416337361181876
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9467327,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Algorithms', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Image Analysis', 'Kinetics', 'Laboratories', 'Locomotion', 'Machine Learning', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2018,510448,0.010128932316208327
"A Modular Automated Platform for Large-scale Drosophila Experiments and Handling PROJECT SUMMARY / ABSTRACT Animal model systems are a powerful tool researchers use to investigate almost all aspects of biology: genetics, development, neuroscience, disease, and more. And fruit flies – Drosophila melanogaster – with their small size, easy care, and remarkable array of available genetic toolkits, occupy a sweet spot on the model organism spectrum. Over 75% of human diseases with a genetic basis have an analogue in the fly, and Drosophila have been a part of the research for six Nobel prizes. Furthermore, the advent of CRISPR/cas9 and other modern genetic tools has opened the door to modeling other diseases and pathways, leading to greater use of Drosophila for drug screens. A great deal of the work (and the majority of the budget) involved in fly experiments is tedious manual labor, and with advances in computer vision, machine learning, and other analytic techniques, the stage is set to automate many phenotypic screens. In this Phase I SBIR, we propose a robotic system – modular automated platform for large-scale experiments (MAPLE) – that can accomplish a wide variety of fly-handling tasks in Drosophila labs. This robot is the fruit fly version of a liquid handling robot, with a large, open workspace that can house a plethora of modules and several manipulators that can move small parts and animals around that workspace. Building on a collaboration between the de Bivort Lab and FlySorter completed in 2017, we will design, fabricate and validate a commercial system that can collect virgin flies, run behavioral assays, conduct drug screens, and adapt to the needs of fly labs through easy-to-code Python scripts. By strategically combining modules and instructions to the robot, MAPLE can perform a wide variety of tasks in a fly lab, saving experimentalists from repetitive chores, cutting labor costs, and increasing scientific output. Just as pipette robots have become standard equipment in wet labs, we envision our fly handling robot will be the engine that powers Drosophila labs in academia and pharma, enabling new kinds of experiments and freeing researchers from the drudgery of fly pushing. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are a powerful model organism used in the study of disease, neuroscience, development, genetics, and recently in drug screens, too, largely through phenotypic screening. This labor-intensive work is time consuming and expensive, and ripe for automation. We propose a fly-handling robot – analogous to a liquid pipetting robot in a wet lab – that can perform a variety of tasks in Drosophila labs, free researchers from the drudgery of fly pushing, and enable a broader spectrum of experiments that will increase scientific knowledge.",A Modular Automated Platform for Large-scale Drosophila Experiments and Handling,9623017,R43MH119092,"['Academia', 'Address', 'Affect', 'Air', 'Anesthesia procedures', 'Animal Model', 'Animals', 'Architecture', 'Automation', 'Basic Science', 'Behavior', 'Behavioral Assay', 'Biological Models', 'Biology', 'Budgets', 'CRISPR/Cas technology', 'Carbon Dioxide', 'Caring', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Data Collection', 'Deposition', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Screening', 'Drug usage', 'Ensure', 'Equipment', 'Feedback', 'Genetic', 'Genetic Screening', 'Genetic study', 'Grant', 'Hand', 'Human', 'Instruction', 'Knowledge', 'Libraries', 'Liquid substance', 'Machine Learning', 'Manuals', 'Modeling', 'Modernization', 'Neurosciences', 'Nobel Prize', 'Organism', 'Output', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Protocols documentation', 'Pythons', 'Reagent', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Running', 'Savings', 'Scanning', 'Small Business Innovation Research Grant', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Transgenic Organisms', 'Travel', 'Universities', 'Update', 'Vacuum', 'Work', 'analog', 'bone', 'cost', 'design', 'drug discovery', 'experimental study', 'flexibility', 'fly', 'graduate student', 'health science research', 'human disease', 'improved', 'operation', 'programs', 'repository', 'robot control', 'screening', 'tool', 'touchscreen']",NIMH,"FLYSORTER, LLC",R43,2018,348007,-0.008063593669882374
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9543557,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,264277,0.02283770411693198
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9451318,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2018,1354554,0.05162380155511625
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9635840,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Awareness', 'Basic Science', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathogenicity', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacology', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2018,854309,0.013066987901127116
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9482419,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modality', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genetic architecture', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,455772,0.008499231432157516
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9517061,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'data warehouse', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2018,306284,-0.009682151479794487
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9415436,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Expert Systems', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic Diseases', 'Genetic study', 'Goals', 'Gold', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'Supervision', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'experimental study', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'public health relevance', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2018,445349,0.03939102503611322
"Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery PROJECT SUMMARY Protein post-translational modification (PTM) plays a critical role in many diseases; however, critical gaps remain in research infrastructure for global analysis of PTMs. Key PTM information concerning enzyme- substrate relationships, regulation of PTM enzymes, PTM cross-talk, and functional consequences of PTM remains buried in the scientific literature. Meanwhile, while high-throughput panomics (genomic, transcriptomic, proteomic, PTM proteomic) data offer an unprecedented opportunity for the discovery of PTM-disease relationships, the data must be analyzed in an integrated and easily accessible knowledge framework in order for researchers and clinicians to gain a molecular understanding of disease. The goal of this application is to develop a collaborative knowledge environment for semantic annotation of scientific literature and integrative panomics analysis for PTM-disease knowledge discovery in precision medicine. We propose to connect PTM information from literature mining and curated databases in a knowledge resource on an ontological framework that supports analysis of panomics data in the context of PTM networks. To broaden impact and foster collaborative development, our resource will be FAIR (Findable, Accessible, Interoperable, Reusable) and interoperable with community standards.  The specific aims are: (i) develop a novel NLP (natural language processing) system for full-scale literature mining and PTM-disease knowledge extraction; (ii) develop a PTM knowledge resource for integrative panomics analysis and network discovery; and (iii) provide a FAIR collaborative environment for scalable semantic annotation and knowledge integration. The proposed system will build upon the NLP technologies and text mining tools already developed by our team and the bioinformatics infrastructure at the Protein Information Resource (PIR). The iPTMnet web portal will allow searching, browsing, visualization and analysis of PTM networks and PTM-related mutations in conjunction with user-supplied omics data, including panomics data from major national initiatives. Use scenarios will include identification of disease-driving genetic variants and analysis of cellular responses to kinase inhibitors. Our PTM knowledgebase will be disseminated with an RDF triple-store and a SPARQL endpoint for semantic queries, while our text mining tools and full-scale literature mining results will be disseminated in the BioC community standard for seamless integration to other text mining pipelines. To engage the community semantic annotation of scientific literature, we will host a hackathon to develop tools to expose BioC-annotated literature corpora to the semantic web, as well as an annotation jamboree to explore tagging of scientific text with precise ontological terms. This project will thus offer a unique research resource for PTM-disease network discovery as well as an integrable collaborative knowledge framework to support Big Data to Knowledge in precision medicine. PROJECT NARRATIVE Precision medicine requires a detailed understanding of the molecular events that are disrupted in disease, including changes in protein post-translational modifications (PTM) that are hallmarks of many diseases. The proposed resource will support analysis of genomic-scale data for exploring PTM-disease networks and PTM-related mutations, as well as knowledge dissemination on the semantic web. These combined efforts will accelerate basic understanding of disease processes and discovery of diagnostic targets and more effective individualized therapies.",Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery,9532909,U01GM120953,"['Address', 'Adopted', 'Automobile Driving', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cells', 'Clinical', 'Communities', 'Controlled Vocabulary', 'Custom', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Drug resistance', 'Educational workshop', 'Environment', 'Enzymes', 'Europe', 'Event', 'Exposure to', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Genomics', 'Goals', 'Graph', 'Hybrids', 'Imagery', 'Information Resources', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Length', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Mutation', 'Names', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Phosphorylation', 'Phosphotransferases', 'Play', 'Post Translational Modification Analysis', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Post-Translational Regulation', 'Process', 'Protein Family', 'Proteins', 'Proteomics', 'PubMed', 'Publications', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Site', 'System', 'Technology', 'Text', 'Tissues', 'Translational Research', 'Variant', 'bioinformatics resource', 'cell type', 'collaborative environment', 'computer based Semantic Analysis', 'enzyme substrate', 'genetic analysis', 'genetic variant', 'hackathon', 'indexing', 'individualized medicine', 'information organization', 'innovation', 'interoperability', 'kinase inhibitor', 'knowledge base', 'knowledge integration', 'novel', 'precision medicine', 'protein complex', 'protein protein interaction', 'response', 'system architecture', 'text searching', 'therapeutic target', 'tool', 'transcriptomics', 'web portal', 'web services', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,U01,2018,365327,-0.0044823003166581995
"A Systems Biology Approach to Investigate the Structure Changes of Biological Network Project Summary/Abstract Networks have been widely used to describe many biological processes. Understanding the structure of biological network, especially regulatory network, will provide a key to discovering the mechanisms underlying important biological processes and pathogenesis of diseases. One of the most challenging tasks in systems biology is how to correctly reconstruct the networks from the high-dimensional data generated by modern genomic technology. Most network inference methods assume the network structure is time-invariant. Some recent studies revealed the structures of some biological networks are non-stationary or time-varying. For example, the neural information flow networks of brains are changing during learning process. Importantly, cancer studies found the native T cells would be converted into senescent T cells due to the structure changes of genetic network during tumorigenesis. The stationary network inference methods can't be used to reconstruct the time-varying network. Non-stationary network inference methods are urgently needed to investigate the time-varying networks at different stages. Some researchers have attempted to develop some time-varying network inference methods. However, the inferred networks using existing methods are only correlation or causality graphs, not regulatory networks which require activation & inhibition information. This project aims to develop novel non-stationary network inference methods to reconstruct time-varying regulatory networks from time series data. Since the networks are highly complex, it is not realistic to manually verify large networks as being used by the traditional methods. We will develop a powerful Model Checker, which is a Turing Award winning technique for hardware system verification, to intelligently verify the inferred time-varying networks. Our long-term goal is to integrate the statistical inference and model checking techniques in a unified platform to automatically reconstruct and verify time-varying networks. This integrative systems biology approach will make the large-network inference and verification automatic, intelligent and efficient. Recent cancer studies show that, restoring senescent T cells represents a promising strategy for cancer treatment. In collaboration with cancer immunologist, we will apply computational-experimental approaches to investigate what structure changes of the genetic network and how they induce T-cell's functional changes and influence its fate decision making from naive T-cells to senescent T-cells. Answering these questions will significantly improve our understanding of the mechanisms underlying the T cell differentiation during tumorigenesis. Public Health Relevance/Narrative This project aims to develop a novel systems biology approach to reconstruct the time-varying biological networks from high-dimensional data in collaboration with the cancer immunologist. The proposed research has relevance to public health, because it seeks to investigate what and how the structure changes of genetic network induce the T-cell's functional changes during tumorigenesis, which will ultimately improve our understanding of the mechanisms underlying the T cell differentiation and cancer.",A Systems Biology Approach to Investigate the Structure Changes of Biological Network,9655801,R15GM129696,"['Algorithms', 'Attention', 'Award', 'Bayesian Modeling', 'Biological', 'Biological Process', 'Brain', 'Cancer Immunology Science', 'Cells', 'Code', 'Collaborations', 'Complex', 'Data', 'Databases', 'Decision Making', 'Development', 'Disease', 'Drosophila genus', 'Etiology', 'Evolution', 'Gene Structure', 'Genetic', 'Genomics', 'Goals', 'Graph', 'Immunologist', 'Knowledge', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Location', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Muscle Development', 'Mutation', 'Pathogenesis', 'Process', 'Public Health', 'Regulator Genes', 'Regulatory T-Lymphocyte', 'Research', 'Research Personnel', 'Series', 'Structure', 'System', 'Systems Biology', 'T cell differentiation', 'T-Lymphocyte', 'Techniques', 'Technology', 'Time', 'Work', 'base', 'cancer therapy', 'computer studies', 'exhaust', 'experimental study', 'high dimensionality', 'improved', 'neoplastic cell', 'next generation sequencing', 'novel', 'public health relevance', 'reconstruction', 'relating to nervous system', 'senescence', 'tool', 'tumor microenvironment', 'tumorigenesis']",NIGMS,SAINT LOUIS UNIVERSITY,R15,2018,454500,-0.0017685376209365204
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9452089,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Gene Targeting', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2018,591415,0.004719087116445649
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9559432,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2018,325325,0.011761031797161942
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9699855,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,75000,0.015887793761347527
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9537614,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,329257,0.015887793761347527
"Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome PROJECT SUMMARY/ABSTRACT  The major goal of this RC2 proposal is to generate the first, multi-omics translational study capturing the sum of environmental exposures (i.e. the exposome) and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without effective medical therapy. PSC shortens survival, is associated with inflammatory bowel disease (IBD) and strongly predisposes to cholangiocarcinoma (i.e. bile duct cancer) and colon cancer. Our recent genome wide association studies (GWAS) revealed the significant role of genetic variation in PSC, while also re-emphasizing the importance of environmental factors and gene-environment interactions in PSC pathogenesis. To further elucidate the role of exposures from our external environment and lifestyle (e.g., diet, stress, toxins, drugs, microbes), we have assembled a world-class, multi-disciplinary team that synergizes expertise and resources across four institutions: Mayo Clinic, Emory University, University of Illinois Urbana-Champaign (UIUC), and University of Oslo, Norway. Our collaborative team will leverage large clinical databases and biorepositories, as well as expertise in PSC and related conditions, exposomics, metabolomics, methylomics, transcriptomics, metagenomics, genomics, and data analytics to develop the PSC Scientific Community Resource for hypothesis-generating science and simultaneously uncover factors contributing to PSC.  We now seek to define the bigger-picture cellular networks, rather than individual genes, driving disease processes. To do so, we will use unbiased network-based approaches designed to integrate multiple layers of omics data. Our proposal is predicated on the hypothesis that multi-omics analyses of data capturing environmental exposures and the associated biological responses, including the effect on the genome, will reveal networks or pathways influencing PSC pathogenesis and outcomes. To test this hypothesis, we will perform a series of sophisticated analyses to identify PSC-associated changes in and across the exposome, metabolome, methylome, and transcriptome in blood as well as the gut metagenome, exposome and metabolome.  Our collaboration and data generation are already underway with pilot studies demonstrating differences in blood exposomes and metabolomes and stool metagenomes between PSC patients and controls. Using a suite of bioinformatic tools and available genetic variation data, we aim to discover stable, detectable, omics-based disease signatures in blood (Aim 1) and stool (Aim 2) that when integrated with clinical data (Aim 3) will reveal biological pathways driving disease pathogenesis and outcomes. All data, residual specimens, and analytical details will be made freely available to the research community in accordance with NIDDK's mission. Furthermore, this effort responds to the NIDDK's call “to better understand the role of the microbiome, genetics, and exposome.” PROJECT NARRATIVE We seek to generate the first, multi-omics translational study and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without medical therapy. We will define the bigger-picture cellular networks and gene-environment interactions driving PSC by integrating multiple layers of -omics data. In so doing, we will identify molecular disease signatures, including environmental toxins, metabolism-related chemicals and gut bacteria, unique to PSC patients.",Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome,9592939,RC2DK118619,"['Accounting', 'Address', 'Age', 'Automobile Driving', 'Bile duct carcinoma', 'Bioinformatics', 'Biological', 'Blood', 'Chemical Exposure', 'Chemicals', 'Childhood', 'Cholangiocarcinoma', 'Cholestasis', 'Chronic', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Colon Carcinoma', 'Communities', 'DNA Methylation', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Diet', 'Disease', 'Environment', 'Environmental Exposure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feces', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Graph', 'High Performance Computing', 'Illinois', 'Individual', 'Inflammatory Bowel Diseases', 'Inflammatory disease of the intestine', 'Institution', 'Life Style', 'Light', 'Link', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Medical', 'Metagenomics', 'Microbe', 'Mission', 'Modeling', 'Molecular Disease', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Network-based', 'Norway', 'Onset of illness', 'Outcome', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Research', 'Residual state', 'Resolution', 'Resources', 'Role', 'Science', 'Series', 'Shotguns', 'Specimen', 'Stress', 'Sum', 'Systems Biology', 'Taxonomy', 'Testing', 'Toxic Environmental Substances', 'Toxin', 'Universities', 'base', 'biobank', 'data integration', 'data resource', 'design', 'gene environment interaction', 'genome wide association study', 'genomic data', 'gut bacteria', 'gut metagenome', 'gut microbiota', 'improved', 'innovation', 'liver transplantation', 'metabolome', 'metabolomics', 'metagenome', 'methylation pattern', 'methylome', 'methylomics', 'microbial', 'microbiome', 'multidisciplinary', 'multiple omics', 'novel', 'patient population', 'peripheral blood', 'personalized approach', 'pollutant', 'primary outcome', 'primary sclerosing cholangitis', 'programs', 'response', 'sex', 'tool', 'toxin metabolism', 'transcriptome', 'transcriptomics', 'translational study']",NIDDK,MAYO CLINIC ROCHESTER,RC2,2018,1622560,0.0018562664859371645
"HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS DESCRIPTION (provided by applicant): The aim of this proposal is to implement a novel way of processing and accessing the vast detailed knowledge contained within collections of scientific publications on the regulation of transcription initiation in bacterial models. In princple, this model for processing and reading information and new knowledge is applicable to other biological domains, potentially benefiting any area of biomedical knowledge. It is certainly criticl to generate new strategies to cope with the ever-increasing amount of knowledge generated in genomics and in biomedical research at large. Improving the efficiency of the traditional high-quality manual curation of scientific publications will enable us also to expand the type of biological knowledge, beyond mechanisms and their elements in the genome, to start including their connections with larger regulated processes and eventually physiological properties of the cell. We will first implement the necessary technology to improve our curation by means of a computational system that has text mining capabilities for preprocessing the papers before a human expert curator identifies which sentences contain the information that is to be added to the database. Premarked options selected by the curators will accelerate their decisions. The accumulative precise mapping between sentences and curated knowledge will provide training sets for text mining technologies to improve their automatic extraction. The curator practices will become more efficient, enabling us to curate selected high-impact published reviews to place mechanisms into a rich context of their physiological processes and general biology. Another relevant component of our proposal is the improved modeling of regulated processes by means of new concepts in biology that capture larger collections of coregulated genes and their concatenated reactions. Starting from all interactions of a local regulator, coregulated regulators and their domain of action will be incorporated to construct the biobricks of complex decisions, as they are encoded in the genome. These are conceptual containers that capture the organization of knowledge to describe the genetic programming of cellular capabilities. These proposals will be formalized and proposed within an international consortium focused in enriching standard models or ontologies of gene regulation for use by the scientific community. Finally, a portal to navigate across all the sentences of a given corpus of a large number (more than 5,000) of related papers will be implemented. The different avenues of navigation will essentially use two technologies, one dealing with automatically generating simpler sentences from original sentences as input, and the other one with the classification of papers based on their theme or ontology. Their combination will enable a novel navigation reading system. If we achieve our aims, this project will give a proof-of-principle prototype with clearly innovative higher levels of large amounts of integrated knowledge. Future directions may adapt these concepts and methods to the biology of higher organisms, including humans. PUBLIC HEALTH RELEVANCE: Scientific knowledge reported within publications provides a wealth of knowledge that we barely capture in databases for genomics. Enhancing the effectiveness of the processing and representation of all this knowledge will change the way we encode our understanding of concatenated interactions that are organized into networks and processes governing cell behavior. Given the conservation in evolution of the nature of biological complexity, a better encoding of our understanding of a bacterial cell shall influence that of any other living organism.",HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS,9407024,R01GM110597,"['Area', 'Bacteria', 'Bacterial Model', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Classification', 'Collection', 'Communities', 'Complex', 'Data Set', 'Databases', 'Effectiveness', 'Elements', 'Escherichia coli', 'Evolution', 'Foundations', 'Future', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Human', 'International', 'Joints', 'Knowledge', 'Letters', 'Linguistics', 'Literature', 'Manuals', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Nature', 'Ontology', 'Operon', 'Organism', 'Paper', 'Physiological', 'Physiological Processes', 'Planet Earth', 'Process', 'Property', 'Publications', 'Publishing', 'Reaction', 'Reading', 'Regulation', 'Regulon', 'Reporting', 'Research Infrastructure', 'Series', 'Signal Transduction', 'Site', 'Solid', 'Source', 'System', 'Technology', 'Text', 'Training', 'Transcription Initiation', 'Transcriptional Regulation', 'base', 'cell behavior', 'digital', 'electronic book', 'experience', 'feeding', 'functional genomics', 'improved', 'innovation', 'member', 'microbial community', 'model organisms databases', 'novel', 'novel strategies', 'promoter', 'prototype', 'public health relevance', 'response', 'software development', 'text searching', 'tool', 'transcription factor', 'usability']",NIGMS,CENTER FOR GENOMIC SCIENCES,R01,2018,395628,0.014643009634566743
"Quantitative microscopy-based rapid phenotyping and screening ﻿    DESCRIPTION:  Synapses are most fundamental to the function of a nervous system. C. elegans is an excellent genetic model system for finding genes and elucidating pathways because of its sequenced genome and the abundance of molecular biology tools and mutants. Due to the simplicity of its nervous system, many breakthroughs have been made in C. elegans for understanding molecular mechanisms in the patterning of the nervous system and synapse development. The current bottlenecks are in the manual and non-quantitative techniques such as visual screens, limiting both the throughput of the experiments and the phenotypes one can examine. Our long-term objective is to develop technologies and to understand how genes, age, and the environment together define and continue to remodel the nervous system of an organism. In the last funding period, we have made large progress in hardware system design (including microtechnologies and automation technologies) and software for quantitative characterization of phenotypes. The objective of this continuation project is to further engineer superior micro devices for large-scale live imaging and quantitative imaging technologies, and combine with the power of genetic and genomic approaches to study synapse development in this in vivo system; genes and pathways emerging from this study could potentially become targets of therapeutics in neurological disorders.  We have shown in the previous phase of the project that quantitative microscopy-based approaches can indeed enable identification of novel genes and pathways that conventional approaches cannot. In the continuation phase, we will further optimize on-chip rapid and high-content in vivo imaging techniques, and in parallel further develop algorithms and quantitative measures for the analysis of such high-content data; we will screen based on novel synthetic phenotype unobservable by eye; we will also exploit powerful genomic techniques to identify loci and potential multigenic interactions that shape the synapse morphology. These experimental approaches will identify genes that cannot have been identified otherwise because of the difficulties associated with the phenotypical profiling, but addressed using our engineered techniques here. The approach is innovative because the technology developed here dramatically increases the throughput, sensitivity, and accuracy of the experiments, and truly enables the utility of extremely powerful genetic and genomic methods. The proposed research is significant because it fills the urgent need in high-throughput and high-content screens as well as identifying novel genes and pathways. In addition, besides the contribution to the specific neurobiology, the technologies are widely applicable to areas such as developmental cell biology, and to other small organisms such as fly larvae and zebrafish embryos. PUBLIC HEALTH RELEVANCE:   Synapse development is an important and active area of research linking genes and environments to the formation and maintenance of synapses in the nervous system. It has direct implications in many human diseases developmental and psychiatric diseases such as Autism Spectrum Disorder and Schizophrenia.",Quantitative microscopy-based rapid phenotyping and screening,9502988,R01GM088333,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alleles', 'Animals', 'Area', 'Automation', 'Biological Models', 'Biology', 'Caenorhabditis elegans', 'Chromosome Mapping', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Developmental Cell Biology', 'Devices', 'Disease', 'Drosophila genus', 'Embryo', 'Engineering', 'Environment', 'Event', 'Eye', 'Fill-It', 'Fluorescence', 'Funding', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Research', 'Genetic Screening', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Inbreeding', 'Larva', 'Lead', 'Link', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Microfluidics', 'Microscopy', 'Molecular', 'Molecular Biology', 'Morphology', 'Nematoda', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurons', 'Organism', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Phylogeny', 'Positioning Attribute', 'Quantitative Microscopy', 'Quantitative Trait Loci', 'Regulatory Pathway', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Speed', 'Synapses', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Vision', 'Visual', 'Work', 'Zebrafish', 'autism spectrum disorder', 'base', 'design', 'developmental disease', 'experience', 'experimental study', 'fly', 'forward genetics', 'genetic approach', 'high dimensionality', 'high throughput screening', 'human disease', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'mutant', 'nerve injury', 'nervous system disorder', 'novel', 'programs', 'public health relevance', 'quantitative imaging', 'screening', 'success', 'synaptogenesis', 'targeted treatment', 'technology development', 'tool', 'trait']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,305174,0.01069010436719535
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9365558,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Cereals', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Models', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'molecular modeling', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,264299,0.02283770411693198
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.02221064280456422
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,0.004991599184346028
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9209155,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2017,1354554,0.05162380155511625
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9324260,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modality', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2017,101908,0.008499231432157516
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design New technologies afford the acquisition of dense “data clouds” of individual humans. However, heterogeneity, dimensionality and multi-scale nature of such data (genomes, transcriptomes, clinical variables, etc.) pose a new challenge: How can one query such dense data clouds of mixed data as an integrated set (as opposed to variable by variable) against multiple knowledge bases, and translate the joint molecular information into the clinical realm? Current lexical mapping and brute-force data mining seek to make heterogeneous data interoperable and accessible but their output is fragmented and requires expertise to assemble into coherent actionable information. We propose DeepTranslate, an innovative approach that incorporates the known actual physical organization of biological entities that are the substrate of pathogenesis into (i) networks (data graphs) and (ii) hierarchies of concepts that span the multiscale space from molecule to clinic. Organizing data sources along such natural structures will allow translation of burgeoning high-dimensional data sets into concepts familiar to clinicians, while capturing mechanistic relationships. DeepTranslate will take a hybrid approach to learn and organize its content from both (i) existing generic comprehensive knowledge sources (GO, KEGG, IDC, etc.) and (ii) newly measured instances of individual data clouds from two demonstration projects: (1) ISB’s Pioneer 100 and (2) St. Jude Lifetime cancer survivors. We will focus on diabetes as test case. These two studies cover a deep biological scale-space and thus can test the full extent of the multiscale capacity of DeepTranslate in a focused application. 1. TYPES OF RESEARCH QUESTION ENABLED. How can a clinician find out that the dozens of “out of range” variables observed in a patient’s data cloud, form a connected set with respect to pathophysiology pathways, from gene to clinical variable? How can the high-dimensional data of studies that measure for each individual 100+ data points of various types (“personal data clouds”) be analyzed as one set in an integrated fashion (as opposed to variable by variable) against existing knowledge bases and also be used to improve the databases? DeepTranslate addresses these two types of questions and thereby will accelerate translation of future personal data clouds into (A) care decisions and (B) hypotheses on new disease mechanisms / treatments, thereby benefiting providers as well as researchers. 2. USE OF EXPERTISE AND RESOURCES. ■ ISB: pioneer in personalized, big-data driven medicine (Demo Project 1); biomedical content expertise; multiscale omics and molecular pathogenesis, big data analysis, housing of databases for public access; query engine designs, GUI. ■ UCSD: leader in biomedical data integration; automated assembly of molecular and clinical data into hierarchical structures; translation between data types ■ U Montreal: biomedical database curation from literature and construction of gene/protein/drug interaction networks; machine learning, open resource database ■ St Jude CRH: Cancer monitoring Demo Project 2, cancer patient data analytics. 3. POTENTIAL DATA AND INFRASTRUCTURE CHALLENGES. (a) Existing comprehensive clinical data sources are not uniform and not explicitly based on biological networks; cross-mapping is being performed at NLM based on lexical relationships: HPO (phenotypes) vs. SNOMED CT (for EMR) vs. IDC or Merck Manual (for diseases). Careful selection of these sources in close collaboration with NLM is needed. (b) Existing molecular pathway databases are static, based on averages of heterogeneous non-stratified populations, while the newly measured high-dimensional data clouds are varied due to intra-individual temporal fluctuation and inter-individual variation. How this will affect building of ontotypes in our hybrid approach, and how large cohorts of data clouds must be to offer statistical power is yet to be determined. Our two Demonstration Projects with their uniquely deep (high-dimensional and multiscale) data in cohorts of limited but growing size are thus crucial first steps in a long journey of collective learning in the TRANSLATOR community. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9486059,OT3TR002026,"['Address', 'Affect', 'Architecture', 'Big Data', 'Biological', 'CRH gene', 'Cancer Patient', 'Cancer Survivor', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Drug Interactions', 'Functional disorder', 'Future', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Graph', 'Heterogeneity', 'Housing', 'Human', 'Hybrids', 'Individual', 'Joints', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medicine', 'Molecular', 'Monitor', 'Nature', 'Output', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Provider', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'SNOMED Clinical Terms', 'Saint Jude Children&apos', 's Research Hospital', 'Source', 'Structure', 'Testing', 'Translating', 'Translations', 'base', 'cohort', 'data integration', 'data mining', 'design', 'high dimensionality', 'improved', 'innovation', 'inter-individual variation', 'interoperability', 'knowledge base', 'lexical', 'molecular assembly/self assembly', 'new technology', 'transcriptome']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT3,2017,1408263,0.026939851862267064
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9306122,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2017,306527,-0.009682151479794487
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9298691,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Dimensions', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Intuition', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Mining', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Analysis', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Scientist', 'Structure', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'big biomedical data', 'clinical phenotype', 'clinical predictors', 'cohort', 'computerized data processing', 'computerized tools', 'crowdsourcing', 'data management', 'data mining', 'data modeling', 'data resource', 'data to knowledge', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'molecular scale', 'multiple omics', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'support tools', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2017,168436,-0.029613069944006743
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9266422,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Expert Systems', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'Supervision', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'experimental study', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'public health relevance', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2017,445349,0.03939102503611322
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design A fundamental challenge to translate insights between biomedical researchers, who study biological mechanisms, and clinicians, who diagnose patient symptoms, is that many links between biological processes and disease pathophysiology are poorly understood. A comprehensive Biomedical Translator must enable chains of inference across objects as diverse as genetic mutations, molecular effects, tissue-specific expression patterns, cellular processes, organ phenotypes, disease states, patient symptoms, and drug responses, a challenge beyond the scope of any one organization. Fortunately, many individual links in this chain have been made by experiments yielding statistical connections between individual data types. High-throughput perturbation screens link chemical and genetic perturbations to cellular phenotypes such as gene-expression patterns, cell survival, or changes in phosphorylation. Genetic association studies link mutations to human disease or intermediate phenotypes and biomarkers. Electronic medical records (EMR) link diseases or human phenotypes to diagnostic or current procedural terminology (CPT) codes, and clinical trials link the impact of drugs and drug candidates on disease states. In principle, incorporating these links into chains of inference could translate results between the full set of data types within them. In practice, each link is maintained by experts with domain-specific experiments, semantic terminology, and methodological standards. While a key challenge faced by a global Biomedical Translator is to establish consistent standards across these existing data types, a more important goal is to develop a principled and robust framework to (a) model biological systems and experimental approaches to investigate them; (b) organize knowledge about biological mechanism and disease; and (c) incorporate diverse datasets that serve as windows into the underlying and unknown state of nature. We propose to implement a Biomedical Translator as a probabilistic graphical model, a paradigm from artificial intelligence (AI) research. Just as separate research communities form weakly coupled parts of the translation process, graphical models allow global inferences from weakly coupled “nodes”. These inferences require each node to publish only probability distributions, enabling interoperability without necessarily having global entity-resolution standards, and benefit from paradigms for quality control, fault tolerance, and relevance assessment common in AI research. We hypothesize that a limited number of APIs, implemented as probability computations by communities around the world, would yield a Biomedical Translator as an emergent property of weakly coupled knowledge sources. From basic properties of graphical models, such a Translator could probabilistically translate among any data types connected within it, allowing for relatively complex query concepts. For example: What cellular processes in which tissues are impacted in a patient-based EMR? What genetic mutations sensitize cells to small-molecule treatment effects? Which small molecules mimic genetic “experiments of nature” that protect against disease? To illustrate the value of these resources and our architectural paradigm, we propose a demonstration project to implement a Biomedical Translator supporting queries between small molecules, biological processes, genes, and disease. The demonstration project will provide a valuable first step to confront key data-integration and organizational challenges and will enable previously impossible queries, such as identifying small molecules that perturb the same biological processes implicated by human genetics in a disease context. In this capacity, such Translator could realistically identify existing drugs for known symptoms (i.e., repurposing), but could more broadly serve as an engine for hypothesis generation and biological discovery, suggesting pre-clinical small molecules to develop based on their observed biological activity, or providing heretofore novel links between cellular protein function and disease pathophysiology. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9540181,OT3TR002025,"['Architecture', 'Artificial Intelligence', 'Biological', 'Biological Models', 'Biological Process', 'Cell Survival', 'Cell physiology', 'Cells', 'Clinical Trials', 'Communities', 'Complex', 'Computerized Medical Record', 'Coupled', 'Current Procedural Terminology Codes', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Functional disorder', 'Gene Expression Profile', 'Generations', 'Genetic', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Link', 'Methodology', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Organ', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Probability', 'Processed Genes', 'Property', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Semantics', 'Source', 'Symptoms', 'Terminology', 'Tissues', 'Translating', 'Translation Process', 'base', 'biological systems', 'chemical genetics', 'data integration', 'design', 'drug candidate', 'experimental study', 'genetic association', 'human disease', 'insight', 'interoperability', 'novel', 'phenotypic biomarker', 'pre-clinical', 'protein function', 'response', 'small molecule', 'treatment effect']",NCATS,"BROAD INSTITUTE, INC.",OT3,2017,651119,0.016299696215911142
"Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery PROJECT SUMMARY Protein post-translational modification (PTM) plays a critical role in many diseases; however, critical gaps remain in research infrastructure for global analysis of PTMs. Key PTM information concerning enzyme- substrate relationships, regulation of PTM enzymes, PTM cross-talk, and functional consequences of PTM remains buried in the scientific literature. Meanwhile, while high-throughput panomics (genomic, transcriptomic, proteomic, PTM proteomic) data offer an unprecedented opportunity for the discovery of PTM-disease relationships, the data must be analyzed in an integrated and easily accessible knowledge framework in order for researchers and clinicians to gain a molecular understanding of disease. The goal of this application is to develop a collaborative knowledge environment for semantic annotation of scientific literature and integrative panomics analysis for PTM-disease knowledge discovery in precision medicine. We propose to connect PTM information from literature mining and curated databases in a knowledge resource on an ontological framework that supports analysis of panomics data in the context of PTM networks. To broaden impact and foster collaborative development, our resource will be FAIR (Findable, Accessible, Interoperable, Reusable) and interoperable with community standards.  The specific aims are: (i) develop a novel NLP (natural language processing) system for full-scale literature mining and PTM-disease knowledge extraction; (ii) develop a PTM knowledge resource for integrative panomics analysis and network discovery; and (iii) provide a FAIR collaborative environment for scalable semantic annotation and knowledge integration. The proposed system will build upon the NLP technologies and text mining tools already developed by our team and the bioinformatics infrastructure at the Protein Information Resource (PIR). The iPTMnet web portal will allow searching, browsing, visualization and analysis of PTM networks and PTM-related mutations in conjunction with user-supplied omics data, including panomics data from major national initiatives. Use scenarios will include identification of disease-driving genetic variants and analysis of cellular responses to kinase inhibitors. Our PTM knowledgebase will be disseminated with an RDF triple-store and a SPARQL endpoint for semantic queries, while our text mining tools and full-scale literature mining results will be disseminated in the BioC community standard for seamless integration to other text mining pipelines. To engage the community semantic annotation of scientific literature, we will host a hackathon to develop tools to expose BioC-annotated literature corpora to the semantic web, as well as an annotation jamboree to explore tagging of scientific text with precise ontological terms. This project will thus offer a unique research resource for PTM-disease network discovery as well as an integrable collaborative knowledge framework to support Big Data to Knowledge in precision medicine. PROJECT NARRATIVE Precision medicine requires a detailed understanding of the molecular events that are disrupted in disease, including changes in protein post-translational modifications (PTM) that are hallmarks of many diseases. The proposed resource will support analysis of genomic-scale data for exploring PTM-disease networks and PTM-related mutations, as well as knowledge dissemination on the semantic web. These combined efforts will accelerate basic understanding of disease processes and discovery of diagnostic targets and more effective individualized therapies.",Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery,9326315,U01GM120953,"['Address', 'Adopted', 'Automobile Driving', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cells', 'Clinical', 'Communities', 'Controlled Vocabulary', 'Custom', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Drug resistance', 'Educational workshop', 'Environment', 'Enzymes', 'Europe', 'Event', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Genomics', 'Goals', 'Graph', 'Hybrids', 'Imagery', 'Information Resources', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Length', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'MicroRNAs', 'Mining', 'Modification', 'Molecular', 'Mutation', 'Names', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Phosphorylation', 'Phosphotransferases', 'Play', 'Post Translational Modification Analysis', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Post-Translational Regulation', 'Process', 'Protein Family', 'Proteins', 'Proteomics', 'PubMed', 'Publications', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Site', 'System', 'Technology', 'Text', 'Tissues', 'Translational Research', 'Variant', 'cell type', 'collaborative environment', 'computer based Semantic Analysis', 'enzyme substrate', 'genetic analysis', 'genetic variant', 'hackathon', 'indexing', 'information organization', 'innovation', 'interoperability', 'kinase inhibitor', 'knowledge base', 'knowledge integration', 'novel', 'precision medicine', 'protein complex', 'protein protein interaction', 'response', 'system architecture', 'text searching', 'therapeutic target', 'tool', 'transcriptomics', 'web portal', 'web services', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,U01,2017,370434,-0.0044823003166581995
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9302935,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Gene Targeting', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2017,668125,0.004719087116445649
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9349367,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2017,326784,0.011761031797161942
"HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS DESCRIPTION (provided by applicant): The aim of this proposal is to implement a novel way of processing and accessing the vast detailed knowledge contained within collections of scientific publications on the regulation of transcription initiation in bacterial models. In princple, this model for processing and reading information and new knowledge is applicable to other biological domains, potentially benefiting any area of biomedical knowledge. It is certainly criticl to generate new strategies to cope with the ever-increasing amount of knowledge generated in genomics and in biomedical research at large. Improving the efficiency of the traditional high-quality manual curation of scientific publications will enable us also to expand the type of biological knowledge, beyond mechanisms and their elements in the genome, to start including their connections with larger regulated processes and eventually physiological properties of the cell. We will first implement the necessary technology to improve our curation by means of a computational system that has text mining capabilities for preprocessing the papers before a human expert curator identifies which sentences contain the information that is to be added to the database. Premarked options selected by the curators will accelerate their decisions. The accumulative precise mapping between sentences and curated knowledge will provide training sets for text mining technologies to improve their automatic extraction. The curator practices will become more efficient, enabling us to curate selected high-impact published reviews to place mechanisms into a rich context of their physiological processes and general biology. Another relevant component of our proposal is the improved modeling of regulated processes by means of new concepts in biology that capture larger collections of coregulated genes and their concatenated reactions. Starting from all interactions of a local regulator, coregulated regulators and their domain of action will be incorporated to construct the biobricks of complex decisions, as they are encoded in the genome. These are conceptual containers that capture the organization of knowledge to describe the genetic programming of cellular capabilities. These proposals will be formalized and proposed within an international consortium focused in enriching standard models or ontologies of gene regulation for use by the scientific community. Finally, a portal to navigate across all the sentences of a given corpus of a large number (more than 5,000) of related papers will be implemented. The different avenues of navigation will essentially use two technologies, one dealing with automatically generating simpler sentences from original sentences as input, and the other one with the classification of papers based on their theme or ontology. Their combination will enable a novel navigation reading system. If we achieve our aims, this project will give a proof-of-principle prototype with clearly innovative higher levels of large amounts of integrated knowledge. Future directions may adapt these concepts and methods to the biology of higher organisms, including humans. PUBLIC HEALTH RELEVANCE: Scientific knowledge reported within publications provides a wealth of knowledge that we barely capture in databases for genomics. Enhancing the effectiveness of the processing and representation of all this knowledge will change the way we encode our understanding of concatenated interactions that are organized into networks and processes governing cell behavior. Given the conservation in evolution of the nature of biological complexity, a better encoding of our understanding of a bacterial cell shall influence that of any other living organism.",HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS,9193091,R01GM110597,"['Area', 'Bacteria', 'Bacterial Model', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Classification', 'Collection', 'Communities', 'Complex', 'Data Set', 'Databases', 'Effectiveness', 'Elements', 'Escherichia coli', 'Evolution', 'Foundations', 'Future', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Human', 'International', 'Joints', 'Knowledge', 'Letters', 'Linguistics', 'Literature', 'Manuals', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Nature', 'Ontology', 'Operon', 'Organism', 'Paper', 'Physiological', 'Physiological Processes', 'Planet Earth', 'Process', 'Property', 'Publications', 'Publishing', 'Reaction', 'Reading', 'Regulation', 'Regulon', 'Reporting', 'Research Infrastructure', 'Series', 'Signal Transduction', 'Site', 'Solid', 'Source', 'System', 'Technology', 'Text', 'Training', 'Transcription Initiation', 'Transcriptional Regulation', 'base', 'cell behavior', 'digital', 'electronic book', 'experience', 'feeding', 'functional genomics', 'improved', 'innovation', 'member', 'microbial community', 'model organisms databases', 'novel', 'novel strategies', 'promoter', 'prototype', 'public health relevance', 'response', 'software development', 'text searching', 'tool', 'transcription factor', 'usability']",NIGMS,CENTER FOR GENOMIC SCIENCES,R01,2017,396248,0.014643009634566743
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9325275,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Plasticizers', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2017,324508,0.015887793761347527
"Quantitative microscopy-based rapid phenotyping and screening ﻿    DESCRIPTION:  Synapses are most fundamental to the function of a nervous system. C. elegans is an excellent genetic model system for finding genes and elucidating pathways because of its sequenced genome and the abundance of molecular biology tools and mutants. Due to the simplicity of its nervous system, many breakthroughs have been made in C. elegans for understanding molecular mechanisms in the patterning of the nervous system and synapse development. The current bottlenecks are in the manual and non-quantitative techniques such as visual screens, limiting both the throughput of the experiments and the phenotypes one can examine. Our long-term objective is to develop technologies and to understand how genes, age, and the environment together define and continue to remodel the nervous system of an organism. In the last funding period, we have made large progress in hardware system design (including microtechnologies and automation technologies) and software for quantitative characterization of phenotypes. The objective of this continuation project is to further engineer superior micro devices for large-scale live imaging and quantitative imaging technologies, and combine with the power of genetic and genomic approaches to study synapse development in this in vivo system; genes and pathways emerging from this study could potentially become targets of therapeutics in neurological disorders.  We have shown in the previous phase of the project that quantitative microscopy-based approaches can indeed enable identification of novel genes and pathways that conventional approaches cannot. In the continuation phase, we will further optimize on-chip rapid and high-content in vivo imaging techniques, and in parallel further develop algorithms and quantitative measures for the analysis of such high-content data; we will screen based on novel synthetic phenotype unobservable by eye; we will also exploit powerful genomic techniques to identify loci and potential multigenic interactions that shape the synapse morphology. These experimental approaches will identify genes that cannot have been identified otherwise because of the difficulties associated with the phenotypical profiling, but addressed using our engineered techniques here. The approach is innovative because the technology developed here dramatically increases the throughput, sensitivity, and accuracy of the experiments, and truly enables the utility of extremely powerful genetic and genomic methods. The proposed research is significant because it fills the urgent need in high-throughput and high-content screens as well as identifying novel genes and pathways. In addition, besides the contribution to the specific neurobiology, the technologies are widely applicable to areas such as developmental cell biology, and to other small organisms such as fly larvae and zebrafish embryos. PUBLIC HEALTH RELEVANCE:   Synapse development is an important and active area of research linking genes and environments to the formation and maintenance of synapses in the nervous system. It has direct implications in many human diseases developmental and psychiatric diseases such as Autism Spectrum Disorder and Schizophrenia.",Quantitative microscopy-based rapid phenotyping and screening,9301591,R01GM088333,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alleles', 'Animals', 'Area', 'Automation', 'Biological Models', 'Biology', 'Caenorhabditis elegans', 'Chromosome Mapping', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Developmental Cell Biology', 'Devices', 'Disease', 'Drosophila genus', 'Embryo', 'Engineering', 'Environment', 'Event', 'Eye', 'Fill-It', 'Fluorescence', 'Funding', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Research', 'Genetic Screening', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Inbreeding', 'Larva', 'Lead', 'Link', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Microfluidics', 'Microscopy', 'Molecular', 'Molecular Biology', 'Morphology', 'Nematoda', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurons', 'Organism', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Phylogeny', 'Positioning Attribute', 'Quantitative Microscopy', 'Quantitative Trait Loci', 'Regulatory Pathway', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Speed', 'Synapses', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Vision', 'Visual', 'Work', 'Zebrafish', 'autism spectrum disorder', 'base', 'design', 'experience', 'experimental study', 'fly', 'forward genetics', 'genetic approach', 'high dimensionality', 'high throughput screening', 'human disease', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'mutant', 'nerve injury', 'nervous system disorder', 'novel', 'programs', 'public health relevance', 'quantitative imaging', 'screening', 'success', 'synaptogenesis', 'targeted treatment', 'technology development', 'tool', 'trait']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2017,305864,0.01069010436719535
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,0.035106554030520286
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,0.035106554030520286
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,9005867,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'mobile computing', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2016,1271107,0.0456183437452769
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9338982,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Basic Science', 'Biological', 'Biomedical Research', 'Cell physiology', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2016,1183132,0.013066987901127116
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9155025,R01EB022574,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'abstracting', 'base', 'brain tract', 'connectome', 'cost', 'data acquisition', 'density', 'evaluation/testing', 'functional outcomes', 'genome-wide', 'genomic data', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'neuroimaging', 'novel', 'novel strategies', 'public health relevance', 'software systems', 'tool', 'trait', 'white matter', 'whole genome']",NIBIB,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2016,500696,0.008499231432157516
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design New technologies afford the acquisition of dense “data clouds” of individual humans. However, heterogeneity, dimensionality and multi-scale nature of such data (genomes, transcriptomes, clinical variables, etc.) pose a new challenge: How can one query such dense data clouds of mixed data as an integrated set (as opposed to variable by variable) against multiple knowledge bases, and translate the joint molecular information into the clinical realm? Current lexical mapping and brute-force data mining seek to make heterogeneous data interoperable and accessible but their output is fragmented and requires expertise to assemble into coherent actionable information. We propose DeepTranslate, an innovative approach that incorporates the known actual physical organization of biological entities that are the substrate of pathogenesis into (i) networks (data graphs) and (ii) hierarchies of concepts that span the multiscale space from molecule to clinic. Organizing data sources along such natural structures will allow translation of burgeoning high-dimensional data sets into concepts familiar to clinicians, while capturing mechanistic relationships. DeepTranslate will take a hybrid approach to learn and organize its content from both (i) existing generic comprehensive knowledge sources (GO, KEGG, IDC, etc.) and (ii) newly measured instances of individual data clouds from two demonstration projects: (1) ISB’s Pioneer 100 and (2) St. Jude Lifetime cancer survivors. We will focus on diabetes as test case. These two studies cover a deep biological scale-space and thus can test the full extent of the multiscale capacity of DeepTranslate in a focused application. 1. TYPES OF RESEARCH QUESTION ENABLED. How can a clinician find out that the dozens of “out of range” variables observed in a patient’s data cloud, form a connected set with respect to pathophysiology pathways, from gene to clinical variable? How can the high-dimensional data of studies that measure for each individual 100+ data points of various types (“personal data clouds”) be analyzed as one set in an integrated fashion (as opposed to variable by variable) against existing knowledge bases and also be used to improve the databases? DeepTranslate addresses these two types of questions and thereby will accelerate translation of future personal data clouds into (A) care decisions and (B) hypotheses on new disease mechanisms / treatments, thereby benefiting providers as well as researchers. 2. USE OF EXPERTISE AND RESOURCES. ■ ISB: pioneer in personalized, big-data driven medicine (Demo Project 1); biomedical content expertise; multiscale omics and molecular pathogenesis, big data analysis, housing of databases for public access; query engine designs, GUI. ■ UCSD: leader in biomedical data integration; automated assembly of molecular and clinical data into hierarchical structures; translation between data types ■ U Montreal: biomedical database curation from literature and construction of gene/protein/drug interaction networks; machine learning, open resource database ■ St Jude CRH: Cancer monitoring Demo Project 2, cancer patient data analytics. 3. POTENTIAL DATA AND INFRASTRUCTURE CHALLENGES. (a) Existing comprehensive clinical data sources are not uniform and not explicitly based on biological networks; cross-mapping is being performed at NLM based on lexical relationships: HPO (phenotypes) vs. SNOMED CT (for EMR) vs. IDC or Merck Manual (for diseases). Careful selection of these sources in close collaboration with NLM is needed. (b) Existing molecular pathway databases are static, based on averages of heterogeneous non-stratified populations, while the newly measured high-dimensional data clouds are varied due to intra-individual temporal fluctuation and inter-individual variation. How this will affect building of ontotypes in our hybrid approach, and how large cohorts of data clouds must be to offer statistical power is yet to be determined. Our two Demonstration Projects with their uniquely deep (high-dimensional and multiscale) data in cohorts of limited but growing size are thus crucial first steps in a long journey of collective learning in the TRANSLATOR community. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9338977,OT3TR002026,"['Address', 'Affect', 'Architecture', 'Big Data', 'Biological', 'CRH gene', 'Cancer Patient', 'Cancer Survivor', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Disease', 'Drug Interactions', 'Functional disorder', 'Future', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Graph', 'Heterogeneity', 'Housing', 'Human', 'Hybrids', 'Individual', 'Joints', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Molecular', 'Monitor', 'Nature', 'Output', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Provider', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'SNOMED Clinical Terms', 'Saint Jude Children&apos', 's Research Hospital', 'Source', 'Structure', 'Testing', 'Translating', 'Translations', 'base', 'cohort', 'data integration', 'data mining', 'design', 'improved', 'innovation', 'inter-individual variation', 'knowledge base', 'lexical', 'molecular assembly/self assembly', 'new technology', 'transcriptome']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT3,2016,1071976,0.026939851862267064
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9099858,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2016,306754,-0.009682151479794487
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,9145523,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'gene product', 'genome-wide', 'improved', 'killings', 'novel', 'novel anticancer drug', 'prediction algorithm', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2016,48576,-0.01583143613425806
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9087292,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Science', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'big biomedical data', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'crowdsourcing', 'data management', 'data modeling', 'data to knowledge', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'multiple omics', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'support tools', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2016,133604,-0.029613069944006743
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9057057,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Health', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'research study', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2016,445349,0.03939102503611322
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design A fundamental challenge to translate insights between biomedical researchers, who study biological mechanisms, and clinicians, who diagnose patient symptoms, is that many links between biological processes and disease pathophysiology are poorly understood. A comprehensive Biomedical Translator must enable chains of inference across objects as diverse as genetic mutations, molecular effects, tissue-specific expression patterns, cellular processes, organ phenotypes, disease states, patient symptoms, and drug responses, a challenge beyond the scope of any one organization. Fortunately, many individual links in this chain have been made by experiments yielding statistical connections between individual data types. High-throughput perturbation screens link chemical and genetic perturbations to cellular phenotypes such as gene-expression patterns, cell survival, or changes in phosphorylation. Genetic association studies link mutations to human disease or intermediate phenotypes and biomarkers. Electronic medical records (EMR) link diseases or human phenotypes to diagnostic or current procedural terminology (CPT) codes, and clinical trials link the impact of drugs and drug candidates on disease states. In principle, incorporating these links into chains of inference could translate results between the full set of data types within them. In practice, each link is maintained by experts with domain-specific experiments, semantic terminology, and methodological standards. While a key challenge faced by a global Biomedical Translator is to establish consistent standards across these existing data types, a more important goal is to develop a principled and robust framework to (a) model biological systems and experimental approaches to investigate them; (b) organize knowledge about biological mechanism and disease; and (c) incorporate diverse datasets that serve as windows into the underlying and unknown state of nature. We propose to implement a Biomedical Translator as a probabilistic graphical model, a paradigm from artificial intelligence (AI) research. Just as separate research communities form weakly coupled parts of the translation process, graphical models allow global inferences from weakly coupled “nodes”. These inferences require each node to publish only probability distributions, enabling interoperability without necessarily having global entity-resolution standards, and benefit from paradigms for quality control, fault tolerance, and relevance assessment common in AI research. We hypothesize that a limited number of APIs, implemented as probability computations by communities around the world, would yield a Biomedical Translator as an emergent property of weakly coupled knowledge sources. From basic properties of graphical models, such a Translator could probabilistically translate among any data types connected within it, allowing for relatively complex query concepts. For example: What cellular processes in which tissues are impacted in a patient-based EMR? What genetic mutations sensitize cells to small-molecule treatment effects? Which small molecules mimic genetic “experiments of nature” that protect against disease? To illustrate the value of these resources and our architectural paradigm, we propose a demonstration project to implement a Biomedical Translator supporting queries between small molecules, biological processes, genes, and disease. The demonstration project will provide a valuable first step to confront key data-integration and organizational challenges and will enable previously impossible queries, such as identifying small molecules that perturb the same biological processes implicated by human genetics in a disease context. In this capacity, such Translator could realistically identify existing drugs for known symptoms (i.e., repurposing), but could more broadly serve as an engine for hypothesis generation and biological discovery, suggesting pre-clinical small molecules to develop based on their observed biological activity, or providing heretofore novel links between cellular protein function and disease pathophysiology. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9337924,OT3TR002025,"['Architecture', 'Artificial Intelligence', 'Biological', 'Biological Markers', 'Biological Process', 'Cell Survival', 'Cell physiology', 'Cells', 'Clinical Trials', 'Communities', 'Complex', 'Computerized Medical Record', 'Coupled', 'Current Procedural Terminology Codes', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Functional disorder', 'Gene Expression Profile', 'Generations', 'Genetic', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Link', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Organ', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Probability', 'Processed Genes', 'Property', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Semantics', 'Source', 'Symptoms', 'Terminology', 'Tissues', 'Translating', 'Translation Process', 'base', 'biological systems', 'chemical genetics', 'data integration', 'design', 'disease phenotype', 'drug candidate', 'genetic association', 'human disease', 'insight', 'interoperability', 'novel', 'pre-clinical', 'protein function', 'research study', 'response', 'small molecule', 'treatment effect']",NCATS,"BROAD INSTITUTE, INC.",OT3,2016,399608,0.016299696215911142
"Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery PROJECT SUMMARY Protein post-translational modification (PTM) plays a critical role in many diseases; however, critical gaps remain in research infrastructure for global analysis of PTMs. Key PTM information concerning enzyme- substrate relationships, regulation of PTM enzymes, PTM cross-talk, and functional consequences of PTM remains buried in the scientific literature. Meanwhile, while high-throughput panomics (genomic, transcriptomic, proteomic, PTM proteomic) data offer an unprecedented opportunity for the discovery of PTM-disease relationships, the data must be analyzed in an integrated and easily accessible knowledge framework in order for researchers and clinicians to gain a molecular understanding of disease. The goal of this application is to develop a collaborative knowledge environment for semantic annotation of scientific literature and integrative panomics analysis for PTM-disease knowledge discovery in precision medicine. We propose to connect PTM information from literature mining and curated databases in a knowledge resource on an ontological framework that supports analysis of panomics data in the context of PTM networks. To broaden impact and foster collaborative development, our resource will be FAIR (Findable, Accessible, Interoperable, Reusable) and interoperable with community standards.  The specific aims are: (i) develop a novel NLP (natural language processing) system for full-scale literature mining and PTM-disease knowledge extraction; (ii) develop a PTM knowledge resource for integrative panomics analysis and network discovery; and (iii) provide a FAIR collaborative environment for scalable semantic annotation and knowledge integration. The proposed system will build upon the NLP technologies and text mining tools already developed by our team and the bioinformatics infrastructure at the Protein Information Resource (PIR). The iPTMnet web portal will allow searching, browsing, visualization and analysis of PTM networks and PTM-related mutations in conjunction with user-supplied omics data, including panomics data from major national initiatives. Use scenarios will include identification of disease-driving genetic variants and analysis of cellular responses to kinase inhibitors. Our PTM knowledgebase will be disseminated with an RDF triple-store and a SPARQL endpoint for semantic queries, while our text mining tools and full-scale literature mining results will be disseminated in the BioC community standard for seamless integration to other text mining pipelines. To engage the community semantic annotation of scientific literature, we will host a hackathon to develop tools to expose BioC-annotated literature corpora to the semantic web, as well as an annotation jamboree to explore tagging of scientific text with precise ontological terms. This project will thus offer a unique research resource for PTM-disease network discovery as well as an integrable collaborative knowledge framework to support Big Data to Knowledge in precision medicine. PROJECT NARRATIVE Precision medicine requires a detailed understanding of the molecular events that are disrupted in disease, including changes in protein post-translational modifications (PTM) that are hallmarks of many diseases. The proposed resource will support analysis of genomic-scale data for exploring PTM-disease networks and PTM-related mutations, as well as knowledge dissemination on the semantic web. These combined efforts will accelerate basic understanding of disease processes and discovery of diagnostic targets and more effective individualized therapies.",Semantic Literature Annotation and Integrative Panomics Analysis for PTM-Disease Knowledge Network Discovery,9195864,U01GM120953,"['Address', 'Adopted', 'Automobile Driving', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cells', 'Clinical', 'Communities', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Drug resistance', 'Educational workshop', 'Environment', 'Enzymes', 'Europe', 'Event', 'Fostering', 'Gene Proteins', 'Genomics', 'Goals', 'Graph', 'Hybrids', 'Imagery', 'Information Resources', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Length', 'Link', 'Literature', 'Malignant Neoplasms', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Mutation', 'Names', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Phosphorylation', 'Phosphorylation Site', 'Phosphotransferases', 'Play', 'Post Translational Modification Analysis', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Databases', 'Protein Family', 'Proteins', 'Proteomics', 'PubMed', 'Publications', 'Regulation', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Staging', 'System', 'Technology', 'Text', 'Tissues', 'Translational Research', 'Variant', 'abstracting', 'cell type', 'collaborative environment', 'computer based Semantic Analysis', 'enzyme substrate', 'genetic analysis', 'genetic variant', 'hackathon', 'indexing', 'information organization', 'innovation', 'kinase inhibitor', 'knowledge base', 'novel', 'precision medicine', 'protein complex', 'protein protein interaction', 'response', 'system architecture', 'text searching', 'therapeutic target', 'tool', 'transcriptomics', 'web portal', 'web services', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,U01,2016,374400,-0.0044823003166581995
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9135552,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2016,324169,0.011761031797161942
"HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS DESCRIPTION (provided by applicant): The aim of this proposal is to implement a novel way of processing and accessing the vast detailed knowledge contained within collections of scientific publications on the regulation of transcription initiation in bacterial models. In princple, this model for processing and reading information and new knowledge is applicable to other biological domains, potentially benefiting any area of biomedical knowledge. It is certainly criticl to generate new strategies to cope with the ever-increasing amount of knowledge generated in genomics and in biomedical research at large. Improving the efficiency of the traditional high-quality manual curation of scientific publications will enable us also to expand the type of biological knowledge, beyond mechanisms and their elements in the genome, to start including their connections with larger regulated processes and eventually physiological properties of the cell. We will first implement the necessary technology to improve our curation by means of a computational system that has text mining capabilities for preprocessing the papers before a human expert curator identifies which sentences contain the information that is to be added to the database. Premarked options selected by the curators will accelerate their decisions. The accumulative precise mapping between sentences and curated knowledge will provide training sets for text mining technologies to improve their automatic extraction. The curator practices will become more efficient, enabling us to curate selected high-impact published reviews to place mechanisms into a rich context of their physiological processes and general biology. Another relevant component of our proposal is the improved modeling of regulated processes by means of new concepts in biology that capture larger collections of coregulated genes and their concatenated reactions. Starting from all interactions of a local regulator, coregulated regulators and their domain of action will be incorporated to construct the biobricks of complex decisions, as they are encoded in the genome. These are conceptual containers that capture the organization of knowledge to describe the genetic programming of cellular capabilities. These proposals will be formalized and proposed within an international consortium focused in enriching standard models or ontologies of gene regulation for use by the scientific community. Finally, a portal to navigate across all the sentences of a given corpus of a large number (more than 5,000) of related papers will be implemented. The different avenues of navigation will essentially use two technologies, one dealing with automatically generating simpler sentences from original sentences as input, and the other one with the classification of papers based on their theme or ontology. Their combination will enable a novel navigation reading system. If we achieve our aims, this project will give a proof-of-principle prototype with clearly innovative higher levels of large amounts of integrated knowledge. Future directions may adapt these concepts and methods to the biology of higher organisms, including humans. PUBLIC HEALTH RELEVANCE: Scientific knowledge reported within publications provides a wealth of knowledge that we barely capture in databases for genomics. Enhancing the effectiveness of the processing and representation of all this knowledge will change the way we encode our understanding of concatenated interactions that are organized into networks and processes governing cell behavior. Given the conservation in evolution of the nature of biological complexity, a better encoding of our understanding of a bacterial cell shall influence that of any other living organism.",HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS,8985684,R01GM110597,"['Area', 'Bacteria', 'Bacterial Model', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Classification', 'Collection', 'Communities', 'Complex', 'Data Set', 'Databases', 'Effectiveness', 'Elements', 'Escherichia coli', 'Evolution', 'Foundations', 'Future', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Indium', 'International', 'Joints', 'Knowledge', 'Letters', 'Life', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Nature', 'Ontology', 'Operon', 'Organism', 'Paper', 'Physiological', 'Physiological Processes', 'Process', 'Property', 'Publications', 'Publishing', 'Reaction', 'Reading', 'Regulation', 'Regulon', 'Reporting', 'Research Infrastructure', 'Series', 'Signal Transduction', 'Site', 'Solid', 'Source', 'System', 'Technology', 'Text', 'Training', 'Transcription Initiation', 'Transcriptional Regulation', 'base', 'cell behavior', 'coping', 'digital', 'electronic book', 'experience', 'feeding', 'functional genomics', 'improved', 'innovation', 'member', 'microbial community', 'model organisms databases', 'novel', 'novel strategies', 'promoter', 'prototype', 'response', 'software development', 'text searching', 'tool', 'transcription factor', 'usability']",NIGMS,CENTER FOR GENOMIC SCIENCES,R01,2016,405708,0.014643009634566743
"Quantitative microscopy-based rapid phenotyping and screening ﻿    DESCRIPTION:  Synapses are most fundamental to the function of a nervous system. C. elegans is an excellent genetic model system for finding genes and elucidating pathways because of its sequenced genome and the abundance of molecular biology tools and mutants. Due to the simplicity of its nervous system, many breakthroughs have been made in C. elegans for understanding molecular mechanisms in the patterning of the nervous system and synapse development. The current bottlenecks are in the manual and non-quantitative techniques such as visual screens, limiting both the throughput of the experiments and the phenotypes one can examine. Our long-term objective is to develop technologies and to understand how genes, age, and the environment together define and continue to remodel the nervous system of an organism. In the last funding period, we have made large progress in hardware system design (including microtechnologies and automation technologies) and software for quantitative characterization of phenotypes. The objective of this continuation project is to further engineer superior micro devices for large-scale live imaging and quantitative imaging technologies, and combine with the power of genetic and genomic approaches to study synapse development in this in vivo system; genes and pathways emerging from this study could potentially become targets of therapeutics in neurological disorders.  We have shown in the previous phase of the project that quantitative microscopy-based approaches can indeed enable identification of novel genes and pathways that conventional approaches cannot. In the continuation phase, we will further optimize on-chip rapid and high-content in vivo imaging techniques, and in parallel further develop algorithms and quantitative measures for the analysis of such high-content data; we will screen based on novel synthetic phenotype unobservable by eye; we will also exploit powerful genomic techniques to identify loci and potential multigenic interactions that shape the synapse morphology. These experimental approaches will identify genes that cannot have been identified otherwise because of the difficulties associated with the phenotypical profiling, but addressed using our engineered techniques here. The approach is innovative because the technology developed here dramatically increases the throughput, sensitivity, and accuracy of the experiments, and truly enables the utility of extremely powerful genetic and genomic methods. The proposed research is significant because it fills the urgent need in high-throughput and high-content screens as well as identifying novel genes and pathways. In addition, besides the contribution to the specific neurobiology, the technologies are widely applicable to areas such as developmental cell biology, and to other small organisms such as fly larvae and zebrafish embryos.         PUBLIC HEALTH RELEVANCE:   Synapse development is an important and active area of research linking genes and environments to the formation and maintenance of synapses in the nervous system. It has direct implications in many human diseases developmental and psychiatric diseases such as Autism Spectrum Disorder and Schizophrenia.                ",Quantitative microscopy-based rapid phenotyping and screening,9116662,R01GM088333,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alleles', 'Animals', 'Area', 'Automation', 'Biological Models', 'Biology', 'Caenorhabditis elegans', 'Chromosome Mapping', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Developmental Cell Biology', 'Devices', 'Disease', 'Drosophila genus', 'Embryo', 'Engineering', 'Environment', 'Event', 'Eye', 'Fill-It', 'Fluorescence', 'Funding', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Research', 'Genetic Screening', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Inbreeding', 'Larva', 'Lead', 'Life', 'Link', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Microfluidics', 'Microscopy', 'Molecular', 'Molecular Biology', 'Morphology', 'Nematoda', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurons', 'Organism', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Phylogeny', 'Positioning Attribute', 'Quantitative Microscopy', 'Quantitative Trait Loci', 'Regulatory Pathway', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Speed', 'Synapses', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Vision', 'Visual', 'Work', 'Zebrafish', 'autism spectrum disorder', 'base', 'design', 'experience', 'fly', 'forward genetics', 'genetic approach', 'genome sequencing', 'high throughput screening', 'human disease', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'mutant', 'nerve injury', 'nervous system disorder', 'novel', 'programs', 'public health relevance', 'quantitative imaging', 'research study', 'screening', 'success', 'synaptogenesis', 'targeted treatment', 'technology development', 'tool', 'trait']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2016,306503,0.01069010436719535
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,0.035106554030520286
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,0.02202629382356905
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,8840984,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2015,1243799,0.0456183437452769
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8951600,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2015,39304,-0.01583143613425806
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages.         PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.            ",Multi-Resolution Docking Methods for Electron Microscopy,8964685,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Image', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Relative (related person)', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2015,307928,-0.009682151479794487
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,8935858,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2015,133604,-0.029613069944006743
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9065764,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2015,183520,-0.029613069944006743
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases.         PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.            ",Integration and Visualization of Diverse Biological Data,8886554,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Drug Targeting', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'drug development', 'drug discovery', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'public health relevance', 'research study', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2015,473642,0.03939102503611322
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,8929328,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'genetic makeup', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'personalized medicine', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2015,329422,0.011761031797161942
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,8836569,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,2687363,0.018161398974187757
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9132876,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,413294,0.018161398974187757
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9133491,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,115911,0.018161398974187757
"HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS     DESCRIPTION (provided by applicant): The aim of this proposal is to implement a novel way of processing and accessing the vast detailed knowledge contained within collections of scientific publications on the regulation of transcription initiation in bacterial models. In princple, this model for processing and reading information and new knowledge is applicable to other biological domains, potentially benefiting any area of biomedical knowledge. It is certainly criticl to generate new strategies to cope with the ever-increasing amount of knowledge generated in genomics and in biomedical research at large. Improving the efficiency of the traditional high-quality manual curation of scientific publications will enable us also to expand the type of biological knowledge, beyond mechanisms and their elements in the genome, to start including their connections with larger regulated processes and eventually physiological properties of the cell. We will first implement the necessary technology to improve our curation by means of a computational system that has text mining capabilities for preprocessing the papers before a human expert curator identifies which sentences contain the information that is to be added to the database. Premarked options selected by the curators will accelerate their decisions. The accumulative precise mapping between sentences and curated knowledge will provide training sets for text mining technologies to improve their automatic extraction. The curator practices will become more efficient, enabling us to curate selected high-impact published reviews to place mechanisms into a rich context of their physiological processes and general biology. Another relevant component of our proposal is the improved modeling of regulated processes by means of new concepts in biology that capture larger collections of coregulated genes and their concatenated reactions. Starting from all interactions of a local regulator, coregulated regulators and their domain of action will be incorporated to construct the biobricks of complex decisions, as they are encoded in the genome. These are conceptual containers that capture the organization of knowledge to describe the genetic programming of cellular capabilities. These proposals will be formalized and proposed within an international consortium focused in enriching standard models or ontologies of gene regulation for use by the scientific community. Finally, a portal to navigate across all the sentences of a given corpus of a large number (more than 5,000) of related papers will be implemented. The different avenues of navigation will essentially use two technologies, one dealing with automatically generating simpler sentences from original sentences as input, and the other one with the classification of papers based on their theme or ontology. Their combination will enable a novel navigation reading system. If we achieve our aims, this project will give a proof-of-principle prototype with clearly innovative higher levels of large amounts of integrated knowledge. Future directions may adapt these concepts and methods to the biology of higher organisms, including humans.         PUBLIC HEALTH RELEVANCE: Scientific knowledge reported within publications provides a wealth of knowledge that we barely capture in databases for genomics. Enhancing the effectiveness of the processing and representation of all this knowledge will change the way we encode our understanding of concatenated interactions that are organized into networks and processes governing cell behavior. Given the conservation in evolution of the nature of biological complexity, a better encoding of our understanding of a bacterial cell shall influence that of any other living organism.            ",HIGH THROUGHPUT LITERATURE CURATION OF GENETIC REGULATION IN BACTERIAL MODELS,8817212,R01GM110597,"['Area', 'Bacteria', 'Bacterial Model', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Books', 'Cells', 'Classification', 'Collection', 'Communities', 'Complex', 'Data Set', 'Databases', 'Effectiveness', 'Elements', 'Escherichia coli', 'Evolution', 'Foundations', 'Future', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Human', 'Indium', 'International', 'Joints', 'Knowledge', 'Letters', 'Life', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Nature', 'Ontology', 'Operon', 'Organism', 'Paper', 'Physiological', 'Physiological Processes', 'Process', 'Property', 'Publications', 'Publishing', 'Reaction', 'Reading', 'Regulation', 'Regulon', 'Reporting', 'Research Infrastructure', 'Series', 'Signal Transduction', 'Site', 'Solid', 'Source', 'System', 'Technology', 'Text', 'Training', 'Transcription Initiation', 'Transcriptional Regulation', 'base', 'cell behavior', 'coping', 'digital', 'experience', 'feeding', 'functional genomics', 'improved', 'innovation', 'member', 'microbial community', 'model organisms databases', 'novel', 'novel strategies', 'promoter', 'prototype', 'public health relevance', 'response', 'software development', 'text searching', 'tool', 'transcription factor', 'usability']",NIGMS,CENTER FOR GENOMIC SCIENCES,R01,2015,406247,0.014643009634566743
"Quantitative microscopy-based rapid phenotyping and screening ﻿    DESCRIPTION:  Synapses are most fundamental to the function of a nervous system. C. elegans is an excellent genetic model system for finding genes and elucidating pathways because of its sequenced genome and the abundance of molecular biology tools and mutants. Due to the simplicity of its nervous system, many breakthroughs have been made in C. elegans for understanding molecular mechanisms in the patterning of the nervous system and synapse development. The current bottlenecks are in the manual and non-quantitative techniques such as visual screens, limiting both the throughput of the experiments and the phenotypes one can examine. Our long-term objective is to develop technologies and to understand how genes, age, and the environment together define and continue to remodel the nervous system of an organism. In the last funding period, we have made large progress in hardware system design (including microtechnologies and automation technologies) and software for quantitative characterization of phenotypes. The objective of this continuation project is to further engineer superior micro devices for large-scale live imaging and quantitative imaging technologies, and combine with the power of genetic and genomic approaches to study synapse development in this in vivo system; genes and pathways emerging from this study could potentially become targets of therapeutics in neurological disorders.  We have shown in the previous phase of the project that quantitative microscopy-based approaches can indeed enable identification of novel genes and pathways that conventional approaches cannot. In the continuation phase, we will further optimize on-chip rapid and high-content in vivo imaging techniques, and in parallel further develop algorithms and quantitative measures for the analysis of such high-content data; we will screen based on novel synthetic phenotype unobservable by eye; we will also exploit powerful genomic techniques to identify loci and potential multigenic interactions that shape the synapse morphology. These experimental approaches will identify genes that cannot have been identified otherwise because of the difficulties associated with the phenotypical profiling, but addressed using our engineered techniques here. The approach is innovative because the technology developed here dramatically increases the throughput, sensitivity, and accuracy of the experiments, and truly enables the utility of extremely powerful genetic and genomic methods. The proposed research is significant because it fills the urgent need in high-throughput and high-content screens as well as identifying novel genes and pathways. In addition, besides the contribution to the specific neurobiology, the technologies are widely applicable to areas such as developmental cell biology, and to other small organisms such as fly larvae and zebrafish embryos.         PUBLIC HEALTH RELEVANCE:   Synapse development is an important and active area of research linking genes and environments to the formation and maintenance of synapses in the nervous system. It has direct implications in many human diseases developmental and psychiatric diseases such as Autism Spectrum Disorder and Schizophrenia.                ",Quantitative microscopy-based rapid phenotyping and screening,8964929,R01GM088333,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alleles', 'Animals', 'Area', 'Automation', 'Biological Models', 'Biology', 'Caenorhabditis elegans', 'Chromosome Mapping', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Developmental Cell Biology', 'Devices', 'Disease', 'Drosophila genus', 'Embryo', 'Engineering', 'Environment', 'Event', 'Eye', 'Fill-It', 'Fluorescence', 'Funding', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Research', 'Genetic Screening', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Inbreeding', 'Larva', 'Lead', 'Life', 'Link', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Microfluidics', 'Microscopy', 'Molecular', 'Molecular Biology', 'Morphology', 'Nematoda', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurons', 'Organism', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Phylogeny', 'Positioning Attribute', 'Quantitative Microscopy', 'Quantitative Trait Loci', 'Regulatory Pathway', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Speed', 'Synapses', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Vision', 'Visual', 'Work', 'Zebrafish', 'autism spectrum disorder', 'base', 'design', 'experience', 'fly', 'forward genetics', 'genetic approach', 'genome sequencing', 'high throughput screening', 'human disease', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'mutant', 'nerve injury', 'nervous system disorder', 'novel', 'programs', 'public health relevance', 'quantitative imaging', 'research study', 'screening', 'success', 'synaptogenesis', 'technology development', 'therapeutic target', 'tool', 'trait']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2015,307094,0.01069010436719535
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,0.035106554030520286
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,0.02202629382356905
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8661774,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2014,1248956,0.0456183437452769
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8644512,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2014,35110,-0.01583143613425806
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,8774362,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2014,28157,-0.029613069944006743
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8727043,R01GM093156,"['Accounting', 'Algorithmic Software', 'Algorithms', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2014,434355,0.008462327275061467
"Building an open-source cloud-based computational platform to improve data access   We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members.  One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. This proposal aims to fill this gap by developing a robust platform that integrates state-of-the-art open-source technologies for data storage, data access, data mining and analysis, annotation, visualization and reporting.  We previously developed a cloud-based BioDatomics platform for Next Generation Sequencing (NGS), BioDX, which has been successful and has been used commercially by several clients. This proposal aims to develop a new platform leveraging our experience with the BioDX platform that integrates: data storage and real-time data querying using Cloudera Impala; powerful and customizable analytics tools using R and its derivative Bioconductor suite of programs for bioinformatics; annotation integration and reporting which is an existing feature of BioDX; and a visual programming interface that will simplify and enhance the development and maintenance of reproducible analytics workflows. We believe this powerful integrated data platform, if successful, will enable real-time collaboration, dramatically reduce data repository costs, and increase the efficiency and efficacy of data analyses for translating experimental data into actionable research products.  We are committed to analyzing stakeholder needs and optimizing hardware, software and information technology systems to meet their demands. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools.  The initial phase of work will involve development of the platform, optimizing performance on the cloud and testing the integration of new technology. BioDatomics is committed to funding the next phase of work which will include usability testing and finalizing a commercial product, following which full commercialization will proceed. Preliminary commercialization plans have demonstrated that the project has the capacity to generate a million dollars in revenue during the first full year after commercial release.  The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This open source platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders. PUBLIC HEALTH RELEVANCE: One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools. The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders.            ",Building an open-source cloud-based computational platform to improve data access,8647860,R43DA036970,"['Academia', 'Apache Indians', 'Bioconductor', 'Bioinformatics', 'Biological', 'Businesses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Clinical', 'Clinical Research', 'Collaborations', 'Commit', 'Complex', 'Computer software', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Drug Industry', 'Environment', 'Expenditure', 'Funding', 'Genomics', 'Government Agencies', 'Growth', 'Imagery', 'Industry', 'Information Dissemination', 'Information Systems', 'Java', 'Language', 'Licensing', 'Link', 'Machine Learning', 'Maintenance', 'Marketing', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Target', 'Mutation', 'Online Systems', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Programming Languages', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk Behaviors', 'Savings', 'Services', 'Software Engineering', 'Software Tools', 'Solutions', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Substance Addiction', 'Substance Use Disorder', 'Substance abuse problem', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Visual', 'Work', 'base', 'beneficiary', 'cloud based', 'commercialization', 'computer infrastructure', 'cost', 'cost effective', 'data mining', 'drug discovery', 'experience', 'improved', 'mathematical model', 'meetings', 'member', 'models and simulation', 'new technology', 'next generation sequencing', 'novel', 'open source', 'programs', 'public health relevance', 'substance abuse treatment', 'success', 'tool', 'usability', 'user-friendly']",NIDA,"BIODATOMICS, LLC",R43,2014,195584,0.009295418827335283
"Data-Driven Statistical Learning with Applications to Genomics     DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software.         PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.            ",Data-Driven Statistical Learning with Applications to Genomics,8796068,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Simulate', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'high throughput analysis', 'interest', 'novel', 'patient population', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2014,361063,0.011761031797161942
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8601095,R01GM071966,"['Address', 'Algorithms', 'Bayesian Method', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Cloud Computing', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Microvascular Dysfunction', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2014,391301,0.01954069125335604
"Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery    DESCRIPTION (provided by applicant):       A great challenge in the biomedical informatics domain is to develop computational methods that combine existing knowledge and experimental data to derive new knowledge regarding biological systems and disease mechanisms. Most knowledge regarding genes and proteins in biomedical literature is stored in the form of free text that is not suitable for computation, and the manual processes of encoding this body of knowledge into computable form cannot keep up with the rate of knowledge accumulation. The main thrust of the proposed research is to design novel statistical text-mining algorithms to acquire and represent knowledge regarding genes and proteins from free-text literature, and further to combine this acquired knowledge with experimental data to derive new knowledge. We will organize the proposed research to the following specific aims. Specific Aim 1. Develop ontology-guided semantic modeling algorithms for extracting biological concepts from free text, in which we will design hierarchical probabilistic topic models that are capable of representing biological concepts as a hierarchy and develop novel learning algorithms to infer biological concepts from free-text documents. Specific Aim 2. Integrate semantic modeling with BioNLP to extract textual evidence supporting protein-function annotations. We will develop information extraction algorithms that will combine the results of hierarchical semantic analysis and BioNLP to identify the text regions that will most likely provide evidence regarding the function of genes/proteins and map the extracted information to a controlled vocabulary. Specific Aim 3. Develop a framework to unify the procedures of knowledge reasoning and data mining for knowledge discovery. In this aim, we will reason using existing knowledge (represented in the form of an ontology) to reveal functional modules among the genes from the experimental data. We will then further develop algorithms that will reveal relationships between these gene modules by mining system-scaled experimental data. The overall framework will integrate functional reasoning and data mining in an iterative manner to refine the knowledge progressively and to derive rules such as: when genes involved in biological process X are perturbed, genes involved in biological process Y will respond. We will test the framework on the data from yeast-system biology studies and the Cancer Genome Atlas (TCGA) project to gain insights into the cellular systems and disease mechanisms of cancer cells.           In recent decades, biomedical sciences have achieved significant advances; most of the knowledge resulting from research is stored in the form of biomedical literature in the form free-text. This project develop computational approaches to extract knowledge from biomedical literature, represent the knowledge in computable form, and combined the knowledge with experiment data to gain insights into biological systems and disease mechanisms",Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery,8714053,R01LM011155,"['Accounting', 'Achievement', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Computing Methodologies', 'Controlled Vocabulary', 'Data', 'Disease', 'Gene Proteins', 'Genes', 'Goals', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Learning', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Names', 'Natural Language Processing', 'Ontology', 'Procedures', 'Process', 'Proteins', 'Psyche structure', 'Research', 'Science', 'Semantics', 'Structure', 'System', 'Systems Biology', 'Testing', 'Text', 'The Cancer Genome Atlas', 'Training', 'Tweens', 'Yeasts', 'biological systems', 'biomedical informatics', 'cancer cell', 'data mining', 'design', 'insight', 'interest', 'knowledge of results', 'novel', 'protein function', 'protein protein interaction', 'research study', 'text searching']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,307471,0.006629730978319077
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8640966,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2014,2699376,0.018161398974187757
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,0.02202629382356905
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8542870,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2013,265099,0.0017109006576924409
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8473164,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2013,1216983,0.0456183437452769
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.03749379103809066
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8531961,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2013,422340,0.008462327275061467
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8403055,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2013,378540,0.01954069125335604
"Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery    DESCRIPTION (provided by applicant):       A great challenge in the biomedical informatics domain is to develop computational methods that combine existing knowledge and experimental data to derive new knowledge regarding biological systems and disease mechanisms. Most knowledge regarding genes and proteins in biomedical literature is stored in the form of free text that is not suitable for computation, and the manual processes of encoding this body of knowledge into computable form cannot keep up with the rate of knowledge accumulation. The main thrust of the proposed research is to design novel statistical text-mining algorithms to acquire and represent knowledge regarding genes and proteins from free-text literature, and further to combine this acquired knowledge with experimental data to derive new knowledge. We will organize the proposed research to the following specific aims. Specific Aim 1. Develop ontology-guided semantic modeling algorithms for extracting biological concepts from free text, in which we will design hierarchical probabilistic topic models that are capable of representing biological concepts as a hierarchy and develop novel learning algorithms to infer biological concepts from free-text documents. Specific Aim 2. Integrate semantic modeling with BioNLP to extract textual evidence supporting protein-function annotations. We will develop information extraction algorithms that will combine the results of hierarchical semantic analysis and BioNLP to identify the text regions that will most likely provide evidence regarding the function of genes/proteins and map the extracted information to a controlled vocabulary. Specific Aim 3. Develop a framework to unify the procedures of knowledge reasoning and data mining for knowledge discovery. In this aim, we will reason using existing knowledge (represented in the form of an ontology) to reveal functional modules among the genes from the experimental data. We will then further develop algorithms that will reveal relationships between these gene modules by mining system-scaled experimental data. The overall framework will integrate functional reasoning and data mining in an iterative manner to refine the knowledge progressively and to derive rules such as: when genes involved in biological process X are perturbed, genes involved in biological process Y will respond. We will test the framework on the data from yeast-system biology studies and the Cancer Genome Atlas (TCGA) project to gain insights into the cellular systems and disease mechanisms of cancer cells.           In recent decades, biomedical sciences have achieved significant advances; most of the knowledge resulting from research is stored in the form of biomedical literature in the form free-text. This project develop computational approaches to extract knowledge from biomedical literature, represent the knowledge in computable form, and combined the knowledge with experiment data to gain insights into biological systems and disease mechanisms",Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery,8535824,R01LM011155,"['Accounting', 'Achievement', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Computing Methodologies', 'Controlled Vocabulary', 'Data', 'Disease', 'Gene Proteins', 'Genes', 'Goals', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Learning', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Names', 'Natural Language Processing', 'Ontology', 'Procedures', 'Process', 'Proteins', 'Psyche structure', 'Research', 'Science', 'Semantics', 'Structure', 'System', 'Systems Biology', 'Testing', 'Text', 'The Cancer Genome Atlas', 'Training', 'Tweens', 'Yeasts', 'biological systems', 'biomedical informatics', 'cancer cell', 'data mining', 'design', 'insight', 'interest', 'knowledge of results', 'novel', 'protein function', 'protein protein interaction', 'research study', 'text searching']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2013,291730,0.006629730978319077
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8447583,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2013,2703817,0.018161398974187757
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,0.026944537962947365
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8322626,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2012,274156,0.0017109006576924409
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.        PUBLIC HEALTH RELEVANCE: RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                  RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8268588,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2012,1300000,0.041723845014358475
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.03749379103809066
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8280356,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2012,218662,-0.0022650512273749016
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8294774,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2012,442016,0.008462327275061467
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8239531,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Health', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2012,515296,0.01695412973529532
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.",Integration and visualization of diverse biological data,8209212,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2012,393228,0.01219035753327636
"Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery    DESCRIPTION (provided by applicant):       A great challenge in the biomedical informatics domain is to develop computational methods that combine existing knowledge and experimental data to derive new knowledge regarding biological systems and disease mechanisms. Most knowledge regarding genes and proteins in biomedical literature is stored in the form of free text that is not suitable for computation, and the manual processes of encoding this body of knowledge into computable form cannot keep up with the rate of knowledge accumulation. The main thrust of the proposed research is to design novel statistical text-mining algorithms to acquire and represent knowledge regarding genes and proteins from free-text literature, and further to combine this acquired knowledge with experimental data to derive new knowledge. We will organize the proposed research to the following specific aims. Specific Aim 1. Develop ontology-guided semantic modeling algorithms for extracting biological concepts from free text, in which we will design hierarchical probabilistic topic models that are capable of representing biological concepts as a hierarchy and develop novel learning algorithms to infer biological concepts from free-text documents. Specific Aim 2. Integrate semantic modeling with BioNLP to extract textual evidence supporting protein-function annotations. We will develop information extraction algorithms that will combine the results of hierarchical semantic analysis and BioNLP to identify the text regions that will most likely provide evidence regarding the function of genes/proteins and map the extracted information to a controlled vocabulary. Specific Aim 3. Develop a framework to unify the procedures of knowledge reasoning and data mining for knowledge discovery. In this aim, we will reason using existing knowledge (represented in the form of an ontology) to reveal functional modules among the genes from the experimental data. We will then further develop algorithms that will reveal relationships between these gene modules by mining system-scaled experimental data. The overall framework will integrate functional reasoning and data mining in an iterative manner to refine the knowledge progressively and to derive rules such as: when genes involved in biological process X are perturbed, genes involved in biological process Y will respond. We will test the framework on the data from yeast-system biology studies and the Cancer Genome Atlas (TCGA) project to gain insights into the cellular systems and disease mechanisms of cancer cells.           In recent decades, biomedical sciences have achieved significant advances; most of the knowledge resulting from research is stored in the form of biomedical literature in the form free-text. This project develop computational approaches to extract knowledge from biomedical literature, represent the knowledge in computable form, and combined the knowledge with experiment data to gain insights into biological systems and disease mechanisms",Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery,8326650,R01LM011155,"['Accounting', 'Achievement', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Computing Methodologies', 'Controlled Vocabulary', 'Data', 'Disease', 'Gene Proteins', 'Genes', 'Goals', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Learning', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Names', 'Natural Language Processing', 'Ontology', 'Procedures', 'Process', 'Proteins', 'Psyche structure', 'Research', 'Science', 'Semantics', 'Structure', 'System', 'Systems Biology', 'Testing', 'Text', 'The Cancer Genome Atlas', 'Training', 'Tweens', 'Yeasts', 'biological systems', 'biomedical informatics', 'cancer cell', 'data mining', 'design', 'insight', 'interest', 'knowledge of results', 'novel', 'protein function', 'protein protein interaction', 'research study', 'text searching']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2012,317212,0.006629730978319077
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8337800,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2012,2751015,0.018161398974187757
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,0.026944537962947365
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8143338,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2011,275732,0.0017109006576924409
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.03749379103809066
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8133157,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2011,218724,-0.0022650512273749016
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8079755,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2011,444631,0.008462327275061467
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8059586,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Health', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2011,512972,0.01695412973529532
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8041717,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2011,433016,0.01219035753327636
"Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery    DESCRIPTION (provided by applicant):       A great challenge in the biomedical informatics domain is to develop computational methods that combine existing knowledge and experimental data to derive new knowledge regarding biological systems and disease mechanisms. Most knowledge regarding genes and proteins in biomedical literature is stored in the form of free text that is not suitable for computation, and the manual processes of encoding this body of knowledge into computable form cannot keep up with the rate of knowledge accumulation. The main thrust of the proposed research is to design novel statistical text-mining algorithms to acquire and represent knowledge regarding genes and proteins from free-text literature, and further to combine this acquired knowledge with experimental data to derive new knowledge. We will organize the proposed research to the following specific aims. Specific Aim 1. Develop ontology-guided semantic modeling algorithms for extracting biological concepts from free text, in which we will design hierarchical probabilistic topic models that are capable of representing biological concepts as a hierarchy and develop novel learning algorithms to infer biological concepts from free-text documents. Specific Aim 2. Integrate semantic modeling with BioNLP to extract textual evidence supporting protein-function annotations. We will develop information extraction algorithms that will combine the results of hierarchical semantic analysis and BioNLP to identify the text regions that will most likely provide evidence regarding the function of genes/proteins and map the extracted information to a controlled vocabulary. Specific Aim 3. Develop a framework to unify the procedures of knowledge reasoning and data mining for knowledge discovery. In this aim, we will reason using existing knowledge (represented in the form of an ontology) to reveal functional modules among the genes from the experimental data. We will then further develop algorithms that will reveal relationships between these gene modules by mining system-scaled experimental data. The overall framework will integrate functional reasoning and data mining in an iterative manner to refine the knowledge progressively and to derive rules such as: when genes involved in biological process X are perturbed, genes involved in biological process Y will respond. We will test the framework on the data from yeast-system biology studies and the Cancer Genome Atlas (TCGA) project to gain insights into the cellular systems and disease mechanisms of cancer cells.           In recent decades, biomedical sciences have achieved significant advances; most of the knowledge resulting from research is stored in the form of biomedical literature in the form free-text. This project develop computational approaches to extract knowledge from biomedical literature, represent the knowledge in computable form, and combined the knowledge with experiment data to gain insights into biological systems and disease mechanisms",Ontology-Driven Methods for Knowledge Acquisition and Knowledge Discovery,8202896,R01LM011155,"['Accounting', 'Achievement', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Computing Methodologies', 'Controlled Vocabulary', 'Data', 'Disease', 'Gene Proteins', 'Genes', 'Goals', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Learning', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Names', 'Natural Language Processing', 'Ontology', 'Procedures', 'Process', 'Proteins', 'Psyche structure', 'Research', 'Science', 'Semantics', 'Structure', 'System', 'Systems Biology', 'Testing', 'Text', 'The Cancer Genome Atlas', 'Training', 'Tweens', 'Yeasts', 'biological systems', 'biomedical informatics', 'cancer cell', 'data mining', 'design', 'insight', 'interest', 'knowledge of results', 'novel', 'protein function', 'protein protein interaction', 'research study', 'text searching']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,312599,0.006629730978319077
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8061704,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'information model', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2011,2923298,0.006878252007680527
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.      PUBLIC HEALTH RELEVANCE:  Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,            Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8242999,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2011,2416667,0.013935958703402064
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8131721,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost effective', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2011,238085,-0.018969064888799056
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,7937611,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2010,296413,0.0017109006576924409
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),8110238,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,29814,0.0522048017454333
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.03749379103809066
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,7887777,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2010,273884,-0.0022650512273749016
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7845601,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,TULANE UNIVERSITY OF LOUISIANA,R21,2010,186306,0.011980615301515592
"Methods for genomic data with graphical structures    DESCRIPTION (provided by applicant): The broad, long-term objective of this project concerns the development of novel statistical methods and computational tools for statistical and probabilistic modeling of genomic data motivated by important biological questions and experiments. The specific aim of the current project is to develop new statistical models and methods for analysis of genomic data with graphical structures, focusing on methods for analyzing genetic pathways and networks, including the development of nonparametric pathway-smooth tests for two-sample and analysis of variance problems for identifying pathways with perturbed activity between two or multiple experimental conditions, the development of group Lasso and group threshold gradient descent regularized estimation procedures for the pathway-smoothed generalized linear models, Cox proportional hazards models and the accelerated failure time models in order to identify pathways that are related to various clinical phenotypes. These methods hinge on novel integration of spectral graph theory, non-parametric methods for analysis of multivariate data and regularized estimation methods fro statistical learning. The new methods can be applied to different types of genomic data and will ideally facilitate the identification of genes and biological pathways underlying various complex human diseases and complex biological processes. The project will also investigate the robustness, power and efficiencies o these methods and compare them with existing methods. In addition, this project will develop practical a feasible computer programs in order to implement the proposed methods, to evaluate the performance o these methods through application to real data on microarray gene expression studies of human hear failure, cardiac allograft rejection and neuroblastoma. The work proposed here will contribute both statistical methodology to modeling genomic data with graphical structures, to studying complex phenotypes and biological systems and methods for high-dimensional data analysis, and offer insight into each of the clinical areas represented by the various data sets to evaluate these new methods. All programs developed under this grant and detailed documentation will be made available free-of-charge to interested researchers via the World Wide Web.          n/a",Methods for genomic data with graphical structures,7798186,R01CA127334,"['Address', 'Analysis of Variance', 'Area', 'Biological', 'Biological Process', 'Charge', 'Clinical', 'Collaborations', 'Complex', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Documentation', 'Event', 'Failure', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Graph', 'Hearing', 'Heart failure', 'Human', 'Internet', 'Lasso', 'Linear Models', 'Machine Learning', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Multivariate Analysis', 'Neuroblastoma', 'Pathway interactions', 'Pennsylvania', 'Performance', 'Phenotype', 'Procedures', 'Proteomics', 'Regulatory Pathway', 'Research Personnel', 'Sampling', 'Signal Pathway', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Testing', 'Time', 'Universities', 'Work', 'allograft rejection', 'biological systems', 'clinical phenotype', 'computer program', 'computerized tools', 'genetic analysis', 'heart allograft', 'high throughput technology', 'human disease', 'insight', 'interest', 'novel', 'programs', 'research study', 'response', 'software development', 'theories', 'vector']",NCI,UNIVERSITY OF PENNSYLVANIA,R01,2010,289814,0.01692670419996321
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7797677,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2010,518640,0.01695412973529532
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8066269,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2010,99944,0.01695412973529532
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of time- and space-varying (rather than static) gene network learning, and Bayesian inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks. We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during breast cancer progression and reversal. Since any complex biological processes such as development and disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is unreasonable to assume that the underlying network of gene interaction is invariant throughout the process. But modern experimental and computational methodology is not able to identify such time/space specific network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Unraveling and characterizing such dynamic activities and trajectories of biological networks can provide a more comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of key elements in the network responsible for the functional integrity of the network and the system; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment scheme.",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,7865088,R01GM093156,"['3-Dimensional', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'Architecture', 'Automobile Driving', 'Back', 'Behavior', 'Belief', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Development', 'Developmental Process', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease Progression', 'Documentation', 'Drosophila genus', 'Drug Delivery Systems', 'Embryo', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Hand', 'Heel', 'Human', 'Imagery', 'Immune response', 'Indium', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Light', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Molecular', 'Molecular Genetics', 'Molecular Profiling', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathologic Processes', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physiological Processes', 'Play', 'Problem Formulations', 'Process', 'Property', 'Proteins', 'Publications', 'Publishing', 'RNA Interference', 'Regulation', 'Regulator Genes', 'Regulatory Pathway', 'Reporting', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Software Tools', 'Solutions', 'Source', 'Staging', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Time', 'Time Study', 'Tissues', 'Trees', 'Ursidae Family', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'cell behavior', 'combinatorial', 'computer based statistical methods', 'cost', 'design', 'driving force', 'environmental change', 'fitness', 'gene function', 'gene interaction', 'grasp', 'heuristics', 'improved', 'in vivo', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'mathematical model', 'novel', 'peer', 'prevent', 'programs', 'promoter', 'protein protein interaction', 'public health relevance', 'research study', 'response', 'scale up', 'software systems', 'sound', 'success', 'tomography', 'tool', 'trait', 'trend', 'tumor progression', 'user friendly software', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2010,460864,0.008462327275061467
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7780085,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,3513343,0.006878252007680527
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8138946,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,745063,0.006878252007680527
"National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.   n/a",National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet),8012947,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,3757192,0.05175599725879199
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7910601,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2010,240491,-0.018969064888799056
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7653790,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,397297,-0.010041065315550811
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7685518,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Series', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'new therapeutic target', 'novel', 'pathway tools', 'programs', 'reconstruction']",NLM,SRI INTERNATIONAL,R01,2009,175647,0.02689068713493866
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7914681,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,116802,0.0522048017454333
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7641582,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Classification', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,UNIVERSITY OF MISSOURI KANSAS CITY,R21,2009,219972,0.011980615301515592
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7663288,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Computer Systems Development', 'Computer software', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Source', 'Structure', 'System', 'Systems Integration', 'Technology', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'meetings', 'models and simulation', 'open source', 'outreach', 'protein complex', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,437938,0.0208757042009709
"Methods for genomic data with graphical structures    DESCRIPTION (provided by applicant): The broad, long-term objective of this project concerns the development of novel statistical methods and computational tools for statistical and probabilistic modeling of genomic data motivated by important biological questions and experiments. The specific aim of the current project is to develop new statistical models and methods for analysis of genomic data with graphical structures, focusing on methods for analyzing genetic pathways and networks, including the development of nonparametric pathway-smooth tests for two-sample and analysis of variance problems for identifying pathways with perturbed activity between two or multiple experimental conditions, the development of group Lasso and group threshold gradient descent regularized estimation procedures for the pathway-smoothed generalized linear models, Cox proportional hazards models and the accelerated failure time models in order to identify pathways that are related to various clinical phenotypes. These methods hinge on novel integration of spectral graph theory, non-parametric methods for analysis of multivariate data and regularized estimation methods fro statistical learning. The new methods can be applied to different types of genomic data and will ideally facilitate the identification of genes and biological pathways underlying various complex human diseases and complex biological processes. The project will also investigate the robustness, power and efficiencies o these methods and compare them with existing methods. In addition, this project will develop practical a feasible computer programs in order to implement the proposed methods, to evaluate the performance o these methods through application to real data on microarray gene expression studies of human hear failure, cardiac allograft rejection and neuroblastoma. The work proposed here will contribute both statistical methodology to modeling genomic data with graphical structures, to studying complex phenotypes and biological systems and methods for high-dimensional data analysis, and offer insight into each of the clinical areas represented by the various data sets to evaluate these new methods. All programs developed under this grant and detailed documentation will be made available free-of-charge to interested researchers via the World Wide Web.          n/a",Methods for genomic data with graphical structures,7599555,R01CA127334,"['Address', 'Analysis of Variance', 'Area', 'Biological', 'Biological Process', 'Charge', 'Clinical', 'Collaborations', 'Complex', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Documentation', 'Event', 'Failure', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Graph', 'Hearing', 'Heart failure', 'Human', 'Internet', 'Lasso', 'Linear Models', 'Machine Learning', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Multivariate Analysis', 'Neuroblastoma', 'Pathway interactions', 'Pennsylvania', 'Performance', 'Phenotype', 'Procedures', 'Proteomics', 'Regulatory Pathway', 'Research Personnel', 'Sampling', 'Signal Pathway', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Testing', 'Time', 'Universities', 'Work', 'biological systems', 'clinical phenotype', 'computer program', 'computerized tools', 'genetic analysis', 'heart allograft', 'high throughput technology', 'human disease', 'insight', 'interest', 'novel', 'programs', 'research study', 'response', 'software development', 'theories', 'vector']",NCI,UNIVERSITY OF PENNSYLVANIA,R01,2009,290671,0.01692670419996321
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7589834,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Upper arm', 'Validation', 'aged', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2009,510289,0.01695412973529532
"Machine vision analysis of C.elegans phenotypic patterns    DESCRIPTION (provided by applicant): The nematode C. elegans has powerful genetics, a well-described nervous system, and a complete genome sequence; thus, it is well suited to analysis of behavior and development at the molecular and cellular levels. In particular, the ability to functionally map the influence of particular genes to specific behavioral consequences makes it possible to use genetic analysis to functionally dissect the molecular mechanisms underlying poorly understood aspects of nervous system function. However, many genes with critical roles in neuronal function have effects on behavior that to a casual observer appear very subtle or difficult to describe precisely. Therefore, to fully realize the potential of C. elegans for the genetic analysis of nervous system function, it is necessary to develop sophisticated methods for the rapid and consistent quantitation of mutant phenotypes, especially those related to behavior.       The goal of this proposed work is to develop computer vision tools for quantitatively characterizing the phenotypic patterns caused by mutations or pharmacological treatments in C. elegans. By making it possible to precisely characterize the behavioral phenotypes of mutants with abnormal locomotion or egglaying, these tools will be particularly useful for correlating specific neurotransmission defects with characteristic behavioral patterns. These analytical tools will also be used to generate a comprehensive database containing complex behavioral data on a large set of mutant strains. This database will make it possible to identify groups of mutants and pharmacological treatments that have similar effects on behavior or development. With the accumulation of increasing phenotypic data on known mutants, it should ultimately be possible to record from unknown mutant or drug-treated animals and make informed initial hypotheses about the functions of uncharacterized genes and the targets of uncharacterized drugs.         n/a",Machine vision analysis of C.elegans phenotypic patterns,7633295,R01DA018341,"['Animals', 'Behavior', 'Behavioral', 'Caenorhabditis elegans', 'Calibration', 'Characteristics', 'Coiled Bodies', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Defect', 'Development', 'Gene Targeting', 'Genes', 'Genetic', 'Goals', 'Image Analysis', 'Locomotion', 'Maps', 'Methods', 'Molecular', 'Mutation', 'Nematoda', 'Nervous System Physiology', 'Nervous system structure', 'Neurons', 'Partner in relationship', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Phenotype', 'Population', 'Posture', 'Reproducibility', 'Role', 'System', 'Variant', 'Vision', 'Work', 'analytical tool', 'egg', 'genetic analysis', 'genome sequencing', 'loss of function', 'mutant', 'neurotransmission', 'rapid technique', 'tool']",NIDA,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2009,293485,0.0014338993544340808
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7788875,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Ontology', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'empowered', 'genome wide association study', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'histone modification', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'public health relevance', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2009,142123,-0.004620545754105931
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7595813,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'biological systems', 'comparative', 'computer based statistical methods', 'data integration', 'design', 'flexibility', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface', 'web site']",NIGMS,PRINCETON UNIVERSITY,R01,2009,243004,0.020538394604429352
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7625039,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Base Management', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data exchange', 'data format', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2009,536571,0.010359769559044165
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7941562,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,1038804,0.006878252007680527
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7581087,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,3437506,0.006878252007680527
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7676864,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,3464579,0.0522048017454333
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7669377,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2009,240426,-0.018969064888799056
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7496031,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Genetics', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Numbers', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Range', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,383732,-0.010041065315550811
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7504002,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Score', 'Series', 'Software Tools', 'Standards of Weights and Measures', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'novel', 'programs', 'reconstruction', 'therapeutic target', 'tool']",NLM,SRI INTERNATIONAL,R01,2008,176002,0.02689068713493866
"A Simulation Tool to Enable Identification of Critical Network Interactions Using    DESCRIPTION (provided by applicant): One of the main challenges in the discovery of intracellular biomarkers and identification of therapeutic targets is the lack of a mechanistic understanding of the complex underlying pathways. The tremendous increase in both the quantity and diversity of cellular data represents a significant challenge to researchers seeking to construct biologically relevant interaction maps, and objectively extract specific actionable information. Machine learning based clustering algorithms serve as a preliminary statistical data analysis metric, but they fail to capture the data in the proper biological context. While chemical kinetics based models have proved to be effective in elucidating the pathway mechanisms, accurate estimates for the model parameters are severely lacking and are often impossible to obtain owing to the inherent difficulties involved in making dynamic measurements of specific intracellular phenomena. Additionally, methods for rational prioritization and selection of critical intracellular interactions (in the absence of kinetic information) are sorely lacking. Therefore, there is a clear need for innovative software tools that enable quantitative analysis of available microarray data in a biological pathway context, ultimately leading to the objective identification of critical biological interactions, providing a direction for more focused future efforts. We propose to address this challenge by developing an automated software platform that utilizes microarray data to select and merge relevant canonical biological pathway models thereby placing significantly expressed genes in their biological context. The analysis software will utilize a microarray expression-weighted metric to objectively rank the most critical interactions within the network model using a novel chemical kinetics-free Boolean dynamics algorithm. In the Phase I effort, we will develop a software tool composed of an R library that enables the automated generation of a pathway model from a given microarray dataset. Additionally, a methodology, and associated R library will be developed to objectively rank critical interactions in the pathway model, using a microarray data expression-weighted metric. Demonstration and validation of proposed algorithm will be carried out using a well characterized lipopolysaccharide (LPS) stimulated RAW 264.7 macrophage system. In Phase II, we will extend the scope of the algorithmic framework to include proteomic and metabolomic weighting in the objective ranking of critical interactions, and add workflow improvements through the addition of a graphical user interface (GUI). Experimental verification and validation of critical interactions identified in Phase I will be carried out using gene-silencing techniques. We also intend to establish collaborative partnerships with commercial entities. The proposing team has extensive experience in the areas of systems biology and bioinformatics (CFDRC) and microarray data analysis (Shawn Levy, University of Vanderbilt). CFDRC has a strong track record in the commercialization of software and hardware. PUBLIC HEALTH RELEVANCE:  Recently, there has been a tremendous increase in both the amount and diversity of cellular data available to researchers, representing a clear need for the development of advanced computational analysis software to enable the discovery of biomarkers of disease states, and identification of new therapeutic targets. However, currently available analysis tools do not consider the data in a proper biological context. This research proposes to develop an automated software platform that utilizes available data to develop and analyze mathematical models of complex processes in an automated fashion, resulting in the identification of critical intracellular processes.             n/a",A Simulation Tool to Enable Identification of Critical Network Interactions Using,7482734,R43GM084890,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Biological Markers', 'Complex', 'Computer Analysis', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Future', 'Gene Silencing', 'Generations', 'Genes', 'Genomics', 'Kinetics', 'Lead', 'Libraries', 'Lipopolysaccharides', 'Machine Learning', 'Maps', 'Measurement', 'Methodology', 'Methods', 'Metric', 'Microarray Analysis', 'Modeling', 'Nature', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Process', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Software Tools', 'Statistical Data Interpretation', 'System', 'Systems Biology', 'Techniques', 'Title', 'Universities', 'Urination', 'Validation', 'Weight', 'base', 'chemical kinetics', 'commercialization', 'editorial', 'experience', 'graphical user interface', 'innovation', 'macrophage', 'mathematical model', 'metabolomics', 'network models', 'novel', 'novel therapeutics', 'simulation', 'therapeutic target', 'tool']",NIGMS,CFD RESEARCH CORPORATION,R43,2008,99571,0.02047354931360348
"Nation Center: Multi-Scale Study- Cellular Networks(RMI) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genomewide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 1 investigators to combine molecular interaction clues from Core 2 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions. n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7674889,U54CA121852,"['Address', 'Algorithms', 'Area', 'Automobile Driving', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA-Protein Interaction', 'Databases', 'Development', 'Dissection', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Genes', 'Genetic Engineering', 'Genomics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Published Comment', 'Range', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Science', 'Signal Pathway', 'Skeleton', 'Source', 'Structure', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'Work', 'base', 'computer framework', 'data mining', 'design', 'graphical user interface', 'improved', 'innovation', 'knowledge base', 'multidisciplinary', 'novel', 'response', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,113826,0.05016450888552011
"Methods for genomic data with graphical structures    DESCRIPTION (provided by applicant): The broad, long-term objective of this project concerns the development of novel statistical methods and computational tools for statistical and probabilistic modeling of genomic data motivated by important biological questions and experiments. The specific aim of the current project is to develop new statistical models and methods for analysis of genomic data with graphical structures, focusing on methods for analyzing genetic pathways and networks, including the development of nonparametric pathway-smooth tests for two-sample and analysis of variance problems for identifying pathways with perturbed activity between two or multiple experimental conditions, the development of group Lasso and group threshold gradient descent regularized estimation procedures for the pathway-smoothed generalized linear models, Cox proportional hazards models and the accelerated failure time models in order to identify pathways that are related to various clinical phenotypes. These methods hinge on novel integration of spectral graph theory, non-parametric methods for analysis of multivariate data and regularized estimation methods fro statistical learning. The new methods can be applied to different types of genomic data and will ideally facilitate the identification of genes and biological pathways underlying various complex human diseases and complex biological processes. The project will also investigate the robustness, power and efficiencies o these methods and compare them with existing methods. In addition, this project will develop practical a feasible computer programs in order to implement the proposed methods, to evaluate the performance o these methods through application to real data on microarray gene expression studies of human hear failure, cardiac allograft rejection and neuroblastoma. The work proposed here will contribute both statistical methodology to modeling genomic data with graphical structures, to studying complex phenotypes and biological systems and methods for high-dimensional data analysis, and offer insight into each of the clinical areas represented by the various data sets to evaluate these new methods. All programs developed under this grant and detailed documentation will be made available free-of-charge to interested researchers via the World Wide Web.          n/a",Methods for genomic data with graphical structures,7407451,R01CA127334,"['Address', 'Analysis of Variance', 'Area', 'Biological', 'Biological Process', 'Charge', 'Clinical', 'Collaborations', 'Complex', 'Computer software', 'Condition', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease regression', 'Documentation', 'Event', 'Failure', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Graph', 'Hearing', 'Heart failure', 'Human', 'Internet', 'Lasso', 'Linear Models', 'Machine Learning', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Multivariate Analysis', 'Neuroblastoma', 'Pathway interactions', 'Pennsylvania', 'Performance', 'Phenotype', 'Procedures', 'Proteomics', 'Regulatory Pathway', 'Research Personnel', 'Sampling', 'Signal Pathway', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Testing', 'Time', 'Universities', 'Work', 'clinical phenotype', 'computer program', 'computerized tools', 'genetic analysis', 'heart allograft', 'high throughput technology', 'human disease', 'insight', 'interest', 'novel', 'programs', 'research study', 'response', 'software development', 'theories', 'vector']",NCI,UNIVERSITY OF PENNSYLVANIA,R01,2008,291451,0.01692670419996321
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7457647,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,437938,0.0208757042009709
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7462512,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Numbers', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoinositide-3-Kinase, Catalytic, Gamma Polypeptide', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Protein Overexpression', 'Proteins', 'Public Health', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Upper arm', 'Validation', 'aged', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2008,499742,0.01695412973529532
"Machine vision analysis of C.elegans phenotypic patterns    DESCRIPTION (provided by applicant): The nematode C. elegans has powerful genetics, a well-described nervous system, and a complete genome sequence; thus, it is well suited to analysis of behavior and development at the molecular and cellular levels. In particular, the ability to functionally map the influence of particular genes to specific behavioral consequences makes it possible to use genetic analysis to functionally dissect the molecular mechanisms underlying poorly understood aspects of nervous system function. However, many genes with critical roles in neuronal function have effects on behavior that to a casual observer appear very subtle or difficult to describe precisely. Therefore, to fully realize the potential of C. elegans for the genetic analysis of nervous system function, it is necessary to develop sophisticated methods for the rapid and consistent quantitation of mutant phenotypes, especially those related to behavior.       The goal of this proposed work is to develop computer vision tools for quantitatively characterizing the phenotypic patterns caused by mutations or pharmacological treatments in C. elegans. By making it possible to precisely characterize the behavioral phenotypes of mutants with abnormal locomotion or egglaying, these tools will be particularly useful for correlating specific neurotransmission defects with characteristic behavioral patterns. These analytical tools will also be used to generate a comprehensive database containing complex behavioral data on a large set of mutant strains. This database will make it possible to identify groups of mutants and pharmacological treatments that have similar effects on behavior or development. With the accumulation of increasing phenotypic data on known mutants, it should ultimately be possible to record from unknown mutant or drug-treated animals and make informed initial hypotheses about the functions of uncharacterized genes and the targets of uncharacterized drugs.         n/a",Machine vision analysis of C.elegans phenotypic patterns,7440354,R01DA018341,"['Animals', 'Behavior', 'Behavioral', 'Caenorhabditis elegans', 'Calibration', 'Characteristics', 'Coiled Bodies', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Defect', 'Development', 'Gene Targeting', 'Genes', 'Genetic', 'Goals', 'Image Analysis', 'Locomotion', 'Maps', 'Methods', 'Molecular', 'Mutation', 'Nematoda', 'Nervous System Physiology', 'Nervous system structure', 'Neurons', 'Partner in relationship', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Phenotype', 'Population', 'Posture', 'Reproducibility', 'Role', 'System', 'Variant', 'Vision', 'Work', 'analytical tool', 'egg', 'genetic analysis', 'genome sequencing', 'loss of function', 'mutant', 'neurotransmission', 'rapid technique', 'tool']",NIDA,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2008,282792,0.0014338993544340808
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7404447,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2008,243004,0.020538394604429352
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7538527,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'GDF15 gene', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Histones', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Modification', 'Numbers', 'Ontology', 'PLAB Protein', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'RNA', 'Range', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2008,157474,-0.004620545754105931
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7440169,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2008,535031,0.010359769559044165
"Causal Discovery Algorithms for Translational Research with High-Throughput Data Project Summary Causal Discovery Algorithms for Translational Research with High-Throughput Data The long-term goal of this project is to provide to the biomedical community next-generation causal algorithms to facilitate discovery of disease molecular pathways and causative as well as predictive biomarkers and molecular signatures from high-throughput data. Such knowledge and methods are necessary toward earlier and more accurate diagnosis and prognosis, personalized medicine, and rational drug design. If successful, the proposed research will have significant and wide methodological and practical implications spanning several areas of biomedicine with a primary focus and immediate benefits in high-throughput diagnostics and personalized medicine. It will provide significantly improved computational methods and deeper theoretical understanding related to producing molecular signatures and understanding mechanisms of disease and concomitant leads for new drugs. It will provide evidence about applicability of novel causal methods in other types of data. It will generate insights in specific pathways of lung cancer in humans. It will deepen our understanding and solutions to the Rashomon effect in ¿omics¿ data. The proposed research will also shed light on the operational value of the stability heuristic. Finally the research will engage the international research community to address open computational causal discovery problems relevant to high-throughput and other biomedical data. ¿ Aim 1. Evaluate and characterize several novel causal algorithms for biomarker selection, molecular signature creation and reverse network engineering using real, simulated, resimulated, and experimental datasets. Study generality of the methods by means of applicability to non-¿omics¿ datasets. ¿ Aim 2. Evaluate and characterize, novel and state of the art causal algorithms against state-of-the-art non-causal and quasi-causal algorithms. ¿ Aim 3. Systematically investigate the Rashomon effect as it applies to biomarker and signature multiplicity. ¿ Aim 4. Systematically investigate the utility of applying the stability heuristic for causal discovery. ¿ Aim 5. Derive novel biomarkers, pathways and hypotheses for lung cancer. ¿ Aim 6. Induce novel solutions through an international causal discovery competition. ¿ Aim 7. Disseminate findings. n/a",Causal Discovery Algorithms for Translational Research with High-Throughput Data,7643514,R56LM007948,"['AKT1 gene', 'AKT2 gene', 'AKT3 gene', 'Address', 'Affect', 'Algorithms', 'Area', 'Arts', 'Benchmarking', 'Bioinformatics', 'Biologic Characteristic', 'Biological Markers', 'Biology', 'Biometry', 'Book Chapters', 'Books', 'Cancer cell line', 'Causations', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consultations', 'Data', 'Data Set', 'Depth', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Drug Design', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Ensure', 'Epidermal Growth Factor Receptor', 'European', 'Evaluation', 'Event', 'Excision', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Hereditary Disease', 'Home environment', 'Human', 'Human Cell Line', 'Inferior', 'Information Retrieval', 'Institution', 'International', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Light', 'Localized', 'Machine Learning', 'Malignant neoplasm of lung', 'Marker Discovery', 'Medicine', 'Methods', 'Modality', 'Molecular', 'Molecular Profiling', 'Neighborhoods', 'Noise', 'Numbers', 'Online Systems', 'Outcome', 'Output', 'Paper', 'Pathway interactions', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Proteomics', 'Protocols documentation', 'Public Domains', 'Publishing', 'Quality Control', 'Random Allocation', 'Randomized', 'Rate', 'Research', 'Research Personnel', 'Research Proposals', 'Role', 'Sample Size', 'Sampling', 'Schedule', 'Score', 'Services', 'Simulate', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Testing', 'Text', 'Thinking', 'Tissues', 'Translational Research', 'Variant', 'Work', 'base', 'c-erbB-1 Proto-Oncogenes', 'clinically relevant', 'computer based statistical methods', 'computer science', 'contextual factors', 'coping', 'data mining', 'design', 'drug development', 'heuristics', 'human data', 'human tissue', 'improved', 'innovation', 'insight', 'journal article', 'member', 'new technology', 'next generation', 'novel', 'novel diagnostics', 'outcome forecast', 'reconstruction', 'research study', 'software systems', 'symposium', 'theories', 'tool']",NLM,VANDERBILT UNIVERSITY,R56,2008,4434,-0.03628571658774203
"System-wide Study of Transcriptional Control of Metabolism    DESCRIPTION (provided by applicant): This proposal is in response to the NIH call for Exploratory Collaborations with National Centers for Biomedical Computing, PAR-06-223, and it will involve a collaboration between Columbia University's MAGNet NCBC and a team at Los Alamos National Laboratory. The aim of the proposal is a system-wide tudy of integrated transcriptional and metabolic networks in Eschericia coli K-12 strain, aiming at a similar analysis of a pathogen, Bacillus anthracis, at a later date. LANL hosts an experimental research program on bacterial metabolomics. Metabolites serve several functions. The most common one is being the precursors to various cellular components. They are also regulators of cellular functions by means of modulating metabolic reactions or binding to transcription factors and subsequently regulating gene expression. Conversely, the genes regulated by a transcription factor often encode enzymes, modulating the speed of metabolic reactions. Thus, to understand and ultimately predict the cellular response to an environmental change of interest (e.g., pathogen entry into its host environment), we must integrate the analysis of the transcriptome and metabolome. To address this need, we will work with the laboratories of Pat Unkefer and John Dunbar, which will produce data sets of about 300 joint metabolic/transcriptional profiles of E.coli under different steady-state growth conditions. The resources of MAGnet NCBC, specifically the algorithms within the geWorkbench bioinformatics platform produced by the center, will be leveraged to reconstruct cellular networks. Specifically, we expect that ARACNE, an algorithm originally developed by MAGNet for high-fidelity analysis of transcriptional networks in mammalian cells, is well positioned for reconstruction of metabolic networks from high throughput system-wide metabolic activity data, provide that appropriate modifications to deal with the specifics of the metabolic data are made. We will also adapt the algorithm to discover modulated interactions, that is, metabolic interactions that are conditional on the activity of a modulator gene (enzyme), or transcriptional interactions that require the presence of a metabolite to proceed. Such integrated genome/metabolome analysis has not been attempted yet. It will be a giant leap towards a complete understanding of cellular processes in an important organism. Because of the comparatively small size of bacterial genomes and metabolomes, it will be possible to perform system-wide analyses of interactions for the entire integrated genome and metabolome. While important in its own right, especially in view of the pathogenic nature of B. anthracis, this research would also represent an important test bed for a subsequent study of metabolic diseases in higher animals, including humans.           n/a",System-wide Study of Transcriptional Control of Metabolism,7387471,R21GM080216,"['Accounting', 'Address', 'Affect', 'Affinity', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Architecture', 'Autistic Disorder', 'Automobile Driving', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Bacillus anthracis', 'Bacterial Genome', 'Beds', 'Benchmarking', 'Binding', 'Biochemical', 'Biochemical Pathway', 'Biochemical Reaction', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Cadherins', 'Cell Adhesion Molecules', 'Cell Separation', 'Cell physiology', 'Cell-Cell Adhesion', 'Cells', 'Chemicals', 'Code', 'Collaborations', 'Commit', 'Communities', 'Complex', 'Computational Biology', 'Computational Technique', 'Computational algorithm', 'Computer Analysis', 'Computer Simulation', 'Computer software', 'Computers', 'Concentration measurement', 'Condition', 'Crystallography', 'DNA Binding', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Dissection', 'Documentation', 'Drug Formulations', 'Drug Interactions', 'Educational workshop', 'Electrical Engineering', 'Engineering', 'Ensure', 'Environment', 'Enzyme Gene', 'Enzymes', 'Escherichia coli', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health Sciences', 'Human', 'Imagery', 'Immune system', 'In Vitro', 'Informatics', 'Institutes', 'Institution', 'Internet', 'Java', 'Joints', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Literature', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Mammalian Cell', 'Manuals', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Metabolic', 'Metabolic Control', 'Metabolic Diseases', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Multimedia', 'Nature', 'Noise', 'Online Systems', 'Ontology', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Phosphotransferases', 'Physics', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Prokaryotic Cells', 'Property', 'Protein Analysis', 'Protein Family', 'Proteins', 'Proteome', 'Publishing', 'RNA', 'Range', 'Rate', 'Reaction', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling', 'Semantics', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Site', 'Software Engineering', 'Solutions', 'Source Code', 'Specific qualifier value', 'Specificity', 'Speed', 'Structural Protein', 'Structure', 'Structure of germinal center of lymph node', 'Students', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Universities', 'Validation', 'Virulence', 'Visual', 'Work', 'base', 'biocomputing', 'biomedical informatics', 'computer framework', 'computer studies', 'computerized tools', 'concept', 'data acquisition', 'data mining', 'data modeling', 'design', 'environmental change', 'experience', 'forging', 'hazard', 'improved', 'innovation', 'interest', 'interoperability', 'knowledge base', 'member', 'metabolomics', 'microbial', 'multidisciplinary', 'nervous system disorder', 'novel', 'pathogen', 'pathogenic bacteria', 'professor', 'programs', 'protein protein interaction', 'reconstruction', 'research study', 'response', 'simulation', 'size', 'software development', 'text searching', 'tool', 'transcription factor']",NIGMS,LOS ALAMOS NAT SECTY-LOS ALAMOS NAT LAB,R21,2008,220227,-0.017891671532664178
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7483692,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2008,242920,-0.018969064888799056
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7502135,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,3570137,0.0522048017454333
"WormBase: a core data resource for C elegans and other nematodes    DESCRIPTION (provided by applicant):  Caenorhabditis elegans is a major model system for basic biological and biomedical research and the first animal for which there is a complete description of its genome, anatomy and development, and some information about each of its ~22,000 genes. Five years of funding is requested to maintain and expand WormBase, a Model Organism Database (MOD), with complete coverage of core genomic, genetic, anatomical and functional information about this and other nematodes. Such a database is necessary to allow the entire biomedical research community to make full use of nematode genomic sequences. The two top priorities will be intensive data curation and user interface improvement. WormBase will include up-to-date annotation of the genomic data, the current genetic and physical maps and many experimental data such as genome-scale datasets connected to the function and interactions of cells and genes, as well as development, physiology and behavior. Direct access to the sources of biological material, such as the strain collection of the Caenorhabditis Genetics Center and direct links to data sets maintained by others will be provided. Data will be recovered from the existing resources, from direct contribution of the individual laboratories, and from the literature. While WormBase will act as a central forum through which every laboratory will be able to contribute constructively to the global effort to fully comprehend this metazoan organism, WormBase professional curators will ensure detailed attribution of data sources and check consistency and integrity. To facilitate communication, WormBase will use technology, terminology and style concordant with other databases wherever possible. WormBase will maintain ontologies for nematode anatomy and phenotypes. WormBase will be Web-based and easy to use. Multiple relational databases will be used for data management; the object-based Acedb database system will be used for integration, and this integrated database plus ""slave"" relational databases will be used to drive the website. Coordination of the project and the main curation site will be at Caltech under the supervision of a C. elegans biologist. Curation and annotation of genomic sequence will take place at the centers - the Sanger Institute and Washington University - that generated the entire genome sequence. Oxford University will maintain genetic nomenclature.  Nematodes (roundworms) are major parasites of humans, livestock and crops, and extension of WormBase to broader coverage of nematode genomics will facilitate research into the diagnosis and treatment of nematode-based disease. Studies of C. elegans have informed us of basic principles of normal development and the molecular basis of aging, cancer, nicotine addiction, as well as a variety of fundamental biological processes such as cell migration, cell differentiation and cell death.              n/a",WormBase: a core data resource for C elegans and other nematodes,7502984,P41HG002223,"['Ablation', 'Age', 'Agriculture', 'Alleles', 'Anatomy', 'Animals', 'Antibodies', 'Architecture', 'Base Sequence', 'Behavior', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biomedical Research', 'Caenorhabditis', 'Caenorhabditis elegans', 'Cell Communication', 'Cell Death', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Chromosome Mapping', 'Code', 'Collection', 'Communication', 'Communities', 'Comparative Anatomy', 'Compatible', 'DNA Sequence', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Ensure', 'Expressed Sequence Tags', 'Funding', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Processes', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Institutes', 'Internet', 'Knock-out', 'Knowledge', 'Laboratories', 'Link', 'Literature', 'Livestock', 'Longevity', 'Malignant Neoplasms', 'Maps', 'Medical', 'Metabolic', 'Methods', 'Molecular', 'Molecular Genetics', 'Mutation', 'Names', 'Natural Language Processing', 'Nature', 'Nematoda', 'Nicotine Dependence', 'Nomenclature', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Parasites', 'Parasitic nematode', 'Pathway interactions', 'Phenotype', 'Physical Chromosome Mapping', 'Physiology', 'Pliability', 'Process', 'Proteins', 'Proteomics', 'RNA Interference', 'Reagent', 'Regulation', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Secure', 'Site', 'Slave', 'Source', 'Subcellular Anatomy', 'Supervision', 'System', 'Techniques', 'Technology', 'Terminology', 'Tertiary Protein Structure', 'Transcript', 'Transgenes', 'Transgenic Organisms', 'Universities', 'Variant', 'Washington', 'Yeasts', 'base', 'cell motility', 'chromatin immunoprecipitation', 'comparative', 'comparative genomic hybridization', 'data integration', 'data management', 'data modeling', 'design', 'experience', 'functional genomics', 'gene function', 'genetic analysis', 'genome sequencing', 'improved', 'interoperability', 'member', 'migration', 'model organisms databases', 'programs', 'research study', 'small molecule', 'tool', 'transcription factor', 'usability', 'web interface', 'yeast two hybrid system']",NHGRI,CALIFORNIA INSTITUTE OF TECHNOLOGY,P41,2008,2750000,0.012081587634720703
"Technology Development for a MolBio Knowledge-Base Since the introduction of the Mycin system more than 25 years ago, it has widely been hypothesized that extensive, well-represented computer knowledge-bases will facilitate a wide variety of scientific and clinical tasks. Driven by growing knowledge-management challenges adsing from the proliferation of high- throughput instrumentation, recently created knowledge-bases in areas related to genomics and related aspects of contemporary biology, such as the Gene Ontology, EcoCyc and PharmGKB, have begun to become integrated into the laboratory practices of a growing number of molecular biologists. However, these successful molecular biology knowledge-bases (MBKBs) have two drawbacks which impede their more general application: each has been narrowed to a particular special purpose, either in its domain of applicability or in the scope of knowledge represented, and each of these knowledge-bases was constructed largely on the basis of enormous human effort. Given the current state of molecular biology data and recent iadvances in database integration and information extraction technology, we proposed to test the following hypothesis: Current computational technology and existing human-curated knowledge resources are sufficient to build an extensive, high-quality computational knowledge-base of molecular biology. To test this hypothesis we propose to first create tools which can (a) automatically link incommensurate knowledge sources using semantic linking, and (b) use natural language processing techniques to extract new information from NCBrs GeneRIFs and from the GO definitions fields; and second, to evaluate the results of these methods by carefully quantifying the degree to which the induced linkages and extracted assertions are complete, consistent and correct. Although we propose to construct a broad and rich knowledge-base in order to develop and test the adequacy of largely automated methods to leverage existing human-curated collections, we do not propose to build a comprehensive MBKB. n/a",Technology Development for a MolBio Knowledge-Base,7473405,R01LM008111,"['Address', 'Area', 'Biology', 'Class', 'Clinical', 'Collection', 'Data', 'Databases', 'Evaluation', 'Facility Construction Funding Category', 'Genes', 'Genome', 'Genomics', 'Genotype', 'Human', 'Indium', 'Informatics', 'Information Resources', 'Information Resources Management', 'Investments', 'Knowledge', 'Knowledge Base (Computer)', 'Laboratories', 'Language', 'Link', 'Machine Learning', 'Manuals', 'Metabolism', 'Methods', 'Metric System', 'Molecular', 'Molecular Biology', 'Mus', 'Names', 'Natural Language Processing', 'Numbers', 'Ontology', 'Persons', 'Pharmaceutical Preparations', 'Plug-in', 'Proteins', 'Purpose', 'Semantics', 'Source', 'SwissProt', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'Work', 'base', 'concept', 'data integration', 'gene function', 'heuristics', 'instrumentation', 'knowledge base', 'success', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2007,234058,0.025821720158078026
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7322388,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Genetics', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Numbers', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Range', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,364130,-0.010041065315550811
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7301424,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Score', 'Series', 'Software Tools', 'Standards of Weights and Measures', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'novel', 'programs', 'reconstruction', 'therapeutic target', 'tool']",NLM,SRI INTERNATIONAL,R01,2007,173307,0.02689068713493866
"Methods for genomic data with graphical structures    DESCRIPTION (provided by applicant): The broad, long-term objective of this project concerns the development of novel statistical methods and computational tools for statistical and probabilistic modeling of genomic data motivated by important biological questions and experiments. The specific aim of the current project is to develop new statistical models and methods for analysis of genomic data with graphical structures, focusing on methods for analyzing genetic pathways and networks, including the development of nonparametric pathway-smooth tests for two-sample and analysis of variance problems for identifying pathways with perturbed activity between two or multiple experimental conditions, the development of group Lasso and group threshold gradient descent regularized estimation procedures for the pathway-smoothed generalized linear models, Cox proportional hazards models and the accelerated failure time models in order to identify pathways that are related to various clinical phenotypes. These methods hinge on novel integration of spectral graph theory, non-parametric methods for analysis of multivariate data and regularized estimation methods fro statistical learning. The new methods can be applied to different types of genomic data and will ideally facilitate the identification of genes and biological pathways underlying various complex human diseases and complex biological processes. The project will also investigate the robustness, power and efficiencies o these methods and compare them with existing methods. In addition, this project will develop practical a feasible computer programs in order to implement the proposed methods, to evaluate the performance o these methods through application to real data on microarray gene expression studies of human hear failure, cardiac allograft rejection and neuroblastoma. The work proposed here will contribute both statistical methodology to modeling genomic data with graphical structures, to studying complex phenotypes and biological systems and methods for high-dimensional data analysis, and offer insight into each of the clinical areas represented by the various data sets to evaluate these new methods. All programs developed under this grant and detailed documentation will be made available free-of-charge to interested researchers via the World Wide Web.          n/a",Methods for genomic data with graphical structures,7247404,R01CA127334,"['Address', 'Analysis of Variance', 'Area', 'Biological', 'Biological Process', 'Charge', 'Clinical', 'Collaborations', 'Complex', 'Computer software', 'Condition', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease regression', 'Documentation', 'Event', 'Failure', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Graph', 'Hearing', 'Heart failure', 'Human', 'Internet', 'Lasso', 'Linear Models', 'Machine Learning', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Multivariate Analysis', 'Neuroblastoma', 'Pathway interactions', 'Pennsylvania', 'Performance', 'Phenotype', 'Procedures', 'Proteomics', 'Regulatory Pathway', 'Research Personnel', 'Sampling', 'Signal Pathway', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Testing', 'Time', 'Universities', 'Work', 'clinical phenotype', 'computer program', 'computerized tools', 'genetic analysis', 'heart allograft', 'high throughput technology', 'human disease', 'insight', 'interest', 'novel', 'programs', 'research study', 'response', 'software development', 'theories', 'vector']",NCI,UNIVERSITY OF PENNSYLVANIA,R01,2007,292160,0.01692670419996321
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7287965,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,446875,0.0208757042009709
"Machine vision analysis of C.elegans phenotypic patterns    DESCRIPTION (provided by applicant): The nematode C. elegans has powerful genetics, a well-described nervous system, and a complete genome sequence; thus, it is well suited to analysis of behavior and development at the molecular and cellular levels. In particular, the ability to functionally map the influence of particular genes to specific behavioral consequences makes it possible to use genetic analysis to functionally dissect the molecular mechanisms underlying poorly understood aspects of nervous system function. However, many genes with critical roles in neuronal function have effects on behavior that to a casual observer appear very subtle or difficult to describe precisely. Therefore, to fully realize the potential of C. elegans for the genetic analysis of nervous system function, it is necessary to develop sophisticated methods for the rapid and consistent quantitation of mutant phenotypes, especially those related to behavior.       The goal of this proposed work is to develop computer vision tools for quantitatively characterizing the phenotypic patterns caused by mutations or pharmacological treatments in C. elegans. By making it possible to precisely characterize the behavioral phenotypes of mutants with abnormal locomotion or egglaying, these tools will be particularly useful for correlating specific neurotransmission defects with characteristic behavioral patterns. These analytical tools will also be used to generate a comprehensive database containing complex behavioral data on a large set of mutant strains. This database will make it possible to identify groups of mutants and pharmacological treatments that have similar effects on behavior or development. With the accumulation of increasing phenotypic data on known mutants, it should ultimately be possible to record from unknown mutant or drug-treated animals and make informed initial hypotheses about the functions of uncharacterized genes and the targets of uncharacterized drugs.         n/a",Machine vision analysis of C.elegans phenotypic patterns,7270627,R01DA018341,"['Animals', 'Behavior', 'Behavioral', 'Caenorhabditis elegans', 'Calibration', 'Characteristics', 'Coiled Bodies', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Defect', 'Development', 'Gene Targeting', 'Genes', 'Genetic', 'Goals', 'Image Analysis', 'Locomotion', 'Maps', 'Methods', 'Molecular', 'Mutation', 'Nematoda', 'Nervous System Physiology', 'Nervous system structure', 'Neurons', 'Partner in relationship', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Phenotype', 'Population', 'Posture', 'Reproducibility', 'Role', 'System', 'Variant', 'Vision', 'Work', 'analytical tool', 'egg', 'genetic analysis', 'genome sequencing', 'loss of function', 'mutant', 'neurotransmission', 'rapid technique', 'tool']",NIDA,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2007,279238,0.0014338993544340808
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7214148,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2007,240927,0.020538394604429352
"Bayesian Methods and Experimental Design for Molecular Biology Experiments    DESCRIPTION (provided by applicant): The goal of this proposal is to provide a suite of software tools for bioinformatics and systems biology researchers who are using molecular biology (Omics) data to identify the best experimental design and to analyze the resulting experimental data using Bayesian tools. A common problem for most bioinformatics experiments is low power due to low replication. This problem can be alleviated economically when an increase in adoption and use of a specific platform leads to a decrease in associated costs, thereby enabling an increase in samples allocated per treatment. Yet, many bioinformatics experiments remain underpowered as researchers use the offsets of decreased costs to explore more complex questions. When designing an experiment, the allocation of samples to treatment regimens, and the choice of treatments to test, are traditionally the only variables to manipulate. Bayesian experimental design provides a framework to find the optimal design out of n possible designs subject to a utility function that can include such items as time and material costs.      Bayesian statistical methods have been gaining substantial favor in bioinformatics and systems biology as they provide a highly flexible framework for fitting and exploring complex models. Bayesian models also provides to domain experts such as biologists and physicians easily interpretable models through posterior probabilities which are more naturally understood than the traditional p-value. While a number of open source tools based on Bayesian models are available, most are applied best in the context of a specific research data analysis problem or model and are not integrated into a single, complete system for data analysis.      We propose to research and develop a statistical analysis software package S+OBAYES (for S-PLUS and R) with generalized tools for Bayesian design of experiments, empirical and fully Bayesian analysis, and modeling and simulation using modern commercial software development practices. These tools will provide functionality for finding the optimal choice and layout of experimental treatments for molecular biology experiments and for fitting Bayesian linear and non-linear models to a variety of data types including time series. We propose to validate the software in molecular biology research problems such as the detection of differential gene, protein, and metabolite abundance. The benefits of this work will be a commercial-quality software package with validated statistical methodology and interactive visualization tools that will appeal to molecular biologists and systems biology investigators. The results of the proposed work will expedite discoveries in basic science, early disease detection, and drug discovery and development.          n/a",Bayesian Methods and Experimental Design for Molecular Biology Experiments,7325828,R43GM083023,"['Address', 'Adoption', 'Algorithms', 'Animal Genetics', 'Arizona', 'Basic Science', 'Bayesian Analysis', 'Bayesian Method', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biometry', 'Biotechnology', 'Cations', 'Chromosome Mapping', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Government', 'Government Agencies', 'Health', 'Imagery', 'Industry', 'Information Systems', 'Institution', 'Iowa', 'Libraries', 'Linear Models', 'Machine Learning', 'Manuals', 'Manuscripts', 'Maps', 'Marketing', 'Mass Spectrum Analysis', 'Measures', 'Medical Informatics', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular', 'Molecular Biology', 'Non-linear Models', 'Numbers', 'Pathway interactions', 'Phase', 'Physicians', 'Population Study', 'Principal Investigator', 'Probability', 'Property', 'Proteome', 'Proteomics', 'Proxy', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Rice', 'Risk Factors', 'SNP genotyping', 'Sampling', 'Science', 'Scientist', 'Series', 'Services', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Software Validation', 'Solutions', 'Speed', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Systems Biology', 'Techniques', 'Telecommunications', 'Testing', 'Time', 'Time Series Analysis', 'Training', 'Treatment Protocols', 'Universities', 'Validation', 'Washington', 'Wisconsin', 'Work', 'animal breeding', 'base', 'cost', 'design', 'drug discovery', 'experience', 'human subject', 'improved', 'interest', 'lecturer', 'models and simulation', 'open source', 'professor', 'programs', 'protein metabolite', 'research and development', 'research study', 'skills', 'software development', 'statistics', 'success', 'theories', 'tool', 'treatment effect']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,103995,0.010630770409896925
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7240459,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2007,543226,0.010359769559044165
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7185305,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Biology, Other', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Computer information processing', 'Data', 'Databases', 'Depth', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'functional genomics', 'genetic element', 'genome database', 'human disease', 'interest', 'model organisms databases', 'repository', 'size', 'tool']",NHGRI,JACKSON LABORATORY,P41,2007,3146180,0.006878252007680527
"System-wide Study of Transcriptional Control of Metabolism    DESCRIPTION (provided by applicant): This proposal is in response to the NIH call for Exploratory Collaborations with National Centers for Biomedical Computing, PAR-06-223, and it will involve a collaboration between Columbia University's MAGNet NCBC and a team at Los Alamos National Laboratory. The aim of the proposal is a system-wide tudy of integrated transcriptional and metabolic networks in Eschericia coli K-12 strain, aiming at a similar analysis of a pathogen, Bacillus anthracis, at a later date. LANL hosts an experimental research program on bacterial metabolomics. Metabolites serve several functions. The most common one is being the precursors to various cellular components. They are also regulators of cellular functions by means of modulating metabolic reactions or binding to transcription factors and subsequently regulating gene expression. Conversely, the genes regulated by a transcription factor often encode enzymes, modulating the speed of metabolic reactions. Thus, to understand and ultimately predict the cellular response to an environmental change of interest (e.g., pathogen entry into its host environment), we must integrate the analysis of the transcriptome and metabolome. To address this need, we will work with the laboratories of Pat Unkefer and John Dunbar, which will produce data sets of about 300 joint metabolic/transcriptional profiles of E.coli under different steady-state growth conditions. The resources of MAGnet NCBC, specifically the algorithms within the geWorkbench bioinformatics platform produced by the center, will be leveraged to reconstruct cellular networks. Specifically, we expect that ARACNE, an algorithm originally developed by MAGNet for high-fidelity analysis of transcriptional networks in mammalian cells, is well positioned for reconstruction of metabolic networks from high throughput system-wide metabolic activity data, provide that appropriate modifications to deal with the specifics of the metabolic data are made. We will also adapt the algorithm to discover modulated interactions, that is, metabolic interactions that are conditional on the activity of a modulator gene (enzyme), or transcriptional interactions that require the presence of a metabolite to proceed. Such integrated genome/metabolome analysis has not been attempted yet. It will be a giant leap towards a complete understanding of cellular processes in an important organism. Because of the comparatively small size of bacterial genomes and metabolomes, it will be possible to perform system-wide analyses of interactions for the entire integrated genome and metabolome. While important in its own right, especially in view of the pathogenic nature of B. anthracis, this research would also represent an important test bed for a subsequent study of metabolic diseases in higher animals, including humans.           n/a",System-wide Study of Transcriptional Control of Metabolism,7234993,R21GM080216,"['Accounting', 'Address', 'Affect', 'Affinity', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Architecture', 'Autistic Disorder', 'Automobile Driving', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Bacillus anthracis', 'Bacterial Genome', 'Beds', 'Benchmarking', 'Binding', 'Biochemical', 'Biochemical Pathway', 'Biochemical Reaction', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Cadherins', 'Cell Adhesion Molecules', 'Cell Separation', 'Cell physiology', 'Cell-Cell Adhesion', 'Cells', 'Chemicals', 'Code', 'Collaborations', 'Commit', 'Communities', 'Complex', 'Computational Biology', 'Computational Technique', 'Computational algorithm', 'Computer Analysis', 'Computer Simulation', 'Computer software', 'Computers', 'Concentration measurement', 'Condition', 'Crystallography', 'DNA Binding', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Dissection', 'Documentation', 'Drug Formulations', 'Drug Interactions', 'Educational workshop', 'Electrical Engineering', 'Engineering', 'Ensure', 'Environment', 'Enzyme Gene', 'Enzymes', 'Escherichia coli', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health Sciences', 'Human', 'Imagery', 'Immune system', 'In Vitro', 'Informatics', 'Institutes', 'Institution', 'Internet', 'Java', 'Joints', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Literature', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Mammalian Cell', 'Manuals', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Metabolic', 'Metabolic Control', 'Metabolic Diseases', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Multimedia', 'Nature', 'Noise', 'Online Systems', 'Ontology', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Phosphotransferases', 'Physics', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Prokaryotic Cells', 'Property', 'Protein Analysis', 'Protein Family', 'Proteins', 'Proteome', 'Publishing', 'RNA', 'Range', 'Rate', 'Reaction', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling', 'Semantics', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Site', 'Software Engineering', 'Solutions', 'Source Code', 'Specific qualifier value', 'Specificity', 'Speed', 'Structural Protein', 'Structure', 'Structure of germinal center of lymph node', 'Students', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Universities', 'Validation', 'Virulence', 'Visual', 'Work', 'base', 'biocomputing', 'biomedical informatics', 'computer framework', 'computer studies', 'computerized tools', 'concept', 'data acquisition', 'data mining', 'data modeling', 'design', 'environmental change', 'experience', 'forging', 'hazard', 'improved', 'innovation', 'interest', 'interoperability', 'knowledge base', 'member', 'metabolomics', 'microbial', 'multidisciplinary', 'nervous system disorder', 'novel', 'pathogen', 'pathogenic bacteria', 'professor', 'programs', 'protein protein interaction', 'reconstruction', 'research study', 'response', 'simulation', 'size', 'software development', 'text searching', 'tool', 'transcription factor']",NIGMS,LOS ALAMOS NAT SECTY-LOS ALAMOS NAT LAB,R21,2007,257655,-0.017891671532664178
"Accelerating metabolic discovery using characterization data    DESCRIPTION (provided by applicant): The long term goal of this project is to develop methods that will allow researchers to gain insight into the metabolic networks of organisms for which we have little or no high-throughput data. Such metabolic networks can reveal aspects of the organism's metabolism that might make it vulnerable to new or existing therapies. A core data set using genomic and other omic data from data-rich bacteria that are related to the organisms of interest will be assembled. The statistical tools needed to integrate these data and to infer metabolic networks using these core data plus characterization (phenotypic) data will then be built. Using the statistical inference algorithms, the characterization data can be leveraged to reveal the metabolic networks of data-poor bacteria for which we have only characterization data. This approach can eliminate the need for genome sequencing, gene expression experiments and the like for thousands of Gram-negative facultative rod bacteria (GNF). There are five tasks in the project: (1) assemble the data sets from data-rich organisms that will be used to inform the inference algorithm. These data include (a) the genomic sequences and annotation information, (b) extant pathway data and (c) gene expression data. All these data contain some level of information about the connectivity within the metabolic network; (2) process the genomic data to enhance its predictive value; (3) develop a data integration algorithm; (4) investigate modeling frameworks to be used for Bayesian data fusion and network inference; (5) validate the metabolic networks. Deliverables from this project should include: (1) a set of pathway genome databases for 35 GNF, This group includes 20 strains classified as category A or B biothreat agents, (2) a core dataset that integrates all the information we have relevant to the metabolic pathways in the 35 sequenced GNF, (3) a probabilistic graphical modeling framework capable of integrating disparate types of data and inferring networks from the integrated data, (4) a method for using characterization data, along with deliverables 2 and 3, to infer metabolic networks for bacterial strains for which we have only characterization data. The ability to rapidly construct models of metabolic networks means researchers will be able to respond to emerging infectious agents or biothreats more quickly. Relevance The methods developed as part of this proposal will allow us to quickly make metabolic maps for thousands of bacteria. Such maps can guide researchers to promising new targets for therapeutic or preventative measures against pathogenic bacteria. The fight against well-known pathogens and biothreat agents, as well as against new, emerging pathogens will be greatly aided by these tools.              n/a",Accelerating metabolic discovery using characterization data,7267998,R21AI067543,"['Adopted', 'Algorithms', 'American Type Culture Collection', 'Artificial Intelligence', 'Bacteria', 'Bacteriology', 'Biochemical', 'Biochemical Pathway', 'Biological Models', 'Biology', 'Bypass', 'Categories', 'Cholera', 'Code', 'Data', 'Data Collection', 'Data Set', 'Depth', 'Disease', 'Electronics', 'Facility Construction Funding Category', 'Gammaproteobacteria', 'Gene Expression', 'Genomics', 'Goals', 'Gram&apos', 's stain', 'Infectious Agent', 'Information Networks', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Nosocomial Infections', 'Numbers', 'Nutritional', 'Organism', 'Outcome', 'Oxygen', 'Pathway interactions', 'Plague', 'Predictive Value', 'Process', 'Prophylactic treatment', 'Proteomics', 'Research Personnel', 'Salmonella typhi', 'Shapes', 'Shigella', 'Shigella Infections', 'Signal Transduction', 'Source', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Typhoid Fever', 'Variant', 'Vibrio cholerae', 'Work', 'Writing', 'Yersinia pestis', 'biothreat', 'computerized data processing', 'data integration', 'design', 'falls', 'fight against', 'genome database', 'genome sequencing', 'gram negative facultative rods', 'innovation', 'insight', 'interest', 'network models', 'novel', 'pathogen', 'pathogenic bacteria', 'programs', 'research study', 'retinal rods', 'routine Bacterial stain', 'sound', 'success', 'therapeutic target', 'tool', 'transcriptomics']",NIAID,AMERICAN TYPE CULTURE COLLECTION,R21,2007,185677,0.0007004513615397922
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7286779,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2007,3638557,0.0522048017454333
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7287978,SC1GM081068,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2007,247625,-0.018969064888799056
"Technology Development for a MolBio Knowledge-Base   DESCRIPTION (provided by applicant):     Since the introduction of the Mycin system more than 25 years ago, it has widely been hypothesized that extensive, well-represented computer knowledge-bases will facilitate a wide variety of scientific and clinical tasks. Driven by growing knowledge-management challenges arising from the proliferation of high throughput instrumentation, recently created knowledge-bases in areas related to genomics and related aspects of contemporary biology, such as the Gene Ontology, EcoCyc and PharmGKB, have begun to become integrated into the laboratory practices of a growing number of molecular biologists. However, these successful molecular biology knowledge-bases (MBKBs) have two drawbacks which impede their more general application: each has been narrowed to a particular special purpose, either in its domain of applicability or in the scope of knowledge represented, and each of these knowledge-bases was constructed largely on the basis of enormous human effort. Given the current state of molecular biology data and recent advances in database integration and information extraction technology, we proposed to test the following hypothesis: Current computational technology and existing human-curated knowledge resources are sufficient to build an extensive, high-quality computational knowledge-base of molecular biology. To test this hypothesis we propose to first create tools which can (a) automatically link incommensurate knowledge sources using semantic linking, and (b) use natural language processing techniques to extract new information from NCBrs GeneRIFs and from the GO definitions fields; and second, to evaluate the results of these methods by carefully quantifying the degree to which the induced linkages and extracted assertions are complete, consistent and correct. Although we propose to construct a broad and rich knowledge-base in order to develop and test the adequacy of largely automated methods to leverage existing human-curated collections, we do not propose to build a comprehensive MBKB.            n/a",Technology Development for a MolBio Knowledge-Base,7123058,R01LM008111,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computational biology', 'computer program /software', 'functional /structural genomics', 'information retrieval', 'molecular biology information system', 'technology /technique development']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2006,611872,0.02644708784061086
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,7107923,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2006,509027,0.004630770001986634
"Computer System for Functional Analysis of Genomic Data    DESCRIPTION (provided by applicant): In two previous stages of this project, both funded by the National Institute of General Medical Sciences and carried out successfully, we developed GeneWays, a completely automated system that efficiently distills information about molecular interactions from an astronomical number of full-text biomedical articles. The next logical stage of the project is to carry this system from the computational laboratory into a practical, useful, and even indispensable tool that researchers can use to solve complex problems currently posed in experimental medicine and biology. The central hypothesis of our work on GeneWays has been that our computational tools will generate biological predictions of a quality sufficiently high that the biomedical community will invest in serious experimental validation. Specifically, we propose the following. 1. We will improve significantly the precision and recall of the GeneWays system. 2. We will develop and implement a probabilistic belief-network formalism?a belief-graph relative of the Bayesian network formalism that allows us to place and update beliefs on both the vertices and the edges of the graph for probabilistic reasoning over the large collection of facts in the GeneWays database. We will develop and implement a coordinated collection of methods for computing and updating beliefs on individual nodes and edges of the belief graph. 3. We will develop and implement a mathematical framework for incorporating pathway information into a genetic- linkage analysis formalism in such a way that each piece of pathway knowledge includes a specified degree of confidence. 4. We will process an enormous collection of texts, such as open-access biomedical journals, PubMed abstracts, and the GeneWays corpus, and thus will build a comprehensive GeneHighWays database. We will make the GeneHighWays database easily and freely accessible to academic researchers through a web interface. We will evaluate the new version of the GeneWays system and the GeneHighWays database for the quality of data, performance of the mathematical methods, and quality of the interface.           n/a",Computer System for Functional Analysis of Genomic Data,7148274,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,303688,0.016078925716795398
"Machine vision analysis of C.elegans phenotypic patterns    DESCRIPTION (provided by applicant): The nematode C. elegans has powerful genetics, a well-described nervous system, and a complete genome sequence; thus, it is well suited to analysis of behavior and development at the molecular and cellular levels. In particular, the ability to functionally map the influence of particular genes to specific behavioral consequences makes it possible to use genetic analysis to functionally dissect the molecular mechanisms underlying poorly understood aspects of nervous system function. However, many genes with critical roles in neuronal function have effects on behavior that to a casual observer appear very subtle or difficult to describe precisely. Therefore, to fully realize the potential of C. elegans for the genetic analysis of nervous system function, it is necessary to develop sophisticated methods for the rapid and consistent quantitation of mutant phenotypes, especially those related to behavior.       The goal of this proposed work is to develop computer vision tools for quantitatively characterizing the phenotypic patterns caused by mutations or pharmacological treatments in C. elegans. By making it possible to precisely characterize the behavioral phenotypes of mutants with abnormal locomotion or egglaying, these tools will be particularly useful for correlating specific neurotransmission defects with characteristic behavioral patterns. These analytical tools will also be used to generate a comprehensive database containing complex behavioral data on a large set of mutant strains. This database will make it possible to identify groups of mutants and pharmacological treatments that have similar effects on behavior or development. With the accumulation of increasing phenotypic data on known mutants, it should ultimately be possible to record from unknown mutant or drug-treated animals and make informed initial hypotheses about the functions of uncharacterized genes and the targets of uncharacterized drugs.         n/a",Machine vision analysis of C.elegans phenotypic patterns,7095200,R01DA018341,"['Caenorhabditis elegans', 'behavior', 'bioinformatics', 'computer program /software', 'computer system design /evaluation', 'ethology', 'molecular biology information system', 'neurogenetics', 'phenotype']",NIDA,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2006,293309,0.0014338993544340808
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7126050,U54CA121852,"['NIH Roadmap Initiative tag', 'bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2006,3747227,0.05239026176522257
"Technology Development for a MolBio Knowledge-Base   DESCRIPTION (provided by applicant):     Since the introduction of the Mycin system more than 25 years ago, it has widely been hypothesized that extensive, well-represented computer knowledge-bases will facilitate a wide variety of scientific and clinical tasks. Driven by growing knowledge-management challenges arising from the proliferation of high throughput instrumentation, recently created knowledge-bases in areas related to genomics and related aspects of contemporary biology, such as the Gene Ontology, EcoCyc and PharmGKB, have begun to become integrated into the laboratory practices of a growing number of molecular biologists. However, these successful molecular biology knowledge-bases (MBKBs) have two drawbacks which impede their more general application: each has been narrowed to a particular special purpose, either in its domain of applicability or in the scope of knowledge represented, and each of these knowledge-bases was constructed largely on the basis of enormous human effort. Given the current state of molecular biology data and recent advances in database integration and information extraction technology, we proposed to test the following hypothesis: Current computational technology and existing human-curated knowledge resources are sufficient to build an extensive, high-quality computational knowledge-base of molecular biology. To test this hypothesis we propose to first create tools which can (a) automatically link incommensurate knowledge sources using semantic linking, and (b) use natural language processing techniques to extract new information from NCBrs GeneRIFs and from the GO definitions fields; and second, to evaluate the results of these methods by carefully quantifying the degree to which the induced linkages and extracted assertions are complete, consistent and correct. Although we propose to construct a broad and rich knowledge-base in order to develop and test the adequacy of largely automated methods to leverage existing human-curated collections, we do not propose to build a comprehensive MBKB.            n/a",Technology Development for a MolBio Knowledge-Base,6953701,R01LM008111,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computational biology', 'computer program /software', 'functional /structural genomics', 'information retrieval', 'molecular biology information system', 'technology /technique development']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2005,613495,0.02644708784061086
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6946761,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2005,100000,0.027223302190887918
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6923756,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,395905,0.03772750817709746
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6944266,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2005,523667,0.004630770001986634
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6908174,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2005,375000,-0.0021489495417824156
"Computer cluster for computational biology DESCRIPTION (provided by applicant):    The present application aims to establish a computer Cluster for Computational Biology and Bioinformatic (CCBB). The cluster will consists of 256 dual nodes connected with Giganet switches to enable rapid communication between the processors. The cluster will enable the integration of the two approaches and make it possible to effectively address the highly demanding computational tasks of the field. It will serve a small group of investigators, supported by the NIH, and their close collaborators. The hardware needs of computational biology and bioinformatic applications, and of the team of investigators listed in this application can be summarized as follows:   1. Significant computer power for complex and expensive simulations.   2. Large storage capacity for the whole cluster (shared) and (separately) for the individual nodes.   3. Large and rapidly accessible memory for effective statistical analysis, application of machine learning techniques, and biological discovery.   4. Fast network for information updates across the network.   In addition CCBB will have high level of databases and software integration including   1. Updates of important ""mirrors"" of shared databases (such as NR, swissprot, human EST, human genome, protein databank, etc.)   2. Local installation and frequent upgrade of widely used software packages (e.g. BLAST, Pfam, CHARMm etc.)   3. Help in porting novel software for optimal use on the CCBB hardware platform.   The combined unification of optimal hardware and software for computational biology and bioinformatic will make the new cluster; an outstanding resource for NIH related research n/a",Computer cluster for computational biology,6877645,S10RR020889,"['bioinformatics', 'biomedical equipment purchase', 'computational biology', 'computer network', 'computer program /software', 'computer system hardware', 'computers']",NCRR,CORNELL UNIVERSITY ITHACA,S10,2005,500000,0.00734737854629209
"Machine vision analysis of C.elegans phenotypic patterns    DESCRIPTION (provided by applicant): The nematode C. elegans has powerful genetics, a well-described nervous system, and a complete genome sequence; thus, it is well suited to analysis of behavior and development at the molecular and cellular levels. In particular, the ability to functionally map the influence of particular genes to specific behavioral consequences makes it possible to use genetic analysis to functionally dissect the molecular mechanisms underlying poorly understood aspects of nervous system function. However, many genes with critical roles in neuronal function have effects on behavior that to a casual observer appear very subtle or difficult to describe precisely. Therefore, to fully realize the potential of C. elegans for the genetic analysis of nervous system function, it is necessary to develop sophisticated methods for the rapid and consistent quantitation of mutant phenotypes, especially those related to behavior.       The goal of this proposed work is to develop computer vision tools for quantitatively characterizing the phenotypic patterns caused by mutations or pharmacological treatments in C. elegans. By making it possible to precisely characterize the behavioral phenotypes of mutants with abnormal locomotion or egglaying, these tools will be particularly useful for correlating specific neurotransmission defects with characteristic behavioral patterns. These analytical tools will also be used to generate a comprehensive database containing complex behavioral data on a large set of mutant strains. This database will make it possible to identify groups of mutants and pharmacological treatments that have similar effects on behavior or development. With the accumulation of increasing phenotypic data on known mutants, it should ultimately be possible to record from unknown mutant or drug-treated animals and make informed initial hypotheses about the functions of uncharacterized genes and the targets of uncharacterized drugs.         n/a",Machine vision analysis of C.elegans phenotypic patterns,6921010,R01DA018341,"['Caenorhabditis elegans', 'behavior', 'bioinformatics', 'computer program /software', 'computer system design /evaluation', 'ethology', 'molecular biology information system', 'neurogenetics', 'phenotype']",NIDA,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,2005,304783,0.0014338993544340808
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7012104,U54CA121852,"['bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2005,3758967,0.05239026176522257
"Technology Development for a MolBio Knowledge-Base   DESCRIPTION (provided by applicant):     Since the introduction of the Mycin system more than 25 years ago, it has widely been hypothesized that extensive, well-represented computer knowledge-bases will facilitate a wide variety of scientific and clinical tasks. Driven by growing knowledge-management challenges arising from the proliferation of high throughput instrumentation, recently created knowledge-bases in areas related to genomics and related aspects of contemporary biology, such as the Gene Ontology, EcoCyc and PharmGKB, have begun to become integrated into the laboratory practices of a growing number of molecular biologists. However, these successful molecular biology knowledge-bases (MBKBs) have two drawbacks which impede their more general application: each has been narrowed to a particular special purpose, either in its domain of applicability or in the scope of knowledge represented, and each of these knowledge-bases was constructed largely on the basis of enormous human effort. Given the current state of molecular biology data and recent advances in database integration and information extraction technology, we proposed to test the following hypothesis: Current computational technology and existing human-curated knowledge resources are sufficient to build an extensive, high-quality computational knowledge-base of molecular biology. To test this hypothesis we propose to first create tools which can (a) automatically link incommensurate knowledge sources using semantic linking, and (b) use natural language processing techniques to extract new information from NCBrs GeneRIFs and from the GO definitions fields; and second, to evaluate the results of these methods by carefully quantifying the degree to which the induced linkages and extracted assertions are complete, consistent and correct. Although we propose to construct a broad and rich knowledge-base in order to develop and test the adequacy of largely automated methods to leverage existing human-curated collections, we do not propose to build a comprehensive MBKB.            n/a",Technology Development for a MolBio Knowledge-Base,6822280,R01LM008111,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computational biology', 'computer program /software', 'functional /structural genomics', 'information retrieval', 'molecular biology information system', 'technology /technique development']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2004,577307,0.02644708784061086
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6805962,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2004,100000,0.027223302190887918
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6777028,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,341671,0.03772750817709746
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6784554,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2004,522252,0.004630770001986634
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6936159,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,52940,0.03772750817709746
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6788945,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2004,375000,-0.0021489495417824156
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6736326,U01GM061374,"['artificial intelligence', 'biomedical resource', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'computer system hardware', 'cooperative study', 'drug interactions', 'drug metabolism', 'gene expression', 'genetic polymorphism', 'informatics', 'information dissemination', 'interactive multimedia', 'molecular biology information system', 'online computer', 'pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2004,337653,0.03621227967136986
"BioMediator: Biologic Data Integration & Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration & Analysis System,6681249,R01HG002288,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' information retrieval', ' molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2003,100000,0.027223302190887918
"Development of Bioinformatic Tools for Virtual Cloning    DESCRIPTION (provided by applicant): The ability to delineate (at least in theory) all the proteins encoded in the human genome and all of those encoded by the genomes of major human parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease.  However, the vast increase in biological knowledge that has resulted from the last decade of genomic DNA sequencing has led us to a a crisis in bioinformatics.  This crisis is two-fold: analysis of data and planning of experiments.  Most of the scientific resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology.  All modern experimental molecular biology (and, increasingly, structural biology) depends upon the availability of plasmid clones to address specific scientific questions.  Although software facilitating DNA manipulations exists, few programs advise users of optimal strategies and none automate the process of clone generation. Genomics initiatives identify proteins at the genome level and demand the generation of hundreds of expression clones for recombinant protein production in exogenous hosts such as E. coli.  Establishment of libraries of expression clones requires automation and optimization as well as effective means of data storage, archiving, annotation and query.  To address these needs, as well as to facilitate routine DNA manipulations in virtually any molecular biology laboratory, we propose (1) to test and build a task centered virtual cloning expert system that serves as a knowledge base for DNA manipulations, and (2) to test and build an information automaton for the construction of expression clone libraries in support of structural genomics initiatives and other high throughput experiments.         n/a",Development of Bioinformatic Tools for Virtual Cloning,6583437,R43GM067279,"['artificial intelligence', ' biomedical automation', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' expression cloning', ' gene expression', ' genetic library', ' genetic manipulation', ' informatics', ' molecular biology information system', ' transfection /expression vector']",NIGMS,"VIRMATICS, LLC",R43,2003,100000,-0.028585729803297766
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6694513,R01GM056529,"['artificial intelligence', ' biochemistry', ' computer program /software', ' computer system design /evaluation', ' dementia', ' enzyme mechanism', ' functional /structural genomics', ' information system analysis', ' mathematical model', ' molecular biology information system', ' molecular dynamics', ' physiology', ' protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2003,556670,0.004630770001986634
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6685421,R01GM061372,"['Internet', ' artificial intelligence', ' automated data processing', ' biological signal transduction', ' biomedical automation', ' computer system design /evaluation', ' functional /structural genomics', ' high throughput technology', ' intermolecular interaction', ' method development', ' molecular biology information system', ' statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,323936,0.03772750817709746
"AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE It is becoming increasingly difficult for biologists to keep pace with           information being published within their own fields, let alone biology           as a whole. The ability to rapidly access specific and current                   biomedical information as well as to quickly gain an overview of current         knowledge in a given field is becoming more difficult while at the same          time more important. Traditional methods of keeping up with advances are         therefore becoming inadequate.                                                                                                                                    This project will involve a unique collaboration between a computational         linguist at Brandeis University and two biologists at Tufts University           School of Medicine. We propose to make use of recent advances in the             computational analysis of text to organize and summarize the biological          literature. Building on our previous language technology research at             Brandeis, we propose to integrate the domain knowledge of the National           Library of Medicine's Unified Medical Language System (UMLS) with                Brandeis' semantic lexicon, CoreLex, toward the development of                   normalized structured representations of the semantic content of                 abstracts in the Medline database. These data structures, called lexical         webs, accelerate the availability of information in a richly hyperlinked         index that facilitates rapid navigation and information access.                  Automated analysis of biological abstracts will be combined with                 information derived from sequence databases to provide an up-to-date and         comprehensive database of information regarding known genes and                  proteins. The results of this analysis will be used to construct a web           accessible database organized on a gene-by-gene basis.                                                                                                            Other unique aspects of this database will be the visualization of               motifs and features extracted from Medline abstracts through the                 generation of annotated structure-function maps of proteins and genes,           and the construction of gene-specific semantic indexes to the relevant           biological literature. This system, called MedStract, will reduce the            time required for biomedical researchers to find information of interest         and should facilitate the development of new research insights.                   n/a",AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE,6744998,R01LM006649,"['Internet', ' abstracting', ' artificial intelligence', ' computer assisted sequence analysis', ' computer system design /evaluation', ' informatics', ' information retrieval', ' information system analysis', ' molecular biology information system', ' nucleic acid sequence', ' protein sequence', ' semantics', ' syntax', ' vocabulary development for information system']",NLM,BRANDEIS UNIVERSITY,R01,2003,191306,0.02142474337805046
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6636465,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2003,327818,0.03621227967136986
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6738628,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2003,159000,0.03621227967136986
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6646557,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2003,237000,-0.014043820469175693
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,0.019090406313582556
"GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES The broad long-term objectives of this proposal are to create and evaluate an infrastructure (GeneSeek) to permit searching across heterogeneous source databases (genomic and citation databases) for relevant information needed for curation of an existing database of clinical knowledge (GeneClinics).  The Specific Aims are: 1) to use a novel, general purpose knowledge representation language to capture the schema of an existing database of clinical knowledge (GeneClinics genetic testing database), 2) to build a shared schema for mediating cross database queries, by extending the schema of GeneClinics and incorporating pertinent schema elements from other structured and semi-structured information sources, 3) to create and test interfaces to the targeted genetic information sources (databases and other structured information) from the shared query mediation schema, 4) to adapt the existing Tukwila data integration system to implement cross database query planning, query execution, and query result aggregation in the context of our shared query mediation schema and the multiple structured (genetic) information sources to create the GeneSeek data integration system, 5) to evaluate the performance of the Tukwila based GeneSeek data integration system and the shared data schema for precision and recall in finding relevant information for curation of a clinical database (GeneClinics genetic testing database). The broad health relatedness of the project is that data integration tools are needed to help clinicians apply the ever- growing body of medical information to patient care.  The tools are needed by curators of databases of medical knowledge as well as by the care providers themselves.  Nowhere is the growth in information more apparent than in the Human Genome project thus the choice of genetics as a domain to test this data integration system.  The specific genetics database whose curation the GeneSeek system will be evaluated against the GeneClinics database.  If successful these data integration systems could be more broadly applied to other domains in biomedicine.  The research design is to apply recent developments in data integration from the artificial intelligence and database areas of computer science to a real world clinical genetics data integration problem to evaluate the applicability of this system to biomedical information retrieval tasks.  The methods are to expand an existing collaboration between the current GeneClinics content and informatics teams and investigators in the Department of Computer science to: 1) enhance the Tukwila data integration architecture and its related CARIN knowledge representation language, and 2) to use these tools and the existing GeneClinics data model to implement and evaluate this data integration system in the specific domain of medical genetics.  n/a",GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES,6526728,R01HG002288,"['artificial intelligence', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' experimental designs', ' information retrieval', ' molecular biology information system', ' vocabulary development for information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2002,372289,0.01714310578411132
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6520265,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2002,318270,0.03621227967136986
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6649647,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2002,232118,0.03621227967136986
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6526274,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2002,237000,-0.014043820469175693
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,0.019090406313582556
"GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES The broad long-term objectives of this proposal are to create and evaluate an infrastructure (GeneSeek) to permit searching across heterogeneous source databases (genomic and citation databases) for relevant information needed for curation of an existing database of clinical knowledge (GeneClinics).  The Specific Aims are: 1) to use a novel, general purpose knowledge representation language to capture the schema of an existing database of clinical knowledge (GeneClinics genetic testing database), 2) to build a shared schema for mediating cross database queries, by extending the schema of GeneClinics and incorporating pertinent schema elements from other structured and semi-structured information sources, 3) to create and test interfaces to the targeted genetic information sources (databases and other structured information) from the shared query mediation schema, 4) to adapt the existing Tukwila data integration system to implement cross database query planning, query execution, and query result aggregation in the context of our shared query mediation schema and the multiple structured (genetic) information sources to create the GeneSeek data integration system, 5) to evaluate the performance of the Tukwila based GeneSeek data integration system and the shared data schema for precision and recall in finding relevant information for curation of a clinical database (GeneClinics genetic testing database). The broad health relatedness of the project is that data integration tools are needed to help clinicians apply the ever- growing body of medical information to patient care.  The tools are needed by curators of databases of medical knowledge as well as by the care providers themselves.  Nowhere is the growth in information more apparent than in the Human Genome project thus the choice of genetics as a domain to test this data integration system.  The specific genetics database whose curation the GeneSeek system will be evaluated against the GeneClinics database.  If successful these data integration systems could be more broadly applied to other domains in biomedicine.  The research design is to apply recent developments in data integration from the artificial intelligence and database areas of computer science to a real world clinical genetics data integration problem to evaluate the applicability of this system to biomedical information retrieval tasks.  The methods are to expand an existing collaboration between the current GeneClinics content and informatics teams and investigators in the Department of Computer science to: 1) enhance the Tukwila data integration architecture and its related CARIN knowledge representation language, and 2) to use these tools and the existing GeneClinics data model to implement and evaluate this data integration system in the specific domain of medical genetics.  n/a",GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES,6388359,R01HG002288,"['artificial intelligence', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' experimental designs', ' information retrieval', ' molecular biology information system', ' vocabulary development for information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2001,362594,0.01714310578411132
"Functional Genomics Software   DESCRIPTION (Applicant's abstract): A substantial commercial potential exists        for software tools that allow a biomedical research scientist to use genomic         data to form experimentally testable hypotheses. These will be used to exploit       genomic sequence data to understand the aetiology of disease, to improve             diagnostic tools, and to develop more effective therapies. The Master Catalog,       a commercial product developed jointly by EraGen Biosciences and the Benner          laboratory at the University of Florida, provides a convenient framework for         implementing heuristics that do this. The Master Catalog is a naturally              organized database that contains evolutionary trees, multiple sequence               alignments, and reconstructed evolutionary intermediates for all of the              proteins in the GenBank database. The Benner laboratory has developed and            anecdotally tested heuristics that date events in the molecular history,             provide evidence for and against functional recruitment within a protein             family, detect distant homologs, associate individual residues important for         functional changes with a crystal structure, find metabolic and regulatory           pathways, and correlate events in the molecular record with the history of life      on Earth. This Phase I proposal seeks to validate a set of these heuristics          more broadly to determine their suitability for database-wide application. In        Phase II, we will implement these within the Master Catalog, and launch a            commercial bioinformatics product to support functional analysis of genomic          databases.                                                                           PROPOSED COMMERCIAL APPLICATION:  In its present version, the Master Catalog is a successful commercial product within a  niche: ""best in class"" of bioinformatics databases.  Adding a validated set of heuristics  for extracting functional information from genome databases will make it the software  of choice for most functional genomics work, and be a central tool in the pharmaceutical/  biotechnology industries.  Academic versions and student versions will find markets in most  universities.                                                                                      n/a",Functional Genomics Software,6337786,R41HG002331,"['artificial intelligence', ' biochemical evolution', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' functional /structural genomics', ' informatics', ' molecular biology information system', ' nucleic acid sequence']",NHGRI,"ERAGEN BIOSCIENCES, INC.",R41,2001,96855,-0.006597937868602441
"AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE It is becoming increasingly difficult for biologists to keep pace with           information being published within their own fields, let alone biology           as a whole. The ability to rapidly access specific and current                   biomedical information as well as to quickly gain an overview of current         knowledge in a given field is becoming more difficult while at the same          time more important. Traditional methods of keeping up with advances are         therefore becoming inadequate.                                                                                                                                    This project will involve a unique collaboration between a computational         linguist at Brandeis University and two biologists at Tufts University           School of Medicine. We propose to make use of recent advances in the             computational analysis of text to organize and summarize the biological          literature. Building on our previous language technology research at             Brandeis, we propose to integrate the domain knowledge of the National           Library of Medicine's Unified Medical Language System (UMLS) with                Brandeis' semantic lexicon, CoreLex, toward the development of                   normalized structured representations of the semantic content of                 abstracts in the Medline database. These data structures, called lexical         webs, accelerate the availability of information in a richly hyperlinked         index that facilitates rapid navigation and information access.                  Automated analysis of biological abstracts will be combined with                 information derived from sequence databases to provide an up-to-date and         comprehensive database of information regarding known genes and                  proteins. The results of this analysis will be used to construct a web           accessible database organized on a gene-by-gene basis.                                                                                                            Other unique aspects of this database will be the visualization of               motifs and features extracted from Medline abstracts through the                 generation of annotated structure-function maps of proteins and genes,           and the construction of gene-specific semantic indexes to the relevant           biological literature. This system, called MedStract, will reduce the            time required for biomedical researchers to find information of interest         and should facilitate the development of new research insights.                   n/a",AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE,6363593,R01LM006649,"['Internet', ' abstracting', ' artificial intelligence', ' computer assisted sequence analysis', ' computer system design /evaluation', ' informatics', ' information retrieval', ' information system analysis', ' molecular biology information system', ' nucleic acid sequence', ' protein sequence', ' semantics', ' syntax', ' vocabulary development for information system']",NLM,BRANDEIS UNIVERSITY,R01,2001,306158,0.02142474337805046
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6495900,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2001,35096,0.03621227967136986
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6387173,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2001,309000,0.03621227967136986
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6401728,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2001,237000,-0.014043820469175693
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,0.019090406313582556
"GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES The broad long-term objectives of this proposal are to create and evaluate an infrastructure (GeneSeek) to permit searching across heterogeneous source databases (genomic and citation databases) for relevant information needed for curation of an existing database of clinical knowledge (GeneClinics).  The Specific Aims are: 1) to use a novel, general purpose knowledge representation language to capture the schema of an existing database of clinical knowledge (GeneClinics genetic testing database), 2) to build a shared schema for mediating cross database queries, by extending the schema of GeneClinics and incorporating pertinent schema elements from other structured and semi-structured information sources, 3) to create and test interfaces to the targeted genetic information sources (databases and other structured information) from the shared query mediation schema, 4) to adapt the existing Tukwila data integration system to implement cross database query planning, query execution, and query result aggregation in the context of our shared query mediation schema and the multiple structured (genetic) information sources to create the GeneSeek data integration system, 5) to evaluate the performance of the Tukwila based GeneSeek data integration system and the shared data schema for precision and recall in finding relevant information for curation of a clinical database (GeneClinics genetic testing database). The broad health relatedness of the project is that data integration tools are needed to help clinicians apply the ever- growing body of medical information to patient care.  The tools are needed by curators of databases of medical knowledge as well as by the care providers themselves.  Nowhere is the growth in information more apparent than in the Human Genome project thus the choice of genetics as a domain to test this data integration system.  The specific genetics database whose curation the GeneSeek system will be evaluated against the GeneClinics database.  If successful these data integration systems could be more broadly applied to other domains in biomedicine.  The research design is to apply recent developments in data integration from the artificial intelligence and database areas of computer science to a real world clinical genetics data integration problem to evaluate the applicability of this system to biomedical information retrieval tasks.  The methods are to expand an existing collaboration between the current GeneClinics content and informatics teams and investigators in the Department of Computer science to: 1) enhance the Tukwila data integration architecture and its related CARIN knowledge representation language, and 2) to use these tools and the existing GeneClinics data model to implement and evaluate this data integration system in the specific domain of medical genetics.  n/a",GENESEEK: DATA INTEGRATION SYSTEM FOR GENETIC DATABASES,6031661,R01HG002288,"['artificial intelligence', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' experimental designs', ' information retrieval', ' molecular biology information system', ' vocabulary development for information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2000,354198,0.01714310578411132
"AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE It is becoming increasingly difficult for biologists to keep pace with           information being published within their own fields, let alone biology           as a whole. The ability to rapidly access specific and current                   biomedical information as well as to quickly gain an overview of current         knowledge in a given field is becoming more difficult while at the same          time more important. Traditional methods of keeping up with advances are         therefore becoming inadequate.                                                                                                                                    This project will involve a unique collaboration between a computational         linguist at Brandeis University and two biologists at Tufts University           School of Medicine. We propose to make use of recent advances in the             computational analysis of text to organize and summarize the biological          literature. Building on our previous language technology research at             Brandeis, we propose to integrate the domain knowledge of the National           Library of Medicine's Unified Medical Language System (UMLS) with                Brandeis' semantic lexicon, CoreLex, toward the development of                   normalized structured representations of the semantic content of                 abstracts in the Medline database. These data structures, called lexical         webs, accelerate the availability of information in a richly hyperlinked         index that facilitates rapid navigation and information access.                  Automated analysis of biological abstracts will be combined with                 information derived from sequence databases to provide an up-to-date and         comprehensive database of information regarding known genes and                  proteins. The results of this analysis will be used to construct a web           accessible database organized on a gene-by-gene basis.                                                                                                            Other unique aspects of this database will be the visualization of               motifs and features extracted from Medline abstracts through the                 generation of annotated structure-function maps of proteins and genes,           and the construction of gene-specific semantic indexes to the relevant           biological literature. This system, called MedStract, will reduce the            time required for biomedical researchers to find information of interest         and should facilitate the development of new research insights.                   n/a",AUTOMATED KNOWLEDGE EXTRACTION FOR BIOMEDICAL LITERATURE,6165092,R01LM006649,"['Internet', ' abstracting', ' artificial intelligence', ' computer assisted sequence analysis', ' computer system design /evaluation', ' informatics', ' information retrieval', ' information system analysis', ' molecular biology information system', ' nucleic acid sequence', ' protein sequence', ' semantics', ' syntax', ' vocabulary development for information system']",NLM,BRANDEIS UNIVERSITY,R01,2000,297119,0.02142474337805046
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6132622,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,300000,0.03621227967136986
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6323962,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,186611,0.03621227967136986
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6344145,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,141192,0.03621227967136986
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,0.019090406313582556
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,0.02114427832371207
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,0.02114427832371207
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10020414,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2020,388750,0.013767492593632474
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,10022122,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'interest', 'machine learning method', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'statistical and machine learning', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2020,67446,0.0013952612322983174
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.020416337361181876
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),9937486,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Catalogs', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2020,1995376,0.03351630543080792
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9983144,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Information Retrieval', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'machine learning method', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'structured data', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,264232,0.02283770411693198
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,0.006937790720457774
"Learning Dynamics of Biological Processes from Time Course Omics Datasets Complex biological processes, including organ development, immune response and disease progression, are inherently dynamic. Learning their regulatory architecture requires understanding how components of a large system dynamically interact with each other and give rise to emergent behavior. Recent experimental advances have made ii possible to investigate these biological systems in a data-driven fashion al high temporal resolution, allowing identification of new genes and their regulatory interactions. Longitudinal omics data sets are becoming increasingly common in clinical practice as well. Information on these collections of interacting genes can be integrated to gain systems-level insights into the roles of biological pathways and processes, including progression of diseases. Consequently, developing interpretable methods for learning functional relationships among genes, proteins or metabolites from high-dimensional time series data has become a timely research problem. The nature of these time-course data sets presents exciting opportunities and interesting challenges from a statistical perspective. Typical time-course omics data sets are challenging because of their high-dimensionality and non-linear relationships among system components. To tackle these challenges, one needs sophisticated dimension-reduction techniques that are biologically meaningful, computationally efficient and allow uncertainty quantification. Methods that incorporate prior biological information (e.g., pathway membership, protein-protein interactions) into the data analysis are good candidates for analyzing such high-dimensional systems using small samples. Here, we will develop three core methods to address the above challenges - (Aim 1): an empirical Bayes framework for clustering high-dimensional omics time-course data using prior biological knowledge; (Aim 2): a quantile-based Granger causality framework for learning interactions among genes or metabolites from their lead-lag relationships; and (Aim 3): a decision tree ensemble framework for searching cascades of interactions among genes from their temporal expression profiles. Our interdisciplinary team of statisticians and scientists will analyze time-course omics data from three research projects: (i) innate immune response systems in Drosophila, (ii) developmental process in mouse models, and (ii) longitudinal metabolite profiling of TB patients. These insights will be used to build and validate our methodology, which will be implemented in a publicly available software. This proposal is innovative in its incorporation of prior biological knowledge in the framework of novel dimension reduction techniques for interrogating high-dimensional time-course omics data. This research is significant in that it will impact basic sciences by elucidating data-driven, testable hypotheses on the regulatory architecture of biological processes, and clinical practice by monitoring disease progression and prognosis. n/a",Learning Dynamics of Biological Processes from Time Course Omics Datasets,10021429,R01GM135926,"['Address', 'Algorithms', 'Architecture', 'Basic Science', 'Behavior', 'Biological', 'Biological Process', 'Clinical', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Development', 'Developmental Process', 'Dimensions', 'Disease Progression', 'Drosophila genus', 'Etiology', 'Expression Profiling', 'Gene Proteins', 'Genes', 'Grouping', 'Immune System Diseases', 'Immune response', 'Innate Immune Response', 'Knowledge', 'Lead', 'Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Process', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Scientist', 'Series', 'Silicon Dioxide', 'Structure', 'System', 'Techniques', 'Time', 'Uncertainty', 'Validation', 'Variant', 'base', 'biological systems', 'clinical practice', 'dynamic system', 'experimental study', 'high dimensionality', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'mouse model', 'novel', 'open source', 'organ growth', 'outcome forecast', 'protein protein interaction', 'random forest', 'temporal measurement']",NIGMS,CORNELL UNIVERSITY,R01,2020,344345,0.012049302550707786
"S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450 This application is requesting funds to purchase the Aperio™ GT-450 digital pathology slide scanner from Leica Biosystems. The requested instrumentation will be located in the Pathology and Biobanking Core of the Lester and Sue Smith Breast Center at Baylor College of Medicine (BCM). The predominant use of the Aperio scanner will be research-based whole slide imaging (WSI) and analysis of patient specimens, patient-derived xenograft (PDX) cancer models, and pre-clinical investigations on various animal- and cell-line model systems. All user projects have large sample cohorts that require high throughput, high-resolution scanning and image analysis. High capacity and improved scanning with dynamic focusing makes the GT-450 microscope scanner well-suited and the most cost-effective for use in the proposed projects. An underlying theme in the studies selected for Aperio scanner-supported services integrates novel biomarker and molecular pathway discovery with spatial morphological characterization, a necessary process to investigate heterogeneity in disease states. This instrument leverages high-throughput scanning capability with open-source, fully customizable machine-learning analytics to meet the evolving needs of investigators at Baylor College of Medicine, in particular faculty groups studying mechanisms of cancer cell dynamics and the development of new therapeutic targets. Expansion of systems biology and precision medicine research is an essential component of the college’s strategic roadmap. The Aperio GT-450 is critically needed as we modernize our laboratory offerings and capabilities; the acquisition of this digital scanner will strengthen existing research programs underway and establish new, collaborative research opportunities and directions within Baylor College of Medicine and surrounding institutions. To address the growing demand for integrating quantitative spatial assessment of biomarkers with molecular pathway discovery, we request funding for the Leica Aperio GT-450 digital microscope scanner. This instrument will facilitate research that seeks to better understand molecular mechanisms of tumorigenesis in the context of its spatial environment and will be critical for the development of clinically correlative biomarkers for next generation precision medicine research initiatives at Baylor College of Medicine.",S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450,9940426,S10OD028671,"['Animals', 'Biological Models', 'Breast', 'Cancer Model', 'Cell Line', 'Development', 'Disease', 'Faculty', 'Funding', 'Grant', 'Heterogeneity', 'Image Analysis', 'Institution', 'Laboratories', 'Machine Learning', 'Medicine', 'Microscope', 'Modernization', 'Molecular', 'Morphology', 'Pathology', 'Pathway interactions', 'Patients', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Slide', 'Specimen', 'Systems Biology', 'Xenograft procedure', 'base', 'biobank', 'cancer cell', 'clinical investigation', 'cohort', 'college', 'cost effective', 'digital', 'digital pathology', 'improved', 'instrument', 'instrumentation', 'new therapeutic target', 'novel marker', 'open source', 'pre-clinical', 'precision medicine', 'programs', 'whole slide imaging']",OD,BAYLOR COLLEGE OF MEDICINE,S10,2020,477043,-0.005271539739496863
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9888390,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2020,1932440,0.05162380155511625
"Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy In this proposed project, we plan to fill the knowledge gap of the relationships between microscopic self-assembled structures, collagen-molecule interactions and macroscopic fiber morphologies of type-I collagen, the primary component of most human tissues and a commonly used biomaterial for tissue engineering. By investigating collagen-water and collagen-protein interactions in in vitro systems that mimic basic aspects of physiologically relevant three- dimensional fibrillar tissue architectures, we aim to fill knowledge gaps in fundamental collagen research. We will achieve this goal by developing a hyperspectral imaging technique – vibrational sum frequency generation (VSFG) microscopy – at high repetition rates (400 kHz) and apply it to collagen. The long-term vision is to develop new biophysics methods to reveal molecular-level structures and interactions for pericellular space research and other complex biological environments, and eventually applying it to study various pericellular environment related diseases. In order to correlate spectral features to microscopic and macroscopic structures of type I collagen, we plan to apply machine-learning techniques to analyze our data and extract spectral signatures of collagen’s micro/macrostructures. We will two major scientific focuses: (A) understanding molecular signatures of microscopic self-assembly fibrils structures and its relationship to the macroscopic morphology (plan 1 and 2); and (B) investigating molecular level collagen-molecule interactions (plan 3 and 4). Specific plans include:  1. Obtaining hyperspectral VSFG images of collagen tissues to study their morphology in a  label free and non-invasive manner  2. Establishing molecular spectral signatures of self-assembled collagen fibril structures  3. Understanding collagen-water interaction in first solvation layer of collagen fibers.  4. Imaging spatial locations of chemicals and peptides that interact with collagens. If successful, the significance is that a label free, vibrational mode specific imaging technique specific for pericellular space will be available, which can reveal molecular level insights of collagen structures and its interactions with surrounding molecules, pertinent to fibrosis and cell— pericellular space interaction related diseases. This proposed project contributes to the scope of NIGMS by developing new technology to reveal fundamental molecular-level principle, mechanism and signatures related to morphology of collagen I at both micro- and macroscopic scales, and collagen-molecule interactions, laying foundations for biophysical/biochemical principles for future biomedical applications related to collagens. This proposed development of vibrational sum frequency generation microscopy, in the short term, will spatially resolve collagen tissues with chemical structure and molecular interaction information in a complicated environment. Machine learning and simulation approaches will be employed to build a data base to convert hyperspectral images of collagen into a spatial map with microscopic structures and molecular interaction information. In the long term, the fundamental biochemical knowledge learned from this development will lay foundations for rationally design biomedical approaches to monitor and control pericellular spaces and its interaction with cells, and further advance treatment to diseases related to it.",Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy,10028946,R35GM138092,"['3-Dimensional', 'Architecture', 'Binding', 'Biochemical', 'Biocompatible Materials', 'Biological', 'Biophysics', 'Cells', 'Chemical Structure', 'Chemicals', 'Collagen', 'Collagen Fiber', 'Collagen Fibril', 'Collagen Type I', 'Complex', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Fiber', 'Fibrosis', 'Foundations', 'Frequencies', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'In Vitro', 'Knowledge', 'Label', 'Location', 'Machine Learning', 'Maps', 'Microscopic', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Monitor', 'Morphology', 'National Institute of General Medical Sciences', 'Peptides', 'Physiological', 'Proteins', 'Research', 'Structure', 'Sum', 'System', 'Techniques', 'Tissue Engineering', 'Tissues', 'Vision', 'Water', 'biophysical techniques', 'design', 'human tissue', 'image reconstruction', 'insight', 'molecular imaging', 'new technology', 'self assembly', 'simulation', 'vibration']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R35,2020,393958,-0.012388719249212359
"Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design PROJECT SUMMARY/ABSTRACT Molecular simulation is a powerful tool to predict the properties of biomolecules, interpret biophysical experiments, and design small molecules or biomolecules with therapeutic utility. However, a number of obstacles have impeded the development of quantitative, cloud-scale research workﬂows involving biomolecular simulation. Two main ob- stacles are the insufﬁcient accuracy of current atomistic models for biomolecules and small molecule therapeutics and the lack of interoperability in simulation toolchains used in both academic and industrial biomolecular research. Our original R01, “Open Data-driven Infrastructure for Building Biomolecular Force Fields for Predictive Bio- physics and Drug Design,” seeks to solve the ﬁrst problem. It helps fund our effort, the Open Force Field Initiative (https://openforceﬁeld.org) to develop open, extensible, and shared software and data infrastructure, implementing statistically robust methods of parameterizing force ﬁelds and choosing new force ﬁelds in a statistically sound manner. This work is designed to create not just a new generation of force ﬁelds, but an open technology to continue advancing force ﬁeld science. However, even with improved molecular models, putting together complete workﬂows of biomolecular simulations involves interfacing substantial numbers of different tools. However the majority of the existing molecular simulation workﬂows are mutually incompatible, with differing representations of the molecular models. The Open Force Field Initiative effort already includes the development of molecular data structures that we can ex- port into existing molecular simulation tools. We propose to extend the existing scope of our R01 to create an extensible common molecular simulation representation and translators to and from this representation. Such a set of tools will immediately make it signiﬁcantly easier to combine the disparate workﬂows developed for different sets of molecular simulation tools. Researchers will be able to set up and build the biophysical simulations using their usual tools, but run and analyze them with currently incompatible tools, enabling better matching of computational resources and methods to problems. It will help avoid trapping in a single software framework, and enable combinations of functionalities previously impossible without substantial developer time and effort. We will (Aim 1) work with partners to generalize our modular, extensible object model for representing parameterized biomolecular systems in a manner that accommodates the force ﬁeld terms currently supported by most popular biomolecular simulation packages. We will engineer it to be extensible to advanced interaction forms, such as polarizability and other multibody terms, and machine learning models for intermolecular forces. We will (Aim 2): enable easy conversion between components of molecular simulation workﬂows by allowing other molecular simulation packages to easily store their representations in this data model, developing converters that can import/export this object model to multiple popular ﬁle formats, focusing initially on OpenMM, AMBER, CHARMM, and GROMACS. We will demonstrate the utility of this interface in cloud-ready workﬂows. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This supplement will make it much easier for molecular simulation workﬂows to interoperate with each other in large-scale workﬂows.",Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design,10166314,R01GM132386,"['Affinity', 'Binding', 'Biophysics', 'COVID-19', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA', 'Development', 'Drug Design', 'Ecosystem', 'Engineering', 'Funding', 'Generations', 'Human', 'Individual', 'Industrialization', 'Infrastructure', 'Language', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Problem Solving', 'Property', 'Proteins', 'Pythons', 'RNA', 'Readability', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Scientist', 'Software Framework', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Work', 'Writing', 'biomaterial interface', 'computing resources', 'data infrastructure', 'data modeling', 'design', 'experimental study', 'file format', 'improved', 'interoperability', 'molecular modeling', 'open data', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'sound', 'structured data', 'tool']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,225000,-0.00016033055287818307
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,9855767,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2020,1835520,0.014330558026571185
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,9888378,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Epithelium', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2020,171720,0.007741017554063494
"Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics Abstract Support is requested for a Keystone Symposia conference entitled Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics, organized by Drs. Jose M. Lora and Timothy K. Lu. The conference will be held in Breckenridge, Colorado from March 29- April 1, 2019. Synthetic Biology tools and principles have matured tremendously over the last decade and have reached extraordinary levels of sophistication, both in eukaryotic and prokaryotic systems. Synthetic biology as a therapeutic modality is starting to enter multiple clinical studies and has the potential to have a significant impact on medicine across a wide range of diseases (e.g., metabolic, immune-mediated, cancer, and neurologic diseases). This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine. While there are conferences that capture synthetic biology in only a few talks mixed in among other various topics, there is a paucity of conferences focused on synthetic biology as drugs to treat disease. However, due to the rapid pace of fundamental scientific advances along with an expanding number of biotechnology companies and emerging clinical studies with synthetic biology at their core, this conference will be highly relevant for a wide audience of scientists both from academia and industry. In addition, other meetings in this field have a highly technology-driven focus on synthetic biology techniques with relatively little attention given to biological and medical context. Ultimately, this Keystone Symposia conference should inspire researchers from diverse backgrounds to discuss synthetic biology via many new angles. PROJECT NARRATIVE Over the past two decades, tremendous advances have been made in the use of biological parts to engineer systems that can effectively direct living cells for a vast variety of purposes (a.k.a. synthetic biology). Synthetic biology is being used to construct more effective therapies in diseases such as cancer, but there are remaining obstacles to the clinical translation of these therapies. This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine.",Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics,9913772,R13EB029305,"['Academia', 'Address', 'Area', 'Attention', 'Biological', 'Biomedical Research', 'Biotechnology', 'Cells', 'Clinical Research', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Colorado', 'Computers', 'Disease', 'Educational workshop', 'Engineering', 'Future', 'Genetic Engineering', 'Genetic Screening', 'Human', 'Immune', 'Industrialization', 'Industry', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Medicine', 'Metabolic', 'Methodology', 'Modality', 'Neurologic', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Preventive', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientific Advances and Accomplishments', 'Scientist', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Work', 'clinical application', 'clinical practice', 'clinical translation', 'combinatorial', 'design', 'effective therapy', 'graduate student', 'meetings', 'nervous system disorder', 'next generation', 'novel diagnostics', 'posters', 'symposium', 'synthetic biology', 'targeted treatment', 'tool']",NIBIB,KEYSTONE SYMPOSIA,R13,2020,10000,0.010007493011154582
"Discovery and validation of neuronal enhancers as development of psychiatric disorders supplement Project Summary/Abstract The mandate of the PsychENCODE Data Analysis Core (DAC) includes the development of novel integrative methodologies to construct a coherent interpretational framework for the data emerging from the consortium. The complexity of building such a framework lies in the diversity of experimental assays and their associated confounding factors, as well as in the inherent uncertainty regarding how the various target biological components function together. As a result, any analytical and computational methods would need to capture this high dimensionality of structure in the data. While classical, parallel computation advances at an incredible pace and continues to serve the needs of the research community, our experience with the ever- increasing complexity of neuropsychiatric datasets has motivated us to also look at other promising technological avenues. Accordingly, motivated by recent developments in the field of quantum computing (QC), we herein explore the use of QC algorithms as applied to two problems of relevance to the PsychENCODE DAC: (1) the prediction of brain-specific enhancers based on variants and functional genomic assays (Aim S1; related to Aim 1 of the parent grant); and (2) the calculation of the contributions of cell types to tissue-level gene expression and to the occurrence of psychiatric disorders like schizophrenia, autism spectrum disorder and bipolar disorder (Aim S2; related to Aim 1 of the parent grant). The nascency of QC hardware technologies and the complexity of simulating quantum algorithms on classical computing resources means that our exploration will be confined to smaller, judiciously chosen datasets.Nevertheless, the work in this supplement will serve to evaluate future prospects for the use of QC algorithms and hardware in genomic analyses. We also consider two different paradigms of QC, the quantum annealer and the quantum gate model, and weigh their efficiency relative to classical computing. Finally, we will incorporate the QC and classical predictions into PsychENCODE consortium's database and online portal for visualizing the relationships between different genetic and genomic elements, and evaluate corroborating evidence for the predictions (Aim S3; related to Aim 2 of the parent grant). Project Narrative The PsychENCODE consortium has conducted extensive functional genomic analyses of samples from individuals diagnosed with psychiatric disorders aim to discover the complex biological architecture that lead from genetic and epigenetic markers of disease to the observed phenotypes. To reveal this underlying structure, the consortium relies on the use of sophisticated computational methods, including machine learning techniques, implemented on cutting-edge massively parallel computing resources by the consrtium’s Data Analysis Core (DAC). However, the scale and complexity of the tasks place significant burdens on these resources, and suggest the need for exploring alternative computing hardware technologies. This supplement to the DAC parent grant evaluates the promise of the emerging field of quantum computing to speed up large-scale computations and more efficiently explore the model landscape, using a comparative analysis of classical and quantum computing algorithms applied to problems relevant to the PsychENCODE DAC: the annotation of brain-specific enhancers and the quantification of cell-type contributions to bulk tissue gene expression.",Discovery and validation of neuronal enhancers as development of psychiatric disorders supplement,10047746,U01MH116492,"['Algorithms', 'Architecture', 'Biological', 'Biological Assay', 'Bipolar Disorder', 'Brain', 'Cells', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Marker', 'Electronic Medical Records and Genomics Network', 'Elements', 'Enhancers', 'Future', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Individual', 'Lead', 'Least-Squares Analysis', 'Machine Learning', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Output', 'Performance', 'Phenotype', 'Publishing', 'Research', 'Resources', 'Running', 'Sampling', 'Schizophrenia', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Toy', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Visualization', 'Work', 'analytical method', 'autism spectrum disorder', 'base', 'cell type', 'comparative', 'computing resources', 'data framework', 'design', 'epigenetic marker', 'epigenomics', 'experience', 'functional genomics', 'high dimensionality', 'neuropsychiatry', 'novel', 'parallel computer', 'parent grant', 'prototype', 'quantum', 'quantum computing', 'simulation', 'transcriptome sequencing', 'web portal']",NIMH,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U01,2020,195697,-0.014630433380680293
"Harnessing ""omics"": A Systems Biology approach to discovery of biologicalpathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biologicalpathways in placental development and parturition",10243626,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,UNIVERSITY OF FLORIDA,R01,2020,357022,0.00027521702687694204
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9855015,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2020,149117,0.004719087116445649
"Next-generation, pathway-specific, polygenic risk scores PROJECT SUMMARY The key appeal of polygenic risk scores (PRS) is the provision of individual-level estimates of genetic liability to complex disease. These proxies of genetic liability enable a raft of applications across clinical and basic research settings. However, while PRS are set to play a pivotal role in the future of biomedical research, their present formulation is suboptimal since it fails to directly account for substructure in genetic disease risk. The overarching goal of our proposal is to introduce a new generation of pathway-specific PRS, informed by biological function. Rather a single genome-wide PRS for each individual, they will have a set of k PRS over k pathways. Pathways will be defined according to multiscale integration of ‘omics data, exploiting co-expression networks, the transcriptome and the epigenome. The key deliverable from this project will be the production of a powerful and comprehensive pathway-specific PRS computational tool, PRSet, informed by biological function. The rationale is that PRS calculated for individuals by aggregating the effects of all risk variants genome-wide, results in a loss of vital individual-level information. Providing pathway-specific estimates of genetic liability, computed in a scalable, statistically rigorous way, informed by latest multi-omic data, could enable researchers to better decompose heterogenous complex disease, identify key pathways that explain overlap or differences among disorders, and explain problems of portability of PRS between and within populations. Applying our pathway-specific PRS tool, we seek to stratify patients into more homogenous subgroups by their liability over key pathways. We will use PRSet for stratification in three ways: (i) stratifying within SCZ/BiP, testing if liability over different pathways forms multiple routes to disease, (ii) differentiating between SCZ and BiP, testing if key pathways differentiate these highly overlapping disorders, (iii) testing whether variation in treatment response can be explained by pathway liability. Such stratification could help explain past successes, failures and adverse-effects in clinical trials, and provide new therapeutic targets tailored to subsets of patients. Our proposal is significant because the burgeoning application of PRS means that any advance in the PRS approach will have immediate, high impact across psychiatric research. Pathway-specific PRS could open-up routes to hypotheses that cannot be answered by genome-wide PRS. If PRSet reveals that genetic liability is more stratified than presently modelled, then this would call for a focus on pathways and their multi-omic integration, paving a new path towards precision medicine. Our proposal is innovative because we develop the first pathway-specific, function-informed, PRS tool, we propose that disease risk may be influenced by multiple genetic liabilities, and we stratify patients according to pathway-specific genetic risk for the first time. In conclusion, our proposal delivers a tool for the field to perform powerful pathway PRS analyses, better understand genetic liability to disease, and which may offer a more direct route to precision medicine. PROJECT NARRATIVE Polygenic risk scores (PRS) are set to play a key role in advancing our understanding of the etiology and treatment of disease. While the application of genome-wide PRS is burgeoning across biomedical research, we propose that pathway-specific PRS have even greater potential to provide etiological insights and will help pave the way to precision medicine. Here we introduce a new generation of pathway-specific polygenic risk scores, informed by biological function, and deliver a comprehensive computational tool for their analysis, applying it to perform patient stratification in schizophrenia and bipolar disorders.","Next-generation, pathway-specific, polygenic risk scores",9947403,R01MH122866,"['Address', 'Adverse effects', 'Basic Science', 'Biochemical', 'Biochemical Pathway', 'Biological', 'Biological Process', 'Biomedical Research', 'Bipolar Disorder', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Computer software', 'Custom', 'Data', 'Diagnostic', 'Disease', 'Disease susceptibility', 'Environment', 'Epigenetic Process', 'Etiology', 'Failure', 'Formulation', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Gold', 'Human', 'In Vitro', 'Individual', 'Intuition', 'Lead', 'Link', 'Location', 'Mental disorders', 'Modeling', 'Multiomic Data', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Prevention', 'Production', 'Proxy', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Route', 'Running', 'Sampling', 'Schizophrenia', 'Stratification', 'Subgroup', 'Symptoms', 'Testing', 'Time', 'Variant', 'base', 'computerized tools', 'disorder risk', 'epigenome', 'functional genomics', 'genome wide association study', 'genome-wide', 'high risk', 'individualized prevention', 'innovation', 'insight', 'multiple omics', 'new therapeutic target', 'next generation', 'novel strategies', 'patient stratification', 'patient subsets', 'personalized medicine', 'personalized therapeutic', 'polygenic risk score', 'portability', 'precision medicine', 'prototype', 'rare variant', 'risk variant', 'statistical and machine learning', 'success', 'tool', 'trait', 'transcriptome', 'treatment response', 'user-friendly']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,545648,-0.007428124611587586
"Privacy-preserving genomic medicine at scale 1 Project Summary  2  3 High-throughput sequencing, biomedical imaging, and electronic health record technologies are 4 generating health-related datasets of unprecedented scale. Integrative analysis of these  5 resources promises to reveal new biology and drive personal and precision medicine. Yet, the  6 sensitive nature of these data often requires that they be kept in isolated silos, limiting their 7 usefulness to science. The goal of this project is to develop innovative privacy-preserving  8 algorithms to enable data sharing and drive genomic medicine. Crucially, we will draw upon our  9 past success in secure genome analysis and algorithmic expertise in computational biology to 10 address the imminent need to perform complex integrative analyses securely and at scale. 11 Current privacy-preserving tools are prohibitively too costly to perform the complex 12 calculations required in genomic analysis. We previously leveraged the highly structured nature 13 of biological data and novel optimization strategies to implement efficient pipelines for secure 14 genome-wide association studies (GWAS) and drug interaction predictions which scaled to 15 millions of samples. In this project, we will further exploit the unique properties of biomedical data 16 to: (i) develop secure integrative analysis methods for genomic medicine; (ii) develop an easy-to- 17 use programming environment with advanced automated optimizations to facilitate the adoption 18 of privacy-preserving analyses; and (iii) promote the use of our privacy techniques to gain novel 19 biological insights through large-scale collaborative genetic studies of multi-ethnic cohorts. 20 With co-I’s Amarasinghe (MIT) and Cho (Broad Institute), we aim to apply these tools to 21 realize the first multi-institution, multi-national secure genetic studies with our partners at the 22 Swiss Personalized Health Network, UK Biobank, Finnish FinnGen, All of Us, NIH NCBI, Broad 23 and Barcelona Supercomputing Center (Letters of Support). We will also use our privacy- 24 preserving approaches to study genomic origins of polygenic traits for disease as well as 25 neuroimaging and other clinical phenotypes. We will continue to actively integrate our methods 26 into community standards (MPEG-G, GA4GH). 27 Successful completion of these aims will result in computational methods and open-source, 28 easy-to-use, production-grade implementations that open the door to secure integration and 29 analysis of massive sets of sensitive genomic and clinical data. With input from our collaborations, 30 we will build these tools and apply them to better understand the molecular causes of human 31 health and its translation to the clinic. Project Narrative Combining genomic and health-related data from millions of patients will empower the development of clinically relevant measures of human health and disease risks. However, this task requires securely sharing sensitive data at an immense scale beyond what existing cryptographic platforms can achieve. Here we develop novel computational methods to enable biomedical data integration, analysis, and interpretation in a privacy-preserving and highly scalable manner.",Privacy-preserving genomic medicine at scale,9998648,R01HG010959,"['Address', 'Adoption', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biological', 'Biology', 'Clinic', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Pooling', 'Data Security', 'Data Set', 'Disease', 'Drug Interactions', 'Electronic Health Record', 'Engineering', 'Environment', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Institutes', 'Institution', 'Knowledge', 'Letters', 'Machine Learning', 'Mainstreaming', 'Measures', 'Medical Imaging', 'Medical Records', 'Medicine', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Patients', 'Performance', 'Pharmacology', 'Polygenic Traits', 'Privacy', 'Process', 'Production', 'Property', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Science', 'Secure', 'Security', 'Software Engineering', 'Software Tools', 'Standardization', 'Stream', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Time', 'Translations', 'United States National Institutes of Health', 'Work', 'analysis pipeline', 'base', 'biobank', 'bioimaging', 'clinical development', 'clinical phenotype', 'clinically relevant', 'cohort', 'computer framework', 'cost', 'cryptography', 'data analysis pipeline', 'data integration', 'data sharing', 'data warehouse', 'disorder risk', 'epidemiology study', 'experimental study', 'genome analysis', 'genome wide association study', 'genomic data', 'health data', 'innovation', 'insight', 'monomethoxypolyethylene glycol', 'neuroimaging', 'novel', 'open source', 'polygenic risk score', 'precision medicine', 'preservation', 'privacy preservation', 'statistics', 'success', 'task analysis', 'theories', 'tool']",NHGRI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,636185,-0.015141511475848583
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10156141,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'structured data', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2020,2075409,-0.013024918814666149
"lntegration and Visualization of Diverse Biological Data PROJECT SUMMARY The onset of most human disease involves numerous molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway, and treatment contexts. This system is probed by thousands of functional genomics and quantitative genetic studies, and integrative analysis of these data can generate testable hypotheses identifying causal genetic variants and linking them to network level changes in cells to disease phenotypes. This can enable deeper molecular-level understanding of pathophysiology, paving the way to genome-based precision medicine.  The long term goal of this project is to enable such discoveries through integrative analysis of high- throughput biological data in a disease context. In the previous funding periods, we developed accurate data integration methods, created algorithms for the prediction of disease genes through context-specific and mechanistic network models and analysis of quantitative genetics data, and made novel insights into important biological processes and diseases. We further enabled experimental biological discovery by building public interactive systems capable of real-time user-driven integration that are popular among experimental biologists.  We now propose to connect these gene-level functional network approaches with the underlying genomic variation by deciphering how genomic variants lead to specific transcriptional and posttranscriptional effects. We propose to develop ab initio sequence-level models capable of predicting biochemical effects of any genomic variant (including rare or never observed) on chromatin state and RNA regulation, then link these effects with gene-level regulatory consequences (including tissue-specific transcription and RNA splicing), and finally put genomic sequence directly into the network context via a statistical approach for detecting genes and network neighborhoods with a significantly elevated mutational burden in disease. Our key deliverable will be a user- friendly, interactive web-based framework enabling systems-level variant impact analysis in a network context and an open source library for computational scientists. In addition to systematic analysis across contexts and diseases, we will collaborate with experimentalists to apply our methods to Alzheimer’s, autism spectrum disorders, chronic kidney disease, immune diseases, and congenital heart defects as case studies for the iterative improvement of our methods and to directly contribute to better understanding of these diseases. PROJECT NARRATIVE To pave the way for mechanistic interpretation of disease in the genomic context and eventually, precision medicine, we will develop algorithms for de novo prediction of functional biochemical effects of noncoding variants at the DNA regulation and RNA processing levels and then build frameworks for sequence-based prediction of tissue-specific transcription and post-transcriptional RNA processes (starting with splicing). To facilitate discovery of disease mechanisms, we will develop approaches for analyzing these variant effects in a network context, including those developed in the previous grant period (mechanistic and functional networks) and novel network models that integrate exon usage information or enhancer-gene interactions. In addition to verifying top predictions experimentally in our group or by our collaborators in case study areas of neurodegenerative disease, chronic kidney disease, ASD, and congenital heart disease, we will make our methods available to the broader biomedical community through public, interactive user interfaces and open source libraries.",lntegration and Visualization of Diverse Biological Data,9902503,R01GM071966,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Base Sequence', 'Binding', 'Biochemical', 'Biological', 'Biological Process', 'Case Study', 'Cell Lineage', 'Cells', 'Chromatin', 'Chronic Kidney Failure', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Congenital Heart Defects', 'DNA', 'Data', 'Data Analyses', 'Deoxyribonucleases', 'Disease', 'Enhancers', 'Exons', 'Feedback', 'Functional disorder', 'Funding', 'Genes', 'Genetic Transcription', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Grant', 'Histones', 'Hypersensitivity', 'Immune System Diseases', 'Immunology', 'Knowledge', 'Laboratories', 'Lead', 'Letters', 'Libraries', 'Link', 'Measurement', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Neighborhoods', 'Nephrology', 'Network-based', 'Neurobiology', 'Neurodegenerative Disorders', 'Online Systems', 'Pathway Analysis', 'Pathway interactions', 'Post-Transcriptional Regulation', 'Process', 'Proteins', 'Quantitative Genetics', 'RNA', 'RNA Processing', 'RNA Splicing', 'RNA-Binding Proteins', 'Regulation', 'Research', 'Research Personnel', 'Scientist', 'System', 'Time', 'Tissue-Specific Gene Expression', 'Tissues', 'Untranslated RNA', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'biomedical scientist', 'causal variant', 'cell type', 'congenital heart disorder', 'crosslinking and immunoprecipitation sequencing', 'data integration', 'deep learning', 'disease phenotype', 'epigenomics', 'functional genomics', 'gene interaction', 'genetic variant', 'genome wide association study', 'genomic variation', 'high throughput analysis', 'human disease', 'improved', 'in vivo', 'insight', 'network models', 'novel', 'open source', 'precision medicine', 'prediction algorithm', 'predictive modeling', 'transcription factor', 'user-friendly']",NIGMS,PRINCETON UNIVERSITY,R01,2020,448294,-0.025713484735596454
"Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome PROJECT SUMMARY/ABSTRACT  The major goal of this RC2 proposal is to generate the first, multi-omics translational study capturing the sum of environmental exposures (i.e. the exposome) and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without effective medical therapy. PSC shortens survival, is associated with inflammatory bowel disease (IBD) and strongly predisposes to cholangiocarcinoma (i.e. bile duct cancer) and colon cancer. Our recent genome wide association studies (GWAS) revealed the significant role of genetic variation in PSC, while also re-emphasizing the importance of environmental factors and gene-environment interactions in PSC pathogenesis. To further elucidate the role of exposures from our external environment and lifestyle (e.g., diet, stress, toxins, drugs, microbes), we have assembled a world-class, multi-disciplinary team that synergizes expertise and resources across four institutions: Mayo Clinic, Emory University, University of Illinois Urbana-Champaign (UIUC), and University of Oslo, Norway. Our collaborative team will leverage large clinical databases and biorepositories, as well as expertise in PSC and related conditions, exposomics, metabolomics, methylomics, transcriptomics, metagenomics, genomics, and data analytics to develop the PSC Scientific Community Resource for hypothesis-generating science and simultaneously uncover factors contributing to PSC.  We now seek to define the bigger-picture cellular networks, rather than individual genes, driving disease processes. To do so, we will use unbiased network-based approaches designed to integrate multiple layers of omics data. Our proposal is predicated on the hypothesis that multi-omics analyses of data capturing environmental exposures and the associated biological responses, including the effect on the genome, will reveal networks or pathways influencing PSC pathogenesis and outcomes. To test this hypothesis, we will perform a series of sophisticated analyses to identify PSC-associated changes in and across the exposome, metabolome, methylome, and transcriptome in blood as well as the gut metagenome, exposome and metabolome.  Our collaboration and data generation are already underway with pilot studies demonstrating differences in blood exposomes and metabolomes and stool metagenomes between PSC patients and controls. Using a suite of bioinformatic tools and available genetic variation data, we aim to discover stable, detectable, omics-based disease signatures in blood (Aim 1) and stool (Aim 2) that when integrated with clinical data (Aim 3) will reveal biological pathways driving disease pathogenesis and outcomes. All data, residual specimens, and analytical details will be made freely available to the research community in accordance with NIDDK's mission. Furthermore, this effort responds to the NIDDK's call “to better understand the role of the microbiome, genetics, and exposome.” PROJECT NARRATIVE We seek to generate the first, multi-omics translational study and comprehensive data resource for Primary Sclerosing Cholangitis (PSC), a chronic, progressive liver disease without medical therapy. We will define the bigger-picture cellular networks and gene-environment interactions driving PSC by integrating multiple layers of -omics data. In so doing, we will identify molecular disease signatures, including environmental toxins, metabolism-related chemicals and gut bacteria, unique to PSC patients.",Dissecting the pathogenesis and outcomes of PSC using multi-omics by studying the exposome and genome,9986790,RC2DK118619,"['Accounting', 'Address', 'Age', 'Automobile Driving', 'Bile duct carcinoma', 'Biological', 'Blood', 'Chemical Exposure', 'Chemicals', 'Childhood', 'Cholangiocarcinoma', 'Cholestasis', 'Chronic', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Colon Carcinoma', 'Communities', 'DNA Methylation', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Analytics', 'Diet', 'Disease', 'Environment', 'Environmental Exposure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feces', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Graph', 'High Performance Computing', 'Illinois', 'Individual', 'Inflammatory Bowel Diseases', 'Institution', 'Life Style', 'Light', 'Link', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Medical', 'Metagenomics', 'Microbe', 'Mission', 'Modeling', 'Molecular Disease', 'Multiomic Data', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Network-based', 'Norway', 'Onset of illness', 'Outcome', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Research', 'Residual state', 'Resolution', 'Resources', 'Role', 'Science', 'Series', 'Shotguns', 'Specimen', 'Stress', 'Sum', 'Systems Biology', 'Taxonomy', 'Testing', 'Toxic Environmental Substances', 'Toxin', 'Universities', 'base', 'biobank', 'bioinformatics tool', 'clinical database', 'data integration', 'data resource', 'design', 'gene environment interaction', 'genome wide association study', 'genomic data', 'gut bacteria', 'gut metagenome', 'gut microbiota', 'improved', 'inflammatory disease of the intestine', 'innovation', 'liver transplantation', 'metabolome', 'metabolomics', 'metagenome', 'methylation pattern', 'methylome', 'methylomics', 'microbial', 'microbiome', 'multidisciplinary', 'multiple omics', 'novel', 'patient population', 'peripheral blood', 'personalized approach', 'pollutant', 'primary outcome', 'primary sclerosing cholangitis', 'programs', 'response', 'sex', 'toxin metabolism', 'transcriptome', 'transcriptomics', 'translational study']",NIDDK,MAYO CLINIC ROCHESTER,RC2,2020,1547338,0.0018562664859371645
