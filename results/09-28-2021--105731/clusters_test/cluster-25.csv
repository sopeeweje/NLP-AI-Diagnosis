text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Affective science and smoking cessation: Real time real world assessment Tobacco use plays a causal role in almost 20 different types of cancer, and although smoking cessation is a cornerstone of cancer risk reduction, the vast majority of smoking quit attempts fail. Numerous conceptual models, as well as a large body of empirical evidence, underscore that affect is a potent determinant of smoking lapse. Unfortunately, very little is known about how the constellation and temporal dynamics of distinct emotions and other factors play out in real time in the real world to influence lapse risk. This lack of knowledge severely hampers both our conceptual models and our ability to optimally intervene. Thus, the overarching objectives of this research are to create a more detailed and comprehensive conceptual model of the role of distinct emotions in self-regulation, as well as the technical, empirical, and analytic foundation necessary to develop effective interventions for smoking cessation and other cancer risk behaviors that can target real time, real world mechanisms. The proposed research directly addresses several objectives from the PAR including the influence of distinct emotions and their time course on cancer risk behaviors, whether the role of distinct emotions is altered by the presence of other emotions (e.g., “blended” emotional states), and how the influence of affective experience is modified by context. The proposed longitudinal cohort study among 300 smokers attempting to quit is guided by a conceptual framework grounded in affective science and conceptual models of self-regulation and addiction. Participants will be followed from 1 week prior to their quit date through 6 months post-quit date. They will be assessed from 1 week pre-quit date through 2 weeks post-quit date using AutoSense, geographic positioning system (GPS), and ecological momentary assessment (EMA). AutoSense, GPS, and EMA collect real time data in natural environments, communicate wirelessly with each other, and data are processed in real time on a smartphone. AutoSense detects specific behavioral and physiologic “signatures” of smoking (the primary outcome) and self regulatory capacity (an intermediate outcome; assessed using high frequency heart rate variability) in real time. GPS real time spatial tracking will be linked with spatially and temporally relevant characteristics of the environment using geographic information system (GIS) data. EMAs assess self-reported emotions, cognition, and context. Analyses utilize advanced dynamic risk prediction models and machine learning approaches to model the dynamics of real time, real world associations among distinct emotions, SRC, and lapse. Tobacco use is the leading preventable cause of death and disability in the U.S. The proposed study will yield a more detailed and comprehensive conceptual model of the role of distinct emotions in self-regulation, as well as the technical, empirical, and analytic foundation necessary to develop more effective interventions for smoking cessation and other cancer risk behaviors that can target real time, real world mechanisms. This knowledge can be utilized to reduce the public health burden of tobacco use.",Affective science and smoking cessation: Real time real world assessment,10074543,R01CA224537,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anger', 'Behavioral', 'Cause of Death', 'Cellular Phone', 'Characteristics', 'Cognition', 'Complement', 'Complex', 'Data', 'Depressed mood', 'Ecological momentary assessment', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Foundations', 'Frequencies', 'Geographic Information Systems', 'Geography', 'Home environment', 'Informal Social Control', 'Intervention', 'Knowledge', 'Link', 'Longitudinal cohort study', 'Machine Learning', 'Measurement', 'Mediating', 'Mediator of activation protein', 'Modeling', 'Outcome', 'Participant', 'Patient Self-Report', 'Physiological', 'Play', 'Positioning Attribute', 'Process', 'Public Health', 'Real-Time Systems', 'Reporting', 'Research', 'Risk', 'Risk Behaviors', 'Risk Reduction', 'Role', 'Science', 'Smoker', 'Smoking', 'Smoking Cessation Intervention', 'Stress', 'System', 'Testing', 'Time', 'Tobacco', 'Tobacco use', 'Volition', 'Wireless Technology', 'adaptive intervention', 'addiction', 'advanced analytics', 'base', 'cancer prevention', 'cancer risk', 'cancer type', 'disability', 'effective intervention', 'experience', 'heart rate variability', 'knowledge base', 'mobile computing', 'negative affect', 'primary outcome', 'risk prediction model', 'role model', 'smoking cessation', 'success']",NCI,UNIVERSITY OF UTAH,R01,2021,1
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,10124433,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2021,199800
"Computational and brain predictors of emotion cue integration The purpose of this project is to develop computational and brain-based models of emotion cue integration: people’s inferences about others’ emotions based on dynamic, multimodal cues. Observers often decide how targets feel based on cues such as facial expressions, prosody, and language. Such inferences scaffold healthy social interaction, and abnormal inference both marks and exacerbates social deficits in numerous psychiatric disorders. Psychologists and neuroscientists have studied emotion inference for decades, but the vast majority of this work employs simplified social cues, such as vignettes or static images of faces. By contrast, “real world” emotion cues are complex, dynamic, and multimodal. Cue integration—inference based on naturalistic emotion information—likely differs from simpler inference at cognitive and neural levels, but this phenomenon remains poorly understood. This means that scientists lack a clear model of how observers adaptively process complex emotion cues, and how that processing goes awry in mental illness. Especially lacking are mechanistic models that can describe the computations and brain processes involved in cue integration with sufficient precision to predict inference in new cases, observers, and samples. This project will merge tools from social psychology, computer science, and neuroscience to generate a novel and rigorous model of emotion cue integration. We have demonstrated that in the face of complex emotion cues, observers dynamically “weight” cues from each modality (e.g., visual, linguistic) over time, a process that (i) tracks shifts in brain activity and connectivity; and (ii) can be captured using Bayesian models. Here, we will expand this work in several ways. First, we will develop precise computational tools to isolate features of emotion cues—such as facial movements, prosody, and linguistic sentiment—that track observers’ use of each cue modality during integration. Second, we will develop multi-region “signatures” of brain activity and connectivity that track emotion inference in each modality. We will use these signatures in conjunction with machine learning to predict unimodal emotion inference and cue integration in new observers and samples, based on brain data alone. Third, we will explore the context-dependence of naturalistic emotion inference by testing whether reinforcement learning can bias observers’ cue integration and accompanying brain signatures. Finally, we will model computational and neural abnormalities associated with cue integration in patients with Major Depressive Disorder and Bipolar Disorder. At the level of basic science, these data will generate a fundamentally new—and more naturalistic—approach to the neuroscience of emotion inference. The computational and brain metrics we produce will also be made publically available to facilitate the open and cumulative study of emotion inference across labs. At a translational level, we will provide a mechanistic, rich account of abnormal emotion inference in mood disorders, paving the way for computational and brain markers that can be used to assess social dysfunction and treatment efficacy in these and other mental illnesses. PROJECT NARRATIVE The proposed research will use methods from social psychology, cognitive neuroscience, and computer science to (i) precisely model people’s inferences about others’ emotions based on complex, dynamic cues, (ii) generate multi-region, brain-based predictors of these inferences, and (iii) characterize abnormalities in inference among individuals with mood disorders. Several psychiatric and neurodevelopmental disorders are characterized by difficulties understanding others’ emotions, which in turn worsen social functioning in patients. In addition to providing new insights about social processes—a core target within the NIMH’s research domain criteria (RDoC) framework—the proposed research will offer powerful, novel computational and neural targets through which to assess and treat difficulties in emotion inference, and to eventually reduce the social burden faced by people with mental illness on a broad scale.",Computational and brain predictors of emotion cue integration,10138024,R01MH112560,"['Affect', 'Agreement', 'Base of the Brain', 'Basic Science', 'Bayesian Modeling', 'Bipolar Disorder', 'Brain', 'Brain region', 'Classification', 'Cognitive', 'Complex', 'Computer Models', 'Cues', 'Data', 'Dependence', 'Emotional', 'Emotional disorder', 'Emotions', 'Event', 'Exhibits', 'Face', 'Face Processing', 'Facial Expression', 'Functional Magnetic Resonance Imaging', 'Future', 'Image', 'Individual', 'Language', 'Lateral', 'Learning', 'Life', 'Linguistics', 'Machine Learning', 'Major Depressive Disorder', 'Measures', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Movement', 'National Institute of Mental Health', 'Neurodevelopmental Disorder', 'Neurosciences', 'Observer Variation', 'Participant', 'Patients', 'Pattern', 'Perception', 'Process', 'Psychological reinforcement', 'Psychologist', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Running', 'Sampling', 'Scanning', 'Scientist', 'Sensory', 'Social Functioning', 'Social Interaction', 'Social Processes', 'Social Psychology', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Visual', 'Weight', 'Work', 'affective computing', 'base', 'brain abnormalities', 'cognitive neuroscience', 'computer science', 'computerized tools', 'executive function', 'insight', 'language comprehension', 'multimodality', 'neuroimaging', 'novel', 'recruit', 'relating to nervous system', 'response', 'scaffold', 'social', 'social deficits', 'tool']",NIMH,STANFORD UNIVERSITY,R01,2021,249264
"Neurophysiology underlying neural representations of value A range of behavioral, physiological, and cognitive responses (e.g. approach and avoidance, autonomic reactivity, and subjective feelings) reflects a subject's emotional state. The cognitive regulation of emotion refers to the capacity to regulate these emotional responses in a flexible manner according to a cognitive operation. Deficits in the cognitive regulation of emotional processes characterize many psychiatric disorders. In everyday life, however, particular sensory stimuli and/or actions can elicit different emotional responses depending upon the situation or context. Contexts often rely on a cognitive understanding of one's current situation in the absence of explicit cues. These types of contexts may be referred to as “abstract” contexts. This grant studies a type of abstract context where the context is determined by a task set. A task set is the set of stimulus- response-outcome mappings (or rules) that dictate correct performance for trials within a particular block. Previous research demonstrates the capacity of primates to learn these abstract contexts, and neural representations of abstract contexts exist in the amygdala and two areas in the prefrontal cortex (PFC), the anterior cingulate and orbitofrontal cortices (ACC and OFC). This grant seeks to understand the mechanisms that underlie the formation and maintenance of these representations of contexts. In contrast to supervised learning driven by error signals, we hypothesize that the occurrence of temporally associated trial types triggers unsupervised learning, presumably through a Hebbian mechanism involving activity-dependent plasticity. This learning could underlie formation of representations of abstract contexts defined by task sets, which will be explored with electrophysiological recordings in Aim 1. The creation of a representation of a task set requires combining information about the current trial with information about the trials that have occurred recently. Brain structures that provide memory traces of recent events and/or that combine information over time could create representations of a task set prior to the emergence of the representations observed in amygdala, OFC, and ACC. Our next experiments therefore target the hippocampus and dorsolateral PFC (DLPFC), which are implicated in memory processes, working memory, and executive functions. We will compare and contrast the encoding of task sets in hippocampus, DLPFC, OFC, and ACC during and after learning about task sets (Aim 2). Finally, we will use causal methods to determine if PFC input to the amygdala and the hippocampus acts to maintain these context representations, which could be a vital mechanism for the cognitive regulation of emotion (Aim 3). Overall, these experiments promise to illuminate neurophysiological mechanisms critical for normal adaptive emotional health. ! The aim of this proposal is to understand brain mechanisms responsible for the cognitive regulation of emotion. Since many psychiatric disorders, like anxiety and mood disorders as well as schizophrenia, autism, and addiction, involve cognitive dysfunction mediated by neural circuits in the brain areas under study, this project promises to provide new insights about neural network function critical for developing new treatments.",Neurophysiology underlying neural representations of value,10053729,R01MH082017,"['Amygdaloid structure', 'Anterior', 'Anxiety Disorders', 'Area', 'Behavioral', 'Brain', 'Cognitive', 'Cues', 'Development', 'Electrophysiology (science)', 'Emotional', 'Emotions', 'Event', 'Feeling', 'Grant', 'Health', 'Hippocampus (Brain)', 'Impaired cognition', 'Knowledge', 'Lead', 'Learning', 'Life', 'Maintenance', 'Mediating', 'Memory', 'Mental disorders', 'Methods', 'Monkeys', 'Mood Disorders', 'Outcome', 'Perception', 'Performance', 'Physiological', 'Play', 'Prefrontal Cortex', 'Primates', 'Process', 'Psychological reinforcement', 'Research', 'Response to stimulus physiology', 'Reversal Learning', 'Rewards', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Stimulus', 'Structure', 'Task Performances', 'Testing', 'Time', 'Update', 'Work', 'addiction', 'autism spectrum disorder', 'cognitive control', 'cognitive process', 'cognitive reappraisal', 'emotion regulation', 'emotional experience', 'executive function', 'expectation', 'experimental study', 'flexibility', 'insight', 'memory process', 'neural circuit', 'neural network', 'neurophysiology', 'operation', 'optogenetics', 'prevent', 'relating to nervous system', 'response', 'sensory stimulus', 'statistics', 'supervised learning', 'unsupervised learning']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,682901
"CRCNS: Optimization of closed-loop control of gamma oscillations Throughout the brain, specialized systems carry out different but complementary functions, sometimes  independently but often in cooperation. However, we do not understand how their activity is dynamically  coordinated, and dysregulation of this is associated with many mental health conditions. Neuronal oscillations, which are detectable in local field potentials (LFPs) at various frequencies, are a promising  target for this coordination. Gamma oscillations (40-100 Hz) in particular have been singled out since they enhance stimulus responses, facilitate interactions between brain regions, and are expressed ubiquitously across cortical and subcortical regions. Indeed, gamma oscillations occur in the basolateral  nucleus of the amygdala (BL), an important regulator of emotional behaviors. BL gamma oscillations are  enhanced during periods of heightened vigilance during a foraging task, following emotionally salient experiences, and upon presentation of socially-relevant stimuli. The variety of circumstances that engage  it make it a promising target for interventions affecting emotional behaviors in general. However, technical challenges abound because gamma manifests as brief intermittent oscillatory bursts, layered atop numerous ongoing activities in other frequency bands. This precludes manipulating gamma exclusively with traditional pharmacological, optogenetic, or chemogenetic approaches, since these have substantial  effects on ongoing non-gamma activities, and are delivered irrespective of whether gamma bursts are present or absent. To overcome this, a closed-loop algorithm was developed that monitors the LFP in  real-time for gamma oscillations and delivers precisely timed optogenetic stimulation capable of enhancing or suppressing gamma strength on a cycle-by-cycle basis. While this improves upon the status  quo,, further refinement is needed. Aim 1 of this proposal seeks to clarify how the gamma modulation technique operates via biophysically detailed modeling of the local circuits in the BL that generate gamma, the effects of optogenetic stimulation, and the closed-loop algorithm. Aim 2 designs better signal  processing routines for detecting and parameterizing gamma in real-time. Aim 3 develops an approach to  create customized biophysical models that reproduce the properties of gamma observed in individual  subjects, which when combined with the results of Aims 1 and 2 should allow for optimized control over gamma oscillations in individual subjects. RELEVANCE (See instructions):  Gamma oscillations occur in the basolateral amygdala, a brain region implicated in emotional regulation.  By developing improved methods to manipulate these oscillations, we hope to better understand their  function and improve our ability to control emotional states and behaviors. n/a",CRCNS: Optimization of closed-loop control of gamma oscillations,10207403,R01MH122023,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Amygdaloid structure', 'Anatomy', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Brain region', 'Cell Nucleus', 'Cells', 'Collaborations', 'Communication', 'Custom', 'Detection', 'Emotional', 'Frequencies', 'Genetic', 'Goals', 'Implant', 'Individual', 'Individual Differences', 'Instruction', 'Interneurons', 'Intervention', 'Machine Learning', 'Mental Health', 'Methods', 'Modeling', 'Monitor', 'Neurons', 'Performance', 'Pharmacology', 'Phase', 'Physiological', 'Property', 'Response to stimulus physiology', 'Rodent Model', 'Route', 'Scheme', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Twin Multiple Birth', 'biophysical model', 'cognitive function', 'design', 'emotion regulation', 'emotional behavior', 'experience', 'experimental study', 'improved', 'in vivo', 'individual variation', 'insight', 'neurophysiology', 'novel', 'optogenetics', 'predictive modeling', 'response', 'signal processing', 'social', 'vigilance']",NIMH,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,284005
"Cerebellar Interactions with the Amygdala and Prefrontal Cortex during Learning Learning is how organisms adapt to changes in their environment and involves the coordination of neural systems mediating cognition, emotion, and motor control. The major goal of the proposed research program is to elucidate the neural circuit mechanisms underlying interactions between cognitive, emotional, and motor systems during associative learning. Interactions between these neural systems are particularly important because the context and emotional significance of stimuli provide essential information for acquisition and performance of motor responses. The breakdown of interactions between cognitive, emotional, and motor systems in various neurological disorders can therefore have devastating consequences for learned behaviors. The prefrontal cortex, amygdala, and cerebellum play significant roles in cognition, emotional responses, and motor learning, respectively. The proposed research program constitutes a comprehensive analysis of cerebellar interactions with the amygdala and prefrontal cortex during associative motor learning. Our general conceptual framework is that the cerebellum receives inputs from the amygdala and prefrontal cortex via the pons regarding which stimuli are important and when they occur, and the cerebellum then sends error-driven feedback to these forebrain systems to facilitate learning about important events. This conceptual framework takes into account the bidirectional relationship between the cerebellum and the relevant forebrain systems as well as interactions between forebrain systems. Multi-site electrophysiology, pathway-specific optogenetics, and precise behavioral analyses will be combined to investigate circuit-level interactions between the cerebellum, amygdala, and prefrontal cortex during associative learning and extinction (inhibitory learning) training. The proposed studies would significantly advance understanding of the neural circuit mechanisms underlying cerebellar interactions with the forebrain. This would be a substantial contribution to the field because it has been known that the cerebellum must interact with the forebrain in many contexts that are crucial for everyday life such as learning, memory, planning, control of emotions, and communication, but very little is known mechanistically about how the cerebellum interacts with the amygdala and prefrontal cortex. Memory deficits are found with many neurological disorders such as Alzheimer's disease and following stroke; the breakdown of interactions between memory systems can be particularly debilitating. This proposal examines the neural mechanisms underlying interactions between emotional and motor memory systems during associative learning. Elucidating the neural mechanisms underlying memory system interactions is potentially important for developing treatments for memory deficits.",Cerebellar Interactions with the Amygdala and Prefrontal Cortex during Learning,10069403,R01NS088567,"['Affect', 'Alzheimer&apos', 's Disease', 'Amygdaloid structure', 'Anatomy', 'Animals', 'Area', 'Attention', 'Behavioral', 'Blinking', 'Cerebellum', 'Cognition', 'Cognitive', 'Communication', 'Conditioned Stimulus', 'Data', 'Electrophysiology (science)', 'Elements', 'Emotional', 'Emotions', 'Environment', 'Etiology', 'Event', 'Extinction (Psychology)', 'Feedback', 'Funding', 'Goals', 'Image', 'Learning', 'Life', 'Medial', 'Mediating', 'Memory', 'Memory impairment', 'Methods', 'Motor', 'Nature', 'Organism', 'Output', 'Pathway interactions', 'Performance', 'Physiological', 'Play', 'Pontine structure', 'Prefrontal Cortex', 'Process', 'Prosencephalon', 'Rattus', 'Research', 'Role', 'Safety', 'Short-Term Memory', 'Signal Transduction', 'Site', 'Stimulus', 'Stroke', 'Structure', 'System', 'Testing', 'Training', 'classical conditioning', 'conditioned fear', 'granule cell', 'indexing', 'learned behavior', 'learning extinction', 'machine learning algorithm', 'motor control', 'motor learning', 'nervous system disorder', 'neural circuit', 'neuromechanism', 'novel', 'optogenetics', 'programs', 'relating to nervous system', 'response', 'two-photon']",NINDS,UNIVERSITY OF IOWA,R01,2021,379571
"Mechanisms of Dynamic Neural Coupling during Face-to-Face Expressions of Emotion PROJECT SUMMARY Little is known about the neural mechanisms that regulate natural dynamic cues during human social and emotional interactions, although these mechanisms are impaired in many psychiatric and neurological disorders. Although it is widely understood that social signals such as facial expressions carry salient, but implicit, emotional and social cues, these “real-time” pathways have not been investigated with dual-brain neuroimaging techniques. This unmet need is largely due to technological limitations that prevent neuroimaging of two or more individuals during natural interactive situations. We overcome this technical “roadblock” with recent advances in an emerging human brain imaging technology, functional near-infrared spectroscopy (fNIRS). This non-invasive technique detects active neural tissue based on hemodynamic signals measured by variations in the absorption spectra associated with oxyhemoglobin and de-oxyhemoglobin. Because detectors and emitters are surface mounted on the head, absent a high magnetic field, they are relatively insensitive to head movement and thus successfully applied to dyadic experiments. The focus of this proposal is to gain a comprehensive understanding of the mechanisms that underlie dynamic cross-brain neural coupling during real interpersonal interactions. Cross-brain neural coupling is defined as the correlation between the temporal patterns of the signals of two brains. It has been proposed that these matched patterns represent shared neural processes including dynamic exchanges of information. However, the basic assumptions of shared information and temporal resonance patterns between specific brain-to-brain regions has not been tested. We pioneer tests of these hypothesis using eye-to-eye contact as a metric of shared information and predict that dynamic neural coupling between the two brains will increase with increasing numbers of eye-to-eye contact events. Mimicry of facial expressions is also a metric of emotional contagion as well as shared information between brains. We further test the hypothesis that neural coupling will increase with the level of mimicry also by virtue of the shared information Confirmation of the hypothesis that neural coupling represents shared information between the two brains would provide a singular advance for understanding mechanisms for dynamic interactions. Both approaches include variations of emotive expressions to test the additional hypothesis that content as well as shared information might influence dynamic coupling mechanisms. Findings from these studies are expected to open a new direction for the study of live and dynamic interactions between individuals, and provide foundational components to a general framework for models of face-to-face interactions. A long-term goal is to understand the neural underpinnings of affective disorders as they present in clinically-relevant and real-world situations. Project Narrative How do two brains interact? We pioneer a novel neuroimaging technology, near infrared spectroscopy, to investigate basic mechanisms of neural coupling between two dynamically interacting individuals. Using these new methods we test the fundamental hypothesis that neural coupling (temporal synchrony between two brains) represents shared information across the two brains.",Mechanisms of Dynamic Neural Coupling during Face-to-Face Expressions of Emotion,10084718,R01MH119430,"['Affective', 'Arousal', 'Brain', 'Brain imaging', 'Brain region', 'Classification', 'Code', 'Communication', 'Coupled', 'Coupling', 'Cues', 'Detection', 'Development', 'Elements', 'Emotional', 'Event', 'Eye', 'Eyebrow structure', 'Face', 'Face Processing', 'Facial Expression', 'Feeling', 'Foundations', 'Goals', 'Head', 'Head Movements', 'Human', 'Imaging technology', 'Impairment', 'Individual', 'International', 'Interpersonal Relations', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Mood Disorders', 'Near-Infrared Spectroscopy', 'Negative Valence', 'Oral cavity', 'Oxyhemoglobin', 'Participant', 'Pathway interactions', 'Pattern', 'Positioning Attribute', 'Positive Valence', 'Process', 'Shapes', 'Signal Transduction', 'Smiling', 'Social Interaction', 'Stimulus', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Variant', 'absorption', 'analog', 'base', 'clinically relevant', 'contagion', 'deoxyhemoglobin', 'detector', 'dyadic interaction', 'emotional reaction', 'experimental study', 'hemodynamics', 'magnetic field', 'mimicry', 'nervous system disorder', 'neural correlate', 'neuroimaging', 'neuromechanism', 'novel', 'prevent', 'relating to nervous system', 'response', 'showing emotion', 'social']",NIMH,YALE UNIVERSITY,R01,2021,399738
"Dynamics of Large-Scale Networks During Emotional and Social Processing The goal of this application is to develop a research program that, as stated in the call entitled The Neural Mechanisms of Multi-Dimensional Emotional and Social Representation (RFA-MH- 17-300), incorporates innovative approaches designed to move the fields of affective and social neuroscience beyond single region-based, modular, and static models of brain function and behavior. The RFA calls for research that is multi-dimensional, that is, that investigates the role of (among others) complex contexts, as well as distributed and/or dynamic processes that unfold over time. The objective of the present application is to jointly investigate emotional and social processes in a richly multi-dimensional manner. Aim 1: Network organization and evolution during emotional and social processing. The objective of this aim is to uncover how large-scale brain networks are organized and evolve temporally during emotional and social processing. Networks will include brain regions that robustly respond to the tasks proposed, and regions from well characterized networks, including the salience, executive control, and task-negative networks. Aim 2: Naturalistic processing during emotional and social processing. The objective of this aim is to understand naturalistic processing of emotional and social information. Although standard experimental designs afford great control over experimental conditions, they lack ecological validity and restrict the experiments that can be studied. We propose to investigate continuous (“naturalistic”) processing during movie watching involving emotional and social content. Continuous processing will be investigated via intersubject correlation analysis, which measures the extent to which signals are correlated across participants. Aim 3: Development of network organization/evolution and naturalistic processing. The objective of this aim is to investigate multi-dimensional emotional and social processes from a developmental perspective. Most developmental research in emotion has focused on observing amygdala responses and those of a few other brain regions during face perception. We focus on a question largely neglected in prior research, specifically sustained threat processing and the involvement of the bed nucleus of the stria terminalis. In the context of social processing, this aim examines the development of intersubject synchrony. Across the emotional and social domains, we propose to study middle childhood (8-9 y), early adolescence (12-13 y), and young adulthood (18-19 y). The goal of this application is to investigate the neural mechanisms of multi-dimensional emotional and social representation. Functional MRI experiments are proposed to investigate the following general questions: organization and evolution of brain networks; naturalistic processing during movie watching; and development.",Dynamics of Large-Scale Networks During Emotional and Social Processing,10120523,R01MH112517,"['Adolescence', 'Adopted', 'Affective', 'Amygdaloid structure', 'Anxiety', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Data', 'Development', 'Developmental Process', 'Disease', 'Emotional', 'Emotions', 'Evolution', 'Experimental Designs', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Individual Differences', 'Lead', 'Link', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Mood Disorders', 'Participant', 'Pathway Analysis', 'Persons', 'Process', 'Property', 'Research', 'Risk', 'Role', 'Series', 'Signal Transduction', 'Social Development', 'Social Environment', 'Social Interaction', 'Social Processes', 'Stimulus', 'Structure', 'Structure of terminal stria nuclei of preoptic region', 'Testing', 'Time', 'Work', 'affective neuroscience', 'age group', 'autism spectrum disorder', 'base', 'design', 'early adolescence', 'executive function', 'experimental study', 'face perception', 'graph theory', 'improved', 'innovation', 'middle childhood', 'movie', 'neglect', 'neurobiological mechanism', 'neuromechanism', 'novel', 'peer', 'positive mood', 'programs', 'relating to nervous system', 'response', 'social', 'social neuroscience', 'young adult']",NIMH,"UNIV OF MARYLAND, COLLEGE PARK",R01,2021,584996
"Unpacking Emotion Inflexibility and Prospective Prediction of Affective Disease PROJECT ABSTRACT/SUMMARY The prevalence of psychiatric disorders has reached nearly epidemic proportions. Rates of common affective diseases (unipolar depression, anxiety and stress disorders) are high across the lifespan and these diseases place a tremendous social and economic burden on the individual and society. Clear evidence indicates that most affective disorders emerge at the intersection of pre-existing vulnerability and significant, highly stressful, life-events. However, current models of emotion-related risk do not adequately account for this confluence of biological, historical, and situational factors. In this investigation, we build upon our prior work demonstrating broad associations between flexible emotion processing and psychological health and adjustment, and in-flexible emotion and psychological risk and affective disease. Specifically, we will recruit 400 adults in hospital following a potentially traumatic event (e.g., accident, violence, fire, etc.) in order to model the influence of early emotion processing on trajectories of adjustment. We focus our investigation on the super-ordinate construct of Emotion flexibility (EF) which encompasses the ability to generate or up-regulate emotions, as well as to shift or down-regulate emotions according to needs and/or environmental demands. EF is well-suited to inform models of emotion-related risk and adjustment as it characterizes an optimal balance of two biologically-based, constituent dimensions: “bottom-up” threat-related processing and “top-down” cognitive control increasingly recognized as central to all emotion processing. We propose rigorous methods to assess EF and related processing in-vivo in lab and via experience sampling. Moreover, we will follow participants to 18 months post event so as to effectively model the association between emotion processing and trajectories of adjustment, while also considering established influences such as physical health status, psychiatric history, childhood maltreatment, daily stress/hassles, and social support. In particular, we will incorporate recent developments in advanced statistical modelling to better characterize the complex and interactive influence of historical and contemporary factors on moment-level emotion processing, EF and adjustment. Broadly, this project is in line with the most recent NIMH strategic plan and will contribute to more complex models of the most common affective diseases, including facilitating the charting of illness trajectories to help determine when, where, and how to intervene. Moreover, this research will directly examine how variation in key systems can influence emotion-processing and adjustment to aversive life events, fitting complex influences more directly into models of risk for the most common and burdensome affective diseases. PUBLIC HEALTH RELEVANCE/NARRATIVE Emotion-related psychiatric disorders, including depression and anxiety, affect a considerable portion of adults in this country and rank as many of the most burdensome diseases worldwide. In this investigation, we will follow an at-risk sample of adults in order to better understand how one key pathway, relating to how individuals process emotion, influences risk for emotion-related diseases over time. In addition, we test the role by which certain other factors, both contemporary and historical (physical health, life stress, social support, psychiatric treatment history, or childhood experiences) may increase or decrease risk via this particular pathway.",Unpacking Emotion Inflexibility and Prospective Prediction of Affective Disease,10089147,R01MH113622,"['Accidents', 'Adult', 'Affect', 'Affective', 'Anxiety', 'Anxiety Disorders', 'Behavioral', 'Biological', 'Categories', 'Child Abuse and Neglect', 'Childhood', 'Clinical', 'Clinical Sciences', 'Complex', 'Country', 'Derivation procedure', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Disease Progression', 'Early Intervention', 'Economic Burden', 'Emotions', 'Epidemic', 'Equilibrium', 'Event', 'Fire - disasters', 'Health', 'Health Status', 'Heritability', 'Hospitals', 'Individual', 'Inherited', 'Investigation', 'Life', 'Life Stress', 'Longevity', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Mood Disorders', 'National Institute of Mental Health', 'Nature', 'Participant', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Post-Traumatic Stress Disorders', 'Prevalence', 'Process', 'Psychiatric therapeutic procedure', 'Psychological adjustment', 'Qualifying', 'Recording of previous events', 'Regulation', 'Research', 'Research Domain Criteria', 'Risk', 'Risk Adjustment', 'Risk Factors', 'Role', 'Sampling', 'Shapes', 'Sleep disturbances', 'Social support', 'Societies', 'Statistical Models', 'Strategic Planning', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Unipolar Depression', 'Variant', 'Violence', 'Work', 'base', 'childhood adversity', 'clinical diagnostics', 'clinically relevant', 'cognitive control', 'emotion regulation', 'experience', 'flexibility', 'improved', 'in vivo', 'indexing', 'laboratory experience', 'longitudinal design', 'machine learning method', 'negative mood', 'network models', 'physical conditioning', 'post-traumatic stress', 'prospective', 'psychologic', 'public health relevance', 'recruit', 'response', 'social', 'stress disorder', 'tool', 'traumatic event']",NIMH,KENT STATE UNIVERSITY,R01,2021,664089
"Creating an artificial intelligence therapy-to-data feedback loop for child developmental healthcare Project Summary There is a sharp and increasing imbalance between the number of children with autism in need of care and the availability of specialists certified to treat the disorder in its multi-faceted manifestations. The autism community faces a dual clinical challenge: how to direct scarce specialist resources to service the diverse array of phenomes and how to monitor and validate best practices in treatment. Clinicians must now look to solutions that scale in a decentralized fashion, placing data capture, remote monitoring, and therapy increasingly into the hands of families. Using artificial intelligence (AI) and large amounts of labeled human emotion computer vision data, we have developed a solution for automatic facial expression recognition that runs on Google Glasses and Android smartphones to deliver real time social cues to individuals with autism in the child’s natural environment. We hypothesize that this informatic system can provide real-time therapy in a way that scales to meet the demand of the growing population of autism families, including underserved minorities, while growing data that can be used to measure progress over time and in the development of novel AI. Our first aim will focus on the development of a deep learning model that enables dynamic emotion recognition in the real world, and on domain adaptation procedures that enable minimal manual labeling to personalize the model for optimal accuracy on the individuals with whom the child will interact most regularly at home. Our second aim will focus on the human computer interface, namely the design of the user experience with the Android application that controls the sessions run on the Google Glass wearable. We will work our clinical colleagues and with groups of autism families to develop and enhance a set of games and activity modes that create social engagements ideal for emotion therapy, including an emotion capture and a charades game. The third aim will test our central hypothesis that the Glass system can create a therapy-to-data feedback loop that delivers clinical care while growing data for measurement and model development. We will work with up to 200 children ages 4-8 who have recent autism diagnoses and do not have access to standard behavioral therapy. We will build a community of autism families through crowdsourcing techniques, befitting the mobile paradigm embodied by our work, and through close collaboration with behavioral therapy providers, the autism outreach organization Autism Speaks, and the digital healthcare company, Cognoa. The families will work with us on design and refinement of our “Superpower Glass” system for fit, engagement, and function of use for both therapy and data capture. Importantly, we will send units home with families to use the device for at least 3 twenty-minute sessions per week for a minimum of 6 weeks. This remote period will generate a massive database to quantify overall social learning, emotion comprehension, eye contact, and sustained social acuity. In all, our work program will show that mobile wearable AI can bring the social learning process out of the clinic and into the real world for faster and more adaptive intervention. Project Narrative There is a sharp and growing imbalance between the number of clinical care providers available and the number of children with an autism diagnosis that leave most children without therapy until after critical periods in development have passed. We intend to address this problem through creation of a machine learning-enabled wearable that brings effective care to the home and empowers both parents, patients, and clinicians with mobile solutions that personalize care delivery to dramatically improve children’s outcomes. The Superpower Glass system, which delivers social cues to children during real-time interactions and provides several engagement modes for families, is a promising solution that enables greater access to care for families across the US, and potentially, across the globe.!",Creating an artificial intelligence therapy-to-data feedback loop for child developmental healthcare,10164858,R01LM013083,"['Address', 'Affect', 'Age', 'Android', 'Artificial Intelligence', 'Award', 'Awareness', 'Behavior Therapy', 'Car Phone', 'Caregivers', 'Caring', 'Cellular Phone', 'Child', 'Child Support', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Complex', 'Comprehension', 'Computer Vision Systems', 'Computer software', 'Control Groups', 'Cues', 'Data', 'Databases', 'Decentralization', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Emotions', 'Environment', 'Eye', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Family', 'Feedback', 'Future', 'Glass', 'Goals', 'Hand', 'Health Services Accessibility', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Informatics', 'Intervention', 'Label', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Parents', 'Participant', 'Patients', 'Persons', 'Population', 'Procedures', 'Process', 'Provider', 'Resources', 'Running', 'Secure', 'Self-Direction', 'Services', 'Severities', 'Social Interaction', 'Socialization', 'Specialist', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'User-Computer Interface', 'Variant', 'Waiting Lists', 'Work', 'adaptive intervention', 'applied behavior analysis', 'autism community', 'autism spectrum disorder', 'autistic children', 'base', 'care delivery', 'care providers', 'clinical care', 'combat', 'critical period', 'crowdsourcing', 'deep learning', 'design', 'digital healthcare', 'experience', 'improved', 'individuals with autism spectrum disorder', 'mobile application', 'mobile computing', 'model development', 'novel', 'outreach', 'personalized care', 'phenome', 'practical application', 'programs', 'prototype', 'remote monitoring', 'skills', 'smartphone Application', 'social', 'social engagement', 'social learning', 'standard of care', 'tool', 'underserved minority', 'user-friendly']",NLM,STANFORD UNIVERSITY,R01,2021,649383
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['3-Dimensional', 'Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
"Emotion Regulation in Distress Disorders: Elucidating the Role of Cognitive Processes and Person-Situation Fit in the Laboratory and Daily Life ABSTRACT: Emotion regulation (ER) is a key transdiagnostic process and treatment target, with particular relevance to distress disorders (depression, generalized anxiety disorder). Distress disorders, which are characterized by heightened negative emotions, are prevalent conditions with considerable public health burden and comparatively lower response to treatment. The efficacy of interventions for distress disorders may be improved by investigating components of effective ER, both as instructed in the lab (ER capacity) and as measured naturalistically in daily life (ER tendency). Effective ER is based on key components such as accurate perceptions of one's emotions (i.e., emotional awareness) as well sensitivity to the environmental context (i.e., contextual sensitivity), which facilitate the selection and implementation of the appropriate ER strategy. For individuals with distress disorders, elevated levels of perseverative negative thinking (PNT) interferes with these processes, contributing to ER deficits and increased symptoms. This contextualized and integrative model of ER in distress disorders has not been tested, and very little is known about the predictors or outcomes of effective ER tendency—a critical gap given that ER capacity is irrelevant if ER is not employed skillfully in daily life. Furthermore, examinations of ER tendency can show how individuals, considering their particular characteristics and abilities, can optimally match particular ER strategies to the specific situations they encounter. The goal of this application is to evaluate components of ineffective ER— both in the lab and in daily life— that influence the severity and course of distress disorders and functioning. Consistent with NIMH strategic objectives and the RDoC framework, this project incorporates multimodal assessment, dimensional symptom measurement, and machine learning approaches. The proposed study will be comprised of 300 adults, oversampled for elevated PNT (50%). Participants will complete a lab assessment to measure predictors of ER capacity, followed by a 10- day ecological momentary assessment study examining predictors of ER tendency in daily life. To better capture negative emotions as they occur, reports in daily life will be physiologically-triggered with algorithms that detect potential episodes of psychological stress. Effective ER will be operationalized in multiple ways in the lab and in daily life, using self-reported changes in affect, physiological indices, and perceived ER success. Effective ER capacity and tendency will then be examined as predictors of distress symptom, functioning, and well-being trajectories assessed monthly for 12 months. Additionally, an exploratory aim is to create predictive models from a multifaceted battery of theoretically motivated variables that impact ER tendency and subsequent clinical outcomes. To this end, machine learning will be used to build a clinically-relevant framework for how person- level, situation-level, and ER strategy use interact to predict optimal ER. Overall, this project contributes to the long-term goal of identifying and refining targets for personalized interventions, by more precisely isolating key mechanisms of effective ER for specific individuals and the contexts they encounter in their daily lives. Project Narrative The proposed study seeks to examine predictors (i.e., emotional awareness, contextual sensitivity, perseverative negative thinking) of dysfunctional emotion regulation that contribute to depression and anxiety, as well as to provide an initial framework for optimal emotion regulation in individualized daily life contexts. This study uses multiple measurements (behavioral, psychophysiological, self-report, clinical interview) in the laboratory and in naturalistic settings in daily life, and it focuses on dimensional and transdiagnostic features that underlie multiple disorders. Consistent with NIMH's mission, findings will be relevant to public health because they can help refine intervention targets and inform personalized treatment for depression and anxiety, which are common and impairing conditions.",Emotion Regulation in Distress Disorders: Elucidating the Role of Cognitive Processes and Person-Situation Fit in the Laboratory and Daily Life,10162664,R01MH118218,"['Adult', 'Affect', 'Algorithms', 'Anxiety', 'Applications Grants', 'Arousal', 'Awareness', 'Behavioral', 'Cardiovascular system', 'Characteristics', 'Clinical', 'Complex', 'Dimensions', 'Disease', 'Distress', 'Ecological momentary assessment', 'Emotional', 'Emotions', 'Generalized Anxiety Disorder', 'Goals', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Interview', 'Laboratories', 'Life', 'Machine Learning', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental Depression', 'Mission', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Perception', 'Personal Satisfaction', 'Persons', 'Physiological', 'Process', 'Psychological Stress', 'Psychophysiology', 'Public Health', 'Reporting', 'Research Domain Criteria', 'Risk', 'Role', 'Severities', 'Symptoms', 'Testing', 'Thinking', 'Time', 'Treatment Efficacy', 'Work', 'adaptive intervention', 'base', 'clinically relevant', 'cognitive process', 'comparative', 'emotion regulation', 'improved', 'improved outcome', 'indexing', 'innovation', 'multimodality', 'novel', 'personalized intervention', 'personalized medicine', 'predictive modeling', 'psychosocial', 'random forest', 'response', 'success', 'treatment response']",NIMH,UNIVERSITY OF WESTERN AUSTRALIA,R01,2021,428695
"Optimized Affective Computing Measures of Social Processes and Negative Valence in Youth Psychopathology ABSTRACT Difficulties with emotion expression and social behavior characterize multiple psychiatric conditions and negatively impact child development. However, existing measurement tools for indexing social-emotional function are imprecise and subjective, or require specialized training that is costly and time-intensive, prohibiting widespread implementation. The imprecision of existing tools has a major negative impact not only on research, but on the ability to assess and treat individuals with mental health concerns – especially among underserved and under-resourced populations. Here, we propose to address this problem by quantifying social and emotional behavior using novel biobehavioral markers derived from computer vision (facial expression analysis) and computational linguistics (social/sentiment analysis). Our team has successfully used these markers to predict the presence of autism spectrum disorder (ASD) with 91% accuracy. In this proposal, we determine the extent to which our markers can serve as continuous measures of social behavior and negative emotion to advance clinical phenotyping and interventions. The proposal brings together two high-bandwidth clinical research programs at the Children’s Hospital of Philadelphia and Baylor College of Medicine to collect data on 750 adolescents (ages 12-17 inclusive) with ASD, a primary anxiety or depressive disorder, or without any developmental/psychiatric condition. At a single assessment, all youth will participate in an extensive clinical phenotyping battery consisting of validated clinical interviews and child-/parent-report scales assessing converging and diverging mental health constructs, and three tasks eliciting positive/negative emotion, social stress, and mild frustration. A subsample of 150 adolescents will be reassessed 6-10 weeks later to allow retest/stability analyses. A novel camera apparatus will capture naturalistic synchronized verbal and nonverbal signals from dyads. Our analytic approach combines state-of-the-art machine learning, computational linguistics, and computer vision – including facial emotion recognition methods that rival several commonly used alternatives. The ultimate goal of this proposal is to develop valid and objective measures of the Social and Negative Valence Systems using novel biobehavioral markers in a large transdiagnostic sample of youth. Secondary goals are to develop easy-to-follow methods to widely disseminate our tools and procedures, and to characterize individual variability in these key RDoC metrics by age, gender, race/ethnicity, and diagnosis. The achievement of these goals will provide researchers with sorely needed measures of social and emotional behavior, and provide clinicians with a new set of tools for identifying and tracking youth in need of mental health treatment. PROJECT NARRATIVE Problems with negative emotion and social behavior are present across many behavioral health conditions, but are poorly measured with existing tools. This application addresses this problem by developing and validating novel facial expression and linguistic measures that can be easily and widely disseminated across research and clinical settings.",Optimized Affective Computing Measures of Social Processes and Negative Valence in Youth Psychopathology,10183399,R01MH125958,"['Achievement', 'Address', 'Adolescence', 'Adolescent', 'Age', 'Anxiety', 'Anxiety Disorders', 'Behavior', 'Behavior assessment', 'Behavioral Sciences', 'Child', 'Child Development', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Computational Linguistics', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Depressive disorder', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Elements', 'Emotional', 'Emotions', 'Ethnic Origin', 'Face', 'Facial Expression', 'Factor Analysis', 'Frustration', 'Funding', 'Gender', 'Goals', 'Grain', 'Hour', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Interview', 'Investments', 'Judgment', 'Laboratories', 'Linguistics', 'Machine Learning', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Modeling', 'Mood Disorders', 'Moods', 'Multivariate Analysis', 'NIH Program Announcements', 'National Institute of Mental Health', 'Negative Valence', 'Parents', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Philadelphia', 'Play', 'Population', 'Predictive Analytics', 'Procedures', 'Psychiatric Diagnosis', 'Psychopathology', 'Quality of life', 'Race', 'Reporting', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Sampling', 'Signal Transduction', 'Site', 'Smiling', 'Social Behavior', 'Social Processes', 'Specialist', 'System', 'Testing', 'Thinness', 'Time', 'Training', 'Translating', 'Trier Social Stress Test', 'Variant', 'Youth', 'affective computing', 'aged', 'autism spectrum disorder', 'autistic children', 'base', 'behavior measurement', 'behavioral health', 'biobehavior', 'clinical phenotype', 'college', 'cost', 'digital', 'emotional behavior', 'emotional functioning', 'experimental study', 'indexing', 'individual variation', 'natural language', 'novel', 'programs', 'repetitive behavior', 'response', 'showing emotion', 'social', 'social anxiety', 'social deficits', 'social metrics', 'social stress', 'tool']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2021,861615
"Neurocomputational Approaches to Emotion Representation Maintaining an adaptive balance of emotions is central to well-being, and dysregulated emotions contribute broadly to clinical disorders that impart high personal and societal burdens. Recognizing the transdiagnostic importance of emotion to mental health, the National Institute of Health's Research Domain Criteria (RDoC) matrix contains overarching domains of Negative Valence, Positive Valence, and Arousal. However, the matrix underspecifies how specific affective states like sadness, anxiety, or craving are organized within and across these domains, in part because it is unknown whether representations of discrete emotions are reliably differentiated. Other RDoC constructs, such as rumination and worry, modify the temporal parameters of emotions that confer psychopathology risk and exacerbate symptom maintenance. Nonetheless, it is unknown how these processes interface with emotional brain circuits to impact affect dynamics, particularly as they often occur spontaneously during mind wandering. The proposed research promises to improve the RDoC depiction of these emotion-related constructs by taking an affective computing approach. During combined recording of psychophysiology and functional magnetic resonance imaging (fMRI), adult participants will experience emotions to vignettes and movie clips spanning the arousal and valence dimensions, and will report on their spontaneous emotions during resting-state fMRI scans. Machine learning algorithms will decode emotion- specific signals across the levels of analysis, which will be integrated using Bayesian state-space modeling. An analysis of classifier errors will test competing predictions from emotion theories regarding the optimal structure of affective space. Using graph theoretic tools, we will characterize the neural network architecture of the discrete emotion representations to identify provincial and connector hubs that can be used as novel targets for future symptom-specific or co-morbid neuromodulation interventions, respectively. We will apply the emotion-specific maps to resting-state data from the same participants to create neurophysiological indices of spontaneous emotions and to relate their frequencies to measures of trait and state affect as a validation step. Using stochastic modeling of the resting-state data, we will derive temporal dynamics metrics to test the hypothesis that rumination and worry promote emotional inertia during mind wandering. Finally, we will use existing data repositories to demonstrate that our novel indices of affect dynamics transdiagnostically differentiate resting-state fMRI activity patterns in mental health disorders from healthy controls. The proposed research will improve upon current RDoC formulations of Negative Affect, Positive Affect, and Arousal domains by informing how discrete emotions are organized within and across these domains, by integrating emotion representations across multiple RDoC units of analysis, by informing how rumination and worry impact neurophysiological signatures of spontaneous emotions, and by establishing the clinical utility of computationally-derived metrics of emotion dynamics. PROJECT NARRATIVE  The overall goal of this project is to characterize how emotions are represented in the brain and autonomic nervous system. Computational modeling approaches will be applied to integrate the data across multiple sources and tasks, to test competing theories about how emotions are organized, and to derive new metrics of emotion dynamics. The outcome of the work will inform how emotions should be conceptualized within a broader research framework of mental health domains.",Neurocomputational Approaches to Emotion Representation,10227196,R01MH124112,"['Adult', 'Affect', 'Affective', 'Age', 'Anxiety', 'Arousal', 'Autonomic nervous system', 'Basic Science', 'Behavioral', 'Brain', 'Categories', 'Classification', 'Clinical', 'Clip', 'Code', 'Computer Models', 'Data', 'Depressed mood', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Equilibrium', 'Exhibits', 'Formulation', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Graph', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Link', 'Machine Learning', 'Maintenance', 'Maps', 'Measures', 'Mental Health', 'Mental disorders', 'Methods', 'Mind', 'Modeling', 'Negative Valence', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Population', 'Positive Valence', 'Process', 'Psychopathology', 'Psychophysiology', 'Reporting', 'Research', 'Research Domain Criteria', 'Rest', 'Risk', 'Role', 'Signal Transduction', 'Source', 'Space Models', 'Structure', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Work', 'affective computing', 'anxious', 'anxious individuals', 'base', 'biobehavior', 'comorbidity', 'craving', 'data repository', 'experience', 'functional MRI scan', 'improved', 'indexing', 'machine learning algorithm', 'markov model', 'movie', 'negative affect', 'neural network architecture', 'neurophysiology', 'neuroregulation', 'novel', 'organizational structure', 'relating to nervous system', 'repository', 'theories', 'tool', 'trait']",NIMH,DUKE UNIVERSITY,R01,2021,774017
