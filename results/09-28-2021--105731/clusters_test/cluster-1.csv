text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Direct Determination of Multiple Specific Forms of DNA Chemical Modifications in Human Genome PROJECT SUMMARY/ABSTRACT The information content of DNA is not limited to the primary sequence (A, C, G, T), but is also conveyed by chemical modifications of individual bases. For example, DNA methylation, specifically 5-methylcytosine (5mC), has been widely studied for its important regulatory roles in human development and diseases. In addition, the discovery of active demethylation of 5mC, mediated by TET enzymes, into 5-hydroxymethylcytosine (5hmC), 5-formylcytosine (5fC) and 5-carboxylcytosine (5caC) revealed great insights into the dynamic nature of the human methylome and its close relevance to multiple human diseases. Beyond these chemical modifications to cytosine, recent studies by us and others discovered that N6-methyladenine (6mA), another form of methylation previously thought exclusively existing in bacteria and protozoa, also exists in eukaryotic genomes including the human genome. In addition to these epigenetic marks, different forms of DNA damages represent another category of DNA chemical modifications that are of important biological relevance. Although a few methods for mapping individual chemical modifications have been developed and some are widely used, it is usually hard for broad researchers to master every protocol to map each form of modification. While third- generation sequencing technologies support the direct detection of DNA modifications, they face fundamental challenges distinguishing among different forms of modifications. The objective of this project is to develop a novel technology for the direct mapping of multiple forms of DNA methylation and DNA damage events simultaneously. The core idea is that each form of nucleic acid modification has a unique signature in terms of their physical interaction with DNA polymerase, or nanopores in third-generation sequencing; and these signatures can be modeled by deep learning methods. We will develop this technology using multiple innovative strategies to address a few fundamental challenges, and then comprehensively evaluate the technology to facilitate broad applications. PROJECT NARRATIVE Chemical DNA modifications are crucial components of human genome that controls many important biological processes in human development and human diseases. In this project, we will develop a novel technology for direct mapping of multiple and specific forms of DNA modifications, which will enable us and a large number of researchers to more effectively study the functions of DNA modifications in human genome.",Direct Determination of Multiple Specific Forms of DNA Chemical Modifications in Human Genome,10204438,R01HG011095,"['Address', 'Antibodies', 'Bacteria', 'Biological', 'Biological Process', 'Categories', 'Characteristics', 'Chemicals', 'Chemistry', 'Classification', 'Complex', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Methylation', 'DNA Modification Process', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Detection', 'Development', 'Discrimination', 'Ensure', 'Enzymes', 'Epigenetic Process', 'Evaluation', 'Event', 'Face', 'Future', 'Genome', 'Goals', 'Heterogeneity', 'Human', 'Human Characteristics', 'Human Development', 'Human Genome', 'Immunoprecipitation', 'Individual', 'Maps', 'Mediating', 'Methods', 'Methylation', 'Modeling', 'Modification', 'Neurons', 'Nucleic Acids', 'Performance', 'Ploidies', 'Protocols documentation', 'Protozoa', 'Research Personnel', 'Resolution', 'Role', 'Technology', 'Third Generation Sequencing', 'Time', 'Training', 'Variant', 'base', 'bisulfite sequencing', 'cancer risk', 'cell type', 'cost', 'deep learning', 'demethylation', 'exome', 'experience', 'human disease', 'innovation', 'insight', 'learning strategy', 'methylome', 'nanopore', 'network models', 'new technology', 'prototype', 'sequencing platform', 'single molecule', 'whole genome']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,833051
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,10113656,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2021,397125
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,10223179,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2021,1186500
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",10107826,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2021,479215
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,10240955,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Hi-C', 'Human', 'Human Biology', 'Human Genome', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2021,1975273
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,10131237,R00HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Visualization', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data framework', 'data integration', 'data reduction', 'data standards', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'learning classifier', 'multidimensional data', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R00,2021,249000
"Integrative genomic and epigenomic analysis of cancer using long read sequencing PROJECT SUMMARY The last twenty years have experienced extensive growth in the sequencing of cancer genomes, leading to a dramatically increased understanding of the role of genetic and epigenetic mutations in cancer. This has largely been enabled by developments in high-throughput “second-generation” sequencing technology and analysis that characterize cancer genomes using short-reads. Recently, a new generation of high-throughput long-read sequencing instruments, primarily from Pacific Biosciences and Oxford Nanopore, have become available that are poised to displace short-read sequencing for many applications. We and others have used these technologies to discover tens of thousands of variants per cancer genome that are not detectable using short-reads, including structural variants and differentially methylated regions in known oncogenes and cancer risk genes. These technologies carry the potential to address many open questions in cancer biology, however, the analysis of long-read sequencing data is computationally demanding and needs specialized algorithms that are either too inefficient to use at scale or do not yet exist. In this proposal, we will address several gaps in the application of long-read technology for basic research and clinical use in cancer genomics. First, we will develop improved methods for finding structural variants and complex repeat expansions from long-reads, both of which are major diagnostic and prognostic indicators of disease, yet are not accurately identified using existing methods. Leveraging the improved phasing capabilities of long reads, this work will include the detection of mosaic variants, revealing tumor heterogeneity and variants in precancerous tissues. Next, we will apply machine learning and systems level advances to accelerate and improve the comparison of variants across large patient cohorts. Critically, this will compensate for the error prone nature of single molecule long-read sequencing to make these comparisons more accurate when comparing tumor-normal samples or pedigrees of related patients so that recurrent driving mutations can be accurately identified. Finally, we will develop integrative methods for the joint analysis of genome, transcriptome, and epigenetic profiling of cancer genomes. These advances will improve the identification of fusion genes, and allow for entirely new forms of epigenetic analysis, such as the allele-specific analysis of methylation across transposable elements and other repetitive elements. Synthesizing the many thousands of novel variants we will detect using our methods, we will then develop algorithms that will identify and evaluate recurrent genetic or epigenetic variations as putative driving mutations. All methods will be released open-source and will empower us, our ITCR collaborators, and the cancer genomics community at large to study genetic and epigenetic variants with near perfect accuracy and thereby unlock many new associations to treatment and disease. PROJECT NARRATIVE Emerging long-read single molecule sequencing platforms are poised to establish a new level of quality and resolution in cancer genome sequencing. Here we will develop and enhance algorithms for several important tasks in genomics with long reads, including improved genetic variation detection, transcriptional profiling, and methylation analysis. We will then work with our collaborators and other researchers to deploy these methods to develop a more complete understanding of cancer progression.",Integrative genomic and epigenomic analysis of cancer using long read sequencing,10187808,U01CA253481,"['Accounting', 'Address', 'Algorithmic Analysis', 'Algorithms', 'Alleles', 'Automobile Driving', 'Basic Science', 'Bioinformatics', 'Biological Sciences', 'Cancer Biology', 'Cancerous', 'Cataloging', 'Characteristics', 'Clinical', 'Communities', 'Complex', 'Computing Methodologies', 'Copy Number Polymorphism', 'Cytosine', 'DNA Sequence Rearrangement', 'DNA Transposable Elements', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Ensure', 'Epigenetic Process', 'Gene Expression Profiling', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Graph', 'Growth', 'Health', 'Individual', 'Joints', 'Karyotype', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Methylation', 'Minisatellite Repeats', 'Modeling', 'Monitor', 'Mosaicism', 'Mutation', 'Nature', 'Normal tissue morphology', 'Oncogenes', 'Outcome', 'Pathogenicity', 'Patients', 'Phase', 'Population', 'Prognostic Marker', 'Protein Isoforms', 'Recurrence', 'Repetitive Sequence', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Signal Transduction', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'System', 'Tandem Repeat Sequences', 'Technology', 'Tissues', 'Tumor Suppressor Proteins', 'Variant', 'Work', 'base', 'cancer genome', 'cancer genomics', 'cancer initiation', 'cancer risk', 'cancer therapy', 'cancer type', 'cohort', 'disorder risk', 'driver mutation', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'experience', 'fusion gene', 'genetic pedigree', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'insight', 'instrument', 'methylome', 'nanopore', 'novel', 'novel strategies', 'open source', 'power analysis', 'premalignant', 'risk variant', 'sequencing platform', 'single molecule', 'transcriptome', 'transcriptomics', 'tumor', 'tumor heterogeneity', 'tumor progression']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2021,383463
"Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks Abstract Accurately detecting structural variation in the genome is a challenging task. Many approaches have been developed over the last few decades, yet it is estimated that tens of thousands of variants are still being missed in a given sample. Many of these variants are missed due to the limitations of using short-read sequencing to identify large variants. Although many of these missed variants are located within complex regions of the genome, it has been shown that some still have clinical relevance making their discovery important. New platforms have been developed for sequencing the genome using long-reads and show promise for overcoming many of these limitations creating the ability to identify the full spectrum of simple and complex structural variants. Because this technology is relatively young, new computational approaches to support the analysis of long-read sequencing data can aid in the discovery of these variants which are still being missed. In addition to detecting novel variation in samples with long-read sequencing data, computational approaches can be developed to leverage these novel variant calls to reanalyze the hundreds of thousands of short-read datasets currently available. In this proposal, we plan to develop new computational approaches to identify novel structural variation in the genome. In Aim 1, we will apply a recurrence approach to analyze long read sequencing datasets utilizing deep neural networks. In Aim 2, we will develop a tool to derive profiles of structural variants predicted in long- reads which can be used to identify and genotype structural variants calls in short read data-sets. Together, these approaches will allow researchers to accurately characterize structural variation in both long and short- read datasets. Narrative Structural variation has been implicated in numerous human diseases but there are still tens of thousands of variants being overlooked in the genome. The proposed research aims to detect novel variation by developing new computational tools to analyze data generated by state-of-the-art sequencing methods. These tools will aid in the discovery of variants associated with human health.",Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks,10128484,F31HG010569,"['Affect', 'Algorithms', 'Benchmarking', 'Biological Sciences', 'Categories', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Resequencing', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Future', 'Genome', 'Genotype', 'Haplotypes', 'Health', 'Human', 'Human Genome', 'Image', 'Image Analysis', 'Label', 'Methods', 'Molecular', 'Molecular Computations', 'Pattern', 'Process', 'Recurrence', 'Repetitive Sequence', 'Research', 'Research Personnel', 'Sampling', 'Structure', 'Techniques', 'Technology', 'Training', 'Validation', 'Variant', 'base', 'clinically relevant', 'comparative', 'computerized tools', 'cost', 'deep learning', 'deep neural network', 'design', 'detection method', 'genome sequencing', 'human disease', 'insertion/deletion mutation', 'new technology', 'novel', 'reference genome', 'structural genomics', 'tool', 'variant detection']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2021,38173
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,10136665,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2021,345658
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,10251876,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Hi-C', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2021,526482
"Computational tools for regulome mapping using single-cell genomic data Project Summary Understanding how genes' activities are controlled is crucial for elucidating the basic operating rules of biology and molecular mechanisms of diseases. Recent innovations in single-cell genomic technologies have opened the door to analyzing a variety of functional genomic features in individual cells. These technologies enable scientists to systematically discover unknown cell subpopulations in complex tissue and disease samples, and allow them to reconstruct a sample's gene regulatory landscape at an unprecedented cellular resolution. Despite these promising developments, many challenges still exist and must be overcome before one can fully decode gene regulation at the single-cell resolution. In particular, current technologies lack the ability to accurately measure the activity of each individual cis-regulatory element (CRE) in a single cell. They also cannot measure all functional genomic data types in the same cell. Moreover, the prevalent technical biases and noises in single-cell genomic data make computational analysis non-trivial. With rapid growth of data, lack of computational tools for data analysis has become a rate-limiting factor for effective applications of single-cell genomic technologies.  The objective of this proposal is to develop computational and statistical methods and software tools for mapping and analyzing gene regulatory landscape using single-cell genomic data. Our Aim 1 addresses the challenge of accurately measuring CRE activities in single cells using single-cell regulome data. Regulome, deﬁned as the activities of all cis-regulatory elements in a genome, contains crucial information for understanding gene regulation. The state-of-the-art technologies for mapping regulome in a single cell produce sparse data that cannot accurately measure activities of individual CREs. We will develop a new computational framework to allow more accurate analysis of individual CREs' activities in single cells using sparse data. Our Aim 2 addresses the challenge of collecting multiple functional genomic data types in the same cell. We will develop a method that uses single-cell RNA sequencing (scRNA-seq), the most widely used single-cell functional genomic technology, to predict cells' regulatory landscape. Since most scRNA-seq datasets do not have accompanying single-cell data for other -omics data types, our method will also signiﬁcantly expand the utility and increase the value of scRNA- seq experiments. Our Aim 3 addresses the challenge of integrating different data types generated by different single-cell genomic technologies from different cells. We will develop a method to align single-cell RNA-seq and single-cell regulome data to generate an integrated map of transcriptome and regulome.  Upon completion of this proposal, we will deliver our methods through open-source software tools. These tools will be widely useful for analyzing and integrating single-cell regulome and transcriptome data. By addressing several major challenges in single-cell genomics, our new methods and tools will help unleash the full potential of single-cell genomic technologies for studying gene regulation. As such, they can have a major impact on advancing our understanding of both basic biology and human diseases. Project Narrative Understanding how genes' activities are controlled at single-cell resolution is crucial for studying human diseases. This proposal will develop a coordinated set of computational and statistical methods and software tools for mapping and analyzing gene regulatory programs using single-cell genomic data. These methods and tools will allow scientists to more accurately and comprehensively reconstruct gene regulatory landscape of individual cells in complex tissue and disease samples, and they can have a major impact on advancing our understanding of both basic biology and human diseases.",Computational tools for regulome mapping using single-cell genomic data,10205134,R01HG010889,"['Address', 'Atlases', 'Behavior', 'Biological', 'Biology', 'Biomedical Research', 'Brain', 'Cells', 'Cellular Assay', 'Chromatin', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Emerging Technologies', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genomics', 'Human', 'Immune system', 'Individual', 'Knowledge', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Modality', 'Molecular', 'Multiomic Data', 'Noise', 'Organ', 'Phase', 'Population', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Software Tools', 'Statistical Methods', 'Stem Cell Development', 'System', 'Technology', 'Therapeutic', 'Tissues', 'Training', 'Transposase', 'base', 'computer framework', 'computerized tools', 'epigenome', 'experimental study', 'functional genomics', 'genomic data', 'histone modification', 'human disease', 'innovation', 'multiple data types', 'multiple omics', 'novel strategies', 'open source', 'predictive modeling', 'programs', 'rapid growth', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'supervised learning', 'tool', 'transcriptome', 'transcriptome sequencing', 'user-friendly']",NHGRI,JOHNS HOPKINS UNIVERSITY,R01,2021,409375
"Tools for Normalizing and Interpreting the Clinical Actionability of Genomic Variants PROJECT SUMMARY/ABSTRACT The availability of high-throughput, low-cost sequencing has transformed the landscape of biomedical research by dramatically expanding our capacity to interrogate the sequence of the human genome. Consequently, there has been an explosion of biomedical literature describing the role of specific genomic variants and their impact on human diseases. These advances are bringing sequencing into the clinic to shape clinical practice from the patient’s genomic content, a paradigm colloquially referred to as genomic or precision medicine. There remain many obstacles to fully realizing our potential in the era of precision medicine. Among them is a recognized need for robust, well-engineered systems that provide knowledge about genomic variants and their role in disease. Ideally, such systems would provide a comprehensive summary of all knowledge that is relevant to the patient’s unique genomic content. An early bottleneck to realizing precision medicine was that, despite the substantial literature and several established knowledgebases that define interactions between drugs and genes, querying across them was extremely challenging. In response to this need, the Drug-Gene Interaction database (DGIdb, dgidb.org) was developed. Through a combination of automated processing and manual curation, drug-gene interaction information was collected, structured, and connected (normalized) from these diverse sources of data and entered into a database with a user-friendly search interface and an application programming interface (API). However, linking drug and drug-gene interaction concepts across resources remains an extremely challenging task, and aggregated drug-gene interactions are also challenging to represent in a way that highlights the utility of the collected knowledge for precision medicine efforts. This proposal seeks to improve our ability to normalize and interpret drug-gene interactions corresponding to patient genomic variants. We will achieve this goal through two specific aims. First, the DGIdb normalization routines will be improved through incorporation of new content and features. Among these, the DGIdb will support collections of drugs, including combination therapies and drug classes. Also, the DGIdb will have new community submission and curation features, allowing users to incorporate new knowledge into the database. Second, the Variant Interpretation Aggregator database (VIAdb) will be created to normalize knowledge across several disparate sources focused on the clinical interpretations of genomic variants. The VIAdb will operate as a stand-alone web tool and API and will behave as a source of relevant interpretations to DGIdb. Finally, we will develop techniques for automated identification of drug-gene interactions and variant interpretation consensus to assist community curation efforts. If successful, this research will improve breadth and consistency of variant interpretations and drug-gene interactions for precision medicine efforts. PROJECT NARRATIVE This research will improve our ability to interpret genomic variations in human patients in support of precision medicine efforts. Specifically, it will provide web-based tools for identifying potential therapies that specifically target the patient’s individual genes or variants, and an assessment of the clinical actionability of those drugs.",Tools for Normalizing and Interpreting the Clinical Actionability of Genomic Variants,10415312,R00HG010157,"['Biological Markers', 'Biomedical Research', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Clinical assessments', 'Cohort Studies', 'Collection', 'Combined Modality Therapy', 'Communities', 'Consensus', 'Data', 'Databases', 'Development', 'Disease', 'Engineering', 'Explosion', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Internet', 'Knowledge', 'Level of Evidence', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Procedures', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Role', 'Services', 'Shapes', 'Side', 'Source', 'Structure', 'Suggestion', 'System', 'Techniques', 'The Vanderbilt-Ingram Cancer Center at the Vanderbilt University', 'Variant', 'Visualization', 'Work', 'application programming interface', 'base', 'cancer type', 'clinical practice', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'design', 'drug discovery', 'drug resource', 'gene interaction', 'genetic variant', 'genomic variation', 'human disease', 'improved', 'individual patient', 'knowledge base', 'learning strategy', 'molecular marker', 'novel', 'novel therapeutics', 'open source', 'precision medicine', 'profiles in patients', 'programs', 'response', 'therapeutic biomarker', 'tool', 'tumor', 'user-friendly', 'web app', 'web interface', 'web-based tool']",NHGRI,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,R00,2021,249000
"Organizational and Cultural Dynamics in Genomics Companies: Industry Engagement in Navigating Social and Ethical Issues This K99/R00 Award is designed to generate scholarship and interventions to guide genomics companies towards more just practices. It does so through a five-year training and research project, which investigates perspectives from members of the genomics industry, and leverages them to inform normative analyses and identify feasible paths towards concrete change. The project addresses issues of price, access and industrial control, with a focus on the ethics of profit and social responsibility. Through the proposed training program, the project prepares the candidate as an independent scholar whose research program links empirical and normative research with practical interventions to positively influence ethics and justice in private sector genomics. The first phase of research (conducted during the K phase, alongside training activities) is a comparative study examining social and cultural factors involved in perceptions of ethical issues among members of industry. The comparative study focuses on three biotech hubs in the US (the Bay Area, San Diego, and Boston), as well as an additional site in South Africa (Cape Town). The South African site helps place investigation of the US industry in light of a shifting global industry, and especially South Africa’s policy focus on genomics for population health (as well as its role in the H3Africa initiative). The study also considers industry subsector and individual company culture, in examining influences on industry approaches to social and ethical issues. During its R phase, the project then involves a systematic normative analysis of profit and social obligation in the genomics industry, based on key theories from bioethics and business ethics. The project will then feed this scholarly analysis back to industry stakeholders; using a Delphi study, it allows members of industry to use results of the normative analysis in strategizing interventions with the greatest likelihood of influencing the genomics industry in ethically desirable ways. This project addresses the NHGRI ELSI research priorities of genomic equity and social justice, as well as genomics and public health. Its career development plan focuses on training in normative analysis and Delphi methods, as well as content training in genomics and entrepreneurship. The training will be conducted at Johns Hopkins University, where the school’s preeminent bioethics center houses world experts in qualitative and quantitative empirical bioethics, alongside the University’s leading research and training in the biomedical sciences and their application in industry. The integrated research and training plan will prepare the candidate as an independent ELSI scholar with a rigorous research program focused on empirical and normative analysis of the business of biomedicine and genomics, and engagement with industry stakeholders. This Pathway to Independence Award (K99/R00) investigates and leverages perspectives from members of the health-related private sector genomics industry, to develop guidance for improving approaches to social and ethical issues in the industry. It does so through in-depth qualitative analysis (interviews, cases studies, comparative analysis), scholarly normative analysis (drawing on theories from bioethics and business ethics), and a Delphi process of iterative questionnaires with industry stakeholders, aimed at strategizing concrete change regarding social obligations of the industry. The research and training program is designed to contribute to a more just distribution of the benefits of genomic technologies.",Organizational and Cultural Dynamics in Genomics Companies: Industry Engagement in Navigating Social and Ethical Issues,10307826,R00HG010499,"['Address', 'Agreement', 'American', 'Area', 'Attention', 'Award', 'Back', 'Bioethics', 'Bioethics Consultants', 'Biotechnology', 'Boston', 'Businesses', 'California', 'Case Study', 'Comparative Study', 'Complement', 'Corporate Ethics', 'DNA', 'Decision Making', 'Delphi Study', 'Development', 'Development Plans', 'Diagnostic', 'Empirical Research', 'Employee', 'Entrepreneurship', 'Ethical Issues', 'Ethics', 'Face', 'Genetic', 'Genomic approach', 'Genomics', 'Goals', 'Government', 'Health', 'Health Technology', 'India', 'Individual', 'Industrialization', 'Industry', 'Inequality', 'Intervention', 'Interview', 'Investigation', 'Justice', 'Licensing', 'Light', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'National Human Genome Research Institute', 'Pathway interactions', 'Patients', 'Perception', 'Phase', 'Play', 'Policies', 'Price', 'Privacy', 'Private Enterprises', 'Private Sector', 'Privatization', 'Process', 'Public Health', 'Questionnaires', 'Research', 'Research Priority', 'Research Project Grants', 'Research Training', 'Role', 'Scholarship', 'Schools', 'Science', 'Shapes', 'Silicon', 'Site', 'Social Justice', 'Social Obligations', 'Social Responsibility', 'South Africa', 'South African', 'Strategic Planning', 'Structure', 'Technology', 'Therapeutic', 'Training', 'Training Activity', 'Training Programs', 'Universities', 'Work', 'base', 'career development', 'comparative', 'curative treatments', 'design', 'drug development', 'ethical legal social implication', 'experience', 'gene therapy', 'genome editing', 'improved', 'individual response', 'innovation', 'insight', 'member', 'nebula', 'next generation sequencing', 'novel diagnostics', 'novel therapeutics', 'operation', 'population health', 'programs', 'research and development', 'social', 'theories', 'training project']",NHGRI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R00,2021,249000
"Development of Technologies for Efficient In Vivo Prime Editing PROJECT SUMMARY  Genome editing is revolutionizing biomedicine and biotechnology by enabling the precise modification of genomic DNA in living cells. While various genome-editing tools have been developed over the past decade, the CRISPR-Cas9 system has emerged as a particularly versatile and efficient technology for editing DNA. Nonetheless, limitations derived from its reliance on DNA double strand breaks (DSB), which can lead to unpredictable editing outcomes and even chromosomal translocations, could limit its applications.  Base editors (BEs) and prime editors (PEs) are two novel classes of genome-editing tools capable of introducing precise single-base conversion in DNA without the requirement of a DSB. PEs, in particular, provide greater flexibility than BEs, owing to their ability to introduce any type of base conversion and even programable small insertions and deletions. This expanded set of capabilities compared to other technologies makes PEs a particularly promising platform for applications in biomedicine; however, the large size of PEs precludes their in vivo delivery by AAV, a promising and effective gene delivery vehicle that is currently under evaluation in multiple clinical trials.  To overcome these obstacles, we have created a split-PE platform that is compatible with AAV delivery and have demonstrated the functionality of this approach in cultured cells. Despite this progress, there still remain several critical challenges, which we here propose to overcome in order to optimize this technology for effective and specific in vivo prime editing.  To accomplish this objective, we have assembled a multidisciplinary team with collective expertise in genome editing (Dr. Perez-Pinera), AAV gene delivery (Dr. Gaj) and computational biology (Dr. Song). Our collaborative efforts will yield an integrated and comprehensive PE toolset that will blend strategies for target identification and editing optimization, with methods for reducing off-target effects and immune responses, thus priming this technology for future in vivo applications.  Given that the flexibility of PEs has significantly expanded the number of actionable target sites that can be genetically modified, we anticipate that the integrated technologies we develop will have large, direct and long- lasting impact in biomedicine by enabling not only novel gene therapies, but also basic research. In particular, our technology will provide investigators with biological tools that are uniquely capable of introducing mutations within post-mitotic cells in vivo, which could be used to dissect functional elements or even determine the role of pathogenic mutations in a cell- and tissue-specific manner. The technologies created by this application will thus broadly impact biotechnology and biomedicine. NARRATIVE Genome editing technologies provide novel opportunities to advance basic research and treat human diseases but approaches that use active nucleases to edit DNA can induce undesired and deleterious effects in the genome, which can reduce their therapeutic potential. Prime editors are a recently emerged gene-editing variant capable of introducing precise modifications to DNA, with minimal damage to the genome. This proposal is focused on creating an integrative prime editing toolkit that will provide investigators with technologies that will enable their use in vivo, improve their specificity and streamline their design and implementation, thereby advancing the applications of this methodology in biotechnology and biomedicine.",Development of Technologies for Efficient In Vivo Prime Editing,10184207,R01GM141296,"['Amyotrophic Lateral Sclerosis', 'Basic Science', 'Biological', 'Biotechnology', 'CRISPR/Cas technology', 'Carrying Capacities', 'Cells', 'Chromosomal translocation', 'Clinical Research', 'Clinical Trials', 'Computational Biology', 'Cultured Cells', 'DNA', 'DNA Double Strand Break', 'DNA Sequence', 'Data', 'Development', 'Elements', 'Engineering', 'Evaluation', 'Experimental Designs', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene Delivery', 'Genes', 'Genome', 'Genomic DNA', 'Genomic approach', 'Immune response', 'Knowledge', 'Lead', 'Machine Learning', 'Mediating', 'Methodology', 'Methods', 'Mitotic', 'Modification', 'Mutation', 'Nonsense Mutation', 'Open Reading Frames', 'Outcome', 'Pathogenicity', 'Peptide Signal Sequences', 'Poly A', 'Positioning Attribute', 'Regulatory Element', 'Research', 'Research Personnel', 'Role', 'Site', 'Site-Directed Mutagenesis', 'Specificity', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Trans-Splicing', 'Variant', 'adeno-associated viral vector', 'base', 'biophysical techniques', 'cell type', 'computational suite', 'design', 'experience', 'experimental study', 'flexibility', 'gene therapy', 'genome editing', 'human disease', 'immunogenic', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'intein', 'miniaturize', 'multidisciplinary', 'novel', 'nuclease', 'particle', 'predictive modeling', 'prevent', 'programs', 'promoter', 'reconstitution', 'response', 'success', 'technology development', 'technology research and development', 'tool']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,535871
"Large scale genome sequencing and integrative analyses to define genomic predictors of recurrent pregnancy loss SUMMARY: Recurrent pregnancy loss (RPL) occurs in approximately 5% of clinically recognized pregnancy losses. The etiology of RPL is not well characterized: after excluding the known etiologies, approximately half of women with RPL still have no identifiable cause. The fact that RPL is, in fact, recurrent suggests a strong genetic component, however there is currently a very limited understanding of the genomic contributions to RPL. Previous studies are typically deficient in their design, limited by small sample size, incomplete clinical phenotyping and/or the recruitment of singletons only. In this proposal, we put forward our plan to recruit 1000 rigorously-phenotyped RPL trios including from diverse and underrepresented backgrounds across the US and to apply WGS and sophisticated variant detection and interpretation methods developed by our labs to identify pathogenic and likely pathogenic variants for RPL. We will then perform comprehensive integrative data analyses to define the genetic basis of unexplained RPL and map the genes and regions of the chromosome that are absolutely required for human development and a successful pregnancy. Our variant interpretation pipeline includes cutting edge approaches to map likely pathogenic noncoding and structural variants rarely assessed in any pregnancy loss study. We will also perform a pilot RNA-seq study to assess the utility of this approach for gene discovery in the pregnancy loss setting. We will first look for recessive pathogenic variation, including compound heterozygosity and then test for models for de novo mosaicism, mitochondrial mutations, regulatory noncoding variation and overall mutational burden. From these combined analyses, we expect to uncover many variants in genes and regions of the chromosome that are intolerable to functional variation, which we define as the human intolerome. We will build on our previous studies to map the intolerome by combining i) available data from all clinical studies to define the genetic etiology of unexplained pregnancy loss, including data generated in this proposal and in our prior work, ii) network-based approaches to prioritize variants genes important for human development and pregnancy, iii) mouse (KOMP, DMDD/MGI) and cell line knockout studies iv) rare and common disease sequencing studies including Centers for Mendelian Genomics (CMG), Center for Common Disease Genomics (CCDG) and Pediatric Cardiac Genomics Consortium (PCGC), iv) emerging human pangenome studies HPP, and v) population-scale biobank projects such as UK BioBank and All of Us. We will then confirm these predictions via collaborator-led functional studies and retrospective analyses of RPL first losses, siblings and grandparents. The sharing of early, unpublished data from the Yale CMG and HPP enabled by our leadership in these projects is a significant strength of what will be by far the largest and most comprehensive study of RPL performed to date. Our findings will take great strides towards the goal of comprehensively mapping the human intolerome and will further expand and refine the exploratory space in which to investigate the genes and chromosomal regions essential for human development. Project Narrative The proposed study is to conduct a large scale genomic discovery of recurrent pregnancy loss using an integrated and innovative genomics approach and construct an intolerome to guide the evaluation of pregnancy loss in clinic and studies of the human early development.",Large scale genome sequencing and integrative analyses to define genomic predictors of recurrent pregnancy loss,10226657,R01HD105267,"['Bioinformatics', 'Biometry', 'Cell Line', 'Chromosomes', 'Clinic', 'Clinical', 'Clinical Research', 'Code', 'Collaborations', 'Collection', 'Conceptions', 'Counseling', 'Couples', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Etiology', 'Evaluation', 'Fathers', 'Fetal Development', 'Funding', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Heterozygote', 'Human', 'Human Development', 'Human Genetics', 'Knock-out', 'Lead', 'Leadership', 'Machine Learning', 'Maps', 'Mendelian disorder', 'Methods', 'Minority', 'Mitochondria', 'Modeling', 'Mosaicism', 'Mothers', 'Mouse Cell Line', 'Mus', 'Mutation', 'National Institute of Child Health and Human Development', 'Nature', 'Network-based', 'Pathogenicity', 'Pediatric Cardiac Genomics Consortium', 'Phenotype', 'Pilot Projects', 'Population', 'Pregnancy', 'Pregnancy loss', 'Recurrence', 'Reproductive Health', 'Reproductive Medicine', 'Research', 'Sample Size', 'Sampling', 'Short Tandem Repeat', 'Siblings', 'Site', 'Structure', 'Sum', 'Testing', 'Untranslated RNA', 'Variant', 'Woman', 'Work', 'base', 'biobank', 'bioinformatics tool', 'clinical phenotype', 'clinical research site', 'cohort', 'computerized data processing', 'design', 'exome sequencing', 'experience', 'gene discovery', 'genetic architecture', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic predictors', 'genomic variation', 'grandparent', 'human pangenome', 'improved', 'innovation', 'multidisciplinary', 'multimodality', 'novel', 'recruit', 'tool', 'transcriptome sequencing', 'variant detection', 'whole genome']",NICHD,YALE UNIVERSITY,R01,2021,1524247
"Polygenic Risk Score (PRS) Methods and Analysis for Populations of Diverse Ancestry - Study Sites Abstract/Summary Globally, non-communicable diseases (NCDs) outrank infectious diseases in terms of public health burden. Cardiometabolic diseases (CMD) such as heart disease and stroke are the leading causes of death worldwide. In this application we will explore the genomic risk for common CMD, including hypertension, stroke, diabetes, obesity, dyslipidemia and kidney disease, and related traits (including BMI, blood pressure, lipid, glucose, insulin and creatine) across populations with African ancestry (AA). There is evidence to suggest that polygenic risk scores (PRSs) translate poorly from a discovery study in one ancestral population (e.g. European Americans) to a target population (e.g. sub-Saharan Africans), especially when they are separated by large genetic differences. However, this has not been evaluated with large, well-powered AA datasets. Furthermore, the high genetic diversity and population structure among non-European Ancestry (EA) populations need to be investigated to understand the performance of PRSs in other regions populated by people with diverse genomic backgrounds. We bring together the Human Heredity and Health in Africa Consortium (H3Africa), other African, Jamaican and African American core cohorts, to develop a joint resource of over 50,000 participants with relevant phenotype and genomics data, referred to as the CARdiometabolic Disorders IN African-ancestry PopuLations (CARDINAL) Study Site. In addition, the CARDINAL Study Site will include 5 replication cohorts with >100,000 participants from diverse ancestry populations. Our main objective is to establish a Study Site for PRS Methods and Analysis for AA Populations and to collaboratively generate and refine PRS for other populations of diverse ancestry by integrating existing datasets with genomics and phenotype data for a range of complex diseases and traits. Our first aim is to integrate phenotype and genomic datasets from ~50,000 African individuals from seven individual cohort studies. Subsequently, we will evaluate PRSs and develop a novel method that takes into consideration, ancestry-specific genomic regions to improve prediction of PRSs in populations characterised by genetic sub-structure. Finally, we will develop an interactive dashboard for dissemination of PRS-related data from diverse ancestry populations. CARDINAL Study Site is ideal for generating novel biologic insights into complex disease etiology, with applications in global populations. Members of the CARDINAL team have successfully worked together for about a decade, generating and disseminating scientific knowledge through high impact publications. By establishing a Study Site in the Polygenic Risk Score Diversity Consortium, CARDINAL brings the largest cohort of African-ancestry participants to the table, to explore the genomics contribution to common CMDs and other NCDs. Narrative Cardiometabolic diseases are on the increase worldwide, contributing to high levels of morbidity and mortality, with limited resources among lower-resource populations in North America and Africa to prevent disease, make diagnosis and clinically manage patients. In this study we bring together ~50,000 African-ancestry participants (African American, Jamaicans and continental African) to form the CARDINAL study to assess and develop polygenic risk scores for cardiometabolic diseases and traits, and to develop analytic approaches for multi-ethnic cohorts leveraging the increased genetic diversity and lower linkage disequilibrium in African genomes. This research will lead to a better understanding of the transferability of polygenic risk scores from discovery to target populations of different ethnicities, informing prevention and diagnostic strategies that could contribute to the development of effective public health policies.",Polygenic Risk Score (PRS) Methods and Analysis for Populations of Diverse Ancestry - Study Sites,10212798,U01HG011717,"['Admixture', 'Affect', 'Africa', 'African', 'African American', 'Algorithms', 'Alleles', 'American', 'Biological', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Cause of Death', 'Chronic Disease', 'Clinical Management', 'Cohort Studies', 'Communicable Diseases', 'Complex', 'Country', 'Creatine', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Diagnostic', 'Disease', 'Dyslipidemias', 'Environment', 'Environmental Risk Factor', 'Ethnic Origin', 'Etiology', 'European', 'Funding', 'Gene Frequency', 'Genetic', 'Genetic Risk', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Glucose', 'Guidelines', 'Health', 'Health Policy', 'Heart Diseases', 'Heredity', 'Heterogeneity', 'Human', 'Hypertension', 'Individual', 'Insulin', 'Jamaican', 'Joints', 'Kidney Diseases', 'Knowledge', 'Lead', 'Life Style', 'Linkage Disequilibrium', 'Lipids', 'Methods', 'Modeling', 'Morbidity - disease rate', 'North America', 'Northern Africa', 'Obesity', 'Participant', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Population', 'Population Analysis', 'Population Heterogeneity', 'Population Study', 'Prevention', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'Quality Control', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Scientist', 'Scoring Method', 'Signal Transduction', 'Site', 'Stroke', 'Structure', 'Target Populations', 'Translating', 'Trust', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'burden of illness', 'cardiometabolism', 'clinical risk', 'cohort', 'dashboard', 'data harmonization', 'data integration', 'data standards', 'disorder risk', 'diverse data', 'genome wide association study', 'genomic data', 'genomic variation', 'health disparity', 'health inequalities', 'improved', 'insight', 'interactive tool', 'lifestyle data', 'machine learning method', 'member', 'mortality', 'novel', 'phenotypic data', 'polygenic risk score', 'population stratification', 'prevent', 'tool', 'trait', 'working group']",NHGRI,UNIVERSITY OF MARYLAND BALTIMORE,U01,2021,958531
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,10202452,U01AI157189,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Bar Codes', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell receptor repertoire sequencing', 'T cell response', 'T-Cell Proliferation', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'detection limit', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'machine learning method', 'next generation', 'novel', 'novel therapeutics', 'off-target mutation', 'off-target site', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2021,610061
"Scalable detection and interpretation of structural variation in human genomes PROJECT SUMMARY Structural variation (SV), is a diverse class of genome variation that includes copy number variants (CNVs) such as deletions and duplications, as well as balanced rearrangements, such as inversions and reciprocal translocations. A typical human genome harbors >4,000 SVs larger than 300bp and their large size increases the potential to delete or duplicate genes, disrupt chromatin structure, and alter expression. Despite their prevalence and potential for phenotypic consequence, SVs remain notoriously difficult to detect and genotype with high accuracy. Much of this difficulty is driven by the fact DNA sequence alignment “signals” indicating SVs are far more complex than for single-nucleotide and insertion deletion variants. Unlike SNP alignments that vary only in allele state, alignments supporting SVs vary in state (supports an alternate structure or not) alignment location, and type. Consequently, the accuracy of SV discovery is much lower than that of SNPs and INDELs. Furthermore, SV pipelines scale poorly and are difficult to run. These challenges are a barrier for single genome analysis and studies of families must invest substantial effort into eliminating a sea of false positives. These problems become exponentially more acute for large-scale sequencing efforts such as TOPmed, the Centers for Common Disease Genetics, and the All of Us program. Software efficiency is key to scalability for such projects. However, of equal importance is comprehensive, accurate discovery.  Building upon more than a decade of software development experience and analyzing SV in diverse disease contexts, we have invested significant effort into understanding the causes of the insufficient accuracy for SV discovery. These efforts, together with our research and development experience in this area, give us unique insight into improving the accuracy and scalability of SV discovery. Our goal is to narrow the accuracy gap between SNP/INDEL variation and structural variation discovery. These developments will empower studies of human genomes in diverse contexts and will therefore have broad impact. Our goals are to: 1. Develop a deep learning model to correct systematic variation in sequence depth. This new machine  learning model will correct systematic biases in DNA sequence depth and dramatically improve the  discovery of deletions and duplications. 2. Improve the speed, scalability, and accuracy of SV detection and genotyping. Using new algorithms,  we will bring the accuracy of SV detection much closer to that of SNP and INDEL discovery and allow  accurate SV discovery to be deployed at scale. 3. Create a map of genomic constraint for SV from population-scale genome analysis. We will deploy  our new methods to detect and genotype structural variation among tens of thousands of human genomes.  The resulting SV map will empower the creation of a model of genomic constraint for SV and enable new  software to predict deleterious SVs, especially in the noncoding genome. PROJECT NARRATIVE Single-nucleotide DNA changes paint an incomplete picture of a human’s genome. A more complete picture must include a genome's structural variation (SV), an important class of genome variation that includes copy number variants (CNVs) such as deletions and duplications. However, existing methods have poor accuracy. As the genetics community transitions to large-scale genome sequencing studies, there is an acute need for improved SV discovery methods. This proposal introduces a series of algorithmic and software innovations that will empower SV discovery, genotyping, and interpretation in large-scale human disease studies.",Scalable detection and interpretation of structural variation in human genomes,10153847,R01HG010757,"['Acute', 'Affect', 'Algorithmic Software', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Area', 'Automobile Driving', 'Biological Assay', 'Chromatin Structure', 'Chromosome Structures', 'Clip', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Data Reporting', 'Detection', 'Development', 'Disease', 'Environment', 'Error Sources', 'Exhibits', 'Family Study', 'Funding', 'Future', 'Gene Duplication', 'Gene Expression', 'Gene Fusion', 'Gene Structure', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Laboratories', 'Large-Scale Sequencing', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Noise', 'Nucleotides', 'Paint', 'Pathogenicity', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Process', 'Reciprocal Translocation', 'Research', 'Running', 'Sampling', 'Sea', 'Sensitivity and Specificity', 'Sequence Alignment', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Speed', 'Structure', 'Systematic Bias', 'Techniques', 'Technology', 'Training', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'algorithm development', 'base', 'convolutional neural network', 'deep learning', 'developmental disease', 'dosage', 'exome', 'experience', 'genome analysis', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'innovation', 'insertion/deletion mutation', 'insight', 'large datasets', 'method development', 'nanopore', 'novel', 'prevent', 'research and development', 'software development', 'success', 'tool', 'variant detection', 'whole genome']",NHGRI,UNIVERSITY OF UTAH,R01,2021,692048
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,10133117,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Comparative Effectiveness Research', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'computer science', 'data sharing', 'design', 'digital', 'diverse data', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'machine learning algorithm', 'machine learning method', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2021,249000
"Identification of Transposable Element Insertions in the Kids First Data Project Summary Insertion of transposable elements (TEs, sometimes referred to as “jumping genes”) into the human genome can be pathogenic. Our aim in this project is to use sophisticated computational approaches to characterize TE insertions in the whole-genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program and identify any insertional mutations that may disrupt gene function. The large scale of the Kids First program provides an unprecedented opportunity to investigate the role of TE insertions in childhood cancers and structural birth defects, as well as to create a resource of reference TE maps that will be important for all other TE studies. We will first modify our existing algorithm called xTEA for the trio design of the Kids First studies and increase the accuracy and efficiency of the algorithm. Then, we will apply it to the thousands of trios that have been profiled in the Kids First program, using a pipeline optimized for the cloud environment. The resulting set of TE insertions (especially L1, Alu, SVA, and HERV insertions) will be curated with all relevant features and be made into a database for the community. We will also apply machine learning methods to improve the calls once a sufficient amount of training data have been obtained. To investigate the potential pathogenicity of the mutation, we will first focus on insertions within genes, but we will also explore those in regulatory elements inferred from epigenetic profiling data. PROJECT NARRATIVE Transposable elements, or “jumping genes”, are genetic elements that can alter the DNA of an individual. We aim to utilize a computational method to identify such elements in the genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program. Our analysis will identify transposable elements that may be causal for a disease phenotype.",Identification of Transposable Element Insertions in the Kids First Data,10172875,R03CA249364,"['Algorithms', 'Communities', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Insertion Elements', 'DNA Transposable Elements', 'Data', 'Data Set', 'Databases', 'Disease', 'Elements', 'Endogenous Retroviruses', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Human Genome', 'Individual', 'Inherited', 'Insertion Mutation', 'Jumping Genes', 'Length', 'Location', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Maps', 'Mendelian disorder', 'Methods', 'Modeling', 'Mutation', 'Neurons', 'Output', 'Parents', 'Paste substance', 'Pathogenicity', 'Pediatric Research', 'Play', 'Population', 'Regulatory Element', 'Reporting', 'Resources', 'Retrotransposon', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Speed', 'Structural Congenital Anomalies', 'Training', 'base', 'cloud based', 'cohort', 'design', 'disease phenotype', 'epigenetic profiling', 'gene function', 'genetic element', 'genome sequencing', 'improved', 'machine learning method', 'proband', 'programs', 'transcriptome sequencing', 'whole genome']",NCI,HARVARD MEDICAL SCHOOL,R03,2021,169000
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10207692,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,382894
"Scalable tools to effectively translate genomic discoveries into the clinic PROJECT SUMMARY We are in the midst of a genomic revolution; more than 250,000 human genomes have been sequenced, generating over a petabase of genomic data. While these new data hold great promise to impact health, there is a disconnect between genomic discovery and clinical care. Providers frequently misinterpret genomic information, patients often don't understand their own test results, and genomic information about disease risk is infrequently shared between patients and family members. Importantly, ineffective communication and data misinterpretation has devastating consequences- including unnecessary organ removal, missed disease prevention opportunities, and premature death. We are addressing these genomic care gaps by developing and testing tools that optimize the integration of whole-exome and whole-genome sequencing (WES, WGS) for general clinical practice. My vision for improving genomic medicine is based on my work within multidisciplinary consortia and addresses the National Human Genome Research Institute's priority research area of improving the effectiveness of healthcare. In the proposed work we will test the effectiveness of a multilevel genomic e-Health intervention in cancer (Aim 1). Our intervention 1) educates physicians and patients about genomics, 2) enables direct-to-patient return-of- results, 3) provides physicians with patient-specific results and resources for interpretation, and 4) facilitates sharing of genomic results within families. We hypothesize that intervention use will result in higher rates of uptake of high-quality, genetically guided care. We will test our hypothesis in a randomized controlled trial among academic and community physicians who use WES for their patients. Next, we will use an iterative process, with stakeholder engagement, to adapt and pilot test our tool for Spanish and Mandarin speaking patients and for patients who have diabetes (Aim 2). Finally, we will create and assess new, moderated, social networks as a platform for genomic information sharing (Aim 3). Our hypothesis is that providers, patients and family members will engage with the genomic information sharing social networks and find them to be highly useful. Our general approach includes 1) creating the secure social networks, 2) integrating the networks into our e-Health intervention, and 3) using complementary methods, such as interviews and natural language processing, to assess stakeholders' network-related attitudes and network information quality. If successful, we will be well positioned to widely disseminate our e-Health tools. In sum, this work stands to transform how people obtain, process and share genomic information in the context of clinical care. Our tools reconceive genetic communication to allow for multi-directional flow of information, connects multiple stakeholders with one another, and integrates high-quality dynamic web-based resources to improve genomic care. In creating and deploying tools that both respond to and leverage the complexities of our information environment, we intend to transform genomic research and clinical practice. PROJECT NARRATIVE/ RELEVANCE OF PROJECT TO RESEARCH AND PUBLIC HEALTH Widespread utilization of genomic sequencing in medicine creates an urgent need to educate providers and patients. Currently, providers frequently misinterpret genomic information and patients often don't understand their own test results. In order to address this critical need, we propose to design and test multiple e-Health communication tools that will help providers and patients to better understand genomic data, lead to higher quality patient care, and facilitate genomic information sharing within families.",Scalable tools to effectively translate genomic discoveries into the clinic,10204071,R35HG010721,"['Address', 'Area', 'Attitude', 'Caring', 'Cessation of life', 'Clinic', 'Communication', 'Communication Tools', 'Community Physician', 'Data', 'Diabetes Mellitus', 'Effectiveness', 'Environment', 'Excision', 'Family', 'Family member', 'Genetic', 'Genome', 'Genomic medicine', 'Genomics', 'Health', 'Healthcare', 'Human Genome', 'Information Networks', 'Intervention', 'Interview', 'Lead', 'Malignant Neoplasms', 'Medicine', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Organ', 'Patient Care', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Provider', 'Public Health', 'Randomized Controlled Trials', 'Research', 'Research Priority', 'Resources', 'Secure', 'Social Network', 'Sum', 'Test Result', 'Testing', 'Translating', 'Vision', 'Work', 'base', 'clinical care', 'clinical practice', 'design', 'disorder prevention', 'disorder risk', 'eHealth', 'effectiveness testing', 'exome', 'genome sequencing', 'genomic data', 'genomic platform', 'improved', 'multidisciplinary', 'online resource', 'premature', 'tool', 'uptake', 'whole genome']",NHGRI,BECKMAN RESEARCH INSTITUTE/CITY OF HOPE,R35,2021,527496
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),10147746,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'efficacy evaluation', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2021,162000
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Single cell quantification of genomic instability in cancer as a determinant of therapeutic response PROJECT ABSTRACT Tumor genetic heterogeneity is an extensive feature of cancer biology and underlies patient response to therapy. One aspect of tumor heterogeneity that has been difficult to study is heterogeneity of large genomic aberrations, including high level amplifications a few megabases in size, whole or partial chromosomal gains and losses and whole genome duplications. This is because identifying these aberrations in subclonal populations (present in <100% of cells) is extremely challenging when sequencing tumors in “bulk”. Single cell genomics however, can resolve these alterations at cellular resolution enabling precise quantification of heterogeneity at these genomic length scales. To comprehensively investigate the extent and consequences of intra-tumor heterogeneity generated by these types of genomic aberrations I will leverage recent advances in robust highly scalable single cell whole genome sequencing and my expertise in computational modeling. In the K99 phase of the award I will investigate how differences in the ability of cells to repair their genomes results in different patterns of genetic heterogeneity, and how such cellular diversity can cause differential response to treatment in high grade serous ovarian cancer, a cancer driven by genomic instability. In the independent phase of the award I will focus on heterogeneity and evolutionary dynamics of extra-chromosomal DNA, small circular pieces of DNA that cause high level amplification of oncogenes. The results of this proposal have the potential to give fundamental new insight into the biology of genomic instability and enable better predication of patient response to therapy and identification of therapeutic vulnerability that may be exploited. This proposal also describes a training plan to advance my career to an independent investigator, combining computational modeling inspired by evolutionary theory, machine learning and high-resolution genomics to quantify cancer evolution in order to better predict patient response to therapy and uncover the mechanisms driving cancer progression. During the K99 phase I will be supported by an interdisciplinary team of experts in single cell genomics, cancer evolution, ovarian cancer biology and genomic instability. I will broaden my knowledge of machine learning, genomic instability and scalable bioinformatics software engineering and improve my communication and leadership skills vital for my transition. PROJECT NARRATIVE In this research proposal we will study how the instability inherent to the genomes of cancer cells impact patient response to therapy. We envisage that the results from this proposal will enable better prediction of patient response to therapy and reveal therapeutic vulnerabilities that may be exploited to design more effective therapies.",Single cell quantification of genomic instability in cancer as a determinant of therapeutic response,10115351,K99CA256508,"['Aftercare', 'Alleles', 'Automobile Driving', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Bioinformatics', 'Biological', 'Biology', 'Breast Epithelial Cells', 'CCNE1 gene', 'Cancer Biology', 'Cancer Patient', 'Cell Line', 'Cells', 'Chromosomal Gain', 'Chromosomal Loss', 'Collection', 'Communication', 'Computer Models', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Pathway', 'Data', 'Defect', 'Elements', 'Environment', 'Evolution', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genetic Heterogeneity', 'Genome', 'Genomic Instability', 'Genomics', 'Heterogeneity', 'Immersion', 'Knowledge', 'Leadership', 'Length', 'Lesion', 'Loss of Heterozygosity', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Mentors', 'Methods', 'Modeling', 'Mutagenesis', 'Neoplasm Metastasis', 'Oncogenes', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Play', 'Population', 'Prediction of Response to Therapy', 'Primary Neoplasm', 'Process', 'Property', 'Relapse', 'Research', 'Research Personnel', 'Research Proposals', 'Resistance development', 'Resolution', 'Role', 'Route', 'Sampling', 'Serous', 'Software Engineering', 'TP53 gene', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Treatment outcome', 'cancer cell', 'cancer genome', 'cancer genomics', 'cancer type', 'career', 'chromosome missegregation', 'design', 'effective therapy', 'extrachromosomal DNA', 'fitness', 'genome sequencing', 'genomic aberrations', 'genotoxicity', 'improved', 'insight', 'mutant', 'novel strategies', 'outcome forecast', 'patient derived xenograft model', 'patient response', 'profiles in patients', 'programs', 'repaired', 'response', 'single cell technology', 'single-cell RNA sequencing', 'skills', 'theories', 'tool', 'treatment comparison', 'treatment response', 'tumor', 'tumor heterogeneity', 'tumor progression', 'whole genome']",NCI,SLOAN-KETTERING INST CAN RESEARCH,K99,2021,99798
