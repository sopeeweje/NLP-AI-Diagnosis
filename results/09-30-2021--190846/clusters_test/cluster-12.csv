text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"High Performance Text Mining for Translator We propose to build a knowledge provider that will seek out, integrate and provide AI-ready, BioLink-compatible models via high-performance text-mining of the biomedical literature. Problems with Translator’s current mining of the biomedical literature that we intend to solve include: (1) weaknesses in framework extensibility and benchmarking that make integrating and validating new text-mining approaches difficult; (2) problematic licensing of software, terminologies and other resources that do not adequately support FAIR (and TLC) best practices; (3) processing only PubMed titles and abstracts, not full text publications; (4) Translator’s use of older NLP technology with relatively poor performance; (5) lack of a mechanism for community feedback regarding errors and other problems; (6) lack of continuous updates to add knowledge from new publications; (7) output knowledge representation that is simplistic and vague, failing to reflect the richness of what is expressed in scientific documents. Plan for implementation: Our team has a long history of productive NLP research, successful open source software projects, effective benchmarking and broad community engagement. We will build on the results of NLM-funded work in information extraction, our gold-standard Colorado Richly Annotated Full Text (CRAFT) corpus, a recent BioNLP Open Shared Task (BioNLP-OST) that we organized, and recent advances in state-of-the-art NLP. For Segment 1, we will: (1) Demonstrate BioStacks, an extensible, cloud-based text-mining framework that produces knowledge graphs grounded in the Open Biomedical Ontologies (OBOs). This BioStacks demo will include a state-of-the-art OBO concept recognizer for multiple ontologies, a state-of-the-art semantic relationship prediction tool, and a state-of-the-art structural analysis tool. All generated assertions will have provenance metadata linking the assertion to a particular text span in a document specified by PMCID. (2) Demonstrate CRAFTST, a cloud-based text-mining evaluation system that evaluates the performance of text-mining systems against the CRAFT gold standard. (3) Demonstrate an adaptive machine learning process illustrating how to efficiently create tools to extract BioLink association types. For Segment 2, we propose to extend the text-mining and evaluation frameworks to align with BioLink and the Translator community, improve text-mining quality and expand the collection of source documents mined. Specifically, we propose to target 10 long term milestones: (1) Align CRAFT to BioLink. (2) Develop new tools for extracting associations from text. (3) Develop and manage a community engagement process on text-mining for Translator. (4) Extend benchmarking. (5) Improve recall. (6) Improve precision. (7) Improve computational efficiency. (8) Expand BioStacks to include all available full text biomedical journal articles. (9) Expand document collections to include Patents & Regulatory filings. (10) Develop a scientist-based movement to improve document access for text-mining from non-open publishers. The types of questions the resulting knowledge graph can be used to address are extremely broad, as it is generated by mining a large part of the biomedical literature. Questions that can be answered include those about specific assertions (e.g. is this drug an agonist-activator of this protein?), general relations (are these two proteins often mentioned together?), and documents (which publications mention this gene, mutation and drug?). Integration: We are long-time contributors to the open-science community and have longstanding collaborations with existing awardees; we were participants in the NIH Data Commons Pilot. We propose to align the output of text-mining tools to the BioLink model via OBO terms. We propose to implement our frameworks in NIH Cloud Computing environments. We propose to adopt the CD2H Contributor Attribution Model to foreground community contributions. We plan to coordinate with the NLM’s nascent benchmarking activities and the SmartAPI effort to build Translator standard interfaces. Challenges and gaps: High-performance mining of rich, contextualized knowledge from the literature remains a difficult task, and is unlikely to be solved in the next five years. Many important publications remain inaccessible to text-mining due to restrictive licensing. n/a",High Performance Text Mining for Translator,10334356,OT2TR003422,"['Address', 'Adopted', 'Agonist', 'Benchmarking', 'Cloud Computing', 'Collaborations', 'Collection', 'Colorado', 'Communities', 'Computer software', 'Data Commons', 'Environment', 'Evaluation', 'Feedback', 'Funding', 'Gene Mutation', 'Gold', 'Information Retrieval', 'Knowledge', 'Legal patent', 'Licensing', 'Link', 'Literature', 'Machine Learning', 'Metadata', 'Mining', 'Modeling', 'Movement', 'Ontology', 'Output', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'PubMed', 'Publications', 'Recording of previous events', 'Research', 'Resources', 'Scientist', 'Semantics', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Terminology', 'Text', 'Time', 'United States National Institutes of Health', 'Update', 'Work', 'base', 'biomedical ontology', 'cloud based', 'improved', 'information organization', 'journal article', 'knowledge graph', 'knowledge of results', 'open data', 'open source', 'text searching', 'tool']",NCATS,UNIVERSITY OF COLORADO DENVER,OT2,2021,471239
"The Metadata Powerwash - Integrated tools to make biomedical data FAIR Project Summary  The metadata that describe scientific data are fundamental resources to enable (1) the discovery and reuse of the data and (2) the reproducibility of the experiments that generated the data in the first place. Metadata are essential for scientists to understand the associated data and to reuse them, as well as for information technology to index the data, to make the data available, and to provide filters for scientists to search for the corresponding datasets. Currently, the scientific metadata hosted in public repositories suffer from multiple quality issues that limit scientists’ ability to find and reuse the experimental datasets to which they refer. It can take many weeks of a scientist’s time to identify a collection of datasets that fulfill specific criteria when the data are so poorly described—and the majority of the process is necessarily manual.  We propose to develop an end-to-end solution to standardize biomedical metadata with the help of ontologies—data structures that define the terms in an application domain and the relationships among them. There are hundreds of ontologies that provide standard terms for use in biomedicine, and they are essential resources to make biomedical metadata interoperable and reusable. Our approach also will build on the technology created by the Center for Expanded Data Annotation and Retrieval (CEDAR), which offers a library of building blocks and common data elements for defining computer-based metadata templates based on community standards.  Our plan involves three specific aims. First, we will develop a method and tool to standardize the multiple, ad hoc metadata field names that may appear in metadata to represent the same type of information by replacing those field names with the field names used in standard metadata templates or, if no appropriate template match is available, with terms from a relevant ontology. Second, we will develop methods and tools to standardize different types of metadata field values, for example, categorical values such as drugs or diseases, and numerical values such as age, or sample collection date. Third, we will evaluate the speed, precision, and recall of our metadata transformation pipeline—built out of the methods and tools to standardize field names and values—on a large corpus of metadata that we will manually curate based on existing public metadata. We will also carry out experiments to test the effect of the standardized metadata when biomedical scientists perform dataset search in the context of their work. Project Narrative Data that offer precise descriptions of data—metadata—are critical scientific resources that facilitate the discovery, reuse, and reproducibility of the data to which they refer. Our goal is to create methods and tools that improve the quality of scientific metadata hosted in public repositories, and thus enhance the discoverability and re-use of public biomedical datasets. Making data more accessible through scientifically rigorous metadata will accelerate the ability to make transformative data-driven biomedical discoveries using public data archives.",The Metadata Powerwash - Integrated tools to make biomedical data FAIR,10093841,R01LM013498,"['Age', 'Biological Specimen Banks', 'Categories', 'Collection', 'Common Data Element', 'Communities', 'Computers', 'Data', 'Data Science', 'Data Set', 'Disease', 'FAIR principles', 'Funding Agency', 'Goals', 'Gold', 'Information Technology', 'Knowledge', 'Libraries', 'Link', 'Manuals', 'Metadata', 'Methods', 'Names', 'Natural Language Processing', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Problem Solving', 'Process', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Sampling', 'Science', 'Scientist', 'Specific qualifier value', 'Speed', 'Standardization', 'Structure', 'Technology', 'Testing', 'Time', 'Variant', 'Work', 'base', 'biomedical scientist', 'data archive', 'data repository', 'data reuse', 'experimental study', 'improved', 'indexing', 'information organization', 'interoperability', 'metadata standards', 'public repository', 'repository', 'sample collection', 'search engine', 'secondary analysis', 'tool']",NLM,STANFORD UNIVERSITY,R01,2021,334847
"Temporal relation discovery for clinical text Project Summary / Abstract The current proposal continues the investigation on the topic of temporal relation extraction from the Electronic Medical Records (EMR) clinical narrative funded by the NLM since 2010 (Temporal Histories of Your Medical Events, or THYME; thyme.healthnlp.org). Through our efforts so far, we have defined the topic as an active area of research attracting attention across the world. Since its inception, the project has pushed the boundaries of this highly challenging task by investigating new computational methods within the context of the latest developments in the fields of natural language processing (NLP), machine learning (ML), artificial intelligence (AI) and biomedical informatics (BMI) resulting in 60+ publications/presentations. We have made our best performing methods available to the community open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES; ctakes.apache.org). In 2015, 2016, 2017 and 2018, we organized an international shared task (Clinical TempEval) on the topic under the umbrella of the highly prestigious SemEval, thus inviting the international community to work with our THYME data and improve on our results. Clinical TempEval has been highly successful with many participants each year, resulting in new discoveries and many publications. We have made all our data along with our gold standard annotations available to the community through the hNLP Center (center.healthnlp.org).  The underlying theme of this renewal is novel methods for combining explicit domain knowledge (linguistic, semantic, biomedical ontological, clinical), readily available unlabeled data (health-related social media, EMRs), and modern machine learning techniques (e.g. neural networks) for temporal relation extraction from the EMR clinical narrative. Therefore, our renewal proposes a novel and much needed exploration of this line of research:  Specific Aim 1: Develop computational models for novel rich semantic representations such as the Abstract Meaning Representations to encapsulate a single, coherent, full-document graphical representation of meaning for temporal relation extraction  Specific Aim 2: Develop computational methods to infuse domain knowledge (linguistic, semantic, biomedical ontological, clinical) into modern machine learning techniques such as NNs for temporal relation extraction – through input representations, pre-trained vectors, or architectures  Specific Aim 3: Develop novel methods for combining labeled and unlabeled data from various sources (EMR, health-related social media, newswire) for temporal relation extraction from the clinical narrative  Specific Aim 4: Apply the best performing methods for temporal relation extraction developed in SA1-3 to temporally sensitive phenotypes for direct translational sciences studies. Dissemination efforts through publications and open source releases into Apache cTAKES. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EMR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,10176589,R01LM010090,"['Address', 'Apache', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer Models', 'Computerized Medical Record', 'Computing Methodologies', 'Coupled', 'Data', 'Development', 'Disease', 'Encapsulated', 'Engineering', 'Event', 'Fostering', 'Foundations', 'Funding', 'Goals', 'Gold', 'Health', 'Image', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Label', 'Linguistics', 'Link', 'Machine Learning', 'Medical', 'Methods', 'Modernization', 'Natural Language Processing', 'Nature', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Publications', 'Recording of previous events', 'Research', 'Semantics', 'Signs and Symptoms', 'Solid', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Text', 'Thyme', 'Time', 'TimeLine', 'Training', 'Translational Research', 'Vision', 'Work', 'advanced disease', 'base', 'biomedical informatics', 'biomedical ontology', 'clinically relevant', 'cohesion', 'electronic data', 'electronic structure', 'epidemiology study', 'improved', 'individualized medicine', 'learning community', 'neural network', 'next generation', 'novel', 'open source', 'programs', 'relating to nervous system', 'social media', 'support vector machine', 'symptom treatment', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,531398
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"Knowledge-Based Biomedical Data Science Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. Building on decades of work in biomedical ontology development, and exploiting the architectures supporting the Semantic Web, we have demonstrated methods that allow effective querying spanning any combination of data sources in purely biological terms, without the queries having to reflect anything about the structure or distribution of information among any of the sources. These methods are also capable of representing apparently conflicting information in a logically consistent manner, and tracking the provenance of all assertions in the knowledge-base. Perhaps the most important feature of these methods is that they scale to potentially include nearly all knowledge of molecular biology.  We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data. To test this hypothesis, we propose to address the following specific aims:  1. Identify representative and significant analytical needs in knowledge-based data science, and  refine and extend our knowledge-base to address those needs in three distinct domains: clinical  pharmacology, cardiovascular disease and rare genetic disease.  2. Develop novel and implement existing symbolic, statistical, network-based, machine learning  and hybrid approaches to goal-driven inference from very large knowledge-bases. Create a goal-  directed framework for selecting and combining these inference methods to address particular  analytical problems.  3. Overcome barriers to broad external adoption of developed methods by analyzing their  computational complexity, optimizing performance of knowledge-based querying and inference,  developing simplified, biology-focused query languages, lightweight packaging of knowledge  resources and systems, and addressing issues of licensing and data redistribution. Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data.",Knowledge-Based Biomedical Data Science,10197219,R01LM008111,"['Address', 'Adoption', 'Architecture', 'Area', 'Artificial Intelligence', 'Biological', 'Biology', 'Biomedical Research', 'Cardiovascular Diseases', 'Clinical Data', 'Clinical Pharmacology', 'Collaborations', 'Communities', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Duchenne muscular dystrophy', 'Fruit', 'Funding', 'Genomics', 'Goals', 'Heart failure', 'Hybrids', 'Information Distribution', 'Information Resources', 'Knowledge', 'Language', 'Licensing', 'Literature', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Network-based', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Publishing', 'Role', 'Semantics', 'Serum', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'biomedical data science', 'biomedical ontology', 'cohort', 'computer based Semantic Analysis', 'design and construction', 'health data', 'innovation', 'knowledge base', 'large scale data', 'light weight', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'online resource', 'ontology development', 'rare genetic disorder', 'tool', 'transcriptomics']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2021,506502
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,10149399,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,313018
